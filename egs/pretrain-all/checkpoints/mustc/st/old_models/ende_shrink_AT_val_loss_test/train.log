2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18900
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 07:22:16 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 07:22:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18900', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 07:22:18 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:22:18 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:22:18 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 07:22:18 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 07:22:18 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:22:23 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 07:22:23 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 07:22:23 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 07:22:25 | INFO | root | load pretrained hubert
2023-07-03 07:22:25 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:22:28 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:22:29 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:22:29 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 07:22:29 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 07:22:29 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 07:22:29 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 07:22:29 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 07:22:29 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 07:22:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 07:22:29 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:22:29 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:22:29 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:22:29 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:22:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 07:22:39 | INFO | torch.distributed.distributed_c10d | Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:2 (world_size=8, worker_count=3, timeout=0:30:00)
2023-07-03 07:22:39 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 07:22:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 07:22:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:22:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:22:40 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 07:22:40 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 07:22:40 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:22:40 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:22:40 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 07:22:40 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:22:40 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:22:40 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:22:42 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:22:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:22:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:23:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 07:23:50 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 07:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 07:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 07:24:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 07:25:06 | INFO | train_inner | epoch 001:    102 / 1474 loss=12.747, trans_loss=5.643, nll_loss=4.219, w2v_ctc_loss=13.809, task_loss=18.858, contrastive_loss=3.303, total=4194.74, n_correct=213.33, ppl=18.62, accuracy=5.086, wps=18787.9, ups=1.5, wpb=12531.3, bsz=465.1, num_updates=100, lr=4.098e-06, gnorm=0.667, clip=0, loss_scale=32, train_wall=68, gb_free=19, wall=146
2023-07-03 07:26:11 | INFO | train_inner | epoch 001:    202 / 1474 loss=11.387, trans_loss=5.44, nll_loss=4.025, w2v_ctc_loss=11.882, task_loss=20.334, contrastive_loss=3.293, total=4125.46, n_correct=256.5, ppl=16.28, accuracy=6.217, wps=18958.6, ups=1.54, wpb=12321.8, bsz=461.7, num_updates=200, lr=8.096e-06, gnorm=2.253, clip=0, loss_scale=32, train_wall=65, gb_free=19, wall=211
2023-07-03 07:27:15 | INFO | train_inner | epoch 001:    302 / 1474 loss=7.148, trans_loss=5.443, nll_loss=4.089, w2v_ctc_loss=5.397, task_loss=23.143, contrastive_loss=3.219, total=4077.62, n_correct=240.03, ppl=17.02, accuracy=5.887, wps=19018.9, ups=1.56, wpb=12184.2, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=2.867, clip=0, loss_scale=32, train_wall=64, gb_free=19.5, wall=275
2023-07-03 07:28:19 | INFO | train_inner | epoch 001:    402 / 1474 loss=6.399, trans_loss=5.481, nll_loss=4.167, w2v_ctc_loss=4.192, task_loss=23.037, contrastive_loss=3.263, total=4177.45, n_correct=197.87, ppl=17.97, accuracy=4.737, wps=19416, ups=1.56, wpb=12472.6, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=1.854, clip=0, loss_scale=32, train_wall=64, gb_free=19, wall=339
2023-07-03 07:29:24 | INFO | train_inner | epoch 001:    502 / 1474 loss=6.134, trans_loss=5.492, nll_loss=4.202, w2v_ctc_loss=3.77, task_loss=20.979, contrastive_loss=3.338, total=4202.06, n_correct=187.66, ppl=18.41, accuracy=4.466, wps=19425.4, ups=1.54, wpb=12582.1, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.897, clip=0, loss_scale=32, train_wall=64, gb_free=16.9, wall=404
2023-07-03 07:30:28 | INFO | train_inner | epoch 001:    602 / 1474 loss=6.031, trans_loss=5.585, nll_loss=4.338, w2v_ctc_loss=3.583, task_loss=20.119, contrastive_loss=3.281, total=4124.52, n_correct=210.85, ppl=20.23, accuracy=5.112, wps=19252.5, ups=1.56, wpb=12305.7, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.489, clip=0, loss_scale=32, train_wall=63, gb_free=19.1, wall=468
2023-07-03 07:31:32 | INFO | train_inner | epoch 001:    702 / 1474 loss=5.912, trans_loss=5.519, nll_loss=4.281, w2v_ctc_loss=3.497, task_loss=21.028, contrastive_loss=3.125, total=4147.01, n_correct=336.75, ppl=19.45, accuracy=8.12, wps=19330.9, ups=1.56, wpb=12358.1, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=64, gb_free=19.4, wall=532
2023-07-03 07:32:36 | INFO | train_inner | epoch 001:    802 / 1474 loss=5.761, trans_loss=5.485, nll_loss=4.221, w2v_ctc_loss=3.347, task_loss=20.472, contrastive_loss=3.08, total=4121.11, n_correct=301.27, ppl=18.65, accuracy=7.31, wps=19233.6, ups=1.56, wpb=12306.8, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=64, gb_free=19.3, wall=596
2023-07-03 07:33:40 | INFO | train_inner | epoch 001:    902 / 1474 loss=5.669, trans_loss=5.54, nll_loss=4.303, w2v_ctc_loss=3.228, task_loss=20.645, contrastive_loss=2.928, total=4167.98, n_correct=244.3, ppl=19.73, accuracy=5.861, wps=19387.4, ups=1.56, wpb=12422.1, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.731, clip=0, loss_scale=32, train_wall=64, gb_free=19.2, wall=660
2023-07-03 07:34:44 | INFO | train_inner | epoch 001:   1002 / 1474 loss=5.487, trans_loss=5.495, nll_loss=4.237, w2v_ctc_loss=3.069, task_loss=19.504, contrastive_loss=2.802, total=4136.38, n_correct=244.05, ppl=18.86, accuracy=5.9, wps=19315.1, ups=1.56, wpb=12363.4, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=0.813, clip=0, loss_scale=32, train_wall=64, gb_free=19.5, wall=724
2023-07-03 07:35:48 | INFO | train_inner | epoch 001:   1102 / 1474 loss=5.306, trans_loss=5.486, nll_loss=4.22, w2v_ctc_loss=2.942, task_loss=18.377, contrastive_loss=2.534, total=4148.31, n_correct=243.46, ppl=18.63, accuracy=5.869, wps=19369.4, ups=1.57, wpb=12363.5, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=0.992, clip=0, loss_scale=32, train_wall=63, gb_free=18.9, wall=788
2023-07-03 07:36:52 | INFO | train_inner | epoch 001:   1202 / 1474 loss=5.112, trans_loss=5.383, nll_loss=4.089, w2v_ctc_loss=2.825, task_loss=18.427, contrastive_loss=2.295, total=4134.43, n_correct=310.43, ppl=17.02, accuracy=7.508, wps=19258.8, ups=1.56, wpb=12370.3, bsz=438.4, num_updates=1200, lr=4.8076e-05, gnorm=1.012, clip=0, loss_scale=32, train_wall=64, gb_free=19.6, wall=852
2023-07-03 07:37:56 | INFO | train_inner | epoch 001:   1302 / 1474 loss=4.954, trans_loss=5.324, nll_loss=4.018, w2v_ctc_loss=2.713, task_loss=17.224, contrastive_loss=2.105, total=4055.44, n_correct=323.39, ppl=16.2, accuracy=7.974, wps=19116.1, ups=1.58, wpb=12117.4, bsz=442.9, num_updates=1300, lr=5.2074e-05, gnorm=1.036, clip=0, loss_scale=32, train_wall=63, gb_free=19.3, wall=915
2023-07-03 07:39:00 | INFO | train_inner | epoch 001:   1402 / 1474 loss=4.838, trans_loss=5.308, nll_loss=4.014, w2v_ctc_loss=2.616, task_loss=16.377, contrastive_loss=2.134, total=4125.61, n_correct=334.48, ppl=16.16, accuracy=8.107, wps=19155.7, ups=1.56, wpb=12282.5, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.079, clip=0, loss_scale=32, train_wall=64, gb_free=18.8, wall=980
2023-07-03 07:39:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Traceback (most recent call last):
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 6 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 505, in validate
    trainer.valid_step(sample)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 1127, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 687, in valid_step
    loss, sample_size, logging_output = self._per_task_pair_valid_loss(per_task, model, criterion, sample)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 567, in _per_task_pair_valid_loss
    loss, sample_size, logging_output = criterion(model, sample[per_task], per_task)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT.py", line 241, in forward
    st_src_tokens, st_src_lengths, st_prev_output_tokens = sample['st']["net_input"].values()
ValueError: too many values to unpack (expected 3)

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 32 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 07:47:07 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18755
2023-07-03 07:47:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 07:47:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 07:47:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 07:47:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 07:47:08 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:47:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 07:47:10 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18755', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 07:47:10 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:47:10 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:47:10 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 07:47:10 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 07:47:10 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:47:15 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 07:47:15 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 07:47:15 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 07:47:17 | INFO | root | load pretrained hubert
2023-07-03 07:47:20 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:47:23 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:47:27 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:47:27 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 07:47:27 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 07:47:27 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 07:47:27 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 07:47:27 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 07:47:27 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 07:47:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 07:47:27 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:47:27 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:47:27 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:47:27 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:47:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 07:47:33 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 07:47:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 07:47:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:47:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:47:34 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 07:47:34 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 07:47:34 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:47:34 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:47:34 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 07:47:34 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:47:34 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:47:34 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:47:35 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:47:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:47:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:48:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 07:48:43 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 07:48:43 | INFO | fairseq_cli.train | Start iterating over samples
##################### {'id': tensor([140734, 102130, 217915, 154201,  57473, 221038, 212034, 219433,  19857,
        190343,  10566,  10159, 201525, 208235,  63347, 107042, 212265, 108641,
        101967,  11949,  97027,  70554,   5472,  48529], device='cuda:6'), 'net_input': {'src_tokens': tensor([[-0.0017, -0.0050, -0.0045,  ..., -0.0016, -0.0020, -0.0016],
        [ 0.0023,  0.0013,  0.0012,  ...,  0.0030,  0.0006, -0.0034],
        [-0.0012, -0.0012, -0.0008,  ...,  0.0011,  0.0016,  0.0023],
        ...,
        [ 0.0375, -0.0006, -0.0222,  ...,  0.0032,  0.0078,  0.0000],
        [ 0.0532,  0.0718,  0.0733,  ..., -0.1022, -0.0996,  0.0000],
        [-0.0054, -0.0065, -0.0062,  ..., -0.0299, -0.0042,  0.0000]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([75840, 75840, 75840, 75840, 75840, 75840, 75840, 75840, 75840, 75840,
        75840, 75840, 75840, 75840, 75840, 75840, 75840, 75840, 75840, 75839,
        75839, 75839, 75839, 75839], device='cuda:6'), 'prev_output_tokens': tensor([[   2,  228,  141,  ...,    1,    1,    1],
        [   2,   64,    9,  ...,    1,    1,    1],
        [   2,  202,   27,  ...,    1,    1,    1],
        ...,
        [   2,   72,  557,  ...,    1,    1,    1],
        [   2, 1297,  153,  ...,    1,    1,    1],
        [   2,  147,  114,  ...,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[   9,   13, 1880, 4745,    4,   25,  498,   71,  211, 2837,    8,  211,
         4774,   10, 1393,   17,  199, 2332,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   29,  131, 3696,    7, 4221,    4,   24,   73,  446,  126,  261,
          143,   80,  155, 1037,  254,   25,  914,  135,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 101,   11,    6,    7, 6099,   12,  958,    9,    7, 6869, 8521, 2353,
           12, 5205,    4,    9,  421,  234,   48,  365,  221,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  24,  162,   86, 2841,    9, 1979,    5,  290,    5,   69,    7, 5225,
           38, 2862,  781,  918,   93,  197, 1017,    5, 2503,   18,  650,  568,
           86, 2115,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [3398, 7936,    8,  284, 1543, 1948, 1985,   87,   21, 2373,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,   84,   11,    6,  288,   91,  227,   15,    6, 2158,  207,   10,
          205,  106,   84,   44,   25,  175,  717,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  10,  101,  128,    4,   10, 1008,    4,   10,  289,   44,   38,  533,
         2056,   13, 1738, 1234,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 206,   11,    6,    7, 2808,   42,   38,  533, 1412, 2215,  159, 2360,
           10,    7, 2182,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 473,  111,    4,   33,   26,   13, 2322,   35, 5444, 2595,  856,  293,
            4,  125,   19,   66,   29,  294, 1516,    6,    9,   89, 1995,  918,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [7494,  185, 1118,  307,   34,   39, 1830,   35, 1933,   35, 1178, 2988,
          120,  101,   34, 1920,   22, 1371,   62,  106, 3022, 1146,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   33,   26,  116,  133,  946,   46,  183,   26,   69,    7, 3089,
           35, 7988,  340,    8,    7, 2509,   26,   69,    7, 1995,   35, 7988,
          340,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,  169,  154, 1827, 1794,  162, 4491,    4,  166,  818,   53,  451,
          601,   25,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   10,   87,   17,    4,   25, 1275,   66,   10, 4988,   13, 1472,
           12, 2066,  416, 1374,  572,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 115,    4, 1220,   25,  659,   51, 1211,   12, 1835,    4,   38,  187,
           11,   45,   86,    9,   18, 2687,  241,   54,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  70,   11,    6,    7,  613,   12,  117, 3742, 3228,    6,   17,   25,
           11,  121,  591,   42,   38,  511,  101,  246,  438,  238,    4,   19,
           11,  121,  211,  479,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [  33,  188, 8166,   19,  362, 1838, 1428,   55,   70,    7, 1479,   26,
          142,   10,   87,    9,    7,  858,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  17,   11,    6, 5653,   10, 1719,   59, 5292, 3147,  111, 1830,  439,
           55, 2677,    8,  248,   10,  391,  439,   55, 5031,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,  180, 2568,  347,   19,  305,   29,  261, 7003,  106, 4990,  589,
          596,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   7, 2403,   26,   17,   84,   11,    6,   13,  785,   35, 9058, 3900,
            4,   86,    7, 1953,  322,   35, 3149,   35,  290,   35, 8856, 3900,
          100,   10, 4482, 2147,    4,   67,   13,  785,   35, 9058, 3900,    5,
            2],
        [   8,    7, 1714,  608,  423,  439,    4,   53,  305,   80,  248,  439,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 244, 2869, 4021,    4, 2008, 6248, 1405,   91,   12,    7,  281, 3861,
          338, 3232,  128, 4621,   24,  135,   80,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,   11,   45,  142,   10,  575,   25,  138, 7218,  204, 2895,    6,
           71,  108, 5967,  282,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 110,  153,  240, 1547,    6, 3067,   62, 6873,    4,    8, 1645, 9745,
            6,    4,  593,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  67,  103,   25,  192,   11,   18,   66, 6759,   35,    6, 2174,  297,
           62, 3867,    4,  180,    7,  630,   12, 1703, 6230,   26,   13,  341,
           91, 5020,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 37, 28, 94, 11, 37, 49, 37, 50, 32, 37, 50, 94, 37, 40, 37, 37, 94,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 83, 37, 59, 37, 47, 11, 38,  6, 59, 37, 83, 50, 37, 37, 94, 37, 37,
         83, 59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 85, 37, 37,  9, 37, 94, 37, 37, 28,  2, 23, 37, 28, 11, 37, 38, 35,
         31, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 85, 83, 49, 37, 38, 11, 35, 11, 37, 37,  2, 38, 35, 35, 35, 35, 82,
         31, 11, 38, 35, 35, 85, 83, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [ 9, 28, 37, 37,  9, 83,  6, 85, 37, 83, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 37, 85, 37, 83, 50, 38, 77, 37, 77, 83, 37, 85, 37, 37, 82, 37, 85,
         34, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 38, 35, 11, 37, 59, 11, 37, 88, 82, 38, 35, 16, 37,  2, 94, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 85, 37, 37, 32, 11, 38, 35,  6, 49, 37, 24, 37, 37,  9, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 83, 11, 37, 85, 37, 29, 38, 28, 29, 58, 35, 11, 37, 38, 85, 83, 50,
         29, 37, 37, 37, 38, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [28, 50, 56, 77, 85, 38, 34, 38, 24, 38, 35,  9, 37, 38, 85,  9, 35, 35,
         31, 37, 28, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 37, 85, 83, 83,  2, 11, 24, 85, 37, 37, 38, 38, 35, 35, 37, 37, 94,
         85, 37, 37, 38, 38, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 85, 59, 56, 56, 85, 56, 11, 37, 88, 37, 85, 49, 37, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 37, 85, 37, 11, 37, 83, 85, 37, 29, 37, 32, 37, 38, 35, 77, 47, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 11, 83, 37,  6, 38, 88, 37, 37, 11, 38, 35, 85, 35, 83, 37, 35, 35,
         35, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [50, 85, 37, 37, 32, 37, 37, 12, 94, 37, 37, 37, 85, 35, 31, 11, 38, 35,
         38, 88, 82, 83, 11, 38, 85, 35, 50, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37],
        [37, 85,  2, 38, 35, 35, 44, 37, 50, 37,  9, 85, 49, 37, 85, 37, 37, 94,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 85, 37, 36, 37, 38, 35, 35, 35, 83, 34, 24, 37, 49, 37, 34, 37, 34,
         24, 37, 59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 37, 31, 83, 38, 49, 83, 83, 94, 37, 28, 35, 56, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 94, 85, 37, 37, 85, 37, 37, 34, 38, 24, 94, 11, 83, 37, 38, 35, 38,
         35, 38, 35, 38, 24, 94, 37, 37, 35, 35, 11, 37, 37, 34, 38, 24, 94, 11,
         83],
        [37, 37,  2, 75, 34, 24, 11, 37, 49, 37, 34, 24, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 50, 24, 11, 28, 28, 31, 50, 37, 37, 75, 38, 35, 35, 35, 56, 38, 59,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 85, 35, 49, 37, 88, 37, 37,  9, 83, 36, 37, 37, 37, 24, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 77, 35, 77, 37, 49, 31, 94, 11, 37,  6, 94, 37, 11, 83, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 37, 37, 85, 85, 35, 85,  9, 38, 37, 35, 35, 31,  9, 11, 37, 37, 94,
         37, 49, 35, 85, 37, 33, 50, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37]], device='cuda:6'), 'lengths': tensor([20, 22, 23, 28, 12, 21, 18, 17, 26, 24, 27, 16, 19, 22, 30, 20, 23, 15,
        37, 14, 21, 18, 17, 28], device='cuda:6'), 'ntokens': 518}, 'target': tensor([[ 228,  141, 4756,  ...,    1,    1,    1],
        [  64,    9,  631,  ...,    1,    1,    1],
        [ 202,   27,   23,  ...,    1,    1,    1],
        ...,
        [  72,  557,  252,  ...,    1,    1,    1],
        [1297,  153,  240,  ...,    1,    1,    1],
        [ 147,  114,   81,  ...,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([21, 23, 23, 22, 14, 18, 20, 17, 26, 22, 31, 21, 16, 14, 28, 17, 17, 20,
        43, 10, 27, 21, 21, 28], device='cuda:6'), 'ntokens': 520, 'nsentences': 24}##################### {'id': tensor([ 51127, 154424, 139260, 153288, 115486, 168074, 185725,  59179],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[-1.9836e-03, -2.4719e-03, -2.8687e-03,  ..., -2.7466e-04,
          1.7090e-03,  4.9133e-03],
        [ 6.1035e-05, -3.6621e-04, -6.4087e-04,  ...,  3.6621e-04,
          2.4414e-04,  6.1035e-05],
        [ 3.6621e-04,  4.2725e-04,  4.2725e-04,  ...,  5.1880e-04,
          2.1362e-04,  9.1553e-05],
        ...,
        [ 3.5400e-03,  2.6550e-03,  2.2583e-03,  ...,  3.8452e-03,
          4.7607e-03,  0.0000e+00],
        [ 3.2654e-03,  4.0283e-03,  4.6387e-03,  ..., -1.3428e-03,
         -3.6621e-04,  0.0000e+00],
        [-7.0190e-04, -5.7983e-04, -7.3242e-04,  ...,  7.1106e-03,
          6.2866e-03,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([201760, 201760, 201760, 201760, 201760, 201759, 201759, 201759],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2,   92,  696,  860,   18,   52, 1131,    4,   16, 1606,   27,   30,
         8674,    4,   34,   14, 1786,   61,    6, 3977, 6844,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3799,   41,   36,  252, 2351,   82,  124,   47,    4,   40, 5324,
           23, 2849,   60, 5641,  301,  483,  710,    6,   16,   60,  141, 1030,
         2778,   49,  308,  754,   35,  754, 2023,  191,    4,   14,   14,  203,
         2050,   45, 1350,  381, 2897,   15, 2272, 3915, 6975,    4, 5008,  441,
         4302,  165,    6, 7694,   20,   78, 3068,  124,   56, 2620, 1979,   18,
          224,  862, 2007,   56, 2620, 1103,   18,  224, 4178, 4332,   15,   39,
           16, 7563,  189,    5],
        [   2, 1815,    6, 3827,    6, 1133,  130,   36,  136,   47, 1453,    4,
           14, 8304,   57,  122, 1347,  130,   14,  742,   15,   18, 1643, 4863,
          301,   37,  352, 4566, 2140,    4,   88,  295, 1652,  112,   14, 2353,
         2974, 4120,   16,   14, 1813, 1840, 2174, 1347,   15, 2369, 4759,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  402, 3828,    4,  782,   95,  195,  902,  237,  119, 1186,   58,
         1426,   47,  594,   40, 1538,   74,   36,   27,    4,  114,   81,   49,
          328,  531,  494,   15,    4, 2531,  911,  247, 1576,    4, 7427,   27,
           42,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3004, 2224, 5357,   15, 9718,    4,   50,   95, 9594,  397, 1360,
          186,  503,    4,   34,  855,    4,   50,  212, 1607, 3361,   98,   58,
         2230,  344, 1038, 1591,   96, 6539,  186,  503,    4,   23,  364,  259,
           23, 1872,  511,  762,  128,   37, 6079,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 2253,   22,   32,  361,   28,  151,   23, 2755,  381, 3402,  265,
          515, 2089,    4, 1207,   22, 3902,    4,   60,  141, 5088,   15, 3969,
          584,   35, 1861, 3287,  271,    4,   49, 1128,    9, 5283,  382, 4051,
            9, 7049,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  396, 2234,  239, 4953,   78,   58, 5306,   22, 2368, 6367,    4,
          136,  394,  547, 1316,   74,   82,  458, 1196, 3319,   22,    9,   58,
         1270,   16, 2898,    4,  258, 7795,  410, 3260, 1443,    4, 1225,   16,
         7433,   20, 3033,   15,   28, 4944,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 4287, 1690,   27,   36,    4,  831, 3733,    4,   50,   43,    4,
          114,   43,  173,  393,  537,    4,   40, 2547,    6, 1550,  714,   83,
           74,   81,  326,  651,    4,   90,  258,   43,  173,   39, 5978,   76,
            4,   16,   14, 2043,   20,    4, 3289,   20, 6233,    4,   50,   81,
         1096, 3526,  502, 5677,   60, 2164,    4,  653,  605,  145,    4,   74,
           43, 2364,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[   7,  422,  874,    4,    9, 6788,  369,   12, 3648,    4,   26,    7,
          874,    9, 2761,   12,   13,  572,  224,    7,  572,   26,    9, 2761,
           12,   13,  874,  224,    8,  722,   26,    7, 7465,  131,  166,  251,
          248,   63, 3249,   62,    9,    7,  772,  207,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1179,   25,  135,   21,  109,   86,    4, 1335, 2348,   12, 1613,   71,
          747, 2693,   11,    6,    8, 1335, 2348,   12,   13,    5,  265,    5,
         6466,    6,  148,  205,   10,    7,  281,  909,  119,  236, 1563, 8562,
            9,  108,  753, 1772,    9,  909,   35, 3080,  109,  909,   35, 9376,
           54,    8, 4429,    4,    8,   53,  467,  132, 2762,  159, 2767,    6,
            5,    2],
        [  67,   21,  465,   11,   18,  468,    7, 2932, 1880,  567,    4,    8,
          113,    7, 2932, 3612, 1381,  832,   18,  233, 1181,   33, 3612, 1181,
         3860,   59, 1710,   10, 5111,   15,   21,    6,  768,   10, 5574,    7,
         1749, 1381,    8,    7,  341,  409, 1955,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,   56, 1285,    4,  347,  192,   11,   18,   25,  450,  117, 6010,
           70,   21,   11,    6,  100,  378, 7000,   71,   33, 4716,  434,  427,
          821,  407,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   9,  409,    4, 2753,  427, 1105,  810, 3565,   17,   21,  659,   51,
         1953,    6,   12, 1655,   12,  215,  801,    4,  166,  818,   17,   33,
         1167,  659,   66,  245,   13, 2003,   15,  106,    7, 1247,   12,   13,
          258, 1591,   17, 2963, 1585, 1763,    7, 1644,  511,  762, 1054,    6,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  21,   11,    6,   13,  563,   93, 2484, 9473,   13, 4866,   10, 2266,
          389,  552, 1252,   11,    6,   38, 5001,  411,  293,  137,   24,   73,
          205,   10,   91,   12,    7,  822,  608,   56, 9694, 1075,    4, 3109,
         3902,    4,    8,  150,  113,   13, 1523, 3609,   12, 2718, 7719,    4,
          106,  747,    9, 1665,   10, 1962,    9, 1912,    5,    2,    1,    1,
            1,    1],
        [  33, 2780,   34, 6291,  111, 2770,   55,    7, 2932, 1232,    4,   67,
          115,   21,   11,    6, 2823,   54,  100, 3139,  140, 2704,    6,    9,
            7,  832,    5,    6,    5,    8, 2627,    4,  206, 2406,    6,   63,
         4213,   48,   10, 3067, 3316, 1006,   85, 3646, 1729,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 108, 2476,   26,   10, 8711,   17,   53, 1516,   71,   13,  509,  841,
           12,  138,   10,  229,  214,  254,  120,   53, 6565,    4,    8,    7,
         2027, 6936,  475, 2041,   17,   25,   73, 1531,  214,  126,  131, 1974,
          416,   54,  336,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 28, 38, 11, 37, 29, 44, 37, 56, 11, 85, 37, 38, 37, 59, 37, 37, 47,
         11, 37, 47, 85, 37, 59, 37, 37, 38, 11, 37, 49, 85, 37, 32, 37, 37, 50,
         34, 85, 36, 31, 37, 37, 75, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 59, 37, 37, 83, 11,  2, 23, 37, 56, 37, 30, 31, 85, 37, 37,  2,
         23, 37, 37, 11, 35, 11, 32, 37, 50, 85, 37, 37, 75, 38, 75, 35,  2, 56,
         37, 37,  9, 49, 37, 38, 38, 31, 37, 38, 38,  9, 49, 37, 49, 11, 37, 37,
         38, 37, 29, 37, 75, 37, 11, 83],
        [37, 37, 85, 85, 35, 29, 37, 28, 28, 32, 11, 37, 83, 37, 28, 28, 94, 38,
         35, 35, 31, 37, 28, 31, 49, 35, 94, 37, 94, 77, 37, 37, 94, 37, 36, 37,
         28, 94, 37, 37, 33, 32, 44, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 35, 11, 83, 85, 85, 35, 37, 88, 37, 56, 50, 37, 85, 37, 37, 49,
         31, 37, 37, 32, 31, 38, 77, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 11, 28, 38, 35, 35, 88, 37, 37,  6, 38, 38, 37, 37, 24, 37, 24,
          2, 11, 37, 88, 37, 37, 26,  6, 85, 83, 37, 35, 77, 37, 37, 56, 37, 37,
         38, 35, 37, 31, 37, 35, 37, 38, 35, 31, 35, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37,  9, 35,  9, 35, 37, 35, 37, 38, 35, 85, 35, 85, 37, 38,
         35, 35, 35, 11, 38,  6, 85, 37, 50, 37, 37,  2, 75, 38, 28, 56, 11, 38,
         35, 11, 37, 59, 83, 37,  2, 23, 37,  9, 33, 11, 37, 30, 37, 38, 37,  2,
         37,  2, 11, 83, 37, 37, 37, 37],
        [37, 94, 85, 28, 83, 31, 37, 37, 28,  9, 11, 37, 83, 37, 85, 37, 49, 49,
         37,  2, 35, 49, 37, 37, 37, 38, 11, 37, 11, 37, 28, 11, 37,  9, 37, 85,
         32, 31, 37, 49, 94, 94, 37,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 85, 37, 88, 37, 37, 29, 37, 37,  2, 32, 37, 37, 37, 49, 56, 37,
         37, 37, 31, 11, 37, 37,  2, 28,  2, 94, 37, 37,  6, 94, 56, 37, 37, 38,
         35, 49, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([46, 62, 45, 28, 50, 58, 47, 41], device='cuda:0'), 'ntokens': 377}, 'target': tensor([[  92,  696,  860,   18,   52, 1131,    4,   16, 1606,   27,   30, 8674,
            4,   34,   14, 1786,   61,    6, 3977, 6844,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3799,   41,   36,  252, 2351,   82,  124,   47,    4,   40, 5324,   23,
         2849,   60, 5641,  301,  483,  710,    6,   16,   60,  141, 1030, 2778,
           49,  308,  754,   35,  754, 2023,  191,    4,   14,   14,  203, 2050,
           45, 1350,  381, 2897,   15, 2272, 3915, 6975,    4, 5008,  441, 4302,
          165,    6, 7694,   20,   78, 3068,  124,   56, 2620, 1979,   18,  224,
          862, 2007,   56, 2620, 1103,   18,  224, 4178, 4332,   15,   39,   16,
         7563,  189,    5,    2],
        [1815,    6, 3827,    6, 1133,  130,   36,  136,   47, 1453,    4,   14,
         8304,   57,  122, 1347,  130,   14,  742,   15,   18, 1643, 4863,  301,
           37,  352, 4566, 2140,    4,   88,  295, 1652,  112,   14, 2353, 2974,
         4120,   16,   14, 1813, 1840, 2174, 1347,   15, 2369, 4759,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 402, 3828,    4,  782,   95,  195,  902,  237,  119, 1186,   58, 1426,
           47,  594,   40, 1538,   74,   36,   27,    4,  114,   81,   49,  328,
          531,  494,   15,    4, 2531,  911,  247, 1576,    4, 7427,   27,   42,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3004, 2224, 5357,   15, 9718,    4,   50,   95, 9594,  397, 1360,  186,
          503,    4,   34,  855,    4,   50,  212, 1607, 3361,   98,   58, 2230,
          344, 1038, 1591,   96, 6539,  186,  503,    4,   23,  364,  259,   23,
         1872,  511,  762,  128,   37, 6079,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [2253,   22,   32,  361,   28,  151,   23, 2755,  381, 3402,  265,  515,
         2089,    4, 1207,   22, 3902,    4,   60,  141, 5088,   15, 3969,  584,
           35, 1861, 3287,  271,    4,   49, 1128,    9, 5283,  382, 4051,    9,
         7049,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 396, 2234,  239, 4953,   78,   58, 5306,   22, 2368, 6367,    4,  136,
          394,  547, 1316,   74,   82,  458, 1196, 3319,   22,    9,   58, 1270,
           16, 2898,    4,  258, 7795,  410, 3260, 1443,    4, 1225,   16, 7433,
           20, 3033,   15,   28, 4944,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [4287, 1690,   27,   36,    4,  831, 3733,    4,   50,   43,    4,  114,
           43,  173,  393,  537,    4,   40, 2547,    6, 1550,  714,   83,   74,
           81,  326,  651,    4,   90,  258,   43,  173,   39, 5978,   76,    4,
           16,   14, 2043,   20,    4, 3289,   20, 6233,    4,   50,   81, 1096,
         3526,  502, 5677,   60, 2164,    4,  653,  605,  145,    4,   74,   43,
         2364,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([22, 76, 48, 37, 44, 39, 43, 63], device='cuda:0'), 'ntokens': 372, 'nsentences': 8}##################### {'id': tensor([209134,  15819, 128028,  84590,  42781,  24682, 130183, 180505],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 2.4414e-04, -6.1035e-05,  0.0000e+00,  ..., -4.0894e-03,
         -5.0354e-03, -4.1504e-03],
        [ 2.4109e-03,  8.8501e-04,  9.1553e-04,  ...,  9.1553e-04,
          3.2959e-03,  4.1504e-03],
        [ 6.1035e-05,  3.3569e-04,  5.7983e-04,  ...,  4.0588e-03,
          3.6316e-03,  3.9673e-03],
        ...,
        [ 2.5024e-03,  6.1646e-03,  8.4534e-03,  ..., -3.5706e-03,
         -3.9368e-03, -3.9978e-03],
        [-3.6621e-03, -3.1128e-03, -1.9226e-03,  ...,  8.4229e-03,
          1.2573e-02,  1.6968e-02],
        [ 3.7231e-03,  4.8218e-03,  4.5776e-03,  ..., -5.8899e-03,
         -6.1951e-03,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([169120, 169120, 169120, 169120, 169120, 169120, 169120, 169119],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2, 3510,   40,    6,   44,  222,   14,  437, 3170,  237,   23,  304,
         2648, 2428,  249,   28, 5140,   27,    4,   90, 4453, 2342,  656,  544,
           58,  817,   51, 3544,    4,  855,   30,    4,   50,   43,  433,  257,
           28, 5140, 2589,   27,   42,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  104, 9274,  107,   49, 1257,  349,   59, 4017,    6,  128,  318,
            4,    9,  631,   32, 4048, 1354, 3613,    5,  147,   97, 2167,   83,
           32,  231,  299, 5598,   20, 2204,  856,    4,   50,   32,    9,  536,
         3653, 7213,   76,    4,   16,  686,  331,   27,  517, 2548,    5,    1,
            1,    1,    1],
        [   2,  864,  195,  902, 3034,   20,  331, 1379, 1602,   75, 3123,   98,
         1679,   15,   16,  102,  314,   52, 2889,  667,  123,  193, 1524,    4,
          124, 3596,  306,  767,  397,  177,  102, 5500,   20,  969,   61,   23,
         1062,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  147,  268,   29,  306,   23, 2086,    6,  469,  588,   47,    9,
           23, 1401,  177, 1126,    4,  605,   43,    9,   23, 1423,   16, 1521,
         2363,    4,   34,   81, 8794, 1391,    4,   27,  216,   61,   23, 5835,
         1100,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 1866,  361,  118, 3017,   20, 5430, 2723,  530,   15,   56, 2448,
         4302,  130,    4,  769,  495,  547,    9,   14, 1131,  940,   16,   51,
         7211,   22,    4,  177, 2009,  217,  844,    5,   92,   27, 1821,    5,
         1272, 3904,   75,  139,    4, 6373,   43, 2316,   22,  549, 2686, 1987,
           37, 1242,    5],
        [   2,  441,  302,  332,  210, 1664,    4,  705,   31,   46,  912,  212,
         5440,   59,  165,  313,   31, 4009,   46,   72,  638,    4,   31,  209,
         1746,  410,  141, 6572,   15, 8997,  184, 3685,  191,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  202,   27,  361,    9,  493, 5535,    5,   38, 2579,    6,   20,
         4785, 3947,  280,   31,  217, 1458, 2974,   18, 2374, 1801,  177,  302,
          332,   61,  102, 4785,  360,   20, 2286,  307,   35,  592, 1434, 3999,
            4,  485, 2349,    4,   90, 1439,    6, 4902,    9,  141, 4842, 3932,
         2545,    5,    1],
        [   2,  222,   32,  361,  393,   58, 3607,   16,   14,  308,  532, 3635,
           15, 2343,    4,   14,  112,   58, 3607, 3086,   46,  396,  308,  532,
         3635,   15,   76,   29,  190,   74,  349,   59,  219, 1870, 5303, 2272,
         7733,    6,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[ 800,   91,   44,  103,  886,  424, 3848,   11,    6,  853,  200,  237,
           26,  593, 3401,  120, 3213,  187, 2044,    6, 1570,    6,  199,    7,
          964,    4,  568,   17,  641,   21,   11,    6,  735,  226,  593, 3401,
           42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24, 8396, 1469,  106,  108, 2914,   37,   93,  131, 2532,  336, 3494,
            4,   67, 1223,   24,   77,   66,   33, 1738, 2914,   37,   93,   17,
           24,   63,  746,   12, 5472, 1117,  108, 3183,    6,    8, 1459,  994,
           26,  126,   84,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2937,  982,  218,  943,    6,    9,  108, 6249,  451,   66,  774,   62,
         3928,    4,    8, 1800,  282,   13, 2333,   10,  175,  850, 1408, 1072,
            6,    4,  109, 3119,  294, 2518,   12,  215, 3928,  254,  956,   69,
          984,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,  125,   29,  294,   12,    7, 2787,    9, 1370, 2924,   11,   18,
          116,    9,  670,    4,   53,   11,   57,    9, 1037,    8, 1237,    4,
           70,   25,  113,  296,    4, 6957,    4,   26,  143,   69,    7,  230,
          874,  926,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,    4,  103,   25, 1816,   66,   13, 5590,   20,  521,   20,  874,
           93,    4,  115,   11,    6,   13,  324,  183,   10,  388,   21,    9,
          155,  874,    8,  598,   21,    4, 2603,   69,    7,  467,    5,   17,
           11,    6,  916,    5,   25,   11,  158,  446,  126,  347,   21,   11,
            6,  434,   13,  862,  365,  232, 1218,   20, 5590,   20,    5,    2],
        [ 248,  215,  581,   85, 1366,    4,   19,  154,   46,   19,   11,  121,
          367,   10,   33, 7034,   46,   19,  154,   19,  659,   66,  226, 5187,
          106,   13, 3643,  384, 7710,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6,    9,   89, 6525,  230,  115,    5,   38,  187,  144,
           33, 1850, 2536,   48, 1850,   62,   69,    7, 1850,    6,   20, 2286,
          307, 4813,  248,  215,  581,   69, 2154, 1374,   18,  881,   11,    6,
          383,    5,   21,   34,    7,  133, 2354,    4,    7,  473, 2829,    9,
            7,  535, 8311,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  29,  115,    4,  103,   24,  274,  270,   85,    7, 3253,    4,   85,
          108, 8196,    6,   17,  162, 5690,   54, 1004,    7, 3253,    4,  117,
         8196,    6,   63,  100,    7,  384,  174, 2003,   12,  108, 2626,  567,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'cluster_tokens': tensor([[23, 50, 82, 37, 38, 35,  9, 85, 37, 38, 35, 35, 85, 83,  2, 37, 28, 35,
         35, 37, 49, 37, 37, 37,  9, 11, 85, 37, 88, 37, 85, 37, 83, 85, 83,  2,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 33, 37, 37, 37, 38, 77, 35, 37, 49, 37, 50, 11, 37, 83, 38, 50, 85,
         37,  2, 38, 77, 35, 37, 38, 85, 83, 37, 31, 37, 37, 94, 37, 37, 50, 50,
         85, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [23,  2, 50,  9, 37, 37, 37, 94, 85, 85, 38, 31, 83, 11, 37, 31, 32, 37,
          6, 37, 85, 37, 35, 24, 37, 11, 37, 83, 50, 50, 37, 24, 83, 37, 31, 37,
         94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 83, 50, 37, 37, 56, 37, 94, 85, 85, 35, 83, 37, 94, 11, 37, 85,
         77, 37, 94, 37, 94, 11, 50, 37, 83, 49, 11, 83, 11, 85, 50, 37, 37, 37,
         38, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 11, 37, 37, 56, 85, 37, 38, 77, 38, 77, 38, 35, 11, 83, 85, 37, 37,
          2, 24, 37, 31, 37, 37, 37, 38, 37, 59, 37, 11, 83, 37, 37, 38, 11, 37,
         85, 37,  2, 11, 37, 85, 35, 59, 37, 83, 37, 85, 37, 31, 37, 38, 35, 77,
         35, 77, 38, 77, 11, 83],
        [34, 24, 83, 37, 28, 11, 38, 59, 11, 38, 85, 35, 85, 37, 37, 32, 11, 38,
         59, 38,  6, 85, 85, 76, 37, 37,  2, 38, 35, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 37, 94, 37, 83, 11, 38, 35, 85, 37, 38, 35, 31, 38, 31,
         37, 37, 38, 37, 77, 35, 77,  9, 34, 24, 83, 37, 38, 77, 35, 77, 85, 37,
         24, 11, 37, 85, 37, 83, 23, 11, 37, 37, 32, 37, 37, 83, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37],
        [83, 83, 11, 37, 38, 59, 37, 37, 37,  9, 11, 37, 37,  9, 37, 37, 85,  9,
         49, 37, 37,  9, 11, 37,  9, 37, 85, 37, 37, 38, 35, 35, 37, 37, 28, 32,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:2'), 'lengths': tensor([38, 41, 39, 40, 60, 31, 53, 38], device='cuda:2'), 'ntokens': 340}, 'target': tensor([[3510,   40,    6,   44,  222,   14,  437, 3170,  237,   23,  304, 2648,
         2428,  249,   28, 5140,   27,    4,   90, 4453, 2342,  656,  544,   58,
          817,   51, 3544,    4,  855,   30,    4,   50,   43,  433,  257,   28,
         5140, 2589,   27,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 104, 9274,  107,   49, 1257,  349,   59, 4017,    6,  128,  318,    4,
            9,  631,   32, 4048, 1354, 3613,    5,  147,   97, 2167,   83,   32,
          231,  299, 5598,   20, 2204,  856,    4,   50,   32,    9,  536, 3653,
         7213,   76,    4,   16,  686,  331,   27,  517, 2548,    5,    2,    1,
            1,    1,    1],
        [ 864,  195,  902, 3034,   20,  331, 1379, 1602,   75, 3123,   98, 1679,
           15,   16,  102,  314,   52, 2889,  667,  123,  193, 1524,    4,  124,
         3596,  306,  767,  397,  177,  102, 5500,   20,  969,   61,   23, 1062,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 147,  268,   29,  306,   23, 2086,    6,  469,  588,   47,    9,   23,
         1401,  177, 1126,    4,  605,   43,    9,   23, 1423,   16, 1521, 2363,
            4,   34,   81, 8794, 1391,    4,   27,  216,   61,   23, 5835, 1100,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1866,  361,  118, 3017,   20, 5430, 2723,  530,   15,   56, 2448, 4302,
          130,    4,  769,  495,  547,    9,   14, 1131,  940,   16,   51, 7211,
           22,    4,  177, 2009,  217,  844,    5,   92,   27, 1821,    5, 1272,
         3904,   75,  139,    4, 6373,   43, 2316,   22,  549, 2686, 1987,   37,
         1242,    5,    2],
        [ 441,  302,  332,  210, 1664,    4,  705,   31,   46,  912,  212, 5440,
           59,  165,  313,   31, 4009,   46,   72,  638,    4,   31,  209, 1746,
          410,  141, 6572,   15, 8997,  184, 3685,  191,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 202,   27,  361,    9,  493, 5535,    5,   38, 2579,    6,   20, 4785,
         3947,  280,   31,  217, 1458, 2974,   18, 2374, 1801,  177,  302,  332,
           61,  102, 4785,  360,   20, 2286,  307,   35,  592, 1434, 3999,    4,
          485, 2349,    4,   90, 1439,    6, 4902,    9,  141, 4842, 3932, 2545,
            5,    2,    1],
        [ 222,   32,  361,  393,   58, 3607,   16,   14,  308,  532, 3635,   15,
         2343,    4,   14,  112,   58, 3607, 3086,   46,  396,  308,  532, 3635,
           15,   76,   29,  190,   74,  349,   59,  219, 1870, 5303, 2272, 7733,
            6,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:2'), 'target_lengths': tensor([41, 47, 38, 38, 51, 34, 50, 39], device='cuda:2'), 'ntokens': 338, 'nsentences': 8}##################### {'id': tensor([103801,  62553, 152962, 204323, 148813, 120015,  56186, 143167],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 1.8311e-04,  5.1880e-04,  2.4414e-04,  ..., -1.5564e-03,
         -7.0190e-04,  6.7139e-04],
        [ 1.5564e-03,  1.5869e-03, -1.9531e-03,  ..., -6.4880e-02,
         -6.8726e-02, -6.9946e-02],
        [-1.8005e-03, -2.6245e-03, -3.8452e-03,  ..., -2.2278e-03,
         -9.1553e-05, -3.3264e-03],
        ...,
        [-6.1035e-05, -2.5024e-03, -1.3733e-03,  ..., -1.6174e-03,
         -5.0659e-03, -8.6975e-03],
        [ 1.4343e-03,  4.6082e-03,  3.9368e-03,  ..., -1.0986e-03,
         -2.5024e-03, -3.2043e-03],
        [ 7.0190e-04,  4.8828e-04,  2.7466e-04,  ..., -1.5564e-03,
         -1.5564e-03, -1.2512e-03]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([154080, 154080, 154080, 154080, 154080, 154080, 154080, 154080],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2, 4287, 2218,  724,  322, 3030, 2087,    4,   23, 1104,   93,  322,
         3030,    4,   23,  107, 1096,  633, 7736,   22,   16, 3898,   15,    4,
         8918,   16,  577, 4261,   18,  186, 5663,    5, 6096,    4, 6783, 2087,
          704,   61, 3233,   96, 1087,    5],
        [   2,  228,   23,  808, 1268, 9914,  584, 4367,   83, 6985, 2904,    6,
         1473,    9,   23, 9242,   15,  974, 1326, 6428, 1684,  676,   16, 1208,
         8211,   34,  517,  730,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 4282, 3502,  971,   57,  221,   37,   95, 4500,   22,    9, 1815,
          210,   98, 7514,   22, 4080,   15,  308,    6,   93,  237,    4,  136,
          306,  127,   49,   23, 5306,   22, 4255,   95,  200,  625,   18,   16,
          318, 7407,    5,    1,    1,    1],
        [   2, 3137,  363, 2511,  303, 2379,  112, 9617,    6,  382,   28,  328,
         1235,  614,   35, 5377,   45, 2446,   37,   61,  771, 1441,   46, 4192,
           76, 6595,    9,   23, 2005,    4,  273,  201,   28,  725,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  705,    4,   50, 2799, 6797, 1213,   47, 1292,  644,   40,
         1263,   96, 2635,  714, 1959, 1582,    4,   34,   60,   58, 6947,   22,
         3376,    4,  114,   14, 2727,   28,  844,   27,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  146, 2132,   15,   95,   20,  236,  549,   75, 8138,    4,  136,
         5025,    9,   23, 8698,  344,  497, 3985,    6,  231,  542, 2289,   20,
            4,  124,  231,  542,  497, 3985,   20,    4,  136, 3776,  395,   81,
           75, 2381, 2351,  186,    5,    1],
        [   2,   64,  832,  543,  389,  411,  673,  503,   36,  186,    4,  136,
           30, 5120,   47, 9434,    4,   50,   32, 2057,   56, 3581,   20, 5634,
           20,   83,   46,   14, 6424, 1769,   35, 8014,   20,    9,   23, 8471,
         6401, 4966,    5,    1,    1,    1],
        [   2, 1545,   38,  760,    4,   16,  197, 9015, 4422, 7418,   37, 4170,
           15,    5,  146,  326,    4,   14, 1001,  696,   16,   14, 3824,    9,
          512,   45,  696,  845, 2344,   76, 3587,   60, 2467, 1688,  387,  165,
            6, 8207,   15, 2474,    5,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[  67,  108, 8830,   48,  589, 7557,    6,    4,  166,   63,    7, 7557,
            6,   17,  601,  170,   10, 6108,    8, 2544,    8,   51,   13,  562,
           18,    8, 9063,   62,    8,   29, 4404,    8,   29,   69,    4,   53,
           63,  261,  143, 7678,   62,  131, 1912,  688,    5,    2,    1,    1,
            1],
        [  24,  116,  144, 6985, 2421,    6, 4502,   80,  854,   39, 3350,  581,
           77, 1004,    7, 6869, 9271,    4, 3381,   70,   11,    6,  956,    5,
            8,   24,   11,  121, 2138,   13,  325,   12,  183,    9,    7, 1726,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 185, 2193, 6248,   22,    6,    9, 1777,  150,  156,   79,   93,  675,
           45,    9, 5222, 1290, 1373,    6,    6,  693,    5,   67,  294,   73,
           51, 5853,  131,    7, 2932, 3288,    4,    8,  203, 1203, 1015,  922,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 106, 1244,   35, 1966,  673,   54, 2409,   10, 2465, 3602,    6,   10,
           33, 2178, 2445,  266, 1192,   69,   89,  906,    4, 3927,   63, 4015,
         5869,   12, 2434,  108,  179,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,  154,   21,   26, 2497, 1226,   55, 1221,   10, 1772,    9,    7,
          245,  561,  929,   13, 2226, 1757,   55,   70,  169, 1085,   10,    7,
          461,  266,  763,  480,    6, 1042,    7, 3677,  188, 3699,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   7, 4100, 1649, 1085,  143, 1149,    4,   67,  914,   69,    7, 1296,
           12,   13, 4400,   15,   22,  996,    4,  333,  555, 7691,  109,  333,
          555, 3619,  215,    5,   67,   21,   11,    6,  499,  250,   10,   51,
         4837,   12,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,    7, 7745,  659,   51,    4,   67,   21,  689,   11,   18, 4432,
           10,  452, 1539,  128,    6,    4,   17,   24,   66, 5020, 6083, 5475,
            6,   46,    7, 1320,   59,  816,  300, 1079, 1643, 1794,  230,   85,
            7, 1219,  859,   35, 2514, 4209,    5,    2,    1,    1,    1,    1,
            1],
        [   9,  409,    4,    7,   29,   70,   26,    4,    9,    7,  572,    4,
         2317,    9, 7418, 3782,    4,    7,  214,   17,  229,  155,  572,  283,
            4,    7,  214,   17,  229,  155, 3236,  283,    9,  155,  572,    4,
           63, 8220,  111,  415,   59, 8186,   71, 2317,    9, 2011, 3043,    5,
            2]], device='cuda:7'), 'cluster_tokens': tensor([[37, 37, 83, 31, 35,  9, 37, 11, 37, 85, 37,  9, 37, 37, 49, 37, 37, 49,
         37,  9, 37, 38, 37, 77, 35, 37, 29, 31, 37, 83, 37, 37, 83, 37, 11, 37,
         85, 83, 50, 29, 31, 37,  2,  9, 11, 83, 37, 37, 37],
        [38, 83, 85, 34, 94, 37, 49, 37, 53, 38, 24, 83, 50, 37, 37, 28, 94, 11,
         59, 50, 85, 37, 31, 11, 37, 38, 85, 35, 31, 37, 83, 37, 24, 37, 37, 32,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 28, 28, 35, 37, 37, 28, 59, 35, 37, 35, 35, 35, 37, 28, 38, 35, 37,
         37, 56, 11, 37, 50,  6, 38, 31, 37, 37, 28, 94, 11, 37, 38, 35, 35, 31,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 38, 35, 35, 49, 56, 37,  2,  9, 37, 37, 37, 38, 35, 35,  9, 37,
         37,  9, 11, 56, 85, 49,  6, 37, 32, 37, 94, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 59, 37, 85, 83,  2, 37, 94, 37, 49, 37, 37, 83,  9, 50, 37,  2, 32,
         37, 50, 85, 85, 37, 37, 32, 35, 35, 35, 37, 83, 37, 32, 85, 31, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  2, 50, 85, 50, 83, 11, 37, 83, 37, 37, 49, 37, 37, 24, 77, 35, 41,
         11, 50, 50, 24, 37, 50, 50, 34, 24, 11, 37, 37, 85, 37, 83, 50, 37, 38,
         86, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37,  2,  6, 38, 11, 37, 37, 85, 85, 35, 49, 37, 38, 77, 35, 37, 11,
         37, 38, 85, 83, 31, 32, 37, 11, 37, 38, 35, 35, 35, 35, 35, 56, 37, 37,
         37, 38, 31, 38, 99, 94, 11, 83, 37, 37, 37, 37, 37],
        [37, 32, 11, 37, 83, 50, 85, 11, 37, 37, 47, 11, 56, 37, 28, 94, 11, 37,
         56, 37, 49, 37, 47, 49, 11, 37, 56, 37, 49, 37, 94, 49, 37, 37, 47, 11,
         85,  2, 83, 38, 35, 36, 37, 56, 37,  9, 29, 11, 83]], device='cuda:7'), 'lengths': tensor([46, 38, 38, 31, 36, 40, 44, 49], device='cuda:7'), 'ntokens': 322}, 'target': tensor([[4287, 2218,  724,  322, 3030, 2087,    4,   23, 1104,   93,  322, 3030,
            4,   23,  107, 1096,  633, 7736,   22,   16, 3898,   15,    4, 8918,
           16,  577, 4261,   18,  186, 5663,    5, 6096,    4, 6783, 2087,  704,
           61, 3233,   96, 1087,    5,    2],
        [ 228,   23,  808, 1268, 9914,  584, 4367,   83, 6985, 2904,    6, 1473,
            9,   23, 9242,   15,  974, 1326, 6428, 1684,  676,   16, 1208, 8211,
           34,  517,  730,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [4282, 3502,  971,   57,  221,   37,   95, 4500,   22,    9, 1815,  210,
           98, 7514,   22, 4080,   15,  308,    6,   93,  237,    4,  136,  306,
          127,   49,   23, 5306,   22, 4255,   95,  200,  625,   18,   16,  318,
         7407,    5,    2,    1,    1,    1],
        [3137,  363, 2511,  303, 2379,  112, 9617,    6,  382,   28,  328, 1235,
          614,   35, 5377,   45, 2446,   37,   61,  771, 1441,   46, 4192,   76,
         6595,    9,   23, 2005,    4,  273,  201,   28,  725,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  705,    4,   50, 2799, 6797, 1213,   47, 1292,  644,   40, 1263,
           96, 2635,  714, 1959, 1582,    4,   34,   60,   58, 6947,   22, 3376,
            4,  114,   14, 2727,   28,  844,   27,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 146, 2132,   15,   95,   20,  236,  549,   75, 8138,    4,  136, 5025,
            9,   23, 8698,  344,  497, 3985,    6,  231,  542, 2289,   20,    4,
          124,  231,  542,  497, 3985,   20,    4,  136, 3776,  395,   81,   75,
         2381, 2351,  186,    5,    2,    1],
        [  64,  832,  543,  389,  411,  673,  503,   36,  186,    4,  136,   30,
         5120,   47, 9434,    4,   50,   32, 2057,   56, 3581,   20, 5634,   20,
           83,   46,   14, 6424, 1769,   35, 8014,   20,    9,   23, 8471, 6401,
         4966,    5,    2,    1,    1,    1],
        [1545,   38,  760,    4,   16,  197, 9015, 4422, 7418,   37, 4170,   15,
            5,  146,  326,    4,   14, 1001,  696,   16,   14, 3824,    9,  512,
           45,  696,  845, 2344,   76, 3587,   60, 2467, 1688,  387,  165,    6,
         8207,   15, 2474,    5,    2,    1]], device='cuda:7'), 'target_lengths': tensor([42, 29, 39, 35, 33, 41, 39, 41], device='cuda:7'), 'ntokens': 299, 'nsentences': 8}##################### {'id': tensor([ 45723, 103656, 119980,  17541,  44537, 119961, 191914,  72860, 221005,
        109666, 169039, 194794, 124932,  21487,  64286,  10640],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 0.0356,  0.0145,  0.0035,  ...,  0.0176,  0.0226,  0.0274],
        [-0.0031, -0.0011,  0.0007,  ...,  0.0028,  0.0028,  0.0029],
        [-0.0021,  0.0027,  0.0038,  ..., -0.0247, -0.0159, -0.0046],
        ...,
        [-0.0096, -0.0111, -0.0091,  ..., -0.0141, -0.0008,  0.0000],
        [-0.0007, -0.0005, -0.0005,  ...,  0.0018,  0.0028,  0.0000],
        [ 0.0050,  0.0058,  0.0053,  ..., -0.0398, -0.0370,  0.0000]],
       device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([103520, 103520, 103520, 103520, 103520, 103520, 103520, 103520, 103520,
        103520, 103520, 103520, 103520, 103519, 103519, 103519],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2, 2046,  579,   83,   32,    9, 1357, 3015,  232,  221,    6, 2099,
         3196,   22, 5306,    6, 2111,    4,  210,  102,   43,  301, 1328,  241,
          221, 2125,  236,  866,   16, 8242,   35,    6,  900,  729, 4156, 5621,
          227,   37, 4176,   15,    4,  124,   42],
        [   2,  526,   83,   32,  196, 2936,   29,  118, 6557,  344, 4800,   15,
         5365,   96, 1036,    4,  136, 4800,   20, 6973,  145,   81, 1626,    4,
          139,  114,   43, 5816,   76,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  402, 1836,   82,   23, 6539,   20,  342, 1879,   37,    5,  202,
           82,   56, 2334,  236,    5,  840,  252,   40, 1550,   78,   14, 2442,
           28,  667,    4,  173,    4, 2274,  167,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 2609,   27,   36,   23, 1885,   20, 8391,    9,   58,   52, 1053,
           23, 4276, 4247,   16,   23, 3970,   56, 8720,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   92,  855,  113,    4,   50,  657, 1957,  295,   10,  191, 7334,
          167,  414, 6968,  123,    4,   16, 4053,   14, 5364,   20, 3992, 1564,
         1125,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  104,   83,   14, 6843, 1652,   28,  334,    4,   38, 2195,   27,
           36,    4,   34,   31,  269,  449,  137,   64,    9,  151,   56, 3323,
         4544, 1698,    4,   27,   30,   78,  163,   52, 5076,  997,    5,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   41,  123,   30, 6299,   61,  212,  308,  311,    6,   20, 8443,
            4,  428,  114,   41,    9,   23, 1022, 1354, 2511,   16,   30, 1139,
          257,  594,  393,   39, 4065,    4,  127,   41,   36, 2936, 2587,    5,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  377,  212, 3670,  449,   31,  252,   49,  872, 2336, 1916,   15,
         1306,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  202,  329,   44,   38, 2851,  390,  176, 1750, 7582,   98,  137,
         1046,   30,   27,  101,  233, 1159, 2181,    4,  139,  114,  374, 5193,
         4603,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 1271,  992,   96,   27,   49,  151, 1186,  287,    4, 7611,  147,
          760,  322,   93,   16, 1612,   48, 1235,  158,  511,   64,   43, 2489,
         1687,    4, 5636,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  228,   58, 4678,    4,   14, 1540, 2725,  127,    4,  578,   14,
            6,   47, 1554, 1164,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 1356,  495, 1571,   36, 1078, 2190,    4,  403,   95,  118, 3630,
          124,   52, 4452, 2063,    4,   43,  681,  231,  364, 1401,  537,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   32,  516,  831,  186,    4,   50,   14,    6,   30, 4590,
          426,   16,  831,  426, 3483,   27,    4,   30,   32, 7795,   22,  364,
         5156, 1175,  123,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  161, 1330, 2133,   15,  223, 5998, 8904,   20, 1458,  360,
          483,  710,   35,  977,    4,   14,   56,   15,   37,  122,  625, 2053,
         5374,   28, 1594,   16,  253, 2368,   28,  990,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   14, 7413,    4,   14,    9,   58, 6656,   22,   49,
          423,  767, 1207,  243, 1079,  549,   24,  176,   18,   16,   61, 1786,
         3386,   23, 6175,  646, 5022,   16, 7951,  702,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  449,    4, 6368,   41,  208,    4,   74,  105, 8997, 7192,
           27,    5,   41,  161,  113,  184, 7110,    4,   29, 6368,   41,  208,
            4, 6368,   36,   56, 7696,   18, 1354,   27,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[  55,  663,    4,    9,  264,  109,  232,  221,    6,   24,   66,  682,
         3196,   22, 2932,  896,    4,  206,   53, 3860,   75,  241,  221,   77,
          236,  866,    8, 6387,    8,   29,  234,  452, 6029, 7401,    5,    2,
            1,    1,    1],
        [ 115,   24,   11,  121,  492, 1110,   13, 7123,  100,   33,   12,   13,
         1470, 3189,    4,   67, 1470, 3189,    6,   73,   51, 1346,    4,  276,
          103,   53,   11,   57,   86, 1110,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [ 168,   26,  138,  488,   12,   13,  775,  411,   37,   34,  859,    5,
           21,   34, 1523,    5,   10,  508,   25,   13,  841,   12,    7, 1823,
            5,    5,    5,   84,   25,  205,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    7, 1885, 5055,    4,   12,  538,    4,   26,  206,   13,  325,
           12,    7, 2394, 4793,    8, 2791,  513,  199,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  29,   21,  818,   17,   51,   20, 7931,  373,   63,  133,  324,   85,
          203, 4030,  140,   54, 2429,   35, 2611,    6,    4,    8,   29,   53,
           11,  121,  226,  529,   10, 3258,  251, 4513,   96,    5,    2,    1,
            1,    1,    1],
        [  24,   66,    7, 2216,  768,   10,  205,    4,   38, 5276,   26,   70,
           19,  213,   10,   87,  137,    8,    9,   13,  613,  982, 1479,    4,
           17,    4,   10,  110,    4,   26,   13, 1968,  279,    5,    2,    1,
            1,    1,    1],
        [  25,   73, 6265,  281,   12,   17,   13, 1674,    6,    4,  125,  103,
           25,   11,   57, 4298,  336, 3594,    4,    8,    7,  595, 3336, 1233,
         2233, 4457,  111,    4,   25,   11,   57,  492,  142,   10, 1713,   17,
          595,    5,    2],
        [  29,    4,   85,   33,  613,    4,   19,   87,  213,   10,  450,   25,
           17,  185,   12,    7, 2767, 4131,   24,   66,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 101, 1119,    4,   38,   18, 2704,  518,  155,  227,  715,   96,  137,
          125,   33,   26, 1320,  111, 2059,    4,   77, 2808,   10,    7, 9510,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  33,   26,  131,   13,  316,  287,    4, 7492,  136,  760,  322,   93,
            8,  697, 1262, 2178,  713,    5,    8,   53,   11,   57, 2091,    9,
         2567, 1507,    4,  116, 5000,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   9,  264, 1884,  166,   63,  142,   10,   51, 1405,    4,   33,  169,
           86,   51, 3118, 1623,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  67,   21,  465,   11,   18,  229,   13, 1878,   10,  565,  103,  284,
          708,  162,  142,   10,   51,   13, 2988,  109,   13, 2088,   44,   53,
          162,  142,   10,  205,   10,  670,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [  67,   24,  499,  213,   10,   51, 1123,   17,   33,   26,    7,  281,
         4089,    8, 2426, 3180,   17,   24,   73,   51, 2985,  199, 2406,    6,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  33,   26,  768,   62,  131, 1962,   35,  699,  119, 3050,    6,  411,
          639,    4, 7176,   20,  111,  752,   10, 1914, 4907,   10,  875,  134,
          199,    7, 1232,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  33,   26,    7, 5714,   17, 7076,    9,    7, 3227,   12,  423,  759,
         2270, 1098,   18,  500,    6,  148,  618,   69, 1102,  926,    6,   12,
            7, 8783,    8, 6907, 4895,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  19,  213,   25,   10,  150,  138,   33, 7223,   26, 5802,   62,    4,
            8,   21,   11,    6,  142,   10, 2546,  436,   29,   25,  150,   17,
           21,   11,    6, 1117,  126,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[37, 32, 11, 37,  2, 37, 77, 35, 37, 38, 85, 38, 35, 35, 28,  9, 11, 37,
         37, 49, 38, 35, 35, 50, 35, 35, 37,  2, 37, 83, 35, 38, 35,  9, 11, 83,
         37, 37, 37],
        [83, 38, 85, 35, 50, 59, 37,  9, 37, 37, 37, 37, 28,  9, 11, 37, 28,  9,
         37,  6, 38, 59, 11, 83, 37, 37, 85, 77, 83, 59, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [37, 85, 37,  2, 37, 37, 38, 35, 77, 85, 31, 11, 37, 85,  2, 11, 37, 88,
         37, 37, 32, 37, 37, 23, 11, 11, 11, 37, 37, 85, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 28,  9, 11, 37, 83, 11, 85, 37, 37, 83, 37, 37, 94, 94, 37, 56,
         85, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 88, 37, 38, 77, 29, 56, 85, 83,  2, 37, 38, 35, 35, 49,  2, 38,
         35, 37, 11, 37, 83, 37, 85, 35, 85,  6, 37, 29, 50,  9, 77, 11, 83, 37,
         37, 37, 37],
        [38, 85, 37, 28, 94, 37, 85, 11, 38, 28, 85, 50, 38, 88, 37, 85, 11, 37,
         37, 37, 32,  2,  9, 11, 37, 11, 37, 37, 11, 85, 37,  2, 50, 11, 83, 37,
         37, 37, 37],
        [37,  6, 29, 75, 37, 37, 37, 54, 37, 11, 37, 37, 37, 85, 77, 49, 37, 94,
         11, 37, 37,  9, 85, 29, 49, 28, 83, 11, 37, 85, 77, 50, 49, 37, 49, 37,
          9, 11, 83],
        [83, 11, 37, 37, 32, 11, 38, 85, 88, 37, 88, 37, 37, 50, 37, 37, 75, 56,
         38, 85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 88, 11, 38, 35, 49, 37, 37, 38, 35, 77, 11, 37, 37, 85, 38, 83, 23,
         11, 50, 32, 37, 37, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 85, 37, 37, 38, 35, 11, 28, 38, 35, 35, 35, 37, 38, 35, 38, 35, 11,
         37, 37, 85, 77, 32, 37, 49, 94, 11, 83, 94, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37,  2, 56, 37, 85, 49, 37, 38, 31, 11, 37, 85, 83, 38, 83,  2, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 85, 85, 35, 49, 37, 33, 37, 37, 37, 37, 56, 85, 49, 37, 38, 37,
          9, 37, 37,  9, 82, 37, 85, 49, 37, 85, 37, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 83, 88, 37, 38, 83, 37, 37, 85, 37, 75,  2, 37,  2, 32, 37, 38,
          6, 38, 49, 37,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 85, 94, 31, 37,  2, 38, 35, 75, 38, 37, 35, 94, 11,  2, 77, 83, 49,
         37, 49, 56, 37, 49, 37, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 85, 37, 94, 37,  8, 37, 37, 47, 37, 34, 24, 38, 35, 35, 35, 37, 50,
         49, 37, 83, 94, 37, 37, 37, 28, 37, 28,  5, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 88, 37, 37, 59, 37, 37, 94, 85, 36, 31, 11, 37, 37, 85, 37, 49, 37,
         38, 77, 83, 37, 59, 37, 37, 85, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:4'), 'lengths': tensor([36, 32, 32, 22, 35, 35, 39, 22, 26, 31, 18, 32, 26, 29, 31, 31],
       device='cuda:4'), 'ntokens': 477}, 'target': tensor([[2046,  579,   83,   32,    9, 1357, 3015,  232,  221,    6, 2099, 3196,
           22, 5306,    6, 2111,    4,  210,  102,   43,  301, 1328,  241,  221,
         2125,  236,  866,   16, 8242,   35,    6,  900,  729, 4156, 5621,  227,
           37, 4176,   15,    4,  124,   42,    2],
        [ 526,   83,   32,  196, 2936,   29,  118, 6557,  344, 4800,   15, 5365,
           96, 1036,    4,  136, 4800,   20, 6973,  145,   81, 1626,    4,  139,
          114,   43, 5816,   76,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 402, 1836,   82,   23, 6539,   20,  342, 1879,   37,    5,  202,   82,
           56, 2334,  236,    5,  840,  252,   40, 1550,   78,   14, 2442,   28,
          667,    4,  173,    4, 2274,  167,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [2609,   27,   36,   23, 1885,   20, 8391,    9,   58,   52, 1053,   23,
         4276, 4247,   16,   23, 3970,   56, 8720,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  92,  855,  113,    4,   50,  657, 1957,  295,   10,  191, 7334,  167,
          414, 6968,  123,    4,   16, 4053,   14, 5364,   20, 3992, 1564, 1125,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 104,   83,   14, 6843, 1652,   28,  334,    4,   38, 2195,   27,   36,
            4,   34,   31,  269,  449,  137,   64,    9,  151,   56, 3323, 4544,
         1698,    4,   27,   30,   78,  163,   52, 5076,  997,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  41,  123,   30, 6299,   61,  212,  308,  311,    6,   20, 8443,    4,
          428,  114,   41,    9,   23, 1022, 1354, 2511,   16,   30, 1139,  257,
          594,  393,   39, 4065,    4,  127,   41,   36, 2936, 2587,    5,    2,
            1,    1,    1,    1,    1,    1,    1],
        [ 377,  212, 3670,  449,   31,  252,   49,  872, 2336, 1916,   15, 1306,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 202,  329,   44,   38, 2851,  390,  176, 1750, 7582,   98,  137, 1046,
           30,   27,  101,  233, 1159, 2181,    4,  139,  114,  374, 5193, 4603,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [1271,  992,   96,   27,   49,  151, 1186,  287,    4, 7611,  147,  760,
          322,   93,   16, 1612,   48, 1235,  158,  511,   64,   43, 2489, 1687,
            4, 5636,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 228,   58, 4678,    4,   14, 1540, 2725,  127,    4,  578,   14,    6,
           47, 1554, 1164,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [1356,  495, 1571,   36, 1078, 2190,    4,  403,   95,  118, 3630,  124,
           52, 4452, 2063,    4,   43,  681,  231,  364, 1401,  537,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 147,   32,  516,  831,  186,    4,   50,   14,    6,   30, 4590,  426,
           16,  831,  426, 3483,   27,    4,   30,   32, 7795,   22,  364, 5156,
         1175,  123,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  99,  161, 1330, 2133,   15,  223, 5998, 8904,   20, 1458,  360,  483,
          710,   35,  977,    4,   14,   56,   15,   37,  122,  625, 2053, 5374,
           28, 1594,   16,  253, 2368,   28,  990,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  92,   27,   14, 7413,    4,   14,    9,   58, 6656,   22,   49,  423,
          767, 1207,  243, 1079,  549,   24,  176,   18,   16,   61, 1786, 3386,
           23, 6175,  646, 5022,   16, 7951,  702,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  72,  449,    4, 6368,   41,  208,    4,   74,  105, 8997, 7192,   27,
            5,   41,  161,  113,  184, 7110,    4,   29, 6368,   41,  208,    4,
         6368,   36,   56, 7696,   18, 1354,   27,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([43, 30, 32, 21, 26, 35, 36, 14, 26, 28, 17, 24, 28, 33, 33, 33],
       device='cuda:4'), 'ntokens': 459, 'nsentences': 16}##################### {'id': tensor([   819, 156778, 105576, 129278,   7627,   8032,   1284,  11141],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-0.0052, -0.0062, -0.0060,  ...,  0.0415, -0.0285, -0.0592],
        [-0.0019, -0.0012,  0.0002,  ..., -0.0020, -0.0034, -0.0027],
        [ 0.0005,  0.0008,  0.0008,  ..., -0.0004,  0.0009,  0.0004],
        ...,
        [-0.0044,  0.0060, -0.0106,  ...,  0.0083,  0.0099,  0.0117],
        [ 0.0201,  0.0483,  0.0813,  ...,  0.0242,  0.0263,  0.0000],
        [-0.0037, -0.0008,  0.0008,  ..., -0.0077, -0.0032,  0.0000]],
       device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([255360, 255360, 255360, 255360, 255360, 255360, 255359, 255359],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,  882, 6988,   23, 7233,  223, 2218,  249,   59,  240, 1660,  394,
           36,   88, 2486, 1419,   74,  742,    5,  592,    5,  123,   32, 4163,
          364, 6857,   22, 4679,  165,   49,  330,  706,  122,   93, 1765,   42,
         3625,   32,  410,  840, 3218,   22, 2078,  272,    4,   34, 1668, 6989,
          364, 5156, 1634,   16,   34,   43,  223, 2486, 1877,   96, 1594,  123,
           42, 1699,  962,  933,    5,    1,    1,    1,    1,    1],
        [   2,   99,  578, 4590,   37,    4,  256, 3864,   98,  102, 8847,   23,
         4542,   16,   23, 9499,   28,  208,    4,  268,   31,  189,   28, 1653,
         4180,    4,  728, 2783,    4,   34,   31,  647, 6511,    5, 4542,   16,
          880,  357,   20,   28,  141, 3618,  351, 1024, 5567,  145,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 7610,    4,   50, 7701,    4,   90, 9801, 2230,    4, 8055,
          186,  792,   78,   52,  751, 2557,   49, 1813, 6395, 3168,   15,  193,
         1699, 2629,    4,  531,  571, 2629,    4, 6725,    6,  812, 1328,  356,
         9224,   22,  160, 1783, 2629,  193, 2971,   14, 3385,   23, 2590,   16,
           14,  441, 7784,   23, 2580,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 5102,   44, 1214, 7115,   59,  633, 5047, 4107,   81,   43, 4051,
            4,  210,  124, 2824, 6115, 8967,    4,   16, 4587,  398,  189,   40,
         9041, 2842,    4,   88,   43,  255,   28, 1564,    5, 1541,  777,  303,
         5102,  221,  119,  390,  122, 1582,   81, 7041,    5,  146, 1483, 5924,
         1604, 1021, 5061,  249,  390, 3971,  210, 3725,   59, 5102,   60, 8339,
           37, 5339,  300, 1347,    5,    1,    1,    1,    1,    1],
        [   2,  520,   31,    9, 3779, 7189,  308,    6,    6, 1694,  195, 9070,
           82,    4, 3933,   31,   49,  141, 1624, 4816,   59, 2915,  539, 3339,
           37,    4,  823,   14, 5006, 1063, 1027,  587,  195,  112, 2050,  588,
          471,    4,   16,   52,  805,  617,    4,   14,   61,   23, 5006,   40,
         1041,  364,  201,  990,  769,    4,  136,  621, 2242, 3777,  788,  548,
          983,   16,  355,  210,   23, 4444, 1176,    5,    1,    1],
        [   2,  222,   36,   52, 4348, 3477,  178,   46,   16,   31,  514,   30,
          263,   46,   14, 1798,   76, 6773,   20,   28, 9486,   15,    4,   14,
         1798,   76,  330,  424,  233,    6,   28, 2251,    5,   72,  313, 2938,
          831,    4,   50,   32,  582,   58, 4364,   23,  489,   78, 1437, 5232,
         1669,  123,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298,  329,   31,  501, 1341,    4,  789,    5,   11,  298,  313,
           31, 1907, 7871,    4,   43, 7529,   61,    4,   60,  102, 1417,   15,
          685,  315,  821,   22,    4,  189, 4047,   43, 1354,   16, 4829, 1433,
         1581, 2741,   16,   43, 4047,   20,   75,  393,   88,   16,   43,   56,
         1358, 1150, 2545,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 6943, 8248,   20,   31,   39,  337, 1946,   15, 3737,   16,  915,
            4,   31,  354,  112, 1447, 1372,   51, 2563,    5,  147,  217, 1498,
            5, 5904,  421,   59,  365, 1021, 4863,   14,  489,   16,   31,   51,
         2448,    4,   50,   31,  582,  112,  423,  397, 1099,  112,   52, 1542,
          489, 7323,  280,   16,   50,   23, 7272,   61, 1357, 1784,  149,   14,
          585,  426,  576,  265,   59,  152,  122,  165,   82,    5]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[3706,   55,    7, 3210,   12, 2058,   35,  249,   59,  240, 1144,    4,
           53,   11,   57,  133,  946, 2787,    9, 2047,   12,    4,   73,   24,
          694,  214,   10, 2231, 2736,  941,    4, 1645, 2078, 2399,   70, 2892,
         1075,   73,   87,    8, 2293,  359, 4531,  946, 6710,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  13,  143, 4089,  207,   10,  154,   80,   89, 6674,    6,  506,   51,
            9, 2047,   12, 1387,  687,    8, 4480,    4,  206,   85,  419, 1800,
          613,    9,  183,    4,   71,  419, 1127,  723,    4,   19,  217, 1102,
         1387,    8, 8219,  106,   17, 2216,    4,   77,   79,   13, 2443,   12,
           70,   19,  296,   10,   87,  230,  115,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   7, 7374,   17, 5290, 1247,    4,   79, 4546, 1247,    4,  220,  508,
         3667,   10,   13,  733, 6608,   12,  341, 1603, 4345,   46, 1259, 1247,
            4,  618,   59, 1247,    4, 3109,  140,   57,  411,  266,   26, 2856,
         1247,   46, 4574,   48,    7, 2303,   12,    7, 1827,    8,    7, 4715,
           12,    7, 1136,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [4157,   44, 7957, 6266, 1119, 1017,   21, 1962,    4,   85,  109, 3019,
          964, 4157,    4,    8,  180, 4587,   13, 1206,  567,   10, 1005,   21,
           84,    5, 4958,    7,   59,  627, 1202,  290, 1408,    5, 6712, 5933,
         6962,   26, 2770,   10, 5989,   85, 1362,   20,  586,  922, 4157,   71,
         3955,   45,  502, 8366,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 120,   19,   34,   39,    9, 1324,    9, 1954, 6935,    4,   19, 1346,
           80,   13, 1361,   12, 8188, 4039,  148,  144, 1828,  244, 1339, 1027,
          587,  195, 3485,    4,    8,   13, 8188, 1793,  148,  692,   10,  508,
         4460,   69,   17, 3485,    4,    8,  211,  218, 3280,  692,   10,  205,
            8,  601,  267,  508, 4460,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 103,   84,   11,    6,   91,  759, 4039,   46,    8,   19,  172,  135,
           33,   46,  148,   63, 3163,   10,  229, 1583,  583,    6,    4,  148,
           63, 3163,   10,   51,   69, 3836,    4,   19,  217, 2497, 1123,   17,
           24,   73,  204,  468,    7,  538,   12, 1261,    4, 2318,    4,   55,
            7, 4959,   12, 1146,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   29,   19,  246,    4,   38,    6, 1049,  137,   29,   19,  175,
          518,    4,    8,  225, 1559,   69,    4,    8,   71,   13,  277,  523,
           12,    7,  170, 1522,    4,   13,  176,    4,  180,  225, 1518,  336,
            4,    8,  225, 1143,   80,  423, 2360,    4,    8,  225, 1518,  270,
          336,    4,    8,  225,   11,    6,   77, 6087,    6,    5,    2,    1,
            1,    1,    1,    1,    1],
        [  85,    7,  183,   19,   34, 1931,   54,    9,  117,  341, 1427,    4,
           19,  474,   19,   34, 3258,   54, 4029, 1352,    4,   67,   69, 1858,
         2007, 1498, 1261, 9096,  237, 1181,    4,    8,   19, 4600,   19,   11,
           48,  204,  226, 3258,   54,   13, 1127,  546,   55,  143,  254,  423,
          215,    4,    8,    7, 2838,   69,  264, 1736,   34,   21,    6, 2402,
          119, 8197,  271,    5,    2]], device='cuda:5'), 'cluster_tokens': tensor([[83, 37, 37, 94, 37, 28, 38, 77, 35, 35, 32, 11, 37, 85, 77, 83,  2, 56,
         37, 32, 37, 11,  6, 38, 32, 56, 37, 49, 29, 94, 11,  6, 94, 49, 50, 49,
         56,  6, 85, 37, 49, 37, 50,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50,  2, 83, 37, 59, 37, 37, 36, 37,  6, 38, 37, 32, 37, 83, 35, 37,
         23, 11, 37, 37, 50, 31, 32, 37, 24, 11, 37, 50, 50, 94, 11, 38, 38, 83,
         83, 37, 20, 37, 37, 28, 11, 50, 37, 37, 94, 37, 50, 38, 49, 37, 85, 37,
         83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 37,  9, 56, 11, 37, 32, 56, 11,  6, 88, 29, 37, 37, 50, 23, 37,
         33, 94, 56, 11,  9, 56, 11, 49, 35, 56, 11, 38, 35, 77, 35, 35, 85, 35,
         56, 11, 49, 31, 37, 94, 37, 37, 56, 37, 37, 94, 37, 37, 28, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [94, 82, 28, 94, 88, 31, 37,  2, 11, 37, 37, 37,  9, 94, 11, 37, 37, 49,
         37, 29, 32, 37, 49, 37, 37, 11, 29, 37, 35, 35, 49, 35, 35, 11,  2, 28,
         94, 85, 31, 37, 49, 37, 38, 77, 35, 31, 94, 37,  9, 35, 35, 94, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 38, 37, 77, 37, 38, 28, 11, 38, 59, 37, 37, 94, 37, 28, 56,
         50, 85, 31, 37, 38, 35, 35, 35, 94, 11, 37, 37, 28, 28, 50, 85, 37, 88,
         94, 37, 37, 94, 11, 37, 50, 50,  9, 85, 37, 85, 37, 49, 37, 88, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 50, 24, 56, 11, 37, 38, 83, 59, 37, 11, 50, 85,  2, 37,
         49,  9, 88, 37, 11, 50, 85,  2, 37, 38, 37, 94, 11, 38, 38, 83, 83, 37,
         38,  6, 83, 29, 37, 83, 37, 94, 11, 83, 11, 37, 37,  9, 37, 28, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 38, 88, 11, 38, 37, 77, 11, 83, 38, 85, 37, 11, 37, 37, 85, 37,
         11, 37, 37, 37, 50, 83, 37, 37, 37, 35, 11, 37, 35, 11, 37, 37, 40, 37,
         11, 37, 37, 85, 37, 34, 24, 11, 37, 37, 40, 37, 37, 11, 37, 37, 85, 37,
         50,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 37, 24, 38, 85, 32, 49, 37, 37, 33, 56, 11, 38, 31, 38, 85, 29, 49,
         33, 18, 11, 37, 37, 17, 11, 34, 94,  9, 35, 31, 11, 37, 38, 31, 38, 85,
         31, 83, 85, 29, 49, 37, 50, 18, 37, 50, 37, 34, 24, 11, 37, 37, 29, 37,
          2, 28, 85, 37, 37, 83, 75, 32, 44, 11, 83]], device='cuda:5'), 'lengths': tensor([47, 57, 53, 54, 55, 54, 59, 65], device='cuda:5'), 'ntokens': 444}, 'target': tensor([[ 882, 6988,   23, 7233,  223, 2218,  249,   59,  240, 1660,  394,   36,
           88, 2486, 1419,   74,  742,    5,  592,    5,  123,   32, 4163,  364,
         6857,   22, 4679,  165,   49,  330,  706,  122,   93, 1765,   42, 3625,
           32,  410,  840, 3218,   22, 2078,  272,    4,   34, 1668, 6989,  364,
         5156, 1634,   16,   34,   43,  223, 2486, 1877,   96, 1594,  123,   42,
         1699,  962,  933,    5,    2,    1,    1,    1,    1,    1],
        [  99,  578, 4590,   37,    4,  256, 3864,   98,  102, 8847,   23, 4542,
           16,   23, 9499,   28,  208,    4,  268,   31,  189,   28, 1653, 4180,
            4,  728, 2783,    4,   34,   31,  647, 6511,    5, 4542,   16,  880,
          357,   20,   28,  141, 3618,  351, 1024, 5567,  145,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146, 7610,    4,   50, 7701,    4,   90, 9801, 2230,    4, 8055,  186,
          792,   78,   52,  751, 2557,   49, 1813, 6395, 3168,   15,  193, 1699,
         2629,    4,  531,  571, 2629,    4, 6725,    6,  812, 1328,  356, 9224,
           22,  160, 1783, 2629,  193, 2971,   14, 3385,   23, 2590,   16,   14,
          441, 7784,   23, 2580,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [5102,   44, 1214, 7115,   59,  633, 5047, 4107,   81,   43, 4051,    4,
          210,  124, 2824, 6115, 8967,    4,   16, 4587,  398,  189,   40, 9041,
         2842,    4,   88,   43,  255,   28, 1564,    5, 1541,  777,  303, 5102,
          221,  119,  390,  122, 1582,   81, 7041,    5,  146, 1483, 5924, 1604,
         1021, 5061,  249,  390, 3971,  210, 3725,   59, 5102,   60, 8339,   37,
         5339,  300, 1347,    5,    2,    1,    1,    1,    1,    1],
        [ 520,   31,    9, 3779, 7189,  308,    6,    6, 1694,  195, 9070,   82,
            4, 3933,   31,   49,  141, 1624, 4816,   59, 2915,  539, 3339,   37,
            4,  823,   14, 5006, 1063, 1027,  587,  195,  112, 2050,  588,  471,
            4,   16,   52,  805,  617,    4,   14,   61,   23, 5006,   40, 1041,
          364,  201,  990,  769,    4,  136,  621, 2242, 3777,  788,  548,  983,
           16,  355,  210,   23, 4444, 1176,    5,    2,    1,    1],
        [ 222,   36,   52, 4348, 3477,  178,   46,   16,   31,  514,   30,  263,
           46,   14, 1798,   76, 6773,   20,   28, 9486,   15,    4,   14, 1798,
           76,  330,  424,  233,    6,   28, 2251,    5,   72,  313, 2938,  831,
            4,   50,   32,  582,   58, 4364,   23,  489,   78, 1437, 5232, 1669,
          123,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298,  329,   31,  501, 1341,    4,  789,    5,   11,  298,  313,   31,
         1907, 7871,    4,   43, 7529,   61,    4,   60,  102, 1417,   15,  685,
          315,  821,   22,    4,  189, 4047,   43, 1354,   16, 4829, 1433, 1581,
         2741,   16,   43, 4047,   20,   75,  393,   88,   16,   43,   56, 1358,
         1150, 2545,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [6943, 8248,   20,   31,   39,  337, 1946,   15, 3737,   16,  915,    4,
           31,  354,  112, 1447, 1372,   51, 2563,    5,  147,  217, 1498,    5,
         5904,  421,   59,  365, 1021, 4863,   14,  489,   16,   31,   51, 2448,
            4,   50,   31,  582,  112,  423,  397, 1099,  112,   52, 1542,  489,
         7323,  280,   16,   50,   23, 7272,   61, 1357, 1784,  149,   14,  585,
          426,  576,  265,   59,  152,  122,  165,   82,    5,    2]],
       device='cuda:5'), 'target_lengths': tensor([65, 47, 54, 65, 68, 51, 52, 70], device='cuda:5'), 'ntokens': 472, 'nsentences': 8}##################### {'id': tensor([137934, 175149, 141393, 206931,  96483, 143726], device='cuda:3'), 'net_input': {'src_tokens': tensor([[-4.9744e-03, -1.8616e-03,  2.5024e-03,  ...,  1.0376e-03,
          1.5259e-04, -1.8311e-03],
        [-1.7090e-03, -1.2207e-03, -5.1880e-04,  ...,  1.5869e-03,
          2.0142e-03,  1.5564e-03],
        [-8.8501e-04,  0.0000e+00,  7.6294e-04,  ..., -7.1960e-02,
         -5.8411e-02, -4.7821e-02],
        [ 3.9673e-04,  2.7466e-04,  6.4087e-04,  ..., -7.0190e-04,
          1.8616e-03,  3.8452e-03],
        [-1.7090e-03, -2.6245e-03, -2.0752e-03,  ..., -2.3499e-03,
          3.0518e-05, -6.7139e-04],
        [-1.3428e-03, -7.3242e-04, -7.3242e-04,  ..., -5.3406e-03,
         -4.5166e-03,  0.0000e+00]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([358400, 358400, 358400, 358400, 358400, 358399], device='cuda:3'), 'prev_output_tokens': tensor([[   2, 1562, 1334,   32,   30,  269,    4,  449,   31,    4,   50,   41,
          604,    4,   50,   28,  686,   51,  297, 3129,  444,  259,    4,  750,
           41,  173, 3355,    4,    9, 2377, 1992,  349,   59, 5524,   15, 2230,
            4,   14, 2583, 5354,  675, 1358,   57,  791, 1015,  505, 2377, 3418,
           15, 4487,   20, 1557,  307,    4,   16,   14, 3418,   20, 1557,   15,
         2726, 2583,  658,  158,  300, 2648,  791, 1015,  505, 4487,   20,   16,
           30,   27,   36,    4,   74,   14, 9460, 6363,   16,  393,  560, 2298,
          161,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 6514,   23, 2310,   22,  515, 2727,  364,  259, 9040,    4, 5454,
           75, 5146,  257,  196,  302,  642,  216,   88,   14,  435,  242,   18,
           57,  241,  165,   90, 8838,    4,   34,  704,   27,   90,   28,  202,
          424, 7239,  656,    6,  259,   15,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 3075,    6, 4218,  329,   28,  669, 1506,   44, 1193, 2809, 2310,
          161,  105, 5535,   88,  815, 6091,  978, 4087,    5, 1701,  512, 1506,
            4,   14, 5374,  319,    4, 3921,   15, 2411,  849,    5, 1193, 2473,
           30,   27,  196,   47,  374,    5,   46, 1190, 1040,  695,  547,   60,
          141, 1280, 4262, 2730, 2199, 1132,  820, 1701,  329,   43,    5, 1193,
         4510,   20, 5535,  161,  189, 1581, 1045, 5998,    5, 1701,   41, 2270,
          335, 1350,   16,  329,   44, 1193,  967,  514,   47,    4,  403,   30,
         1581, 1045, 2715,  241,  221,  124, 1581, 1045, 4816,  978,   76,    4,
          136,  981, 1548,    6,   76,   36, 1581, 1045,    5, 1701,   68,  379,
           65],
        [   2,  402,   74,  470,   49,  107, 5241, 7211,   59,   78,  273, 1699,
          181,   57, 1090,   22,  195,    4,  273,  308,   18,   45,  165,   16,
          273, 3004, 3240,    4,    9,   23, 2675,    4, 4053, 3461,   28, 7041,
            4,  123,   32,  107, 1481,    4,  403,   14, 7627,   23, 2880,    4,
           14,   32,  843,    4, 8099,   15,    4,  417,   35,  424,  233,   15,
           16, 2251,    4,  107,  177,  790,  236,   52,  312, 9290, 7819,    4,
          403,   60,  536,  553,    6,   93, 1150,  190,   47, 2714,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  147,   60,  212, 3992,   15, 6251,    9,   52, 2436,   23, 3048,
          191,   83,   32,    9,  935, 1285,  726,  156, 2757,    4,   50,   32,
           14, 3190,  427, 5844, 2404, 9322,  123,  382,   28, 1421,  787,   23,
           23,  790,  236, 1417,   15, 3190,   46, 1056,  978,  427, 5844, 2404,
            4,   32,  260,   36,   78, 1268,    4,  820,  828,   16,   32,  123,
           14, 3190,  196,  463, 6275,    5,   92,   27,   52,  645,  129,  840,
         2170,    6,    5,  222,   32,   60,  216, 3048,  191,  845,  123,    4,
          123,   32,  273, 4231,  444, 3427, 3261,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  146,  157,    9, 1846,   15, 4727,   60,  872, 4427,   15,   28,
          990,    4, 6844,   43,   60,  157,  112,  259,   16,  817, 5937,    4,
           23,   15,  314,  485, 1229,  319,   90,  273,    4,  136,   14,  139,
         2675,   15,   16, 4967,  145,  191,    4, 1442,   18,  152, 2435,  491,
           16, 2064,   20,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[  67,  490,   24,   87,   17,    4,   19,   11,   48,  100,   25,   10,
          154,   17,   85,  419, 1800,  183,  120,   25,   11,   57, 2202,   84,
            4,    9,  155, 1992, 5896, 1247,    4,    7, 2583, 8748, 9169, 3413,
           54,   10,  155, 9879,    4,    7, 9879,   26, 3413,   54,   10,  155,
         2583, 8748, 9169,    8,   33,   26,  138,  155, 4941,   26, 3803,    8,
         8965,   48,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [5609,   10,    7, 1793,  183,  368, 5673,    4, 1276,    6,  499,   87,
         4986,   79,  261, 1269, 2536,   20,   79, 1970,    6,    4,  166,   26,
          509,  254,   21,   34,    9,   95,  424, 3400, 2197,   11,    6,  383,
            4,   67,   19,  499,  154,   17,  250,  225, 2396,   26, 4803, 5040,
           44,   38,  187,   66,   86,  226, 2373,    9,    7, 9091, 1313, 9094,
          137,   68,  194,   65,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  56,  525,   11,    6, 4197,  246,   10,  267, 1848,    4,   38,  160,
         1491,    4,   33, 4925, 2823,    6,   55,  815, 6091, 1086,  137,  267,
         1848,    4,  148,   63, 1102, 4907,    4, 1260,   69,    4, 4340,  982,
            5,   38,  511,   17,   11,    6,   86,   77,   46,  415, 1040,   26,
         1028,  126,   71,   13,  264, 1375,    4, 2199, 1132,  820,  438,  225,
          246,    5,   38, 2207, 4925,  164, 2823,   55, 1581, 1274,  137,  225,
         8640,   48,    8,  246,    4,   38,  187,  192,   11,   18,  135,  103,
           17,   11,    6, 1581, 1274, 1995,  241,  221,  109, 1581, 1274, 1793,
         1086,    4,   67, 3296,    4,   21,   11,    6, 1581, 1274,  137,   68,
          194,   65,    2],
        [   8,    9,    7,  370,  207,  294,   12,  170,   63,  115, 5954, 4273,
            6,   17, 3412,  108, 1259, 1882,    4,  108,  203,    6,  777, 1991,
            4,  108, 3857,    4,   69,    7, 1080,    6,   17,   33,  659,  601,
          170, 3560, 4390,    4,   24,   73,  884, 1179, 5625,   54,    8,   39,
          128,   93,  195,   54,    7, 1289,   24, 2056,    4,   24, 8099,    4,
           24, 3836,    4,   24, 2153,    4,   73,  450,  170, 4324,   12,  183,
         1179,  250,  659,  205, 1226,   71,  108, 3227,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  67,   71,   33,  822, 5108,    9,   13, 3708, 4774,    4,   24,   66,
         6960,   48,    9,  824, 2723,   45,  726, 1090,   17,   24,   73, 3814,
            7, 1729,   35, 1727,  430,  690, 3275,  110,  249,  132,   10, 1421,
          439,   12,   70,   26, 5914, 1417,   46,  248, 1086,  690, 3275,  110,
          249,    4,   24,   87,   21,   85, 7738,    5,  820,  828,    4,    8,
           24,   73,  499,  875,   17, 3151,  346,    5,  630,   12, 1823,    5,
          103,   25,   73,  875,    9,  143, 3708,    6,    4,   24,   73,  204,
          229,    7,  126, 2446,  276, 3028,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 875,   54,   94,  970,   10,  970,   71,  108, 3648,   26,   13,  207,
           12,  875,   54,  134,  970,   10,  970,   71,   94, 1004,  183,    4,
         1004,  672,    4, 4355,  931,  659,   66,  226,  133,  341,   10,  108,
          447,    4,   67,  148,    4,  100,  170,    4,  144, 1080,    6,    8,
         4989,    4, 2084,  335,   18, 1991,    6,    8, 3128, 2261,    9,  159,
          931,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 37, 38, 85, 37, 11, 38, 85, 31, 37, 37, 37, 59, 37, 37, 50, 31, 24,
         37, 37, 85, 77, 59, 37, 11, 37, 37, 34, 24, 56, 11, 37, 83, 28, 94, 32,
         49, 37, 37,  9, 11, 37,  9, 85, 32, 49, 37, 37, 83, 28, 94, 37, 37, 85,
         37, 37, 29, 85, 31, 37, 29, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 37, 28, 24, 49, 94, 11, 94, 37, 83, 85,  4, 37, 83,  9, 35, 77,
         37,  9, 37, 11, 37, 85,  2, 37, 37, 85, 37, 38, 35, 94, 35, 85, 37, 24,
         11, 37, 38, 83, 59, 37, 50, 37, 31, 85, 83,  2, 82, 38, 35, 85, 83, 85,
         83, 37, 37,  9, 37, 24, 11, 38,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 35, 85, 37, 94, 88, 37, 37, 56, 11, 38, 35, 28, 11, 37,  9, 49, 37,
         37, 17, 73, 32, 11, 37, 56, 11, 50, 85, 83, 56, 11, 59, 37, 11, 16,  2,
         11, 38, 35, 37, 85, 37, 83, 50, 11, 38, 35, 85, 49, 37, 37, 37,  2, 94,
         11, 34, 73, 73, 82, 37, 88, 11, 38, 77,  9, 85, 49, 37, 17, 60, 11, 37,
         29, 31, 37, 88, 11, 38, 35, 85, 85, 35, 59, 37, 37, 85, 37, 17, 60, 38,
         35, 35, 37, 17, 60, 28, 32, 11, 37, 83, 11, 37, 85, 37, 17, 60, 11, 38,
          9, 11, 83],
        [37, 37, 37,  4, 83, 50, 37, 37, 85, 83, 49,  9, 37, 37, 29, 37,  9, 23,
         11, 37, 38, 37, 67, 94, 11, 37, 47, 11, 37, 37, 94, 37, 37, 37,  6, 49,
         37, 29, 56, 11, 38,  6, 88, 37, 29, 49, 37, 38, 35, 35, 35, 49, 37, 56,
         38, 16, 11, 38,  9, 11, 38, 94, 11, 38, 49, 11,  6, 88, 37, 83, 37, 24,
         37, 50,  6, 85,  2, 37, 37, 47, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 37,  2, 94, 37, 37, 94, 94, 11, 38, 85, 88, 31, 37, 38, 35, 35,
         35, 35, 37, 38,  6,  5, 37, 56, 38, 35, 35, 38,  9, 37, 77, 37, 37, 34,
         24, 37, 50, 85, 83,  2, 11, 34, 32, 38,  9, 37, 77, 11, 38, 85, 37, 37,
          9, 11, 73, 73, 11, 37, 38,  6, 83, 49, 37, 32, 37, 11, 94, 37, 23, 11,
         37, 37,  6, 49, 37, 50, 94, 37, 11, 38,  6, 83, 49, 37, 37, 35, 83,  2,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [49, 49, 56, 32, 37, 32, 37, 37, 56, 85, 37, 83, 37, 49, 49, 37, 32, 37,
         32, 37, 56, 37, 24, 11, 37,  9, 11, 88, 37,  6, 85, 85, 83, 33, 37, 37,
         37, 11, 37, 50, 11, 37, 37, 11, 85, 94, 37, 37, 56, 11, 38, 35, 35, 94,
         37, 37, 49, 56, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:3'), 'lengths': tensor([ 64,  65, 111,  82,  92,  63], device='cuda:3'), 'ntokens': 477}, 'target': tensor([[1562, 1334,   32,   30,  269,    4,  449,   31,    4,   50,   41,  604,
            4,   50,   28,  686,   51,  297, 3129,  444,  259,    4,  750,   41,
          173, 3355,    4,    9, 2377, 1992,  349,   59, 5524,   15, 2230,    4,
           14, 2583, 5354,  675, 1358,   57,  791, 1015,  505, 2377, 3418,   15,
         4487,   20, 1557,  307,    4,   16,   14, 3418,   20, 1557,   15, 2726,
         2583,  658,  158,  300, 2648,  791, 1015,  505, 4487,   20,   16,   30,
           27,   36,    4,   74,   14, 9460, 6363,   16,  393,  560, 2298,  161,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [6514,   23, 2310,   22,  515, 2727,  364,  259, 9040,    4, 5454,   75,
         5146,  257,  196,  302,  642,  216,   88,   14,  435,  242,   18,   57,
          241,  165,   90, 8838,    4,   34,  704,   27,   90,   28,  202,  424,
         7239,  656,    6,  259,   15,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [3075,    6, 4218,  329,   28,  669, 1506,   44, 1193, 2809, 2310,  161,
          105, 5535,   88,  815, 6091,  978, 4087,    5, 1701,  512, 1506,    4,
           14, 5374,  319,    4, 3921,   15, 2411,  849,    5, 1193, 2473,   30,
           27,  196,   47,  374,    5,   46, 1190, 1040,  695,  547,   60,  141,
         1280, 4262, 2730, 2199, 1132,  820, 1701,  329,   43,    5, 1193, 4510,
           20, 5535,  161,  189, 1581, 1045, 5998,    5, 1701,   41, 2270,  335,
         1350,   16,  329,   44, 1193,  967,  514,   47,    4,  403,   30, 1581,
         1045, 2715,  241,  221,  124, 1581, 1045, 4816,  978,   76,    4,  136,
          981, 1548,    6,   76,   36, 1581, 1045,    5, 1701,   68,  379,   65,
            2],
        [ 402,   74,  470,   49,  107, 5241, 7211,   59,   78,  273, 1699,  181,
           57, 1090,   22,  195,    4,  273,  308,   18,   45,  165,   16,  273,
         3004, 3240,    4,    9,   23, 2675,    4, 4053, 3461,   28, 7041,    4,
          123,   32,  107, 1481,    4,  403,   14, 7627,   23, 2880,    4,   14,
           32,  843,    4, 8099,   15,    4,  417,   35,  424,  233,   15,   16,
         2251,    4,  107,  177,  790,  236,   52,  312, 9290, 7819,    4,  403,
           60,  536,  553,    6,   93, 1150,  190,   47, 2714,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 147,   60,  212, 3992,   15, 6251,    9,   52, 2436,   23, 3048,  191,
           83,   32,    9,  935, 1285,  726,  156, 2757,    4,   50,   32,   14,
         3190,  427, 5844, 2404, 9322,  123,  382,   28, 1421,  787,   23,   23,
          790,  236, 1417,   15, 3190,   46, 1056,  978,  427, 5844, 2404,    4,
           32,  260,   36,   78, 1268,    4,  820,  828,   16,   32,  123,   14,
         3190,  196,  463, 6275,    5,   92,   27,   52,  645,  129,  840, 2170,
            6,    5,  222,   32,   60,  216, 3048,  191,  845,  123,    4,  123,
           32,  273, 4231,  444, 3427, 3261,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 146,  157,    9, 1846,   15, 4727,   60,  872, 4427,   15,   28,  990,
            4, 6844,   43,   60,  157,  112,  259,   16,  817, 5937,    4,   23,
           15,  314,  485, 1229,  319,   90,  273,    4,  136,   14,  139, 2675,
           15,   16, 4967,  145,  191,    4, 1442,   18,  152, 2435,  491,   16,
         2064,   20,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:3'), 'target_lengths': tensor([ 86,  43, 109,  83,  92,  52], device='cuda:3'), 'ntokens': 465, 'nsentences': 6}##################### {'id': tensor([  2330,  32727, 192313, 160900,  73023, 101478, 146457, 184148,  33229,
        172307, 152388, 159474, 137357, 136901,  93571, 211315],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[-3.2959e-03, -2.9602e-03, -3.1433e-03,  ...,  1.0681e-03,
          2.1973e-03,  3.3875e-03],
        [-1.0529e-02, -7.1106e-03,  2.1973e-03,  ...,  6.1340e-03,
          3.1128e-03, -4.7302e-03],
        [-9.7656e-04,  1.3733e-03, -2.7466e-04,  ..., -9.1553e-05,
         -9.1553e-05, -9.1553e-05],
        ...,
        [-1.1292e-03, -9.7656e-04, -5.7983e-04,  ..., -4.2725e-04,
          2.1973e-03,  3.0823e-03],
        [-2.1118e-01, -2.1924e-01, -2.1777e-01,  ...,  8.1543e-02,
          6.2073e-02,  0.0000e+00],
        [ 3.6926e-03,  4.0283e-03,  4.0894e-03,  ...,  6.4087e-04,
          1.8616e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([119680, 119680, 119680, 119680, 119680, 119680, 119680, 119680, 119680,
        119680, 119680, 119680, 119680, 119680, 119679, 119679],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2,  147,   32,  208,   50,  686,   49,  448,  582, 4637,   18,   16,
          118,  351,  758,  130,    4, 3205,    4,   74,   81, 3948,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 1462, 1667,   82,  301, 1178,  411,    4,   16,  406, 8447, 2492,
           37,   16,  139,   40, 6045,   37,   37,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   72,  557,  252,   52,  489,   49,  302, 1813, 1340, 1306,    4,
           49,  302, 6423,   15, 1340,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 4104, 1709, 1071,  280,   30, 4205,  406,  751,    6, 1464,   16,
          374,   34, 1657,   82,    9,  308, 1199, 6019,    5,  882, 6988,   49,
          198,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  104, 3195,   15,  118, 1016, 2741, 5641,  867,  973,  221,   37,
            4,  113,  273, 5393,    4,  177,   14, 2161,   57,  349,  292, 1341,
            6,    4,  536, 5065,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   41, 1457,    4,   43, 5775,  291,   37,   45,  219,   48,  418,
            4,   75,   39, 2954,   23,  349,  152,   22,  658,   28, 2425,    4,
            9,   23, 2675,    4,   50,  331, 4540,  262, 4440,   56, 2564,   15,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  222,   32,  917, 1717,   20,  334,    4,  189,  604,   14,  731,
           49,  252,   39,  435,    5,   92, 2714,    5, 1737,  950, 1577,  435,
         1671,  917, 1717,   20,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  864,   18, 3056, 1350, 3533, 4611,   14, 6866,   90, 2890, 1378,
            4, 3262,   30, 1690,  463, 2306,    4,   90, 6947,    9,  704,   37,
         1299,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 1186,   56, 6280,  119, 1593,  149, 1473,   30, 2819,   98,    5,
           38, 6312,  406, 8915,   27,  438,  327,   27,   39, 2099,  616,  249,
          634, 1791,   42,   38,  967,  209,    9, 2099,  616,  249,  634,  433,
          167,  414, 9150,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  202, 2832,   20,  716,    4,   14, 1572,  223,   14, 2580, 3598,
           28,  123,    4,   16,   32, 1495,  105,  157,  742,  673, 1691, 8280,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   41,  319,  278, 1485, 5796,  951,  662,  157,    4,  136,  139,
          263, 7176,   20, 6612, 1694,    4,   16,   43,  522,   51,  195, 1895,
          236,   18,    4,   97, 4061,   28,  351,   41,   48,  562,   22, 2834,
         3716, 7321,   28,  186,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 3442,  389,   45,  381, 1548,    6,  285,    6, 2652,  721,   46,
           50,   95,   49,  151,   56, 4017, 1374, 1271,  243,  160,   22,  101,
          389,  247,    6, 1338,  239,    4,   40, 3591,    4,   23,  495, 2036,
         1089,  153,    4,  258, 4819,   88,   30,  314,   98, 1002,   28, 1336,
          307, 1527,    5],
        [   2,   64,   43, 5190,   15,  600,    4,   50,   43,   75, 9602,   37,
         3582,   15,    4, 2211,   43, 3906,   15,  471,    4, 2211,   43,   14,
         1980,  683, 2719,   20, 2674,    9, 1474,  314,   39, 1395,   15,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 2708,   43, 7967,    4, 1097,  158,  494,  272,   14, 4002,  549,
           60, 2972,   15,   16, 3645,  210,  686,   23,  938,  158,  340,  369,
           15,  118,  580,  805,  972,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  520,   31,  217, 1190,  500,  140,  233,   12,  301,  609,   15,
           18,  597,  266,  228, 1050,  119,  724,  472,    6,   20, 3232,   82,
          193, 1016, 2380,  866,  634,  193,  114,  302, 1140,  804, 3134,  240,
          634,   47, 2630, 2411,   15,    4, 3371,   20,   31, 2062,    6,   61,
            5,    1,    1],
        [   2, 2467,   30, 5023,  240, 2485,   23, 1356,    6, 1512,   20,   51,
          221, 5960,   15, 1438,   61, 3409, 1058,  669, 6717,   39,   23, 1734,
           22, 1977, 6515,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[  67,   24,  150,   17,  545,   91,   12,  117,   26,  204, 4637,   54,
            4,    8,  188,   13,  341,  207,   12, 3101,  126,  138,   10,   87,
          282,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   89, 1970,   34,   13, 3090,  756,    4,    8,   89,  291, 3769,
           34,   13, 1390,   37,  684,    8,  113,   13, 1116, 1040,   37,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  164,  450,   25,   13,  546,   12,  248,  341, 2352,    4,  248,
         1284, 2352,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  391, 1551, 1065,    4,   17, 2182,  144, 3814,   48,   89,  637,
            8,  333,  473,  279,    9,   21, 3706,   55,  110,   10,   13, 1098,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  24, 3195, 6482,   35, 6937,  227, 3134,  221,    4,   19,    5,   20,
            5,  108, 2805,    4,  132,   10,  108, 7009,    6,   11, 1492, 1485,
           12, 3402,   93,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  53,  246,   53,  169,  780,   29,  835,   10, 1008,    7, 8365,    6,
           12,    7, 3311,    4, 7443,   17, 1573,  162, 3754,    8,  401,    7,
          370,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,   24,  289, 1228, 3374,    4,  281,   12,   25,  154,   80,  708,
            5,   21,   11,    6, 1301,    5, 2703,  901,  439,   12,  708,   87,
          722, 1228, 3374,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 291, 1105,   18, 3396, 1095,    7, 4480,   79, 1019, 2071,    4, 1095,
            7, 5640, 1375,   79, 1019, 2071,  755,    4,  254,   94,  148,  162,
            9,  509, 1862,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  25,   11,   57,  116, 2213,   54,    8, 9171,    5,   38, 3127,   89,
         3397,   26,  438,   70,   11,    6, 1226,   71,  682,  616,  249,  407,
            6,   42,   38,  187,   11,  121,  144,  185,  453,  110,  128,    6,
           85,  682,  616,  249,  407,    6,    5,    2],
        [ 101, 5523,   17, 1381,  220,   51, 1405,  131,    7,   94,    4,    8,
           24,  583,  251,   94, 9475, 4637,  373,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  53,  162, 1052, 1563,   94,    4,   67,   53,  162,  113,  172, 7176,
           20, 3979, 2120,    4,    8,   53,  162, 9231,   62,   12, 4391, 3834,
           12, 3716,   35, 7305, 2527,   15,  609,   96,    4, 5653,   10,    7,
          218,  415, 2633, 2120,    5,    2,    1,    1],
        [  85, 4615,    4, 9785,  369,   46,   17,  101,   11,   48,  226,  987,
         1181,  131,   39, 6651, 2266,  160,   22,    4,   13, 5289,  126,   10,
         2585,   20,  366,  565,    4,  276,   10, 9304,    7,  282,  126,   12,
          565,    5,    2,    1,    1,    1,    1,    1],
        [   8,   53,  276, 2982,   80, 1790, 8661,    4,  276, 1445,   53,  162,
            9, 3454,    4,  276, 1445,   53,  162,  830, 1785,  810,    7, 5167,
          608, 2020,   12,  159,  931,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  117, 4312,   22,    6,    4, 1025, 3043,   54,    4,   53,  415,
          158, 1515,   71,    7, 7224,    4,    8,    9,  117,  415,  158,  340,
         1955,   53, 3121,   13, 1905, 1762,   12,  941,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,   19,   34,   85, 8195,   12, 2931, 2735, 1221,   46, 1016, 4618,
          866,  693,   46,  120,  248, 4618,  866,  693,  162,   86,  952,   10,
          545,  218,    4,   19,  169,  939, 8966,  834,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 131, 5114,  235, 2399, 1006,    4,  889,   63,    4,    9,   13,  841,
            4, 1449, 1778,  159, 5186,   10,    7, 1722, 3609,   12,  422, 6222,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 38, 59, 37, 50, 50, 37, 37, 85, 83,  9, 49, 11, 37, 85, 37, 33, 83,
         37, 59, 37, 37, 37, 85, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37,  9, 85, 37, 31, 77, 11, 37, 37, 38, 35, 85, 37,  9, 77, 35, 37,
         83, 37, 38, 35, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 88, 37, 37, 18, 37, 34, 33, 56, 11, 34,  2, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 34, 24, 24, 11, 37,  9, 85,  5, 31, 37, 37, 37, 50, 37, 50, 37, 37,
         83, 37, 37, 37, 37, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 49, 34, 38, 23, 38, 35, 35, 11, 38, 11, 77, 11, 37, 94, 11, 37, 37,
         37,  9, 37, 85, 38, 77, 37, 38, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 88, 37, 85, 88, 83,  2, 37, 59, 37, 29, 37, 37, 37,  9, 11, 88, 37,
         50, 85,  2, 37, 49, 37,  4, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 88, 32, 56, 11, 75, 37, 37, 59, 37, 56, 11, 37, 85, 37,  2, 11,
         34, 35, 24, 37, 56, 85, 49, 32, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 35, 56, 59, 37, 23, 37, 83, 35, 11, 59, 37, 49, 94, 37, 83, 35,
         37, 11, 37, 56, 50, 85, 37,  2, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 77, 83, 49, 49, 37, 49, 11, 38, 35, 37, 16, 85, 82, 50, 85, 37,
          2, 37, 38, 77, 77, 35, 37, 11, 38, 35, 85, 35, 85, 50,  2, 37, 35, 37,
         37, 38, 77, 77, 35, 37, 11, 83],
        [38, 31, 37, 94,  6, 38, 31, 37, 37, 56, 11, 37, 38, 88, 50, 56, 28,  9,
         56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 38,  2, 56, 11, 37, 37, 85, 83, 83,  2, 77, 28, 56, 11, 37, 37,
         85, 29, 31, 37,  2, 56, 37, 32, 38, 49, 83, 77, 35, 77, 11, 36, 37, 37,
         50, 38, 35, 56, 11, 83, 37, 37],
        [37, 75, 11,  9, 44, 11, 37, 38, 85, 31, 85, 38, 31, 37, 38,  2, 38, 35,
         35, 11, 37,  9, 37, 37, 29, 77, 77, 37, 11, 83, 37, 10, 37, 32, 37, 37,
         37, 11, 83, 37, 37, 37, 37, 37],
        [37, 37, 83, 16, 37, 32,  2, 11, 83, 37, 37, 85, 37,  9, 11, 83, 37, 37,
         85, 62, 35, 35, 37,  2, 75, 94, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 28, 35, 37, 11, 24, 29, 49, 11, 37, 38, 35, 92, 37, 37, 56, 11,
         37, 37, 37, 38, 35, 35, 44, 37, 29, 37, 50, 23, 37, 94, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 37,  9, 37, 28, 94, 94, 11, 34, 94, 35, 56, 11, 37, 34, 94,
         35, 56, 85, 83, 16, 37, 50, 50, 11, 38, 85, 38, 35, 11, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 35, 49, 94, 11, 56, 85, 11, 37, 37, 32, 11, 38, 35, 37, 88, 37,
         37,  2, 23, 37, 28, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:1'), 'lengths': tensor([27, 25, 16, 26, 29, 27, 29, 29, 44, 21, 42, 39, 31, 34, 34, 26],
       device='cuda:1'), 'ntokens': 479}, 'target': tensor([[ 147,   32,  208,   50,  686,   49,  448,  582, 4637,   18,   16,  118,
          351,  758,  130,    4, 3205,    4,   74,   81, 3948,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1462, 1667,   82,  301, 1178,  411,    4,   16,  406, 8447, 2492,   37,
           16,  139,   40, 6045,   37,   37,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  72,  557,  252,   52,  489,   49,  302, 1813, 1340, 1306,    4,   49,
          302, 6423,   15, 1340,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [4104, 1709, 1071,  280,   30, 4205,  406,  751,    6, 1464,   16,  374,
           34, 1657,   82,    9,  308, 1199, 6019,    5,  882, 6988,   49,  198,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 104, 3195,   15,  118, 1016, 2741, 5641,  867,  973,  221,   37,    4,
          113,  273, 5393,    4,  177,   14, 2161,   57,  349,  292, 1341,    6,
            4,  536, 5065,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  41, 1457,    4,   43, 5775,  291,   37,   45,  219,   48,  418,    4,
           75,   39, 2954,   23,  349,  152,   22,  658,   28, 2425,    4,    9,
           23, 2675,    4,   50,  331, 4540,  262, 4440,   56, 2564,   15,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 222,   32,  917, 1717,   20,  334,    4,  189,  604,   14,  731,   49,
          252,   39,  435,    5,   92, 2714,    5, 1737,  950, 1577,  435, 1671,
          917, 1717,   20,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 864,   18, 3056, 1350, 3533, 4611,   14, 6866,   90, 2890, 1378,    4,
         3262,   30, 1690,  463, 2306,    4,   90, 6947,    9,  704,   37, 1299,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1186,   56, 6280,  119, 1593,  149, 1473,   30, 2819,   98,    5,   38,
         6312,  406, 8915,   27,  438,  327,   27,   39, 2099,  616,  249,  634,
         1791,   42,   38,  967,  209,    9, 2099,  616,  249,  634,  433,  167,
          414, 9150,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 202, 2832,   20,  716,    4,   14, 1572,  223,   14, 2580, 3598,   28,
          123,    4,   16,   32, 1495,  105,  157,  742,  673, 1691, 8280,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  41,  319,  278, 1485, 5796,  951,  662,  157,    4,  136,  139,  263,
         7176,   20, 6612, 1694,    4,   16,   43,  522,   51,  195, 1895,  236,
           18,    4,   97, 4061,   28,  351,   41,   48,  562,   22, 2834, 3716,
         7321,   28,  186,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [3442,  389,   45,  381, 1548,    6,  285,    6, 2652,  721,   46,   50,
           95,   49,  151,   56, 4017, 1374, 1271,  243,  160,   22,  101,  389,
          247,    6, 1338,  239,    4,   40, 3591,    4,   23,  495, 2036, 1089,
          153,    4,  258, 4819,   88,   30,  314,   98, 1002,   28, 1336,  307,
         1527,    5,    2],
        [  64,   43, 5190,   15,  600,    4,   50,   43,   75, 9602,   37, 3582,
           15,    4, 2211,   43, 3906,   15,  471,    4, 2211,   43,   14, 1980,
          683, 2719,   20, 2674,    9, 1474,  314,   39, 1395,   15,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [2708,   43, 7967,    4, 1097,  158,  494,  272,   14, 4002,  549,   60,
         2972,   15,   16, 3645,  210,  686,   23,  938,  158,  340,  369,   15,
          118,  580,  805,  972,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 520,   31,  217, 1190,  500,  140,  233,   12,  301,  609,   15,   18,
          597,  266,  228, 1050,  119,  724,  472,    6,   20, 3232,   82,  193,
         1016, 2380,  866,  634,  193,  114,  302, 1140,  804, 3134,  240,  634,
           47, 2630, 2411,   15,    4, 3371,   20,   31, 2062,    6,   61,    5,
            2,    1,    1],
        [2467,   30, 5023,  240, 2485,   23, 1356,    6, 1512,   20,   51,  221,
         5960,   15, 1438,   61, 3409, 1058,  669, 6717,   39,   23, 1734,   22,
         1977, 6515,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([23, 20, 18, 26, 29, 37, 29, 26, 40, 25, 41, 51, 36, 30, 49, 28],
       device='cuda:1'), 'ntokens': 508, 'nsentences': 16}
##################### {'id': tensor([ 48670,   1098,  20786,  12102, 136280, 167847,  34825, 146491, 208300,
        166991,  16409,  61366, 119502, 169739,  51440, 183174],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 6.9885e-03,  5.9204e-03,  4.9744e-03,  ..., -8.6060e-03,
         -1.0376e-02, -1.1017e-02],
        [ 8.8501e-04,  2.1973e-03,  6.4087e-04,  ...,  2.4719e-03,
          6.5613e-03,  9.0332e-03],
        [-1.9836e-03, -2.4414e-03, -3.2654e-03,  ...,  2.5757e-02,
          2.3590e-02,  2.2217e-02],
        ...,
        [-6.4087e-04, -7.6294e-04, -1.5259e-03,  ..., -2.2583e-03,
         -2.0752e-03,  0.0000e+00],
        [-1.2207e-03,  4.2725e-04,  9.1553e-05,  ..., -3.3569e-04,
          0.0000e+00,  0.0000e+00],
        [-2.7466e-04, -6.7139e-04, -1.1902e-03,  ..., -6.3782e-03,
         -7.4768e-03,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([100640, 100640, 100640, 100640, 100640, 100640, 100640, 100640, 100640,
        100640, 100640, 100640, 100640, 100639, 100639, 100639],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2,  147,  728,  216,   32,   36, 3511,   15,    4,  129,  412, 1263,
           37,  239,    4,   50, 3626, 1938,   23, 4133,  319,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298, 6680,   22,   32,   52, 5940,  165,    4,   16,  189,  130,
           40, 3370, 2295, 3774, 7353,    9, 1357, 1784,   46,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2308,    4,   31,  256,    4,   31,  638,  193, 2358,   44,  147,
           76,   30,  512, 5179,   20,   42, 1104,  592,   44, 2308, 2358,   44,
          327,   82,  428,   30,   42,    1,    1,    1,    1,    1],
        [   2,  720,   27,  406, 3055, 4634,    5, 5028, 3370,    5, 3100, 1489,
          190,   28, 1092,  372,   18,   48,   57,    6,    6,   54,    6,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  557, 2915,  221,  335,   39,  156, 4076,   15,   16,   32,
          123,  208,    4,   74, 2915,  221,  335,   60, 1400, 4248,   15,   88,
           75,  363, 2546,  398,    5,    1,    1,    1,    1,    1],
        [   2, 3923,   31,  252,   30, 1606, 7558,  145,    4, 6511,   31,  470,
         7902,    4,   14,  485, 1013,  173,   61,   14, 4033,  615,   16,  189,
          260,   32,   52, 1012, 4410,   20,  441, 4362,    5,    1],
        [   2,  104,   83,  714, 1078, 2370,  756,  699,  262, 3491,   74, 1096,
          917,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  651,  118, 2190,    4,  403,   41,   30, 1139,  177,   75,
          208,   16,   58, 7439,   29, 7041,    4,  124,  403,   41,  118, 7439,
           83,    5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 8948,   22,   32,   61,   29,  190,   13, 2051,   42, 1414, 4790,
            5,   99,   27,  766,    4,   30,   28,  320,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  882,   77,  102,  164,   31,  334,    4,   50,   14, 9533,  646,
          102,    4,   34,   32, 8083,    4,   16,  102,    4,   34,   32, 4245,
          123,    4,  257, 2890,  161,    5,    1,    1,    1,    1],
        [   2,  396,   76,   98,   38, 5142,  864,   18,  187,   62, 1589, 1485,
           12, 9777,  857,  564,  868, 1047,  319,   36, 1107,  820,  550,   37,
          427,  472,   22,   18,  706,    5,    1,    1,    1,    1],
        [   2, 1209, 6882,   83,   43,  118, 1280,  880, 2023,   35,  899,  176,
          763,    4,   23,  892, 3114, 8764,   90,  273, 8032,    6,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 5455,    4,   14,    6,    9,  151, 3852, 1133, 6838,   27,
         5717,  728,   22, 4049, 1210, 4288,    6,   96,  124,  686,  482, 4770,
          303, 3199,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146,  326,   76, 1229,    4,  428,  361,  514,   31,    4,   50,
         5160,   15,   40, 2165,  247, 2919, 1845,   76,    4,   30,  686,  130,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41,  123,   75, 4612, 4436, 1782,   35, 6043,  232, 4044,  232,
           13, 5295, 1172,  382,   41,   95, 1688, 2845,   15,    4,  681,   41,
           47,  208,    4,  782,   43, 8242,  459,  458, 1172,    5],
        [   2,  104, 1770,   52, 1981,  502, 7570,   60,  102,  947,   15, 1087,
            4,   23,  947,   15, 5102,    4,   23,  947,   15,  817,  675,  527,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:0')}, 'transcript': {'tokens': tensor([[  67,    7,  143,   24, 1260,   85,   21,    4,    7,  143,   24, 1873,
           17, 1057,  453, 3540,   34,    7,  133, 1890,  279,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  29,   24,  552,  132,   71,   13, 4445,    4,    8,  204,   70,  956,
           34,   91, 2767, 2923,   37,    9,  264, 1736,   46,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 211,    4,   19,  641,    4,   19,  154,   46,  682,   44,   67,   26,
           17,  155, 4234,   42,  846,  174,   44,  211,    5,  682,   44,   70,
           34,   17,   91,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  33,   26,   89, 9264,    5,   86,  860,   13,  488,   91,    5,   19,
          213,   10,  289,  116,   13, 1455,   80, 2263,  556, 5610,   54,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19,   11,   45,  142,   10, 4431,   35,  140, 4076,   69,  832, 1486,
          335,    4,    8,   24,   73,  150,  832, 1486,  335, 2546,  829,   69,
           21,    6,  926, 1585,   71,   21,    6, 4241,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [   9, 1296,   10, 2572,   25,   33, 1678,    4,   19,   11,   45,  142,
           10,  296,  185, 5825,    6,   10,  367,  132,   69,    6, 5072,  172,
         2117,    4,    8,   24,   11,   57,  142,   10,   87,   13,  277, 1860,
           35,  399,  102,  287,    5,    2],
        [  24,  465,   11,   18,   87,   33,  131,  204, 2905, 3141,    4,  100,
           25,   87,    9,   13, 1192,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  17, 1073,   13, 1878,  629, 1891,    7,  595,    9, 1416,   12,   25,
            8, 4958,   54,    7, 4292,    4,  109,  893,  199,   39, 4292,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 115,   26,   33,  250,   17,   24,  451,   51,  101,   62, 1256,   12,
           42,   12,  538,    5,   21,   11,    6,  528,   17,   24,  135,   33,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  77,   12,   33,   10,  289,   17,    7, 4719,  629,   70,   24,   73,
         7039,    8,   70,   24,   73, 2032,   26,  288,  142,   10, 4038,   22,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  33,   26,  106,   38,  469,  291,   18,  187,   62, 1224,   12, 1491,
          137,    9,  564,  868, 1047,    4,   84,  162, 1107,  820, 5149,  690,
         7653,   20,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  60,  116,  188,   13,  264, 3742, 6211,   17,  368,    6, 1019,  908,
          768,  254,  108, 6211,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   7, 5346,   12, 1009,   17, 1241,   13, 1127,  567,   26,    4,  554,
            4, 2816,  419, 1661,   57,  969,    6,  369,  109,  419, 1620,   54,
         5974,  440,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 214,   63,  341,  125,  115,   19,  135,   17, 4751,   26,    7, 1037,
         2829,   17, 1459,  188,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 103,   25, 1260,   85, 2264,  241,  140, 1782, 5152, 1160,  158,   25,
          162, 2639,    4,   25, 2220, 1631,  830,  150,  347,   53, 5953,   48,
         6387,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  24,  692,   10,   66,   13,  740,  672,   71,    7,  230,  688,    4,
           71,    7,  230, 4157,    4,   71,    7,  230, 1404,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 37, 50, 38, 59, 37, 37, 11, 37, 50, 38, 86, 37, 49,  2, 56, 85, 37,
         83, 32, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 38, 85, 37, 37, 37, 94, 11, 37, 83, 50, 31, 85, 50, 75, 49, 77, 37,
          2, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [50, 11, 38, 88, 11, 38, 59, 11, 38, 82, 37, 85, 37, 37,  9, 11, 38, 35,
         82, 50, 11, 38, 82, 50, 85, 37, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 37,  9, 11, 83, 83, 37,  2, 50, 11, 38, 88, 37, 88, 83, 37, 32,
         37, 38, 35, 49, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 85, 35, 49, 37, 29, 38, 35, 35, 37, 38, 35, 35, 11, 37, 38,  6, 59,
         38, 35, 35, 38, 49, 37, 37, 37, 94, 37, 37, 37, 37,  9, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37],
        [37, 49, 37, 88, 37, 37, 32, 11, 38, 85, 35, 49, 37, 49, 50, 28, 37, 37,
         85, 37, 37, 37, 77, 83, 83, 11, 37, 38, 85, 77, 49, 37, 85, 37, 50, 56,
         38, 35, 38, 35, 11, 83],
        [38, 85, 85, 35, 85, 37, 37, 83, 49,  9, 11, 37, 37, 85, 37, 37,  9, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 37, 33, 37, 59, 37,  9, 37, 37, 37, 37, 37, 29, 49, 37, 32, 11,
         37, 49, 37, 38, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 85, 37, 50, 37, 38, 85, 38, 38, 31,  2, 37, 11, 37, 83, 11, 37, 85,
         37,  2, 37, 38, 59, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [50, 37, 37, 37, 88, 37, 37, 33, 37, 50, 38,  6, 59, 37, 50, 38,  6, 23,
         85, 83, 49, 37,  2, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 37, 38, 35, 38, 35, 35, 31, 56, 37, 28, 11, 37, 34, 73, 73, 11,
         37, 85, 17, 73, 56, 38, 29, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 83, 85, 37,  2, 12,  9, 37, 49, 37, 83, 50, 94, 37, 37,  9, 37, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 94, 37, 49, 37, 37, 37, 50, 32, 85, 11, 83, 11, 37, 50, 36, 77, 77,
         37, 44, 37, 50, 85, 49, 94, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [56, 85, 33, 37, 83, 38, 59, 37, 94, 85, 37, 94, 32, 37, 50, 85, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 59, 37, 38, 35, 35, 77, 56, 38, 35, 37, 85,  2, 11, 37, 85, 85,
         62, 59, 83, 37, 29, 31,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 85, 37, 85, 37, 49,  9, 37, 37, 37,  9, 11, 37, 37, 37, 94, 11, 37,
         37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([23, 22, 29, 25, 35, 42, 19, 25, 26, 26, 28, 19, 28, 18, 27, 23],
       device='cuda:0'), 'ntokens': 415}, 'target': tensor([[ 147,  728,  216,   32,   36, 3511,   15,    4,  129,  412, 1263,   37,
          239,    4,   50, 3626, 1938,   23, 4133,  319,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298, 6680,   22,   32,   52, 5940,  165,    4,   16,  189,  130,   40,
         3370, 2295, 3774, 7353,    9, 1357, 1784,   46,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2308,    4,   31,  256,    4,   31,  638,  193, 2358,   44,  147,   76,
           30,  512, 5179,   20,   42, 1104,  592,   44, 2308, 2358,   44,  327,
           82,  428,   30,   42,    2,    1,    1,    1,    1,    1],
        [ 720,   27,  406, 3055, 4634,    5, 5028, 3370,    5, 3100, 1489,  190,
           28, 1092,  372,   18,   48,   57,    6,    6,   54,    6,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  557, 2915,  221,  335,   39,  156, 4076,   15,   16,   32,  123,
          208,    4,   74, 2915,  221,  335,   60, 1400, 4248,   15,   88,   75,
          363, 2546,  398,    5,    2,    1,    1,    1,    1,    1],
        [3923,   31,  252,   30, 1606, 7558,  145,    4, 6511,   31,  470, 7902,
            4,   14,  485, 1013,  173,   61,   14, 4033,  615,   16,  189,  260,
           32,   52, 1012, 4410,   20,  441, 4362,    5,    2,    1],
        [ 104,   83,  714, 1078, 2370,  756,  699,  262, 3491,   74, 1096,  917,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,  651,  118, 2190,    4,  403,   41,   30, 1139,  177,   75,  208,
           16,   58, 7439,   29, 7041,    4,  124,  403,   41,  118, 7439,   83,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [8948,   22,   32,   61,   29,  190,   13, 2051,   42, 1414, 4790,    5,
           99,   27,  766,    4,   30,   28,  320,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 882,   77,  102,  164,   31,  334,    4,   50,   14, 9533,  646,  102,
            4,   34,   32, 8083,    4,   16,  102,    4,   34,   32, 4245,  123,
            4,  257, 2890,  161,    5,    2,    1,    1,    1,    1],
        [ 396,   76,   98,   38, 5142,  864,   18,  187,   62, 1589, 1485,   12,
         9777,  857,  564,  868, 1047,  319,   36, 1107,  820,  550,   37,  427,
          472,   22,   18,  706,    5,    2,    1,    1,    1,    1],
        [1209, 6882,   83,   43,  118, 1280,  880, 2023,   35,  899,  176,  763,
            4,   23,  892, 3114, 8764,   90,  273, 8032,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146, 5455,    4,   14,    6,    9,  151, 3852, 1133, 6838,   27, 5717,
          728,   22, 4049, 1210, 4288,    6,   96,  124,  686,  482, 4770,  303,
         3199,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 146,  326,   76, 1229,    4,  428,  361,  514,   31,    4,   50, 5160,
           15,   40, 2165,  247, 2919, 1845,   76,    4,   30,  686,  130,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  41,  123,   75, 4612, 4436, 1782,   35, 6043,  232, 4044,  232,   13,
         5295, 1172,  382,   41,   95, 1688, 2845,   15,    4,  681,   41,   47,
          208,    4,  782,   43, 8242,  459,  458, 1172,    5,    2],
        [ 104, 1770,   52, 1981,  502, 7570,   60,  102,  947,   15, 1087,    4,
           23,  947,   15, 5102,    4,   23,  947,   15,  817,  675,  527,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:0'), 'target_lengths': tensor([22, 21, 29, 24, 29, 33, 14, 26, 21, 30, 30, 23, 27, 25, 34, 25],
       device='cuda:0'), 'ntokens': 413, 'nsentences': 16}
##################### {'id': tensor([165741,  27890, 121867, 133661, 146721,  17716,  45477, 164035],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-4.8828e-04, -1.2207e-04,  3.6621e-04,  ...,  6.4087e-04,
         -6.4087e-04, -3.5095e-03],
        [ 8.9417e-03,  1.0712e-02,  1.1841e-02,  ...,  1.4496e-02,
          1.3123e-02,  1.3733e-02],
        [-5.9509e-03, -3.6011e-03,  0.0000e+00,  ...,  5.3406e-03,
         -6.1035e-05, -6.1951e-03],
        ...,
        [ 3.2043e-03,  2.7771e-03,  1.3428e-03,  ..., -6.7139e-04,
          3.0518e-04,  0.0000e+00],
        [-8.7036e-02, -1.5289e-02,  5.6091e-02,  ...,  5.5542e-03,
          8.5327e-02,  0.0000e+00],
        [ 1.3428e-03,  1.3428e-03,  1.3733e-03,  ..., -4.2725e-04,
          1.0376e-03,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([223680, 223680, 223680, 223680, 223680, 223679, 223679, 223679],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,   72,  280,  196,  286,  478,   20, 2144,  477,    4,  136,   31,
          280,   30, 1550,    4,   50,   32,   52,  585, 8028,   49, 5975,   22,
         1391,   15,    4,  139,   52,  353, 1702,    6, 8207,   16, 4236, 3407,
            6, 5013,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3100,   82,   43,   56, 4916,  158,    5,  327,  855,    4,   50,
          911, 1050, 3519,  262, 4163,   83, 2081,    4,  757,   28,   51, 5999,
           88,   14,  302, 4731,  767,  978,   28, 6590,   16, 1071,  216,   78,
         8080, 8068,   15,   16,   58, 5528,    6,   15,  345,   16,   58, 5281,
           37,   16, 2542,   58, 2559,   57,  311,  706,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   14,  645,  695,   61,   44, 3331,    4,  136,   74,  275,
         6590, 2915, 1265,  241, 2142,    4, 3492,  122,  241, 2142,    4, 1926,
          380,   18,  160,  634,   16,  789,   23, 3450,    6,  233,  589,  481,
         1612, 1499,    6, 4216,  791,  412, 7478,    6,  779,   78,  337, 2570,
           15, 8774,   28,   23,   15, 2309,   39,   58, 1612, 1499,    6, 4216,
         7245,  484,    4,   23,   58, 4754, 4520,   42,    1],
        [   2,  404, 3208,   30, 6994,    6,  242,  122,   59, 1869,  165,   16,
           36, 6750,  410,  331,   45,    4,   50,   81, 6857, 8298,   22,   16,
          867,   59, 5319,   15,  364, 5156, 2529,   16,   52, 4521,   37, 2479,
         5612,   16,  331,  182,  533,  340,  418, 4590,   20, 3033,   15,   39,
          726, 2022,   18,    4,   88,   14, 4521, 9214, 1295,   28, 6275,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,   95, 1154, 1480,   61,   23,  228,  191,    6,  673, 5038,
           16,   14, 3309,  319, 7900,    4,   50,   14,  707,  754,   40, 2064,
         2813,   82,    4,  255,   31,   28,   23,  259,  433,   40, 2755,  905,
          770, 1030,  685, 2550, 1856,  666,   16,   31,  915,   44,   38,  710,
          287,  158,    4,   31, 4337, 1939,  364,  707,  111,  362,  407,  262,
         2236,   68,  379,   65,   72,  280,  286, 4798,    5],
        [   2,   64,  361,  795,   43,  163,  892, 2955,  187,  445,  128,  127,
           16,  334,    4,   50,  314, 3789,  343,   34, 3154, 2065,    4,   14,
           32,   61,  328, 5546, 1773,    4, 9015,  343,  114,   81,   40,  314,
         8981,    4,   50,  344, 7040,  373,    4,  344, 1938,    6,    4,  141,
         1145,    4,  105,  157,  123,  231, 8114,  190,  364, 2309,  210, 3960,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  449,  299,  173,  139,   40, 1538,   61, 2049,    5,  400,
         5421,   43,   42,   72, 6189,   43,   61,   52,   51, 1689,  784, 6971,
            4,   16, 2012,   58,   38, 8009, 1769, 7533,   22, 5074,   37, 1190,
           59,   22, 1243,  857, 2139,   42,   99,  394, 1633,    5, 1555, 7452,
           32,   36,  253, 4364,   15,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  228,   23, 3068,  239,   14, 2218, 9395,  271, 1517, 2140,    4,
           88, 2979,  871, 5303,   74, 7667,    4, 1725, 9592,   22,    4, 3653,
            4, 1458,   15,   15,   16, 4852, 5135,    4,  823, 2717,    9, 1676,
         2504, 8922,  522,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[  21,   11,    6,   86,   79,  103,   19,  144,  419,  479,   70,   21,
          169,  274,  100,    4,   67,   84,   34,   13,  841,   17,   24,  169,
           66,   10,   87,  250,   71,  264, 9520,   12, 5149,    8,  250, 1057,
           10,   87,   71, 1588,  468,    8,  250, 1057,   10,   87,   71, 1136,
         1370,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  21,   11,    6,  116,  226, 4174,    4,  166,  818,  251,  148,  162,
         7220,  144,   10,   66,   13,  207,   12, 8254,  839,   10, 1703,  251,
          248,    8,   13,  854,  759, 1086,    4,    8, 1065,    4,  143,   55,
            7, 6580, 8068,    4,    8,    7, 3742, 7856,  249,    4,    8,    7,
         4528,    4,    8, 3097,    7, 2248,  181, 3414,   20,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [  67,    7,  630,   13, 2003,   96,   44, 1189,    4,   29,  138,  261,
           87,   56,  234, 1265,  241, 2142,    4, 2994,  122,  241, 2142,    4,
           13,   59,  380,   18, 3110,    8, 3098,    7, 1503,   12,  886,  412,
         3276,  287,    9, 4928, 1703,   55,   17, 7752,    9, 2446,   10,   17,
         2340,   10,    7, 1503,   12, 7121,  484,    4,  166, 2231,    6,   17,
         3833, 1548,   42,    2,    1,    1],
        [  21,   11,    6,  434, 3919, 8570,    4,    8,   21, 6430,    6,    4,
         2584,  218,  214,    4, 7753, 2736,  296, 1212,    8,  227,   93, 1069,
           96,    4, 2797,   54, 1868,  187, 3635, 1319, 3562, 7289,    8,  218,
         2808,   35, 5444, 2840,    6,   10, 3814, 3001, 3188, 1068,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19,  258,  636,  132,    9, 5950,   20, 1006,    4,    8,    7, 3564,
          162,  172, 3633,   17,    7, 5317,  144,  226,   13, 2786,    4,  125,
           85,   17, 2110,    4,   19,  144,   13,  277,  523,   12, 2080,    9,
           91,   12,   89,  488,   10,   96,    4,    8,   19,  474,    4,   38,
          122,   57,  411,    4,  125,   19,   11,   45,  142,   10,    7, 8022,
            6, 2236,   68,  194,   65,    2],
        [   8,  115,  339,  110,  873,  908, 2955,  187,  445,  128,    4,    8,
          289,   17, 4586,  931,   46,  166,  185,   12,    7, 4793,   24,  175,
          568,   69,   33, 4959,   46,  120,   25, 2554,    7,  282,   12, 2307,
            4,   13, 2980,   37,    4,   13, 3700,    4,   13, 1276,    4,   53,
           63,  521, 1015, 3127,   54, 7553,  111,  199,    7, 2340,    5,    2,
            1,    1,    1,    1,    1,    1],
        [  19,  113,  213,   10, 2678,   33,   91,  132,   13,  523,    5,  138,
           73,   53, 4477,   42,   19,   11,   45,  142,   10,  388,  134,   69,
           13,  824,  586,  457, 5445,    4,  166,   26,    7,   38,  122,  241,
         1515,   10, 4853, 1435,   85, 8251, 1243,  137, 1189,   42,   29,  168,
           21,   26,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1220,    9, 3023,    4, 2058,  181,  541, 1775,  271, 4814,    6,   66,
          226,  619,   10, 1754, 7371,  955, 2028,    4,  100, 4896,    6,    4,
         2678,  777,  812,    6,    4, 3183,    4, 2011, 6504,    6,    8, 4222,
            4,   17,   66,  226, 3150,  111, 7225,   62,  199, 2116,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:5'), 'cluster_tokens': tensor([[37, 85, 37, 83, 37, 37, 38, 85, 50, 94, 50, 37, 85, 59, 37, 11, 37, 37,
         85, 37, 32, 37, 38, 85, 85, 37, 85, 50, 37,  2, 56, 37, 56, 37, 50, 49,
         37, 85, 37, 32, 29, 37, 50, 49, 37, 85, 37, 28, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 85, 28, 11, 37, 88, 50, 50, 85, 49, 85, 37, 85, 37, 83,
         37, 49, 32, 37, 49, 50, 34, 37, 37, 53, 24, 32, 11, 37, 24, 11, 50, 37,
         37, 38, 35, 11, 37, 37, 12, 12, 77, 11, 37, 37, 12, 11, 37, 83, 37, 83,
         35, 35, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 37, 35, 77, 82, 83, 11, 83, 37, 83, 85, 38, 35, 35, 35, 35,
         11, 38, 35, 35, 35, 11, 37, 35, 77, 35, 28, 37, 83, 37, 13, 37, 38, 35,
          2, 35, 37, 28, 49, 37, 37,  2, 37, 35, 37, 37, 94, 37, 37, 13, 37, 28,
         35, 11, 37, 49, 37, 37, 29, 35, 11, 83, 37, 37],
        [37, 85, 37, 31, 38, 29, 11, 37, 37, 49, 37, 11, 36, 50, 56, 11, 49, 29,
         49, 77, 37, 38, 35, 49, 77, 11, 88, 49, 38, 35, 35, 38, 94, 94, 37, 50,
         32, 38, 28, 94, 37, 37,  5, 28, 36, 35, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 38, 77, 37, 37,  2, 77, 94, 11, 37, 37, 56, 85, 83,  2, 37, 37, 49,
         85, 85, 37, 32, 11, 37, 37, 37, 23, 11, 38, 85, 37, 50, 83, 37, 94, 37,
         50, 37, 37,  2, 37, 77, 11, 37, 38, 31, 11, 38, 35, 77, 35, 11, 37, 38,
         85, 35, 49, 37, 37, 28, 37, 11, 38,  9, 11, 83],
        [37, 83, 49, 37, 85, 50, 31, 35, 35, 35, 11, 37, 88, 37, 49, 37, 11, 37,
         50, 37, 37, 94, 38, 85, 85, 37, 37,  9, 11, 37, 37, 49, 37, 32, 37, 50,
         11, 37, 23, 77, 11, 37,  9, 11, 37, 94, 11, 37, 85, 38, 35, 35, 49,  2,
         83, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37],
        [38, 83, 88, 37,  9, 37, 50, 37, 37, 83, 11, 37,  6, 37, 16, 11, 38, 85,
         35, 49, 37, 31, 37, 37, 37, 38, 35,  2, 94, 11, 37, 85, 37, 38, 35, 35,
         92, 37, 29, 59, 37, 28, 35, 11, 83, 11, 83, 37, 37, 85, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 94, 11, 28, 35, 35, 35, 44, 94, 37, 85, 85, 31, 37, 49,  2,  9,
         56, 11, 37,  9, 37, 11,  9, 67, 35, 37, 11, 94, 11,  9, 22, 37, 37,  9,
         11, 37, 85, 85,  2, 83, 29, 31, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([51, 59, 64, 48, 66, 60, 52, 48], device='cuda:5'), 'ntokens': 448}, 'target': tensor([[  72,  280,  196,  286,  478,   20, 2144,  477,    4,  136,   31,  280,
           30, 1550,    4,   50,   32,   52,  585, 8028,   49, 5975,   22, 1391,
           15,    4,  139,   52,  353, 1702,    6, 8207,   16, 4236, 3407,    6,
         5013,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3100,   82,   43,   56, 4916,  158,    5,  327,  855,    4,   50,  911,
         1050, 3519,  262, 4163,   83, 2081,    4,  757,   28,   51, 5999,   88,
           14,  302, 4731,  767,  978,   28, 6590,   16, 1071,  216,   78, 8080,
         8068,   15,   16,   58, 5528,    6,   15,  345,   16,   58, 5281,   37,
           16, 2542,   58, 2559,   57,  311,  706,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   14,  645,  695,   61,   44, 3331,    4,  136,   74,  275, 6590,
         2915, 1265,  241, 2142,    4, 3492,  122,  241, 2142,    4, 1926,  380,
           18,  160,  634,   16,  789,   23, 3450,    6,  233,  589,  481, 1612,
         1499,    6, 4216,  791,  412, 7478,    6,  779,   78,  337, 2570,   15,
         8774,   28,   23,   15, 2309,   39,   58, 1612, 1499,    6, 4216, 7245,
          484,    4,   23,   58, 4754, 4520,   42,    2,    1],
        [ 404, 3208,   30, 6994,    6,  242,  122,   59, 1869,  165,   16,   36,
         6750,  410,  331,   45,    4,   50,   81, 6857, 8298,   22,   16,  867,
           59, 5319,   15,  364, 5156, 2529,   16,   52, 4521,   37, 2479, 5612,
           16,  331,  182,  533,  340,  418, 4590,   20, 3033,   15,   39,  726,
         2022,   18,    4,   88,   14, 4521, 9214, 1295,   28, 6275,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,   95, 1154, 1480,   61,   23,  228,  191,    6,  673, 5038,   16,
           14, 3309,  319, 7900,    4,   50,   14,  707,  754,   40, 2064, 2813,
           82,    4,  255,   31,   28,   23,  259,  433,   40, 2755,  905,  770,
         1030,  685, 2550, 1856,  666,   16,   31,  915,   44,   38,  710,  287,
          158,    4,   31, 4337, 1939,  364,  707,  111,  362,  407,  262, 2236,
           68,  379,   65,   72,  280,  286, 4798,    5,    2],
        [  64,  361,  795,   43,  163,  892, 2955,  187,  445,  128,  127,   16,
          334,    4,   50,  314, 3789,  343,   34, 3154, 2065,    4,   14,   32,
           61,  328, 5546, 1773,    4, 9015,  343,  114,   81,   40,  314, 8981,
            4,   50,  344, 7040,  373,    4,  344, 1938,    6,    4,  141, 1145,
            4,  105,  157,  123,  231, 8114,  190,  364, 2309,  210, 3960,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  449,  299,  173,  139,   40, 1538,   61, 2049,    5,  400, 5421,
           43,   42,   72, 6189,   43,   61,   52,   51, 1689,  784, 6971,    4,
           16, 2012,   58,   38, 8009, 1769, 7533,   22, 5074,   37, 1190,   59,
           22, 1243,  857, 2139,   42,   99,  394, 1633,    5, 1555, 7452,   32,
           36,  253, 4364,   15,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 228,   23, 3068,  239,   14, 2218, 9395,  271, 1517, 2140,    4,   88,
         2979,  871, 5303,   74, 7667,    4, 1725, 9592,   22,    4, 3653,    4,
         1458,   15,   15,   16, 4852, 5135,    4,  823, 2717,    9, 1676, 2504,
         8922,  522,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'target_lengths': tensor([39, 57, 68, 60, 69, 61, 54, 40], device='cuda:5'), 'ntokens': 448, 'nsentences': 8}
##################### {'id': tensor([178269, 148524, 125623, 101117,  78924, 224540, 167252,  92437, 118957,
         39713, 220316, 147860, 214205, 154970,  80374, 177508, 137058, 127555,
        128814, 202766, 211823,  12233,  49848, 149643], device='cuda:7'), 'net_input': {'src_tokens': tensor([[-1.6724e-02, -2.0294e-02, -2.4750e-02,  ..., -2.7405e-02,
         -3.2104e-02, -2.8198e-02],
        [ 1.1597e-03,  8.8501e-04,  9.1553e-04,  ...,  6.3477e-03,
          6.3782e-03,  6.5308e-03],
        [ 7.4158e-03,  3.8147e-03,  1.7395e-03,  ...,  3.6621e-04,
          1.2512e-03,  2.1362e-03],
        ...,
        [-1.7090e-03, -6.7139e-04, -6.1035e-05,  ...,  1.2512e-03,
          1.2207e-03,  1.0071e-03],
        [-3.0518e-05, -3.6621e-04, -1.2207e-03,  ..., -4.2725e-03,
         -4.8523e-03,  0.0000e+00],
        [-1.5259e-04, -1.2207e-04, -3.0518e-05,  ..., -1.1597e-03,
         -9.4604e-04,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720,
        86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720, 86720,
        86720, 86720, 86719, 86719], device='cuda:7'), 'prev_output_tokens': tensor([[   2,   14,   49,   58, 4617,  292,  610, 1015, 1527, 7881,   15,  212,
          259,  317, 1279,  130,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   31,  354,   23,   15,  550, 1700,  223,  337,  953, 8133,
           22, 6156,   95,  122,  152,   22,  610,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,   82,  317,   47, 1798,    4,   31, 1398,   61, 1500,    5,
           38, 2473,   43,  329, 2642,   72, 2794,  105, 3177,   16, 2752,  112,
         3175,  163,  299, 4153, 1550, 3289,   37, 7790,    5],
        [   2, 2316, 2689, 3608, 1212, 8946,  382,  482,  216,   16,  216, 2204,
          510,  153, 4408,    4,   88, 7056, 9683,    9, 9108,   28, 5790,   14,
         5161, 2025, 3821,    5,    1,    1,    1,    1,    1],
        [   2,   56, 6624,  174,  418, 2710,  604,   32,  210, 2370,   15,   39,
         3655,   20,  326,    4,   14,   32,   78,  118, 8029,   22, 5857, 5214,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2609, 1669,   75,  273, 5938,   47,  149,   97, 4364,   23,  259,
            4,   43, 1669,   75,  139,   49, 1093,   28, 1093,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41,   83, 1659,   35, 9318,   20,   16, 5219,   20,  253, 4521,
         4103, 1349,    4,   14,  602, 5325,  293, 2447,   45,   37,  622, 2189,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298,  114,   23,  590, 2479,   28, 5595,   15, 2713,    4,  145,
           14, 1024,   30,  496, 8534,   16,   61,   30,  496,   40,  983,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  911,  412, 5389,  308,  130,   52,  353, 6921,    9,   75,    4,
           14,   43,    4,  114,   43, 2920,  398,  161,    4, 1354,  879,  174,
           59,  272, 2344,    4, 6939, 8105,    5,    1,    1],
        [   2,  298,   27,  330,  156,  119, 2614, 6939,   40, 1961,    9,   52,
          331, 3788,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   23, 1483, 1231, 1577, 1670,   15, 3476,  352, 5328,
           15, 2589,    4, 7695,   40, 3581,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   43, 4034,  198,   49,  669, 1550,   15,    4,   14,   43,
           90, 5685, 3723,   39,  478,  212, 3670, 1290,  530,  569,   15,  280,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  209, 1489,   61, 5947, 1399,  364, 1923,  184,    6, 1338,
            5,   72, 1204,  302,  349,  533,  307,    6, 1846, 2796, 1929,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99, 5103,    4,   90,  403,   32,   47,  216,   90, 3004,   16,
         1940,  186,  792,    4,  136,   74, 4775,   18,   81,   30,   52,   98,
          102,  351,  653,   42,    1,    1,    1,    1,    1],
        [   2,  298,   27,   30,  350, 5265,   22,   49, 2939,   16, 6023,   15,
         2164, 5157,    4,   88, 2114, 2495,   28,  574, 5416,   22,   16,   28,
         2299,  902,  729,    5,    1,    1,    1,    1,    1],
        [   2,  202,   27,  113, 4179,   52, 6140, 6518,    4,   29, 1023,   36,
         3048,   18, 3304, 2531,    4,   90,  139,   52, 3827,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1356, 8280,   27,   14, 2999,  149,   40, 1600,    6, 7057, 2935,
            4,   30,  897, 5719,    4, 4827, 1785,   18,   28,  127,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99, 9158,   20,  190,    4,   30,   31,  433, 1238,   97, 1550,
          280,    4,   16, 2012,    4,   50,   30, 2300,  190,  210, 4385,   22,
          449,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146,  259, 4261,   20,   27,   28, 1489,    4,   90,   50,   75,
          231,  107, 1731,   15, 3731, 8348,   15, 6469,   83,  792,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1815,  130, 1517,   40, 1070,   96, 2815,   96, 1133,   78,  330,
         2921,    6, 4103,  177, 2298,    4,   30, 1642,    6,  497,    9, 2552,
           56, 3544,    5,    1,    1,    1,    1,    1,    1],
        [   2,   99,  178,  423, 6856, 4361,    4,   14, 5478,    9,  805, 4667,
           16, 5096,   76,   16,   14,   14,  310, 1669,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  313,  198,  863,  831,    4,   50,   32,  337, 1389, 1238,
          171, 2323,   18,   83,   39,  102, 6654,  654,  507,   45,  539, 7327,
         5754,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,  312,  898, 2284, 3281,    6, 4471,    6,  344, 1140,   93,    6,
          221,   35, 7094, 5061,  292,    6,    6, 3650,   60,  328,  791,  380,
          160, 1054,   18,    5,    1,    1,    1,    1,    1],
        [   2, 1814,    6,   27,   23,   56,  111,    6, 3620,   20,  685,   93,
         1934,  335,    4,   23,   14,  507, 2919,  709, 2896,  879,  729,   40,
         2491,    5,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7')}, 'transcript': {'tokens': tensor([[ 131, 1183,  148,   26, 1948,  664,   62,  132,   71,    7, 4617,  292,
         2109, 1775, 4040,    6,   12,   33, 6536,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   19,   11,   48,  100,   10,  227, 2174,  232,  445,  159,  283,
           71,   13,  277, 7074, 4112,    4,    8,    7, 4112,   26,   33,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19, 1425,   19,  144,   10, 1336,  235,    5,   19,  442,   17, 3486,
            8,   79, 2392,   79,   19,  442,   21,    4,   39, 2285, 1790,   12,
         2922,  552,  244,  110,    5,    2,    1,    1,    1,    1],
        [ 877,  290, 2689, 2345, 1212,  188, 2277,   48,   10, 2699,  143,    8,
          143, 5593,   10,   33,    4, 5413, 3301, 5690,    6,  199,  459,  510,
           96,   17,  719, 2070,    5,    2,    1,    1,    1,    1],
        [  29,   24, 6103,  154,   12, 4781,   79,  378, 3816,  214,   17,   24,
          991,   55,  133, 3926, 3965,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  12,  538,    4,  108, 4734,  192,   11,   18,  116,  468, 1004,  183,
            4,   53,  113,  468,  106,  561,   10,  561,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  53,   66, 4595, 1122,   59,  699,   35,    6,  819,  424, 1942,   96,
            8, 4515,    6,   17,   63,   86, 3412,   62,  131,  883,   48,  293,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  103, 2263,   96,  498,   10, 3424,    4,  180,    7,  723,   73,
         5415,    7,  524,    8, 3536,    7, 2517,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 427,  412,  430,  158,   13,  188,   13, 1905,  321,   12, 6873, 1117,
           17,    4,  120, 8491,   48,    4,    7,  427,  412,  430,  158, 3336,
           10, 1051, 1672,  153,  336,    4,  116, 7743,    5,    2],
        [  29,  417,  140, 2362,    6,   93,   26, 3423,   13, 1396, 2233,  199,
           39, 3993, 1874,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  33,  188,  226,    7, 3841,    6,   20,   12,  333, 1670, 2127, 9746,
            6,    4, 3448, 7414,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  225, 4576,    6,   10,  110,    7, 1790,  225, 1831,   79,   13,
          785,   35, 1933,   35, 1178, 3642,    9,   17, 6460, 4057,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  116,  323,   13, 4454, 2761,   69, 5335,   80,    7, 5169,    8,
         1095,  248, 8099,    6,  558,   10,  545,  218,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21, 4639,   17,   24,  220,   51, 1155,  143,  254, 3857,    8, 1064,
            4,   67,  138,   10, 3918,    6,   20,  126,    7,   91,  106,    7,
          218,   42,    2,    1,    1,    1,    1,    1,    1,    1],
        [  29,    7, 2551,   12,  324,    8, 6790,  214,   26, 2720,   48,   10,
         7572,    8,  211,  234, 1410,  837, 5002,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  101,   11,    6,   13, 4961, 1531,    4,   79, 3708,   18, 3304,
          169,   66,  246,    4,   79,  238,   79,   13, 1880, 1531,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   10, 4637,  373,    4, 2192,   26,  116,  486, 6101,  567, 4111,
           10,   51, 4637,   62,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21, 8900,   62,  250,   19,  172,  144,   13, 2184,   22,  311,   69,
            4,   26,   17,    7, 1956,  204,  213,    6,   10,  283,   55,  159,
          110,  128,    5,    2,    1,    1,    1,    1,    1,    1],
        [   8,   17,   11,    6,  593, 1706,   12,   13,  183, 2760,   55,   77,
            7,  341, 1565,  409, 1215,   17,   24,  135,   10,  468,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1777,  188, 1220, 6380,   48,   17, 2439,  558,  464,    4,   53,   11,
           57, 5332,   54,   13, 4369,  200, 1515, 2902,    8, 3585,  567,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  84,   63,  423,   12,  117, 3357,    4,    8,   53,   63, 4673,    9,
          159, 4268,    8,  159, 4972,    4,    8,   53,   63, 2762,   94,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   11,   45,  976, 8372,   17,   24,   66,  535, 1313, 5260,    7,
          613,  206, 4387,    6, 3480,  108,   24, 1591, 2637,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  13,  717,   35, 1315,  322,  801, 5725,    6,  221, 1339, 5061,  292,
            6,    6, 3222, 1026,   14,   48,   71,   33,    9,   21,    6, 9442,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  69,    7,  939, 2836,  834,   26,    7,   56,  111,    6, 3620,  266,
          207,   17,  368,    6, 2829, 7337, 7393,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'cluster_tokens': tensor([[37, 50, 50, 85, 83, 38, 31, 37, 37, 37, 38, 35, 35, 35, 28, 37, 37, 37,
         24, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 31, 37, 37, 38, 35, 77, 35, 37, 49, 37, 37, 50, 28, 32, 11,
         37, 37, 32, 85, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 38, 85, 37, 38, 35, 11, 38, 31, 37, 94, 37, 37, 83, 37, 38, 31,
         37, 11, 38,  2, 32, 37,  9, 85, 37, 37, 11, 83, 37, 37, 37, 37],
        [38, 35, 35, 38, 77, 85, 49, 31, 37, 49, 50, 37, 50, 56, 37, 37, 11, 40,
         29,  9, 37, 37, 38, 35, 77, 37, 49, 32, 11, 83, 37, 37, 37, 37],
        [83, 38, 83, 59, 37, 56, 37, 49,  2, 56, 37, 38, 49, 37, 83,  2, 32, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 56, 85, 85, 35, 83, 29, 37, 24, 11, 37, 83, 29, 37,  9,
         37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 31, 38, 35, 35, 38, 37, 35, 35, 96, 77, 37, 22, 37, 37, 85, 83,
         29, 31, 37, 38, 31, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 38, 77, 49, 37, 29, 11, 37, 37, 94,  6, 36, 37, 32, 37, 16, 37,
         32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 35, 35, 37, 85, 37, 50, 38, 37, 94, 37, 37, 11, 37, 49, 31, 11,
         37, 38, 35, 35, 35, 85, 37, 38, 35, 77, 37, 11, 83, 49, 11, 83],
        [83, 38, 35, 35, 37, 35, 85, 83, 37, 32, 49, 37, 38, 94, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 85, 37, 29, 37, 77, 37, 50, 28,  9, 16, 37, 11, 83, 28, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 88, 37, 37, 37, 37, 32, 37, 31, 37, 37, 34, 38, 24, 38, 35, 49,
         37, 37, 83,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 83, 85, 37, 83, 59, 37, 28, 37, 37, 94, 37, 59, 34,  9, 37, 37, 37,
         50, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 31, 37, 38,  6, 38, 50, 50, 37, 47, 37, 32, 11, 37, 37, 37,  9, 37,
         77, 37, 37, 50, 37, 37, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 29, 37,  2, 37,  2, 56, 85, 49, 31, 37, 49, 37, 50, 35, 35, 28,
         56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 85, 37, 37, 28, 94, 11, 37, 94, 35, 35, 85, 85, 88, 11, 37, 83,
         37, 37, 28, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37,  9, 56, 11, 94, 85, 83, 50, 49, 32, 49, 37, 38,  9, 31, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 88, 31, 50, 38, 83, 85, 37, 38, 35, 35, 37, 11, 85, 37, 37, 32, 83,
         88, 37, 37, 49, 37, 37, 37, 35, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 83,  2, 37, 37, 24, 23, 37, 50, 37, 33, 32, 32, 56, 37,
         38, 59, 37, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [28, 85, 83, 88, 31, 37, 49, 37, 24, 11, 37, 85, 77, 49, 49, 37, 94, 35,
         92, 38, 37,  9, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 34, 37, 37, 56, 11, 37, 37, 85,  2, 37, 37, 94, 37, 37, 94, 11,
         37, 37, 85, 29, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 83,  2, 37, 38, 85, 83, 37, 31, 37, 32, 37, 94, 37, 29, 37,
         38, 35, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 34, 38, 35, 35,  2, 49, 37, 35, 38, 35, 35, 37, 37, 38, 35, 38, 31,
         37, 37, 37, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 35, 11, 85, 37, 38, 83, 37, 77, 35, 83, 37, 49, 37, 32,  9,
         56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:7'), 'lengths': tensor([20, 25, 30, 30, 20, 22, 26, 21, 34, 17, 18, 24, 22, 27, 21, 24, 18, 28,
        24, 25, 25, 23, 26, 21], device='cuda:7'), 'ntokens': 571}, 'target': tensor([[  14,   49,   58, 4617,  292,  610, 1015, 1527, 7881,   15,  212,  259,
          317, 1279,  130,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   31,  354,   23,   15,  550, 1700,  223,  337,  953, 8133,   22,
         6156,   95,  122,  152,   22,  610,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,   82,  317,   47, 1798,    4,   31, 1398,   61, 1500,    5,   38,
         2473,   43,  329, 2642,   72, 2794,  105, 3177,   16, 2752,  112, 3175,
          163,  299, 4153, 1550, 3289,   37, 7790,    5,    2],
        [2316, 2689, 3608, 1212, 8946,  382,  482,  216,   16,  216, 2204,  510,
          153, 4408,    4,   88, 7056, 9683,    9, 9108,   28, 5790,   14, 5161,
         2025, 3821,    5,    2,    1,    1,    1,    1,    1],
        [  56, 6624,  174,  418, 2710,  604,   32,  210, 2370,   15,   39, 3655,
           20,  326,    4,   14,   32,   78,  118, 8029,   22, 5857, 5214,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [2609, 1669,   75,  273, 5938,   47,  149,   97, 4364,   23,  259,    4,
           43, 1669,   75,  139,   49, 1093,   28, 1093,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  41,   83, 1659,   35, 9318,   20,   16, 5219,   20,  253, 4521, 4103,
         1349,    4,   14,  602, 5325,  293, 2447,   45,   37,  622, 2189,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298,  114,   23,  590, 2479,   28, 5595,   15, 2713,    4,  145,   14,
         1024,   30,  496, 8534,   16,   61,   30,  496,   40,  983,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 911,  412, 5389,  308,  130,   52,  353, 6921,    9,   75,    4,   14,
           43,    4,  114,   43, 2920,  398,  161,    4, 1354,  879,  174,   59,
          272, 2344,    4, 6939, 8105,    5,    2,    1,    1],
        [ 298,   27,  330,  156,  119, 2614, 6939,   40, 1961,    9,   52,  331,
         3788,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92,   27,   23, 1483, 1231, 1577, 1670,   15, 3476,  352, 5328,   15,
         2589,    4, 7695,   40, 3581,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   43, 4034,  198,   49,  669, 1550,   15,    4,   14,   43,   90,
         5685, 3723,   39,  478,  212, 3670, 1290,  530,  569,   15,  280,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  209, 1489,   61, 5947, 1399,  364, 1923,  184,    6, 1338,    5,
           72, 1204,  302,  349,  533,  307,    6, 1846, 2796, 1929,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99, 5103,    4,   90,  403,   32,   47,  216,   90, 3004,   16, 1940,
          186,  792,    4,  136,   74, 4775,   18,   81,   30,   52,   98,  102,
          351,  653,   42,    2,    1,    1,    1,    1,    1],
        [ 298,   27,   30,  350, 5265,   22,   49, 2939,   16, 6023,   15, 2164,
         5157,    4,   88, 2114, 2495,   28,  574, 5416,   22,   16,   28, 2299,
          902,  729,    5,    2,    1,    1,    1,    1,    1],
        [ 202,   27,  113, 4179,   52, 6140, 6518,    4,   29, 1023,   36, 3048,
           18, 3304, 2531,    4,   90,  139,   52, 3827,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1356, 8280,   27,   14, 2999,  149,   40, 1600,    6, 7057, 2935,    4,
           30,  897, 5719,    4, 4827, 1785,   18,   28,  127,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99, 9158,   20,  190,    4,   30,   31,  433, 1238,   97, 1550,  280,
            4,   16, 2012,    4,   50,   30, 2300,  190,  210, 4385,   22,  449,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 146,  259, 4261,   20,   27,   28, 1489,    4,   90,   50,   75,  231,
          107, 1731,   15, 3731, 8348,   15, 6469,   83,  792,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1815,  130, 1517,   40, 1070,   96, 2815,   96, 1133,   78,  330, 2921,
            6, 4103,  177, 2298,    4,   30, 1642,    6,  497,    9, 2552,   56,
         3544,    5,    2,    1,    1,    1,    1,    1,    1],
        [  99,  178,  423, 6856, 4361,    4,   14, 5478,    9,  805, 4667,   16,
         5096,   76,   16,   14,   14,  310, 1669,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  313,  198,  863,  831,    4,   50,   32,  337, 1389, 1238,  171,
         2323,   18,   83,   39,  102, 6654,  654,  507,   45,  539, 7327, 5754,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 312,  898, 2284, 3281,    6, 4471,    6,  344, 1140,   93,    6,  221,
           35, 7094, 5061,  292,    6,    6, 3650,   60,  328,  791,  380,  160,
         1054,   18,    5,    2,    1,    1,    1,    1,    1],
        [1814,    6,   27,   23,   56,  111,    6, 3620,   20,  685,   93, 1934,
          335,    4,   23,   14,  507, 2919,  709, 2896,  879,  729,   40, 2491,
            5,    2,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'target_lengths': tensor([17, 20, 33, 28, 25, 22, 25, 24, 31, 15, 19, 25, 24, 28, 28, 22, 23, 26,
        23, 27, 21, 26, 28, 26], device='cuda:7'), 'ntokens': 586, 'nsentences': 24}
##################### {'id': tensor([128627, 224109, 201335,  91689, 128636, 160842, 183877,  69746, 115915,
         22655,  90605, 105910, 156358, 217801, 223990,  75664],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 8.5449e-04,  9.4604e-04,  7.6294e-04,  ...,  1.0071e-03,
          5.7983e-04, -3.3569e-04],
        [ 4.5776e-04, -1.8311e-04,  9.1553e-05,  ...,  2.0142e-03,
          1.4648e-03,  1.0986e-03],
        [ 1.7700e-03,  3.8452e-03,  4.1504e-03,  ..., -1.0315e-02,
         -8.9417e-03, -8.6365e-03],
        ...,
        [ 9.1553e-05,  1.2207e-04,  3.3569e-04,  ..., -3.0518e-05,
          8.8501e-04,  0.0000e+00],
        [ 6.1035e-05, -5.4932e-04, -6.4087e-04,  ..., -1.0986e-03,
         -8.2397e-04,  0.0000e+00],
        [ 1.3025e-01,  1.0278e-01,  1.5393e-01,  ..., -1.4130e-02,
         -1.5503e-02,  0.0000e+00]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([149120, 149120, 149120, 149120, 149120, 149120, 149120, 149120, 149120,
        149120, 149120, 149120, 149119, 149119, 149119, 149119],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2,  222,   41, 1112,    4,   41,  320,   36,    4,  110,  237,  303,
           41,   75,    5,   99,   76, 1230,    5, 4109,  161,  647,   49,   58,
         8364, 2725,    4,   14,  351, 1362,  181, 6238,  107,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  396, 7544,   82,   29, 1836,   74,   40, 1464,   16, 5630,   78,
         3579,    4, 7412,   16, 1014,    5, 1272,  164,   43, 2588, 1126,   16,
           39,   23,  489, 2581, 1685,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 7607,   90,   14,  731, 6135, 2887,   27,   95, 3341,    4,   51,
         1265,   18, 1699, 6332,   15,  177,   16, 7322, 2928, 1209,  160,  794,
          152,  234,   15,   16, 7972,   20,    4,  761,  707,  458, 1488,   35,
          868,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  657,  734, 2835,   36, 5469,   20,    4,   14,   32,   90, 7056,
           51, 3641,  681,    4,  742,    5,  592,    5, 9434,    6, 3449,  241,
          124, 5172,  541, 3215,    4,   16,  145,   43,    9,   40, 4458,   18,
          160, 3484,    6, 2098,  111,   45,   37,   88, 1304, 1194,    4,   30,
           81,    9,  743, 1342, 1299,  990,  145,    5],
        [   2,   64,   14, 1270,   56, 6836,   15,    9,  761,  423,  767, 3204,
           57,  237,  427,  623,    4,   30,   76,  682,    5, 1450,  950,  129,
         3664,   15, 1928,   15, 4072, 3886,    6,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   27, 1163,   22,  140,  416,   22, 1297,  556, 1949,    5,
           41, 1364,  815,    4,  852, 1709,   60,  102, 1139,   56,  315,    6,
         1867,   49, 3779, 7189,    9,   58, 2865,   15,   23,   41,   59,  371,
         1872,  827, 1151,   61, 1433, 3697, 4630,   22, 2404,   22,    5,   72,
         5310,  517, 1091, 1142,  332,   61,    5,    1],
        [   2,  104, 1602,  600, 2040, 7404,   15,    5, 1952,   41,   75,   30,
          177,    5, 1647,   36, 5792,  286, 3340, 1707,  181,   37, 1869,   60,
         9346, 6947,   22,    4,  114,   36,  139,   52, 5432,  330,   35, 4830,
          269,  354,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  520, 1544,   22,  335,  894,   41,  196, 2533,   20, 2001,  611,
            5,   68,  348,   65,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  327,   31,  252,  647, 2757,  209,    4,   76, 3660,   49,  485,
          317,   15,   16, 2029,   15, 6376,    4,   74, 6024,   15,    4, 2945,
            6,   37,  122,  152,   22,  195,  165,    6, 2016,  176,  152, 1217,
          562,   16, 1191,  620,  233,  156,  569,  662,   14, 6458,   78,  295,
         1129, 5857,   20,  171, 8777,  123,    5,    1],
        [   2,  104,  208, 6197,   16, 6197,    9,   58, 7536,   23, 6310,    4,
           16,   29,  615,   32, 1746, 3178,   16, 3178,   39,  299, 2570,   20,
         3656,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  331, 2350,    6, 5497,   22,    4,   74,   41,  302,  181,
          356,  849,  320,    4,   76, 5451,  112, 1399,   98,  330,   35, 4830,
           35, 2809,  249, 5646,   15,    4, 5665, 5801,   15,    4, 3125, 2495,
           15, 1817,   16,   29,  463,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   32,  231,  260,   30,   40,  905, 1229,   16, 6655,  123,
           32,  231,    9,   58, 2014, 2052,  803, 3319, 1989,   16,   14,    6,
          208,   16,  139,   30,   16,  139,  299,  173,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41, 3490,    9,   23, 2275,   96,  444, 4945, 6887,   90, 1196,
          156,   57,   18,  683,  160,   97, 1162, 2407,  411,    6,  174,  219,
          292,    4, 2782, 1204,   43,  231,  435,    4,   14,   98, 3950,   45,
          734,   98,  102, 7117, 2707, 5132,   15,  522,   16,  897, 5719,   15,
            4,  772,  371,  527,   28,  127,    5,    1],
        [   2, 2712,   28,   23,  259,    4,    9,   23,  198,   14,    6, 1263,
          239,    4, 5859,   31,  112,   14, 6175,  129, 5637,   16, 3546,   20,
            4,   50,   32,  196,   52,  489,  171, 2323,  191,   44,   58, 1476,
            9, 9297,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 1109,  517,   90, 1802,   35, 8707,   59,    4,   16, 2800,
          198,  118,  157,    9,  141, 2742,   15, 2258,  177,    5,  396,   59,
         5068,  666,   75,   47,  363, 1176,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  459,   37,  658,    5,   68,  348,   65, 2308,    4,   43,
          319,  263,  799,  612,   57,  571,    4,   16,   43, 4196,   47,  275,
           49, 1407,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[3929,  155,  874,  103,   25,  154,   25,  135,    5,   84,   63, 1230,
            5,   91,   26,  850, 6566,  131,    7, 2932,    8,    7,  218, 1498,
         5804,   10,  170,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   9,    7,  467,    4,    7,  453, 6578,  148,   34,    7, 1951,   12,
           13, 1318,    8, 5555,   55,   24, 6868,    7, 1406,    4, 2082,    8,
          858, 4007,    6,   10,  367, 4404,    8,   51,   13,  461,   12,    7,
          546,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6, 3849,    4,   21, 3560,    6, 1259, 1599,    4,   21,
         2293,    6, 1890,   13,  525,  287, 7195,    6,    8, 1890, 3577,  901,
         7195,    6,  100,   56, 2175, 1488,   35,  868,    6,    4,  166,   26,
          133,  341,  106, 1120,  419,  218, 2475,   12, 6293,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21,  204, 1847,  214,   24,  169, 2807, 3301,   46,  214,  100,  150,
           48, 2184,    6,  156,    6,  109, 4377,   93, 2058,  424,    6,    6,
           46,    8,   73, 2575,  134,  199,   13, 4458,   18,  160, 1032, 1116,
          111,   45,   37,    4,  166,   25,   73,  774,  199, 1120,  419, 1862,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [   8,    7, 1384, 1224,  368,    6,   80,  423,  759, 9162,    6,   13,
          383,    4,  166,   26,   80, 1450,  439,   12,   77,    7, 1947,  619,
         5948,    9,    7,  179,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1291,   22,  140,  416,   22,  110,  556, 1949,   11,    6,   13,  391,
           35,  511,   35,  290,   35, 6979,   35,  715,  234, 1927, 3156,   12,
         1954, 6935,    9,    7,   43,   59,  371, 1644,  827, 1151, 3144,    6,
            4,   85,   80, 6581, 5494, 1360, 5997,    4,    8,   19,   11,  121,
          226, 1797,   54,   84,   55,  294,  215,    5,    2],
        [  94,  506,  204,  498, 1557,   54,  126, 8282,    6,    5,  934,  408,
          109,   53,  506,   86,   66,   13, 4561,  583,   71, 1230,   94,   10,
          456,   80,   13, 6711,  120,   53,  220,  116,   87,   13, 4454, 3836,
            8,  175,   21,  691,   71,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  853,   22,  335,   26,   17,   25,   73,  446, 2533, 5203,  336,
           21,    5,   68,  194,   65,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  70,   19,   11,  121,  116, 3498,   25,   63, 3302,   12,    7,  133,
          946,    8, 9743, 1081,   17, 5577,    6,    8,  896,  227, 2174,  232,
          445, 6442, 1052,   62,   48,  562,    6,    8, 1122, 1079,  292, 3751,
            6,   73, 9478, 2808,   55,  159,  447, 3965,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,  274, 6269,    8, 6269,  199,    7, 1710,   12, 5554,    4,    8,
            9,   17,  207,   24,  175,  914, 4616,    8, 4616,   10,   33, 2570,
         2240,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  218, 2604,    6,   12,  813,    4,   79,   25,   11,   57,  211,
         6449, 4837,   63, 2875,   80,  860, 4825,    6,    4,  106, 3836, 4506,
            6,    4, 1817, 4506,    6,    4, 1817,  837, 5002,    8,   29, 4404,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   24,   77,   87,   33,   13,  277, 4838,    4,  166,   26,  347,
           24,   73,   77,  274,  132,   85,    7,  370, 1303, 3253,    8,  150,
           33,    8,  113,   33,    8,  113,   33,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 225, 1639,   85,    7, 1749,  747,  670,   79,   13, 2829, 1020,    9,
            7,  384,  221,   11,    6, 2100,    4,   29,  225,  278,   10,  150,
           77,    7,  807,   17,  278, 3172,   22,  126,   12, 2092,    4,   55,
         1976, 1043,    4,  148,  162, 4111,   10,   51, 7806,   48,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 116,  336,   17,  183,  206,   19,   34,  961,   17, 7374,    4,   19,
         1260, 1004,    7, 4895,   12, 5205,    8, 4776,   84,   34,  486,  546,
           24,  162, 5054,   44,    7,   82,    9, 7723,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   34, 3642,   84,    4,  116,   13,  110,   57, 1802,   35, 1933,
           35, 1178,    4,    8,   19,  934,   48,   13,  422,  378,    9,   13,
         2414, 2196,    4,  125,   33, 5353,  220,   86,  601, 1584,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   11,   45, 2464, 1778,    5,   68,  194,   65,  211,    4,   53,
          162,  172,  488,  184, 2148,    6,    4,    8,   53,  465,   11,   18,
          135,  261,   80,  998,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'cluster_tokens': tensor([[29, 37, 38, 37, 37, 59, 37, 59, 11, 37, 85, 17, 11, 50, 85, 37,  9, 37,
         37, 28, 37, 37, 50, 34, 49, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 38, 11, 37,  2, 94, 50, 85, 37, 23, 37, 37,  9, 37,  2, 37, 38,
         49, 37, 37, 11, 88, 37, 94, 88, 37, 37, 85, 37, 37, 38, 37, 32, 37, 37,
         18, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 85, 37,  2, 11, 37, 29, 37,  9, 26, 11, 37, 49, 37, 32, 37, 35, 35,
          2, 37, 37, 32,  2, 35,  2, 37, 37, 38, 77, 35, 38, 73, 37, 11, 37, 85,
         83, 33, 37, 83, 50, 50, 38, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 83, 49, 56, 38, 85, 88, 29, 11, 56, 37, 59, 31, 38, 37, 35, 37, 37,
          9, 35, 28, 35, 37, 37, 11, 37,  6, 29, 37, 37, 37, 38, 35, 35,  2, 38,
         83, 35, 77, 11, 37, 37,  6, 38, 37, 83, 50, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 31, 56, 49, 37, 37, 34, 24,  9, 37, 37, 24, 11, 37, 85, 37, 34,
         24, 37, 50, 37,  9, 31, 83, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 35, 35, 35, 35, 37, 35, 35, 85, 37, 37, 34, 38, 35, 38, 35, 38, 83,
         38, 35, 35, 49, 28, 37, 38, 28, 37, 37, 38, 35, 35, 38, 35, 35,  9, 37,
         11, 37, 37, 34, 24, 37, 23, 11, 37, 38, 85, 35, 85, 23, 49, 37, 37, 50,
         24, 11, 83],
        [56,  6, 83, 49, 49, 49, 37, 32, 37, 11, 88, 11, 37, 37,  6, 83, 85, 37,
         94, 88, 37, 17, 56, 37, 16, 37, 37, 32, 37, 37,  6, 83, 85, 37, 83, 94,
         37, 85, 37, 31, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 35, 35, 85, 37, 37,  6, 59, 28, 35, 37, 37, 11, 38,  9, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [50, 38, 85, 35, 83, 88, 37, 85, 56, 37, 37, 83,  2, 37,  2, 56, 37, 28,
         37, 37,  9, 38, 35, 77, 35, 94, 38, 31, 31, 77, 37, 37, 38, 35, 35, 35,
         37,  6, 29, 32, 37, 37, 37, 32, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 59,  2, 37,  2, 37, 37, 94, 37, 56, 11, 37, 37, 37, 83, 38, 85, 83,
         36, 37, 36, 37, 37,  2, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 50, 94, 37, 37, 94, 11, 37, 37, 85, 77, 50, 32, 86, 85, 31, 37, 83,
         32, 37, 11, 37, 94, 36, 37, 11, 25, 36, 37, 11, 25, 28, 56, 37, 83, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 50, 85, 37, 37, 50, 33, 11, 37, 85, 83, 38,  6, 50, 59, 37, 37,
         37,  4, 24,  9, 37, 59, 37, 37, 83, 37, 37, 83, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 31, 37, 37, 28, 30, 94, 37, 37, 32, 35, 37, 37, 38, 35, 85, 37,  9,
         11, 83, 37, 31, 37, 59, 50, 37, 56, 37, 31, 49, 35, 37, 37, 23, 11, 37,
         50, 32, 11, 50, 85, 49, 37, 38, 94, 31, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 37, 24, 37, 38, 85, 49, 37, 94, 11, 38, 59, 37, 37,  5, 37, 28,
         37, 86, 37, 85, 50, 18, 38, 85, 49, 82, 37, 53, 37, 28, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 49, 37, 11, 83, 37, 37, 77, 34, 38, 24, 38, 35, 11, 37, 38, 88,
         31, 37, 28, 49, 37, 37,  4, 94, 11, 37, 37,  9,  6, 83, 49, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 35, 38, 35, 11, 38,  9, 11, 50, 11, 37, 85, 83,  2, 38, 35, 37,
         11, 37, 37, 85, 85, 35, 59, 83, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:4'), 'lengths': tensor([29, 39, 47, 50, 30, 57, 43, 18, 47, 27, 38, 33, 48, 34, 36, 30],
       device='cuda:4'), 'ntokens': 606}, 'target': tensor([[ 222,   41, 1112,    4,   41,  320,   36,    4,  110,  237,  303,   41,
           75,    5,   99,   76, 1230,    5, 4109,  161,  647,   49,   58, 8364,
         2725,    4,   14,  351, 1362,  181, 6238,  107,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 396, 7544,   82,   29, 1836,   74,   40, 1464,   16, 5630,   78, 3579,
            4, 7412,   16, 1014,    5, 1272,  164,   43, 2588, 1126,   16,   39,
           23,  489, 2581, 1685,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [7607,   90,   14,  731, 6135, 2887,   27,   95, 3341,    4,   51, 1265,
           18, 1699, 6332,   15,  177,   16, 7322, 2928, 1209,  160,  794,  152,
          234,   15,   16, 7972,   20,    4,  761,  707,  458, 1488,   35,  868,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 657,  734, 2835,   36, 5469,   20,    4,   14,   32,   90, 7056,   51,
         3641,  681,    4,  742,    5,  592,    5, 9434,    6, 3449,  241,  124,
         5172,  541, 3215,    4,   16,  145,   43,    9,   40, 4458,   18,  160,
         3484,    6, 2098,  111,   45,   37,   88, 1304, 1194,    4,   30,   81,
            9,  743, 1342, 1299,  990,  145,    5,    2],
        [  64,   14, 1270,   56, 6836,   15,    9,  761,  423,  767, 3204,   57,
          237,  427,  623,    4,   30,   76,  682,    5, 1450,  950,  129, 3664,
           15, 1928,   15, 4072, 3886,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  92,   27, 1163,   22,  140,  416,   22, 1297,  556, 1949,    5,   41,
         1364,  815,    4,  852, 1709,   60,  102, 1139,   56,  315,    6, 1867,
           49, 3779, 7189,    9,   58, 2865,   15,   23,   41,   59,  371, 1872,
          827, 1151,   61, 1433, 3697, 4630,   22, 2404,   22,    5,   72, 5310,
          517, 1091, 1142,  332,   61,    5,    2,    1],
        [ 104, 1602,  600, 2040, 7404,   15,    5, 1952,   41,   75,   30,  177,
            5, 1647,   36, 5792,  286, 3340, 1707,  181,   37, 1869,   60, 9346,
         6947,   22,    4,  114,   36,  139,   52, 5432,  330,   35, 4830,  269,
          354,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 520, 1544,   22,  335,  894,   41,  196, 2533,   20, 2001,  611,    5,
           68,  348,   65,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 327,   31,  252,  647, 2757,  209,    4,   76, 3660,   49,  485,  317,
           15,   16, 2029,   15, 6376,    4,   74, 6024,   15,    4, 2945,    6,
           37,  122,  152,   22,  195,  165,    6, 2016,  176,  152, 1217,  562,
           16, 1191,  620,  233,  156,  569,  662,   14, 6458,   78,  295, 1129,
         5857,   20,  171, 8777,  123,    5,    2,    1],
        [ 104,  208, 6197,   16, 6197,    9,   58, 7536,   23, 6310,    4,   16,
           29,  615,   32, 1746, 3178,   16, 3178,   39,  299, 2570,   20, 3656,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  331, 2350,    6, 5497,   22,    4,   74,   41,  302,  181,  356,
          849,  320,    4,   76, 5451,  112, 1399,   98,  330,   35, 4830,   35,
         2809,  249, 5646,   15,    4, 5665, 5801,   15,    4, 3125, 2495,   15,
         1817,   16,   29,  463,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   32,  231,  260,   30,   40,  905, 1229,   16, 6655,  123,   32,
          231,    9,   58, 2014, 2052,  803, 3319, 1989,   16,   14,    6,  208,
           16,  139,   30,   16,  139,  299,  173,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  41, 3490,    9,   23, 2275,   96,  444, 4945, 6887,   90, 1196,  156,
           57,   18,  683,  160,   97, 1162, 2407,  411,    6,  174,  219,  292,
            4, 2782, 1204,   43,  231,  435,    4,   14,   98, 3950,   45,  734,
           98,  102, 7117, 2707, 5132,   15,  522,   16,  897, 5719,   15,    4,
          772,  371,  527,   28,  127,    5,    2,    1],
        [2712,   28,   23,  259,    4,    9,   23,  198,   14,    6, 1263,  239,
            4, 5859,   31,  112,   14, 6175,  129, 5637,   16, 3546,   20,    4,
           50,   32,  196,   52,  489,  171, 2323,  191,   44,   58, 1476,    9,
         9297,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 1109,  517,   90, 1802,   35, 8707,   59,    4,   16, 2800,  198,
          118,  157,    9,  141, 2742,   15, 2258,  177,    5,  396,   59, 5068,
          666,   75,   47,  363, 1176,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  459,   37,  658,    5,   68,  348,   65, 2308,    4,   43,  319,
          263,  799,  612,   57,  571,    4,   16,   43, 4196,   47,  275,   49,
         1407,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([34, 30, 38, 56, 32, 55, 39, 16, 55, 26, 42, 33, 55, 39, 31, 27],
       device='cuda:4'), 'ntokens': 608, 'nsentences': 16}
##################### {'id': tensor([164131,  79590,  83519, 192659,  16491,  80067, 189617,  76195,  43422,
        104839, 197047,  88599,   9717, 218118,  17176, 152432, 212355, 113173,
         41948, 195530, 222634,   7202,   4356, 200245,  62959,  12072,  85156,
        183345,  57070,  56397,  97382, 130010,  57734, 145561,  55663, 127541,
        125134, 210326,  16699,  26172], device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 0.0040,  0.0037,  0.0037,  ..., -0.0055, -0.0049, -0.0051],
        [-0.0019, -0.0019, -0.0019,  ..., -0.0020, -0.0027, -0.0029],
        [ 0.0007,  0.0002,  0.0002,  ...,  0.0050,  0.0027,  0.0012],
        ...,
        [-0.0007,  0.0006,  0.0023,  ..., -0.0023, -0.0043,  0.0000],
        [-0.0019,  0.0007,  0.0031,  ...,  0.0024,  0.0030,  0.0000],
        [ 0.1379,  0.1320,  0.1278,  ..., -0.1168, -0.1125,  0.0000]],
       device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680,
        55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680,
        55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680, 55680,
        55680, 55680, 55680, 55680, 55680, 55679, 55679, 55679, 55679, 55679],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2,   41, 8473,  ...,    1,    1,    1],
        [   2, 4573,   32,  ...,    1,    1,    1],
        [   2,   64,  789,  ...,    1,    1,    1],
        ...,
        [   2,  104,  309,  ...,    1,    1,    1],
        [   2,  147,  707,  ...,    1,    1,    1],
        [   2,   64, 2783,  ...,    1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[  53, 2828,  987,  ...,    1,    1,    1],
        [6938,   25,   66,  ...,    1,    1,    1],
        [   8,   12,  538,  ...,    1,    1,    1],
        ...,
        [  29,   24,   66,  ...,    1,    1,    1],
        [  67,  985,  687,  ...,    1,    1,    1],
        [   8,  432,   24,  ...,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 29, 38,  ..., 37, 37, 37],
        [88, 37, 85,  ..., 37, 37, 37],
        [37, 37, 83,  ..., 37, 37, 37],
        ...,
        [83, 38, 85,  ..., 37, 37, 37],
        [37,  2, 35,  ..., 37, 37, 37],
        [37, 37, 38,  ..., 37, 37, 37]], device='cuda:1'), 'lengths': tensor([14, 13, 24, 16, 21, 17, 19, 15, 18, 17, 24, 12, 15, 15, 28, 26, 20, 11,
        22, 13, 15, 22, 24, 13, 20, 16, 15, 15, 15,  9, 16, 21, 15, 13, 16, 26,
        19, 13, 24, 12], device='cuda:1'), 'ntokens': 699}, 'target': tensor([[  41, 8473,   14,  ...,    1,    1,    1],
        [4573,   32,   39,  ...,    1,    1,    1],
        [  64,  789,    4,  ...,    1,    1,    1],
        ...,
        [ 104,  309,  299,  ...,    1,    1,    1],
        [ 147,  707,  649,  ...,    1,    1,    1],
        [  64, 2783,   32,  ...,    1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([17, 14, 20, 19, 23, 18, 25, 16, 17, 25, 16, 22, 14, 18, 20, 28, 20, 14,
        21, 13, 20, 20, 17, 14, 19, 20, 13, 18, 23, 11, 14, 18, 15, 16, 25, 23,
        21, 13, 22, 17], device='cuda:1'), 'ntokens': 739, 'nsentences': 40}
##################### {'id': tensor([ 64152,  97563,  70426, 127739,  60317, 109129, 140500, 178703],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 9.1553e-05,  1.5259e-04,  2.1362e-04,  ..., -1.1902e-03,
         -6.7139e-04,  9.1553e-05],
        [ 5.4932e-04,  1.2207e-03,  1.0681e-03,  ...,  5.1575e-03,
          5.3711e-03,  5.9509e-03],
        [-5.4626e-02, -2.7924e-02, -5.9204e-03,  ...,  1.4954e-03,
         -6.9275e-03, -1.3153e-02],
        ...,
        [ 1.8616e-03,  2.6855e-03, -1.9226e-03,  ..., -9.4299e-03,
         -1.6907e-02, -1.4191e-02],
        [ 1.1566e-02,  9.2468e-03,  8.7585e-03,  ..., -5.3101e-03,
         -6.4087e-03,  0.0000e+00],
        [ 1.1292e-02,  1.1322e-02,  1.1536e-02,  ..., -6.7139e-04,
          1.0071e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([161440, 161440, 161440, 161440, 161440, 161440, 161439, 161439],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2, 1493, 5306, 3644,    9, 3075,   15,   35,  606, 5731, 1868,   37,
          272,   16,   14,  731, 3075,   15, 5735,  193, 2389,  530,   37,    4,
          685,  160,  156,    4, 4453,  193,   16,   43, 4208,  272,   14, 8642,
           20, 8890,   16,   56,  315,    6, 1867,  182, 1815,    5,    1,    1],
        [   2,  738, 5675, 2727,    9,   58, 1270, 3874,    4,   50,   49,   58,
          171, 6472,   15,   56, 9205,   15, 3332,    6, 5078,   22,    4,  302,
         5304,   23,  171, 6472,   15, 1438,  435,   83,  136,  149,   40, 5304,
           23,  171, 6472,   15,  617,    5,    1,    1,    1,    1,    1,    1],
        [   2,  312,    6,   60,  212, 5734, 7630,   49,   23, 5700,  721,   23,
          912,  352, 1842,    5,   38,  680, 1824, 1198,    4,   34,  257,   41,
          334,    4,   31,   13,  156,  658,  265, 5133,   36,  137,  312, 4193,
            9, 1750, 1024,    4,   16, 1186,  203,  652,  756,  119,  897,    5],
        [   2, 4409,   20, 4422,    9,   23, 3691,  502, 3681, 3353,    4,   14,
          112, 2970,  762, 3985,   20,   49,  332,   61, 1903,    4, 1380,   14,
          350, 3583,   49, 7905,   61,   23, 1062,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   34, 1023,   43,   47,  196,  374,  269,  123,    4,  114,
           43,   14, 5903, 3734,    6, 2016, 6286, 1023,    4,   88,   40, 1550,
           28, 1205,    4,   50,  986,   30,  864, 1240,    4,   30,  255,  177,
           75,  814,    4, 2752,  190,  410, 2050,  588,  127, 1398,   42,    1],
        [   2,   72,   56,  219,  242,  924,    4,  757,   61,   23, 3063,   28,
          605,    5,   68,  348,   65,   64,   31,   56, 4522,   20,  112,   14,
         8576,    5,   64,   31,  209,   40,  542, 2030, 2525,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4663,   41,   75, 3990,    4, 6373,   29,  306, 1134,  622, 2124,
           15,    9,   58,  808,  640,  332,  466, 9505,   76,   42,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  657, 2167,  329,  198,   30,   46,   68,  379,   65,   68,  431,
           65,   46, 2089,    4,   14,   32, 1334, 2506,   15,    4,   76, 1225,
         2089,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1')}, 'transcript': {'tokens': tensor([[ 125,    9, 2483,   35,  606, 5731,    4, 2932, 6930,    6, 5989,    8,
          447,  281,   12,    7, 2483,    6,   46, 4346,  737,    4,  742,  160,
          140,    4, 3213,   46,    8,   53, 5470,    7, 2791, 2008,    8, 3156,
          199, 2248,  713, 1777,    5,    2],
        [  13, 4495, 1435,    9,    7,  832,    5,    6,    5, 2721,   17,    4,
           12, 5990, 8459, 3665, 1118,    4,  248,   35, 8516,    6,   12,    7,
         5990,  889,  144,  708,    8,  288,   91,   35, 8516,   12,    7, 5990,
          596,  144,  708,    5,    2,    1],
        [ 168,   26,   13,   29,  300,  166,  188,  278,   77,    7, 8681,   12,
         7343,    5, 3280,    4, 1976,   25,  289,    4,   19, 3250,   21,    5,
           39,   19,  362, 1838,  235, 5384,    9,   25,    8,  180,   25, 3745,
           10,   21,    5,    2,    1,    1],
        [ 822, 2317,    9,  984,   11,    6, 6339,   17, 4877,  244, 1953,    6,
           10, 2386,   12, 1655,   12,  215, 4373,    7, 6484,   12, 7616,   69,
          984,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  67,   70,  143,  220,  225,   66,  691,  103,  225, 1631, 1088,  144,
            7, 1885,  818,   12, 3802,    6, 2875,   10,  267,   10,  719,   13,
          841,   17,    7, 9413,   17,   94, 1095,  144,   10,   51, 1529,   62,
         3840, 4173,   42,    2,    1,    1],
        [  19, 1223, 2894,   55, 3101,  839,   69,    7, 2291,    5,   68,  194,
           65,    8,   19, 5429,   80,    7, 5986,    6,    4,    8,   19,   66,
          591,   13,  555,  214,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  66,   25, 1060, 9832,  347,    8,  138,   29,  294, 9696, 2419,    6,
           66, 6028,   48,  244,    7,  473,  640,  215,   42,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1223,   70,   21,  968,  110,   34,   46,   68,  194,   65,   68,  386,
           65,   46,    7, 1587,   12, 1075,   24, 5559,   63,  324, 1075,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 37, 37, 38, 35, 35, 11, 28,  2, 37, 49, 37, 37, 75, 37, 37, 37, 37,
         11, 38, 35, 11, 38, 35, 35, 11, 28, 11, 37, 37,  9, 37, 56, 28, 37, 28,
         37, 83, 35, 28, 11, 83],
        [37, 83, 59, 37, 37, 38, 11, 37, 11, 88, 37, 11, 37, 31,  2, 49, 56, 11,
         34, 38, 28, 37, 37, 37, 31, 56, 85, 56, 37, 83, 50, 38, 28, 37, 37, 31,
         56, 85, 56, 11, 83, 37],
        [37, 85, 37, 83, 35, 37, 85, 31, 50, 37, 94, 37, 32, 11,  9, 11, 50, 37,
         88, 11, 38, 88, 37, 11, 38, 38, 35, 35, 35, 32, 37, 37, 37, 37, 37, 49,
         37, 37, 11, 83, 37, 37],
        [ 2, 56, 37, 94, 85, 37, 94, 37, 85, 37, 38, 37, 37, 34, 37, 24, 37, 24,
         38, 37, 94, 37,  9, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 50, 50,  6, 37, 85, 31, 37, 37, 85, 38, 85, 37, 28, 88, 37, 16, 37,
         31, 37, 37, 37, 49, 37, 32, 37, 37, 21, 37, 56, 59, 85, 37, 38, 49, 31,
         37, 83, 11, 83, 37, 37],
        [38, 83, 49, 37, 59, 32, 37, 37, 94, 11, 38,  9, 11, 37, 38,  8, 37, 37,
          9, 37, 11, 37, 38, 85, 31, 37, 50, 56, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [85, 37, 31, 37, 83, 37, 37, 83, 50,  9, 35, 37, 85, 10, 31, 37, 37, 37,
         34, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 50, 37, 88, 37, 85, 11, 38,  9, 11, 38, 28, 11, 11, 37, 50, 37, 56,
         38, 29, 85,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:1'), 'lengths': tensor([42, 41, 40, 27, 40, 30, 22, 25], device='cuda:1'), 'ntokens': 267}, 'target': tensor([[1493, 5306, 3644,    9, 3075,   15,   35,  606, 5731, 1868,   37,  272,
           16,   14,  731, 3075,   15, 5735,  193, 2389,  530,   37,    4,  685,
          160,  156,    4, 4453,  193,   16,   43, 4208,  272,   14, 8642,   20,
         8890,   16,   56,  315,    6, 1867,  182, 1815,    5,    2,    1,    1],
        [ 738, 5675, 2727,    9,   58, 1270, 3874,    4,   50,   49,   58,  171,
         6472,   15,   56, 9205,   15, 3332,    6, 5078,   22,    4,  302, 5304,
           23,  171, 6472,   15, 1438,  435,   83,  136,  149,   40, 5304,   23,
          171, 6472,   15,  617,    5,    2,    1,    1,    1,    1,    1,    1],
        [ 312,    6,   60,  212, 5734, 7630,   49,   23, 5700,  721,   23,  912,
          352, 1842,    5,   38,  680, 1824, 1198,    4,   34,  257,   41,  334,
            4,   31,   13,  156,  658,  265, 5133,   36,  137,  312, 4193,    9,
         1750, 1024,    4,   16, 1186,  203,  652,  756,  119,  897,    5,    2],
        [4409,   20, 4422,    9,   23, 3691,  502, 3681, 3353,    4,   14,  112,
         2970,  762, 3985,   20,   49,  332,   61, 1903,    4, 1380,   14,  350,
         3583,   49, 7905,   61,   23, 1062,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   34, 1023,   43,   47,  196,  374,  269,  123,    4,  114,   43,
           14, 5903, 3734,    6, 2016, 6286, 1023,    4,   88,   40, 1550,   28,
         1205,    4,   50,  986,   30,  864, 1240,    4,   30,  255,  177,   75,
          814,    4, 2752,  190,  410, 2050,  588,  127, 1398,   42,    2,    1],
        [  72,   56,  219,  242,  924,    4,  757,   61,   23, 3063,   28,  605,
            5,   68,  348,   65,   64,   31,   56, 4522,   20,  112,   14, 8576,
            5,   64,   31,  209,   40,  542, 2030, 2525,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [4663,   41,   75, 3990,    4, 6373,   29,  306, 1134,  622, 2124,   15,
            9,   58,  808,  640,  332,  466, 9505,   76,   42,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 657, 2167,  329,  198,   30,   46,   68,  379,   65,   68,  431,   65,
           46, 2089,    4,   14,   32, 1334, 2506,   15,    4,   76, 1225, 2089,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1'), 'target_lengths': tensor([46, 42, 48, 32, 47, 34, 22, 26], device='cuda:1'), 'ntokens': 297, 'nsentences': 8}
##################### {'id': tensor([ 45991, 133792,  89559, 196530,  74102, 136737,  65235, 161740],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[-2.1362e-04, -5.7983e-04, -4.5776e-04,  ..., -8.9722e-03,
         -5.0354e-03,  1.8311e-04],
        [ 7.6782e-02,  9.0942e-03, -4.9835e-02,  ..., -1.0010e-02,
         -6.8359e-03, -2.3499e-03],
        [-3.3569e-04,  9.1553e-05,  1.8311e-04,  ...,  2.7161e-03,
          1.3123e-03,  7.3242e-04],
        ...,
        [-1.0620e-02, -1.9501e-02, -3.7506e-02,  ...,  3.5217e-02,
         -2.0966e-02, -2.0630e-02],
        [ 1.9226e-03,  1.3123e-03,  3.9673e-04,  ...,  1.5259e-04,
          2.1362e-04,  0.0000e+00],
        [ 1.0681e-03,  1.4343e-03,  1.6785e-03,  ..., -1.7395e-03,
         -1.3733e-03,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([184160, 184160, 184160, 184160, 184160, 184160, 184160, 184159],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,   64, 4084,   75, 1000,   39,  299, 1278,   38, 2809,  119,  480,
         8888,  673, 1611,   55, 2715, 3392, 4649,  232,  197,  193,   60,   56,
         3856,  340, 4785,   37,    9, 1653, 1278,   42,  402, 1277,  330,  680,
         1861,    5,  350,  122, 2652,   41,   47,   44,   40,  917,  836,  644,
         3824,   61,   58, 2368,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  912, 3746,   23, 3830,  158,   15, 3225,   82,   14, 1053,   39,
         5809,    4,   14,   75,    9, 1299,   49, 4880,   97, 3691, 1788, 5080,
            6, 8201,    4, 1343, 1836,   74,   14, 1053,   39, 5809,    9, 1299,
           49, 3691, 4588,    9, 1092,  241,  607, 1926,  541,  634,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 1209,  844,   76,   32,   28,  102, 3442, 3171, 4009,    4,   50,
         1826,    9, 3133,   49, 5194, 1152,  123,    4,  917,   16,   30, 1287,
           28, 1168,    4, 3525, 1170,  307, 2381, 1513,   43,  319,    4,  124,
          258,   43,   75, 8201,   15,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  104, 3371,   15,  113,  118,  877, 1967,   15, 6778,   15,  344,
          867,  975,  292, 2404,    6,    4,   60,  102,   81, 1447, 9075,   15,
          223, 5721,  145,    4,   14, 1447,  867,  975,  729, 3821,    4,   34,
          847, 1176,  145,    4,   14, 4696,   20,   97,  599,   28, 8534,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  228,  249,   96,    6,  480,   27,    4,   50,   43,  105, 2727,
            9, 2598,  727,   37, 2241,   16, 6777,  223, 5723,   15,    4,  258,
           36,  417,  322,  625, 8507,   37,   27,    4, 3739,  658,  804,    6,
           28,  667,    5,   41, 2081,   36,  139,    9,   58, 1270,  667,    4,
           88,   14,  912, 2706,  165,   28, 1773,    4,   36, 4611,  113,    4,
          705,   31,    4,  462, 3131,   35, 5267,   18,  634,  191,   97, 3229,
         1357, 1784,   39,   23, 2727, 2581,    5],
        [   2,   99,   27,   52, 2864, 5336,    4,   36,   27,  707,  649,   15,
          721,    4,   36,   27,   40, 4627, 1577, 3822, 1399,   47,  149,  112,
           58, 5569, 1632,    4,   14, 4121, 3353,   16, 4217,   15,    4,  519,
          139,  112, 7872, 5497,   22,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  578,  198,  632,    9,   58, 1971, 4009,   28,  604,    4,
          149,  268,   31,  118, 6889, 6282,  280,    4,    9,  102,   52, 1024,
           40, 8116,   22,   45,  932,  345,   82,    4,   50,  212, 1843,  231,
         3477, 8741,   20,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 3130,   20,   58, 5678, 3467,    4,   16, 3452,    4,   60,
          448,    9, 2010,   59, 1058,   88, 3387,    4,  136, 6151,  203,  809,
          975, 2208,    4,    9,  631,   31,  118, 2430,   15, 1877,   49, 3734,
           16,  342,  416, 5822,  271,   61, 1769,  153,    4,  223,   58,   32,
         3194,   22,    4,  466,  425, 3951,   16, 4085,   28, 4095,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[   8,   46, 2307, 1008,   33,  283, 7772,    4,   38,  160,  119,  480,
         6880,   55,  155, 5223,  197,   46, 1363, 1850,   37,    9,  545, 1227,
           42,   33,   34,  138, 7803, 1808,    5,  192,   11,   18, 3995,   44,
           13, 1192,  552,  126,  224,   21,  144,  211, 3236,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,    7, 4174, 2078,  487,    4,    7, 1762,   12, 2718, 2202, 6611,
         6671,    9,    7,  774,   12, 5428,   34,   79,  488,   79,    7, 1762,
           12, 2718, 2202,  850, 3909,  607, 4357,  407,    9,    7,  774,   12,
         1947,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   85,    7,  467,   12,   21,    4,   24, 8152,   48,   17, 2878,
           12,  708,   73, 1082,   10,  368, 2930,    8,    7, 1465,   69,  159,
          447,    4, 5333, 2515,  366,   12,  148,  109,  206,   53,  162,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24, 1405,   13,  846, 4399, 7016,   12,   13,   56, 2515,  292,
         2404,    4,    8,   25,   73, 3684,  375,  688,  359,  341, 8829,    6,
           17, 2231,  341, 7125,    6,    4,   29,   17,   73,  601,   25, 5415,
           70,   11,    6,    9,    7,  563,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  70,   11,    6,  916,   26,   53,  323,   21,    9, 2008, 1491,    8,
         6343,    4,  206,   21,   11,    6,   38,  626,   57, 6505,  128,   10,
          508,  561,  804,    6,  137,   53,  144,   10,  508,   21,  113,    9,
            7,  832,    5,    6,    5,   10,  175, 1719,  292, 2460,    4,   29,
           19,  154,   84,  162,  391,  832,    5,    6,    5, 2116,    9,  132,
         6034,  264, 1736,  148,  162,  461,   12,    7, 3677,    5,    2],
        [  33,   26,   13, 1523, 7376,    5,   21,   11,    6,   39,  985,  687,
            4,   21,   11,    6,   13, 4912,   12,   77, 1587,   12,  813,    4,
           86,  116,   80, 5807,    8, 9827,    8, 6689,    8,   29,   69,    4,
           67,   80,  896, 2604,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   21,  169,  492,   66, 7747,   10,  110,   10,  154,   17,  116,
          125,   19,  144, 1157,   13, 5462,    9,  166,   13, 2232,   34,   13,
          227,   37, 1010, 2650,   37,   17,  101,   34, 3524, 2015, 1197,   12,
           77, 4039,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  169, 1017, 8788,   55,    7, 1732,    6,    4,    8,  780,   10,
         2895,   71,  134,    9,   13,  207,   17,   34,   79,    6,  762,  366,
         1094, 3835, 1256,    4, 6510,   54,   13, 2866,  979,   12, 3802,    8,
         7376,    9,  166,   24,  220, 1082,   10,  283,  540,    8, 1766,   91,
          486,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'cluster_tokens': tensor([[37, 11, 50, 59, 37, 49, 35, 11, 38, 35, 75, 35, 56, 37, 37,  9, 82, 11,
          2, 38, 77, 37, 50,  9, 11, 37, 85, 37, 32, 31, 11, 85, 85, 35, 88, 82,
         37,  9, 85, 37, 11, 37, 85, 50, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 28, 94, 31, 11, 37, 23, 37,  9, 59, 37, 28, 37, 37, 38, 37, 28,
         85, 37,  2, 37, 37, 23, 37,  9, 59, 37, 38, 35, 28, 35, 37, 37, 38, 37,
          9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 37, 38, 37, 37, 11, 38, 88, 31, 37, 56, 37, 56,  6, 59, 37, 49,
         56, 37, 37,  9, 37, 37, 37, 11,  2, 32, 77, 37, 50, 37, 37, 37, 85, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 31, 37, 38,  2, 32, 37, 37, 38, 32, 35, 23, 11, 37, 37,  6, 38,
         77,  9, 37, 33, 94, 37, 37, 49, 33,  9, 37, 11, 83, 37,  6, 49, 37, 36,
         50, 85, 37, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 85, 37,  2, 85, 37, 85, 37, 37, 28, 28, 37, 28, 11, 37, 37, 85, 37,
         38, 35, 77, 94, 35, 37, 88,  9, 35, 37, 11, 37, 85, 37, 88, 37, 83, 37,
         37, 38, 11, 37, 11, 37, 85, 38, 35, 35, 11, 83, 38, 59, 37, 85, 34, 38,
         11, 37, 11, 56, 37, 37, 35,  2, 28, 50, 85, 32, 37, 37, 32, 11, 83],
        [37, 85, 37,  2, 94, 11, 37, 85, 37, 38,  2, 35, 11, 37, 85, 37, 37, 49,
         37, 50, 50, 37, 94, 11, 83, 83, 37, 24, 37, 94, 37, 94, 37, 83, 37, 11,
         37, 37,  9, 94, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 50, 85, 31, 37, 37, 37, 59, 37, 83, 37, 38, 85, 88, 37,  9,
         37, 37, 37,  9, 85, 37, 38, 77, 35, 10, 77, 37, 38, 85, 83, 36, 77, 37,
         50, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 31,  5, 37, 37, 94, 37, 11, 37, 88, 37, 36, 37, 37, 37, 37, 83,
         37, 85, 37, 37, 31, 77, 83, 36,  2, 11, 29, 49, 37, 29, 32, 37, 16, 37,
         94, 37, 37, 38,  6, 59, 37, 49, 36, 37, 49, 50, 50, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:7'), 'lengths': tensor([47, 39, 37, 44, 71, 43, 40, 51], device='cuda:7'), 'ntokens': 372}, 'target': tensor([[  64, 4084,   75, 1000,   39,  299, 1278,   38, 2809,  119,  480, 8888,
          673, 1611,   55, 2715, 3392, 4649,  232,  197,  193,   60,   56, 3856,
          340, 4785,   37,    9, 1653, 1278,   42,  402, 1277,  330,  680, 1861,
            5,  350,  122, 2652,   41,   47,   44,   40,  917,  836,  644, 3824,
           61,   58, 2368,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 912, 3746,   23, 3830,  158,   15, 3225,   82,   14, 1053,   39, 5809,
            4,   14,   75,    9, 1299,   49, 4880,   97, 3691, 1788, 5080,    6,
         8201,    4, 1343, 1836,   74,   14, 1053,   39, 5809,    9, 1299,   49,
         3691, 4588,    9, 1092,  241,  607, 1926,  541,  634,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [1209,  844,   76,   32,   28,  102, 3442, 3171, 4009,    4,   50, 1826,
            9, 3133,   49, 5194, 1152,  123,    4,  917,   16,   30, 1287,   28,
         1168,    4, 3525, 1170,  307, 2381, 1513,   43,  319,    4,  124,  258,
           43,   75, 8201,   15,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 104, 3371,   15,  113,  118,  877, 1967,   15, 6778,   15,  344,  867,
          975,  292, 2404,    6,    4,   60,  102,   81, 1447, 9075,   15,  223,
         5721,  145,    4,   14, 1447,  867,  975,  729, 3821,    4,   34,  847,
         1176,  145,    4,   14, 4696,   20,   97,  599,   28, 8534,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 228,  249,   96,    6,  480,   27,    4,   50,   43,  105, 2727,    9,
         2598,  727,   37, 2241,   16, 6777,  223, 5723,   15,    4,  258,   36,
          417,  322,  625, 8507,   37,   27,    4, 3739,  658,  804,    6,   28,
          667,    5,   41, 2081,   36,  139,    9,   58, 1270,  667,    4,   88,
           14,  912, 2706,  165,   28, 1773,    4,   36, 4611,  113,    4,  705,
           31,    4,  462, 3131,   35, 5267,   18,  634,  191,   97, 3229, 1357,
         1784,   39,   23, 2727, 2581,    5,    2],
        [  99,   27,   52, 2864, 5336,    4,   36,   27,  707,  649,   15,  721,
            4,   36,   27,   40, 4627, 1577, 3822, 1399,   47,  149,  112,   58,
         5569, 1632,    4,   14, 4121, 3353,   16, 4217,   15,    4,  519,  139,
          112, 7872, 5497,   22,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  99,  578,  198,  632,    9,   58, 1971, 4009,   28,  604,    4,  149,
          268,   31,  118, 6889, 6282,  280,    4,    9,  102,   52, 1024,   40,
         8116,   22,   45,  932,  345,   82,    4,   50,  212, 1843,  231, 3477,
         8741,   20,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  72, 3130,   20,   58, 5678, 3467,    4,   16, 3452,    4,   60,  448,
            9, 2010,   59, 1058,   88, 3387,    4,  136, 6151,  203,  809,  975,
         2208,    4,    9,  631,   31,  118, 2430,   15, 1877,   49, 3734,   16,
          342,  416, 5822,  271,   61, 1769,  153,    4,  223,   58,   32, 3194,
           22,    4,  466,  425, 3951,   16, 4085,   28, 4095,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:7'), 'target_lengths': tensor([53, 47, 42, 48, 79, 42, 40, 59], device='cuda:7'), 'ntokens': 410, 'nsentences': 8}
##################### {'id': tensor([190025, 122904, 204336,  96053,  63611,  58520,  21431],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 1.7700e-03,  8.5449e-04,  0.0000e+00,  ..., -1.8311e-03,
         -2.1057e-03, -2.3193e-03],
        [ 2.3193e-03, -2.7466e-04, -2.2278e-03,  ...,  5.9814e-03,
          4.6387e-03,  6.7444e-03],
        [ 4.2419e-03,  4.5166e-03,  2.5330e-03,  ..., -8.5449e-04,
         -2.8992e-03, -3.8147e-03],
        ...,
        [ 6.1035e-05,  1.8311e-04, -1.2207e-04,  ...,  1.8311e-04,
          8.5449e-04,  0.0000e+00],
        [ 1.6479e-03,  1.8616e-03,  6.7139e-04,  ..., -3.3264e-03,
         -4.1199e-03, -3.5706e-03],
        [ 1.5564e-03,  7.3242e-03,  9.9487e-03,  ...,  1.0254e-02,
          2.1362e-03,  8.2397e-04]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([302400, 302400, 302400, 302400, 302400, 302400, 302400],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2,  104,   83,   40, 6067, 2224,    6, 7881,    4,   60,  102,   32,
          107,  141, 1024,   28, 3160,   22,    4,  385,  105,   52,  467, 2776,
         4191,   49, 6281,   22, 7630,   44, 1196,  187,  406, 2249,   59, 1163,
         3129, 3701,   37,    4,  406,  772,   37, 2441,    4,   23, 2819, 1506,
         1619,    4,  406,  350,  587,  387,   37,    4,  406, 2294,   37,  507,
         8203,   20,    4,    9, 1635,  975, 1317,  158,   61,  493, 6134, 5284,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1562,   34, 1235,  335,  684, 7392,    4,   16,   41,  127,   36,
          139,    9, 5176,  237,    6,   15,    6, 3224,  362,  715,   22,  634,
         1626,    4,   82,    4,   50,   14, 4842,    4, 6728,    4, 2084, 1338,
         4027, 4438,   23, 9640,  129,  564,    5, 4535,   75, 1474,  844, 3178,
          191,    4,   16,   50,   32, 5215,  319,    4,    9,  118,  212, 3786,
           15,  590, 3512,   20,   23,  489,   28,  184, 2789,    4,    9,  628,
         1652,   56, 3952,   18,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  202, 2647,   41,   60,  198,  253,  698,  642, 1975,    4,  173,
           61,   23, 1664,   35,  592,  219,  176,  375,    4,   52, 3712, 2178,
         2445,  481, 8080, 1411,  271,  646,  198,   16,  771, 2441,    4, 1807,
            5, 1935,  649,   57,   93,  966,  240, 2003,    4,  602, 1935,   18,
          911,  265,  300,    6,  369, 2380,  866,   93,   23, 7203,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298, 1092,  411,  122,  387,    4,   30,   97, 2380,   81,  763,
          300,  398,  161,    4,  385,   36,  190, 2000,    4,   34,   49,   23,
         1191,   47,  177,  247, 1883,   27,  343,  742,    5,  592,    5,    9,
          631,   81,   14, 2999,  344, 4321,    6,    9,   14, 2999,  141, 2161,
          424,  412, 4739,  343,   19,  122,  235,   18,  408, 7613,   41,  163,
           47, 1791,   44,   72, 1627, 4321,   16, 5736,  411,   15,    4,  136,
           29,  190,   27,  921, 1746, 9466,    5,   68,  348,   65,   92, 1092,
          411,  122,  387,  161,  189, 1330, 8922,   16, 5565,    5],
        [   2,  738, 1624,   49, 1426,    4,   14,   39,  151, 6423,   15,  623,
         2548,    4,  118,  664,   15,  532, 4544,  817,   51, 1903,    4,   39,
          669,  349,   37,  525,  128,    6,  330,   35, 4830,    6,   16, 5241,
          709,    6,   60, 7689, 2974, 5880, 2887,    4,   74,   14,  173,    4,
         2526,    4,   16,   43,  410, 1471,   75,  112, 2495,   20,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  361,   27,   14, 9012,   20, 1572,    4,  823,   78,   40,
         7205,  397,   30, 3389, 1640, 2717,  184, 1105,  543,  762,  130,   27,
            9,   23, 4904, 3617,   28,  309,  403,  751, 6094,   20, 3115,  124,
          318, 9123,  127,    5, 1493,   14, 3724,  891,  271,   28, 1209,  436,
          234, 3080,  634,   29, 5088,   27,   50,   43,   47, 1229,  385, 5437,
          123,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146,  602, 4366, 1330, 2133,   15,   15, 2368,   57,  891,   15,
          193,   16,   31,  209,  761,  798,  397,  385, 5217,    4,   58, 5546,
           28,   51, 6153,   22,    4, 2799,   28, 1070, 3501,  962, 6647,   22,
           28, 8168,    4,   16,  209, 5009, 1217,  562,    9,  392,  382,  798,
         2499,  299, 5546,    6, 3395,   18,    4, 6075,   49, 5009, 1217,  562,
           22,  193, 3452,   28,  725,   34,  255,  375,  739,  814,   60,  536,
         2368,   57,  891,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4')}, 'transcript': {'tokens': tensor([[  24,   66,   13, 7524, 4040,    9,  166,   24, 1393,   10,   91,  723,
           10, 8714,   39,  467,  982, 2884,   12, 1833,   44,   10,   51,   89,
         4023,  570,   59,    4,   89,  772, 1751,    4,    7,  772, 5370,    4,
           89, 2444,   62,  521, 1105,   48,  480,    4,   89, 2294, 1661,  221,
          369,    4,   89, 5930, 4888,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  67,   70, 1320,  335,  684, 4600,    4,    8,   25, 1510,   21,    9,
            7,  227,   93,  362,  715, 2378,    6,   12,  632,  237,    6,   15,
          593,    4,   34,   17,    7,  535,    4, 3139,    4,  227,  233, 2341,
         4267,    6,   12,  574, 2256,   12,    7,  564,  322, 1910,  162, 1028,
           10,   13, 1387,    4,    8,   17,   24,  162,   80,   10,  954,  199,
           91,   12,  251, 9200, 2760,    6,   12, 1261,  120,  768, 2317,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  19, 7750,   25,   10, 1064,    4,   55,    7,  245,  183, 3983,    9,
            7,  179,    4,  168,   69,    7, 1366, 2110,    4,   13,  475,   35,
         5203, 2178, 2445,  266, 6580, 1411,  271,    4,  629,  110,    8,   89,
         1751,    4,  903,    5,  728,  649,   57,   93, 2734, 2003,    4,  106,
         7002,   11,    6,  728,   18, 3411,  300,    6,  369, 7312,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  17,   26,  120,   13,  150,   48,   26, 6788,   62,    9,   13, 7312,
           10,   87,  250,   86,    9,  191,   48,   62,  131, 1377,   46,  100,
         1520,    7, 2192,   12,   13, 1390,    8, 2985,   21,  199,    7, 2192,
           12,   13,   10,  424,  412,    5, 1995, 2083,    5,  192,   11,   18,
          175,  110, 1226,    4,   19,  100, 1390,    8,   10,  424,  412,   96,
            4,   67,   33,   26,  116,  775,   20, 1718,   93,    5,   68,  194,
           65,    7,  150,   48,    6,   63,  180, 2685,   62,    4,  180, 5847,
            5,    2],
        [   7, 2193, 1793, 2493, 7012, 1198,    6, 1361,    4,   13, 1361,   12,
           94,  148,    4,   69,   13, 1284,  383, 1663,    4, 3284,  199,   13,
         3508,  982,  964,    4,   85,  159, 3506,  160,  128,    6, 3696, 3836,
            8, 2187,    6,    9, 2828,   62, 7689, 1974,   22,   18,    4,  100,
           33,    4,    8,   53,  456,   80, 5002,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   29,  115,    7, 2932, 1381,    4,  148,   55,   13,   87,  610,
          215,    4,  188,  923, 3150,  111, 6226,   62,    7, 2688,    4,   26,
          115,    9,    7, 3140,   12, 1057,   10, 4007, 1179,   10, 2156,  109,
         6406,  346, 1711, 4166,    4,  125,    7, 6105,   10,   13, 3147,  234,
         1827,   26,   29, 4126,   17,   53,   73,   11,   18, 1799,   71,   21,
          419,  218,  207,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   7, 1232, 5917,    6,  427,  362, 1011,  131,    7, 3022,   46,    8,
           19,   11,  121, 2138,  185,  798,  215, 2115,   54,  336,    7, 4959,
          401, 1221,   69, 8633, 1232,    6,    4,    8,   66, 3395,   62, 3585,
         1118,    9,  392,   10,  798, 1075,    9,   33, 4959,    4, 2386,   12,
         3585, 1118,   46,  752,   10,  661,   70,  513, 1226,   71,  108, 1232,
         5917,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[38, 85, 37, 28, 28, 37, 37, 38, 40, 37, 50, 94, 37, 49, 38, 38,  2, 94,
         37, 56, 82, 37, 38, 37, 75, 94, 35, 11, 37, 75,  9, 11, 37, 75,  9, 11,
         37, 32, 31, 38, 35, 31, 35, 11, 37,  2, 36, 35, 44, 11, 37, 28,  4, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 38, 35, 35, 31, 11, 37, 37, 59, 37, 37, 37, 38, 35, 35, 35, 77,
         37, 37, 38, 35, 37, 77, 83, 11, 85, 37, 37, 83, 11,  2, 11, 38, 35, 35,
         24, 37, 37, 38, 94, 37, 37, 34, 35, 24, 85, 49, 37, 37, 83, 11, 37, 37,
         38, 85, 37, 37, 49, 37, 50, 37, 50,  2, 23, 37, 37, 94, 37, 94, 56, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 49, 37, 37, 32, 11, 37, 37, 83, 24, 50, 37, 37, 94, 11, 37, 37, 37,
         28, 23, 11, 37,  2, 38, 35, 38, 35, 35, 38, 35, 44, 11, 37, 37, 37, 37,
          9, 11, 38, 11, 38, 35, 77, 35, 38, 35, 11, 37, 28, 85, 37, 38, 35, 38,
         35, 37, 44,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 59, 31, 85, 29, 31, 37, 37,  9, 37, 85, 50, 83, 37, 77,
         31, 31, 37, 94, 11, 37, 49, 37, 94, 37, 37,  9, 37, 49, 37, 37, 37, 94,
         37, 37, 37, 35, 35, 11, 38, 35, 11, 85, 85, 35, 85, 37,  2, 11, 38, 37,
          9, 37, 37, 35, 35, 77, 11, 37, 37, 85, 83, 38, 77, 35, 35, 11, 38,  9,
         11, 37, 59, 31, 37, 85, 37, 94, 31, 11, 37, 31, 11, 83],
        [37, 28, 28,  9, 94, 35, 37, 94, 11, 37, 94, 37, 56, 50, 11, 37, 37,  2,
         24, 37, 11, 49, 37, 37,  9,  2,  9, 11, 37, 37, 32, 35, 35, 37, 59, 94,
         37, 94, 37, 37, 29, 31, 23, 38, 35, 35, 11, 37, 37, 11, 37, 37, 16, 37,
         56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 83, 37, 28, 94, 11, 50, 37, 37, 85, 77, 24, 11, 85, 83,  2, 83,
          9, 31, 37,  9, 11, 85, 83, 37, 37, 94, 37, 49, 37, 88, 37, 37,  6, 37,
         29, 37, 50, 56, 11, 37, 37, 94, 37, 37, 35, 35, 56, 85, 83,  2, 37, 37,
          6, 85, 35, 49, 37, 37, 50, 50, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  9, 94, 37, 38, 35, 31, 37, 37, 28, 11, 37, 38, 85, 35, 31, 50, 34,
         24, 49, 49, 37, 37,  9, 49, 94, 37, 28,  9, 37, 11, 37, 85, 16, 31,  9,
         56, 37, 17, 37, 34, 56, 37, 37,  9, 11, 34, 37,  9, 56, 11, 49, 37, 59,
         50, 85,  2, 37, 37,  9, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:4'), 'lengths': tensor([55, 73, 60, 86, 57, 65, 63], device='cuda:4'), 'ntokens': 459}, 'target': tensor([[ 104,   83,   40, 6067, 2224,    6, 7881,    4,   60,  102,   32,  107,
          141, 1024,   28, 3160,   22,    4,  385,  105,   52,  467, 2776, 4191,
           49, 6281,   22, 7630,   44, 1196,  187,  406, 2249,   59, 1163, 3129,
         3701,   37,    4,  406,  772,   37, 2441,    4,   23, 2819, 1506, 1619,
            4,  406,  350,  587,  387,   37,    4,  406, 2294,   37,  507, 8203,
           20,    4,    9, 1635,  975, 1317,  158,   61,  493, 6134, 5284,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1562,   34, 1235,  335,  684, 7392,    4,   16,   41,  127,   36,  139,
            9, 5176,  237,    6,   15,    6, 3224,  362,  715,   22,  634, 1626,
            4,   82,    4,   50,   14, 4842,    4, 6728,    4, 2084, 1338, 4027,
         4438,   23, 9640,  129,  564,    5, 4535,   75, 1474,  844, 3178,  191,
            4,   16,   50,   32, 5215,  319,    4,    9,  118,  212, 3786,   15,
          590, 3512,   20,   23,  489,   28,  184, 2789,    4,    9,  628, 1652,
           56, 3952,   18,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 202, 2647,   41,   60,  198,  253,  698,  642, 1975,    4,  173,   61,
           23, 1664,   35,  592,  219,  176,  375,    4,   52, 3712, 2178, 2445,
          481, 8080, 1411,  271,  646,  198,   16,  771, 2441,    4, 1807,    5,
         1935,  649,   57,   93,  966,  240, 2003,    4,  602, 1935,   18,  911,
          265,  300,    6,  369, 2380,  866,   93,   23, 7203,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298, 1092,  411,  122,  387,    4,   30,   97, 2380,   81,  763,  300,
          398,  161,    4,  385,   36,  190, 2000,    4,   34,   49,   23, 1191,
           47,  177,  247, 1883,   27,  343,  742,    5,  592,    5,    9,  631,
           81,   14, 2999,  344, 4321,    6,    9,   14, 2999,  141, 2161,  424,
          412, 4739,  343,   19,  122,  235,   18,  408, 7613,   41,  163,   47,
         1791,   44,   72, 1627, 4321,   16, 5736,  411,   15,    4,  136,   29,
          190,   27,  921, 1746, 9466,    5,   68,  348,   65,   92, 1092,  411,
          122,  387,  161,  189, 1330, 8922,   16, 5565,    5,    2],
        [ 738, 1624,   49, 1426,    4,   14,   39,  151, 6423,   15,  623, 2548,
            4,  118,  664,   15,  532, 4544,  817,   51, 1903,    4,   39,  669,
          349,   37,  525,  128,    6,  330,   35, 4830,    6,   16, 5241,  709,
            6,   60, 7689, 2974, 5880, 2887,    4,   74,   14,  173,    4, 2526,
            4,   16,   43,  410, 1471,   75,  112, 2495,   20,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  361,   27,   14, 9012,   20, 1572,    4,  823,   78,   40, 7205,
          397,   30, 3389, 1640, 2717,  184, 1105,  543,  762,  130,   27,    9,
           23, 4904, 3617,   28,  309,  403,  751, 6094,   20, 3115,  124,  318,
         9123,  127,    5, 1493,   14, 3724,  891,  271,   28, 1209,  436,  234,
         3080,  634,   29, 5088,   27,   50,   43,   47, 1229,  385, 5437,  123,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146,  602, 4366, 1330, 2133,   15,   15, 2368,   57,  891,   15,  193,
           16,   31,  209,  761,  798,  397,  385, 5217,    4,   58, 5546,   28,
           51, 6153,   22,    4, 2799,   28, 1070, 3501,  962, 6647,   22,   28,
         8168,    4,   16,  209, 5009, 1217,  562,    9,  392,  382,  798, 2499,
          299, 5546,    6, 3395,   18,    4, 6075,   49, 5009, 1217,  562,   22,
          193, 3452,   28,  725,   34,  255,  375,  739,  814,   60,  536, 2368,
           57,  891,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'target_lengths': tensor([73, 77, 59, 94, 59, 62, 76], device='cuda:4'), 'ntokens': 500, 'nsentences': 7}
##################### {'id': tensor([ 86406, 169327, 136656, 159054, 188715,  47388, 143906, 212776,  24381,
        117948, 104768,  64591,  60325,  87370,  97978,  31705,  96780,  65443,
         39202,  95396,  47190,  67284, 165994, 222378, 107552,  57107, 139211,
         60033, 170166,  71025,  11178, 224234,  48879,  67983,  96877,  61455,
         24417, 169290, 153602,  37854, 155379, 224281,  45372,  15865, 106694,
        140005,  36136, 183229,  42154,  45623, 183382,  34338,  41051, 168838,
        101898, 178775,  33522, 149760, 103722, 160478, 133380, 202151, 140706,
         67465,  56392, 153286, 113584, 194192, 203893,  31795,  56213, 168566,
          9616, 170999, 102155, 161879, 127196,  92147, 221778, 119677],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[ 3.4180e-03,  5.0049e-03,  5.6152e-03,  ...,  6.4392e-03,
          8.4839e-03,  1.0345e-02],
        [-1.6785e-03, -1.4343e-03, -2.1973e-03,  ..., -3.6621e-04,
         -6.1035e-05, -1.2207e-04],
        [-1.7700e-03, -4.5776e-03, -4.6387e-03,  ..., -5.2185e-03,
         -4.1962e-02, -3.7781e-02],
        ...,
        [-6.9885e-03, -5.9204e-03, -4.3945e-03,  ...,  1.1719e-02,
          1.2024e-02,  0.0000e+00],
        [-2.9297e-03, -1.8616e-03,  1.2207e-04,  ..., -7.1411e-03,
         -6.7749e-03,  0.0000e+00],
        [ 8.5754e-03,  1.0132e-02,  8.6060e-03,  ...,  1.0803e-02,
          1.0651e-02,  0.0000e+00]], device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480, 28480,
        28480, 28480, 28480, 28479, 28479, 28479, 28479, 28479, 28479, 28479],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2, 6703,   83,  ...,    1,    1,    1],
        [   2, 1659, 1337,  ...,    1,    1,    1],
        [   2,  147,   81,  ...,    1,    1,    1],
        ...,
        [   2, 9578, 2004,  ...,    1,    1,    1],
        [   2,  104,  320,  ...,    1,    1,    1],
        [   2,   72,  280,  ...,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[1250,    4,   53,  ...,    1,    1,    1],
        [ 832, 1337,   22,  ...,    1,    1,    1],
        [  67,   25,  113,  ...,    1,    1,    1],
        ...,
        [  24,  278,    4,  ...,    1,    1,    1],
        [  24,  321,   12,  ...,    1,    1,    1],
        [  19,   11,   45,  ...,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[83, 11, 37,  ..., 37, 37, 37],
        [38, 35, 35,  ..., 37, 37, 37],
        [37, 37, 83,  ..., 37, 37, 37],
        ...,
        [38, 31, 11,  ..., 37, 37, 37],
        [38, 38, 37,  ..., 37, 37, 37],
        [38, 85, 35,  ..., 37, 37, 37]], device='cuda:6'), 'lengths': tensor([ 9, 11,  9, 12, 12, 11, 12, 12, 16,  8, 10, 10, 10, 11, 11, 12, 13, 11,
        11, 10,  9, 13, 15, 13,  7,  9, 11, 12, 15,  6,  7,  8, 10,  8,  9,  8,
         9, 11, 14, 13, 11,  8,  8, 19, 12,  9,  9,  6,  7, 14,  8, 12, 11, 11,
         9, 12, 10, 13, 10, 13,  7, 12, 11, 12, 13,  9, 12,  8, 13, 20,  8,  8,
         8,  6,  9, 11, 12, 11, 11, 12], device='cuda:6'), 'ntokens': 853}, 'target': tensor([[6703,   83,   43,  ...,    1,    1,    1],
        [1659, 1337,   22,  ...,    1,    1,    1],
        [ 147,   81,  769,  ...,    1,    1,    1],
        ...,
        [9578, 2004,   14,  ...,    1,    1,    1],
        [ 104,  320,  361,  ...,    1,    1,    1],
        [  72,  280,   30,  ...,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([ 9, 11,  8, 11,  8,  7, 13,  9, 18,  9, 12, 13, 12,  9, 11, 10, 11, 10,
        12, 11,  9,  9, 11, 12,  7,  9,  8, 14, 16,  7,  9,  9, 11, 11,  8,  9,
        10, 10, 11, 17, 18,  8,  8, 15, 12, 10,  8,  8,  9, 13,  8, 12, 12, 38,
        11,  9, 13, 17, 11, 11,  9, 11, 11,  8, 12,  9, 10, 11, 26, 21,  9, 11,
         9,  8, 11, 13, 11, 11, 12, 10], device='cuda:6'), 'ntokens': 905, 'nsentences': 80}
##################### {'id': tensor([ 46784,  41759, 199040,  89584,  81506,  34360, 204734, 164503],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[ 0.0034,  0.0027,  0.0009,  ..., -0.0052, -0.0052, -0.0038],
        [ 0.0073,  0.0083,  0.0068,  ...,  0.0049,  0.0054,  0.0042],
        [ 0.0035,  0.0029,  0.0019,  ...,  0.0075,  0.0101,  0.0087],
        ...,
        [-0.0011, -0.0014, -0.0010,  ...,  0.0006,  0.0014,  0.0021],
        [ 0.0025,  0.0018,  0.0012,  ...,  0.0003,  0.0003,  0.0003],
        [ 0.0008,  0.0020,  0.0015,  ..., -0.0038, -0.0034, -0.0031]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([233920, 233920, 233920, 233920, 233920, 233920, 233920, 233920],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,   99,   27,   40, 8744,   96, 8763,    4, 3368,   31,    4,   30,
         4947,   61, 4957,    4, 4947,  203,  181,  232,  622,  398,    4,   16,
           31,  705,    4,  105,  350,  539, 1597,   49, 2031,   16, 1407,   97,
         4052,  817,   27,   40, 2382,    4,   61,  102,   14, 1270,   52, 3712,
         3332,    6, 2729,   20, 7246,  145,    4,   16, 7546,   27,   40,  579,
          714,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  298,  173,  130,   81,   40, 1133,    4, 6176,   46,   16,   36,
          178, 1279,   49,  102, 3369,    9,   23, 4668,   46, 3950, 9075,  178,
           40, 4002,   22,  318,   16,   30, 4002,   22, 2053,   28, 3571,   15,
           16,  149,  114,   40, 6660,   60,   23,  947,   15, 2106,   54,  165,
           40, 1015,  649,   18,  695,   36,   28,  141, 3273,    4, 3823,   42,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  376, 5238,  262,  912, 7718,   49, 1437,   16, 7767,  182, 2898,
         5403, 1517, 2430,   16, 2578, 3262,   32,  337, 3024,   22,  912,  200,
         1040,    6,  750,   23,  698, 2284,  299, 3758,    5, 1135,   42,   72,
          705,   98,  462, 5798,    4,  302, 6987,   15,   16,  151,  576, 2342,
            6,   37,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  329,    4,   38,  967, 2669,   36,   49, 1162,  237,  803,
           98,  137,   41, 1457,    4,   38, 4122,  123,   47,  112,   30,  757,
           23, 2897,   97, 2206,   49,  141, 4348, 7671,   49, 1162,  237,  803,
           98, 9532,  137,  298, 6803,   31,  198, 6769,  118, 6072,   15,  404,
         1795,   16, 4669,  182, 1357, 1027,  119,  232,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,   82,  433,  257,   40, 9607, 3456,    5,   38, 2473,   31,
          329, 2642, 7764,   83,   41,   75,  428,  611, 4202,   42,   38, 3629,
          329, 2642,  437,  399,   90, 1041,    5,   38, 3629,  329, 2642,  228,
           23, 1401,   82,   30,  263,   40,  496,    4,  428,  114,   81,    9,
           23, 1401,   27,    4,  164,  686, 9607, 3456,  127,    5,   38, 3629,
          329, 2642,  147,   31,  788, 9607, 3456,  127,    5,   38, 2473,   95,
          329, 2642,  520,   31,    9,    6, 1439, 2855, 4688,  836,    4, 4611,
          256, 1938,   30,   47, 4334,    5],
        [   2,   72, 2069,   43,    4,   34,  355, 5502, 1156,    4,   16,   43,
          329,   44,   38, 8004,   41,    4,  454,  557,   31,  702,    4,  454,
          557,   31, 2437,    4,  136,   31,  209, 1078, 5502,  137,   41, 2101,
          387,   20,  285,   18, 1194, 3170,    4,   14,  295, 7668,  112,   14,
          397, 5937,  167, 2546,  184,  181,  683, 1630,  471,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 1173,  933,    5,   68,  431,   65,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  202, 1812,  653,    4,   50,   43,   75,   24, 1159,  191,    4,
         4042,  603,  469, 2224,    6,   28,   56, 3161,   59,   22,    4,  534,
           28,  851, 2148,  300,  272,    4,   34,  186,  503,    4,   16, 2800,
         2542, 1208,    4,   50,   43,   75,   60,  590,    6,  587, 2449,   15,
          124,  102,  377, 3160,   22,   49, 8431,  210,  337,  590,    6,  587,
         2449,   15, 1164, 4280,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[   8,   21,   11,    6,   13,   24,  237, 1355,   54, 1909,    4,   19,
          154,    4,    9, 8041,   12, 4972,    4, 3982,  366,   12, 4972,    4,
            8,   19,  154,   33, 5510,   12, 1102,  639,    8,  998,    9,    7,
         1136, 5055,   26,   39, 1909,  206,    7,  832,    5,    6,    5,   73,
          172,  305,   13, 5247, 2883,    4,    8, 7419,   26,   91,  663,    5,
            2,    1,    1,    1,    1,    1],
        [  29,  168,   25,   66,   13,  567,    4,   25,   66,  250,   46,    8,
           84, 1631,  227, 8263,   12,   17,  993,    9, 3804,   46,  185, 8829,
         2385,   39, 4312,   22,    4,    8,    7, 4312,   22, 3060,   96,   10,
         3793,    4,    8,  288,  120,   13, 6737,  925, 1585,   17,  188,    7,
          230, 1051,  174, 1991,  568,    7, 5250, 1085,    4, 1239,   42,    2,
            1,    1,    1,    1,    1,    1],
        [  84,  188,  226,   39, 2244,   48, 2080,  199, 2627,  106, 1146,    4,
          106, 5036,    4,   67, 5830, 2288,    4,    8,   77,   12,   13, 5827,
           24,  144,   33, 3024, 2244,    9,    7,  245, 1345,   12,   33,  464,
            5,  347,   42,   19,  154,   84,   63,  391, 2826,    4,  248,  535,
           35, 4935, 1649,    8,    7, 7678,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19,  246,    4,   38,  187,   11,  158,   87,   21,  106,  384,  237,
          803,  137,   53,  246,    4,   38,  469,   57,   11,    6,  211,  207,
           25,   11,   57,  142,   10, 6785,   13,  759, 6052,   35, 3481,  176,
           12, 2811,  839, 2202,    9,  384,  237,  803,  137,   29,    9, 6769,
            4,   19, 5016, 1222,   13, 6478,  244,  699,  411,    8, 3122,   10,
          264, 1027,  119,  232,    5,    2],
        [ 101,  246,    4,   38, 3127,   19,  692,   10,   51,   13, 2182,  684,
          137,    8,  101,  246,    4,   38,  200,  969,   19,  278,   10,    7,
         8459,  464,   12,  670,    4,   89, 3540,  465,   11,   18,  305,   21,
         6064,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19, 1060,  267,   80,  267, 3013,    4,    8,  225,  246,    4,   38,
         1969,  135,    4,  635,   19,   11,  158,  618,    4,  635,   19,   11,
          158,   14,    4,   67,   19,  192,   11,   18,   66,   13, 3013,  137,
          225,   34, 1922,  200,   54,   51, 1795, 2073,   18,    4,  166, 6121,
          267, 7150,  244,    7,  215,   10, 1393,  133, 1665,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 476,   25,    5,   68,  386,   65,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 101,  591,   17,   53,  162,   56, 8862,   10,  384, 1050,  140,   54,
            7, 7522,  469,   18, 1568,    4,   10, 9547,  945,   80,   70,  506,
           51,    4,    8,  101,  591, 1730,   17,   53,  465,   11,   18, 1799,
          238,   71, 6765, 1955,  109,  802, 6027,   69,  251, 6765, 1955,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 37, 85, 37, 37, 38, 35, 35, 49, 23, 11, 38, 59, 11, 37,  2, 37, 94,
         11, 29, 77, 37, 94, 11, 37, 38, 59, 37, 94, 37, 83, 94, 37, 94, 37, 37,
         28,  9, 85, 38, 23, 37, 37, 38, 11, 37, 11,  6, 83, 49, 37, 94, 94, 11,
         37, 28, 85, 50, 32, 11, 83, 37, 37, 37, 37, 37],
        [83, 37, 37, 85, 37, 32, 11, 37, 85, 50, 11, 37, 37, 85, 38, 83, 37, 37,
         32, 37, 94, 11, 50, 94, 49, 38, 28, 35, 11, 37, 37, 28, 35, 38, 77, 37,
         29, 11, 37, 83, 37, 37,  9, 85, 37, 37, 85, 37, 37, 38, 35, 94, 85, 37,
         94, 85, 11, 28, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 85, 85, 38, 29, 31, 94, 37, 28, 37, 28, 11, 37, 28, 11, 37, 83, 49,
         11, 37, 50, 37, 37, 83, 38, 85, 37,  2, 29, 37, 37, 83, 24, 37, 37, 24,
         11, 83, 11, 38, 59, 37, 85, 34, 56, 11, 34, 83, 38, 35, 50, 37, 37, 29,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 88, 11, 38, 35, 85, 35, 85, 37, 37, 38, 35, 35, 11, 37, 88, 11, 38,
         35, 77, 85, 37, 50, 83, 37, 85, 77, 49, 37, 49, 37, 24, 23, 38, 35, 35,
         37, 94, 32, 59, 37, 38, 35, 35, 11, 83, 37, 25, 11, 38, 31, 37, 37,  2,
         37, 35, 35, 37, 31, 37,  2, 35, 75, 77, 11, 83],
        [38, 88, 11, 38, 35, 38, 85, 37, 38, 37,  9, 35, 11, 37, 38, 88, 11, 38,
         35, 77, 38, 31, 37, 37,  2, 24, 37, 94, 11, 37, 56, 85, 85, 35, 49, 37,
         83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 37, 37, 37, 88, 11, 37, 37, 88, 11, 38, 37, 59, 11,  6, 38, 85,
         35, 49, 11,  6, 38, 85, 35, 38, 11, 37, 38, 85, 85, 35, 85, 37, 88, 11,
         37, 85, 38, 35, 49, 38, 77, 38, 35, 11, 37, 31, 37, 56, 37, 37, 24, 37,
         40, 83, 38, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 11, 38, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 37, 37, 85, 38,  2, 37, 38, 35, 35, 49, 37, 38, 35, 35, 28, 11,
         37, 29, 77, 37, 50,  6, 38, 11, 37, 38, 31, 83, 37, 37, 85, 85, 35, 49,
         83, 37,  2, 44, 37, 49, 94, 37, 50,  2, 44, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:6'), 'lengths': tensor([61, 60, 56, 66, 39, 59,  7, 49], device='cuda:6'), 'ntokens': 397}, 'target': tensor([[  99,   27,   40, 8744,   96, 8763,    4, 3368,   31,    4,   30, 4947,
           61, 4957,    4, 4947,  203,  181,  232,  622,  398,    4,   16,   31,
          705,    4,  105,  350,  539, 1597,   49, 2031,   16, 1407,   97, 4052,
          817,   27,   40, 2382,    4,   61,  102,   14, 1270,   52, 3712, 3332,
            6, 2729,   20, 7246,  145,    4,   16, 7546,   27,   40,  579,  714,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 298,  173,  130,   81,   40, 1133,    4, 6176,   46,   16,   36,  178,
         1279,   49,  102, 3369,    9,   23, 4668,   46, 3950, 9075,  178,   40,
         4002,   22,  318,   16,   30, 4002,   22, 2053,   28, 3571,   15,   16,
          149,  114,   40, 6660,   60,   23,  947,   15, 2106,   54,  165,   40,
         1015,  649,   18,  695,   36,   28,  141, 3273,    4, 3823,   42,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 376, 5238,  262,  912, 7718,   49, 1437,   16, 7767,  182, 2898, 5403,
         1517, 2430,   16, 2578, 3262,   32,  337, 3024,   22,  912,  200, 1040,
            6,  750,   23,  698, 2284,  299, 3758,    5, 1135,   42,   72,  705,
           98,  462, 5798,    4,  302, 6987,   15,   16,  151,  576, 2342,    6,
           37,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  329,    4,   38,  967, 2669,   36,   49, 1162,  237,  803,   98,
          137,   41, 1457,    4,   38, 4122,  123,   47,  112,   30,  757,   23,
         2897,   97, 2206,   49,  141, 4348, 7671,   49, 1162,  237,  803,   98,
         9532,  137,  298, 6803,   31,  198, 6769,  118, 6072,   15,  404, 1795,
           16, 4669,  182, 1357, 1027,  119,  232,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,   82,  433,  257,   40, 9607, 3456,    5,   38, 2473,   31,  329,
         2642, 7764,   83,   41,   75,  428,  611, 4202,   42,   38, 3629,  329,
         2642,  437,  399,   90, 1041,    5,   38, 3629,  329, 2642,  228,   23,
         1401,   82,   30,  263,   40,  496,    4,  428,  114,   81,    9,   23,
         1401,   27,    4,  164,  686, 9607, 3456,  127,    5,   38, 3629,  329,
         2642,  147,   31,  788, 9607, 3456,  127,    5,   38, 2473,   95,  329,
         2642,  520,   31,    9,    6, 1439, 2855, 4688,  836,    4, 4611,  256,
         1938,   30,   47, 4334,    5,    2],
        [  72, 2069,   43,    4,   34,  355, 5502, 1156,    4,   16,   43,  329,
           44,   38, 8004,   41,    4,  454,  557,   31,  702,    4,  454,  557,
           31, 2437,    4,  136,   31,  209, 1078, 5502,  137,   41, 2101,  387,
           20,  285,   18, 1194, 3170,    4,   14,  295, 7668,  112,   14,  397,
         5937,  167, 2546,  184,  181,  683, 1630,  471,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1173,  933,    5,   68,  431,   65,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 202, 1812,  653,    4,   50,   43,   75,   24, 1159,  191,    4, 4042,
          603,  469, 2224,    6,   28,   56, 3161,   59,   22,    4,  534,   28,
          851, 2148,  300,  272,    4,   34,  186,  503,    4,   16, 2800, 2542,
         1208,    4,   50,   43,   75,   60,  590,    6,  587, 2449,   15,  124,
          102,  377, 3160,   22,   49, 8431,  210,  337,  590,    6,  587, 2449,
           15, 1164, 4280,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([62, 60, 51, 57, 90, 58,  7, 65], device='cuda:6'), 'ntokens': 450, 'nsentences': 8}
##################### {'id': tensor([112216,   3189, 209953, 111461, 105179,  49474, 210498,  44521,  82174,
         13754,   8908,  32837,  21610,  44265,   7828, 204941,  69633, 188803,
        165115, 171427,  76634, 159202, 112091, 120402, 178087,  40692,   7664,
         73079,   2812, 130028, 104459,  72213,  69877, 212645, 212650,   7127,
        223204, 102959, 212644, 208365,   9552,   4241, 135799, 219940, 217980,
        139412, 187167,  42367, 163604, 149884, 114977,   7184, 121232, 135551,
        189119,  43714, 134363, 124811, 133419,  63282,  75240,  54846, 100406,
         49265], device='cuda:3'), 'net_input': {'src_tokens': tensor([[ 1.7700e-03,  2.0142e-03,  2.0447e-03,  ...,  4.0161e-02,
          4.1687e-02,  2.4384e-02],
        [-3.3569e-03, -6.7444e-03, -4.0588e-03,  ..., -6.3782e-03,
         -5.5237e-03, -5.5542e-03],
        [-4.8828e-04, -7.3242e-04, -1.0376e-03,  ..., -6.1035e-05,
          7.3242e-04,  2.4719e-03],
        ...,
        [-1.5564e-02, -2.7649e-02,  1.6907e-02,  ...,  0.0000e+00,
          1.7700e-03,  0.0000e+00],
        [-6.7139e-04, -4.2725e-04, -4.2725e-04,  ..., -1.8219e-02,
         -1.9745e-02,  0.0000e+00],
        [ 8.7280e-03,  5.3406e-03,  3.5095e-03,  ...,  6.3110e-02,
          6.3110e-02,  0.0000e+00]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360,
        35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360,
        35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360,
        35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360,
        35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360, 35360,
        35360, 35360, 35360, 35360, 35360, 35360, 35360, 35359, 35359, 35359,
        35359, 35359, 35359, 35359], device='cuda:3'), 'prev_output_tokens': tensor([[   2,  147,   41,  ...,    1,    1,    1],
        [   2,  460,   27,  ...,    1,    1,    1],
        [   2,  327,   78,  ...,    1,    1,    1],
        ...,
        [   2,  298,  123,  ...,    1,    1,    1],
        [   2, 4769,   37,  ...,    1,    1,    1],
        [   2,  222,  316,  ...,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[  67,   25,  296,  ...,    1,    1,    1],
        [  84,   11,    6,  ...,    1,    1,    1],
        [  29,   70,  321,  ...,    1,    1,    1],
        ...,
        [  29,   24,   73,  ...,    1,    1,    1],
        [ 229, 1118,   63,  ...,    1,    1,    1],
        [ 103,   25,   11,  ...,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 37, 49,  ..., 37, 37, 37],
        [37, 85, 37,  ..., 37, 37, 37],
        [83, 50, 38,  ..., 37, 37, 37],
        ...,
        [83, 38,  6,  ..., 37, 37, 37],
        [49, 56, 85,  ..., 37, 37, 37],
        [37, 37, 85,  ..., 37, 37, 37]], device='cuda:3'), 'lengths': tensor([ 9,  9, 13, 11, 14, 10, 12, 14, 15, 10, 13, 13,  8, 18, 11, 17, 18, 14,
        17, 12, 13, 11,  7, 14,  7, 12, 13, 13, 15, 10, 12, 14, 13,  9, 10, 11,
        12, 14, 11, 12, 15, 10, 11, 11, 13,  9, 10, 11, 15, 13,  7, 15, 15, 13,
         8, 15, 13, 20,  7, 16, 14, 13,  7, 13], device='cuda:3'), 'ntokens': 785}, 'target': tensor([[ 147,   41,  309,  ...,    1,    1,    1],
        [ 460,   27,   29,  ...,    1,    1,    1],
        [ 327,   78,   52,  ...,    1,    1,    1],
        ...,
        [ 298,  123,   32,  ...,    1,    1,    1],
        [4769,   37,   83,  ...,    1,    1,    1],
        [ 222,  316, 1421,  ...,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([ 9,  9, 13, 10, 12, 10, 13, 12, 16, 11, 15, 15,  9, 13,  7, 32, 17, 12,
        13,  7, 14,  9,  8, 15,  7, 11, 14, 15, 15, 14, 12, 16, 17,  7, 11, 14,
        11, 11,  8, 10, 18,  6, 12, 14, 12,  7, 16, 17, 22, 14,  7, 17, 12,  9,
         8, 14,  9,  7,  9, 14, 11, 13,  7, 16], device='cuda:3'), 'ntokens': 785, 'nsentences': 64}
##################### {'id': tensor([182787, 220212, 188402, 166499,  13497, 201495,  42518, 136838, 108926,
        162163, 195786, 172518,  10468,   6323,  89756,  15996],
       device='cuda:3'), 'net_input': {'src_tokens': tensor([[-0.0019,  0.0036,  0.0044,  ...,  0.0119,  0.0084,  0.0025],
        [ 0.0023,  0.0016,  0.0010,  ..., -0.0019, -0.0017, -0.0029],
        [ 0.0013,  0.0020,  0.0034,  ..., -0.0052, -0.0067, -0.0065],
        ...,
        [-0.0069, -0.0053, -0.0032,  ...,  0.0003, -0.0004,  0.0000],
        [ 0.0034, -0.0009, -0.0078,  ...,  0.0217,  0.0306,  0.0000],
        [ 0.0396,  0.0569,  0.0452,  ...,  0.0121,  0.0105,  0.0000]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([108320, 108320, 108320, 108320, 108320, 108320, 108320, 108320, 108320,
        108320, 108320, 108320, 108320, 108319, 108319, 108319],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,  228,  328,  965, 3889,   15,   32,  118,  553,  483,  748,    4,
          594,  208,    4,  403,   31,   30,  947,  334,  145,    4,   40, 1052,
          300,    6, 5296, 3685,  219,  303, 8368, 1350,    6, 1483,  241,  240,
         2175,  249,    5,    1,    1,    1],
        [   2,  376, 1207,   22,  195,   37,  129,  553,  249,  781, 1158,  239,
            9, 2825, 2950,  175,  290, 1338,    4,   60,  151,  553, 1055,   35,
         1007,  762,    4,   58,   32,  382,  844,  299, 4535, 4351,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 6943, 7210,   31,   47,   39,   23,  304,  932,    6,   20,  845,
            4,  118, 1612,    6, 2976,    4,  124,   40, 3305, 7128,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,  471,  433, 3469,  790,  236,   56, 4274,   20, 6793,   15,
          153, 9493,   22,    4,   14, 1130, 1596,  253,  633,  200,  683,  588,
         1391,   15,    5,   64,  189,   82,  374,    9,  151,  421,   59,  152,
         2879,  962, 1087,   95, 7910,    5],
        [   2, 8035, 7295,   31,  113,  173,    4,  791,   18, 6054, 4688, 1854,
          564,  957, 1132,    4,   16,   30,  730,    4,   16,   32, 1496,    4,
           50,   36,  621,   38, 1689,  197,  178,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  449,   14, 7163,   22, 7408,   29, 4832, 1302,  418,  226,
          303,    4,   47,  149,    4,  268,   30, 3338, 5856,  156, 1753,   15,
           76,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 1952,   41,   75,   36,   90,   52, 2270,  777,   37,   48,  219,
           22,  375,  799, 2546,  272,  262, 5738,   49, 3259, 3985,   15, 6130,
          177,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  915,    4,  114,   31,   36,  644, 3468,  459, 2097,   20,
            4,  503,   31,   51, 2617,    4,   50,   31,  924, 1213,   47,  263,
         1052,    6,   93,  311,  625, 5467,  313,    4,   50,   30, 5399,   40,
         3786,   37, 2692,   82,    5,    1],
        [   2,  228,  328,  965, 3663,   36,   75,   88,  118, 5820, 5716,  369,
            9, 4799, 1488,  603,   57,   61,  105, 2864,  349,  389,   20,   35,
          360, 1996,   57,   35, 3484,  531,  160, 1304,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64, 3627, 5180,   27,   40,  167, 3081,  580,  129, 4507, 2019,
            6,   16,   32, 9115,  273, 3216,    4, 3659,   97, 6840,   22,   28,
         2229,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  633,   23,  351, 1100,   83,   32, 2089,    4,   14,   97, 6559,
           28, 1474, 7708,  118, 5641, 3125, 3116,   83,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 1186,   22, 3605, 5586,  130, 1078, 1030, 1271, 2315,  364, 5801,
            4,   36, 1156,  428,  223,  377, 4946,    6, 2194,    5, 2609, 2774,
           32,  216,  534,  320,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  526,    4,   14,  331,  353,  129, 8137,  243,   57, 1172, 5621,
           96,   27,   23,  437, 1604,  249,   37,   35,  360,   18, 5854, 1825,
         1158,    4,   16,  105, 5617, 4934,  437,  375, 1172, 1333,  786,   18,
          242, 2478,  418,    5,    1,    1],
        [   2, 7571,  944,   32,   52,  734, 6616,  129,  496, 6154,    6,    4,
           47,  149,   23,  496,  352,  458,  494,  165,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64,  299, 4427,  239,   49,  377, 1034,  502,   95,  200,  240,
          739,    5,  460, 1637,  161,   95,  217,  844,  924,  671,   83,    4,
          428,   36,  161,  171, 1050,   22,  381,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  400,   51, 4065,   81,  136,   14, 5818,  878,    6,  369,   23,
          773,  380,  900, 1249,  210,    4,  750,   81,   30, 2451,   97, 4156,
         4107,   42,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[   9,   33, 1760, 1165,    4,   24,  162,  802,   13, 2270,   45,    4,
          109,    4,  339,  110,  116,  150,  103,   19,   73,  175,   33, 4481,
            4,   13, 9238,  217, 1076, 5997,   56, 8368,  922, 2806,  240, 2175,
          249,    5,    2],
        [   7,  225,  158,   12,    7, 1052,  249,  781, 1158,   34,  561,   48,
          199, 1580, 6032,   85,   13, 2290,   17,   24,   11,   57, 2438,   54,
          131,    7,  467,   12,   33, 1910,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [   8,    9,  251, 1113,    4,   19, 1608,   11,   18,  283,   69,    7,
         6389, 6035,    4,   19, 1608,   11,   18, 1927,   13, 4446,  109, 2618,
           39, 5651,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  24,  144,    7, 1666,  941,   35, 9748,  688, 9372,    6,   17,  842,
          785, 1601,   10,   82,   45,  132,    8,  180,   25,  162,  859,  665,
           13,  321,   12, 4594,  111, 1650,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [  29,    4,   77,   12,   13, 5827,    4,  168,   19,  217,    4, 6815,
          241,  829,  106,  747,  670,    9,  564,  957, 1132,    4,    8,   33,
         1148,    4,    8,   24, 2252,   17,   38,  290, 1408,  197,  513,  755,
            5,    2,    1],
        [   7, 1043,   19,   11,   45,   29, 7105,   80,  467,   54, 3753, 3023,
         1382,   11,   18,  116,  125,   21,   11,    6,  999, 3023,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  29,    4,  154,   80,   21,   79,   13, 1780,   35,   18, 1397,    4,
         1523, 1909,   12,  294, 2386,   12, 1655,   12, 2602,    4,  166,   26,
         2546,  829,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  19, 1831,   17,  103,   19,  220, 3665,  929, 7897,    4,   19,  220,
         4075,   17,    4,  432,   77,    4,   19, 1359,   11,   18,  172, 2702,
          111,   19,  158,    4,   21,   34,  185, 4416, 4113,    5,    2,    1,
            1,    1,    1],
        [  29,    9,   33, 1165,    4,   21,   11,    6,   39, 1663, 1039,  369,
           55, 2327, 1034,  240,   20,   69,  117, 4601,  825, 3275,   35, 3794,
         2885,    6,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   56, 3168, 2445,   93,   11,    6,   13,  133,  528,  461,   12,
            7, 9655,    8,   24, 5150,  108, 1613,   10,  274,    9, 1820,   55,
         4455,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,   69,    7,  218,  874,    4,   24,   66, 1075,   17,   63,
          244,  737,  891,   54,   69,  837, 2694, 5955,   10,  159, 6768,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [2072,  988,   26,  250,   17,  689,   11,   18,  100,   10, 2895,  133,
          261,    4, 3706,  359, 7036,    4,    8,   12,  538,   24,  169,  100,
           10, 1082,  143,   80,   21,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,    7,  218, 2475,   12,   81,   18,  340, 8978,   26,    7,
          227,  424,    6,  560, 5824,  424, 1825, 1158,    4,    8,  117, 1816,
          985,  132,  227,  760,  233,    6,   55,   13, 1074,    5,    2,    1,
            1,    1,    1],
        [1980, 1068,    4,   24,  296,   13,  574,  833,   12,  524,   35, 1105,
          505,   54,    4,   86,  116,  524,   35, 5001, 3635,  833,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   33,   34, 2861,   62,  131,   39,  786,  727,   46,  166,   26,
          100,    4, 1730,    9,    7,  467,    4,  101,  164,   86,   66,  995,
            4,  125,   21,  164,  417,  827,  603, 1906,    5,    2,    1,    1,
            1,    1,    1],
        [ 138,   87,   25, 1005,    7,  909,  609,    6,  369,   12,    7, 2018,
         2510,  429,   12,    7, 1683,  724, 1025, 6433,   54,    7, 8094,  429,
           12,    7, 1478,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 37,  2, 32, 11, 38, 85, 49, 37, 38, 35, 11, 37, 11, 49, 37, 83, 59,
         37, 38,  6, 85, 37, 83, 11, 37,  9, 38, 35, 23, 38, 35, 31, 38, 35, 77,
         77, 11, 83],
        [37, 37, 35, 37, 37, 38, 77, 35, 35, 85,  9, 31, 37,  9, 35, 37, 37, 38,
         37, 38, 85, 77, 88, 49, 37, 37, 38, 37, 37, 24, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 50, 24, 11, 38,  6, 85, 35, 49, 37, 37, 23, 29, 11, 38,  6, 85,
         35, 49, 37,  9, 37,  8, 38,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 37, 83, 94, 38,  2,  9, 94, 37, 37, 31, 34, 24, 37, 53, 35, 37,
         37, 37, 37, 85, 31, 59, 37, 38, 37,  2, 83, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 50, 37, 37, 83, 11, 37, 38, 38, 11, 23, 35, 49, 37, 30, 94, 37,
         34, 73, 73, 11, 37, 37, 85, 11, 37, 38, 86, 37, 38, 35, 35, 82, 85, 37,
         11, 83, 37],
        [37, 32, 38, 85, 35, 83,  2, 37, 38, 49, 28, 94, 85, 85, 35, 83, 37, 37,
         85, 37,  2, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 59, 37, 37, 37, 37,  9, 38, 35, 35, 11,  2, 23, 37, 50, 34, 37,
         24, 37, 24, 11, 37, 85, 38, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 31, 37, 37, 38,  6, 49, 50, 94, 11, 38,  6, 88, 37, 11, 37, 50, 11,
         38, 85, 85, 35, 83, 87, 83, 38, 35, 11, 37, 85, 50,  2, 32, 11, 83, 37,
         37, 37, 37],
        [83, 37, 37, 32, 11, 37, 85, 37, 38, 37, 32, 44, 37, 38, 35, 35, 77, 37,
         37,  2, 24,  9, 38,  4,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 35, 35, 35, 85, 37, 37, 83,  2, 32, 37, 37,  9, 37, 38, 29, 37,
         56, 37, 59, 37, 35, 37,  1, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 37, 37, 50, 38, 11, 38, 85, 56, 37, 85, 37, 35, 35, 49, 37, 28,
         32, 36, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [ 2, 23, 85, 50, 37, 85, 85, 35, 37, 37, 36, 83, 83, 11, 83, 37, 94, 11,
         37, 37, 83, 38, 85, 37, 37, 59, 50, 37, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 37, 50, 38, 37, 38, 35, 35,  9, 85, 37, 38, 35, 37, 35, 38, 35,
         35, 35, 11, 37, 37, 56,  2, 37, 38, 35, 35, 37, 37, 37, 49, 11, 83, 37,
         37, 37, 37],
        [38, 35, 11, 38, 49, 37, 38, 35, 37, 32, 38, 35, 35, 49, 11, 83, 83, 32,
         38, 35, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 85, 49, 31, 37, 38, 35, 35, 11, 37, 85, 37, 11, 83, 37, 37, 38,
         11, 38, 85, 83, 85, 50, 11, 37, 37, 85, 38, 35, 35, 77, 11, 83, 37, 37,
         37, 37, 37],
        [37, 85, 37, 49, 37, 38, 35, 37, 44, 37, 37, 38, 89, 94, 37, 37, 32, 35,
         24, 49, 49, 37, 94, 94, 37, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:3'), 'lengths': tensor([39, 32, 28, 32, 38, 24, 28, 35, 28, 27, 25, 31, 35, 24, 34, 29],
       device='cuda:3'), 'ntokens': 489}, 'target': tensor([[ 228,  328,  965, 3889,   15,   32,  118,  553,  483,  748,    4,  594,
          208,    4,  403,   31,   30,  947,  334,  145,    4,   40, 1052,  300,
            6, 5296, 3685,  219,  303, 8368, 1350,    6, 1483,  241,  240, 2175,
          249,    5,    2,    1,    1,    1],
        [ 376, 1207,   22,  195,   37,  129,  553,  249,  781, 1158,  239,    9,
         2825, 2950,  175,  290, 1338,    4,   60,  151,  553, 1055,   35, 1007,
          762,    4,   58,   32,  382,  844,  299, 4535, 4351,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [6943, 7210,   31,   47,   39,   23,  304,  932,    6,   20,  845,    4,
          118, 1612,    6, 2976,    4,  124,   40, 3305, 7128,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,  471,  433, 3469,  790,  236,   56, 4274,   20, 6793,   15,  153,
         9493,   22,    4,   14, 1130, 1596,  253,  633,  200,  683,  588, 1391,
           15,    5,   64,  189,   82,  374,    9,  151,  421,   59,  152, 2879,
          962, 1087,   95, 7910,    5,    2],
        [8035, 7295,   31,  113,  173,    4,  791,   18, 6054, 4688, 1854,  564,
          957, 1132,    4,   16,   30,  730,    4,   16,   32, 1496,    4,   50,
           36,  621,   38, 1689,  197,  178,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  449,   14, 7163,   22, 7408,   29, 4832, 1302,  418,  226,  303,
            4,   47,  149,    4,  268,   30, 3338, 5856,  156, 1753,   15,   76,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1952,   41,   75,   36,   90,   52, 2270,  777,   37,   48,  219,   22,
          375,  799, 2546,  272,  262, 5738,   49, 3259, 3985,   15, 6130,  177,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  915,    4,  114,   31,   36,  644, 3468,  459, 2097,   20,    4,
          503,   31,   51, 2617,    4,   50,   31,  924, 1213,   47,  263, 1052,
            6,   93,  311,  625, 5467,  313,    4,   50,   30, 5399,   40, 3786,
           37, 2692,   82,    5,    2,    1],
        [ 228,  328,  965, 3663,   36,   75,   88,  118, 5820, 5716,  369,    9,
         4799, 1488,  603,   57,   61,  105, 2864,  349,  389,   20,   35,  360,
         1996,   57,   35, 3484,  531,  160, 1304,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  64, 3627, 5180,   27,   40,  167, 3081,  580,  129, 4507, 2019,    6,
           16,   32, 9115,  273, 3216,    4, 3659,   97, 6840,   22,   28, 2229,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 633,   23,  351, 1100,   83,   32, 2089,    4,   14,   97, 6559,   28,
         1474, 7708,  118, 5641, 3125, 3116,   83,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1186,   22, 3605, 5586,  130, 1078, 1030, 1271, 2315,  364, 5801,    4,
           36, 1156,  428,  223,  377, 4946,    6, 2194,    5, 2609, 2774,   32,
          216,  534,  320,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 526,    4,   14,  331,  353,  129, 8137,  243,   57, 1172, 5621,   96,
           27,   23,  437, 1604,  249,   37,   35,  360,   18, 5854, 1825, 1158,
            4,   16,  105, 5617, 4934,  437,  375, 1172, 1333,  786,   18,  242,
         2478,  418,    5,    2,    1,    1],
        [7571,  944,   32,   52,  734, 6616,  129,  496, 6154,    6,    4,   47,
          149,   23,  496,  352,  458,  494,  165,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  64,  299, 4427,  239,   49,  377, 1034,  502,   95,  200,  240,  739,
            5,  460, 1637,  161,   95,  217,  844,  924,  671,   83,    4,  428,
           36,  161,  171, 1050,   22,  381,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 400,   51, 4065,   81,  136,   14, 5818,  878,    6,  369,   23,  773,
          380,  900, 1249,  210,    4,  750,   81,   30, 2451,   97, 4156, 4107,
           42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([39, 35, 23, 42, 32, 26, 26, 41, 33, 26, 21, 29, 40, 21, 32, 26],
       device='cuda:3'), 'ntokens': 492, 'nsentences': 16}
##################### {'id': tensor([ 78102, 212988, 174058, 196891,  59137, 219765,  62090, 187860, 206294,
        205791, 179307, 129915,  12876,  15161, 158880, 158866,  66165, 156593,
         42641,  38197,  81490,  53504,  24359,  66525, 104383,  12295, 175030,
        115870, 193549, 159840,  90711, 188742, 131582, 105638,  14446,  52894,
         64716, 203111, 126685, 127324, 210971,  78854, 100186,  99447, 100946,
        164489, 153836, 100436], device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 2.4414e-04,  3.0518e-04,  4.2725e-04,  ..., -6.1035e-05,
         -8.5449e-04, -2.4414e-04],
        [-9.9487e-03, -1.0895e-02, -1.1658e-02,  ...,  2.8687e-03,
          2.7161e-03,  2.2583e-03],
        [-4.2419e-03, -1.5564e-03,  1.7090e-03,  ..., -4.6387e-03,
         -6.6833e-03, -7.7209e-03],
        ...,
        [-4.2725e-04,  1.2207e-04,  7.9346e-04,  ...,  2.8076e-03,
          1.6785e-03,  0.0000e+00],
        [-5.8594e-03, -8.1482e-03, -8.1482e-03,  ...,  2.6855e-03,
          2.9297e-03,  0.0000e+00],
        [ 9.7656e-04,  3.3264e-03,  4.1809e-03,  ...,  2.8381e-03,
         -3.9368e-03,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360,
        47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360,
        47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360,
        47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47360, 47359,
        47359, 47359, 47359, 47359, 47359, 47359, 47359, 47359],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2,   41,  145,  ...,    1,    1,    1],
        [   2,  202,  876,  ...,    1,    1,    1],
        [   2, 1084,  754,  ...,    1,    1,    1],
        ...,
        [   2, 1647,   76,  ...,    1,    1,    1],
        [   2,  504,   76,  ...,    1,    1,    1],
        [   2,   64,   30,  ...,    1,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[ 225,    4,  509,  ...,    1,    1,    1],
        [ 101,  876,  140,  ...,    1,    1,    1],
        [1979,  265,   44,  ...,    1,    1,    1],
        ...,
        [ 109,   63,   24,  ...,    1,    1,    1],
        [ 117,   63, 4700,  ...,    1,    1,    1],
        [   8,   33,  321,  ...,    1,    1,    1]], device='cuda:2'), 'cluster_tokens': tensor([[37, 11,  2,  ..., 37, 37, 37],
        [38, 38, 35,  ..., 37, 37, 37],
        [38, 35, 82,  ..., 37, 37, 37],
        ...,
        [37, 85, 38,  ..., 37, 37, 37],
        [37, 85,  9,  ..., 37, 37, 37],
        [37, 37, 38,  ..., 37, 37, 37]], device='cuda:2'), 'lengths': tensor([14, 12, 18, 10, 15, 16, 11, 12, 18, 11, 13, 17, 11, 18,  9, 13, 12, 24,
        19, 14, 20, 21, 20, 17, 15, 18, 19, 24, 10, 15, 10, 13, 18, 14, 10, 15,
        15, 17, 19, 22, 19, 17, 17, 18, 18, 14, 12, 12], device='cuda:2'), 'ntokens': 746}, 'target': tensor([[  41,  145,  153,  ...,    1,    1,    1],
        [ 202,  876,  622,  ...,    1,    1,    1],
        [1084,  754,   44,  ...,    1,    1,    1],
        ...,
        [1647,   76,   32,  ...,    1,    1,    1],
        [ 504,   76, 1432,  ...,    1,    1,    1],
        [  64,   30,  173,  ...,    1,    1,    1]], device='cuda:2'), 'target_lengths': tensor([15,  9, 21, 26, 19, 20, 13, 11, 22, 13, 13, 16, 10, 15, 13, 14, 15, 25,
        16, 15, 20, 29, 20, 18, 15, 19, 21, 22, 10, 19, 13, 11, 19, 24, 12, 18,
        18, 14, 21, 21, 17, 17, 16, 18, 22, 15, 12, 11], device='cuda:2'), 'ntokens': 813, 'nsentences': 48}
##################### {'id': tensor([199567,  14546,  63043,  25869, 223009,  81190, 186550, 176464],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[-3.1128e-03, -9.4604e-04,  9.1553e-05,  ...,  9.4604e-04,
         -2.7466e-03, -5.8594e-03],
        [ 2.7527e-02,  3.8696e-02,  4.4464e-02,  ...,  1.1169e-02,
          1.0773e-02,  1.2421e-02],
        [ 6.1035e-05,  3.3569e-04,  2.7466e-04,  ...,  7.0190e-04,
         -2.1362e-04, -1.0986e-03],
        ...,
        [ 2.1362e-03,  1.8921e-03,  1.2207e-03,  ...,  2.6550e-03,
          4.8828e-03,  4.5776e-03],
        [-1.0681e-03, -1.0376e-03, -7.9346e-04,  ...,  1.7090e-03,
          3.3569e-04,  0.0000e+00],
        [-1.4343e-03, -1.2817e-03, -9.7656e-04,  ..., -1.1292e-03,
         -7.0190e-04,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([196320, 196320, 196320, 196320, 196320, 196320, 196319, 196319],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2,  677, 3170,   22,   41,  728,   40, 2979,    6,  496, 2186,    4,
          269,   41, 5843,  302,  326,   44,  520, 6242,    6, 2228, 1418,   41,
          299,  496,    9,  405, 5163, 5303,    4, 3377,   41,   14, 5163, 5303,
         8533,  123,  224,   90, 2328, 1485, 3230,   41,   14, 5163, 5303,  393,
          466,    4,   88,  118, 1442, 5322,   28,   56, 2843,    5],
        [   2,  104,  681,   29,  190,  350, 1188, 1485,  632,  260,    5,  147,
           46,  981, 1548,    6, 2498,   32,  653,    4,   50,  114,   32,   43,
          231,   61, 6496,   15,   16,  109,   48, 1430,   15,    4,   14,  731,
          310, 1657,  112,  539, 5619,   15,    4,    9, 4613, 9490,   43,  184,
         1124, 1430,  186,  776,    5,    1,    1,    1,    1,    1],
        [   2,   64,   14, 1463,   27,   44, 1581, 4647,   20, 7914,   43,   75,
            4,  423,  212, 8613,  804,  959,   20, 2004,  112,   14, 4541,   59,
          407, 1342, 2968, 2052,  327, 4280,  105,  157,   60,  102, 1083,  757,
            4,   30,   43, 6364,   15,   42,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 7905,   16, 3969,  584,   76,   52, 4365,   46,   68,  431,   65,
           46,  136,    9,  536, 4396,   23,  201,    4,   83,   32,  231, 1468,
         1946,   37, 6376,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   32, 7214,   15,  118, 1030, 4519,  657, 1411,   20,  234,
           78,  107,    4,   23,   29, 2733,   82,    4,   50,   95,   40, 2062,
          182, 5012, 2398,   59, 2241, 3839,  153,    4,   88,   14,  472,   22,
           18,  541,  233, 1182,   23, 8995, 6092,   28, 4096,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,   27,   40, 1538,   29,    4,   90, 1602,   41,  118, 2151,
            9, 7546,   16,  681,  189,  182,  612,    5, 9891,  171, 2491,    4,
           16, 1001, 3408,   27,   47, 5090,  477,    4,  428,   41,  309,   30,
         4121,   18, 1026,  307, 5580,   16,   76, 2600, 8142,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  738,  187,  662, 9459,   20,   83,   28,  736,  950,   14, 2255,
         2039,   16,   28,  736,  950, 2255, 3004,    5, 2328, 2037,  662, 9459,
           20, 2337,  736,  950,  805, 2039,    4,  136,    4,   74,  331, 9426,
          139,    4,  149,  655,  950,  805, 3004,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99, 1492,  543,  392, 7484,    5,  978, 2944,    6, 1803,   15,
            5,  400,  210, 1142, 1444, 3984,  836,   23,  441,  989,  466,   16,
         9069,   20,  112, 1442, 2706,  491,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2')}, 'transcript': {'tokens': tensor([[   7,  245,   91,   26,    4,   25,  305,   17,  524, 4474,  199,   21,
            6,  523,    6,    8, 3675,   29,   17,   25,   73, 5382, 7394,  251,
          523,    6,    8, 3675,    4,    8,  180,   12,  538,   25,   87,    7,
          744,  461,    5,   25,  388,   77,   12,  117,  523,    6,    8, 3675,
          270,  540,  554,   10,  367,   10,  155, 7034,    5,    2],
        [  24,  169,  492,   87,  860,   13, 3310,  279,    4,   67,   46,    9,
          419, 1165,    4,   24,  591,  103,   24,  116, 1223, 2396,  134,   77,
          346,    8, 1296,   62,  134,    4,   17,  281,   94,  169,  204, 2990,
           70,    7, 1296,   54,  451,   51,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,    7, 1141,   26, 1111, 6504,    6,    5,    8, 1008,    4,  423,
           12,  117, 3049, 4515,    6,  162, 1028, 1004,    7,   13, 1966,  407,
          816,  333, 1127, 1303,    5,   29,   70,  162,  117, 1816,  401,   71,
           77,    7,  839,   53,  162,  961,   42,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [7616,    8,  415,  584,   26,   91, 4401,    5,    5,    5,   68,  386,
           65,   67,    9,  108, 5605,  336,    7,  179,    4,   24,   66,   77,
         1587,   12,  218, 4401,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   24,  278,   13, 1335, 1793, 7470,   97, 1411,   37, 2091,  890,
           10, 1557,   13, 1543,   12, 9829,    6,   10, 3022, 1146,   71,  170,
           10, 3522,    7, 4749, 5242,   11,    6, 1051, 2256,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   21,   11,    6,  321,   12,  100,   25, 1057,   13, 1329,    9,
         7419,    4,    8,  180,   25,  175, 6899, 1314,   10,  574,    5, 9784,
            4,    8,  155,  886,  153,   26,   86, 1767,   80,   33,  125,   25,
           11,  121,  278,   10, 1703, 1404, 1610,   57,    4,  125,   25,   11,
           57, 2107, 1978,    5,    2,    1,    1,    1,    1,    1],
        [  29, 8093, 8187,    6, 1452,  736,  439,   12,  159, 1422,    8,  736,
          439,   12,  159, 3857,    4, 6872, 1752,   35,  494,   15,   18, 1568,
         8187,    6, 1452,  736,  439,   12,  159, 1422,    4,   67,  116,  100,
          419, 3460,    8, 4197,    4, 1452,  288,  655,  439,   12,  159, 3857,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  53, 1918,   10, 2554,  392,  759, 1086,    4,   29,    4,  100,   29,
          294, 1881,  440,    4,    7, 3516,  278,  540,    8, 6732,   62, 5725,
         2502,    6,    5,    8,  853,  174, 8227,   48,    5,   25,  150,    4,
          853,  174,  689,   11,   18,  703,    9,  906, 2937,    6,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'cluster_tokens': tensor([[37, 83, 50, 85, 11, 37, 49, 37, 32, 33, 37, 37, 37, 83, 37, 37, 56, 83,
         37, 37,  6, 83, 29, 50, 83, 37, 37, 56, 11, 37, 37, 37, 83, 37, 85, 37,
         24, 32, 11, 37, 31, 50, 37, 37, 83, 37, 37, 56, 37, 36, 83, 37, 85, 37,
         37, 32, 11, 83],
        [38, 85, 50, 85, 83, 37,  2, 50, 11, 37, 11, 37, 50, 32, 11, 38, 31, 37,
         38, 83, 83, 31, 37, 50, 37, 37, 49, 31, 37, 11, 37, 75, 56, 85, 83, 88,
         50, 37, 49, 49, 85, 38, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [37, 37, 94, 85, 34, 22, 37, 11, 37, 59, 11, 34, 37, 37, 94, 22, 37, 85,
         49, 37, 37, 37, 35, 35, 35, 50, 50, 24, 11, 83, 50, 85, 37, 56, 49, 37,
         50, 37, 32, 37, 85, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [ 9, 37, 38, 73, 85, 50, 94, 11, 11, 11, 38, 28, 11, 37, 37, 37, 94, 37,
         37, 94, 11, 38, 85, 50, 50, 37, 50, 94, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [37, 38, 31, 37,  2, 28, 32, 38, 35, 77, 32, 83, 37, 49, 37,  9, 37, 32,
         37, 37, 28, 28, 37, 37, 37, 59, 37, 49, 94, 85, 37, 38, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [83, 37, 85, 37, 38, 37, 37, 37, 49, 37, 32, 37, 28, 11, 37, 37, 37, 85,
         12, 31, 37, 38, 11, 28, 11, 37, 37, 38, 77, 85, 83,  2, 37, 37, 37, 37,
         85, 35, 31, 37, 49, 94, 35, 77, 11, 37, 37, 85, 77, 31, 83, 11, 83, 37,
         37, 37, 37, 37],
        [83,  4,  9, 37, 88, 34, 24, 37, 37, 94, 37, 34, 24, 37, 37, 47, 11, 83,
         38, 38, 35, 77, 35, 28,  9, 37, 88, 34, 24, 37, 37, 94, 11, 37, 83, 37,
         50,  9, 37, 94, 11, 88, 83, 34, 24, 37, 37, 47, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37],
        [37, 31, 37, 49, 17, 24, 32, 11, 83, 11, 37, 83, 50, 56, 83, 11, 37, 23,
         31, 36, 37, 16, 31, 49, 35, 37, 11, 37, 38, 35, 29, 31, 11, 37, 59, 11,
         38, 35, 85, 85, 35, 88, 37,  9, 23, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37]], device='cuda:2'), 'lengths': tensor([58, 44, 44, 31, 35, 53, 50, 48], device='cuda:2'), 'ntokens': 363}, 'target': tensor([[ 677, 3170,   22,   41,  728,   40, 2979,    6,  496, 2186,    4,  269,
           41, 5843,  302,  326,   44,  520, 6242,    6, 2228, 1418,   41,  299,
          496,    9,  405, 5163, 5303,    4, 3377,   41,   14, 5163, 5303, 8533,
          123,  224,   90, 2328, 1485, 3230,   41,   14, 5163, 5303,  393,  466,
            4,   88,  118, 1442, 5322,   28,   56, 2843,    5,    2],
        [ 104,  681,   29,  190,  350, 1188, 1485,  632,  260,    5,  147,   46,
          981, 1548,    6, 2498,   32,  653,    4,   50,  114,   32,   43,  231,
           61, 6496,   15,   16,  109,   48, 1430,   15,    4,   14,  731,  310,
         1657,  112,  539, 5619,   15,    4,    9, 4613, 9490,   43,  184, 1124,
         1430,  186,  776,    5,    2,    1,    1,    1,    1,    1],
        [  64,   14, 1463,   27,   44, 1581, 4647,   20, 7914,   43,   75,    4,
          423,  212, 8613,  804,  959,   20, 2004,  112,   14, 4541,   59,  407,
         1342, 2968, 2052,  327, 4280,  105,  157,   60,  102, 1083,  757,    4,
           30,   43, 6364,   15,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [7905,   16, 3969,  584,   76,   52, 4365,   46,   68,  431,   65,   46,
          136,    9,  536, 4396,   23,  201,    4,   83,   32,  231, 1468, 1946,
           37, 6376,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   32, 7214,   15,  118, 1030, 4519,  657, 1411,   20,  234,   78,
          107,    4,   23,   29, 2733,   82,    4,   50,   95,   40, 2062,  182,
         5012, 2398,   59, 2241, 3839,  153,    4,   88,   14,  472,   22,   18,
          541,  233, 1182,   23, 8995, 6092,   28, 4096,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,   27,   40, 1538,   29,    4,   90, 1602,   41,  118, 2151,    9,
         7546,   16,  681,  189,  182,  612,    5, 9891,  171, 2491,    4,   16,
         1001, 3408,   27,   47, 5090,  477,    4,  428,   41,  309,   30, 4121,
           18, 1026,  307, 5580,   16,   76, 2600, 8142,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 738,  187,  662, 9459,   20,   83,   28,  736,  950,   14, 2255, 2039,
           16,   28,  736,  950, 2255, 3004,    5, 2328, 2037,  662, 9459,   20,
         2337,  736,  950,  805, 2039,    4,  136,    4,   74,  331, 9426,  139,
            4,  149,  655,  950,  805, 3004,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99, 1492,  543,  392, 7484,    5,  978, 2944,    6, 1803,   15,    5,
          400,  210, 1142, 1444, 3984,  836,   23,  441,  989,  466,   16, 9069,
           20,  112, 1442, 2706,  491,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'target_lengths': tensor([58, 53, 42, 28, 46, 46, 44, 31], device='cuda:2'), 'ntokens': 348, 'nsentences': 8}
##################### {'id': tensor([ 93652, 158423, 216298, 214113,  37915, 101007, 172522,  10911,   3696,
        215790, 165219, 172866,  14931, 182213, 192579,  43492, 136274,  46826,
        201773, 167592,  70406, 153652, 120502,  71678], device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 5.7983e-04,  6.1035e-04,  1.5259e-04,  ...,  1.4954e-03,
          1.9531e-03,  1.7395e-03],
        [-6.1035e-05,  7.0190e-04,  1.1902e-03,  ..., -1.4343e-03,
         -1.1902e-03, -7.3242e-04],
        [ 1.0681e-03,  1.3428e-03,  1.6174e-03,  ...,  9.4604e-03,
          9.9182e-03,  9.3384e-03],
        ...,
        [ 7.5684e-03,  1.4954e-02,  2.0294e-02,  ..., -9.4604e-04,
         -1.4038e-03,  0.0000e+00],
        [-2.4994e-02, -2.4811e-02, -2.5665e-02,  ..., -7.0801e-03,
         -4.8828e-03,  0.0000e+00],
        [-1.2299e-02, -9.7656e-03,  1.0254e-02,  ...,  1.1597e-03,
          2.4414e-03,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960,
        84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960,
        84959, 84959, 84959, 84959], device='cuda:0'), 'prev_output_tokens': tensor([[   2, 2401,   36,   49, 2608,   42,  674,   15, 7500,   36,   42, 2401,
           14,    6,  149,   40, 1606,   50, 9256,   15,   16,  308, 1147,  631,
          678,   37, 1671,   42,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  312,  210,   48,  176,  152, 1217, 1159, 4923, 3456,   27,   52,
          382,  783,  241, 1283, 1024,    4,   16,   32, 2106,  300,   15,   16,
          531,    6,  739, 1671,   78,   30,  331, 2062,    5,    1,    1,    1,
            1,    1,    1],
        [   2,   92,  171,   59, 3962,  107, 5794,   44,  396,   59, 4331,   15,
         4482,  181,   35,  920,  649,  975,   27,  139,  421, 2706, 5394,   16,
          883,    6,    6, 5394,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   92,   27,  113, 1208,    9,  107,  171, 1966, 1029,  153,   18,
            4,  382,   28,  151, 2747,   22, 4420,   42, 1477, 1055,   44,  590,
            6,  416,  387,    5,   92,   27,   40, 7661,   37, 4119, 1977, 4526,
         7277,    6,    5],
        [   2,   64,   90,  354,   30,  196,   47, 2615,   15,    4,  888,   43,
          139,    4,   50,   36,   58,  731,  177,  102, 2855,  541, 5322, 2623,
          161,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  402, 1294,   43,   75,   60,  102,  965, 6837,    4,  795,   32,
          495,   47, 1724,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  840,  105,  645,   28, 6119,    4,  395,   31, 6331,   52,  331,
         1175,   44,  327,  730,    4,  114, 6377, 9255, 1097,  158,  494,  272,
           42,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  526,    4,   74,  313,   31,    9,  105, 4124,  350,  910,   18,
          562, 4674, 4009,   42,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   64,   30, 2161,  158,   20,   39,  328, 3446,  974,  233, 2016,
           82,    4,   50,   81,   36,  139,  210, 4409, 4336,  357,   16,  301,
          152, 1265,  810,   15, 2024,  666,    5,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 2119,   41,  716,    4,   41,   76,   14, 5552,    4,  428,   41,
          702,    9,  805, 1423,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   92,  308, 2198,  614,   35, 9013,   82,   14, 2249, 4054,    6,
         4654, 3104,    9,   23,  489,   23, 3356,   22, 2480,   49, 2310,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 7385,    4, 1513,   30, 6299,  757, 6364,  124, 1513,  217,  731,
            9,   14, 4771, 7584,  130,   42,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   99,  145,  382,   28, 3938, 2741, 2043,   56, 5482,    4, 1088,
            5,  176,    5,   36,   27,   29,   22,  549, 2586,  500, 9214,    4,
          255,   36,   60, 8984, 3771,  861, 1087,  357, 1332,   59,  219,  426,
           18,   27,    5],
        [   2, 1185,  887,  950,   23,  201,  242, 6018,  165, 3948,    9, 4678,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  298, 3371,   20, 5568, 1063,  783,  511,   37,  118,  342,  152,
          181,  236,    4,   58,   38, 1018,  411,  191, 4811,  980,   23, 9385,
           40, 3048,  191,  803, 3319,   27,    5,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   72, 2069,  105, 1419,   16,   32, 3251,  191,  112,  118, 1077,
            6,   20, 1310,   37,  257,    9,   29,  151,  764,  237,  174,  181,
          237,  219,    6, 1324,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  104,   83,  460,  200,   22,   97, 3015, 3237,   88, 1458,   20,
         2362,    4,   16,  173, 7087,   27, 1357, 1235,   59,  797, 1921,    4,
          647,   28,  553,  675,  412, 8142,    5,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 2540,    4,   34,   81,   47,  208,  145,   44,   92, 2540,  129,
          864, 1842, 4027,   16,  864, 1610,    6,    6, 4027,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 7456, 1397, 5517,   81, 1096,  377,  156, 4076,   15,   30,  911,
          181,  233,  141, 8655,    4,   60,  102, 4276, 1865,   18, 5701,   23,
         8655,  253, 1864,  200,   22, 6758,    5,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 8250, 7214,   31,   52, 1053,  312, 2664,   20,  124,   38,  483,
          335, 2664,   20,  980,   74,   31,   43, 3888,    4,  326,    4,   14,
           31, 2418,  209,    4, 1091,   31,  406, 6132, 6366, 8497,    5,    1,
            1,    1,    1],
        [   2,   72,  638,   32,  776,   90,  624,    6, 3638, 2648,    4,   34,
           36,  855,    4, 2639,   28,  186,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 5028,   37,  695,   58, 6306, 2824,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 5118,    4,   14, 8003, 3566,    4,   50,   36, 8892, 4845, 3235,
           28,  285, 1879,  491,  178,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  441, 6482,  332,  846,  315,   22,   18,  122,  153, 6391, 8738,
           14, 1131, 1253, 1044,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[ 347,  568,   21,  988,   42,  148, 1006,    6,   42,   26,   33,  116,
           13, 1678,   17, 9004,    6,    8, 6904,    6,  722,   42,    2,    1,
            1,    1,    1,    1,    1,    1],
        [  13, 4746,   35,  803,   18,  249,   26,   13,  382,  783, 1522,  723,
            4,    8,   24, 5874,    8,  749,    6,  174,  589, 6010,  722,   55,
            7,  218, 1543,    5,    2,    1],
        [  70,   33, 3565,  170,   26,    4,   33,  164,   15, 4482,  181, 2958,
            4,   21,   11,    6,  113, 2092,  365,    8,  883,  140,  365,    5,
            2,    1,    1,    1,    1,    1],
        [  25,   11,   57, 1211,   17,   17,   11,    6,  204, 1031,  156,   62,
          199,  281,   94,   11,    6, 2702,   32,   54,   85,  185, 1648,   42,
            2,    1,    1,    1,    1,    1],
        [   8,  103,   17,   11,    6,   86,  890,    4,   53,   11,  121, 2107,
           69,   10,  289,    4,  281,  490,   53, 4853,  747,  670,    5,    2,
            1,    1,    1,    1,    1,    1],
        [1325,   53, 5415,   33, 1165,    4,   24,   11,  158,  492, 6290,  565,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  10, 1141,   17,  630,    4,   19,   11,   45,  142,   10,   66,   10,
          884,  486,   91,    4,  166,   26,    4,   70, 1148,  120, 6249, 8221,
            6,  415,  158, 1515,   42,    2],
        [ 115,    4,  138,  323,   19,  367,   10,   33, 1760, 3140,   12,   13,
           48, 1184,  140, 3085,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   8,    7, 4268,   12,    7,  744, 6213,   55,   33, 1599,   34,   17,
           21,  220,   51,  619,   69, 8786,    6,    8,   91,   35, 1933,   35,
         1178,    6,    5,    2,    1,    1],
        [1008,   46,   25,   11,   57,    7, 3698,    4,  125,   25,  618,  155,
         1037,  282,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   7,   13, 2198,  614, 1810,   34,    7, 4023, 2922, 2371,   56, 4654,
         2041,    9,    7, 1261,   12,    7, 1384, 1224,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  26,   21,  148, 1073,    7,  281,  839,  109,  148,   26,  281, 8064,
           10,  267, 3557,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  21,   73,  876,  121,   10, 2697, 2360,    4,   10,  206, 7616,  568,
           86, 2705,  307, 1906,    4,    8,   26,  417, 1841, 1059,   62,   71,
         1894,  688,    6,    5,    2,    1],
        [2018,  527,   93,   35, 2287,  234,  439,   12,    7,  179,   11,    6,
         1682,  931,    9,  108, 1884,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  29, 4479, 1339,  783,  511,   37, 1405,   13,  682,  247,   17,  101,
          434,   38, 1879, 2102,  438,  166,   26, 1223, 8044,   55, 3708,    6,
            5,    2,    1,    1,    1,    1],
        [  19,  321,   12,  100, 1060,  117, 1532,    8, 2346,   18, 1011,   71,
          565,  359,   13, 2555,  237,  866,    9,  321,   12,   13,  854, 4656,
            6,  737,    5,    2,    1,    1],
        [  24,   66,  255,  200,   22, 6339,   54, 2200, 2362,    4,    8,   24,
           66,  244,  168,  264, 8973,    6,   69,   13, 4481, 3489,   10, 1764,
          387,  287,    5,    2,    1,    1],
        [2805, 2219,   69,   70,   91, 1985,  150,    4,    7, 2805,   12,   17,
          107,   20,   15,    8,  291,  156, 3837,  457,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  29,  103,   17,   11,    6,   86, 4949,  890,    4,   25,   73, 5652,
           91,    8,   25,  175,   13, 2685, 8831,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 106,   17,  552,   13,  325,   12, 5828,    6,    4,  109,  126,    6,
         2893,    6,    4,   79,   19,  434,  134,    4,  214,   17,   19, 1385,
         1313, 6263,   89, 6878,    5,    2],
        [  19,  154,  245,   21,   11,    6,  528,   55,  170,   10, 2613,   70,
           21,   26,   10,   51, 2639,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [3695,   12,  134,   63, 1387,   10,  206,    7, 4458,  362,    6,   63,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   7,  744,   26,    9,    6,  234,   54,   17,   84,   26, 8902, 1666,
         2214,   10,  415,  500, 1783,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  29,    4, 6482,  215,  581,    4,  903,    5,  846,  315,   22,   18,
          380, 3089,   35, 3304,   62,  284, 3780,   11,    6,  874,    5,    2,
            1,    1,    1,    1,    1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[83, 85, 37, 23, 11, 50, 94, 37, 11, 85, 37, 83, 37, 32, 37, 28, 37, 37,
         28, 37, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 29, 38, 35, 35, 77, 85, 37, 38, 35, 35, 94, 11, 37, 38, 28, 37, 38,
         37, 35, 35, 56, 49, 37, 37, 50,  9, 11, 83, 37],
        [50, 37, 88, 37, 85, 11, 37, 85, 77, 35, 35, 32, 11, 37, 85, 37, 83, 23,
         35, 37, 38, 35, 35, 11, 83, 37, 37, 37, 37, 37],
        [37, 85, 77, 88, 37, 37, 85, 37, 83, 38, 35, 31, 37, 75, 56, 85, 37, 87,
         38, 49, 37, 50, 23, 11, 83, 37, 37, 37, 37, 37],
        [37, 37, 37, 85, 37, 83, 83, 11, 37, 85, 35, 31, 37, 37, 88, 11, 75, 37,
         37, 29, 30, 94, 11, 83, 37, 37, 37, 37, 37, 37],
        [24, 37, 36, 37, 32, 11, 38, 85, 35, 50, 29, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 37, 94, 11, 38, 85, 35, 49, 37, 85, 37, 88, 50, 50, 11, 37, 85,
         11, 50, 85, 37, 94,  9, 37, 38, 35, 92, 11, 83],
        [83, 11, 37, 85, 38, 85, 37, 37,  2, 94, 37, 37, 31, 35, 35, 94, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 37, 37, 24, 29, 37, 37, 26, 85, 37, 37,  6, 38, 31, 37,  9,
         37, 37, 50, 38, 24, 38, 35, 37, 11, 83, 37, 37],
        [59, 11, 37, 85, 77, 37, 32, 11, 37, 37, 49, 37, 94, 32, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 35, 35, 32, 85, 37, 75,  9, 24, 38, 35, 94, 37, 37, 94, 37, 37,
         31, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [85, 37, 50, 85, 37, 75, 32, 37, 50, 85, 75, 31, 37, 37, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  6, 38, 35, 37, 34, 24, 11, 37, 37,  9, 85, 83, 38, 77, 77, 11, 37,
         85, 38, 35, 35, 31, 37,  2,  9, 37, 11, 83, 37],
        [38, 77, 35, 38, 35, 35, 24, 37, 37, 94, 85, 37, 23, 37, 37, 37, 56, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 32, 38, 35, 35, 77, 31, 37, 38, 77, 37, 38, 31, 38, 35,  9, 82, 37,
         85, 83,  9, 37, 94, 37, 11, 83, 37, 37, 37, 37],
        [38, 38, 37, 37, 31, 37, 56, 37, 38, 35, 31, 37, 37, 37, 37, 38, 35, 35,
         37, 38, 37, 37, 53, 38, 37, 35, 11, 83, 37, 37],
        [38, 85, 38, 35, 35, 94, 49, 38, 35, 11, 37, 38, 85, 37, 37,  2,  9, 37,
         37, 37, 83, 31, 37, 38, 35, 35, 11, 83, 37, 37],
        [94, 83, 37, 50, 50,  6, 59, 11, 37, 94, 37, 37, 38, 77, 77, 37, 38, 35,
         35,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 37, 85, 37, 83,  2, 83, 11, 37,  6,  9, 50, 37, 37, 85, 37, 94,
         32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 83, 37, 32, 37, 11, 37, 37, 37, 35, 37, 11, 37, 38, 31,
         37, 11, 56, 37, 38, 31, 37, 29, 37, 32, 11, 83],
        [38, 59, 83, 37, 85, 37,  2, 37, 37, 37, 86, 50, 37, 85, 37, 38,  2, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 37, 37, 85, 83, 37, 37, 37, 38, 35, 37, 85, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 24, 85, 37, 37, 35, 49, 37, 37, 85, 83, 83, 49, 37, 38, 35, 35, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 34, 24, 83, 11, 38, 11, 38, 35, 35, 35, 77, 38, 38, 35, 31, 37,
         94, 85, 37, 38, 11, 83, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([23, 29, 25, 25, 24, 14, 30, 18, 28, 16, 22, 17, 29, 19, 26, 28, 28, 22,
        21, 30, 19, 14, 19, 24], device='cuda:0'), 'ntokens': 550}, 'target': tensor([[2401,   36,   49, 2608,   42,  674,   15, 7500,   36,   42, 2401,   14,
            6,  149,   40, 1606,   50, 9256,   15,   16,  308, 1147,  631,  678,
           37, 1671,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 312,  210,   48,  176,  152, 1217, 1159, 4923, 3456,   27,   52,  382,
          783,  241, 1283, 1024,    4,   16,   32, 2106,  300,   15,   16,  531,
            6,  739, 1671,   78,   30,  331, 2062,    5,    2,    1,    1,    1,
            1,    1,    1],
        [  92,  171,   59, 3962,  107, 5794,   44,  396,   59, 4331,   15, 4482,
          181,   35,  920,  649,  975,   27,  139,  421, 2706, 5394,   16,  883,
            6,    6, 5394,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  92,   27,  113, 1208,    9,  107,  171, 1966, 1029,  153,   18,    4,
          382,   28,  151, 2747,   22, 4420,   42, 1477, 1055,   44,  590,    6,
          416,  387,    5,   92,   27,   40, 7661,   37, 4119, 1977, 4526, 7277,
            6,    5,    2],
        [  64,   90,  354,   30,  196,   47, 2615,   15,    4,  888,   43,  139,
            4,   50,   36,   58,  731,  177,  102, 2855,  541, 5322, 2623,  161,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 402, 1294,   43,   75,   60,  102,  965, 6837,    4,  795,   32,  495,
           47, 1724,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 840,  105,  645,   28, 6119,    4,  395,   31, 6331,   52,  331, 1175,
           44,  327,  730,    4,  114, 6377, 9255, 1097,  158,  494,  272,   42,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 526,    4,   74,  313,   31,    9,  105, 4124,  350,  910,   18,  562,
         4674, 4009,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  64,   30, 2161,  158,   20,   39,  328, 3446,  974,  233, 2016,   82,
            4,   50,   81,   36,  139,  210, 4409, 4336,  357,   16,  301,  152,
         1265,  810,   15, 2024,  666,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [2119,   41,  716,    4,   41,   76,   14, 5552,    4,  428,   41,  702,
            9,  805, 1423,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  92,  308, 2198,  614,   35, 9013,   82,   14, 2249, 4054,    6, 4654,
         3104,    9,   23,  489,   23, 3356,   22, 2480,   49, 2310,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [7385,    4, 1513,   30, 6299,  757, 6364,  124, 1513,  217,  731,    9,
           14, 4771, 7584,  130,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  99,  145,  382,   28, 3938, 2741, 2043,   56, 5482,    4, 1088,    5,
          176,    5,   36,   27,   29,   22,  549, 2586,  500, 9214,    4,  255,
           36,   60, 8984, 3771,  861, 1087,  357, 1332,   59,  219,  426,   18,
           27,    5,    2],
        [1185,  887,  950,   23,  201,  242, 6018,  165, 3948,    9, 4678,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 298, 3371,   20, 5568, 1063,  783,  511,   37,  118,  342,  152,  181,
          236,    4,   58,   38, 1018,  411,  191, 4811,  980,   23, 9385,   40,
         3048,  191,  803, 3319,   27,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  72, 2069,  105, 1419,   16,   32, 3251,  191,  112,  118, 1077,    6,
           20, 1310,   37,  257,    9,   29,  151,  764,  237,  174,  181,  237,
          219,    6, 1324,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 104,   83,  460,  200,   22,   97, 3015, 3237,   88, 1458,   20, 2362,
            4,   16,  173, 7087,   27, 1357, 1235,   59,  797, 1921,    4,  647,
           28,  553,  675,  412, 8142,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [2540,    4,   34,   81,   47,  208,  145,   44,   92, 2540,  129,  864,
         1842, 4027,   16,  864, 1610,    6,    6, 4027,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [7456, 1397, 5517,   81, 1096,  377,  156, 4076,   15,   30,  911,  181,
          233,  141, 8655,    4,   60,  102, 4276, 1865,   18, 5701,   23, 8655,
          253, 1864,  200,   22, 6758,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [8250, 7214,   31,   52, 1053,  312, 2664,   20,  124,   38,  483,  335,
         2664,   20,  980,   74,   31,   43, 3888,    4,  326,    4,   14,   31,
         2418,  209,    4, 1091,   31,  406, 6132, 6366, 8497,    5,    2,    1,
            1,    1,    1],
        [  72,  638,   32,  776,   90,  624,    6, 3638, 2648,    4,   34,   36,
          855,    4, 2639,   28,  186,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [5028,   37,  695,   58, 6306, 2824,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [5118,    4,   14, 8003, 3566,    4,   50,   36, 8892, 4845, 3235,   28,
          285, 1879,  491,  178,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 441, 6482,  332,  846,  315,   22,   18,  122,  153, 6391, 8738,   14,
         1131, 1253, 1044,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([28, 33, 29, 39, 26, 16, 25, 16, 31, 17, 24, 18, 39, 13, 31, 29, 31, 22,
        31, 35, 19,  8, 18, 17], device='cuda:0'), 'ntokens': 595, 'nsentences': 24}
##################### {'id': tensor([145812, 181675,  77687, 150676, 133187, 199285,  39674],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-1.3123e-03,  2.8625e-02,  5.2917e-02,  ..., -2.5635e-03,
         -2.4109e-03, -2.2278e-03],
        [-9.2468e-03, -2.4109e-03,  1.5259e-04,  ..., -1.6815e-02,
         -5.1270e-03,  6.7139e-04],
        [-7.2632e-03, -8.0261e-03, -8.0261e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-4.0283e-03, -2.8381e-03, -1.2207e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.5259e-04,  3.0518e-04,  8.5449e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-3.0518e-05, -6.7139e-04, -7.3242e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([341440, 341440, 341280, 341280, 341280, 341280, 341280],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2, 1190,  416,  124,   42, 2119,   32, 3596,    5,  460,   32,  361,
          299, 4921,   20, 1349,   83,   16,  105, 5107, 2498,    4,   14,  107,
          105,  326,  269,  795,    4, 3546,   15,   32, 2430,    4,   50,   97,
         4060,  374,    4,   34,   81,   60, 3113,    4,  374,   34,   81,   60,
         3113,   16, 5940,  260,  145,    4,   30,  145,   81,  361,  139,   60,
         9405,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  104,   56, 5682,   22,  257,  196, 1399,   61, 9083,   22,    4,
          136,  361,  123,   32,  275,  216, 1399,   56, 5682,   22,    4,  216,
           90, 2691, 2454,    5, 4162,   22,   27, 4582,    5, 7705,  729,   27,
         4582,    5, 4627,   27, 4582,    5, 7456, 9838,   27, 4582,    5,  104,
          123,   14, 1399,   78, 5857,   20,  393,  352, 3160,   22,    4,   14,
           78,  107,  291, 1900,    6, 1635,  712,  319,    4,   90,   32,   14,
          711,   30,  624,  642, 7209,   15,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 1214, 1421, 1596, 2904, 3681,  790, 2800,   75,  653,    4, 2783,
           95,  405, 2269,  433,  863, 1263, 8913,  280,    4,   50,   95,  255,
          337,  764,  861,  130,   16,   95,  280,  139, 1400,    5,    5,    5,
          202, 6305,   58, 2118,  892,   90,  302, 1709,   16,  666,   75,  363,
          190,   28, 7504,   40, 1527,  861,    5,  202,  239,  167, 2294, 1853,
           23, 2530,    4, 1853,  129, 6279,    6,    4, 1853,  405,    6, 6279,
            6,    4,   50,   14,    6,   30,  624,  642, 1091,  815, 1132,  332,
           82,    4,   50,   95,   75,  393,   29, 3878,    4,   90, 1023,   95,
          118, 2118,    5],
        [   2, 4287, 8770,  182, 4072,  569,   15,  721,    4,  654, 8770,  182,
         9639,    4,  124,  654, 8770,  182, 2136,   16, 8889,    4,  124,  654,
         8770,  182, 3105,    6,  539,   16,  182, 1139, 2050,  390,    5,  222,
           41,   39,  299, 1041,   61,  512,   45,  437,  287, 1177,  604,    4,
           30,   75,   39,  243,   45,  390, 1282,   16,   75, 1746,   16,  831,
         3582,    4,   16, 5905,  395,  686,   49,  107,  648,    9,   14,  201,
         2680,    4,   88,   43,   28, 3958,   16,   28, 5341,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   99,  178,  113, 3106,   40, 3545,  496,   60,   23, 1530,  174,
         1069,  165,    4,   16,   30,  130,  163,  263,  184,  683,  821,   18,
            4,  428, 3873, 1535, 1391,   36,  182,  141, 6419, 4251,  682,    5,
         1061, 2284,    4,  382,   23, 3527, 1169, 1769,   40,  236, 6839,   39,
         6259,    4,   14, 3527, 1169, 1769, 8757, 2713,    4,  136,   58,  731,
           27,   47, 1263,    4,   50,   36,   56, 6453, 3497,   35, 5890,  124,
          216, 2095, 4055,    4,  382,   14,   51,   59,  219,  951,  236,  191,
          880,  920,  748,  483,   35, 5273,  176, 2388,   59, 1975, 2850, 2641,
         5482,    5,    1],
        [   2,  228,   58, 3125, 2495,   15, 5145,   75,   14, 2146,  122, 3518,
          249,   44,   38, 4818, 2867,   22,   96,  634,   30,  145,    4,  782,
           47,   32,  358,   72, 3888,   30, 7919,   61, 5081,   44,   38, 4510,
           20, 3225,  986, 6676,    4,  864,  247, 1240, 1249,   16, 1134,  622,
         2124,   15,  137,   72, 2800,   58, 9913, 2877, 2709, 1659,    6,  357,
           52,  645,   44,   38, 1055, 4722,   27,   23, 1802,    5, 8376,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   99,  178,  302, 1048,   20,  633, 5789,   15,   44, 4470,   32,
         2186,  105,   47,   35, 3313, 6675,   15,  259,  174, 4599,   15,   61,
           52, 8379,   20, 1058,  536, 1923,    4,    9,  631,   32, 4011, 5010,
         4789,   95, 2305,    4,  124,  136,  105, 3692,   20,  127,   61, 8807,
           20, 1058, 6883,    4,   14,   32,   47,  363, 4376,  343, 1939,  223,
         1476,   20,    4, 3461,  124, 5981,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:5')}, 'transcript': {'tokens': tensor([[ 976, 1475,    4, 2184,  176,   42,   24,  154,   29,    5,   29,  115,
           17,   24, 2534,  117, 2522,    8,  591,  117, 3422,   17,  339,  170,
           87,  117,  214,    4,   24,  487,   10, 2252,   17,    4, 3423,    4,
          995,   17,   24,   73,   87,   71, 1780,    4,  995,   17,   24,   73,
           87,   71,   13, 1472,   12, 1780,    8,   13, 2705,   24,   73,  115,
           87,   71, 5414,    6,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,  499, 3008,  813,   69, 3634,    6,    4,   67,  115,   24,   73,
         3008,   13,  325,  143,  813,    4,  143,  254,  700,  490,    5, 2761,
           54,   21,   26, 4865,    5, 4585,   54,   21, 4865,    5, 4912,   21,
           26, 4865,    5,  979,   54,   21,   26, 4865,    5,    8,   70,   24,
           73,   87,   26,   24,   73,  203, 1792,   33,  813,   55,  368,    6,
           17,   24,  492,  276,  934,   48,  120,   24,  245, 2861,   62,    7,
          660,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   21, 1518,  126,   17,   71, 1421, 1601, 2421,    6, 3195,   54,
            9,    7, 5199,    4,  432,  101,  976,  261,  442,  284, 3140, 2226,
           69,   33,   46,  101,  144,  284, 7986,    8,  101,  144,  284,   46,
          101,  258,   57,   33, 1266,   55,  908,  254,  248, 1551,    8,   34,
          529,   10, 7554, 4115,   13, 4058,    8,  278,  923, 2294,  244,    7,
          409,   17,    4, 5098,   46,  284, 5098,   46,   21,   11,    6,    7,
          245,  183,  101,   11,    6, 1831,  100,  101,   11,    6,  144,   39,
         1266,    9,  815, 1132,  215,    5,    2,    1,    1,    1],
        [ 108,  296,   55, 3051,    4,  108,  296,   55, 4029,  687,    4,  109,
          108,  296,   55, 3069,    8, 8464,    4,  109,  108,  296,   55,  540,
          687,    8,   55, 2848, 2050,   93,    4,    8,  103,   25,  154,   80,
            7,  277, 1920,  148, 2456,    6,   69,  155, 1067,  265,    8,  148,
           26,  415,  878,  111, 7307,   62,  168,    8,  133, 7759,    8, 6128,
            4,    8,   85,  185,  613,   77,   12,  170,  296,   10,  205,  126,
          199,    7,  179,   10, 3231,    8,   10, 3522,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29, 2983,   84,   11,    6,   13, 3024, 7927, 4719,    4,    8,   33,
          172,  132,    6,  307,  110,    4,  125,   13, 1027,  631,  407, 3565,
           25,  432,   13, 2767, 6204,    4,   84,   11,    6, 7008,   80,   39,
         1061,   35, 1315,  322,  183, 5848,   10,   46,   24,  321,  290, 4971,
            4,  498,    7, 4971,   93,  979,    4,   67,   70,  281,   94,  192,
           11,   18, 2252,   26,   17,   69, 2313,   21, 1847, 3497,   10, 1421,
         1113,  109,  143,   55,    7,    9, 1610,   45, 1032, 1809,  424, 1420,
          233,  373,   10,  276, 1772,   10,  575,  132,    5,    2],
        [5902,  589,    6,   69,  837, 1827,  162, 6386,    4,   38,  597,  269,
          340,  407,  323,   21,    4,  347,   73,   11,   18,   24,  358,   19,
         1850,   62,   39, 2792,   69, 5063,    8,  434,   21,   38,  290, 2078,
         1525, 6664,    4, 9413,    8, 9696, 2419,  137,   19, 8063,   48,   13,
          630,   10,    7,  640, 3431, 6463,   12,    7, 2672,   85,    7,  183,
           44,   38,  412, 2366,   26,    7, 1802,  322,   12, 8338,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  203,  779,  675,  793,   26,  142,   10, 3128, 2129,   12,  248,
         3834,   44, 2129,   24,  164, 8896,  117, 1752,   35,    6,  335,   18,
         1617,  457,  183,   35, 2470,    6,   96,    9, 1764,   20,  484,  480,
         1081,   12,  108,  447, 2573,  131, 1520,  203, 7712,  237, 2332,    4,
          109,  994,  117, 3382,    6,   63,  142,   10,  175, 7154,   48,    9,
          291, 1076,   20,  484,  480, 1081,   86,   12,  108, 2573,   46, 1187,
          111,    4,  131,   82,    4, 1599,  109, 2145,  586,  271,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'cluster_tokens': tensor([[83,  2, 11, 38, 35, 11, 38, 59, 83, 11, 83, 83, 37, 38, 31, 37, 56, 37,
         31, 37, 56, 37, 49, 37, 85, 37, 56, 11, 38, 31, 37, 86, 37, 11, 83, 11,
         50, 37, 38,  6, 85, 37,  9, 11, 50, 37, 38,  6, 85, 37, 37, 32, 37,  9,
         37, 37, 38, 38,  6, 83, 85, 37, 28, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [38, 83,  9, 94, 37, 33, 37, 11, 37, 83, 38,  6,  9, 37, 83, 50, 94, 11,
         50, 37, 50, 37, 11, 59, 49, 37, 85,  2, 11, 29, 49, 37,  2, 11, 49, 37,
         85,  2, 11, 32, 49, 37, 85,  2, 11, 37, 50, 38,  6, 85, 85, 38,  6, 38,
         77, 37, 94, 37, 49, 37, 37, 38, 50, 83, 88, 31, 37, 38, 83, 49, 31, 37,
         56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [37, 37, 40, 37, 37, 37, 34, 24, 94, 37, 49, 49, 37, 37, 32, 11, 37, 38,
         83, 83, 31, 37, 94,  2, 37, 37, 11, 38, 85, 37,  9, 37, 38, 85, 37, 11,
         38, 38, 77, 37,  9, 37, 50, 37, 34, 24, 37, 85,  6, 37, 49, 37, 37, 49,
         37, 31, 83,  2, 37, 37, 32, 37, 11, 32, 11, 37, 32, 11, 37, 85, 37, 37,
         83, 24, 38, 85, 37, 31, 37, 38, 85, 37, 85, 38,  9, 37, 17, 73, 24, 11,
         83, 37, 37, 37],
        [37, 49, 37, 36, 11, 37, 49, 37, 33, 35, 11, 37, 37, 49, 37, 94, 37, 32,
         11, 37, 37, 49, 37, 36, 35, 37, 37, 38, 35, 35, 11, 37, 37, 37, 59, 37,
         37, 50,  9, 50, 38, 37, 37, 37, 38, 35, 37, 50, 85, 38, 35, 83,  9, 31,
         37, 37, 83,  2, 37,  2, 11, 37, 37, 50, 32, 50, 37, 37, 49, 37, 85, 37,
         37, 37, 94, 37, 88, 37, 37, 59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [83, 83, 37, 85, 37, 37,  2,  9, 33, 11, 37, 37, 83, 37, 37, 77, 37, 11,
         37, 37, 35, 35, 35, 88, 37, 37, 37, 75, 94, 11, 37, 85, 37, 83, 37, 38,
         84, 38, 35, 35, 24,  9, 37, 11, 38, 38, 35, 29, 11, 49, 37, 29, 35, 32,
         11, 37, 50, 75, 56, 85, 85, 35, 86, 85, 37, 37, 83, 37, 49, 34, 37, 34,
         24, 37, 50, 37, 37, 37, 35, 35,  2, 38, 35, 38, 35, 56, 37, 83, 49, 37,
         88, 37, 11, 83],
        [28, 35, 37, 37, 28, 56, 85, 88, 11, 38, 35, 79, 35, 35, 85, 37, 11, 83,
          6, 85, 35, 38, 11, 38, 38, 31, 38, 32, 37, 28, 37, 31, 37, 38, 35, 94,
         37, 94, 11, 21, 37,  9, 35, 11, 38, 88, 31, 37, 94, 37, 37, 34, 60, 56,
         37, 37, 94, 37, 37, 24, 82, 38, 35, 24, 85, 37, 34, 35, 37, 24, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37],
        [37, 38, 35, 35, 35, 85, 49, 37, 49, 50, 37, 34, 56, 82, 50, 38, 85, 29,
         37, 38, 38, 37, 35, 35, 35,  2, 24, 38, 52, 37, 77, 37, 38, 77, 35, 35,
         56, 37, 37, 37, 94, 37, 49, 38, 35, 35, 94, 11, 37, 50, 37,  9, 37, 85,
         49, 37, 85, 29, 31, 37, 38, 35, 77, 35, 35, 56, 83, 37, 37, 94, 11, 32,
         83, 11, 37, 53, 11, 26, 37, 38, 35, 44, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([66, 75, 91, 82, 94, 72, 84], device='cuda:5'), 'ntokens': 564}, 'target': tensor([[1190,  416,  124,   42, 2119,   32, 3596,    5,  460,   32,  361,  299,
         4921,   20, 1349,   83,   16,  105, 5107, 2498,    4,   14,  107,  105,
          326,  269,  795,    4, 3546,   15,   32, 2430,    4,   50,   97, 4060,
          374,    4,   34,   81,   60, 3113,    4,  374,   34,   81,   60, 3113,
           16, 5940,  260,  145,    4,   30,  145,   81,  361,  139,   60, 9405,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 104,   56, 5682,   22,  257,  196, 1399,   61, 9083,   22,    4,  136,
          361,  123,   32,  275,  216, 1399,   56, 5682,   22,    4,  216,   90,
         2691, 2454,    5, 4162,   22,   27, 4582,    5, 7705,  729,   27, 4582,
            5, 4627,   27, 4582,    5, 7456, 9838,   27, 4582,    5,  104,  123,
           14, 1399,   78, 5857,   20,  393,  352, 3160,   22,    4,   14,   78,
          107,  291, 1900,    6, 1635,  712,  319,    4,   90,   32,   14,  711,
           30,  624,  642, 7209,   15,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1214, 1421, 1596, 2904, 3681,  790, 2800,   75,  653,    4, 2783,   95,
          405, 2269,  433,  863, 1263, 8913,  280,    4,   50,   95,  255,  337,
          764,  861,  130,   16,   95,  280,  139, 1400,    5,    5,    5,  202,
         6305,   58, 2118,  892,   90,  302, 1709,   16,  666,   75,  363,  190,
           28, 7504,   40, 1527,  861,    5,  202,  239,  167, 2294, 1853,   23,
         2530,    4, 1853,  129, 6279,    6,    4, 1853,  405,    6, 6279,    6,
            4,   50,   14,    6,   30,  624,  642, 1091,  815, 1132,  332,   82,
            4,   50,   95,   75,  393,   29, 3878,    4,   90, 1023,   95,  118,
         2118,    5,    2],
        [4287, 8770,  182, 4072,  569,   15,  721,    4,  654, 8770,  182, 9639,
            4,  124,  654, 8770,  182, 2136,   16, 8889,    4,  124,  654, 8770,
          182, 3105,    6,  539,   16,  182, 1139, 2050,  390,    5,  222,   41,
           39,  299, 1041,   61,  512,   45,  437,  287, 1177,  604,    4,   30,
           75,   39,  243,   45,  390, 1282,   16,   75, 1746,   16,  831, 3582,
            4,   16, 5905,  395,  686,   49,  107,  648,    9,   14,  201, 2680,
            4,   88,   43,   28, 3958,   16,   28, 5341,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  99,  178,  113, 3106,   40, 3545,  496,   60,   23, 1530,  174, 1069,
          165,    4,   16,   30,  130,  163,  263,  184,  683,  821,   18,    4,
          428, 3873, 1535, 1391,   36,  182,  141, 6419, 4251,  682,    5, 1061,
         2284,    4,  382,   23, 3527, 1169, 1769,   40,  236, 6839,   39, 6259,
            4,   14, 3527, 1169, 1769, 8757, 2713,    4,  136,   58,  731,   27,
           47, 1263,    4,   50,   36,   56, 6453, 3497,   35, 5890,  124,  216,
         2095, 4055,    4,  382,   14,   51,   59,  219,  951,  236,  191,  880,
          920,  748,  483,   35, 5273,  176, 2388,   59, 1975, 2850, 2641, 5482,
            5,    2,    1],
        [ 228,   58, 3125, 2495,   15, 5145,   75,   14, 2146,  122, 3518,  249,
           44,   38, 4818, 2867,   22,   96,  634,   30,  145,    4,  782,   47,
           32,  358,   72, 3888,   30, 7919,   61, 5081,   44,   38, 4510,   20,
         3225,  986, 6676,    4,  864,  247, 1240, 1249,   16, 1134,  622, 2124,
           15,  137,   72, 2800,   58, 9913, 2877, 2709, 1659,    6,  357,   52,
          645,   44,   38, 1055, 4722,   27,   23, 1802,    5, 8376,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  99,  178,  302, 1048,   20,  633, 5789,   15,   44, 4470,   32, 2186,
          105,   47,   35, 3313, 6675,   15,  259,  174, 4599,   15,   61,   52,
         8379,   20, 1058,  536, 1923,    4,    9,  631,   32, 4011, 5010, 4789,
           95, 2305,    4,  124,  136,  105, 3692,   20,  127,   61, 8807,   20,
         1058, 6883,    4,   14,   32,   47,  363, 4376,  343, 1939,  223, 1476,
           20,    4, 3461,  124, 5981,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:5'), 'target_lengths': tensor([62, 79, 99, 82, 98, 72, 67], device='cuda:5'), 'ntokens': 559, 'nsentences': 7}
##################### {'id': tensor([  3705, 195562, 168680,  42929,  52394, 154579,  94228,  79312],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[-9.1248e-03, -1.0193e-02, -1.1566e-02,  ...,  8.9722e-03,
          2.4048e-02,  3.4180e-02],
        [ 1.0376e-03,  6.4087e-04,  4.2725e-04,  ...,  6.4087e-04,
         -3.0518e-05, -7.9346e-04],
        [ 3.1860e-02,  4.0680e-02,  6.5979e-02,  ...,  6.1035e-05,
         -9.7656e-04, -1.9836e-03],
        ...,
        [ 3.0518e-04,  3.6621e-04,  6.4087e-04,  ...,  1.7395e-03,
          1.5869e-03,  1.6785e-03],
        [ 7.0190e-04,  1.1292e-03,  1.1292e-03,  ...,  2.0142e-03,
          1.5869e-03,  0.0000e+00],
        [ 0.0000e+00, -1.9531e-03, -3.0823e-03,  ..., -2.7771e-03,
         -2.3499e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([167040, 167040, 167040, 167040, 167040, 167040, 167039, 167039],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2, 4010,  769,   81,   47,   61,   14, 4860,   20,   16, 2486, 2234,
           88, 5457,    5,   38, 2473,   14, 1572, 3933,  295,  489,   16,   14,
           23,  351,   16,  329, 2642, 1001, 5841, 1640,    4,   32,  776,   40,
         3656,   95, 2740,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  376, 1804, 2154,  338, 1350, 2967,   20,  444, 1302,   15, 1096,
         3260,   15,   16, 4375,   20,  815,    4,  852,  848, 4842, 5888,   98,
          151, 4239, 2967,    4,   30,   28,  736,  950, 8549,  712,   27,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  933, 2271,  157,   76, 9602,   20,  157,    4,   16, 9602,   20,
          157,    5,    5,    5, 1935, 9602,   37,   14,  157,   76,    4,  129,
          412, 9602,   37,   27,  273,  201,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  573, 9327,    5,  928,  836, 1544, 3174, 4796,    5, 2400,
           83,   32, 4671, 3174, 4796,    4,   14,  903,  235,   18,  122,   59,
          315,    6,  426, 1641, 4916,    9,   23,  201,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,  189, 1204,   31,  872,  472,  622,  240,    9, 1935,  221,
            6,   16, 1258,  158,  156,  371,  380, 4291,  158, 6066,  364, 4275,
          615,    4,   16, 1812,   30, 3525, 1240,    5,  298, 4368,   31,   43,
          385,    9, 7790,  343,  136,  109,  303, 1867,   16,  184,  530, 1875,
           18, 2081,   43,  433,  186,    5,    1,    1,    1,    1,    1,    1],
        [   2,  376, 1783,  242, 8616,    4,   74, 3931,   60,  102, 1659,  237,
          587,  243, 1021,    4,  161, 1746, 7166, 1679,  242, 2450,  165,   83,
            5,   92, 3483,  161,  334,   44,   38, 1055, 4778,    4, 4254,    4,
         4182,    4, 3142,    4,  566,  202,  266,    4,   30,   27,  478,   14,
         3670,    4,   23,   15,  773,   32,   39, 1750,   22, 6391, 4572,  857],
        [   2,   72,  814,  393,    9,   14, 2480,   16, 3452, 3660,   78,   98,
         2298,   20, 8504,   20, 2492, 2170,  297,  610,  610,   28,  605,    5,
          400,   75,  653, 3306,   20,    4,  573,   36,  286,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  526,  414,    4,  795,   41,  163,  252,   40,  579,  701,   49,
         5700,  721,    4,  141, 3618,  353,    5,   64,  189,  449,   31,  118,
         4815,   40, 2297,   58,   31,   78,  167,  697, 3886,  712, 5658,    4,
         1939,   38, 8009,  119, 1034, 1194,  857,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1')}, 'transcript': {'tokens': tensor([[  21,  914,   26,    7, 1226,  279,   10,   87,   10, 4746,    8,  368,
            7, 3939,    8,  946, 2780,    5,   38,  511,    7, 1381,    4,   53,
         1346,  267,  546,    8,    7,  218,   94,    4,    8,   53,  246,  438,
         1768,    4,   25,   11,   57,  230,    4,   24,  451,  229,   13, 2240,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 2964,  169, 2154,  724, 2468, 7147,   69,    7, 2618,    8,  719,
          117, 1230,   35, 6937,   35, 7596, 1710,    6,  442,   12,   13, 1127,
         2468,    4,  736,  439,  203, 1255, 4711, 1755,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [7823,   94,   63, 4820, 1256,   94,    4,    8, 4820, 1256,   94,   46,
            7,  143,    8,  143, 4820, 1256,   94,   84,   63,    4,    7,  143,
            8,  143,   24,   11,  158,   66,   13, 4820, 1256,  179,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  84,   34, 9199,    5,  180,  552,  853, 3174, 4796,    5,  440,   24,
           66,  211, 3174, 4796,    4,    7, 1575,   35,  372,   59,  247,  119,
         1819, 2735,    9,    7,  179,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 180,   19, 1095,  108, 2333,  158,  240, 1028,   10,  670,    9,   58,
          389,    6,    8, 2852,   59,   18, 1374, 2197,    6,    4,    8,  474,
            4,   21,   11,    6,   86,  230,   55,  110,   10, 1005,   33,  218,
          939,  668,  232,  834,   29,   19,  339,  134,  116,   46,   53,  144,
           10,   51, 1644,  411,    8, 2736,    5,    2,    1,    1,    1],
        [  17,  370, 4506,   17,   24,  116,  323,   71,    7, 6144,  779,  569,
          164, 2676,   66,  475,   35, 2371, 1683,  979,   54,    4,    8,    7,
         3180,  164,  289,    4,   38,  786,    4,  346,    4,  859,    4,  230,
            4,   13,  176,    4,   95,  266,    4,   17,   11,    6,    7, 2636,
         4057,   10, 1557,   17, 1683,  518,   10,  155, 3280,  137,    2],
        [  19,  513,  270,   10,    7, 1224,    8,  487,  665,  336,   10,  150,
          103,   19,  220,  446, 3302,  206, 7490, 1390,   54, 7521,    6,  144,
          226, 2517,   48,    4,    8,   21, 1932,  126,   84,  162, 3695,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  77,  230,    4,   29,  339,  110,  508,   25,   39,  663,   12, 8681,
           12,   13, 1760,  321,    5,    8,   19,  213,   10, 7032,   13, 1455,
           17,   19,  154,   26,  133, 4501,    4,  166,   26, 8164,   54,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1'), 'cluster_tokens': tensor([[37, 83, 85, 37,  2, 50, 37, 85, 37, 29, 37, 49, 37,  2, 37,  2, 94, 11,
         38, 35, 37, 94, 11, 37, 59, 37, 18, 37, 37, 50, 56, 11, 37, 37, 88, 82,
         83, 11, 37, 85, 77, 37, 11, 38, 85, 49, 37, 32, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37,  9, 85, 38, 35, 32, 56, 37, 37,  8, 37, 49, 37, 17, 38, 23, 38, 35,
         94, 37, 31, 37, 37, 50, 32, 11, 34, 24, 38, 35, 35, 77, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [ 2, 56, 85, 94,  2, 56, 11, 37, 94,  2, 56, 11, 37, 50, 37, 50, 94,  2,
         56, 37, 85, 11, 37, 50, 37, 50, 38, 85, 35, 85, 37, 94,  2, 94, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 85, 28, 11, 37, 85, 38, 35, 35, 11, 83, 38, 85, 50, 35, 35, 11, 37,
         28, 38, 35, 35, 77, 75,  9, 94, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 38, 59, 37,  6, 35, 35, 49, 37, 94, 37, 38, 35, 37, 37, 79, 35, 35,
         77, 35, 37, 11, 37, 31, 11, 37, 85, 37, 83, 37, 37, 37, 37, 49, 37, 50,
         38, 35, 77, 11, 83, 38, 49, 37, 83, 11, 37, 85, 37, 38, 38, 35, 37, 29,
         11, 83, 37, 37, 37],
        [37,  4, 36, 37, 38, 83, 85, 37, 37, 28, 35, 35, 85, 83, 85,  2, 38, 24,
         32, 32, 49, 11, 37, 37, 32, 85, 88, 11, 38, 35, 11, 37, 11, 31, 11, 37,
         11, 37, 35, 11, 38, 35, 11, 37, 85, 37, 37,  2,  9, 37, 49, 37, 32, 37,
         37, 37,  9, 11, 83],
        [38, 85, 37, 37, 37, 56, 37, 31, 59, 37, 37, 59, 37, 38,  6, 59, 56, 37,
         29,  9, 49, 94, 37, 85, 85, 32, 31, 11, 37, 37, 40, 37, 37, 85, 50, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [50, 37, 11, 83, 49, 37, 88, 37, 38, 32, 37, 94, 37, 37,  2, 38, 11, 37,
         38, 88, 37, 88, 37, 32, 37, 38, 59, 85, 83,  2, 11, 37, 85, 29, 49, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37]], device='cuda:1'), 'lengths': tensor([50, 34, 36, 31, 56, 59, 37, 37], device='cuda:1'), 'ntokens': 340}, 'target': tensor([[4010,  769,   81,   47,   61,   14, 4860,   20,   16, 2486, 2234,   88,
         5457,    5,   38, 2473,   14, 1572, 3933,  295,  489,   16,   14,   23,
          351,   16,  329, 2642, 1001, 5841, 1640,    4,   32,  776,   40, 3656,
           95, 2740,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 376, 1804, 2154,  338, 1350, 2967,   20,  444, 1302,   15, 1096, 3260,
           15,   16, 4375,   20,  815,    4,  852,  848, 4842, 5888,   98,  151,
         4239, 2967,    4,   30,   28,  736,  950, 8549,  712,   27,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 933, 2271,  157,   76, 9602,   20,  157,    4,   16, 9602,   20,  157,
            5,    5,    5, 1935, 9602,   37,   14,  157,   76,    4,  129,  412,
         9602,   37,   27,  273,  201,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,  573, 9327,    5,  928,  836, 1544, 3174, 4796,    5, 2400,   83,
           32, 4671, 3174, 4796,    4,   14,  903,  235,   18,  122,   59,  315,
            6,  426, 1641, 4916,    9,   23,  201,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,  189, 1204,   31,  872,  472,  622,  240,    9, 1935,  221,    6,
           16, 1258,  158,  156,  371,  380, 4291,  158, 6066,  364, 4275,  615,
            4,   16, 1812,   30, 3525, 1240,    5,  298, 4368,   31,   43,  385,
            9, 7790,  343,  136,  109,  303, 1867,   16,  184,  530, 1875,   18,
         2081,   43,  433,  186,    5,    2,    1,    1,    1,    1,    1,    1],
        [ 376, 1783,  242, 8616,    4,   74, 3931,   60,  102, 1659,  237,  587,
          243, 1021,    4,  161, 1746, 7166, 1679,  242, 2450,  165,   83,    5,
           92, 3483,  161,  334,   44,   38, 1055, 4778,    4, 4254,    4, 4182,
            4, 3142,    4,  566,  202,  266,    4,   30,   27,  478,   14, 3670,
            4,   23,   15,  773,   32,   39, 1750,   22, 6391, 4572,  857,    2],
        [  72,  814,  393,    9,   14, 2480,   16, 3452, 3660,   78,   98, 2298,
           20, 8504,   20, 2492, 2170,  297,  610,  610,   28,  605,    5,  400,
           75,  653, 3306,   20,    4,  573,   36,  286,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 526,  414,    4,  795,   41,  163,  252,   40,  579,  701,   49, 5700,
          721,    4,  141, 3618,  353,    5,   64,  189,  449,   31,  118, 4815,
           40, 2297,   58,   31,   78,  167,  697, 3886,  712, 5658,    4, 1939,
           38, 8009,  119, 1034, 1194,  857,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1'), 'target_lengths': tensor([40, 36, 31, 33, 54, 60, 34, 43], device='cuda:1'), 'ntokens': 331, 'nsentences': 8}
##################### {'id': tensor([ 36213, 120383, 160119, 149187, 126055,   9288, 162978, 205433],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 8.3313e-03,  8.8196e-03,  5.3406e-03,  ...,  1.8921e-03,
          5.2490e-03,  8.6060e-03],
        [ 1.8311e-04,  2.1362e-04,  1.3123e-03,  ..., -4.2725e-04,
         -3.3569e-04, -4.8828e-04],
        [-2.0752e-03, -3.4790e-03, -4.5776e-03,  ...,  1.0590e-02,
          8.6975e-03,  7.9346e-03],
        ...,
        [ 2.1667e-03,  9.1553e-04, -9.1553e-05,  ..., -7.4463e-03,
         -8.4229e-03, -8.3313e-03],
        [-1.6785e-03, -8.8501e-04, -8.5449e-04,  ..., -8.3252e-02,
         -2.4994e-02,  7.1411e-03],
        [-2.5635e-03, -2.4109e-03, -2.2278e-03,  ..., -1.5259e-04,
          1.1902e-03,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([181440, 181440, 181440, 181440, 181440, 181440, 181440, 181439],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2, 1186, 2886, 6716,    4, 1593, 1443,   29,  306, 3345,   15, 2029,
            5,   64,   31,  329,   44, 1493,   31,  173,  313,   16,  268,   36,
         4860,   27,    4,   16, 5647, 1627,   31, 3219,   18,   18,    6, 3884,
          176,  485, 3709,    5,  222,   30,   47,   23, 1088,  219,   45,   45,
          426,  734,   78,   40, 3124,  371,  119, 1262,  996,   27,    4,   58,
           31, 2691, 1388,  209,    5],
        [   2, 1896,   15,   41,  107,  385, 1959,    4,   40,  542, 4815,   20,
           28, 6417,    5,  327,   27,  285, 4729,   22,   42,  285, 4729,   22,
           27,   30, 1550,    4,   30,   32, 3766,    4,  114,   32,  604,    4,
           50,  273, 5675, 2258,  704,  124, 1925,   37,  186,  503,    4,  114,
           32,    9,   23, 3579,  190, 1229,  676, 1602,    5,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,   43,    4, 2363,  351,  669,  758, 2641,  195,  200,   54,
           15,    4,  295,  259,  216,   78, 3827,  472,  891,   15,   97, 1129,
         1464, 2512,   15,    4, 7350,   15,   43,   23, 3037,  454, 2547, 2889,
           22,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  104,  309,  831, 2112,    4,   50,   43, 1798,   76,    4, 3332,
            6, 5078, 2272, 2560,   15, 3915,   28,  186,    4,  344, 3915,    4,
           30,   74,  621, 1549,   27,    4,   40,  643,    4,   30,  163,  981,
          623, 7483,  171, 1688,  219,  649,   18,    4,   40,  643,    4,   30,
           61,    6,  152,    6,    6,  236,   27,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 8322, 3115,   20,  107,  118, 3126,    9,   14, 1014,  534,    4,
           74, 6419,   22, 4247,    9,  141, 5591,  352, 3559,  191,  201, 2655,
          503,    4,    9,   23,   14,  157, 3235,   28, 2465,   15, 7658,  181,
         2023, 4449,   15,   83,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  327,  503,   40, 1285,   37,  186,    4,   90,  602, 9470,   88,
          176,  219,  158,   18,   28,  186,    4,  141,   23,  531, 1733,   15,
         1750,    6, 4738,   96,   28,  186,    4,   14, 1750, 1834,  843,    4,
          286, 1818,   28,   83,    4,   14, 8015,   23, 6810,  463, 5504,    4,
          124,   14, 2675,  435,   28, 4351,   42,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 1272,   83,   14, 4194, 1128,  247,   57,  311, 1430,    4,   50,
            9,   58, 1759,  332,    4,    9,  628,   43,   14, 4943, 3215, 6995,
           15,    4, 1061,  584, 2709, 3477,  177,  790,  236, 3650,   15,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  147, 1229,   90, 1096, 2424,   59,  338, 2407,  280,   23, 4308,
           78,  337, 2316,   45,  424, 1753,  616, 1739,   37,   47,   14, 9109,
            4,  612,  234,   45,  243,  152,  303,   28, 5286,    5, 5583, 7278,
            6, 1735,   78,   38, 3678,  197,   27,    9,  328, 5378,   52, 5818,
         4674,    4,   14,  136,   40, 3378, 1391,    4,  113,   40, 6990,  119,
          480,  673,    5,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[  25,  135,    4,   25,   11,   57, 2465,    4,   25,   66,   77,  117,
          214,  142,   55,   25,    5,   38,  511,   19,   11,   45,  100,  438,
          125,   19,   11,   45,  168,    8,   21,   11,    6, 3939,    4,    8,
           25,  135,    4,   19,  321,   12,  100, 2180,   18,   18,    6, 3884,
          176,    5,   38, 3794,    4,   17,   11,    6,    7, 9132,  608, 1043,
           19,   11,  121,  700, 1346,   55, 4432,   54,   10, 2240,  670,    5,
            2],
        [  29,  339,   11,    6,  498,  518,  131,  384, 2172,   54,  185, 2047,
            5,   70,   26, 7898,   42, 7898,   26,    7, 6408,   24, 1064,  120,
           24,  154,   17,  108, 2082, 2196,  220,   51,  509,  109, 8661,  103,
           24,  144,  691,  250,  341,    9,    7, 1406,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 103,   53,  169, 1744,  116,   13,  277,  908,  183,   69,  752,   10,
         2509,  159,  207, 3298, 1573,    4,    8,   13,  277,  523,  143,   69,
         1880, 5917,   85,  637,    4,   53,  506,  508,  159, 3226,   13,  509,
         2333,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  24,   66,   10,  229, 1123,   53,   11,   57, 3163,   10,   51,    7,
         3348,   12,   33,  453,  753,   12,  108,    6,    4,   13,  753,   17,
           26,  100,  211,  218,    4,   13,  753,   17,  217, 6167,   96,  110,
          333, 1127,  383,    4,   13,  753,   17,   11,    6, 2084, 1625, 1563,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [8084, 3531,  170,   10, 1103,  297,  362,    6,   20,  199,   13,  858,
           12,   70, 6204, 3071,  506,  274,  100,    9,   13, 5591,   35, 1218,
          375,  140, 1011,  179,  206,   94,   66, 2214,   10, 3901, 2465, 5259,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  70,  220,   51,  143, 9649,  254,   10,   51,   56,   15,  121, 3576,
           62,    9, 6462,    4,   10,   51,    7,  473,   12,  155,   94,   10,
         2056,  155, 1234,    4,   10,   66,  211,  207,   10, 2423,   69,    7,
         6266,   12,    7,   39,  430,  119, 1215,  109, 9237,    7, 4893,   12,
            7,  708,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 115,    7, 5873, 5318,   48,   17,  244,    7, 1830,  215,   53,  162,
         2839,   54, 1723,    6,    4, 1061,  584, 1274, 4039,   14,   48,  909,
         2965, 1049,  111,    4,   86,  106, 3611,    4,   67,  106,    7, 4699,
           17, 3611,   26,  999,   55,   25,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 115,    4, 5385,   71,    7, 2184,   59, 1775,  221,   20,    4,   71,
           33,   38, 3794,  438,    7, 4503,  465,   11,   18,   66,    7, 8511,
           12,  129, 2286, 1331,   54, 2184,   59, 1775,  221,   20, 4821,    5,
           38, 3794,  197,    9,   33,  841,   26,   13,  909, 4674,    4,    8,
           13,  909, 4674, 1847,   39, 2987,    4,  166,   26,   13,  211,  500,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:2'), 'cluster_tokens': tensor([[37, 59, 11, 37, 85, 77,  2, 11, 37, 85, 50, 37, 56, 49, 37, 37, 11, 38,
         35, 38, 85, 35, 37, 82, 37, 38, 85, 35, 37, 37, 37, 85, 37,  2, 11, 37,
         37, 59, 11, 38, 38, 37, 37, 38, 35, 35, 37, 35, 35, 11, 38,  4, 11, 37,
         85, 37, 37,  2, 75, 32, 38, 85, 35, 50, 59, 37, 49, 49, 37, 32, 94, 11,
         83],
        [83, 49, 85, 37, 49, 37, 37, 38, 35, 49, 50, 32, 11, 50, 85, 32, 11, 32,
         85, 37, 32, 38, 32, 37, 38, 59, 37, 37, 88, 94,  6, 38,  2, 37,  2, 37,
         38, 85, 31, 50, 33, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 37, 85, 49, 83, 37, 50, 50, 24, 37, 49, 37, 94, 37, 83, 37, 50, 11,
         37, 37, 50, 83, 50, 37, 28, 94, 37, 37, 11, 37,  6, 88, 37, 94, 37,  2,
          6, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [38, 85, 37, 49, 83, 37, 85, 77,  2, 37, 38, 37, 56, 37, 37,  2,  9, 37,
         37, 37, 11, 37,  9, 37, 85, 37, 50, 50, 11, 37,  9, 37, 38, 35, 77, 37,
         50, 50, 24, 11, 37,  9, 37, 85, 37, 38, 35,  2, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [28,  6, 37, 37, 38, 35, 35, 37, 77, 37, 37, 94, 37, 50, 94, 94,  6, 59,
         37, 37, 37,  9, 38, 35, 77, 35, 31, 94, 37, 56, 85, 49, 37, 28,  2, 56,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [50,  6, 38, 50,  2, 37, 37, 38, 38, 77, 35, 35, 31, 37, 29, 11, 37, 38,
         37, 37, 37, 37, 56, 37, 16, 37, 94, 11, 37, 85, 50, 83, 37, 80, 37, 37,
         94, 37, 37, 38, 35, 75, 56, 37, 59, 37, 88, 37, 37, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 37, 56, 88, 31, 37, 37, 37, 34, 24, 37, 85, 29, 49,  9, 37, 11, 84,
         73, 60, 56, 38, 31, 38, 35, 77, 83, 11, 83, 37,  9, 11, 37, 37, 37, 32,
         37,  9, 85,  2, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 11, 83, 37, 37, 38, 35, 35, 35, 77, 11, 37, 37, 38,  4, 82, 37,  9,
         85, 85, 35, 85, 37, 29, 37, 38, 35, 43, 49, 38, 35, 35, 35, 77, 29, 11,
         38,  4, 82, 37, 37, 32, 85, 37, 38, 35, 11, 37, 37, 38, 35, 49, 38, 32,
         11, 37, 85, 37, 50, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37]], device='cuda:2'), 'lengths': tensor([73, 46, 39, 50, 38, 52, 44, 62], device='cuda:2'), 'ntokens': 404}, 'target': tensor([[1186, 2886, 6716,    4, 1593, 1443,   29,  306, 3345,   15, 2029,    5,
           64,   31,  329,   44, 1493,   31,  173,  313,   16,  268,   36, 4860,
           27,    4,   16, 5647, 1627,   31, 3219,   18,   18,    6, 3884,  176,
          485, 3709,    5,  222,   30,   47,   23, 1088,  219,   45,   45,  426,
          734,   78,   40, 3124,  371,  119, 1262,  996,   27,    4,   58,   31,
         2691, 1388,  209,    5,    2],
        [1896,   15,   41,  107,  385, 1959,    4,   40,  542, 4815,   20,   28,
         6417,    5,  327,   27,  285, 4729,   22,   42,  285, 4729,   22,   27,
           30, 1550,    4,   30,   32, 3766,    4,  114,   32,  604,    4,   50,
          273, 5675, 2258,  704,  124, 1925,   37,  186,  503,    4,  114,   32,
            9,   23, 3579,  190, 1229,  676, 1602,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,   43,    4, 2363,  351,  669,  758, 2641,  195,  200,   54,   15,
            4,  295,  259,  216,   78, 3827,  472,  891,   15,   97, 1129, 1464,
         2512,   15,    4, 7350,   15,   43,   23, 3037,  454, 2547, 2889,   22,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 104,  309,  831, 2112,    4,   50,   43, 1798,   76,    4, 3332,    6,
         5078, 2272, 2560,   15, 3915,   28,  186,    4,  344, 3915,    4,   30,
           74,  621, 1549,   27,    4,   40,  643,    4,   30,  163,  981,  623,
         7483,  171, 1688,  219,  649,   18,    4,   40,  643,    4,   30,   61,
            6,  152,    6,    6,  236,   27,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [8322, 3115,   20,  107,  118, 3126,    9,   14, 1014,  534,    4,   74,
         6419,   22, 4247,    9,  141, 5591,  352, 3559,  191,  201, 2655,  503,
            4,    9,   23,   14,  157, 3235,   28, 2465,   15, 7658,  181, 2023,
         4449,   15,   83,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 327,  503,   40, 1285,   37,  186,    4,   90,  602, 9470,   88,  176,
          219,  158,   18,   28,  186,    4,  141,   23,  531, 1733,   15, 1750,
            6, 4738,   96,   28,  186,    4,   14, 1750, 1834,  843,    4,  286,
         1818,   28,   83,    4,   14, 8015,   23, 6810,  463, 5504,    4,  124,
           14, 2675,  435,   28, 4351,   42,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [1272,   83,   14, 4194, 1128,  247,   57,  311, 1430,    4,   50,    9,
           58, 1759,  332,    4,    9,  628,   43,   14, 4943, 3215, 6995,   15,
            4, 1061,  584, 2709, 3477,  177,  790,  236, 3650,   15,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 147, 1229,   90, 1096, 2424,   59,  338, 2407,  280,   23, 4308,   78,
          337, 2316,   45,  424, 1753,  616, 1739,   37,   47,   14, 9109,    4,
          612,  234,   45,  243,  152,  303,   28, 5286,    5, 5583, 7278,    6,
         1735,   78,   38, 3678,  197,   27,    9,  328, 5378,   52, 5818, 4674,
            4,   14,  136,   40, 3378, 1391,    4,  113,   40, 6990,  119,  480,
          673,    5,    2,    1,    1]], device='cuda:2'), 'target_lengths': tensor([65, 57, 38, 56, 41, 55, 36, 63], device='cuda:2'), 'ntokens': 411, 'nsentences': 8}
##################### {'id': tensor([ 30649, 197852, 130523, 220790, 211709,  97538, 122978, 207610,  53064,
         67032, 198473,  88598, 187993, 151632,  64438, 170333],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[-1.5259e-04, -1.0681e-03, -2.1362e-04,  ...,  2.7466e-04,
          1.5259e-03,  2.8381e-03],
        [ 0.0000e+00, -8.5449e-04, -6.1035e-05,  ..., -1.4343e-03,
         -1.3428e-03, -1.4648e-03],
        [ 1.8921e-03,  3.0823e-03,  2.1973e-03,  ...,  3.0518e-05,
          3.0518e-05,  3.0518e-05],
        ...,
        [ 3.6743e-02,  3.3173e-02,  2.4933e-02,  ..., -7.0496e-03,
         -7.3853e-03,  0.0000e+00],
        [ 1.2817e-03,  1.1597e-03,  1.0071e-03,  ...,  1.8311e-04,
         -9.1553e-05,  0.0000e+00],
        [ 1.1597e-03,  7.0190e-04,  7.0190e-04,  ...,  4.2725e-04,
          1.8311e-04,  0.0000e+00]], device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([117440, 117440, 117440, 117440, 117440, 117440, 117440, 117440, 117440,
        117440, 117439, 117439, 117439, 117439, 117439, 117439],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,   41,  888,    4,   38, 4683,    4,   30,   27, 1528,    5,  327,
           27,   30,   42, 2401,   30,  865,  656,  650, 5270, 2044,  358,   64,
         5527,  145,   31,   40, 1538,   28, 3807,  186,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   99,   82,  167, 4681,    5,   72, 3194,  275,  285,   45,   37,
          861,    6, 4807,    6,   16, 1571, 5076, 9773, 1302,   15,    4,   16,
          477,  449,   31,  252,  482, 1306,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  354,  167, 3709,   60,  252,  843,    5, 1173,  933,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  228,   58, 4485,  332, 3650,   15,  406, 1667,   16, 5537,   39,
         1607,   16,   31,   82, 1746,  112,  152,  930,    6, 1867,    4,   34,
         3461,   39, 1395,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 7961,   22,   41,  580,  212, 8247,    4,   34, 1602,   41, 1121,
           42, 4799,   48,   41,  410,  242, 2006,   18,   42, 2785,  191,   41,
            4,   74, 2254,   41,   30,  320,    4,  255,   41,   47,  534, 1561,
         5564,   42,    1,    1,    1,    1],
        [   2,   92,   27,  113,   47,  149,   52, 8541,    4,   14,   14, 8361,
         5120,    4,  519,  139,   14, 6038,    9, 1437,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72, 6558,    4,   50, 5637,   16, 5022,   14,  808,  642,   20,
          319,    4,    9,  628,   23, 4366, 2053,  130,    4,   36, 5194,   28,
          203,  907,   22,    4,   16,   36,   27,  107,   47,  184, 2817,   15,
            5,    1,    1,    1,    1,    1],
        [   2,  312, 5648,   35,  483,  174,    6,  416,  121,   22,   18, 6364,
           20, 7001,   88,  392,  787,  216,   90,   97,  497, 8979,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  720,  239, 4053,   95, 6003,   18,    4,   50,   30, 2967,   23,
         1923,    4, 1140,  525,  411,    4,   30,   31, 2588,  425, 4753, 3452,
            4,   75,  149,    9,  302, 6541,   15,  853,  122,    5,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  146,  353,   16, 1058,    4,   74,   14, 8337,   22, 5781,    4,
         3115,  107,   68,  303,   22,  361,   83,   32,   52, 1834,  714,   65,
            4,   28,  701,    4,   50,  105, 8337,   22, 5757, 6625,   76,    5,
            1,    1,    1,    1,    1,    1],
        [   2,  912, 3746,   23, 1140,  311,    6,  195, 1338,  522,  382,   28,
          462, 6842, 4702, 6045, 4136,  171,  181,  219,   18,  249,   18,    4,
           88,   40, 5513,    6, 6842, 4702, 1140,  311,    6,   28, 3821,    5,
            1,    1,    1,    1,    1,    1],
        [   2,   99,   56, 3247,   14, 6696,   20,  912,   35,   16,  590, 4591,
           23, 9612,   16, 5102,   15,   61,   16, 5483,  382,  253, 3746,   23,
          808, 2152,  790,  420,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   27,  789,   40, 2038,   37, 1309,  587,  119,   28,   58,
         3383,  156, 1314,  235,   15,   16, 7592,   15, 6251,   15,   16,  102,
          912, 1685,   23, 2989,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72, 2800,  118,   38, 1174, 4778,    9,   23, 3248,  197,  343,
         5377,   45, 2446,   37,  517,   61,    4, 1886,   48,  374, 1048,   20,
          112, 2999,   35, 3736, 8439,   98,  102, 1287, 4450,    4, 7977,   31,
           30, 6299,  139,   47, 7392,    5],
        [   2,   92, 2250,  118,    9,   14, 7412, 2381,    4,   34, 1673,    4,
         3876,   59,  827,  760,    4, 1541,  424,  124, 1432,  287, 2531,  161,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  350, 2428,  418, 2203,   14,  731,   49,  448, 1925,   37,   16,
         9324,   16,   90, 6658, 2203,  306,   49,  448, 1246, 7501,   37,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[ 225, 1119,    4,   38, 1461,    4,   17,   11,    6, 1284,    5,   70,
           26,   21,   42,   26,   17, 7148,  650, 3727, 1994,  358,    8, 4069,
            4,   19,   73,   51,   13,  277,  593, 4187,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   21,   34,  133, 3315,    8,   19, 1385,  185, 4673,  214,    8,
          442,  185, 1968, 3051,    6,   17,   19,  213,   10, 1452,   71,   25,
          440,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 294, 3940,    5,   68,  386,   65,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  55,  251,  370,  215,    4,   89, 1970,    8, 3460, 1102,   14,   48,
           12, 1167,    4,    8,   19,   34,  914,  244,  221,  505, 1563,   80,
         6088,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 103,   25,  162,  461,   12,   33, 5673,    4,   70,  169,   25,  289,
           42,   63,   25,  850, 1203,  494,   42,  238,    4, 2859,   46,  138,
           87,   25,  276,  135,    4,  125,   25,   11,   57,   86, 3531,   10,
          456,   80,   21,   42,    2],
        [  29,   33,   26,   86,  116,   13, 6429,   80, 7291,    6,  224,   21,
           11,    6,   13, 6429,   80, 3295,    9, 1146,   79,  238,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  89, 2574,   26, 5205,    8, 4970,   63,    7,  473,  825,  120,    7,
         3022,  188, 2096,   10,   87,   21, 1574,    4,    8,   24, 2775,   11,
           18, 5768,   62,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 276,   13, 2900, 6815, 5707,   62,  392,  439,  143,    9, 7001,  254,
          225,  323,    9, 8979,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [8310,   54,   17,    4,    7, 2468,   12, 2573,    4, 1067,  525,  436,
            4,   17,   19,   34,  752,   10,  747, 2653,    4,  288,   51, 1217,
            6,    9,  248, 6874,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  67,    7,  207,    7,  227,   93,   45, 1604, 2334, 2895, 5070,  170,
           46,   24,   11,  121,  115,  278,   13, 1234,   10, 9375,  347,  117,
          227,   93,   45, 1604, 2334,   63, 7071,  341,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [ 120,   53,  245,  487, 2980,   54, 2263, 1315,    4,   21,  220,  305,
           79,  294,   79, 1111, 6052,   12, 2533, 1390,   10,  229,   13, 1127,
         1116,  569,   12, 2263, 1315,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  21, 1797,    6,    7,   39,   22, 1522, 3667,    8, 2322,   12, 7932,
         2673,   96,    8, 4157,    6,  142,  270,  490,    7,   69,    6,  307,
           12,    7,  473, 2217, 1137,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  25,   11,   57,  961,  736,  439, 7692,  629, 2481, 2286,   62,  235,
            8, 5225, 5108,    8, 2288, 5225, 5108,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  19,  388,    9, 3189,    9,    7, 1832, 2930,   84,    4, 7774,   62,
           77, 1587,   12,  993,  106,    7, 1465,   80, 2192, 6631,  793,    4,
          281,   12,  166,   19,  465,   11,   18,  661,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   21,  875,    6,   25,  199,    7, 7771,   12,   70,   11,    6,
          226,  434, 1440,    4, 2243,   59,  827,  760,    4,  883,  424,    4,
         1579,  287,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  19,  154,  281,   12,  134,  169,   51, 8661,    8,  958,  756,    4,
            8,   79, 5474,    4,  294,   12,  134,  169,  914,   51, 7078,  706,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 88, 11, 38, 35, 11, 37, 85, 37,  2, 11, 50, 85, 37, 11, 85, 37,  9,
         35, 94, 35, 11, 37, 83, 11, 38,  6, 38, 37, 50, 83,  2, 11, 83, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 85, 83,  2, 37, 38, 31, 50,  2, 56, 37, 31, 50,  2, 36, 37, 37,
         38, 88, 37, 88, 37, 37, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [50, 83, 11, 38, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 50,  4, 24, 11, 37,  9, 37,  9, 83, 38, 31, 37, 26, 11, 37, 38, 85,
         83, 37, 35, 35,  2, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 85, 32, 37, 37, 94, 11, 50, 85, 37, 88, 11, 85, 37, 37, 35, 35,
         11, 83, 11, 49, 11, 37, 85, 37, 83, 59, 11, 37, 37, 85, 77, 83,  6, 37,
         16, 37, 37, 11, 83],
        [83, 37, 85, 83, 83, 37, 32, 37,  9, 37, 11, 37, 85, 37, 37, 32, 37, 56,
         37, 28, 37, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 88, 85, 28, 37, 28, 85, 37, 37, 24, 37, 37, 28, 85, 31, 37, 85, 37,
         37, 11, 37, 38, 85, 85, 35,  2, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [83, 37,  9, 23, 49, 31, 17, 24, 50, 37, 25, 37, 37, 85, 37, 25, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [36, 49, 37, 11, 37, 32, 37, 94, 11, 38, 35, 77, 11, 37, 38, 85, 49, 37,
         30, 32, 11, 83, 38, 35, 37, 37, 34, 23, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 83, 37, 38, 35, 35, 35, 56, 36,  6, 37, 11, 38, 85, 35, 83, 31,
         37, 94, 37, 33, 83, 37, 38, 35, 35, 35, 56, 85, 83, 33, 11, 83, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 83, 31, 23, 49, 38, 35, 11, 37,  6, 49, 37, 50, 37, 34, 23, 37,
         28,  9, 37, 49, 37, 50, 38, 35, 37, 38, 35, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 23, 37, 37, 38, 35, 35, 29, 37, 29, 37, 32,  9, 77, 37, 94, 37, 49,
         37, 37, 37, 37, 37, 77, 37, 37, 37,  9, 24, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 85, 77, 49, 34, 24, 36, 37, 28, 35, 31, 35, 37,  2, 94, 37, 49,  2,
         94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [38, 31, 37,  9, 37, 37, 94, 56, 37, 11, 29, 31, 50, 50, 37, 32, 37, 37,
          9, 37, 94, 29, 35, 11, 75, 37, 37, 38, 85, 85, 35, 59, 11, 83, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 49, 37, 37, 37, 37, 94, 37, 50, 85, 37, 85, 31,  9, 11, 38, 35,
         35, 35, 11, 38, 35, 11, 38, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [38, 59, 75, 37, 37, 85, 38,  2, 37, 94, 77, 11, 37, 37, 56, 11, 50, 37,
         37, 85, 83, 38,  2, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37]], device='cuda:6'), 'lengths': tensor([34, 27,  7, 27, 41, 24, 29, 18, 30, 34, 31, 32, 21, 34, 28, 26],
       device='cuda:6'), 'ntokens': 443}, 'target': tensor([[  41,  888,    4,   38, 4683,    4,   30,   27, 1528,    5,  327,   27,
           30,   42, 2401,   30,  865,  656,  650, 5270, 2044,  358,   64, 5527,
          145,   31,   40, 1538,   28, 3807,  186,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  99,   82,  167, 4681,    5,   72, 3194,  275,  285,   45,   37,  861,
            6, 4807,    6,   16, 1571, 5076, 9773, 1302,   15,    4,   16,  477,
          449,   31,  252,  482, 1306,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  354,  167, 3709,   60,  252,  843,    5, 1173,  933,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 228,   58, 4485,  332, 3650,   15,  406, 1667,   16, 5537,   39, 1607,
           16,   31,   82, 1746,  112,  152,  930,    6, 1867,    4,   34, 3461,
           39, 1395,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [7961,   22,   41,  580,  212, 8247,    4,   34, 1602,   41, 1121,   42,
         4799,   48,   41,  410,  242, 2006,   18,   42, 2785,  191,   41,    4,
           74, 2254,   41,   30,  320,    4,  255,   41,   47,  534, 1561, 5564,
           42,    2,    1,    1,    1,    1],
        [  92,   27,  113,   47,  149,   52, 8541,    4,   14,   14, 8361, 5120,
            4,  519,  139,   14, 6038,    9, 1437,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72, 6558,    4,   50, 5637,   16, 5022,   14,  808,  642,   20,  319,
            4,    9,  628,   23, 4366, 2053,  130,    4,   36, 5194,   28,  203,
          907,   22,    4,   16,   36,   27,  107,   47,  184, 2817,   15,    5,
            2,    1,    1,    1,    1,    1],
        [ 312, 5648,   35,  483,  174,    6,  416,  121,   22,   18, 6364,   20,
         7001,   88,  392,  787,  216,   90,   97,  497, 8979,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 720,  239, 4053,   95, 6003,   18,    4,   50,   30, 2967,   23, 1923,
            4, 1140,  525,  411,    4,   30,   31, 2588,  425, 4753, 3452,    4,
           75,  149,    9,  302, 6541,   15,  853,  122,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 146,  353,   16, 1058,    4,   74,   14, 8337,   22, 5781,    4, 3115,
          107,   68,  303,   22,  361,   83,   32,   52, 1834,  714,   65,    4,
           28,  701,    4,   50,  105, 8337,   22, 5757, 6625,   76,    5,    2,
            1,    1,    1,    1,    1,    1],
        [ 912, 3746,   23, 1140,  311,    6,  195, 1338,  522,  382,   28,  462,
         6842, 4702, 6045, 4136,  171,  181,  219,   18,  249,   18,    4,   88,
           40, 5513,    6, 6842, 4702, 1140,  311,    6,   28, 3821,    5,    2,
            1,    1,    1,    1,    1,    1],
        [  99,   56, 3247,   14, 6696,   20,  912,   35,   16,  590, 4591,   23,
         9612,   16, 5102,   15,   61,   16, 5483,  382,  253, 3746,   23,  808,
         2152,  790,  420,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   27,  789,   40, 2038,   37, 1309,  587,  119,   28,   58, 3383,
          156, 1314,  235,   15,   16, 7592,   15, 6251,   15,   16,  102,  912,
         1685,   23, 2989,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72, 2800,  118,   38, 1174, 4778,    9,   23, 3248,  197,  343, 5377,
           45, 2446,   37,  517,   61,    4, 1886,   48,  374, 1048,   20,  112,
         2999,   35, 3736, 8439,   98,  102, 1287, 4450,    4, 7977,   31,   30,
         6299,  139,   47, 7392,    5,    2],
        [  92, 2250,  118,    9,   14, 7412, 2381,    4,   34, 1673,    4, 3876,
           59,  827,  760,    4, 1541,  424,  124, 1432,  287, 2531,  161,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 350, 2428,  418, 2203,   14,  731,   49,  448, 1925,   37,   16, 9324,
           16,   90, 6658, 2203,  306,   49,  448, 1246, 7501,   37,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([33, 31, 12, 28, 38, 21, 37, 23, 34, 36, 36, 29, 29, 42, 25, 24],
       device='cuda:6'), 'ntokens': 478, 'nsentences': 16}
##################### {'id': tensor([173432,  35654, 217610,  13025, 126214, 183918,  77495, 198956,  22376,
        195587, 163225, 192728,  66902, 216373, 194841,  82954],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 3.6926e-02,  3.3417e-02,  2.8625e-02,  ...,  3.6316e-03,
          3.4485e-03,  3.6011e-03],
        [-4.2419e-03, -1.9226e-03,  3.0518e-05,  ..., -2.0752e-03,
         -1.8921e-03, -2.8687e-03],
        [-6.1035e-04, -6.1035e-04, -7.9346e-04,  ...,  6.1035e-05,
          5.4932e-04,  1.1902e-03],
        ...,
        [ 9.7656e-04,  2.1362e-04, -7.0190e-04,  ...,  1.9531e-03,
          7.0496e-03,  5.2490e-03],
        [-1.0986e-03, -9.1553e-04, -4.8828e-04,  ..., -3.2776e-02,
         -3.2654e-02,  0.0000e+00],
        [ 5.1575e-03,  6.1340e-03,  6.0120e-03,  ..., -3.0518e-04,
         -7.9346e-04,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([129120, 129120, 129120, 129120, 129120, 129120, 129120, 129120, 129120,
        129120, 129120, 129120, 129120, 129120, 129119, 129119],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2, 1092,  380,   32,    4,   41,  940,   14, 1270,    5, 1092,  380,
           32, 1162,  372, 1761,   20,    5, 1272,  123,   41,  317, 1817,  118,
         3644,  221,  726,   20,  249,  605,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   31,  705,    4,  355, 6252, 1656,   60,  343,   60, 1451,
         2975, 2974,   98,   44,   14,  404, 2510, 3496,   18,   35,  360,  777,
         1643,   15,   16,   23,  751,  342, 3414,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  312,  627, 4511,   31,  182,  151, 6374,   24,  160,  856,   98,
          102, 1464,   16,    9,   40, 2099,  181, 3435,    5, 4885, 2638,   31,
           14,  342, 1243,   22, 3103,   88,  118, 5940,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  114,   31, 3554, 1855,    4,  503,   36,  257,  196,   29,
         4349,   61, 1903,    4,   50,  621,  330,  187,  713,  129,  732,  728,
          151,  351, 9320,    4,   16,   30,   27,   40, 5791,   37, 6002,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  139,   14, 1439,  912, 3312,  951,   78,   14, 2249, 3526,
          262, 2533,   37,  304,  219,  649,  356,    4,   16,  789,  139, 4784,
           20,  732, 8667,   78,  196,   52,  751, 2557, 2242, 1468,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  310,   78, 2051,   75,   29,  167,  177, 5096,    4,   50,   43,
         1166,    4,  981,  611,   28, 8495,    4, 1417,   28,  127,    4,  363,
           14,    4,   14,   36,   47,  516,  124,  123,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3192,   41,  149,  648,   61, 3354,  441, 3935, 3956,   44,  657,
          737, 1010, 1660,   16,  938, 2633,  340,  271,    4, 7282,   20,    4,
         6620,  674,    5, 1612, 1098,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3093,   20, 5775, 4706,  240,   20, 5861,   28,  725,    4,  782,
           36,  337,  167, 3750,   15, 2206,  130,    4,   16,   43, 7819,   15,
           52, 2778, 1048,   37, 5887,   15,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3826,   37,  124, 1071,  127,   32,   60, 2798,  611, 8109,  186,
            4,   16,   36,   27,  704,    4,  114,   32,  534, 6254, 2934,    4,
          139,  114,   32, 6254,  112, 3639, 2934,    4,  782,   32,   36,  632,
          269,  776,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  173,  210, 1664,  161,   36,  253,  698,  642, 2757,   46,
          654,  624,    6, 4878, 1806,  469, 2224,    6,  674,   20,  293,  457,
            4, 1509, 5924,   20, 2766,  152,  232,   56, 5721,   60,  314,    9,
           23,  674,   20,  293,  457,   35, 3176, 7165,  165,    5],
        [   2,  298, 2957,   32,  485,  585, 4163,    4,   88,  112,   58, 2295,
          141, 3895,  312, 4183, 3735,    4,  223,   30, 1311,   38,  748, 2704,
         2801,  119, 3157,  980,   30,   32, 5855,    9,    6,  314, 5732,   15,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  202,   82, 1061,    4,   43,   82,  798,    5, 2093,  331, 5545,
           20,    4,   14,   32, 2794,   15,    4, 1457, 3513,  190,  553,  803,
          849,  781,  176,  481,    6,  112,  295, 4845, 2798,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  441,  462,  332, 6079,   31,  196,    9,  151, 4409, 1337,    6,
           61,  151, 3672,   35,  748,  973,   35,  754,  293,  156, 2916,    5,
           64,  482, 4864,   31,  210, 1664,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2660, 1097, 1480,   43,  966, 1262, 1194,    4,  268,   43,  831,
          537,  788,    4,   50,   43,  190, 1097,  951,    4,   34,  295,  435,
         2159,  681,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  228,  328, 1003, 1904,   31,    4,   50,   31,  771, 4738, 2086,
           16, 2324,  667, 1398,    5,  460, 1486, 3945,   31, 7367,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,   55,  345,   20,  113,   52,  585, 4074,    6,  242, 7700,
           46,   31, 3615, 1071,  897,  420,   46,   16,  454,   14, 5027,  344,
         1280, 3234,    6,    9,   14, 7278, 1834,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:0')}, 'transcript': {'tokens': tensor([[1189,    4,   29,  339,   11,    6,  289,   21,   11,    6, 1491,    4,
            8,  339,   11,    6,  289,   21,   11,    6,  384,  372, 1761,   20,
            4,    8,  115,   25,   73, 1948,  205, 1817,    8,  446, 1835,   13,
         1484, 3762, 2293,   59,    5,    2,    1,    1,    1,    1],
        [  67,   25,  135,    4,   19,  154,   25,   63, 4130,   71, 2084, 1625,
          128,    6,   46,    7,   81, 2510, 3496,   18, 9875,    6,    8,   77,
          117,  214,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  91,  383,    4,   19, 7262,   62,  126,   12,    7, 2657,    9, 3918,
         1118,  432,   13, 3040,   71,   13, 3532,   91,    4,    8,   19, 5429,
           62,  199,   13,  682,  181, 3435,    4,  206,   19, 1060,    7, 2859,
           57,    6,    6,   55,   13, 2705,    5,    2,    1,    1],
        [   8,  120,   19,  289,  923, 1738,    4,   21,  220,  499,   51,   29,
         4733,   17,  211,   91, 3485,   12,  282,  700, 6317,    6,  486,    4,
          166,   26,   13, 3462,  474,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  113,    7,  473,  203, 2470,  247,   55,    7, 3299,  267,   48,
           12, 2533,  382,  399,    4,    8,  113,    4,   12,  538,    4, 3547,
         6952,   55,  486,  733, 3609,   12,  218, 1369,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  94,   63,   29, 4493,   12, 6608,   17,   53,  780,    8, 2509, 1459,
            4,  276,   94,  148,  192,   11,   18,  213,   10,  109,   73,   11,
           18,    4,   10,  873, 1417,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 432,   77,    4,  305,   13,  274,   85,  117, 2792,    6,   44,   97,
          737, 1010, 1144,    8,  415, 2633, 2041,    4,  179,   82,    6,    4,
         6229, 1106,    5, 7050,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  240, 2120,   66, 2138, 4021,  752,   10,  661,  347,   21,  188,
           33,  133, 2035, 1236,  297,  293,  111, 3495,   35,   18,  500,   62,
          800,    4,    8,   53,   11,  121,  367,  132,   71,   13,  800,   12,
         1254, 7052,    6,    5,    2,    1,    1,    1,    1,    1],
        [ 125, 2392,   37,  109, 1065,    4,   24,   11,  158,   51, 7258,   62,
           71, 4012,   80,   33,    4,    8,   21,   11,    6,  509,  103,   24,
          154,  835,   80,   21,    4,  276,  103,   24,  213,   10,  154,  835,
           80, 2826,  347,   24,  451,  492,   87,   21,    5,    2],
        [   8,  168,   21,   26,   55,    7,  245,  183,  291,  121,  233,   62,
           85, 1366,   46,  108,  245, 4878, 1806,  469,  816,   24,  293,  457,
            4, 6712, 5831,    6, 1103, 3007,   54,   71,  282, 1117,   13,   24,
          293,  457, 7757,   54,    5,    2,    1,    1,    1,    1],
        [   8,   29,   70,   24,  487,   71,   34,  172,   13,  264,  207,   12,
          826,   80, 1009,   39,    9, 3562,    4,  359,   13, 1039,  434,  229,
         1261,    4,  166,   24, 6532,    9, 5855,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 101,   34, 1061,    4,  225,   34,  798,    5,  100,   13,  325,   12,
            7, 1323,    6,   24, 1618,    4,   53, 3994,   11,   18, 2603,   56,
         7038, 1568,   80,  159, 1666, 4388,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 391,  215,  581,   19,   34, 1074,    9,   13, 5200,    9,   13,   56,
         2561,   35,   45,  973, 2102,   54,  325,    4,    8,  440,   19,   11,
           45, 4379,   85, 1366,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  225, 3673,   62, 1406,  290,  125,  225,  692,   10,  229, 1123,
          225, 3673,   62,  250,  225, 1425,  267,  708,  169, 2034,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   19, 1425,   17,   85,   17,  765,   17,   70,   19,  451,  508,
           10,   89,   94,   26, 1370,    8,  958,    4,    8,   17,   11,    6,
           70,   19,  513,  432,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   70,   19,   11,   45, 2659,   55,   26,    7, 5708,   12,   13,
          264, 1329, 6813,   46,   19,   11,  158,  367,   10,   33,   13,  277,
         1065,   46,    8, 1645,    7, 4936,   12,   13,  264, 1455,  199,    7,
         2781, 1234,    5,    2,    1,    1,    1,    1,    1,    1]],
       device='cuda:0'), 'cluster_tokens': tensor([[83, 11, 83, 49, 85, 37, 88, 37, 85, 37, 28, 11, 37, 49, 85, 37, 88, 37,
         85, 37, 38, 35, 35, 77, 11, 37, 83, 37,  6, 83, 85, 25, 37, 59, 37, 37,
         94, 32, 49, 35, 11, 83, 37, 37, 37, 37],
        [37, 37, 59, 11, 38, 59, 37, 85,  2, 37, 38, 35, 35, 37, 11, 37, 38, 89,
         35, 35, 94, 37, 37, 50, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 24, 11, 38,  9, 31, 37, 37, 37, 94, 37,  9, 56, 37, 37, 76, 37, 37,
         31, 50, 11, 37, 38,  8, 31, 37, 37, 38, 35, 35, 11, 37, 38, 31, 37, 49,
         77, 37, 37, 37, 37, 38, 11, 83, 37, 37],
        [37, 37, 38, 88, 83,  2, 11, 37,  6, 83, 38, 83,  2, 37, 50, 50, 94, 37,
         32, 50, 36, 37, 50, 11, 37, 85, 37,  2, 31, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 37, 37, 38, 52, 77, 37, 37, 75, 37, 31, 37, 28, 38, 35, 11, 37,
         83, 11, 37, 83, 11,  2,  9, 37, 50, 50, 23, 37, 50, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [56, 85, 83, 98, 37, 23, 37, 37, 88, 37, 94, 50, 11, 83, 56, 50, 85, 85,
         35, 88, 37, 37,  6, 85, 35, 11, 37, 85,  2, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 11, 49, 37, 59, 37, 37, 32, 37, 82, 38, 35, 35, 32, 37, 38, 35,
         94, 11, 94, 53, 37, 11, 28, 38, 11,  9, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 35, 56, 85, 31, 24, 49, 37, 59, 83, 37, 85, 37, 83, 38, 35, 35, 35,
         83,  2, 38, 35, 35, 31, 23, 11, 37, 37, 85, 35, 85, 37, 37, 37, 23, 37,
          6, 94, 37, 11, 83, 37, 37, 37, 37, 37],
        [37, 83, 77, 37, 24, 11, 38, 85, 35, 38, 36, 31, 37, 56, 37, 37, 11, 37,
         37, 85, 37,  2, 37, 38, 59,  2, 37, 37, 11, 83, 37, 38, 88, 37, 59,  2,
         37, 56, 83, 38, 85, 50, 85, 37, 11, 83],
        [37, 37, 37, 85, 37, 37, 83, 24, 38, 35, 35, 31, 37, 28, 11, 37, 83, 56,
         35, 35, 35, 38, 35,  2, 11,  2,  9, 37, 38, 35, 49, 37, 32, 37, 37, 38,
         35,  2,  9, 49, 11, 83, 37, 37, 37, 37],
        [37, 83, 50, 38, 31, 37, 85, 83, 37,  2, 83, 37, 59, 37, 49, 38, 37, 94,
         11, 37, 37, 32, 31, 49, 94, 11, 37, 38, 31, 37, 25, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 84, 11, 37, 85, 34, 11, 37, 37, 83, 37, 37, 50, 37, 38, 31, 11,
         37, 85, 85, 35, 83, 38, 35, 28, 37, 37, 83, 56, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [34, 24, 83, 38, 85, 49, 37, 37,  9, 37, 37, 38, 35, 38, 35, 35,  9, 49,
         83, 11, 37, 83, 38, 85, 35, 16, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 49, 31, 37, 35, 37, 37, 85, 37, 49, 83, 37, 49, 31, 50, 37, 31,
         37, 56, 85, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 37, 37, 24, 37, 50, 38, 85, 88, 37, 37, 56, 85, 94, 37,
         94, 11, 37, 37, 85, 37, 50, 38, 85, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 50, 38, 85, 35, 88, 37, 85, 37, 94, 37, 37,  2, 32,  9, 11, 38, 85,
         35, 85, 37, 37, 37, 50, 24, 11, 37,  6, 37, 83, 37, 37,  2, 32, 37, 37,
         28, 94, 11, 83, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([42, 28, 44, 31, 34, 31, 30, 41, 46, 42, 33, 32, 30, 24, 30, 40],
       device='cuda:0'), 'ntokens': 558}, 'target': tensor([[1092,  380,   32,    4,   41,  940,   14, 1270,    5, 1092,  380,   32,
         1162,  372, 1761,   20,    5, 1272,  123,   41,  317, 1817,  118, 3644,
          221,  726,   20,  249,  605,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   31,  705,    4,  355, 6252, 1656,   60,  343,   60, 1451, 2975,
         2974,   98,   44,   14,  404, 2510, 3496,   18,   35,  360,  777, 1643,
           15,   16,   23,  751,  342, 3414,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 312,  627, 4511,   31,  182,  151, 6374,   24,  160,  856,   98,  102,
         1464,   16,    9,   40, 2099,  181, 3435,    5, 4885, 2638,   31,   14,
          342, 1243,   22, 3103,   88,  118, 5940,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  114,   31, 3554, 1855,    4,  503,   36,  257,  196,   29, 4349,
           61, 1903,    4,   50,  621,  330,  187,  713,  129,  732,  728,  151,
          351, 9320,    4,   16,   30,   27,   40, 5791,   37, 6002,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  139,   14, 1439,  912, 3312,  951,   78,   14, 2249, 3526,  262,
         2533,   37,  304,  219,  649,  356,    4,   16,  789,  139, 4784,   20,
          732, 8667,   78,  196,   52,  751, 2557, 2242, 1468,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 310,   78, 2051,   75,   29,  167,  177, 5096,    4,   50,   43, 1166,
            4,  981,  611,   28, 8495,    4, 1417,   28,  127,    4,  363,   14,
            4,   14,   36,   47,  516,  124,  123,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3192,   41,  149,  648,   61, 3354,  441, 3935, 3956,   44,  657,  737,
         1010, 1660,   16,  938, 2633,  340,  271,    4, 7282,   20,    4, 6620,
          674,    5, 1612, 1098,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3093,   20, 5775, 4706,  240,   20, 5861,   28,  725,    4,  782,   36,
          337,  167, 3750,   15, 2206,  130,    4,   16,   43, 7819,   15,   52,
         2778, 1048,   37, 5887,   15,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3826,   37,  124, 1071,  127,   32,   60, 2798,  611, 8109,  186,    4,
           16,   36,   27,  704,    4,  114,   32,  534, 6254, 2934,    4,  139,
          114,   32, 6254,  112, 3639, 2934,    4,  782,   32,   36,  632,  269,
          776,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  64,  173,  210, 1664,  161,   36,  253,  698,  642, 2757,   46,  654,
          624,    6, 4878, 1806,  469, 2224,    6,  674,   20,  293,  457,    4,
         1509, 5924,   20, 2766,  152,  232,   56, 5721,   60,  314,    9,   23,
          674,   20,  293,  457,   35, 3176, 7165,  165,    5,    2],
        [ 298, 2957,   32,  485,  585, 4163,    4,   88,  112,   58, 2295,  141,
         3895,  312, 4183, 3735,    4,  223,   30, 1311,   38,  748, 2704, 2801,
          119, 3157,  980,   30,   32, 5855,    9,    6,  314, 5732,   15,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 202,   82, 1061,    4,   43,   82,  798,    5, 2093,  331, 5545,   20,
            4,   14,   32, 2794,   15,    4, 1457, 3513,  190,  553,  803,  849,
          781,  176,  481,    6,  112,  295, 4845, 2798,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 441,  462,  332, 6079,   31,  196,    9,  151, 4409, 1337,    6,   61,
          151, 3672,   35,  748,  973,   35,  754,  293,  156, 2916,    5,   64,
          482, 4864,   31,  210, 1664,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2660, 1097, 1480,   43,  966, 1262, 1194,    4,  268,   43,  831,  537,
          788,    4,   50,   43,  190, 1097,  951,    4,   34,  295,  435, 2159,
          681,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 228,  328, 1003, 1904,   31,    4,   50,   31,  771, 4738, 2086,   16,
         2324,  667, 1398,    5,  460, 1486, 3945,   31, 7367,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,   55,  345,   20,  113,   52,  585, 4074,    6,  242, 7700,   46,
           31, 3615, 1071,  897,  420,   46,   16,  454,   14, 5027,  344, 1280,
         3234,    6,    9,   14, 7278, 1834,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:0'), 'target_lengths': tensor([31, 32, 33, 36, 35, 33, 30, 31, 39, 46, 37, 34, 31, 27, 23, 32],
       device='cuda:0'), 'ntokens': 530, 'nsentences': 16}
##################### {'id': tensor([ 32129,  24401, 189645, 107396, 172818,  92042, 215868],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[-1.1597e-03, -4.2725e-04, -3.0518e-05,  ..., -1.8280e-02,
         -1.6327e-02, -1.5289e-02],
        [-6.5125e-02, -2.4109e-02,  6.7444e-03,  ...,  2.2888e-03,
          1.7395e-03, -2.3499e-03],
        [-2.1973e-03, -1.9226e-03, -9.7656e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 4.5776e-04,  3.3569e-04,  2.1362e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.3569e-04,  4.8828e-04,  6.4087e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.8501e-04,  9.4604e-04,  1.0071e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([328480, 328480, 328320, 328320, 328320, 328320, 328320],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2, 4695,    6,   34,  766,  578,    4,  136,  139,  190,    4,   30,
           77,   14, 9071,  634, 1168,  503,    4,   14,   81,  280,    5,   38,
         2195,   82,   97,  965,   49, 9009, 1140,  174,  306,  310,   28, 1293,
            4,   14, 4470,    9,  441,  989,    6, 4674,   15,  124,   56, 6366,
           48,  319,    4,  136,  139,    4,   74,    9,  770,  965,    4,   14,
           75,   47,  216,   88,  295, 4771, 5454, 2081,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   31, 2063, 1421, 1716, 2772,   78,  256, 1401,  268,   31,
          705,    4,   50, 5146,    9, 4526, 4247,   16, 8985, 7593, 6829,   16,
         2631,   37, 2049,  262, 1506,   36, 5181,    9,   52, 1401,   28,  615,
            9,   23,   36,  874, 7228,   20, 9122,  178,   14,  118, 3664,   51,
          122,   59,  219, 1177,   15,  268,   36,   52, 5926,  165,   16,   52,
         5821,  477, 3567,   34,   81, 1426, 2670, 7161,   18, 1238, 1334,   81,
          448,  118, 2978, 4107,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1214,  423,  332, 8797,   37, 5357,   16,   56, 2355,   48, 3811,
          285,  122,  387, 1170,  165,  223, 4898, 4900,   20, 5434,  156,  416,
         1418,   27, 1342, 5681,   20,  320, 4303, 4045,   61,   23,  201,   28,
          102, 4384, 4009,    4,   50,   81,  231,  482,   56, 8271,   15, 1687,
         6219,  831, 2159,  145,    5,   64,   50, 1885,   20, 2210, 6621,   47,
         3778,   37,   27,   90, 3279,   20, 6376,   23, 5633,   15, 3000,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1001,  167,  113,   74,   23, 1641,  173, 6714,  223, 2949,    4,
           16,  189,    5,    5,    5,   68,  431,   65,   92,  285,   45,   37,
          861,    6, 4807,  426,   27,  136,    4,   50,  256, 1131, 1238, 1279,
         6859, 4841, 4844,   22,   27,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   82,  406, 1003,    4,   88,   61,    6, 5399,   28,  537,
            4,  163,    9,    6, 3369,   28, 4417,    4,   78,   52,   23,  263,
         4349,   15, 5641, 3606,   15,   97, 5820, 4752,  996,    5,   72,  280,
          647,   40, 3545, 1061,   35, 1315,  411,  662,    6, 1311,   78, 3075,
          365, 3103,  559, 1533,  741, 2717, 8389,   16, 1904,    4,   50,   31,
          141, 5253, 2674,  184, 4741,  186,  354,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92, 9471,   35,  710,   20,  727,  349, 1307,  754,  754,  130,
           30,   64,   15,  156, 2271, 1892,   44, 4104, 2062,    6,   83, 1998,
         1101, 9471,   20, 2771,  398,    4, 7049, 8720,   15,   35,    4,  507,
          237,  174, 8720,   15,   35,   16, 5390,   15, 9471,    4,  231,  364,
         4485,  259,   46,   60,  227, 1512, 1285,   95,  927, 1630,   15, 3893,
         1347,    6,  352, 2511,    4,  210,  628,   32, 2680, 2511,    4, 1546,
          380,   48,  784, 9471,   20, 5008,    4,   43,   60, 3893,   15,    4,
           14,  600,  301,   15,    6, 2169,  210,   22, 1471,    4,  171,    6,
           20,  620,    4,   16,  189,  393, 1724, 2740,    5],
        [   2,  633,  102,  351,  685,  307, 1795, 1634,   44,   38, 2579,  201,
          239,  256,   18, 1689,   15, 2489,  980,   34,  855,    4,   50,   36,
         1378,   27,    4,   50,   31,   47,  374,  269,  145,    4,  136,   31,
          145,  831,  190,  269,    5,   72,  145,  171, 1500,    5,   72,  145,
         2969,    5,   72,  145,  548, 1126,    5,   72,  145, 6295,  272,    5,
           72,  145,  580,  299, 3425,    6,  186,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4')}, 'transcript': {'tokens': tensor([[ 250,   17,  169,   51,  528,    4,   67,  113,  250,   17,  169,  305,
         5542,   12,   77,   12,  117, 7099,    6,   17,   91,  144,    5,   38,
          511,    9,    7, 1165,   12,    7, 1827, 2260,    4, 4619,   13,  325,
           12,   94,    4, 4619,   94,  148,  162, 2129, 9829,    6,  109, 4488,
           93,    4,    8,  113,   86, 1057,    4,    9,   89,  447, 1165,    4,
           13, 3557,   10, 4110,   80, 3903,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   19,  278, 1421, 3675,  126,   12,   21,   55,   89,  670,  125,
           19, 1831,   17,   24, 1591, 2637, 3181,    6,    8,  811,   35,  426,
          356, 5149,    8, 1127, 1848, 7178,   48,   10,  367,   10,   13,  670,
          206,   84,   34,  874, 2286, 5575,   62, 8517,   17,  877,   20,  307,
           62,  134,  333,  383,    5,  125,   21, 1017,    6,   13,   10,  375,
            8,   39, 7574,   80,  138,   25,  598,   80,   94,  535,  490,   25,
          508,  134,    7, 4340,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 432,  423,  215,   12, 7989, 1435,    8,   56, 2687,  240, 1032, 6606,
         6480,  131, 1655,   12, 5709, 2245,    4,  333, 2767, 2931, 3182,    9,
            7,  179,  188, 8152,   48,   17,    7, 6929,    6, 5914,   69,    7,
         1232,   63, 2426,   10, 2034,    8,   17,    7,  979,   12, 2753, 4429,
           26,  211,  143, 1565,   93,  254, 3563, 4401,    6,   12, 2753,  824,
           48, 4577,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   79,   25,  150,    7, 1819,  205,    9, 6714,  111,  359,   84,
            4,    8,  180,    5,    5,    5,   68,  386,   65,    8,    7,  281,
         4673, 1809,  411,   26,   17,   89,  874,  204, 1917,   62,  499,  535,
          890,   10,   87,   17,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  33,   34,   89,  765,   10,  749,  221,    9,    4,   10, 2750, 1222,
         2433,   55,   70,   63,  172,  288,   13,  874, 1256,   12,    7,  133,
         1219, 5222, 3770, 3254,    4,    8,   19,  144,  116, 5893,   13,  488,
            4, 1061,   35, 1315,  322, 1039,   55, 2829, 1020, 1747,  160,  741,
            4, 3150,  111,    4,    8,   19, 1425,   19,  220, 6785,   13, 3028,
         1329,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  269,  290, 1543,  106,   10, 1059,  188,  691,    7,  291,   18,
         1397,  156,  457,   44,  391, 1543,    6, 4437, 2361, 1268,    4,  895,
         1101,  269,  484,    4, 1912, 2172,    4, 5087, 2172,    8, 1339, 1373,
          699,   57,   77,   85,    7,  370,  183,   46, 6835,  203,  620,  293,
            6,   62, 4437, 1395, 4781,    9,  166,   24,  205,  126,    4, 2213,
          132, 1546,  121,   22, 1691,  269,  484,    4,  388,    9,    7, 4437,
            6,   17,  204,   66,    7, 4273,    6,    4, 3020,  126,    7,  269,
          290,    8,  180,  339,  134,  205,    5,    2],
        [   7,  218, 8314,   12, 1780, 1119,    4,   38, 1865,   89,  227, 2704,
            7,  179,   34, 1621,  137,  166,   26,   10,  289,   21,   11,    6,
         1301,   17,   19,   73,   11,   18,   87,  778,    4,   67,   19,   73,
         1123,  111,   87,  250,    5,   19,   73,   55,  122,  366,    5,   19,
           73,  570,    5,   19,   73,  575,  132,    5,   19,   73, 6295,    5,
           19,   73,   51,   13,  461,   12,   33, 2469,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[50, 37, 85, 38,  2, 11, 37, 83, 50, 37, 85, 49, 32, 37, 50, 37, 37, 32,
         37, 37, 50, 85, 11, 38, 35, 37, 37, 32, 37, 37, 56,  9, 11, 59, 37, 83,
         37, 56, 11, 59, 56, 50, 85, 50, 32, 37, 37,  9, 35, 11, 37, 83, 83, 49,
         11, 37, 37, 37, 32, 11, 37, 94, 37, 94, 37, 83, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 38, 31, 34, 56, 37, 37, 37, 37, 37, 94, 37, 38, 31, 37, 38, 35, 77,
         94, 37, 37, 38, 38, 77, 77, 56, 37, 50, 56, 88, 31, 37, 85, 37, 37, 94,
         37, 37, 85, 38, 35, 35, 31, 56, 37, 38, 77, 77, 31, 37, 50, 24, 11, 37,
         37, 31, 37, 37, 37, 77, 37, 38, 94, 37, 37, 37, 59, 37, 56, 83, 37, 37,
         88, 37, 37, 16, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 34, 24, 37,  2, 59, 37, 38, 35, 35,  2, 59, 12, 37, 24, 37,  2, 56,
         11, 50, 75, 28, 94, 37, 37, 94, 85, 88, 31, 37, 37, 94, 37, 83, 37, 37,
          9, 85,  2, 37, 49, 37, 37, 37, 32, 37, 28, 49, 85, 50, 50, 32, 35, 37,
          2, 94, 37, 37, 28, 38, 31, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 37, 37, 59, 37,  9, 85, 37,  2, 83, 37, 37, 11, 37, 37, 11, 11, 11,
         38, 28, 11, 37, 37, 75,  2, 38, 35, 85, 37, 37, 38, 83, 49, 31, 83, 83,
         83, 37, 85, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 85, 37, 24, 37, 38, 35, 37, 11, 37, 29, 37, 37, 37, 50, 85, 83, 83,
         37, 38,  2, 37, 37, 83, 38, 28, 94, 56, 11, 37, 38, 85, 83, 31, 37,  2,
         11, 84, 38, 35, 35, 32, 37, 32, 35, 38, 35, 35, 11,  2, 83, 11, 37, 38,
         31, 38,  6, 49, 37,  2, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 79, 35,  9, 37, 37, 35, 85, 31, 37, 38, 35, 35, 35,  2, 82, 34,  9,
         37, 38, 31, 17, 11, 73, 60, 79, 35, 11,  2, 35, 11,  2, 35, 37, 38, 35,
         35, 77, 50, 37, 37,  4, 24, 11, 83, 38, 77, 35, 37, 31, 38, 53, 56, 37,
         37, 38, 85, 37, 11, 49, 37, 38, 35, 35, 77, 79, 35, 11, 31, 37, 37, 38,
         37, 37, 83, 85, 37,  9, 37, 11,  9, 37, 37, 79, 35, 37, 37, 49, 37, 85,
         11, 83],
        [37, 50, 29, 37,  9, 88, 11, 38, 35, 37, 38, 49, 37, 94, 85, 31, 11, 37,
         85, 37, 88, 37, 85, 37,  2, 37, 38,  6, 85, 35, 85, 50, 11, 37, 38,  6,
         83, 83, 85, 50, 11, 38,  6, 37, 35, 77, 11, 38,  6, 94, 11, 38,  6, 88,
         37, 11, 38,  6, 32, 11, 38,  6, 38, 37, 32, 37, 37, 16, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37]], device='cuda:4'), 'lengths': tensor([68, 78, 64, 42, 63, 92, 70], device='cuda:4'), 'ntokens': 477}, 'target': tensor([[4695,    6,   34,  766,  578,    4,  136,  139,  190,    4,   30,   77,
           14, 9071,  634, 1168,  503,    4,   14,   81,  280,    5,   38, 2195,
           82,   97,  965,   49, 9009, 1140,  174,  306,  310,   28, 1293,    4,
           14, 4470,    9,  441,  989,    6, 4674,   15,  124,   56, 6366,   48,
          319,    4,  136,  139,    4,   74,    9,  770,  965,    4,   14,   75,
           47,  216,   88,  295, 4771, 5454, 2081,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   31, 2063, 1421, 1716, 2772,   78,  256, 1401,  268,   31,  705,
            4,   50, 5146,    9, 4526, 4247,   16, 8985, 7593, 6829,   16, 2631,
           37, 2049,  262, 1506,   36, 5181,    9,   52, 1401,   28,  615,    9,
           23,   36,  874, 7228,   20, 9122,  178,   14,  118, 3664,   51,  122,
           59,  219, 1177,   15,  268,   36,   52, 5926,  165,   16,   52, 5821,
          477, 3567,   34,   81, 1426, 2670, 7161,   18, 1238, 1334,   81,  448,
          118, 2978, 4107,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1214,  423,  332, 8797,   37, 5357,   16,   56, 2355,   48, 3811,  285,
          122,  387, 1170,  165,  223, 4898, 4900,   20, 5434,  156,  416, 1418,
           27, 1342, 5681,   20,  320, 4303, 4045,   61,   23,  201,   28,  102,
         4384, 4009,    4,   50,   81,  231,  482,   56, 8271,   15, 1687, 6219,
          831, 2159,  145,    5,   64,   50, 1885,   20, 2210, 6621,   47, 3778,
           37,   27,   90, 3279,   20, 6376,   23, 5633,   15, 3000,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1001,  167,  113,   74,   23, 1641,  173, 6714,  223, 2949,    4,   16,
          189,    5,    5,    5,   68,  431,   65,   92,  285,   45,   37,  861,
            6, 4807,  426,   27,  136,    4,   50,  256, 1131, 1238, 1279, 6859,
         4841, 4844,   22,   27,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92,   82,  406, 1003,    4,   88,   61,    6, 5399,   28,  537,    4,
          163,    9,    6, 3369,   28, 4417,    4,   78,   52,   23,  263, 4349,
           15, 5641, 3606,   15,   97, 5820, 4752,  996,    5,   72,  280,  647,
           40, 3545, 1061,   35, 1315,  411,  662,    6, 1311,   78, 3075,  365,
         3103,  559, 1533,  741, 2717, 8389,   16, 1904,    4,   50,   31,  141,
         5253, 2674,  184, 4741,  186,  354,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92, 9471,   35,  710,   20,  727,  349, 1307,  754,  754,  130,   30,
           64,   15,  156, 2271, 1892,   44, 4104, 2062,    6,   83, 1998, 1101,
         9471,   20, 2771,  398,    4, 7049, 8720,   15,   35,    4,  507,  237,
          174, 8720,   15,   35,   16, 5390,   15, 9471,    4,  231,  364, 4485,
          259,   46,   60,  227, 1512, 1285,   95,  927, 1630,   15, 3893, 1347,
            6,  352, 2511,    4,  210,  628,   32, 2680, 2511,    4, 1546,  380,
           48,  784, 9471,   20, 5008,    4,   43,   60, 3893,   15,    4,   14,
          600,  301,   15,    6, 2169,  210,   22, 1471,    4,  171,    6,   20,
          620,    4,   16,  189,  393, 1724, 2740,    5,    2],
        [ 633,  102,  351,  685,  307, 1795, 1634,   44,   38, 2579,  201,  239,
          256,   18, 1689,   15, 2489,  980,   34,  855,    4,   50,   36, 1378,
           27,    4,   50,   31,   47,  374,  269,  145,    4,  136,   31,  145,
          831,  190,  269,    5,   72,  145,  171, 1500,    5,   72,  145, 2969,
            5,   72,  145,  548, 1126,    5,   72,  145, 6295,  272,    5,   72,
          145,  580,  299, 3425,    6,  186,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'target_lengths': tensor([ 69,  77,  72,  42,  68, 105,  68], device='cuda:4'), 'ntokens': 501, 'nsentences': 7}
2023-07-03 07:48:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0

##################### {'id': tensor([120532, 184334, 128537,  94020,  13156,  93870, 128796, 212640, 220280,
        210517, 188144,  21621, 160771, 210539, 128969, 128719,  92001, 198858,
         37504,   5913, 223361,    324,  88265,  39082, 111592, 212765, 146801,
         39363, 124780, 120943, 143780,    534,  83930, 111644,  90318,   7296,
         87711, 147078,  74846,  90231, 153336, 126463,  23957,  98313,  23871,
         86012,  46384,   5314], device='cuda:3'), 'net_input': {'src_tokens': tensor([[-3.1433e-03, -3.2654e-03, -4.0894e-03,  ..., -7.5134e-02,
         -7.4768e-02, -6.8420e-02],
        [-1.8311e-04, -5.1880e-04, -1.4038e-03,  ...,  1.7700e-03,
          2.4414e-04, -5.0354e-03],
        [-1.6785e-02, -1.9318e-02, -2.3285e-02,  ..., -9.4604e-04,
          2.1362e-04,  1.4038e-03],
        ...,
        [ 2.7466e-04,  8.8501e-04,  3.0518e-04,  ...,  8.5449e-04,
         -4.5471e-03,  0.0000e+00],
        [ 8.7280e-03,  2.0142e-03,  1.4038e-03,  ...,  3.5400e-03,
          2.1362e-03,  0.0000e+00],
        [ 9.1553e-05,  6.1035e-05,  0.0000e+00,  ..., -2.7466e-04,
         -3.0518e-04,  0.0000e+00]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160,
        44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160,
        44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160,
        44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160, 44160,
        44160, 44160, 44160, 44160, 44159, 44159, 44159, 44159],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,  146, 4255,  ...,    1,    1,    1],
        [   2,   41,   95,  ...,    1,    1,    1],
        [   2,   92,   27,  ...,  186,    5,    1],
        ...,
        [   2, 6925, 3663,  ...,    1,    1,    1],
        [   2, 1394, 1938,  ...,    1,    1,    1],
        [   2,   92,   27,  ...,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[   7, 3288,   63,  ...,    1,    1,    1],
        [  53,  113,  180,  ...,    1,    1,    1],
        [ 282,   26,   80,  ...,    1,    1,    1],
        ...,
        [4069,    4,   21,  ...,    1,    1,    1],
        [2869, 3540, 4712,  ...,    1,    1,    1],
        [  33,   26,    7,  ...,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 94, 85,  ..., 37, 37, 37],
        [37, 83, 37,  ..., 37, 37, 37],
        [32, 85, 37,  ..., 37, 37, 37],
        ...,
        [83, 11, 37,  ..., 37, 37, 37],
        [50, 56, 83,  ..., 37, 37, 37],
        [37, 85, 37,  ..., 37, 37, 37]], device='cuda:3'), 'lengths': tensor([15, 15, 16, 13, 21, 10, 18, 12, 11, 14, 16,  9, 14, 19, 15,  8, 15, 14,
        15, 12, 10, 15, 19, 18,  8, 23, 16, 18, 12, 12, 11, 20, 19,  8, 15, 18,
        11, 21, 15, 13, 18, 15, 15, 11, 14, 13,  7, 14], device='cuda:3'), 'ntokens': 691}, 'target': tensor([[ 146, 4255,   27,  ...,    1,    1,    1],
        [  41,   95, 2563,  ...,    1,    1,    1],
        [  92,   27,    4,  ...,    5,    2,    1],
        ...,
        [6925, 3663,   36,  ...,    1,    1,    1],
        [1394, 1938, 1602,  ...,    1,    1,    1],
        [  92,   27, 5305,  ...,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([15, 20, 26, 16, 21, 10, 15, 15, 15, 14, 17,  9, 19, 19, 14,  9, 15, 15,
        18, 10,  7, 13, 21, 11, 12, 17, 14, 17, 13, 13, 27, 16, 18, 10, 15, 11,
        13, 17, 19, 10, 17, 13, 20, 12, 10, 14,  9, 11], device='cuda:3'), 'ntokens': 712, 'nsentences': 48}
##################### {'id': tensor([ 57248, 172152,  91707, 171473,   8470, 141066, 166562, 220143],
       device='cuda:3'), 'net_input': {'src_tokens': tensor([[ 0.0008, -0.0003, -0.0010,  ..., -0.0258, -0.0255, -0.0248],
        [-0.0006, -0.0003, -0.0002,  ..., -0.0013, -0.0014, -0.0009],
        [-0.0036, -0.0008,  0.0016,  ...,  0.0264,  0.0060, -0.0275],
        ...,
        [-0.0008, -0.0002, -0.0009,  ..., -0.0008, -0.0013, -0.0020],
        [-0.0033, -0.0049, -0.0059,  ...,  0.0013,  0.0004,  0.0000],
        [ 0.0865,  0.0524,  0.0225,  ..., -0.1154, -0.1107,  0.0000]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([199680, 199680, 199680, 199680, 199680, 199680, 199679, 199679],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,   64, 2012,   28,  141, 4633,  352, 7508,    5,   68,  379,   65,
           72,  514,    4,  167, 6067, 2472,    5,   68,  379,   65,  147,   90,
           31,  495, 1293,  562, 1887,    4,   82, 3204, 1785,  196, 1190,   45,
           45,  500,  429, 4486,  797,   37,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72, 6520,   56, 2006, 2776, 1709,    9, 1572,    6,  726, 1688,
         1353,  469,  861,   16, 3452,   28,  725,    4,   74,   14,  840, 3218,
         3332,    6,  737,    6,  315,   22, 1695,   15,  184,  891,   18,   83,
            4,   14, 2798,    4,   14,   43, 2794,   15,    4,   16,  139,   14,
         4161,  212, 2798,  112,  295, 1209,   18,    6,  790, 2680,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  228,  536,  377, 2577,  223, 3347,   43,   40,   56, 5701, 4550,
            6, 1133,    4,   30,  299, 2967,  227,  152,  241, 3256,    4, 1097,
          951,    4,  421, 2356,   18,   16, 1406,   20,  234, 2259,    4,  750,
           36, 3283,  257,  393,   60, 1257, 3922, 5354,  996, 1330, 1788,  762,
          161,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  520,   31,  421, 1034,  398,  280,    4,   50,   40,  377,  389,
          866,   14, 6156, 6070,   20,  651,    4,   14,   31,   97,  349, 1861,
         1204,    4,  329,   31, 2752,   44,   38,  360,  287,   34,  449,   31,
          127,  137,   72,  514,   47,    4,  403,   31,   36,  149,    9, 2105,
          124, 3873,  329,    4,  136,    9,  328, 1003,  239,   52,  799, 2888,
         1150,   78,  406,  314, 4079,    5],
        [   2, 1647,  316, 3989,    9,   40, 3305, 5238,    4,  182, 5106,  930,
          443,  187, 2996,    4, 1312,  177,  301, 2514,  290,  501,    6, 3363,
            6,    9,   52, 7480, 1175,  343,   30, 4801, 1246, 5371,    4, 7172,
          978,  343,   16, 1750,   22, 4592,    4,   56, 1285,   18, 2381,  441,
         4056,  420,  352, 1294,   15,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 2400,  164,   31,   47,  112, 8242,   20, 5182, 1561,    4,  519,
          112,   14, 8807,   20, 4108,  571, 2564,  129, 1514,    6,   46,  105,
         2447, 1534, 1322,   15, 7109,   35, 3344,  176,   57,    4,  114,   81,
         2053,   28,  725,    4,   74,   14,  201, 1035,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  298,  239,   40,  531,  235,  971,   48,  783, 1349,    4,   16,
           32,   83,  547, 1536,  472,  311, 2412,    6, 4359,   37, 1928,    4,
           14,  981,  623,  831, 2112,    4,   50,   77,  273, 5964,   15, 1225,
         1981, 9111,  831, 2112,    4,   14,  157, 1240,   20,   13, 2051,   16,
          831, 2112,    4,   50,   36,  286,  435, 2450,  178,    5,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   41,  123,  512, 5715, 1168,    4,   88, 7873,   22,   28, 1376,
           16,  157, 5730,   28, 1564,    4,  124,    4,   88,  437, 2150,   15,
         6637,  425, 7949,   16,   43,  164, 1126,   28, 6728,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[   8,  284, 5207,   34,   10,  205,   71,  565,   10,   13, 1237, 3321,
            5,   68,  194,   65,   19,  135,    4,  138, 7524,    5,   68,  194,
           65,   67,  120,   24, 1618,    4, 1598, 1785,   34,   13, 1237, 7756,
           59,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   19, 2138, 2937,  982, 1551,    9, 3398, 1010, 1291, 1672, 2334,
          752,   10,  661,  138,    7, 1422,  144, 1862,   48,    7, 3348,    4,
            7,  954,    6,   17,   53,  442,    4,    8,  180,    7, 2302,   12,
          251,  954,    6, 2816,  159, 1953, 1049,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   70,   53,   11,   57,  401,    9,  108, 6629,   26,  142,  359,
           13, 8148,  567,    4,  166, 2736,    6,    4, 3673,    6,    4, 1475,
            6,    8, 1406,   20,  234, 1115,    6,  117, 3422,    4, 1025,  113,
         8148,  111,    9, 1327,  300,  829,  134,   71,  108,   89,  140,  356,
          996,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 120,   19, 4600,   17,   39,   39,  389,  866, 1073,    7, 5639,    6,
           19, 1095,   69, 4158,    4,   19, 4173,  246,    4,   38, 5224,   11,
            6,   70,   19,  213,   10,   51,  137,   19,  192,   11,   18,  135,
          103,   19,  246,   21, 2702,  111,  109,  126, 6341,    4,   67,   17,
           34,   13,  453,  111,  384, 2172,   54,  765,    9,   89,  282,    5,
            2],
        [ 109,   25,   73,  175,   69,   13, 5165,    4, 2618,   10, 2769,  930,
          443,  187,    4, 1336,   20, 1317,  132, 1663, 2769,   22, 1151,   11,
            6, 2100,    6,   46, 1729,  914, 5371,    4, 7172, 1086,   46,    8,
          203, 4711,  389,  155, 2232,    4,  175,  155, 1261,  270,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 440,    4,   19,  192,   11,   18,  213,   10,  456,   80, 1284, 4059,
            4,   19,  213,   10,  456,   80,    7, 9558,   13,  870, 1212,  140,
         1068,   12,  694,   46,  251,  746,   12,   87,   59, 4037, 5425,  215,
          206,   25,   11,   57,  752,   10, 1531,  126,  138,    7,  179, 1429,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,   13, 3141,   12, 5823,   34, 2534,    4,    8,  115,   24,   66,
         1536, 8087, 1215,  126,    9,    7,  179,  333,  383,  961, 1123,   77,
          108,  409,  240,  693, 7759,  324,  740, 3530,    8, 2103,  422,  230,
            6,    8,  229, 1123,   84,   26,  211, 1269, 4618,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,   25,  659,  368,  155,  768,   10,  991, 1832,    6,    8, 1005,
           94, 1663,    4,  109,   25,  659,  368,   21,   10, 2033, 7149,    6,
            8, 7338,  134,    9,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 37, 32, 85, 37, 85, 37, 37, 37, 37, 94, 49, 11, 38,  9, 11, 38, 59,
         11, 37, 28, 11, 38,  9, 11, 37, 37, 38, 31, 11, 38, 35, 85, 37, 94, 49,
         35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 23,  2, 24, 37,  9, 35, 38, 35, 56, 49, 37, 59, 37, 37, 94,
         85, 94, 31, 37, 56, 11, 37, 49, 37, 37, 37, 31, 11, 37, 37, 37,  1, 37,
         50, 49, 37, 37, 37, 38, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 50, 37, 85, 77, 49, 37, 37, 94, 85, 49, 37, 37, 29, 32, 11, 37, 29,
         37, 11, 49, 37, 11,  2, 37, 37, 37, 77, 35, 37, 37, 37, 56, 11, 24, 83,
         29, 83, 37, 35, 35, 49, 37, 37, 37, 37, 35, 77, 41, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 38, 38, 35, 35, 85, 37, 28, 37, 38, 59, 37, 12, 11, 38,
         83, 88, 11, 38, 31, 85, 37, 50, 38, 88, 37, 38, 11, 38, 85, 85, 35, 59,
         37, 38, 88, 37, 87, 83, 37, 37,  2, 11, 37, 37, 85, 37,  2, 83, 38, 35,
         49, 24, 37, 37, 32, 11, 83],
        [37, 37,  6, 85, 37, 37,  9, 11,  8, 37, 38, 35, 35, 35, 11, 38, 77, 77,
         37, 37, 38, 35, 35, 85, 37,  9, 37, 11, 56, 83, 34, 11, 34, 32, 11, 37,
         38, 35, 35, 37,  9, 11, 85, 37, 94, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 85, 85, 35, 88, 37, 16, 37,  2, 56, 11, 38, 88, 37, 16, 37,
         37,  2, 37, 35, 77, 35, 35, 37, 32, 11, 50, 83, 37, 85, 35, 35,  9, 24,
         37, 37, 85, 77, 49, 37, 94, 37, 37, 37, 94, 56, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 37,  9, 37, 49, 85, 31, 11, 37, 83, 38, 85, 34, 32, 56, 37, 37, 37,
         94, 50, 24, 49, 83, 50, 37, 32, 35, 56,  2,  2, 49, 56, 37, 29, 28, 37,
         37, 37, 49, 83, 37, 85, 50,  9, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 37,  6, 49, 37, 94, 37, 49, 94, 37, 37, 49, 56, 37, 11, 37, 37,  6,
         49, 37, 37, 29,  5, 37, 37, 29, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37]], device='cuda:3'), 'lengths': tensor([39, 45, 51, 61, 48, 50, 47, 30], device='cuda:3'), 'ntokens': 371}, 'target': tensor([[  64, 2012,   28,  141, 4633,  352, 7508,    5,   68,  379,   65,   72,
          514,    4,  167, 6067, 2472,    5,   68,  379,   65,  147,   90,   31,
          495, 1293,  562, 1887,    4,   82, 3204, 1785,  196, 1190,   45,   45,
          500,  429, 4486,  797,   37,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72, 6520,   56, 2006, 2776, 1709,    9, 1572,    6,  726, 1688, 1353,
          469,  861,   16, 3452,   28,  725,    4,   74,   14,  840, 3218, 3332,
            6,  737,    6,  315,   22, 1695,   15,  184,  891,   18,   83,    4,
           14, 2798,    4,   14,   43, 2794,   15,    4,   16,  139,   14, 4161,
          212, 2798,  112,  295, 1209,   18,    6,  790, 2680,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 228,  536,  377, 2577,  223, 3347,   43,   40,   56, 5701, 4550,    6,
         1133,    4,   30,  299, 2967,  227,  152,  241, 3256,    4, 1097,  951,
            4,  421, 2356,   18,   16, 1406,   20,  234, 2259,    4,  750,   36,
         3283,  257,  393,   60, 1257, 3922, 5354,  996, 1330, 1788,  762,  161,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 520,   31,  421, 1034,  398,  280,    4,   50,   40,  377,  389,  866,
           14, 6156, 6070,   20,  651,    4,   14,   31,   97,  349, 1861, 1204,
            4,  329,   31, 2752,   44,   38,  360,  287,   34,  449,   31,  127,
          137,   72,  514,   47,    4,  403,   31,   36,  149,    9, 2105,  124,
         3873,  329,    4,  136,    9,  328, 1003,  239,   52,  799, 2888, 1150,
           78,  406,  314, 4079,    5,    2],
        [1647,  316, 3989,    9,   40, 3305, 5238,    4,  182, 5106,  930,  443,
          187, 2996,    4, 1312,  177,  301, 2514,  290,  501,    6, 3363,    6,
            9,   52, 7480, 1175,  343,   30, 4801, 1246, 5371,    4, 7172,  978,
          343,   16, 1750,   22, 4592,    4,   56, 1285,   18, 2381,  441, 4056,
          420,  352, 1294,   15,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2400,  164,   31,   47,  112, 8242,   20, 5182, 1561,    4,  519,  112,
           14, 8807,   20, 4108,  571, 2564,  129, 1514,    6,   46,  105, 2447,
         1534, 1322,   15, 7109,   35, 3344,  176,   57,    4,  114,   81, 2053,
           28,  725,    4,   74,   14,  201, 1035,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 298,  239,   40,  531,  235,  971,   48,  783, 1349,    4,   16,   32,
           83,  547, 1536,  472,  311, 2412,    6, 4359,   37, 1928,    4,   14,
          981,  623,  831, 2112,    4,   50,   77,  273, 5964,   15, 1225, 1981,
         9111,  831, 2112,    4,   14,  157, 1240,   20,   13, 2051,   16,  831,
         2112,    4,   50,   36,  286,  435, 2450,  178,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  41,  123,  512, 5715, 1168,    4,   88, 7873,   22,   28, 1376,   16,
          157, 5730,   28, 1564,    4,  124,    4,   88,  437, 2150,   15, 6637,
          425, 7949,   16,   43,  164, 1126,   28, 6728,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([43, 59, 50, 66, 54, 45, 58, 34], device='cuda:3'), 'ntokens': 409, 'nsentences': 8}
##################### {'id': tensor([ 36064,  29110,  85488,  95539, 202908,  62433,  69656, 188816,  12104,
        105282, 109853,  68218, 181176,  32218, 209431,  54111, 149439,   4155,
        158548,  98486, 148304, 142894, 118159,  85160,  57263, 151510, 101506,
         56533,  31930, 139300, 144122,  66973,   2766,  98394, 205325,  19616,
        106383, 161944, 106746, 172278, 173699, 207658, 172953, 171394,  30304,
        128914, 202148,  43127,  58833,  16033, 128379,  13123, 149215,  75362,
        171332,   4377, 162398, 223459, 156127,  57611,  28091,  16778, 168641,
         56330,  57541,  60487,  30893,  38300, 138576, 177217,  57687, 133456,
         74813,  21825, 128944, 203288,  75832, 177387, 189224,  54727,  86234,
        173255, 168842,  95874,  35609, 101779, 151889, 218839],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 6.4087e-02,  6.3416e-02,  5.6793e-02,  ...,  1.2561e-01,
          1.0400e-01,  5.9387e-02],
        [-8.3008e-03, -8.6670e-03, -8.6670e-03,  ...,  1.5686e-01,
          1.6943e-01,  1.3269e-01],
        [-2.5330e-03, -3.2959e-03, -3.9062e-03,  ..., -1.3428e-03,
         -1.6785e-03, -2.2278e-03],
        ...,
        [ 2.4219e-01,  2.3730e-01,  2.0837e-01,  ..., -1.3916e-01,
         -1.5393e-01,  0.0000e+00],
        [ 2.4414e-04, -5.1880e-04, -3.0518e-04,  ..., -4.4861e-03,
         -1.9836e-03,  0.0000e+00],
        [ 3.0518e-05,  1.2207e-04,  3.0518e-05,  ..., -1.1902e-03,
          4.4556e-03,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520, 27520,
        27520, 27520, 27520, 27520, 27520, 27520, 27520, 27519, 27519, 27519,
        27519, 27519, 27519, 27519, 27519, 27519, 27519, 27519],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2, 8137,   15,  ...,    1,    1,    1],
        [   2,   92,  239,  ...,    1,    1,    1],
        [   2, 2867,   22,  ...,    1,    1,    1],
        ...,
        [   2,  677,  483,  ...,    1,    1,    1],
        [   2,   72, 2669,  ...,    1,    1,    1],
        [   2,  617,  123,  ...,    1,    1,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[ 24, 498,  71,  ...,   1,   1,   1],
        [ 33,  34, 245,  ...,   1,   1,   1],
        [ 87,  21, 238,  ...,   1,   1,   1],
        ...,
        [886,  44, 476,  ...,   1,   1,   1],
        [ 29,  19, 415,  ...,   1,   1,   1],
        [596,  73,  66,  ...,   1,   1,   1]], device='cuda:7'), 'cluster_tokens': tensor([[38, 49, 37,  ..., 37, 37, 37],
        [37, 85, 83,  ..., 37, 37, 37],
        [85, 37, 83,  ..., 37, 37, 37],
        ...,
        [38, 82, 83,  ..., 37, 37, 37],
        [83, 38, 38,  ..., 37, 37, 37],
        [56,  6, 85,  ..., 37, 37, 37]], device='cuda:7'), 'lengths': tensor([ 6, 10, 10,  7, 10,  7, 10, 11, 10, 10,  6, 11,  9, 13, 10, 12, 14, 18,
        14,  8,  8, 14, 11, 11, 11, 13, 12, 11, 10, 14, 14, 10, 13, 20,  8, 17,
         9,  9, 21,  9, 17, 10, 12, 12,  8,  8,  7, 11, 14, 11, 10, 11,  9, 10,
        11, 12,  7,  8,  8,  4, 10, 12,  9, 12,  9, 14, 10, 15, 11,  9, 10, 14,
         8, 11,  7, 11,  9, 13,  9, 12, 13,  8, 13, 12,  7, 10, 10, 11],
       device='cuda:7'), 'ntokens': 950}, 'target': tensor([[8137,   15,   32,  ...,    1,    1,    1],
        [  92,  239,  253,  ...,    1,    1,    1],
        [2867,   22,   41,  ...,    1,    1,    1],
        ...,
        [ 677,  483,   44,  ...,    1,    1,    1],
        [  72, 2669,  113,  ...,    1,    1,    1],
        [ 617,  123,  435,  ...,    1,    1,    1]], device='cuda:7'), 'target_lengths': tensor([ 8, 13, 17,  7, 10,  8,  8,  7,  8, 10,  8,  9,  8, 18, 10, 12, 14, 14,
        14, 12,  7, 12, 15, 12,  8, 28, 15, 15,  9, 11, 10,  8, 11, 16,  9, 15,
        10, 10, 12,  8, 12, 11, 12, 11,  8,  7,  7,  6, 14,  9, 12, 13, 11, 10,
        12, 12,  7,  7,  9,  4, 11, 15,  9, 16, 10, 13,  9,  9, 14,  6,  8, 14,
         7,  9,  8, 15,  9, 12,  8, 12,  6, 12, 10, 12, 11, 12, 11, 10],
       device='cuda:7'), 'ntokens': 948, 'nsentences': 88}
##################### {'id': tensor([  1441, 198086,  68404, 215797, 118455, 174873, 213650],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 0.0443,  0.0429,  0.0427,  ..., -0.0434, -0.0413, -0.0312],
        [ 0.0008,  0.0008,  0.0007,  ..., -0.0034, -0.0017, -0.0004],
        [-0.0902, -0.0970, -0.1010,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0003,  0.0022,  0.0027,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0002,  0.0003,  0.0003,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0034, -0.0022, -0.0021,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([301760, 301760, 301600, 301600, 301600, 301600, 301600],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,  104,  459,  556,   15,  107,  363,   61,   23, 1083,  201,    4,
           16,   32,  459,  556,   15,   58, 4805,   16, 2157,   23, 1191,   46,
         1145, 1191,    4,   14,  107, 2588, 3011,  130,  224, 1145, 1191,    4,
           49,   23,   31,  705,    4,   50,   32,    9,  355,  259, 4583,  309,
            4,  258, 4025,   16,  304,  675,  588,   16, 5519,   76,    4,   78,
           52, 1225, 7453, 1668,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1589,   18, 5394, 3558,   44, 1935, 2942,   52, 1044,  182,   23,
         1442, 7281,  393,  845,  394,    4,  129,  412, 3554,   37,  161,   43,
           39,   13,  649,  975,  366,   22, 7512,   15,   97, 2013,  174, 1502,
         4832,    4,   74, 5160,   15,  124, 1413, 9684,    5,  396,  202,  156,
         2150,  491,   83,  306, 1048,   20, 5263,    5, 8672,   27,   14,  302,
          322,  152,  241,  181,  236,  426, 4943,  234,    6, 4117,   78,  617,
           97,  698,  497,  182,  141, 1442, 7281,    5,    1,    1,    1],
        [   2,  520,  228,  345,    4,   16,  547,  139, 5337,   16, 1572,    6,
         4752,  313,   31,  863,   88,   58, 3026, 3319,    4,   23,  654,  643,
         5120,    4, 6826,    4,   77,   30,  507,   57,  262,  112, 1741,   90,
         5361,  201, 5074,   37,    4,  566,  600,   14,  585, 3055,   45, 1170,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  145,  163,   39,   14, 2052, 2425,    4,    9,   23,   31,
          112,   52, 2557, 1097, 1124,  160, 1350, 7239,   22,  221, 2448,   20,
            9,   23, 1297,   18,  292,   49,  791, 1966,  494, 2279,    4,   16,
           31, 1109,   61,    4,  814,  253, 4740,  544,    4,    9,  102,  406,
         1581, 2284, 3281,    6, 4000,   56, 4406,  418, 6993,   48, 2891,    4,
           16,   31, 3933,   58, 9468, 3459, 6362,    6,    4,   16,   40, 1550,
           23, 1807,   54, 1695,  566,  122,  153,  223,  770,  871,    5],
        [   2, 1737,  787,   23,  202,  381,   18, 1199,  494,   37, 6542,   22,
          757,   16,   49,   58,  330,   45,  530, 2388,   59,   22, 5044, 6051,
          787,  190,  477,  420,    5,  147,  782,   42, 1033,   23, 5241,  165,
          129, 9509,    6, 2800,   75,  653,    4,   50,  728,  216,  757,   14,
         2155, 1024, 4728,    4,  129,  412,  216, 9509, 4520,   20,   30,  696,
            5,   64,  728,  216, 9509, 7382,   82,    4,  129,  412,  216,  757,
          239,  420, 3552,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,  633,  328, 2339,  745,  374, 3436,   98,    4,  136,  212, 2316,
           22,  235, 4428,    4,  105, 1087,   37,    4,   14, 1857, 3207,  212,
         4097,    4,   14,  184, 8922,   15, 4025,   16,   14, 1813, 6240, 6544,
          319,  231,  580,  344, 3714,   96,    4,  299, 1311,    9,  118, 1093,
           28, 5790,    4,   39,  102,   14,  157,  186, 1770,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  376, 8400,  426,  580, 2272,  871,    6,   27,   30,  696,    5,
         1735,  200,  932, 1867,   16, 2907, 1434,  625, 1036,    5, 4287,  696,
           51, 4807,   18,  864,  242, 2407, 1887,    6,   90, 8400,    5,    5,
            5, 1885,   20, 1407,    4,   13,  741, 1693, 1351,    4,  865,  195,
          195,  454,   46,  924,  139, 1458, 1018,   35,  592,  338,  158,   15,
           46, 6572,   20, 8726,    4,  342, 5284,   16, 3533,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7')}, 'transcript': {'tokens': tensor([[  24,   11,   57, 3919,   54, 1469,  336,    7,  179,    4,   79,  238,
           79, 3919,   54,    7, 1508,    4,   79,  238,   79, 3919,   54, 1377,
         8420,   46, 1276, 1377,    4,   17, 2393,  170,  199,  378,  224, 1276,
         1377,    4,  206,   19,  703,   24,  296,   10, 1744,  183,    4,  206,
           84,   11,    6, 3379,    8, 5464,    6,    8, 4435,   55,  108,  324,
         7074, 2394,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [4233, 1490, 4379,    4,    7, 1706,   37,   13, 1365,   11,    6, 1516,
          432, 1057,   13, 2610,    4,    7,  143, 2676,  225,  164,   51,   10,
         5427,  106, 1850, 3134,  502,  824, 1158, 5465,    6,  100, 4751,    8,
         8198,    4,    8, 2584,  294, 2463, 4620,    6,   12,  251, 5465,    6,
            4, 8423,   26,    7,  744,  281, 1738, 3420,   12, 1723,    9,   13,
         1365,   11,    6,  245,  464, 1850, 3134,  502,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  79,   39, 4290,    4,    8,  115,   79,   13, 5911,    8,   13, 1381,
         6099,    4,   19,   11,  121,  873, 1552, 5988,   80,    7, 5932,  812,
           24,   11,   57, 5031,   80,  108,  447,  753,    4,   77,   33,  456,
           80, 1662, 4015,   13,  179, 5949,    4,  276,    7,  558, 1629, 5952,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19, 1008,    7, 1303,   17,   19, 1157,   80,    7, 4004,   12, 9659,
           48, 3400,   54,    6,    9,    7, 1319, 1408,  567,    9, 5710,  338,
           48,    4,    8,   19,  278,  132,    8,   19, 4311,  244,   10,    7,
          775, 1331,  206,   89, 1111,   35, 1315,  322,   35, 1178, 2610, 2088,
         5725, 2544,   54, 6387,  111,    4,    8,   19, 1346,    7, 7557,   12,
          267, 3200,    4,    8,   19, 1831,   33,  841,   12, 7252,   22, 1255,
          415,  234,    6,   54,  359,   89,  955,    5,    2],
        [  24,  591, 1737,  439,   12,    7,  245, 3486,   35, 6439,    6, 2955,
          839,    4,    8,   12,  251,  148, 5692,  839,    4, 6051,  439, 3447,
           62,  185,   12,   21,    5,   67,  347,   42,  238,  131, 8634, 9300,
           24,  591,   17,    7,  143,  839,    7,  744,  723, 5692,    4,    7,
          143,  159,  572, 5035, 9300,    4,    8,    7,  143, 9300,   69, 3516,
            4,    7,  143,  839,   53, 3447,   62,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   9,   33, 3743,    4,  778, 1321,  133, 5893,    4,   67,   17,  877,
          221, 1547, 4389,    4,  251,  688,    6,    4,    7,  270,   69,   17,
           51,   22,  311,    4,    7, 3379,    9, 2685,   54,    4,    8,    7,
          294,  341, 1587,   12, 1427,   10, 2456,  162,   77,  277, 5656,    6,
           17, 1932,   33, 1039,  199,   13,  561,   17,   94,  692,   10,   51,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,   56, 1265, 3688,   18,  461,   12,  108,  955,   26,  108,  572,
            5, 2318,    8, 2907, 1434, 3358,    5,  108,  572,  203, 1454,    6,
         8121,   70,   26,  291,  181, 3365,  297,  293,    5,    5,    5, 1885,
          998,    4,   13,  741,  128, 1298,    4,  566,  195,  195,    4,  635,
           46, 3050,   59,  205, 8637,    6,   55,   17,  988,   46, 3643, 3648,
            4, 2728,    8,   94,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'cluster_tokens': tensor([[38, 85, 77, 38, 49, 37, 37, 37, 94, 11, 37, 83, 37, 38, 49, 37, 56, 11,
         37, 83, 37, 38, 49, 94, 37, 11, 94, 94, 11, 37, 31, 37, 37, 49, 11, 94,
         94, 11, 37, 38, 88, 38, 49, 37, 49, 24, 11, 37, 37, 85, 37, 56, 37, 94,
         37, 37, 56, 37, 37,  2, 28, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [28, 83, 16, 11, 37,  2, 77, 37, 94, 85, 37, 29, 37, 49, 37,  9, 11, 37,
         50, 83, 37, 85, 38, 37, 76, 37, 38, 35, 35, 38, 35, 94, 37, 37, 94, 37,
         94, 11, 37, 36, 50,  6, 32, 37, 37, 50, 94, 37, 11,  9, 85, 37, 24, 75,
          2, 32, 37,  9, 37, 37, 94, 85, 37, 83, 24, 38, 35, 35, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 28, 11, 37, 83, 37, 37, 28, 37, 37, 94,  9, 11, 38, 85, 35, 85,
         83,  2, 37, 37, 38, 35, 38, 85, 77, 59, 37, 37, 37,  9, 11, 50, 37, 16,
         37, 28, 49, 37, 94,  9, 11, 83, 37, 37, 38, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 59, 37, 24, 37, 38, 88, 37, 37, 94, 37, 36, 31, 94, 49, 37, 37, 37,
         38, 35, 32, 37,  2, 35, 31, 11, 37, 38, 31, 37, 37, 38, 31, 37, 37, 37,
         38, 43, 37, 37, 34, 38, 35, 35, 38, 35,  9,  9, 49,  9, 49,  2, 83, 11,
         37, 38, 59, 37,  9, 37, 37, 49, 11, 37, 38, 31, 37, 32, 37, 32, 35, 35,
         38, 35, 37, 49, 37, 37,  9, 11, 83],
        [38, 31, 34, 24, 37, 37, 83, 94, 38, 29, 37, 31, 32, 11, 37, 37, 50, 50,
         31, 32, 11, 34, 24, 49, 31, 50, 37, 37, 11, 37, 83, 11, 83, 37, 49, 28,
         38, 31, 37, 37, 50, 32, 37, 24, 94, 31, 11, 37, 50, 37, 47, 31, 28, 11,
         37, 37, 50, 28, 37, 23, 11, 37, 50, 32, 37, 49, 31, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 32, 11, 50, 59, 83, 31, 11, 37, 37, 38, 35, 77,  5, 11, 50,  9,
         37, 11, 37, 37, 37, 37, 38, 35, 35, 11, 37, 56, 37, 94, 49, 11, 37, 37,
         50, 33, 50, 37, 56, 37, 38, 85, 50, 50, 76, 37, 37, 40, 37, 32, 37, 37,
          9, 37, 56, 85, 37, 38, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 35, 35, 35, 32, 37, 37,  9, 85, 37, 47, 11, 83, 37, 28, 35, 83,
         11, 37, 47, 38, 77, 37,  2, 50, 85, 38, 35, 35, 35, 35, 11, 11, 11, 28,
         94, 11, 37, 35, 35, 94, 11, 38, 35, 35, 11,  6, 11, 38, 35, 85, 35, 37,
         37, 37, 23, 11,  2, 56, 11, 56, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:7'), 'lengths': tensor([64, 70, 50, 81, 69, 62, 66], device='cuda:7'), 'ntokens': 462}, 'target': tensor([[ 104,  459,  556,   15,  107,  363,   61,   23, 1083,  201,    4,   16,
           32,  459,  556,   15,   58, 4805,   16, 2157,   23, 1191,   46, 1145,
         1191,    4,   14,  107, 2588, 3011,  130,  224, 1145, 1191,    4,   49,
           23,   31,  705,    4,   50,   32,    9,  355,  259, 4583,  309,    4,
          258, 4025,   16,  304,  675,  588,   16, 5519,   76,    4,   78,   52,
         1225, 7453, 1668,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1589,   18, 5394, 3558,   44, 1935, 2942,   52, 1044,  182,   23, 1442,
         7281,  393,  845,  394,    4,  129,  412, 3554,   37,  161,   43,   39,
           13,  649,  975,  366,   22, 7512,   15,   97, 2013,  174, 1502, 4832,
            4,   74, 5160,   15,  124, 1413, 9684,    5,  396,  202,  156, 2150,
          491,   83,  306, 1048,   20, 5263,    5, 8672,   27,   14,  302,  322,
          152,  241,  181,  236,  426, 4943,  234,    6, 4117,   78,  617,   97,
          698,  497,  182,  141, 1442, 7281,    5,    2,    1,    1,    1],
        [ 520,  228,  345,    4,   16,  547,  139, 5337,   16, 1572,    6, 4752,
          313,   31,  863,   88,   58, 3026, 3319,    4,   23,  654,  643, 5120,
            4, 6826,    4,   77,   30,  507,   57,  262,  112, 1741,   90, 5361,
          201, 5074,   37,    4,  566,  600,   14,  585, 3055,   45, 1170,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  145,  163,   39,   14, 2052, 2425,    4,    9,   23,   31,  112,
           52, 2557, 1097, 1124,  160, 1350, 7239,   22,  221, 2448,   20,    9,
           23, 1297,   18,  292,   49,  791, 1966,  494, 2279,    4,   16,   31,
         1109,   61,    4,  814,  253, 4740,  544,    4,    9,  102,  406, 1581,
         2284, 3281,    6, 4000,   56, 4406,  418, 6993,   48, 2891,    4,   16,
           31, 3933,   58, 9468, 3459, 6362,    6,    4,   16,   40, 1550,   23,
         1807,   54, 1695,  566,  122,  153,  223,  770,  871,    5,    2],
        [1737,  787,   23,  202,  381,   18, 1199,  494,   37, 6542,   22,  757,
           16,   49,   58,  330,   45,  530, 2388,   59,   22, 5044, 6051,  787,
          190,  477,  420,    5,  147,  782,   42, 1033,   23, 5241,  165,  129,
         9509,    6, 2800,   75,  653,    4,   50,  728,  216,  757,   14, 2155,
         1024, 4728,    4,  129,  412,  216, 9509, 4520,   20,   30,  696,    5,
           64,  728,  216, 9509, 7382,   82,    4,  129,  412,  216,  757,  239,
          420, 3552,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 633,  328, 2339,  745,  374, 3436,   98,    4,  136,  212, 2316,   22,
          235, 4428,    4,  105, 1087,   37,    4,   14, 1857, 3207,  212, 4097,
            4,   14,  184, 8922,   15, 4025,   16,   14, 1813, 6240, 6544,  319,
          231,  580,  344, 3714,   96,    4,  299, 1311,    9,  118, 1093,   28,
         5790,    4,   39,  102,   14,  157,  186, 1770,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 376, 8400,  426,  580, 2272,  871,    6,   27,   30,  696,    5, 1735,
          200,  932, 1867,   16, 2907, 1434,  625, 1036,    5, 4287,  696,   51,
         4807,   18,  864,  242, 2407, 1887,    6,   90, 8400,    5,    5,    5,
         1885,   20, 1407,    4,   13,  741, 1693, 1351,    4,  865,  195,  195,
          454,   46,  924,  139, 1458, 1018,   35,  592,  338,  158,   15,   46,
         6572,   20, 8726,    4,  342, 5284,   16, 3533,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'target_lengths': tensor([65, 80, 49, 83, 76, 58, 70], device='cuda:7'), 'ntokens': 481, 'nsentences': 7}##################### {'id': tensor([120580,  62990, 169181, 132272,  24891,  37092,  99796,  52319],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 0.0013,  0.0020,  0.0021,  ...,  0.0002, -0.0015, -0.0023],
        [-0.0012, -0.0021, -0.0016,  ..., -0.0040, -0.0049, -0.0059],
        [ 0.0357,  0.0280,  0.0253,  ..., -0.0051, -0.0046, -0.0026],
        ...,
        [-0.0084, -0.0062, -0.0042,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0010,  0.0014,  0.0016,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0663,  0.0800,  0.0880,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([276960, 276960, 276960, 276960, 276960, 276800, 276800, 276800],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2, 1462, 2171,  482, 1242, 4238,   64,  611,  449,   31, 3709,  173,
           16,  361,  118,  953, 2612,   60,  252,  260,    5, 4799,   48,   41,
         1798,   42, 7764, 2713, 4238,   42, 1272, 1959,   41,   28,  112, 1418,
           44, 1555,  604,   41,   39,   58,  698,  441,  243,  300, 1801,    4,
          124,   39,   58,  435,  122, 2887,  224,   39,   58,  698, 2855, 1801,
           97, 7458,   60,  102, 1938,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   82,   36,    4,   34,   31, 9798, 2607,   16,   90, 8046,
          852,  767,  157, 4665,   30, 1814, 7214,   15,  295, 4120,  363,   28,
         4376,   82,   31, 5090,    4,  136,   31,   82,  139,   40,  905, 6826,
          112,  470,   23, 8807,   37,   15,  326,   14, 1654,  102,  939,   20,
          340,  357,   15,  834,  441,  176, 1409, 6071,   37,  191,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 1209,  844,   27,   23, 2181,  167, 7498,    4,   74,   40, 4000,
          603,  603,    5,   68,  379,   65,   92,  773,   27,   47,   51, 2450,
          307,    5,   68,  379,   65,  720,   27,   14, 1401,    4,   14,   60,
           23, 2002, 2725,  239,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   41, 3417,   47,  275,  534,    4,  136,   43, 5044,  198,   14,
         4078,    4,   43,  466,   60,  448,   28, 3958,    4,   16,  223,  105,
         3654, 5396,    4,  209,   31,   30, 8770,   28, 1166,    4,   43,   29,
         1142,  157,   74, 1048, 3178,   28,  990,    4,   43, 1843,  463, 5504,
            4, 2812,   60,  823,   22, 1983,   22,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  404,  145, 7475,    4,   50,   23, 1207,   22,  195,   37,   23,
          301, 4259,  156,   59,  315,  153,  141, 7869,   22, 3095, 9430,    5,
          400, 5791,  578,   14,  301, 4259,  156,   59,  315,  153,  113,    4,
          114,   81,  337, 2306,   20,   42,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 8170,    4,  114,   81,  547,   14, 4723, 8710,   49, 9721,   22,
         5036, 3732, 8355,   22,   16, 3346,   15, 2835,    4,   16,   43,   60,
           23,  585,  381, 7068, 9103, 1434,  390, 4682, 9218,    4,  695,   81,
            4,  638,   31,    4,   28, 3354,   22, 4384, 3161,   59,  491,   44,
           92,    6,  273, 1640, 5999,   15, 3591,   37,   49,   23, 3388,  714,
          676,  522,  107,    9, 2062,    6,   28,  171,  539,  444,    4,  107,
          986,  331, 2062,    6, 3193,   18, 3613,   16,   88,  107,  189,   78,
           14, 2311, 2639,   28,  260,    5],
        [   2,   99,  178,  113,   52, 1238,  489,   49, 4632,   15, 8324,   22,
         5091,   35, 8174,   15,    9, 1815,    4,   34,  107, 5025,  425, 2625,
         4035,    4,   34,   32,  482,  208,    4,   34,   29,  190,   27,   74,
           23, 4104,   35, 2507,  675, 2051,   35, 5703,   45,   45,   16,  306,
          331,  576,   48, 1188,   20, 8324,   59,  938,  362, 2520,  195, 2054,
         1815,    6,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 8621,   59, 6193,    4,   30, 3389,   27, 2094,   16,   14, 3824,
           27,   95,  174,  683,   45,  418,    5,  312, 3426,    6, 8879,   22,
           35, 1055,  511,   93,    5,   72,  209, 1388,    4,   50,   36,   52,
         3092, 3553,  178,    4,   30,  767,  642,  184,   22, 1010,   37,   27,
           90,  406, 3553,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[   8,    9,   17, 5289,    4,   19,  213,   10, 3571,   69,   25,   77,
           13, 3674, 1336,  797,    5, 3163,   42,  120,  568, 1609, 1772,   42,
          115,   79,   25, 1116, 1454,   17,  630,    4,  635,   25,   11,   57,
          826,   80,    7,  245,  383,   12,  909, 7991,  109,  321,   37,  122,
         2887,    4,    7,  245,  183,   17,  807,   63,    9,   13, 5003,   71,
           13, 3700,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   29,  120, 8046,  852,  759,   94, 1730, 1704,    7,  230,   10,
         3265,  159,  447, 4341,    4,   19,   34,  417,  140, 2362,  816,    4,
           67,   19,   34,  113,   13, 2677, 5891,   80,  185,   12,    7, 1122,
          119,  756,  214, 1886,   59, 1778, 1708,    7, 1832,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,  180,   25,   66,   33, 2173,    4,  133, 3495,    4,  100,   13,
         2610, 2354,    5,   68,  194,   65,   21,   11,    6,   86, 4878, 3430,
         2077,    5,   68,  194,   65,   33,   26,    7,  670,    4, 1405,   71,
            7, 1237,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  53,  465,   11,   18,  135,   77,   17,  261,   80,   21,    4,   67,
           53, 1742,  110,    7, 2212,   10, 3231,   21,  540,   71,  134,    5,
            8,   19,  154, 5166,  131,   17, 3238,    4,   21,   11,    6,  226,
           89, 4854,   10,  780,    8,  875,   21,   10,   79,  294,  218,   94,
           79,   19,   73,    4,  746,   12, 2423,   21,   69,  359, 1976,  818,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,  120,   25, 2252,   17,    7,  682,    6, 1090,   12,    7, 2852,
           59,   18,  232, 1321,  100,   39, 3135, 2076,    6,    6,  235, 6054,
            4,    8,   73,   24,  934,    4,  103,   24, 1897,    7,  682,    6,
         1090,   12,    7, 2852,   59,   18,  232,    4,  138, 3462,  225,   11,
            6,  142,   10,   51,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 238,    4,  103,   25,  305,    7, 4023, 5828,    6,  106, 4748,   79,
          589,   56, 7038,  693,    8, 3334,    6,    4,    8,   25, 4812,  134,
           71,    7, 2402,  119, 1221,   69, 2645, 7425,    4,   19,  154,   25,
          367,   10,  117, 7034,    6,   44,   17,  108,  230,   20, 1032, 3227,
          162, 2770,  131, 2569,   10, 4533,   20,  170,  199, 1543,    6,    4,
           10, 5039,  170, 1525,  218, 1543,    6,    8,  180,   10, 2639,  170,
           10,    7, 2403,    5,    2],
        [  29,   84,   11,    6,   13,  535, 1261,   12, 3586, 1503,    9,  181,
          371,  119,  668,  140, 1079, 1643, 3357,    9, 1777,    4,  166,   19,
         6938,  601,    6,  170,   10, 1945,   70,   24,  150,  440,    4,  166,
           26,  250,  100,    7,  391,  205,   59,  247,    6,  255,   45,    8,
          294,  218, 5560,    6,   12, 1503, 7119,   22,  430, 1241, 1777,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 999, 1511,    4,    7, 3413,   11,    6, 5691,    4,    7, 3236,  574,
          160,  156,    6,    5,   13,  442,   35,  160,   35,  620,  158, 1583,
            5,   19,   11,  121, 1346,   84,   11,    6,  250,  264,   46,   13,
          759,  825,  143,  883,   48,  254,   89, 1583,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 37, 37,  9, 11, 38, 88, 37, 38, 37, 37, 50, 37, 38, 38, 35, 11,  2,
         11, 37, 85, 59, 49, 11, 83, 37, 37, 38, 77, 37, 94, 11,  6, 37, 85, 77,
         59, 37, 37, 83, 24, 37, 38, 94, 37, 38, 77, 35, 77, 11, 37, 83, 24, 37,
         56, 85, 37, 37,  9, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 83, 37, 34, 73, 24, 56, 83, 31, 37, 37, 37, 88, 37, 37, 56, 11, 38,
         85, 38, 35, 35, 35, 11, 37, 38, 85, 83, 37, 49,  2, 37, 50, 37, 37, 38,
         75, 77, 56, 38, 35, 35, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 37, 85, 37, 32, 11, 83,  2, 11, 37, 37,  9, 23, 11, 38,  9, 11,
         37, 85, 37, 83, 56, 35, 31, 11, 38,  9, 11, 37, 85, 37, 94, 11, 31, 37,
         37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 85, 85, 35, 59, 50, 37, 83, 37, 37, 11, 37, 37, 31, 37, 37, 94, 37,
         88, 37, 36, 37, 37, 11, 37, 38, 59, 31, 37, 37, 32, 11, 37, 85, 37, 85,
         37, 32, 37, 88, 37, 49, 37, 37, 37, 50, 50, 56, 37, 38,  6, 11, 83, 37,
         80, 37, 37, 37, 50, 88, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 37, 86, 37, 37, 38, 37, 35, 37, 37, 79, 35, 35, 77, 59, 37, 38,
         28, 38, 37, 37, 35, 35, 11, 37,  6, 38, 88, 11, 37, 38, 31, 37, 38, 37,
         35, 37, 37, 79, 35, 35, 77, 11, 37,  2, 37, 85, 37, 49, 37, 38, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [83, 11, 37, 37, 49, 37, 75, 32, 37, 37,  2, 37, 35, 38, 35, 56, 37, 94,
         37, 11, 37, 37, 36, 37, 37, 37, 83, 75, 94, 37, 28, 94, 11, 38, 59, 37,
         85, 37, 37, 32, 37, 82, 37, 37, 37, 77,  2, 47, 85, 31, 37, 94, 37, 23,
         77, 37, 37,  9, 37, 11, 37, 33, 37, 37, 50,  9, 37, 37, 37, 37,  2, 37,
         37, 37, 94, 11, 83],
        [83, 37, 85, 37, 37, 83, 94, 37,  2, 13, 37, 35, 35, 75, 35, 35, 35, 35,
         56, 37, 28, 11, 37, 38, 88, 49, 37, 37, 37, 88, 50, 38, 59, 83, 11, 37,
         85, 50, 37, 37, 34, 85, 35, 77, 37, 38, 35, 37, 50, 50, 32, 37, 37, 13,
         76, 35, 35, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [ 2,  9, 11, 37, 32, 85, 37,  2, 11, 37, 94, 38, 35, 35, 37, 11, 37, 31,
         38, 35, 38, 77, 35,  9, 11, 38, 85, 35, 59, 37, 85, 37, 50,  2, 11, 37,
         24, 24, 50, 38, 31, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([64, 47, 40, 62, 54, 77, 61, 46], device='cuda:0'), 'ntokens': 451}, 'target': tensor([[1462, 2171,  482, 1242, 4238,   64,  611,  449,   31, 3709,  173,   16,
          361,  118,  953, 2612,   60,  252,  260,    5, 4799,   48,   41, 1798,
           42, 7764, 2713, 4238,   42, 1272, 1959,   41,   28,  112, 1418,   44,
         1555,  604,   41,   39,   58,  698,  441,  243,  300, 1801,    4,  124,
           39,   58,  435,  122, 2887,  224,   39,   58,  698, 2855, 1801,   97,
         7458,   60,  102, 1938,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   82,   36,    4,   34,   31, 9798, 2607,   16,   90, 8046,  852,
          767,  157, 4665,   30, 1814, 7214,   15,  295, 4120,  363,   28, 4376,
           82,   31, 5090,    4,  136,   31,   82,  139,   40,  905, 6826,  112,
          470,   23, 8807,   37,   15,  326,   14, 1654,  102,  939,   20,  340,
          357,   15,  834,  441,  176, 1409, 6071,   37,  191,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1209,  844,   27,   23, 2181,  167, 7498,    4,   74,   40, 4000,  603,
          603,    5,   68,  379,   65,   92,  773,   27,   47,   51, 2450,  307,
            5,   68,  379,   65,  720,   27,   14, 1401,    4,   14,   60,   23,
         2002, 2725,  239,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  41, 3417,   47,  275,  534,    4,  136,   43, 5044,  198,   14, 4078,
            4,   43,  466,   60,  448,   28, 3958,    4,   16,  223,  105, 3654,
         5396,    4,  209,   31,   30, 8770,   28, 1166,    4,   43,   29, 1142,
          157,   74, 1048, 3178,   28,  990,    4,   43, 1843,  463, 5504,    4,
         2812,   60,  823,   22, 1983,   22,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 404,  145, 7475,    4,   50,   23, 1207,   22,  195,   37,   23,  301,
         4259,  156,   59,  315,  153,  141, 7869,   22, 3095, 9430,    5,  400,
         5791,  578,   14,  301, 4259,  156,   59,  315,  153,  113,    4,  114,
           81,  337, 2306,   20,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [8170,    4,  114,   81,  547,   14, 4723, 8710,   49, 9721,   22, 5036,
         3732, 8355,   22,   16, 3346,   15, 2835,    4,   16,   43,   60,   23,
          585,  381, 7068, 9103, 1434,  390, 4682, 9218,    4,  695,   81,    4,
          638,   31,    4,   28, 3354,   22, 4384, 3161,   59,  491,   44,   92,
            6,  273, 1640, 5999,   15, 3591,   37,   49,   23, 3388,  714,  676,
          522,  107,    9, 2062,    6,   28,  171,  539,  444,    4,  107,  986,
          331, 2062,    6, 3193,   18, 3613,   16,   88,  107,  189,   78,   14,
         2311, 2639,   28,  260,    5,    2],
        [  99,  178,  113,   52, 1238,  489,   49, 4632,   15, 8324,   22, 5091,
           35, 8174,   15,    9, 1815,    4,   34,  107, 5025,  425, 2625, 4035,
            4,   34,   32,  482,  208,    4,   34,   29,  190,   27,   74,   23,
         4104,   35, 2507,  675, 2051,   35, 5703,   45,   45,   16,  306,  331,
          576,   48, 1188,   20, 8324,   59,  938,  362, 2520,  195, 2054, 1815,
            6,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [8621,   59, 6193,    4,   30, 3389,   27, 2094,   16,   14, 3824,   27,
           95,  174,  683,   45,  418,    5,  312, 3426,    6, 8879,   22,   35,
         1055,  511,   93,    5,   72,  209, 1388,    4,   50,   36,   52, 3092,
         3553,  178,    4,   30,  767,  642,  184,   22, 1010,   37,   27,   90,
          406, 3553,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([66, 59, 41, 56, 42, 90, 63, 52], device='cuda:0'), 'ntokens': 469, 'nsentences': 8}
##################### {'id': tensor([ 18643,  72004, 123044,  92952,    119,   4235, 157495, 101019, 144886,
         30532,  42491, 150933,  83030,   4544, 137425,  18819, 194200, 124344,
         56788,  28732,  85964, 143801,  50645, 192301,   2471,  98294,  53412,
         92755,  58077, 118305,  80761, 142804,  35987, 119874, 180726, 138720,
        112708, 140269, 125151, 186622,  63943,  98359, 154204, 206039,  75982,
        225089,  15421, 177690, 103039,  26284, 134555, 156933, 193616, 212512,
         16586,  79571], device='cuda:5'), 'net_input': {'src_tokens': tensor([[-9.1553e-04, -1.9714e-02, -5.0140e-02,  ..., -6.5613e-03,
         -5.0964e-03, -3.4180e-03],
        [-1.7700e-03, -1.3733e-03, -1.8005e-03,  ...,  7.9346e-04,
          1.4954e-03,  2.6855e-03],
        [ 8.9722e-03,  1.0254e-02,  8.6670e-03,  ..., -9.5520e-03,
          1.1810e-02, -3.1128e-03],
        ...,
        [ 1.8311e-04, -1.2207e-04, -3.0518e-05,  ...,  1.7700e-03,
          1.9836e-03,  0.0000e+00],
        [ 2.3621e-02,  2.2552e-02,  3.5522e-02,  ...,  1.5533e-02,
          1.4612e-01,  0.0000e+00],
        [ 1.4038e-03,  9.1553e-04,  1.8311e-04,  ...,  3.3875e-03,
          2.8687e-03,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920,
        41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920,
        41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920,
        41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920,
        41920, 41920, 41920, 41920, 41920, 41920, 41920, 41920, 41919, 41919,
        41919, 41919, 41919, 41919, 41919, 41919], device='cuda:5'), 'prev_output_tokens': tensor([[   2,   41,  123,  ...,    1,    1,    1],
        [   2,   64,   14,  ...,    1,    1,    1],
        [   2,  376, 3543,  ...,    1,    1,    1],
        ...,
        [   2, 3105, 4669,  ...,    1,    1,    1],
        [   2,   72,  557,  ...,    1,    1,    1],
        [   2, 1555,  776,  ...,    1,    1,    1]], device='cuda:5')}, 'transcript': {'tokens': tensor([[  29,    4,   25,  ...,    1,    1,    1],
        [   8,  180,    7,  ...,    1,    1,    1],
        [   7, 4821,   10,  ...,    1,    1,    1],
        ...,
        [ 540,   53, 3122,  ...,    1,    1,    1],
        [   8,   19,   11,  ...,    1,    1,    1],
        [ 635,   24,  296,  ...,    1,    1,    1]], device='cuda:5'), 'cluster_tokens': tensor([[83, 11, 37,  ..., 37, 37, 37],
        [37, 37, 37,  ..., 37, 37, 37],
        [37, 29, 37,  ..., 37, 37, 37],
        ...,
        [36, 37, 31,  ..., 37, 37, 37],
        [37, 38, 85,  ..., 37, 37, 37],
        [ 6, 38, 49,  ..., 37, 37, 37]], device='cuda:5'), 'lengths': tensor([13, 13, 18, 13, 14, 18, 16, 10, 16, 11, 16, 13, 17, 11, 17, 12,  6, 10,
         8, 15, 12, 21, 12, 12, 15, 18, 17, 15, 19, 21, 15, 12,  9, 18, 11, 16,
        14, 14, 12, 21, 12, 13, 15, 11, 21, 14, 20, 17, 20,  7, 17, 14, 11, 14,
        15, 13], device='cuda:5'), 'ntokens': 805}, 'target': tensor([[  41,  123,  921,  ...,    1,    1,    1],
        [  64,   14, 5695,  ...,    1,    1,    1],
        [ 376, 3543, 6994,  ...,    1,    1,    1],
        ...,
        [3105, 4669,   15,  ...,    1,    1,    1],
        [  72,  557,  263,  ...,    1,    1,    1],
        [1555,  776,   32,  ...,    1,    1,    1]], device='cuda:5'), 'target_lengths': tensor([12, 14, 23, 13, 11, 21, 11, 11, 65, 14, 11, 10, 18, 16, 16, 14, 10,  9,
        13, 12, 14, 32, 14, 11, 13, 22, 16, 21, 23, 13, 19, 12,  8, 18, 11, 13,
        16, 16, 10, 15, 18, 12, 18, 10, 13, 15, 22, 16, 34,  7, 16, 15, 12, 17,
        11, 11], device='cuda:5'), 'ntokens': 888, 'nsentences': 56}
##################### {'id': tensor([ 56659, 169943,  51731,  61336, 193899, 212167, 150108, 194132, 181388,
         82160, 174731,  52771, 113658,  44509,  76445, 154096],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-6.7749e-03, -7.8430e-03, -1.0406e-02,  ...,  4.1199e-03,
         -6.1035e-05, -5.2490e-03],
        [ 1.2512e-03,  8.2397e-04,  7.6294e-04,  ..., -2.6428e-02,
         -2.7557e-02, -2.8229e-02],
        [-4.0588e-03, -3.8147e-03, -6.7139e-04,  ...,  9.4910e-03,
          3.1189e-02,  4.6844e-02],
        ...,
        [ 1.3489e-02,  1.2268e-02,  8.7891e-03,  ..., -4.2419e-03,
         -1.2817e-03, -6.4087e-04],
        [ 9.6130e-03,  1.2299e-02,  3.0212e-03,  ..., -1.2207e-04,
          1.5869e-03,  4.2419e-03],
        [-8.8501e-04, -1.0376e-03, -9.1553e-04,  ...,  6.1035e-05,
          4.2725e-04,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([127840, 127840, 127840, 127840, 127840, 127840, 127840, 127840, 127840,
        127840, 127840, 127840, 127840, 127840, 127840, 127839],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2, 1741,   24,  365, 1343, 6839, 3786,   20, 3482, 4175,   20,   23,
         1980,  315,  718,   15,  353,   49, 1699,  242, 6003,  303,   61,    4,
           23, 2831,   15,  353,   49, 8671,    4,   23, 2831,   15,  353,   49,
         7972,    6, 1338,    5,    1,    1,    1,    1,    1],
        [   2,  882,  742,   15,   18, 1643, 2259,   37, 8235,  130,   81,   14,
         5360,    6, 1707,   18, 2729,   20,   97, 1840, 3059,   16,  130,   29,
         1096, 2624,   49, 1536,  978,  196,   52,   40, 6116,   20, 4679, 4261,
           20,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  557,   36,  182,  560,  173,   98, 2112,    4,  428,   31,
          449,    4,   50,   41,   36, 1128, 4753,   16,   39, 2843,  123,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  396,   59, 1063,  606,  338,  322, 3030,  239,    9,   40, 3824,
         4024,   40, 8359,    4,   60,  102, 6025,   22,   16,  349,   59,  152,
          821, 6585,  676,  127, 2254,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   14, 1642, 1084,  152,  241,  181, 3103, 1629,  243,   22,
         1243, 4063,    4, 1364,   30,   39,  805, 3055,  221,  119,   57,  930,
          165,    4,  124,  716,    4,   74,   14, 3809, 1084,  152,  241,  181,
         3103,   58, 1589,  174,  112, 1500,  130,   42,    1],
        [   2,   41,  123,  118, 6860, 1669,  124,  118,   56, 2342, 1527,    4,
          124,    4,  177, 2009,    4,  585, 2999,   40,  181, 2628,   22,    5,
           99,   27,   74,   40, 3402, 1341,   22,  481,    6, 6548,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  228,  412,  562,  221,  195,    4,  576, 5322,   16, 1541, 1150,
          522,   28,   58,  937, 1707,   15,   23,  939,  885,  416,  247,  790,
          834,   23, 3225,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,   51, 2514,  232,  405, 4852, 7292,   15,   16,  202,  243,
          315,  530,  165,    4,  136,  731,    6,  604,   32,  466, 3873,  112,
          186,  314,  182,   46,  112,  273,  314,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  573,  517, 3825,   96, 3369,    4,   49,  102,  256, 1145,
          320,  769,    5,   68,  379,   65,   72, 4034,  355,  167, 1700,  374,
          534,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104,    4,   90,  157,    4,   76, 4286,   14,  326, 5356,   16,
           32,  776,  831, 2112,    4,   50,  273, 4192,  107,  847, 1176,   16,
          897, 6040,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  377,  328, 1550,   23, 2675,  127,   32, 1208, 1471,   16,  127,
          714, 4787,    4,   29,   98, 1842,    6,  849,   14, 7786,  139, 3882,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  396, 2533,   20,  202, 6497,  721,    4,   14,  574,  902,  562,
           22, 2079, 2634, 1852, 2424,  616,    4,   14,  202,  786,  793,   15,
            4,   98,  102, 2043,  381,  228,  706,  381,   23, 8249,  184, 2133,
           15,    4,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  105, 3385,  354,   23, 2258,  253, 2467, 4761,  171,  620,
         1591,   15,    4, 4462,   74, 1245,  351, 3386,    5,   38,  967,  638,
            4,   36,  178, 1447, 9296,   22,  129, 2064,    6,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   30,   27,   30, 2155,  497,    9, 5440,    4,    9,  102,
           32,  216,   90,  640,  950,   23, 8051,   22, 2716,   83,    4,  124,
         3596, 6846,   32,    4,   50,   36,   97, 7061,  640,  950,  319,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  400,   51, 3641,   32,  946,    4,  410, 3270,  262, 2863,    4,
           16,   30,   27,   23,  624,   49, 1185,  301, 3887,   22,    4,   14,
           31,    9,  328, 2978,   51, 2416,   15,  557,    5, 1702,    6, 2908,
           37,   76,  766,    5,  400, 1669,   32, 1702,   42],
        [   2,   64,   30, 3208,   75,   38,  360,  356,  174,  119,   35,  592,
          900,  980,  210,  328, 1877, 3230,   75, 3525, 1124, 1430,   20, 6747,
           28,  141,  184, 1124, 1430,   15, 3095, 2631,  223, 4285, 5801,  466,
            5,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[1662,  188, 7573, 7749,  958, 1195,   12,    7, 3286, 1503,   12, 2788,
          407,  140, 2517,    4,    7, 3286, 1503,   12, 8481,    4,    7, 3286,
         1503,   12, 8416,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   71, 3612, 1181, 7398,    4,   25,   73, 1206,    7, 3316, 1206,
            4,    8,   25,   73, 1988,   17, 4891, 7015, 3151,  613,   71, 3716,
         8264,    6, 1405,    9,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 168,    4,   19,   11,   45,  142,   10,  388,   21,  126,   84,    4,
         1065,   69, 7688,    4,    8,   19,  213,   25,   10, 2213,   21,  132,
            8, 6785,   21,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  33, 4516,  188,  226,  388,  199,   13, 3236, 1810,   17,   11,    6,
          115,  378,  619,   10,  229, 4638,    6,  688,  533, 2893,    4,   10,
          229, 1009,   51,  727,    6,  688,  533, 2893,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [  67,  120,    7,  558, 1202,  706, 1202,    6, 1629,   35, 1610,  119,
            4,   26,   21,  125,  225,  442,   13, 1629, 3916,    4,  109,  125,
           12,    7,  207,    7, 1575, 1202,  706, 5260,    7, 1031,  741,   42,
            2,    1,    1,    1,    1],
        [  29,   25,   73,  468,   13, 3493,    4,   25,   73,  305, 3493,    6,
          126,    4,   67,  281, 5221,    4,   25,   73,  993,  264, 2192,    9,
            4,  321,   12,  100,   13, 3402, 1341,   22, 5689,    5,    2,    1,
            1,    1,    1,    1,    1],
        [ 199,  562,  833,    4,  811,  140, 7710,    8,  203,  121,   22,  247,
         1505,    7,   19, 1218,    6,   12,    7,  939, 5575,   37,  424,  322,
          834,   12,    7, 2078,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  24,  283,   69,  284, 4222, 3454,    8,  284, 3577,  236, 1317,    4,
           67,  281,   12,    7,  183,   24, 1744,  826,  126, 6341,  540,   80,
          284,  282,   46,  172,    4,   80,  108,  931,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [  84,   34,  185,  218, 4949,  993,   17,   19,  154,   89, 3181,  451,
          135,   80,    5,   68,  194,   65,    8,   19,   34, 1767,   10,  450,
          267,   77,   80,   21,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  24,   11,   57,    4,   79,  422, 3772,    4,    7, 5558,   17,  719,
            4,    8,   24,  451,  229, 1123,   17,  108, 3927, 4793,  170,    9,
           17, 3487,    8,   63, 1405,    9,   17,  370, 1683,    5,    2,    1,
            1,    1,    1,    1,    1],
        [  17,  841,   12, 1080,    4,   24,   11,   57,  142,   10, 2215,    4,
            8,   24,   11,   57,  142,   10, 3040,   55,    4, 3610, 3756,   33,
         5656, 1321,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  77,   17, 3153,  827,  247, 3917,   20,  234,    4,    7, 6901,   93,
         2264,  160,  945, 1320, 2147,   96,    4,    7,   95,  786,  793,    6,
         1927,   22,  106,    7, 7828,   11,    6,  506,   93,    9,   22,  918,
            6,    4,    2,    1,    1],
        [   8,   17, 2303,  169,  601, 8940,    7, 2196,    4,   79,  238,   79,
           77,   12,    7,  218,  926,    6,   12,   21,    5,   38,  187,  154,
           84,   11,    6,   13,  800,   12, 6442,  293,    6,   10, 2786,    5,
            2,    1,    1,    1,    1],
        [   8,   33,   26,    7,  744,  464,    9,   13, 5865,   24,   66, 2128,
          244,  640,  439,   12,    7, 9518,    4,  109,   24, 5318,   24,   11,
          121, 2128,  640,  439,   12,    7, 9518,  244,    7, 6852,    5,    2,
            1,    1,    1,    1,    1],
        [ 138,   87,   25,  388,  946, 7415,  366, 2671,    4,    8,    7,  245,
           12,  785, 7196,    6,   17,   19,   11,   45,  142,   10,  456,   80,
            9,   33,  456,   42, 1588,  128, 2771,  373,  988,    5,  138,   87,
           24,  468, 1588,   42,    2],
        [   8,   17,   11,    6,  434, 1244,   35, 2959,   45,  174,  111,    4,
          166,   26,   13,  979,  131,  166, 5465,   62, 2028,  991,   39, 1296,
           62, 1710,  359,  288, 1749, 4506,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:5'), 'cluster_tokens': tensor([[28, 85,  4,  2, 94, 56, 37, 37,  2, 13, 37, 94, 35, 35, 32, 11, 37,  2,
         13, 37, 28, 11, 37,  2, 13, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 28, 31, 94, 11, 37,  6, 29, 37, 94, 29, 11, 37, 37,  6, 31, 37,
         32, 73, 32, 32, 37, 32,  5, 37, 31, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37, 11, 38, 85, 35, 49, 37, 31, 37, 37, 37, 11, 24, 37, 83, 11, 37, 38,
         88, 37, 37, 49, 37, 37, 37, 49, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [37,  9, 85, 85, 31, 37, 37, 94, 32, 37, 85, 37, 83, 49, 31, 37, 49, 94,
         37,  9, 35, 35, 11, 37, 49, 49, 38, 35, 37,  9, 35, 35, 11, 83, 37, 37,
         37, 37, 37, 37, 37],
        [37, 37, 37, 37, 49, 77, 49, 37, 38, 38, 35, 75, 11, 85, 37, 37, 37, 31,
         37, 38, 32, 11, 37, 37, 37, 37, 83, 37, 28, 49, 77, 31, 37, 38, 35, 11,
         83, 37, 37, 37, 37],
        [83, 37,  6, 29, 37,  9, 11, 37,  6, 49,  9, 37, 37, 11, 37, 75, 83, 11,
         37,  6, 32,  2, 94, 37, 11, 38, 37, 37, 37, 38, 35, 35,  9, 11, 83, 37,
         37, 37, 37, 37, 37],
        [37, 77, 35, 11, 38, 35, 35, 37, 38, 35, 35, 77, 85, 37, 38, 35, 37, 37,
         37, 38, 35, 77, 35, 35, 11, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [38, 49, 37, 37,  9,  9, 37, 37,  2, 35, 77, 11, 37, 75, 37, 37, 24, 38,
         49, 59, 37,  2, 36, 37, 37, 32, 11, 83, 11, 37, 37, 37, 11, 83, 37, 37,
         37, 37, 37, 37, 37],
        [37, 85, 50, 50,  2, 32, 37, 38, 59, 37, 94, 85, 59, 37, 11, 38,  9, 11,
         37, 38, 85,  2, 37, 88, 37, 50, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [38, 85, 77, 11, 37, 28, 56, 11, 37, 56, 37, 49, 11, 37, 38, 85, 49, 83,
         37, 37, 56, 94, 37, 37, 37, 94, 37, 85, 31, 37, 37,  4, 32, 11, 83, 37,
         37, 37, 37, 37, 37],
        [37, 32, 37, 94, 11, 38, 85, 77, 49, 37, 49, 11, 37, 38, 85, 77, 49, 37,
         76, 37, 11, 83,  6, 37, 76, 59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37],
        [50, 37, 38, 35, 77, 38, 77, 35, 11, 37,  9, 35, 38, 35, 77, 38, 35, 77,
         11, 37, 38, 35, 35, 37, 49, 35, 37, 37,  9, 85, 37,  6, 35, 37, 35, 35,
         37, 11, 83, 37, 37],
        [37, 37, 94, 85, 49, 29, 37, 94, 11, 37, 83, 37, 50, 37, 37, 50, 94, 37,
         37, 37, 11, 38, 35, 59, 37, 85, 37, 37, 23, 37, 94, 35, 37, 37, 32, 11,
         83, 37, 37, 37, 37],
        [37, 37, 85, 37, 24, 24, 37, 37, 94, 38, 85, 31, 37, 34, 24, 37, 37, 56,
         11, 37, 38, 88, 38, 85, 35, 31, 34, 24, 37, 37, 56, 37, 37,  9, 11, 83,
         37, 37, 37, 37, 37],
        [37, 85, 37, 31,  2, 29, 77, 56, 11, 37, 37, 83, 37, 34, 32, 37, 37, 38,
         85, 35, 49, 37, 16, 37, 37, 37, 16, 11, 32, 35, 32, 56, 23, 11, 37, 85,
         38, 29, 32, 11, 83],
        [37, 37, 85, 37, 31, 32, 38, 77, 35, 35, 83, 11, 37, 85, 37, 32, 37, 37,
         94, 31, 56, 49, 38, 49, 31, 94, 37, 83, 28, 36, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([29, 30, 29, 34, 37, 35, 30, 34, 30, 35, 28, 39, 37, 36, 41, 32],
       device='cuda:5'), 'ntokens': 536}, 'target': tensor([[1741,   24,  365, 1343, 6839, 3786,   20, 3482, 4175,   20,   23, 1980,
          315,  718,   15,  353,   49, 1699,  242, 6003,  303,   61,    4,   23,
         2831,   15,  353,   49, 8671,    4,   23, 2831,   15,  353,   49, 7972,
            6, 1338,    5,    2,    1,    1,    1,    1,    1],
        [ 882,  742,   15,   18, 1643, 2259,   37, 8235,  130,   81,   14, 5360,
            6, 1707,   18, 2729,   20,   97, 1840, 3059,   16,  130,   29, 1096,
         2624,   49, 1536,  978,  196,   52,   40, 6116,   20, 4679, 4261,   20,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  72,  557,   36,  182,  560,  173,   98, 2112,    4,  428,   31,  449,
            4,   50,   41,   36, 1128, 4753,   16,   39, 2843,  123,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 396,   59, 1063,  606,  338,  322, 3030,  239,    9,   40, 3824, 4024,
           40, 8359,    4,   60,  102, 6025,   22,   16,  349,   59,  152,  821,
         6585,  676,  127, 2254,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 222,   14, 1642, 1084,  152,  241,  181, 3103, 1629,  243,   22, 1243,
         4063,    4, 1364,   30,   39,  805, 3055,  221,  119,   57,  930,  165,
            4,  124,  716,    4,   74,   14, 3809, 1084,  152,  241,  181, 3103,
           58, 1589,  174,  112, 1500,  130,   42,    2,    1],
        [  41,  123,  118, 6860, 1669,  124,  118,   56, 2342, 1527,    4,  124,
            4,  177, 2009,    4,  585, 2999,   40,  181, 2628,   22,    5,   99,
           27,   74,   40, 3402, 1341,   22,  481,    6, 6548,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 228,  412,  562,  221,  195,    4,  576, 5322,   16, 1541, 1150,  522,
           28,   58,  937, 1707,   15,   23,  939,  885,  416,  247,  790,  834,
           23, 3225,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,   51, 2514,  232,  405, 4852, 7292,   15,   16,  202,  243,  315,
          530,  165,    4,  136,  731,    6,  604,   32,  466, 3873,  112,  186,
          314,  182,   46,  112,  273,  314,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,  573,  517, 3825,   96, 3369,    4,   49,  102,  256, 1145,  320,
          769,    5,   68,  379,   65,   72, 4034,  355,  167, 1700,  374,  534,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104,    4,   90,  157,    4,   76, 4286,   14,  326, 5356,   16,   32,
          776,  831, 2112,    4,   50,  273, 4192,  107,  847, 1176,   16,  897,
         6040,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 377,  328, 1550,   23, 2675,  127,   32, 1208, 1471,   16,  127,  714,
         4787,    4,   29,   98, 1842,    6,  849,   14, 7786,  139, 3882,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 396, 2533,   20,  202, 6497,  721,    4,   14,  574,  902,  562,   22,
         2079, 2634, 1852, 2424,  616,    4,   14,  202,  786,  793,   15,    4,
           98,  102, 2043,  381,  228,  706,  381,   23, 8249,  184, 2133,   15,
            4,    2,    1,    1,    1,    1,    1,    1,    1],
        [  64,  105, 3385,  354,   23, 2258,  253, 2467, 4761,  171,  620, 1591,
           15,    4, 4462,   74, 1245,  351, 3386,    5,   38,  967,  638,    4,
           36,  178, 1447, 9296,   22,  129, 2064,    6,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   30,   27,   30, 2155,  497,    9, 5440,    4,    9,  102,   32,
          216,   90,  640,  950,   23, 8051,   22, 2716,   83,    4,  124, 3596,
         6846,   32,    4,   50,   36,   97, 7061,  640,  950,  319,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 400,   51, 3641,   32,  946,    4,  410, 3270,  262, 2863,    4,   16,
           30,   27,   23,  624,   49, 1185,  301, 3887,   22,    4,   14,   31,
            9,  328, 2978,   51, 2416,   15,  557,    5, 1702,    6, 2908,   37,
           76,  766,    5,  400, 1669,   32, 1702,   42,    2],
        [  64,   30, 3208,   75,   38,  360,  356,  174,  119,   35,  592,  900,
          980,  210,  328, 1877, 3230,   75, 3525, 1124, 1430,   20, 6747,   28,
          141,  184, 1124, 1430,   15, 3095, 2631,  223, 4285, 5801,  466,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'target_lengths': tensor([40, 38, 24, 30, 44, 35, 28, 32, 26, 27, 25, 38, 34, 36, 45, 37],
       device='cuda:5'), 'ntokens': 539, 'nsentences': 16}
##################### {'id': tensor([ 11989, 217401,  74203, 175895, 143557, 218979,   1728,  98221,  92012,
        142160,  24026,  86170, 101740, 136017, 150937,  98171],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[-1.8335e-01, -2.6807e-01, -3.1543e-01,  ...,  5.6519e-02,
          5.7526e-02,  5.6946e-02],
        [-6.6772e-02, -5.1483e-02, -3.2104e-02,  ...,  1.7090e-03,
          1.4954e-03,  5.4932e-04],
        [-5.4932e-04, -1.0986e-03, -6.4087e-04,  ..., -4.8828e-04,
         -5.7983e-04, -2.1362e-04],
        ...,
        [ 5.1880e-04,  3.0518e-04,  6.1035e-05,  ..., -9.7351e-03,
         -7.5684e-03, -4.4556e-03],
        [ 3.6621e-04,  5.7983e-04,  4.5776e-04,  ...,  2.5024e-03,
          2.0752e-03,  0.0000e+00],
        [ 1.5564e-03,  1.4038e-03,  1.3428e-03,  ..., -3.6621e-04,
         -3.6621e-04,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([136640, 136640, 136640, 136640, 136640, 136640, 136640, 136640, 136640,
        136640, 136640, 136640, 136640, 136640, 136639, 136639],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2,   72,  145,   14,   13, 8413, 2089,  410, 3010,    5,  400,  208,
           43,   98,   42,   92, 1783,  242, 3476,    4, 5529, 1687,    4, 5529,
         3346,    5,  312, 2864,   59, 2190,    5, 1414,  646, 1214,  712, 4216,
           15,    5, 1935,  588,   44, 8816,    5, 1458,  483,  920,   44,  757,
            4,   30, 1640, 1343, 4527,   16,  414, 2512,  239,    5],
        [   2,   41,  604,  189, 1746,   44,   38, 2579,    6,   20, 1024,  145,
           30,  757, 1246,   47,   61,   18, 5976,    5,  146,  585, 1024,  258,
         4819,  433,  857,   41,   76, 2730,    4,   14,  615, 2149,   16,   29,
         4063,   14, 3076, 1576,  463,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  349,  360,   44,  298,    4,  299,  773,  173,    4,   31,  788,
          190,  167, 5700,   96,  260,   40, 2486,    6,    4,   19, 1707,  481,
            6,  590, 1679,  302,   37,   75,  112, 4307, 1454, 6134,  891,   15,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  173,  208,   32, 3828,    6, 6132,  706,  586,    4,   23,
         1846,  253,  696, 1908,    5,   72, 9849,  361,  113,  355,  696,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   31,  280,  118, 5297, 2361, 2556,   15,    4,   90,   31,
         1673, 4406,  437,  372, 1265, 4742,   20,    4,   16, 2012,   82,   31,
           39,  151,  437,   20, 1515, 1689,    9,  771,  314,   16,   31, 3452,
            4,  163,  646, 1351,   16, 3068,   28, 3617,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1135,  145,   36,   47,  501,  458,  881, 1940,   90, 1937,   11,
          186,   42,   38, 2195,   82,   23, 1783,  242,  919,    4,   23,   12,
           18,  112,  405, 1940,   90, 3329,   59,  919, 3251,  153,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 1627,   14, 2144,    4,   60, 3895, 1426,  466,  425, 3951,
            4,  268,   36,  118,   39,   18, 1675, 1630,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1673,  363,   82,  485, 5842,   49, 1400, 3123,   15, 9356,   15,
           90,  865,  176,  533,  193,  417,  597,   37, 8945,   61, 1193,  636,
          881,  351, 9687, 1701,   51,  443,   59,  729,   48,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298,  178,   36,  302, 9471,  603,  265, 3077,   15,   46,   52,
         5620,  603,  265, 3077,   15,    4,   14,   32, 2771,  272,  123,   46,
           43, 6998,  253, 5620,   49, 7298,    4,   30,  209,   31,  252, 2757,
           46,   16,   52, 2155, 8333,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  376, 5339,  340,    6,   20,  234,    4,   23, 1654,   58, 5339,
         2974, 1634,    4,  161,   41,   39, 6891,    4, 5401,   28,  171, 7084,
            4,  136,   95,  161,   41,   47, 5211,    4, 5401,   28,  171, 7084,
            4,   14,   95,   47,  208,  145,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   14,  924,   20,  489,   49,   38, 3344,  200,    6,  197,
         1333,   45, 2510,   18,   49,  151, 5439,    4,   23,   88, 1400, 2758,
            9,   23,  201, 7842,   46,   60, 1253,  677,  152,   22,   22, 1695,
            4,   60, 1253, 1423,    4,   74,   95,    9, 1253, 1280, 1022,   28,
         1240, 1126, 1582,    5,    1,    1,    1,    1,    1,    1],
        [   2,   64,  255,  406, 4498,  684,    9, 2401,  221,  174,  300, 3948,
            4, 2971,   31,   39,    4,  646, 1926,  797,  399,  290,   16, 2401,
          221,  174,  300,   28, 2705, 2510,   22,    5, 2328, 9177,   61,   23,
         3691, 6996,    4,   14,   47, 1946,   37,  186,  792,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298,  329,   31,   28,  771,  308,    6, 6357,   15,    4,   38,
         5419,  262,   14,  351, 6589,   22,  472,  265,   59,  152,    6,   15,
           18,  480,   15,   40,  137,   64,   31,  915,   31,  354,  306,  617,
            9,  771, 4649,  973,   20,  445,  177, 2668,   15,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1462, 8175, 3650,    4,   90,   31,  196, 2755,   82,    5,  147,
          405, 1774,   28,  791,   20, 5012, 3948,  196,   90, 5961, 4968, 4550,
            9,   23, 2999, 1253, 1214, 1126,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1562,  114,  406, 1667,  836,    4,  255, 4087,   20,   95,   14,
         9678,    4,   95, 4087,   20,  273,  202, 3722, 3956,   16,   95,  814,
           98,   16,  830, 2150,   60, 1400, 4648,    9,   58,  342,  375,  763,
           15,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   81,   30,  130,    4, 1225,    4, 3587,   20, 3864,   60,
          351,  157,    4,  550,    4,   14, 8907,   16, 8129,   48,   27,    4,
         1391,   81,   47,  275,  216,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2')}, 'transcript': {'tokens': tensor([[  19,   73, 7461, 4357, 1224,    5,  138,   63,   53,   42,  370, 2127,
            4,  370, 1507,    4,  370, 3334,   46, 1523, 1878,    5,  276,  629,
         4563,    6,    5, 1995,  510,   15,    4, 4186,   82,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   85,   17,  613,    4,   53,   11,   48,  154,    4,   38, 1824,
            4,   21,   11,    6, 5385,  111,   33,  723,   73,  367,  132,   71,
            7,  839,    4,   21,   11,    6,  143, 2676,   33,  264,  723,  164,
          137,   25,   11,   57,  126,    4,   53,   11,   57,    9,    4,    8,
            7, 1677, 3803, 1944,  100,   17,    5,    2,    1,    1,    1,    1],
        [ 830,    6,   44,  238,    4,   33, 3869,  168,    4,   19,  692,   10,
           87,  250,  133,  946,    4,   13,  946,    4,   19, 1218,  266, 1683,
           12,  248, 7171, 1076,   96, 1696,  616, 1069,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1189,    4,    8,   70,   24,   11,   57,  665,   85,  168,    4,   33,
           26,   56, 1285,   11,    6, 1868,  816, 7447,    4,  166,   26,   13,
         5293, 9373,   12,  267,  572,    4,   29,   19,   11,   45,  204,  665,
           85,  267,  572,   79,   24,  274,   84,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   19,  144,   39,  832, 2545,  338,  240,  824,   18,  366,   12,
         3082,   54,  278,   18, 4406, 6346,  122,    4,    8,   21,   34,   33,
           44,   17,   19,   34,   85,   13, 3221,  292,  556,    6,    9,   89,
          282,    4,  752,   10, 3265,  629, 1298,    8, 3023,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 347,   73,   11,   18,   21,   51,  501, 1969,   59, 1064,   79,   13,
          422,  378,   11,   42,   38, 3837,    4,   33,   34,    7,  370,   81,
          148,  169, 1149,  456,   80,  284, 1064,   79,   13, 1470,   81,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  100,    7,  479,   12, 7376,   71,   94,  100,   17,  125,   21,
         2750,   96,   25,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1440, 4115,   34, 8573,  111, 4130,  106,  284, 3928, 8197,  271,   79,
         6148,  176,  533,  176,    4,  728,  128, 1032,  111,    9,    6,  365,
           54,   69,  211,  218, 1440,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  248, 1682,    6,   12,  269,  484,   46,   17,   26,    4,   24,
           66,   13, 8126, 1682,    4,   91,   17,   24,   73, 4437,   46,   53,
          205,   10,    7, 8126,   12, 6817,    4,   19, 2721,   25,   17,   46,
            8,   13,  744, 1682,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 6431,    4, 3642, 1708,    7, 1017,   12,  225,  237,  121,    6,
            4,   26,  142,   10, 5293,   25,   10,  954, 3648,  336,    4,   67,
         1008,    4,  101,   11,    6,   86,  142,   10,  884,   25,   10,  954,
         3648,   17,  101,   73,   11,   18,  150,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  279,   80,   38, 1341,  200,    6,  197,   26,    4,   21,   11,
            6,  172,   80,   13, 1300,  148,   26,  746,   12, 6354,   71,  284,
          561,    9,    7,  179,   46,   71,  284,  886,    6, 1236, 1533,  429,
            4,   71,  284, 1037,    4,  138,  101,   11,    6,  142,   10,    4,
           25,  135,    4,  229,   21,  283,    9,   33,  264, 3594,    5,    2],
        [   8, 1313,   89, 4856,   26,    9,   27,  221,  174,  300,    4,   19,
          487,  415,   45, 2428,   54,  629,   13,  338, 3528,  760,    8,   27,
          221,  174,  300,   46,    7,  248, 1427,   69,    7, 2085,   12,  984,
           17, 1608,   11,   18,   51,  143,  341,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   19,  246,   10,   89,   79,    6,  365,  480,    4,   38,  160,
          879,  153,    7,  218,  596, 6533, 2015, 1197,    6,  137,    8,   19,
          474,  120,   19,   11,   48,  175,   10,   89, 7145,   17,   84,   11,
           48,   51,   13,  325,   12,  596,   84,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  25,  135,    4,   89, 7684,   14,   48,  294,  215,  581,  120,   19,
           34,  277,    4,   67,  284,  570,   55,  886,   20, 3022,  931,   69,
           79,   13, 2319, 4374,  810,    9,    7, 2192,   12,  284,  427,  380,
           93,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,  120,   89, 1970,  552,    4,  101,  169, 2823,    7, 5987,    6,
            4,  101,  169, 2823,    7, 3781,   24,  144,    4,    8,  101,  513,
            8, 5544,  156,   71,  284, 1431,    9,    7, 1598,    6,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   25,   66,   17,    4,  324, 1387, 6674,    6,   71,  218,   94,
            4,  283,   17,   11,    6, 7097,    8, 8714,   54,    4,   25,  192,
           11,   18,  261,  296,  995,  994,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'cluster_tokens': tensor([[38,  6, 33, 28, 56, 11, 37, 85, 37, 11,  4,  9, 11,  4, 94, 11,  4, 94,
         11,  2, 33, 11, 83, 37,  9, 37, 11, 38, 35, 77, 11,  9, 53, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 37, 32, 11, 37, 85, 31, 59, 11, 38, 35, 11, 37, 85, 37, 83, 83,
         37, 94,  6, 85, 37, 37, 37, 32, 11, 37, 85, 37, 50, 83, 37,  2, 94, 85,
         11, 37, 85, 77, 37, 11, 37, 85, 77, 37, 11, 37, 37, 94, 31, 49, 37, 37,
         11, 83, 37, 37, 37, 37],
        [62, 37, 82, 83, 11, 37, 32, 37, 11, 38, 85, 37, 85, 50, 83,  2, 11, 37,
          2, 11, 38, 35, 35, 32, 37, 34, 29, 35, 77, 38, 77, 49, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 11, 37, 50, 38, 85, 77, 59, 37, 37, 11, 37, 85, 38, 35, 85, 37, 38,
         35,  9, 11, 37, 85, 37, 36, 29, 37, 37, 47, 11, 83, 38, 85, 35, 83, 59,
         37, 37, 47, 37, 38, 59, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 38, 85, 38, 38, 66, 35, 35, 38, 35, 77, 37, 49, 49, 31, 35, 35,  2,
         35, 11, 37, 37, 85, 37, 82, 37, 38, 85, 37, 37, 29, 35, 35, 37, 37, 37,
         32, 11, 49, 37, 88, 37, 94, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83,  6, 85, 35, 37, 38, 38, 37, 35, 32, 37, 37, 28, 49, 85, 11, 38, 35,
         11, 37, 85, 37,  4, 38, 50, 85, 83, 16, 37, 37, 32, 37, 37, 28, 38, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 37, 37, 94, 37, 94, 37, 56, 37, 37, 37, 37, 29, 77, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [ 9, 37, 85,  2, 83,  2, 37, 37, 83, 32, 44, 37, 28, 35, 35, 35, 11, 38,
         35,  2, 83, 37, 37, 35, 49, 37, 50, 50,  9, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 34, 23, 37, 37, 79, 35, 11, 37, 85, 11, 38, 85, 37,  9, 23, 11, 50,
         37, 38,  6, 38, 11, 37, 85, 37, 37,  9, 37, 28, 11, 38, 88, 37, 37, 11,
         37, 37, 24, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37,  9, 11, 49, 37, 37, 31, 37, 37, 35, 35, 37, 11, 85, 49, 37, 36, 37,
         37, 49, 56, 37, 11, 37, 59, 11, 38, 85, 37, 83, 49, 37, 88, 37, 37, 49,
         56, 37, 38,  6, 85, 35, 59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 50, 37, 38, 35, 35, 37, 82, 85, 11, 37, 85, 37, 83, 37, 37,  9, 50,
         85, 83, 37, 49, 37, 37,  9, 37, 37, 94, 11, 37, 37, 38, 37, 35,  3, 94,
         11, 37, 37, 94, 11, 37, 38, 85, 37, 49, 37, 11, 37, 59, 11, 49, 37, 49,
         37, 37,  2, 94, 11, 83],
        [37, 37, 37,  9, 85, 37, 53, 35, 35, 35, 11, 38, 31, 38, 35, 35, 49, 37,
         37, 35, 35, 35, 37, 53, 35, 35, 35, 11, 37, 34, 56, 37, 37, 94, 37, 94,
         37,  6, 85, 35, 38, 50, 33, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 38, 88, 37, 37, 37, 37, 35, 35, 11, 38, 35, 35, 77, 37, 50, 56,  2,
         36, 77, 37, 11, 37, 38, 31, 37, 38, 85, 31, 85, 37, 37, 94, 37, 37, 85,
         31, 38, 37, 83, 37, 56, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 59, 11, 37,  9, 38, 31, 50, 24, 83, 37, 38, 85, 50, 11, 37, 37, 94,
         37, 38, 77, 28, 37, 37, 37, 37, 38, 35, 35, 37, 37, 94, 37, 37, 38, 77,
         35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 37,  9, 85, 11, 38, 85, 49, 37, 94, 37, 11, 38, 85, 49, 37, 56,
         38, 85, 11, 37, 38, 85, 37, 38, 35, 37, 37, 56, 37, 37, 38, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 11,  2, 83, 36, 37, 37, 50, 56, 11, 49, 37, 85, 37,  2,
         37, 49, 49, 11, 37, 85, 85, 35, 83, 49, 50, 50, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:2'), 'lengths': tensor([35, 56, 34, 45, 47, 37, 17, 32, 42, 45, 60, 45, 45, 39, 36, 32],
       device='cuda:2'), 'ntokens': 647}, 'target': tensor([[  72,  145,   14,   13, 8413, 2089,  410, 3010,    5,  400,  208,   43,
           98,   42,   92, 1783,  242, 3476,    4, 5529, 1687,    4, 5529, 3346,
            5,  312, 2864,   59, 2190,    5, 1414,  646, 1214,  712, 4216,   15,
            5, 1935,  588,   44, 8816,    5, 1458,  483,  920,   44,  757,    4,
           30, 1640, 1343, 4527,   16,  414, 2512,  239,    5,    2],
        [  41,  604,  189, 1746,   44,   38, 2579,    6,   20, 1024,  145,   30,
          757, 1246,   47,   61,   18, 5976,    5,  146,  585, 1024,  258, 4819,
          433,  857,   41,   76, 2730,    4,   14,  615, 2149,   16,   29, 4063,
           14, 3076, 1576,  463,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 349,  360,   44,  298,    4,  299,  773,  173,    4,   31,  788,  190,
          167, 5700,   96,  260,   40, 2486,    6,    4,   19, 1707,  481,    6,
          590, 1679,  302,   37,   75,  112, 4307, 1454, 6134,  891,   15,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  173,  208,   32, 3828,    6, 6132,  706,  586,    4,   23, 1846,
          253,  696, 1908,    5,   72, 9849,  361,  113,  355,  696,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   31,  280,  118, 5297, 2361, 2556,   15,    4,   90,   31, 1673,
         4406,  437,  372, 1265, 4742,   20,    4,   16, 2012,   82,   31,   39,
          151,  437,   20, 1515, 1689,    9,  771,  314,   16,   31, 3452,    4,
          163,  646, 1351,   16, 3068,   28, 3617,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1135,  145,   36,   47,  501,  458,  881, 1940,   90, 1937,   11,  186,
           42,   38, 2195,   82,   23, 1783,  242,  919,    4,   23,   12,   18,
          112,  405, 1940,   90, 3329,   59,  919, 3251,  153,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 1627,   14, 2144,    4,   60, 3895, 1426,  466,  425, 3951,    4,
          268,   36,  118,   39,   18, 1675, 1630,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1673,  363,   82,  485, 5842,   49, 1400, 3123,   15, 9356,   15,   90,
          865,  176,  533,  193,  417,  597,   37, 8945,   61, 1193,  636,  881,
          351, 9687, 1701,   51,  443,   59,  729,   48,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298,  178,   36,  302, 9471,  603,  265, 3077,   15,   46,   52, 5620,
          603,  265, 3077,   15,    4,   14,   32, 2771,  272,  123,   46,   43,
         6998,  253, 5620,   49, 7298,    4,   30,  209,   31,  252, 2757,   46,
           16,   52, 2155, 8333,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 376, 5339,  340,    6,   20,  234,    4,   23, 1654,   58, 5339, 2974,
         1634,    4,  161,   41,   39, 6891,    4, 5401,   28,  171, 7084,    4,
          136,   95,  161,   41,   47, 5211,    4, 5401,   28,  171, 7084,    4,
           14,   95,   47,  208,  145,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   14,  924,   20,  489,   49,   38, 3344,  200,    6,  197, 1333,
           45, 2510,   18,   49,  151, 5439,    4,   23,   88, 1400, 2758,    9,
           23,  201, 7842,   46,   60, 1253,  677,  152,   22,   22, 1695,    4,
           60, 1253, 1423,    4,   74,   95,    9, 1253, 1280, 1022,   28, 1240,
         1126, 1582,    5,    2,    1,    1,    1,    1,    1,    1],
        [  64,  255,  406, 4498,  684,    9, 2401,  221,  174,  300, 3948,    4,
         2971,   31,   39,    4,  646, 1926,  797,  399,  290,   16, 2401,  221,
          174,  300,   28, 2705, 2510,   22,    5, 2328, 9177,   61,   23, 3691,
         6996,    4,   14,   47, 1946,   37,  186,  792,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298,  329,   31,   28,  771,  308,    6, 6357,   15,    4,   38, 5419,
          262,   14,  351, 6589,   22,  472,  265,   59,  152,    6,   15,   18,
          480,   15,   40,  137,   64,   31,  915,   31,  354,  306,  617,    9,
          771, 4649,  973,   20,  445,  177, 2668,   15,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1462, 8175, 3650,    4,   90,   31,  196, 2755,   82,    5,  147,  405,
         1774,   28,  791,   20, 5012, 3948,  196,   90, 5961, 4968, 4550,    9,
           23, 2999, 1253, 1214, 1126,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1562,  114,  406, 1667,  836,    4,  255, 4087,   20,   95,   14, 9678,
            4,   95, 4087,   20,  273,  202, 3722, 3956,   16,   95,  814,   98,
           16,  830, 2150,   60, 1400, 4648,    9,   58,  342,  375,  763,   15,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 222,   81,   30,  130,    4, 1225,    4, 3587,   20, 3864,   60,  351,
          157,    4,  550,    4,   14, 8907,   16, 8129,   48,   27,    4, 1391,
           81,   47,  275,  216,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'target_lengths': tensor([58, 42, 37, 24, 45, 35, 21, 34, 42, 43, 52, 46, 46, 31, 38, 30],
       device='cuda:2'), 'ntokens': 624, 'nsentences': 16}
##################### {'id': tensor([101031,  98098,  84148, 162010,  59887, 191995, 170696, 194444,  32719,
        163591, 166509,  39073,  84244, 197008, 188815, 174528, 212222, 214532,
        209730, 152231,  56857, 207087, 125913,  96770, 146495,  90600,  77882,
          8304, 179623, 144412, 100497, 213224, 125038, 126893, 160988, 114087,
        200251,  36536,   4696, 109691], device='cuda:6'), 'net_input': {'src_tokens': tensor([[-0.0483, -0.0499, -0.0573,  ...,  0.0236,  0.0185,  0.0092],
        [-0.0011, -0.0012, -0.0014,  ..., -0.0018, -0.0015, -0.0013],
        [ 0.0009,  0.0009,  0.0006,  ..., -0.0032, -0.0003, -0.0015],
        ...,
        [ 0.1003,  0.1449,  0.1562,  ..., -0.0152, -0.0102,  0.0000],
        [ 0.0078,  0.0058,  0.0041,  ...,  0.0174,  0.0128,  0.0000],
        [-0.0155, -0.0201, -0.0265,  ...,  0.0222,  0.0331,  0.0000]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440,
        53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440,
        53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440, 53440,
        53440, 53440, 53440, 53440, 53439, 53439, 53439, 53439, 53439, 53439],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2, 6283,  788,  ...,    1,    1,    1],
        [   2,   64, 3446,  ...,    1,    1,    1],
        [   2, 1394,   82,  ...,    1,    1,    1],
        ...,
        [   2,  301, 1007,  ...,    1,    1,    1],
        [   2,  104,  776,  ...,    1,    1,    1],
        [   2,   64,   30,  ...,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[ 635,   19,  451,  ...,    1,    1,    1],
        [   8,  744,    4,  ...,    1,    1,    1],
        [2483,   34,   17,  ...,    1,    1,    1],
        ...,
        [2066,   44,   87,  ...,    1,    1,    1],
        [  24, 7674,   10,  ...,    1,    1,    1],
        [   8,   17,   11,  ...,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[ 6, 38, 85,  ..., 37, 37, 37],
        [37, 24, 11,  ..., 37, 37, 37],
        [37, 85, 37,  ..., 37, 37, 37],
        ...,
        [38, 82, 85,  ..., 37, 37, 37],
        [38, 83, 37,  ..., 37, 37, 37],
        [37, 37, 85,  ..., 37, 37, 37]], device='cuda:6'), 'lengths': tensor([16, 13, 17, 22, 18, 16, 18, 16, 42, 17, 19, 30, 16, 14, 14, 10, 18, 15,
        18, 16, 15, 15, 17, 17, 13, 22, 22, 20, 11, 18, 19, 18, 18, 23, 18, 13,
        20,  8, 21, 11], device='cuda:6'), 'ntokens': 704}, 'target': tensor([[6283,  788,   31,  ...,    1,    1,    1],
        [  64, 3446,    6,  ...,    1,    1,    1],
        [1394,   82,   30,  ...,    1,    1,    1],
        ...,
        [ 301, 1007,   44,  ...,    1,    1,    1],
        [ 104,  776, 3277,  ...,    1,    1,    1],
        [  64,   30,   27,  ...,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([15, 13, 19, 18, 19, 15, 15, 15, 62, 15, 18, 29, 14, 18, 13, 15, 15, 24,
        23, 22, 18, 16, 22, 14,  9, 20, 18, 17, 11, 18, 19, 19, 16, 19, 14, 14,
        19, 10, 24,  9], device='cuda:6'), 'ntokens': 723, 'nsentences': 40}
##################### {'id': tensor([222118, 202039,  77628,  35613,  92307,  57526,  77648, 171266],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[-0.0005,  0.0002,  0.0005,  ..., -0.0014, -0.0023, -0.0020],
        [-0.0007, -0.0002,  0.0006,  ..., -0.0056,  0.0057,  0.0029],
        [ 0.1121,  0.1188,  0.1220,  ..., -0.0023, -0.0002,  0.0039],
        ...,
        [-0.0295, -0.0187, -0.0066,  ...,  0.0023,  0.0017,  0.0005],
        [ 0.0043,  0.0044,  0.0056,  ..., -0.0039, -0.0009,  0.0042],
        [ 0.0476,  0.0446,  0.0424,  ...,  0.1339,  0.1209,  0.1332]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([151040, 151040, 151040, 151040, 151040, 151040, 151040, 151040],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,  441, 1787,  332,  145,  153,  621, 2017,   14, 5514,  124, 3383,
         3438,   15,    9,  512,   45, 7329,    4,   58, 1093,    4,   58,   41,
          704, 1293,   90,  981,  351,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72, 7266,  477,    4,   60,  157,   28, 1561,   44,   60,   56,
         8959, 7023,   22,    4, 9450,   35,  885, 1029,   59,  357,    4, 5879,
          187,  918, 2648,    4,  435,  122,  683,   18,  706, 3138,    4, 3229,
          779,  571,  176,  152,  786, 1324,    4,  228,  119, 1021,  436,  234,
           15,    5,    1,    1,    1,    1],
        [   2,   92,   76,   77,   14, 2089,    9, 7067,    4,  258,  646,  151,
           49, 2681,   16,  151,   49,  462, 6722, 4016,   35,  160, 1105, 4555,
           76,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 2609,  145,   31,   14, 5548,  139, 6918,    4,  136,   30,  394,
          275, 2942,    5,  865,    4, 2714,  355,  198,   28,   42,  504,  209,
           31,  547,  582,  343,   72,  514,  478,    4,  258,   14, 5548,   76,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   40, 1389,    4,   23,   47,   98,   23, 8412,  695,
            4,  136,   36,   27,  190,    4,   30,   14, 3269,  257, 9281,  130,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,  471,   52, 1061,  950,   19,  247,  612,   20, 1159,  165,
          210,  151, 1756, 2362, 2896,  978, 2479,    9,  686, 1299,   49, 2350,
            6, 5131, 2054,  129,  808, 4484,   15, 4535,    4, 4875,   23, 2530,
            4,   50,   81, 1210,  497, 6828,   29,  275,   74,   97,  441, 4688,
         5517,    5,    1,    1,    1,    1],
        [   2,  301,  709,   31,  547,    4,   13,  311,  566,    4, 1629, 5818,
          121,   22,  793,    6,   35,  360,   18, 1906, 3908,    4, 1626,   32,
          317,   61,    4,   14,  310,   28, 4558,   42, 2609,   47,    5, 2609,
           47,    4,   32,  309,  203,   18,  292,  879, 1643,   20, 7240,   29,
          414,   32,  123,   98, 4759,    5],
        [   2,  413,  413,  147,  114,   31,  173,  118, 3451, 1263,  653,  459,
           45, 3507,   57,    4,  413,  413,  557,   18,  355,  320,    4,   50,
           31,  163, 2430,  136,  831, 3517,  247,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[  79,   12,   13,  555,  215,  581,    4,  211, 4772,  220,  450,   25,
           70, 7416,    6,  109, 2481, 3438,    6,  618,    9,  155,  637,   46,
          155,  637,    4,    7,  561,   25,  135,  509,  254, 3983,  994,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,   19,  229,   89, 1074,  952,   10,   94,   44,  211, 1368,
         5334, 1997,  706,    6,    4, 5470, 4676,    6,    4, 1072,  290,  551,
           96,    4,  321,   37,  122, 2887, 3540,    4,  906,    6,   12, 1503,
            4, 1764,  502,  571,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 117,   63,   77, 1075,    9, 6687, 1146,  206,  629,   91,    9, 1646,
            4,    8,   91,    9,  391,   12,   77, 5474,    4,   63, 8284,   71,
         3538,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  12,  538,    4,   19,   73, 2937,    7, 2788,    6,    4,   67,   33,
           26,  261, 4454,   37,    5,  230,   42,   25, 2990,    5,   29,  168,
           19,   66,    4,  204,   46,   19,  135, 1456,  206,    7, 2788,    6,
           63,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  17,   26,   13,  613,   17,   26,   86, 1028,  126,  106,    7,  697,
         2158,    4,   67,   21,   11,    6,  250,   17,  172,   13,  140, 1355,
         3471,  187,   62, 3649,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  24,   11,  121,  144, 1061,  439, 2247,    9, 7345, 1086,    9,  333,
          774,   12,  813,  639,   55,    7,  473,  854,   35, 8546,    4, 4580,
            7,  409,   17,   25,   73,  175, 4986,   79,  261,   12,   21,  545,
          464,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,  217,   19, 1211,    4,   38, 1461,    4,  238,    4,  453,
         3560,  369, 5492,    5,  339,   11,    6,  116, 1233, 2644,   54,   94,
          137,   12,  538,   86,    4,   12,  538,   86,    5,   24,  296,   10,
         4220, 2667,   57,   18,  292,  879, 1643, 2840,   79,  261,   79,   24,
           73,    5,    2],
        [ 413,  413,   67,  103,   19,   51,  543,   91,   86,   20,  126, 3761,
            4,  413,  413,   25,   11,  158,  135,   19,   11,   45, 4971,   54,
         5830,   67, 1123,  111,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 37, 37, 50, 24, 83, 11, 50,  9,  6, 88, 37, 50,  9, 37, 37, 28, 32,
         37, 49, 37, 37, 37, 11, 37, 37, 11, 37,  9, 37, 59,  2, 37, 50, 50, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 49, 37, 49, 16, 37, 56, 82, 50, 77, 32, 38, 77, 37, 11,  9,
         32, 37, 11, 24, 35, 69, 77, 11, 38, 77, 35, 77, 56, 11,  9, 37, 37, 13,
         11, 38, 35, 77, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 50, 56, 37, 28, 28, 37, 37, 50, 37, 34, 11, 37, 50, 37, 34, 37,
         50, 56, 11, 85, 31, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 38,  6, 23, 37, 94, 37, 11, 37, 37, 85, 83, 83, 77, 11, 37,
         11, 37, 88, 11, 83, 37, 38, 85, 11, 83, 11, 38, 59, 83, 37, 37, 94, 37,
         85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 32, 37, 85, 83, 49, 37, 37, 37, 38, 77, 11, 37, 37, 85, 37,
         50, 37, 83, 37, 35, 35, 35, 35, 31, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 85, 84, 24, 32, 37, 36, 32, 37, 50, 38, 37, 94, 94, 37, 37,
         37, 53, 38, 24, 11, 37, 37, 32, 37, 37,  6, 85,  4, 37, 83, 37, 37, 50,
         24, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 38, 88, 11, 38, 35, 11, 83, 11,  2, 29, 44, 94, 11, 49, 85,
         37, 83, 29, 49, 49, 56, 11, 37, 83, 83, 11, 37, 83, 83, 11, 38, 49, 37,
         29, 38, 77, 35, 35, 35, 35, 94, 37, 83, 37, 38,  6, 11, 83],
        [11, 11, 37, 37, 38, 38, 66, 50, 83, 77, 37, 83, 11, 11, 11, 37, 85, 35,
         59, 38, 85, 35, 29, 49, 83, 37, 83, 83, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:6'), 'lengths': tensor([37, 43, 27, 39, 30, 39, 51, 30], device='cuda:6'), 'ntokens': 296}, 'target': tensor([[ 441, 1787,  332,  145,  153,  621, 2017,   14, 5514,  124, 3383, 3438,
           15,    9,  512,   45, 7329,    4,   58, 1093,    4,   58,   41,  704,
         1293,   90,  981,  351,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72, 7266,  477,    4,   60,  157,   28, 1561,   44,   60,   56, 8959,
         7023,   22,    4, 9450,   35,  885, 1029,   59,  357,    4, 5879,  187,
          918, 2648,    4,  435,  122,  683,   18,  706, 3138,    4, 3229,  779,
          571,  176,  152,  786, 1324,    4,  228,  119, 1021,  436,  234,   15,
            5,    2,    1,    1,    1,    1],
        [  92,   76,   77,   14, 2089,    9, 7067,    4,  258,  646,  151,   49,
         2681,   16,  151,   49,  462, 6722, 4016,   35,  160, 1105, 4555,   76,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2609,  145,   31,   14, 5548,  139, 6918,    4,  136,   30,  394,  275,
         2942,    5,  865,    4, 2714,  355,  198,   28,   42,  504,  209,   31,
          547,  582,  343,   72,  514,  478,    4,  258,   14, 5548,   76,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   27,   40, 1389,    4,   23,   47,   98,   23, 8412,  695,    4,
          136,   36,   27,  190,    4,   30,   14, 3269,  257, 9281,  130,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,  471,   52, 1061,  950,   19,  247,  612,   20, 1159,  165,  210,
          151, 1756, 2362, 2896,  978, 2479,    9,  686, 1299,   49, 2350,    6,
         5131, 2054,  129,  808, 4484,   15, 4535,    4, 4875,   23, 2530,    4,
           50,   81, 1210,  497, 6828,   29,  275,   74,   97,  441, 4688, 5517,
            5,    2,    1,    1,    1,    1],
        [ 301,  709,   31,  547,    4,   13,  311,  566,    4, 1629, 5818,  121,
           22,  793,    6,   35,  360,   18, 1906, 3908,    4, 1626,   32,  317,
           61,    4,   14,  310,   28, 4558,   42, 2609,   47,    5, 2609,   47,
            4,   32,  309,  203,   18,  292,  879, 1643,   20, 7240,   29,  414,
           32,  123,   98, 4759,    5,    2],
        [ 413,  413,  147,  114,   31,  173,  118, 3451, 1263,  653,  459,   45,
         3507,   57,    4,  413,  413,  557,   18,  355,  320,    4,   50,   31,
          163, 2430,  136,  831, 3517,  247,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([30, 50, 26, 37, 25, 50, 54, 32], device='cuda:6'), 'ntokens': 304, 'nsentences': 8}
##################### {'id': tensor([ 83014, 152609, 138551,  27390,  14565,  10349, 111361, 150528],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[-9.1553e-05, -6.1035e-05, -2.7466e-04,  ...,  7.0190e-04,
          2.1362e-04, -9.1553e-05],
        [-2.0447e-03, -1.4343e-03, -1.0376e-03,  ..., -1.0437e-02,
         -1.1841e-02, -1.3458e-02],
        [-4.5105e-02, -5.8197e-02, -7.0312e-02,  ..., -3.7537e-03,
         -2.6245e-03, -2.0142e-03],
        ...,
        [-1.4697e-01, -1.2427e-01, -1.1127e-01,  ...,  9.3689e-03,
          1.6235e-02,  6.6223e-03],
        [ 1.3123e-03,  6.4087e-04, -1.3428e-03,  ...,  1.2207e-04,
          0.0000e+00,  1.2207e-04],
        [ 2.0752e-03,  2.7771e-03,  3.6926e-03,  ...,  1.1902e-03,
          2.7466e-04,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([164160, 164160, 164160, 164160, 164160, 164160, 164160, 164159],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,  147,   34, 3376,   27,    4,   50, 6939,  343,   16,   14, 5698,
           23,  349,  541, 2061, 3014,  156, 3077,  130,  173,   47,  364, 7351,
          210, 6397,  224,  306,  326,   83,   30,   47, 5754,  343,   14, 3278,
         3441,   16,   14, 1572,   39,  141,  353, 3740,   35, 1180,   20,  494,
         4832,    5,    1,    1,    1,    1,    1,    1],
        [   2,  146, 2999,   98, 1474, 3032,   59,  239,  577, 2050,  588,    4,
           90,  184,  156, 2633,  153, 5163,  232,    9,   52, 8651, 2504, 8922,
            4,   14, 9686,   82, 2717,   16,   40,  702,  345, 4000,   35,  754,
           93,  729,  152,   15, 2074,  174, 1994,   82, 2929,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  209,   40, 3545, 1716, 3113,   16,  118, 8030, 2858,  571,
           16,  145,   36,   98, 2440,   15,    5,   38, 7595, 8581,   95,  139,
          118,  553,  614,   18,  249,    4,   16,   39,  328, 1389,  280,   95,
           52,  863, 1225, 3076,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  377,  212, 3670,  354,   31,  252, 1700, 1306,    4,  823, 2880,
           14, 1264, 2044,   15,   49,  764,   93,   96,  764,  158,   56, 3519,
           44,   38, 7094,  232, 2311,   27,   40,    6,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   74,   32,  216,   16,  216,   52, 4118, 3054,  127,    4,
         7438,   32,    4,   74,  107,  105,  326,  263, 5077,   46,  123,   32,
           60, 1426,    4,   14,   47,   97, 4485,  817,   76,    4, 2717,  466,
          845,   42,   64, 1973, 2030,    5, 5700,   20,  326,   74,  105,  123,
          263,  118,  167, 3276,   15, 2190,  260,    5],
        [   2, 1494,   44, 6804,   18,  316,  198,    4,   40,  542, 1972, 4588,
          195,  544,   28, 2178,   15,   42, 3331,    5,  104,  944,  139,  196,
          216, 1972, 4588,  195,  544,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,  496,   27,    4,   50,   14, 1438,    4,   14,   95, 9540,
            4,   39,  141,   56, 2917, 2208,   15,   16,   56, 9465, 1852, 2521,
         4832,    4,   14, 1926, 2846,   20,   47, 6827,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   76,   52, 1053,  711,    4,   16,  268,   32, 4264, 1770,
            4, 1513,   14,  201,  203,  122,  398,    4, 6492,   32,    4,  107,
           61, 2555,   22,  271, 1693, 1309,  195,  357,   20,   28, 4589,    4,
         1907,  156,  960,  195,   18,   90,  349, 1180,  899,    6,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[  67,   70,   26, 1592,   26,   17, 7033,   46,    8,    7, 6180,   12,
            7, 2551,    6,  620,  307,  188,   22,   11,   18, 4327,   33,  224,
         1771,   12,  214, 2775,   11,   18, 4327,   33,   46, 1201,    8, 1381,
         5427,    6,  106,   13,  321,   12, 4141,   56,   15,  586,   93,    5,
            2,    1,    1,    1,    1],
        [  53,  842,    7, 2192,  106,   17, 4896,    4,   53, 2685,   62,   21,
           79,   13, 1747,  399,   62, 5901,    9,   13,  205,  411,    4,    7,
          909,  122,   22,  221, 1255,  552,   10, 3506,    4,    8,   13,  618,
         2610,   56, 1337, 2536,  870,   34, 2188,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  19,   11,  121,  278,   13,  488, 1472,   12, 1780,    8,   39,    9,
          156, 2705,    8,   19,   11,  158,  229,   21, 7466,    5,   38,  779,
          101, 2770,   13, 7466,  249,   79,  238,    4,    8,    4,   25,  135,
            4,   85,   17,  613,    4,   19,  154,  101,  278,  976,  261,   13,
          976,  324, 1677,    5,    2],
        [  29,    4,   85,   33,  183,    4,   19,   11,   48,  100,   10,  450,
           25,    7, 1289,    9,    6, 2286, 1331,   62, 3840,    7, 1333,   93,
           96, 4468,   10, 1556,   51,  158,    6,   44,   38, 1021, 2403,   26,
           91,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   8,   79,   24,  873,  143,   12,   13,  913, 1484,    4,   24,  446,
          117,  214,  172, 3429,  170,   46,   25,  135,    4,   73,   24,  283,
         7033,   71,   94,  148, 2924,   11,   18,    9,    7,  964,   42,    8,
          214,  100,   17,    5,    8,  946,  214,  100,   33,   73,  172,  229,
           13,  488, 1878,    5,    2],
        [1228,   44,   25,  142,   10,  601,  175,  185, 3020,    6,   42,  324,
            5,   24,  296,  143, 3020,    6,    4,  593,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   7,  524,   26,   17,    7,  889,  850,  284, 1006,   63, 5187,  106,
           39,  811,  140,  668,  609,  829,    8,  384,  726, 3685,  829, 4716,
           17, 3920,  390,  689,   11,   18,  172,  661,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  33,   26,   13,  325,   12,  660,    4,    8,  125,   24,  692,   10,
          446,  126,   38,  200,  715, 3002,    7,  179,  438,   24, 1446,   10,
         2238,   69, 2555,   22,  271,  128, 8182,    6,    4,  109,   38,   18,
           22,  140,    6,  438,   55, 1706,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:7'), 'cluster_tokens': tensor([[37, 50, 85, 49, 85, 37, 83, 11, 37, 37, 94, 37, 37, 29, 37, 77, 77, 85,
         35, 85, 35, 31, 37, 11, 50, 37, 56, 85, 85, 35, 31, 37, 11, 32, 37, 94,
         76, 37, 37, 37, 38, 37, 94, 38, 77, 35, 35, 11, 83, 37, 37, 37, 37],
        [37, 31, 37, 94, 37, 37,  9, 11, 37, 94, 31, 37, 37, 37, 38, 35, 31,  9,
         37, 37, 85, 35, 11, 37, 38, 35, 35, 35, 35, 85, 37, 32, 11, 37, 37, 49,
          9, 38, 35, 35, 35, 85, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 31, 37,  2, 32, 37,  9, 37, 38, 37, 35, 38, 37, 38, 85, 35,
         49, 37, 32, 11, 38, 35, 38, 31, 37, 32, 77, 37, 83, 11, 37, 11, 37, 59,
         11, 37, 37, 32, 11, 38, 59, 38, 31, 83, 83, 37, 83,  2, 94, 11, 83],
        [83, 11, 37, 37, 24, 11, 38, 85, 31, 37, 37, 88, 37, 37, 56, 37, 37, 35,
         43, 31, 37, 37, 38, 35, 77,  9, 37, 35, 38, 35, 37, 82, 38, 35, 94, 85,
         50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 85, 50, 37, 37, 28, 94, 11, 38, 59, 37, 56, 83,  1, 37, 11,
         37, 59, 11,  6, 38, 49, 83, 37, 56, 50, 85, 85, 35, 37, 37,  9, 11, 37,
         56, 37, 37, 11, 37,  2, 56, 37, 37,  6, 83, 49, 37,  2, 33, 11, 83],
        [32, 82, 37, 49, 37, 49, 85, 50,  9, 37, 11,  2, 11, 38, 49, 50,  9, 37,
         11, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 85, 37, 37, 56, 37, 37, 94, 85, 76, 37, 38, 38, 35, 35, 35, 49,
         37, 38, 35, 35, 49, 32, 37, 38, 77, 85, 85, 35, 83, 59, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 37, 56, 11, 37, 37, 38, 85, 37, 59, 37, 38, 35, 35, 56,
         37, 94, 82, 38, 31, 37, 29, 37, 38, 35, 44, 35, 36, 37, 11, 37, 38, 35,
         35, 35, 37, 82, 37,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:7'), 'lengths': tensor([49, 45, 53, 39, 53, 22, 34, 44], device='cuda:7'), 'ntokens': 339}, 'target': tensor([[ 147,   34, 3376,   27,    4,   50, 6939,  343,   16,   14, 5698,   23,
          349,  541, 2061, 3014,  156, 3077,  130,  173,   47,  364, 7351,  210,
         6397,  224,  306,  326,   83,   30,   47, 5754,  343,   14, 3278, 3441,
           16,   14, 1572,   39,  141,  353, 3740,   35, 1180,   20,  494, 4832,
            5,    2,    1,    1,    1,    1,    1,    1],
        [ 146, 2999,   98, 1474, 3032,   59,  239,  577, 2050,  588,    4,   90,
          184,  156, 2633,  153, 5163,  232,    9,   52, 8651, 2504, 8922,    4,
           14, 9686,   82, 2717,   16,   40,  702,  345, 4000,   35,  754,   93,
          729,  152,   15, 2074,  174, 1994,   82, 2929,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  209,   40, 3545, 1716, 3113,   16,  118, 8030, 2858,  571,   16,
          145,   36,   98, 2440,   15,    5,   38, 7595, 8581,   95,  139,  118,
          553,  614,   18,  249,    4,   16,   39,  328, 1389,  280,   95,   52,
          863, 1225, 3076,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 377,  212, 3670,  354,   31,  252, 1700, 1306,    4,  823, 2880,   14,
         1264, 2044,   15,   49,  764,   93,   96,  764,  158,   56, 3519,   44,
           38, 7094,  232, 2311,   27,   40,    6,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   74,   32,  216,   16,  216,   52, 4118, 3054,  127,    4, 7438,
           32,    4,   74,  107,  105,  326,  263, 5077,   46,  123,   32,   60,
         1426,    4,   14,   47,   97, 4485,  817,   76,    4, 2717,  466,  845,
           42,   64, 1973, 2030,    5, 5700,   20,  326,   74,  105,  123,  263,
          118,  167, 3276,   15, 2190,  260,    5,    2],
        [1494,   44, 6804,   18,  316,  198,    4,   40,  542, 1972, 4588,  195,
          544,   28, 2178,   15,   42, 3331,    5,  104,  944,  139,  196,  216,
         1972, 4588,  195,  544,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  92,  496,   27,    4,   50,   14, 1438,    4,   14,   95, 9540,    4,
           39,  141,   56, 2917, 2208,   15,   16,   56, 9465, 1852, 2521, 4832,
            4,   14, 1926, 2846,   20,   47, 6827,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  92,   76,   52, 1053,  711,    4,   16,  268,   32, 4264, 1770,    4,
         1513,   14,  201,  203,  122,  398,    4, 6492,   32,    4,  107,   61,
         2555,   22,  271, 1693, 1309,  195,  357,   20,   28, 4589,    4, 1907,
          156,  960,  195,   18,   90,  349, 1180,  899,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:7'), 'target_lengths': tensor([50, 46, 41, 33, 56, 30, 33, 47], device='cuda:7'), 'ntokens': 336, 'nsentences': 8}
##################### {'id': tensor([207396,  87089,  20502,  11049, 185824, 112624, 194510,  25189],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 2.0905e-02,  1.9348e-02,  1.9012e-02,  ...,  2.1729e-02,
          1.7426e-02,  3.6469e-02],
        [-4.3335e-03, -4.8828e-03, -5.8289e-03,  ...,  6.1035e-05,
          1.2207e-04,  2.4414e-04],
        [-3.7964e-02, -4.4403e-02, -5.1636e-02,  ...,  3.5858e-02,
          2.5757e-02,  1.4923e-02],
        ...,
        [-9.4604e-04, -1.0071e-03, -1.3733e-03,  ..., -2.1973e-03,
         -2.2278e-03, -1.8311e-03],
        [ 2.3712e-02, -1.4343e-03,  1.2451e-02,  ...,  2.1637e-02,
          1.6449e-02,  1.4526e-02],
        [ 6.1035e-05, -2.6245e-03, -4.3030e-03,  ..., -7.3242e-04,
         -6.4087e-04,  3.9062e-03]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([171360, 171360, 171360, 171360, 171360, 171360, 171360, 171360],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2,  396, 1624,  449,   31,   60,  493, 1190, 3080,   93, 1594,    5,
         1135, 1190, 3080,   93,   42,  633,  141,  301, 1147,  372,   49, 1190,
         3080,   93,   28, 4686,  243,  219,   57, 1334, 2506,   18,   23, 5134,
         1285,   37, 2241,  706, 1190, 3080,   93,    4,   74,   81,    9,  328,
         6587,  745,    5,    1,    1,    1,    1],
        [   2,   72, 2669,  198,  799, 5697,   88, 1886,  527,  411,   45, 1089,
         7904,   20,    4,  428,   30,   27,  406, 5048, 4316,    4,  139,  534,
           50,   43, 1210,  627,    4,  114,   43,   39,   14,  599, 6996,  615,
            4,   88,   28,   85,  588,    4,  337, 1509,  219,  951,  444, 1271,
          152,  362, 1322,   98, 2622,   76,    5],
        [   2,  312, 8339,   37, 8403,   49,  655,  382, 4116,  452,   45,   27,
          196,   30, 2819,    4, 8010,   32, 6365,  123,    4,   36,  503,  139,
          392,  642,   29, 2690,  186,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 7001,   36, 3014, 1350,   23,  633,  989,   16,  239,   28,  151,
           51,  200, 2097, 1430,   15, 3692,    4,   16,  141,   23, 5253,  441,
         3215,   82,   14, 7812,  344, 3003,  152,  119,  160,   15,    6,  515,
         8627,    6, 4307,    6,    9,   23, 1022, 1477,   15,  160,   97, 5012,
         1899, 1124,  221,  713,    5,    1,    1],
        [   2,   92,    6,   32,   97, 2167, 2272, 4237,    6, 1320,  649, 2412,
            6, 2776,  330,  606, 1694, 4884,    4,   27,   52, 5860, 2472,   35,
         5142,  240,  390,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  437,  399,  393,    4,   30, 2281,  602,  350, 3728,  357,   97,
         1030, 4901,   60,  216,   90, 3961,  767,  157,    4,   14,   75, 1481,
            4,  403,   43,   58,  623,  112, 3094,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   99,   27, 4582,   38, 1180, 1159,  407,  197,   28,  334,    4,
           90,   38, 5419,  606,    6,   16,  304,   37, 1533,  980,   16,   60,
         3282,  791,  265,    6,  123,   32,  257, 2149, 3528, 1526,   15,    4,
           49,  151,  643,   28,  141, 1022,   28,  151, 6545,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  526,  260,  105, 3644,   14,    6,   47,   98, 1063,   18,  668,
         1660,    5,   41,  260,   14,    6,    4,  268,   43, 1152,    4,   50,
           52, 2747,  353,   23, 2276,   15, 7450,    9, 1474, 1129, 2927, 1364,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[  33,   26,    7, 1361,   19,  100,   10, 3978,   71,  837, 4926,  367,
         1251,    5,  347,  367, 1251,   42,  125,   69,   13, 1823,   12,  367,
         1251,   10,  862, 4778, 1049,    4,    7, 2313, 1793, 5559,    6,  367,
         1251,    4,   79,   25,   73,  150,  106,   33, 5562,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  19,   11,   45,  133, 5891,   80,    7, 1404,   35,  174,   57,  411,
          176,   54, 6814,    6,  125,   19, 1435,  134,    4,   67,  113,    4,
            7,  207,  159,  142,   10,   51, 8425,   26,  333,  183,   53,  367,
           10,    7, 2085,   10,  305,   13, 3200,    4,   53,   11,   57,  142,
           10,    9, 1054,   20,  117, 2108,  372,   18, 1691, 3053,  458,    6,
            5,    2],
        [  13, 3955,   45,  502,   12,  423,   10,  640,    9, 1150,    6,   12,
         2244,    9, 1580, 4266,   26,    7,  772, 1165,   17,   24,   73, 1080,
           55,    4,    8,   21,  220,   51,  392,  825,   17,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   9, 7001,    4,    7,  132, 2003,   54,   36, 4434,  922,  199,   39,
         1266,   62, 3382,    4,    8,   91,   12,    7, 2767, 8261,    6,   34,
            7, 7713,   12,    7, 3003,  608,  160,  589, 4857, 3539,    9,    7,
         3022, 2535, 3594,   12,  728,   22,  160,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,  115,    4,   33,  479,   17,  103,   24,  205, 2027, 1241,    4,
           24,   63, 5333,  262,  510, 3042, 1244, 1410,    4,   33,   26, 1266,
         5693,  551,  948,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1094,  554,    4,    7,  970,   12, 2145,  586,  271,   85, 1335, 1823,
           71,  143,  254, 2703,  759,   94, 6386,  103,   53,   73,  229,   21,
           10,    7,  558,  383,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  21,   11,    6, 4454,   37,   10,  289,   38,   22, 1159,  407,  197,
          254,   38, 5769,  794,    8,   51,   59, 1533,  438,    8,   79,   71,
         2991, 1636,    6,    4,   24,   73,  735, 6271,    9, 4616,    4,  106,
          753,   10,  942,   10, 4380,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 115, 3695,   12,  117, 1881,   63,  401,   33,  126,   12, 1360,  668,
         1144,  224,   53,   11,   57,  401,   21,  125,   53,   11,   57, 1609,
           17,   13, 1905,  321,   12, 4912,   26,    9,  159, 1244,   35, 9524,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 85, 37, 94, 38, 37, 37, 32, 37, 28, 21, 85, 35, 11, 83, 85, 35, 11,
         37, 37, 37, 23, 37, 85, 35, 37, 38, 35, 77, 11, 37, 83, 28, 29, 37, 85,
         35, 11, 37, 37,  6, 59, 37, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 83,  2, 37, 37, 94, 38, 35, 77, 35, 35, 49,  9, 37, 37, 38,
         59, 37, 11, 37, 83, 11, 37, 83, 37, 49, 37, 38, 31, 85, 50, 24, 37, 85,
         37, 37, 94, 37, 49, 37, 49, 11, 37, 85, 77, 49, 37, 37, 35, 77, 37, 38,
         35, 35, 77, 38, 77, 37, 11, 83],
        [37,  9, 35, 35, 37, 34, 37, 34, 37, 77, 37, 37, 29, 37,  9, 23, 85, 37,
         75, 32, 37, 38,  6, 94, 37, 11, 37, 37,  6, 38, 17, 24, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 25, 11, 37, 37, 35, 49, 38, 35, 31, 37, 38,  9, 31,  9, 11, 37, 50,
         37, 37, 75, 32, 37, 85, 37, 94, 37, 37, 38, 75, 35, 35, 28,  9, 37, 37,
         28, 94, 94, 37, 38, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 83, 11, 37, 94, 37, 37, 38, 85,  2, 37, 11, 38, 85,  2, 77, 35, 83,
         32, 35, 11, 37, 85,  9, 35, 69, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 83, 11, 37, 32, 37, 38, 35, 44, 37,  2, 23, 37, 50, 37, 34, 24, 56,
         88, 37, 37,  6, 49, 37, 37, 37, 37, 24, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 77, 37, 88, 38, 35, 77, 35, 82, 37, 38, 35, 35, 37, 38,
         35,  3, 82, 37, 37, 37, 28, 94, 37, 11, 38,  6, 83, 29, 37, 36, 11, 37,
          9, 37, 94, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 50, 37, 37, 56, 85, 49, 37, 37, 37, 37, 35, 32, 11, 37, 85, 77, 49,
         37, 37, 37, 85, 77, 59, 37, 37, 50, 38, 37, 49, 85, 37, 37, 32, 38, 32,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([47, 62, 35, 45, 29, 30, 43, 38], device='cuda:0'), 'ntokens': 329}, 'target': tensor([[ 396, 1624,  449,   31,   60,  493, 1190, 3080,   93, 1594,    5, 1135,
         1190, 3080,   93,   42,  633,  141,  301, 1147,  372,   49, 1190, 3080,
           93,   28, 4686,  243,  219,   57, 1334, 2506,   18,   23, 5134, 1285,
           37, 2241,  706, 1190, 3080,   93,    4,   74,   81,    9,  328, 6587,
          745,    5,    2,    1,    1,    1,    1],
        [  72, 2669,  198,  799, 5697,   88, 1886,  527,  411,   45, 1089, 7904,
           20,    4,  428,   30,   27,  406, 5048, 4316,    4,  139,  534,   50,
           43, 1210,  627,    4,  114,   43,   39,   14,  599, 6996,  615,    4,
           88,   28,   85,  588,    4,  337, 1509,  219,  951,  444, 1271,  152,
          362, 1322,   98, 2622,   76,    5,    2],
        [ 312, 8339,   37, 8403,   49,  655,  382, 4116,  452,   45,   27,  196,
           30, 2819,    4, 8010,   32, 6365,  123,    4,   36,  503,  139,  392,
          642,   29, 2690,  186,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [7001,   36, 3014, 1350,   23,  633,  989,   16,  239,   28,  151,   51,
          200, 2097, 1430,   15, 3692,    4,   16,  141,   23, 5253,  441, 3215,
           82,   14, 7812,  344, 3003,  152,  119,  160,   15,    6,  515, 8627,
            6, 4307,    6,    9,   23, 1022, 1477,   15,  160,   97, 5012, 1899,
         1124,  221,  713,    5,    2,    1,    1],
        [  92,    6,   32,   97, 2167, 2272, 4237,    6, 1320,  649, 2412,    6,
         2776,  330,  606, 1694, 4884,    4,   27,   52, 5860, 2472,   35, 5142,
          240,  390,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 437,  399,  393,    4,   30, 2281,  602,  350, 3728,  357,   97, 1030,
         4901,   60,  216,   90, 3961,  767,  157,    4,   14,   75, 1481,    4,
          403,   43,   58,  623,  112, 3094,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  99,   27, 4582,   38, 1180, 1159,  407,  197,   28,  334,    4,   90,
           38, 5419,  606,    6,   16,  304,   37, 1533,  980,   16,   60, 3282,
          791,  265,    6,  123,   32,  257, 2149, 3528, 1526,   15,    4,   49,
          151,  643,   28,  141, 1022,   28,  151, 6545,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 526,  260,  105, 3644,   14,    6,   47,   98, 1063,   18,  668, 1660,
            5,   41,  260,   14,    6,    4,  268,   43, 1152,    4,   50,   52,
         2747,  353,   23, 2276,   15, 7450,    9, 1474, 1129, 2927, 1364,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([51, 55, 30, 53, 28, 32, 46, 37], device='cuda:0'), 'ntokens': 332, 'nsentences': 8}
##################### {'id': tensor([ 29299,  76916,  47946, 153324, 105943, 152108, 219410],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-6.4697e-02, -1.0498e-01, -1.3049e-01,  ...,  2.2339e-02,
          1.8768e-02,  2.0813e-02],
        [-2.5635e-03, -4.7913e-03, -3.5400e-03,  ..., -3.5400e-03,
         -2.8992e-03, -3.4485e-03],
        [ 3.0823e-03,  5.7983e-03,  5.9509e-03,  ...,  7.5684e-03,
          8.6670e-03,  8.7585e-03],
        ...,
        [ 1.4954e-03,  1.5869e-03,  1.6174e-03,  ..., -6.4087e-04,
         -4.8828e-04, -2.7161e-03],
        [-1.2512e-03,  5.7983e-04,  1.0071e-03,  ...,  2.4414e-04,
          6.1035e-05, -1.7090e-03],
        [-1.1597e-03, -1.6785e-03, -1.7700e-03,  ..., -8.2397e-03,
         -1.1780e-02,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([304320, 304320, 304320, 304320, 304320, 304320, 304319],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2, 4319,    4,   85,  588,   41,  231, 2043,   40,    4,   16,   98,
            5, 3823,    5, 1272,  196,  594,    4,   16,  343, 3905,    4, 3905,
            4, 3905,    4, 3905,    4, 3905,    4, 3905,    4, 3905,    5,   56,
         4142,  649,  549,    5, 3905,    4, 3905,    4, 3905,    4, 3905,    4,
         3905,    4, 3905,    4, 3905,    4, 3905,    5, 3331,    5,  437,  219,
           18,   18, 1194,   41,  512, 3705,   98,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3828, 4694, 2003,   44,  865,    4,  547,    4,   31,  638,   31,
          209, 2053,    4,   30,    9,  151, 5378, 1796, 2416,   15,  750,   31,
           14,  259,  209,  171,  119, 4693,  208,    4,  136,   14,  645,   27,
            4,   34,  855,  501, 3721, 6958,  236,   11,    9,  151, 5778,    4,
            9,  102, 1438, 3409,  202, 1761,   18,  491,   83,   16,  316, 1213,
          480,  398,   61,   52, 3409, 1058, 4497,   32,  119,    4,  114,  316,
         1312,   47, 1697,  936,   37,  119,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   64,   36,   27,   30, 6242,   46,   72,  209,  647,  105, 1280,
          301, 6537,   35, 3176,  881,  894,    4,   14,   41,    9,   23, 2176,
         6569,  208,   46,   16,   31,  209,   28,   23,  259,  196,   47,  184,
           45,   37,  622,    4,   74,  275,  437, 7390,    4,  725,   41,   14,
         1053,   39,  437, 7390,    4,   14,   31,    9,   23,  402, 2594, 1765,
          354,    4,   30,   82, 4073,   74,   40,  437,   45,  756, 2162,    4,
           16,   31, 3878,  163,    9,   23, 1122, 3084,  402, 2594,   74,   40,
          342,  416,  739,    5],
        [   2,  202,  239,  602,  674,   93,    6,    6,   56, 6055,    9, 7971,
         4782,    5,  146, 4194,   83, 2230,  344,  157, 2512,   16,   83,   43,
            9, 1084,  491, 2629,   88,  247, 1304, 1779,    4,   88,   28, 5567,
          403, 1447, 3468,   22,  352, 7281,   15,    4,   14,   81,   61,   14,
         2230,  178,    4, 4102,  236,  124,  831,   76,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 1493,   14, 2803,   49,  102,    4,   34,  217, 8584,  381,   16,
         2078,  683,  381,   27,  193, 1664, 8394,  193,   47, 1378,    5,   68,
          348,   65,  764,   18, 1843,   47,  184, 1934, 1371,   18,    4,  124,
           42,   68,  348,   65, 1038,   27,  406, 1935,   18, 4392,    4, 2640,
           42,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   64,   95,   82,   29, 7900,    4,   50,   95,  405, 5535,   22,
         3797,  812,   39,  424, 1480,    4,   88,  704,   28,  208,    4,   16,
           23, 1264,  236,  480,  577,  181,  614,  176,   47,    4,  113, 1565,
         1350,   95,   30,  312, 6059,  129,  514,   15, 1087,    6,  217, 1659,
           35, 9318,    4,   34,   52, 8249,   23, 1092,  380,   98, 1644, 1688,
          444, 3922,  322,   15,   61, 1972,  680,   35, 4398, 3016,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 1348,    9,   58,  731, 5550,    4,   47,    9,   58, 1889,   59,
         1527,  303, 5550,    4,  519,    9, 1653, 3852,  965,    4,    9,  102,
           95,   75,   61,   58, 1235,  614,  140,  904,   18,   51, 3528,  122,
            4,  319,  405, 1330,  174,  962, 6458,  171,  195,   37,   59,   18,
            4,  764,  237,  174, 1154,  718,  721,   15,    4, 1453,   20,  711,
            4, 1453,   20,  590, 7503,    4, 3425,   20,   60, 2870,    4,   23,
           47,  847,   82,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:5')}, 'transcript': {'tokens': tensor([[1239,    5,   29,    4, 1308,  305,   13, 2027, 3200,    9,    4, 3200,
          126,    5, 1239,    5,  115,    4,   91,  143,  183,    4,    8,   46,
         3763,    4, 3763,    4, 3763,    4, 3763,    4, 3763,    4, 3763,    4,
         3763,    4, 3763,    5,  985,    5, 3763,    4, 3763,    4, 3763,    4,
         3763,    4, 3763,    4, 3763,    4, 3763,    4, 3763,    5, 1239,    5,
         6264,  155, 1860,  126,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  56, 1285, 3065, 2003,   44, 1768,    4,  238,   19,  154,   19, 2096,
           10,   56, 3496, 1040,   33,    9,   13, 4897,    4, 3381,    7, 7339,
         5539,   54,    4,   67,    7,  630,   26,   44,   70,   26, 2108,  675,
           22,   18, 1020,    9,   13, 3317,  206,  889,   66, 1905, 8045,    4,
            8,   25,   11,   57, 8370,   48,   10,   51, 5973,    9,   13, 1905,
          207,  103,   25,  192,   11,   18, 2200,  233, 1835,   42,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  21,   34,  172,    4,  172, 3139,    5,    8,   21,   11,    6,    7,
          245,   46,   19,  144,  116, 4908,  117,  264,  227, 6537,   54, 4372,
           17,   25,  150,    9,   17, 2058,    4,    8,   19,  465,   11,   18,
         2252,   85,   17,  183,   17,    7, 1762,   12, 7889,   54,   19,  169,
           51,  401,    9,    7,   29,  656,   46,   21,  204, 1529,   62,  100,
           13, 1886,  174, 1775,  480,    8,   19,   11,   48,   51,    4,  321,
           12,    4, 2180,    6,  741,   54,    9,    7,   29, 2594,   18,    5,
            2],
        [  33,   26,  250, 1621,  131,    7, 1106,   93,    6,    6, 6142,    9,
         7802,    4,    8,   70,   53,   66,  691,  168,    4,  103,   24,   73,
         1202,    7,  277, 1228,    4,   26,   10,  305, 1247,  106,   39, 2216,
            4, 1393,  134,  199,    7, 1587,   12, 1247,   17,   63, 2082,    9,
            7, 6089,    4,    8, 4962,   70,  169, 1085,  103,   25, 6931,   10,
           33, 4531, 3001, 8310,    6,   10,  150,  103,   53,   63, 7377,  109,
         2426,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 125,  854,    7,  993,   17,   11,    6,    7,  281, 1066,   35,  804,
          122,  122,  810,    8,  179,   35, 4914,   54,   46, 1366, 8394,   46,
           56, 2550,    5,   68,  194,   65,  465,   11,   18,  172,  283,  126,
           17,  207,    4,  323,   21,   42,   68,  194,   65,  206,   11,    6,
           89,  728,   18, 2793,    4, 3108,   42,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,  180,  101,  278,   29, 3633,    4,  101, 1932,   69,  284, 7622,
         2653,  125,  101,  692,   10,  150,  509,    4,    8,    7, 4601,  465,
           11,   18, 1202,  755,    4,   29,  101, 1565,   62, 5413,   69,    7,
         1950,  688,    6,   69,    7, 1319,   45,  373, 2158,    4,  875,   54,
           13, 7828,   12, 4417,   48,  106,    7, 2914,  901, 1261,  199,  747,
           35,   57,  779,  675,  793, 1228,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  86,    9,  281, 3885,    4,    8,   86,    9,    7,  909,  603, 1454,
          833,   12, 3885,    4,   67,    9,  333, 1127, 4212,  206,  101,  442,
          185, 7421,   10,    7, 2178, 1327,  904,   18,    4,   17,  284, 3263,
         2808,   34, 9478,   62,    4,  854,   35,   18,  668,  322,    4, 5207,
           35, 2619, 2361,    4, 4658,   35, 2619, 2361,    4, 1183,  388,   85,
           13, 3321,  148, 1359,   11,   18,   84,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:5'), 'cluster_tokens': tensor([[28, 11, 83, 11, 50, 49, 37,  2, 49, 37, 11, 49, 37, 11, 28, 11, 83, 11,
         50, 50, 24, 11, 37, 11,  9, 11,  9, 11,  9, 11,  9, 11,  9, 11,  9, 11,
          9, 11,  9, 11,  2, 11,  9, 11,  9, 11,  9, 11,  9, 11,  9, 11,  9, 11,
          9, 11,  9, 11, 28, 11, 49, 37, 56, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 38, 35, 82, 83, 11, 83, 38, 59, 38, 31, 37, 38, 35, 35, 37, 37,
         37, 32, 11, 59, 37, 94, 49, 49, 11, 37, 37, 94, 85, 82, 50, 85, 38, 35,
         35, 35, 35, 37, 37, 36, 37, 56, 85, 50, 56, 11, 37, 37, 85, 77, 29, 31,
         37, 38, 31, 37, 37, 50, 83, 37, 37, 85, 85, 35, 38, 35, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83, 11, 83,  2, 11, 37, 37, 85, 37, 37, 83, 11, 38, 85, 83, 31,
         37,  2, 38, 35, 49, 56, 37, 37, 59, 37, 37, 28, 11, 37, 38, 85, 85, 35,
         86, 37, 37, 24, 37, 37, 23, 37,  9, 49, 38, 85, 38, 49, 37, 37, 83, 35,
         11, 37, 83, 49, 31, 37, 37, 38, 35, 35, 35, 37, 38, 85, 31, 38, 11, 38,
         37, 11, 38, 37, 35, 49, 37, 37, 83, 77, 35, 11, 83],
        [37, 85, 50, 31, 37, 37, 38, 35, 37, 37, 32, 37, 28, 11, 37, 50, 37, 85,
         31, 37, 11, 37, 38,  6, 49, 37, 50, 32, 11, 85, 37, 49, 56, 37, 38, 28,
         11, 40, 37, 37, 37, 50, 37, 56, 37, 85, 88, 37, 37, 94, 11, 37, 88, 50,
         85, 85, 37, 37, 31, 37, 37, 50, 28, 36, 37, 37, 59, 37, 37, 85,  2, 37,
          2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 53, 37, 32, 37, 85, 37, 37, 75, 47, 38, 35, 35, 35, 35, 37, 94, 38,
         65, 49, 11, 28, 25, 11, 38, 35, 11, 38,  9, 11, 85, 85, 35, 83, 49, 37,
         37, 83, 11, 85, 37, 11, 38,  9, 11, 37, 85, 37, 37, 38, 35, 38, 11, 28,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 31, 83,  2, 11, 38, 40, 37, 37, 29, 32, 37, 38, 85, 37, 59,
          2, 11, 37, 37,  2, 85, 85, 35, 49, 37, 11, 83, 38, 32, 31, 40, 37, 37,
          2,  9, 37, 37, 37, 38, 35, 56, 77, 11, 49, 49, 37,  9, 37, 94, 31, 37,
         37, 38, 35, 94, 37, 30, 38, 77, 35, 35, 35, 32, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 75, 56, 11, 37, 83, 37, 37, 38, 35, 77, 35, 37, 56, 11, 37, 37,
         50, 50, 32, 37, 38, 31, 50, 32, 37, 37, 38, 35, 35, 35, 11, 37, 37, 88,
         32, 85, 29, 31, 11, 53, 38, 35, 35, 35, 11, 32, 38, 35, 31, 11, 94, 38,
         35, 31, 11, 50, 31, 37, 37, 49, 50, 85, 85, 35, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([66, 71, 85, 75, 56, 68, 69], device='cuda:5'), 'ntokens': 490}, 'target': tensor([[4319,    4,   85,  588,   41,  231, 2043,   40,    4,   16,   98,    5,
         3823,    5, 1272,  196,  594,    4,   16,  343, 3905,    4, 3905,    4,
         3905,    4, 3905,    4, 3905,    4, 3905,    4, 3905,    5,   56, 4142,
          649,  549,    5, 3905,    4, 3905,    4, 3905,    4, 3905,    4, 3905,
            4, 3905,    4, 3905,    4, 3905,    5, 3331,    5,  437,  219,   18,
           18, 1194,   41,  512, 3705,   98,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3828, 4694, 2003,   44,  865,    4,  547,    4,   31,  638,   31,  209,
         2053,    4,   30,    9,  151, 5378, 1796, 2416,   15,  750,   31,   14,
          259,  209,  171,  119, 4693,  208,    4,  136,   14,  645,   27,    4,
           34,  855,  501, 3721, 6958,  236,   11,    9,  151, 5778,    4,    9,
          102, 1438, 3409,  202, 1761,   18,  491,   83,   16,  316, 1213,  480,
          398,   61,   52, 3409, 1058, 4497,   32,  119,    4,  114,  316, 1312,
           47, 1697,  936,   37,  119,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  64,   36,   27,   30, 6242,   46,   72,  209,  647,  105, 1280,  301,
         6537,   35, 3176,  881,  894,    4,   14,   41,    9,   23, 2176, 6569,
          208,   46,   16,   31,  209,   28,   23,  259,  196,   47,  184,   45,
           37,  622,    4,   74,  275,  437, 7390,    4,  725,   41,   14, 1053,
           39,  437, 7390,    4,   14,   31,    9,   23,  402, 2594, 1765,  354,
            4,   30,   82, 4073,   74,   40,  437,   45,  756, 2162,    4,   16,
           31, 3878,  163,    9,   23, 1122, 3084,  402, 2594,   74,   40,  342,
          416,  739,    5,    2],
        [ 202,  239,  602,  674,   93,    6,    6,   56, 6055,    9, 7971, 4782,
            5,  146, 4194,   83, 2230,  344,  157, 2512,   16,   83,   43,    9,
         1084,  491, 2629,   88,  247, 1304, 1779,    4,   88,   28, 5567,  403,
         1447, 3468,   22,  352, 7281,   15,    4,   14,   81,   61,   14, 2230,
          178,    4, 4102,  236,  124,  831,   76,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [1493,   14, 2803,   49,  102,    4,   34,  217, 8584,  381,   16, 2078,
          683,  381,   27,  193, 1664, 8394,  193,   47, 1378,    5,   68,  348,
           65,  764,   18, 1843,   47,  184, 1934, 1371,   18,    4,  124,   42,
           68,  348,   65, 1038,   27,  406, 1935,   18, 4392,    4, 2640,   42,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  64,   95,   82,   29, 7900,    4,   50,   95,  405, 5535,   22, 3797,
          812,   39,  424, 1480,    4,   88,  704,   28,  208,    4,   16,   23,
         1264,  236,  480,  577,  181,  614,  176,   47,    4,  113, 1565, 1350,
           95,   30,  312, 6059,  129,  514,   15, 1087,    6,  217, 1659,   35,
         9318,    4,   34,   52, 8249,   23, 1092,  380,   98, 1644, 1688,  444,
         3922,  322,   15,   61, 1972,  680,   35, 4398, 3016,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [1348,    9,   58,  731, 5550,    4,   47,    9,   58, 1889,   59, 1527,
          303, 5550,    4,  519,    9, 1653, 3852,  965,    4,    9,  102,   95,
           75,   61,   58, 1235,  614,  140,  904,   18,   51, 3528,  122,    4,
          319,  405, 1330,  174,  962, 6458,  171,  195,   37,   59,   18,    4,
          764,  237,  174, 1154,  718,  721,   15,    4, 1453,   20,  711,    4,
         1453,   20,  590, 7503,    4, 3425,   20,   60, 2870,    4,   23,   47,
          847,   82,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:5'), 'target_lengths': tensor([68, 79, 88, 57, 49, 71, 76], device='cuda:5'), 'ntokens': 488, 'nsentences': 7}
##################### {'id': tensor([ 28418, 176553, 181982, 217320,  75586, 183664, 116319,  20307, 185980,
         52339, 208468,  84576, 210132,   3634,  81718, 197149, 185007, 168665,
        113478,  12172,  94337,  99384,  88094,  56297], device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 2.1362e-04,  6.1035e-05, -4.5776e-04,  ...,  8.3313e-03,
          1.0620e-02,  1.0468e-02],
        [ 0.0000e+00, -9.1553e-05, -6.1035e-05,  ...,  3.7689e-02,
          4.4250e-02,  4.8889e-02],
        [ 5.7983e-03,  9.9792e-03,  7.3242e-03,  ...,  7.0496e-03,
          8.1177e-03,  5.6152e-03],
        ...,
        [ 3.0518e-05, -6.1035e-05, -1.8311e-04,  ...,  9.1553e-05,
         -2.7466e-04,  0.0000e+00],
        [ 1.0681e-02,  1.2360e-02,  1.2787e-02,  ...,  8.8501e-04,
          0.0000e+00,  0.0000e+00],
        [ 2.5330e-03,  2.5635e-03,  2.0447e-03,  ..., -4.8523e-03,
         -4.9438e-03,  0.0000e+00]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640,
        96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640, 96640,
        96639, 96639, 96639, 96639], device='cuda:4'), 'prev_output_tokens': tensor([[   2, 9310,   82,  ...,    1,    1,    1],
        [   2, 6041, 2794,  ...,    1,    1,    1],
        [   2, 4282, 1626,  ...,    1,    1,    1],
        ...,
        [   2,   41,  604,  ...,    1,    1,    1],
        [   2, 2888,  174,  ...,    1,    1,    1],
        [   2,   41, 3115,  ...,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[ 115, 3761,    4,  ...,    1,    1,    1],
        [  29,   19,  144,  ..., 2182,    5,    2],
        [  29,  185,   94,  ...,    1,    1,    1],
        ...,
        [ 115,    4,   25,  ...,    1,    1,    1],
        [3726, 1732,   44,  ...,    1,    1,    1],
        [  21, 5070,    6,  ...,    1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[83, 83, 11,  ..., 37, 37, 37],
        [83, 38, 85,  ...,  9, 11, 83],
        [83, 50, 56,  ..., 37, 37, 37],
        ...,
        [83, 11, 37,  ..., 37, 37, 37],
        [28, 94, 82,  ..., 37, 37, 37],
        [37,  6, 37,  ..., 37, 37, 37]], device='cuda:4'), 'lengths': tensor([16, 44, 20, 33, 26, 44, 11, 23, 37, 32, 24, 29, 33, 27, 21, 31, 22, 18,
        30, 28, 29, 27, 20, 26], device='cuda:4'), 'ntokens': 651}, 'target': tensor([[9310,   82,  869,  ...,    1,    1,    1],
        [6041, 2794,  113,  ...,    1,    1,    1],
        [4282, 1626,  105,  ...,    1,    1,    1],
        ...,
        [  41,  604,   75,  ...,    1,    1,    1],
        [2888,  174,  784,  ...,    1,    1,    1],
        [  41, 3115,   20,  ...,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([16, 24, 21, 27, 32, 31, 10, 25, 36, 53, 24, 30, 19, 38, 27, 17, 18, 18,
        26, 33, 40, 37, 26, 29], device='cuda:4'), 'ntokens': 657, 'nsentences': 24}
##################### {'id': tensor([133117,  78978, 157407, 183074,  39714], device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 0.0361,  0.0327,  0.0188,  ..., -0.0101, -0.0025,  0.0061],
        [ 0.0322,  0.0455,  0.0648,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0096,  0.0046, -0.0007,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0022, -0.0020, -0.0018,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0184,  0.0222,  0.0204,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([402399, 402240, 402240, 402240, 402239], device='cuda:4'), 'prev_output_tokens': tensor([[   2,  441, 9346,  332,   56, 2133,   31,  163,   61,   23, 3063, 6986,
           16, 2166,  770, 2225,   88,   28,  334,   44,   38,  967, 1620,  756,
           20,  137,  928,  814,   31,  611,  112,    4, 3914,   49,  157,   61,
         3859,   16,   43,    9,   58, 2765,   28, 1764, 1161,  411,  272,   88,
           28,  334,   44,   38, 4122, 4770,  137, 3137,   58,  441, 1632,   15,
           49, 7695,  382,  548,  364, 7873,  646, 6802,   16, 1207, 1358,  119,
         3110,    4,   61,   58, 1271,  152, 1902,   22, 6781,    6,   16,    9,
           58, 1424,  121, 3165,   49, 2359,  287,    4,   60, 3113,   16, 2649,
           20,  571,  193,  485, 1487, 5279,    5],
        [   2,  147,   30, 1690,   27,   36,  275,  463,   28,  537,   16,    4,
          167,   88, 2843,   48,    4,   77,  105, 1468,  129, 1281,    6,   28,
          102, 1824, 1879, 2485,   16,   28, 1166,   52,   28,  352, 6195,   20,
         4553,    9, 1245, 1876,   15,   28,  127,    4,   88, 6452,   28,  186,
            4, 4464,   28, 8029,   22, 1419,    4,   14,  310,   83,    4,   28,
           95, 5752,    4,   47,    9,  631,   30,  223,    6, 1338,  161,    4,
           34,  331,  310, 1889, 3491,   83,    4,  519,    9,  631,   81, 5941,
           96, 1281, 3889,    4,   88,  585, 4464,   61, 8029, 1419,   28,  667,
            5,    1,    1,    1,    1,    1,    1],
        [   2,  147,  924,  449,   31,  263,   23, 5946,   16,  102,  935,  748,
          483,   35, 9896,  701,    4,   50,   14, 3223,  381,  612, 2356,   20,
         4286,   76,    4,   14,   49,  151, 1804,  676,  522,    4,   29,   74,
          212, 4106, 7387,   49, 1134,   59,  156, 4762, 1454,  938,  287,  187,
         1899,    4,  258,   40, 1804,    4, 2742,   74,  210,  141, 7045, 1203,
         2362, 1079,  242,    4,   52, 5935,   98,  203, 1255,  430,  543,   15,
          342, 2356,  243, 2150, 3010,    4,   90,  578,   36,   40, 3545, 1544,
           22, 4732,    4,   28,  151, 7387,  774,   18,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 1572,  280,   52, 9315,    4, 1546,   59, 5043,   16,   52,
         3827, 4922,    4,  136,   43,  406,  153,   44,   38, 2759,   83,  286,
         3734,    6, 6854,   20,    4,   16, 1246,  578,   36, 2707,   20,  235,
            4,   52,   28,   83,  137,  104, 4919,  107, 2752,  212, 2674,    5,
           99,   82,   52, 4078,    4,   58, 8055,  129, 3692,   96,   28, 5077,
           46,   60,   58, 2164,   16,  102, 1131, 1837, 3722,    4,   30,   32,
         9730,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   36,   27, 1821,    4,  114,   41,  594,  903, 2746, 2934,
            4,   74,    4,  114,   81,  112,   14, 6005,   15, 8668,    4,   14,
           32,   90, 8804,   20, 1448,   59,  202,   59,  491, 1302, 2343,    4,
          403,   30,  547, 1815,   27,    4, 8765,  713,    4,   14, 6005,   23,
         4338, 1050,    6,    4,  124,   14,  791, 4128,    6,    4,   14, 2146,
          122, 3518,  249,  343,   34,   32,  112,   43,  320,    4, 4047,   75,
           88,  295,  330,  156, 2362,    6,   15,    4,   16,   47,   88,  669,
         7391,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[ 830,  200,  356,  121,  215,  581,    4,   19,   34,    9,    7, 2291,
         2905,   89, 1187,   10,  289,    4,   38,  187, 1620,  137,  180,   19,
          513,   10, 1520, 4878,   12,   94,   10, 1406,   20,  134,   69,    7,
         2291,   10,  289,    4,   38,  469,   93, 1620,  137,  106,    7, 8785,
            6,   12, 7414,   10,    7, 1832,   12, 5245,    8, 3003,  608,  881,
            4,    7, 5124, 1825,    6,   12, 5712,   10,    7, 1560,  121, 3165,
           12,  846, 1353,    4, 1780,    8, 2264, 1317,   46,   79, 1829,   79,
           17,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  67,    7, 2476,   26,   10,  205,  261, 3143,    8,    4,  133, 5168,
          111,    4,   10, 8747, 1115,   77,   12,   33, 2410,    4,    8,   10,
          780,    8,   51,   39, 4503,  235, 1197, 2604,    9,   77, 2384,    5,
           10,   51,  529,   10, 1661,  387,   20, 4548,   10, 3926, 1532,   17,
           94,   66,    4,   86,  131, 2761,   54,   70,  218,   94,  659,   66,
         3924,  346,  490,    4,   67,  131,  802, 1405,    9, 2410,   10, 1661,
          387,   20, 5966,  264, 4548,   10, 3926, 1532,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  67,    9, 2403,    4,   70,   19,  172,  169,  100,   10, 1945,   10,
            7, 1136,    8,   10,    7, 1956,    6,   12,  824,  424,   26,   17,
            7,  281,  916, 4879,    6,   63,    7, 1649,   17,   63,  204,  442,
          131,   13, 2964,    4,  100,   33, 1284, 4879,  131, 1593,  156, 5200,
          345, 1097,  287,  187, 1899,    4,  206,   13, 2964,  384,  603,    6,
          235,    6,   13,  593,  322, 1203,  426,   35, 3794, 2185,  234,   12,
         8549,   48,  203,  181,   59, 1159,  866, 2028,    4,   79,  103,  101,
          162,   13,  488,   73, 1251,    4,    8, 1073,   13, 4879,  126,   12,
           21,    5,    2],
        [   7, 1381,  144,   13, 3973, 5492,    4,   21,  144,   13, 3666, 5492,
            4,   21,  144,   13, 1880, 5492,    4,   67,   21,  246,    4,   38,
          533,  192,   11,   18,  172,   66,   13, 3802,    6, 5492,    4,    8,
           21,  914,  169,   51,   13,  324,  279,   10,   66,  438,   29,   24,
         1446,   10, 4173, 3793,  199,   33,    4,  125,   21,   26,   39, 2212,
           10, 3429,    7, 5204,   12,    7, 3382,   71,    7,  214,   17,   24,
           87,    4,   71,    7, 2522,   17,   24,   66,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   21,   11,    6,  916,    4,  103,   25,  154,   80,   21,    4,
          138,    4,  120,   24,  154,   80,    7, 5099,    6,   17,   24,  274,
          132,   10,   79, 1057,  226, 5590,  760, 3769,    6,   12,  422, 3128,
          445,   46, 1179,   21,   11,    6, 1777,    4,  877,   20,   20,  430,
            4,    7,  548, 1050, 5099,    4,  109,    7,  659,  484,    4,  109,
         5902,  589,    6,   46,   70,   24,  135,   80,  134,   26,  172,   80,
          159,  417,  140, 2362,    6,  693,    4,   86,   80,  159, 5948,  282,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[62, 35, 77, 35, 24, 83, 11, 38, 85, 37, 37, 94, 49, 37, 32, 37, 88, 11,
         38, 35, 85, 11, 37, 38, 85, 37, 49, 56, 37, 56, 37, 37, 77, 37, 37, 37,
         94, 37, 88, 11, 38, 35, 35, 85, 11, 37, 37,  9, 37, 37, 28, 37, 37, 94,
         37, 28, 37, 38, 75, 77, 11, 37,  9, 35, 37, 37, 28, 37, 37, 38, 35, 35,
         37, 38, 35, 11,  9, 37, 38, 77, 11, 37,  2, 37, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 32, 85, 37, 85, 83, 83, 37, 11, 83,  2, 83, 11, 37, 28, 37, 50,
         37, 37, 32, 11, 37, 37, 88, 37, 38, 38,  9, 35, 77, 94, 37, 50, 56, 11,
         37, 38,  6, 37, 36, 35, 77, 56, 37,  2, 56, 37, 56, 85, 11, 83, 37, 59,
         49, 50, 50, 56,  6, 85, 31, 37, 37, 11, 37, 37, 49, 31, 37, 32, 37, 36,
         35, 77, 28,  2, 56, 37,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 11, 50, 38, 83, 85, 37, 37, 88, 37, 37, 28, 37, 37, 37, 32,
         37, 37, 38, 35, 85, 37, 37, 75,  2,  9, 37, 85, 37, 50, 37, 85, 83, 31,
         37, 37,  9, 11, 37, 37,  2,  9, 37, 38, 35,  9, 77, 81, 35, 35, 35, 11,
         37, 37,  9, 38, 35, 37, 35, 37, 37, 83, 35, 35, 77, 38,  4, 38, 35, 37,
         29, 31, 38, 35, 35, 77, 35, 56, 11, 37, 37, 38, 85, 37,  2,  6, 35, 11,
         37, 85, 37,  9, 37, 37, 37, 11, 83],
        [37, 94, 85, 37,  9, 94, 11, 37, 85, 37, 28, 94, 11, 37, 85, 37, 28, 94,
         11, 37, 37, 88, 11, 38, 35, 85, 85, 35, 83, 85, 37, 16, 37, 94, 11, 37,
         37, 83, 85, 38, 37,  2, 50, 37, 85, 82, 83, 38, 31, 37, 83, 29, 37, 37,
         11, 37, 37, 85, 38, 94, 37,  1, 37, 32, 37, 37,  9, 37, 37, 56, 37, 38,
         85, 11, 37, 37, 56, 37, 38, 85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37,  2, 11, 37, 37, 59, 37, 37, 11, 37, 11, 37, 38, 59, 37,
         37, 94, 37, 37, 38, 59, 37, 37, 37, 49, 85, 38, 35, 35, 37, 37, 28, 49,
         35, 11, 37, 37, 85, 37, 28, 11, 38, 77, 77, 35, 11, 37, 57, 35, 94, 11,
         37, 37,  6, 35, 11, 37, 28, 35, 37, 11, 50, 38, 59, 37, 37, 85, 83, 37,
         37, 38, 35, 35, 37, 56, 11, 83, 37, 37, 83, 32, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:4'), 'lengths': tensor([87, 82, 99, 82, 86], device='cuda:4'), 'ntokens': 436}, 'target': tensor([[ 441, 9346,  332,   56, 2133,   31,  163,   61,   23, 3063, 6986,   16,
         2166,  770, 2225,   88,   28,  334,   44,   38,  967, 1620,  756,   20,
          137,  928,  814,   31,  611,  112,    4, 3914,   49,  157,   61, 3859,
           16,   43,    9,   58, 2765,   28, 1764, 1161,  411,  272,   88,   28,
          334,   44,   38, 4122, 4770,  137, 3137,   58,  441, 1632,   15,   49,
         7695,  382,  548,  364, 7873,  646, 6802,   16, 1207, 1358,  119, 3110,
            4,   61,   58, 1271,  152, 1902,   22, 6781,    6,   16,    9,   58,
         1424,  121, 3165,   49, 2359,  287,    4,   60, 3113,   16, 2649,   20,
          571,  193,  485, 1487, 5279,    5,    2],
        [ 147,   30, 1690,   27,   36,  275,  463,   28,  537,   16,    4,  167,
           88, 2843,   48,    4,   77,  105, 1468,  129, 1281,    6,   28,  102,
         1824, 1879, 2485,   16,   28, 1166,   52,   28,  352, 6195,   20, 4553,
            9, 1245, 1876,   15,   28,  127,    4,   88, 6452,   28,  186,    4,
         4464,   28, 8029,   22, 1419,    4,   14,  310,   83,    4,   28,   95,
         5752,    4,   47,    9,  631,   30,  223,    6, 1338,  161,    4,   34,
          331,  310, 1889, 3491,   83,    4,  519,    9,  631,   81, 5941,   96,
         1281, 3889,    4,   88,  585, 4464,   61, 8029, 1419,   28,  667,    5,
            2,    1,    1,    1,    1,    1,    1],
        [ 147,  924,  449,   31,  263,   23, 5946,   16,  102,  935,  748,  483,
           35, 9896,  701,    4,   50,   14, 3223,  381,  612, 2356,   20, 4286,
           76,    4,   14,   49,  151, 1804,  676,  522,    4,   29,   74,  212,
         4106, 7387,   49, 1134,   59,  156, 4762, 1454,  938,  287,  187, 1899,
            4,  258,   40, 1804,    4, 2742,   74,  210,  141, 7045, 1203, 2362,
         1079,  242,    4,   52, 5935,   98,  203, 1255,  430,  543,   15,  342,
         2356,  243, 2150, 3010,    4,   90,  578,   36,   40, 3545, 1544,   22,
         4732,    4,   28,  151, 7387,  774,   18,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 146, 1572,  280,   52, 9315,    4, 1546,   59, 5043,   16,   52, 3827,
         4922,    4,  136,   43,  406,  153,   44,   38, 2759,   83,  286, 3734,
            6, 6854,   20,    4,   16, 1246,  578,   36, 2707,   20,  235,    4,
           52,   28,   83,  137,  104, 4919,  107, 2752,  212, 2674,    5,   99,
           82,   52, 4078,    4,   58, 8055,  129, 3692,   96,   28, 5077,   46,
           60,   58, 2164,   16,  102, 1131, 1837, 3722,    4,   30,   32, 9730,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  64,   36,   27, 1821,    4,  114,   41,  594,  903, 2746, 2934,    4,
           74,    4,  114,   81,  112,   14, 6005,   15, 8668,    4,   14,   32,
           90, 8804,   20, 1448,   59,  202,   59,  491, 1302, 2343,    4,  403,
           30,  547, 1815,   27,    4, 8765,  713,    4,   14, 6005,   23, 4338,
         1050,    6,    4,  124,   14,  791, 4128,    6,    4,   14, 2146,  122,
         3518,  249,  343,   34,   32,  112,   43,  320,    4, 4047,   75,   88,
          295,  330,  156, 2362,    6,   15,    4,   16,   47,   88,  669, 7391,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([103,  97,  93,  74,  86], device='cuda:4'), 'ntokens': 453, 'nsentences': 5}
##################### {'id': tensor([ 74949,  17833,  62539,   7963, 140920,  13361, 213051, 187561, 177558,
         87344, 125529, 173422,  83867,  39000, 189616, 141409],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 1.3428e-02,  1.4313e-02,  2.6428e-02,  ..., -1.7334e-02,
         -1.4984e-02, -1.3092e-02],
        [-5.6396e-02, -1.4868e-01, -1.9067e-01,  ...,  7.5073e-03,
          6.5002e-03, -2.4414e-04],
        [-3.6621e-04, -6.1035e-05, -1.2207e-04,  ..., -1.9531e-03,
         -1.6174e-03, -1.8921e-03],
        ...,
        [ 1.0284e-02,  1.3245e-02,  1.6144e-02,  ...,  1.2909e-02,
          1.8890e-02,  0.0000e+00],
        [-1.0986e-03, -1.4954e-03, -1.4038e-03,  ...,  1.3733e-03,
          1.8005e-03,  0.0000e+00],
        [ 3.2043e-03, -6.1646e-03, -1.4343e-02,  ..., -6.9031e-02,
         -6.4026e-02,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([147360, 147360, 147360, 147360, 147360, 147360, 147360, 147360, 147360,
        147360, 147359, 147359, 147359, 147359, 147359, 147359],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2,  441,   40,  542,  332,  239,   36,    9, 4686, 1820, 1190,  500,
          901,    4, 9179,    4,  171, 2763,   15,    4,    9,   23, 2855, 1203,
         1792,   28,   56, 3613,    5,   68,  379,   65,   92, 1242,    4,  231,
         5617,  127,  308,  680, 1055,  360,  894,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  674,  806,   44, 6614,   45,   31,   60,   23, 1401,   61, 8206,
          280,    4,  814,   31,    9,   14, 7634,    4,   16, 2279,   40, 1278,
           46,   38, 3855,  200, 4171,   49,  972,  438,   16, 1812, 2350,  112,
           30, 2295,   15,  344, 2910, 3593,    6,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,   41, 1443,   61, 6805,   15, 1096, 8815,    4,  113,   61,  141,
         1208,   15, 4904,    4,   16,   43, 3534,   14, 3388,   23, 5117,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  147, 7881, 1660,  184, 1203,  973,   60, 5856,  122, 2965, 1660,
            4,   14, 2146,   59,   45,  356, 1128,  156,   57, 5279,   22,   16,
           14,  201,   40,  905, 2582,   20,  380,    4,   30,   27, 4681,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  520,   14, 5678, 1332,  195,  902,  543,  522, 3874,   75,    4,
           50,  462, 6545,   23, 1923,  242, 1240,  236,  191,  118, 5398,   15,
         5926,  658,   18, 1795,  318, 3552,  471,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,   31,  317,  334,  145,    4,   38,  592,  235,  153,   56,
         9216,   15,  137,   64,   58, 6193,   49, 1864,   22,  706, 3821,  145,
            5,   72,  638,    4,   32,   83,  231,  433, 1864,   22,  706, 4352,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,  566,    4,  189, 1959,   41,   30, 2281,   23, 5816,   15,
         1476,    6,  200,  569,   15,   28,  208,    4, 5983, 1397, 1731,   90,
         4785,   18, 2325,  411,  481, 9771,    6,  119,  932,  165,   16, 8592,
           35, 1055,  551,   22, 3372,  290,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 1924,  129, 3758,  280,  911,  741, 4830,   29,  306,  285, 8031,
            4,   50,  273, 9183,   15,   95,  243,  315,  530,   18,  319,   16,
           90,   30, 3444,    4, 2607,   75,  273, 1190,   45,   45,  500,  429,
          466,   16, 1744, 2022,   52, 5513, 4348,  978,    5,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  520,   32,   43,  189, 5145,    4,   74,  275,   43, 6590,  681,
            4,   88,  669, 4496, 3030,  678,   37,   49,  177,  392,  332,   28,
         1626,    4,  319,   36,  149, 1536, 3131,   35, 7782,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,   64,  268,   32,  105,  550,  364,  259,  129, 7044,   22, 3105,
         4761,    6, 3292,    4,   28,   23,  259,    4,   90,   14,  685,  200,
         1409,    6, 2208,  119,   57,  656,  491,    9,   14, 2926, 2004,    4,
         1457,   32,    4, 1980,   45,   45,   45,    4,  454,  776,   32,  582,
           97, 3986, 5438, 1959,    5],
        [   2, 3048,  307,    4,  258,   30,  267, 3690,  408, 1807, 4117,    5,
          504,   27,  113,   40, 1092,  234,  756,   60, 1589,  311, 1194,   98,
          102, 5297,  971,  530,    4,  644, 2389, 5876,   16,   60, 1980,  315,
         3637, 3484,   22, 2164,   61,   23, 6965,   22, 8230,    5,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  147,   78,  981,  965,    4,   58,   32,   16,  331,   61, 4858,
           22,    4,  178,   36,  196,  306,  216,    4,   14, 5603, 2189,  127,
            4, 4008,  129, 5675,   22, 1133,    6,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 1235,  649,   15, 1867,   27,   36,  198,  184, 2817,   15,    4,
           60,  337,  579,   15,   28,  701,    4,   50,   32,   28, 5922,  364,
          202, 4183,   49, 4545, 4316,   15,  196,  331, 4163,   40, 5530,  123,
            4,  385,   23, 2265,   78, 3672,   20,  831, 3520,   16,   43, 4952,
         2630, 5421,  123,    5,    1],
        [   2,  228,   58,  542, 4094,    4,   14,   31,  196,  209,    4,  449,
           31, 1489,  112,   58, 1092,  128,  363,  843,    4,    9,  102,   32,
          263,   52, 1053,  260,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,   41,    9,   52, 2218,   35,  124, 1756,  121,   22,  793,
         1283, 8325, 4128,  210, 1177,   15,    4,   14,   60,  102, 5362, 8103,
           27,    4,  127,   41,   61, 2777,  627,  216, 8430,  510, 4985,  421,
          900,   15,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  147,  257,  196, 2376,  405, 3453,   23,  201,   16,  273, 9428,
            4,  550,   37,   90,   56, 9089, 2776, 5935,   28,  208,    4,   16,
           29, 4443,   36,  107, 1164,    4,  107,  355,  263,   96, 2119, 7299,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[  13, 1323,   12,  215,  581,    4,   56, 3496, 1820, 2937,   93,    4,
         9164,    4, 4598, 2871, 2532,   85,  203,  430,    6,    6,    5,   68,
          194,   65,   17,  818,   77,    7, 4478,   63,  142,   10,   51, 2699,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1106,  156,   44,  432,   19, 7448,  126,   12,  670,    4,   19,  513,
           10, 7174,    4,    8,   19, 1157,   13, 1227,   17,  169,   46,   38,
          335,   54,  941,  438,    8,   19,  175,  813,   80,  401,    7, 4400,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  117, 2421,    6,   63, 3140,   62,   69, 3164,    6,   69,    7,
          926,    6,   12,    7, 8932,    6,    4,    8,   53,  274,    9,   69,
            7, 8932,  106, 6533,    4,   51, 1966, 1994, 3140,    6,    4,    8,
           53, 2283,    7, 2569,   12,    7, 4358,    5,    2,    1,    1,    1],
        [  67, 4040, 1144,   77,  187,   62,   71, 4137,  122, 2965, 1144,    4,
           71, 3195,   54,  132,  155, 2185,   20,   20,  121,    6,    8,  961,
            7,  179,   51, 1217,   13,  523,    4,   26,  133, 3315,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  120,    7, 4269,    6,  144,  226, 2937,   62,    4,  391,   35,
         2287,  234,  322,    6,   12,    7,   94,   66, 4269,   48,   71,   13,
         8480, 3158,  959,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   19,   73,  116,  289,    4,   38, 1076,   20, 2614, 1747, 1034,
            8,  719,    7, 1511,   12, 1911,  569,   37,  137,   19,   11,   45,
           79, 2391,   54,   24,   11,  121,   77, 6107, 1911,  569,   37,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   25,   73,    4,   25,   11,   57, 1913,   10,  150,    7,  970,
           12,    7, 5867,  258,  569,    6,   12,   82,    4, 1738,  111, 2134,
           79, 1850,   35,  587,  241, 5188, 3611, 5465,    8, 6146,  816,  572,
         9028,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3928,   33,  464,    4,  427,  741,  424,  233,  204,  144,   29,  294,
         6463,   17,   24, 2711,  126,   12, 2791,    4,    8,  120,   33,  956,
            4,  108, 1237,   12, 6463,  278,  540,    8,  192,  922,  854,   13,
          759, 1086,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8, 1094,    4,  120,   24, 1060,  134,  138,  261,   53,  169, 1703,
           10,  150,    7,  723,  148,   34,  159, 2911,  392,  215,  581, 3657,
          440,    4,   53,  289,  288, 1536, 1086,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  125,   24,  487,   33,  283,  336,    7,  183,   12,    7, 3980,
         6028,    4,  336,    7,  183,  120,   55,   20,  140,  849, 1049,    6,
          162, 1988,  945,    7, 1569,    4,   24,  246,    4, 1980, 2045,   45,
            4,  635,   24,  451,  204,  498,    9,    7, 3980, 8826,    5,    2],
        [2574,  206,   17,  552,  106,   42, 5525,  399,    5,   29,  168,   11,
            6,   13, 5495,   17,  188,  851,  678,   96, 3020,   54,  126,   12,
           21,    6,  906,    4,  211,   87,  458,    8, 1103,   22,  293,  111,
          993,   69,   21,    6,  211,    6,   20,    5,    2,    1,    1,    1],
        [  67,    4,   55,  333, 1165,   17,   24,    8, 1573,  811,  265, 1782,
           84,   63,   29,  294,  143,   17,  164, 3320, 6013,  755,  125,   12,
            7, 3790,  567,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19, 1080,  117, 3302,   66, 3498,  185,   12,    7,  341, 3440,    6,
           24,   73,  305,    9, 4936,   10, 2103,   62, 2384,   10,   51,  529,
           10, 1005,    7, 1402, 2426,   55, 5019,    6,   10,   51,  529,   10,
         2277,   10, 4477,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  67,   70,   19,  692,   10,   87,   34,  305,   13, 1323,   12, 4299,
           17,   19,   66,  859,   10,  116,  456,   80,    7, 4468, 1584,    4,
          166,   26,  321,   12,  206,   24,   11,   57,  172,  401,   13, 3024,
         1762,   12,  283,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   25,  523,   20,  199,   39, 6084,  109, 7957, 2270, 1203, 4128,
           17,   26, 8284,   71,    7, 4747,    4,   25,  164,   51, 1922,  200,
           54,   69, 1953,  181, 1178,  143, 8430, 4188,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8, 1094,    4,  284, 1466,   12,    7,  179,  690,    6, 2120,    4,
            8,  108, 9654,   10,  150,    7, 5149,   79,  970,  982, 2239,   96,
            4,   10,  934,   17,   24,   73,  135,   70,   53,   11,   57,  172,
          826,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'cluster_tokens': tensor([[37, 50, 37, 24, 83, 11, 38, 35, 35, 23, 35, 11, 28, 11, 29, 31, 49, 37,
         38, 35, 37, 37, 11, 38,  9, 11, 37, 88, 50, 37, 56, 85, 49, 37, 38, 49,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 82, 37, 38, 31, 37, 37, 94, 11, 38, 85, 37, 94, 11, 37, 38, 88,
         37,  9, 37, 85, 11, 38, 35, 49, 94, 82, 37, 38, 85, 94, 37, 49, 37, 24,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 37, 85, 94, 31, 37,  9, 37, 37, 37, 94, 37, 37, 37,  9, 37,
         11, 37, 37, 59, 37, 37, 37,  9, 37,  2, 11, 38, 35, 35, 94, 37, 11, 37,
         37, 59, 37, 94, 37, 37, 94, 11, 83, 37, 37, 37],
        [37, 28, 32, 50, 35, 31, 37, 38, 35, 35, 32, 11, 37, 49, 49, 37, 37, 38,
         77, 77, 35, 37, 37, 49, 37, 94, 38, 35, 37, 83, 11, 85, 83,  2, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 94, 37, 85, 85, 23, 31, 11, 34, 38, 35, 35, 35, 37, 37, 37,
         56, 85, 94, 31, 37, 37,  2,  9, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38,  6, 83, 88, 11, 38, 35, 77, 77, 38, 35, 37, 49, 37,  9, 37, 38,
         35, 77, 11, 38, 85, 35, 37, 35, 49, 38, 85, 35, 50, 31, 38, 35, 77, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37,  6, 11, 37, 85, 77, 32, 37, 59, 37, 32, 37, 37,  2, 38, 35, 37,
         37, 53, 11,  2, 83, 31, 37, 38, 38, 35, 35, 35,  9, 94, 37, 28, 35, 47,
         94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 24, 11, 38, 35, 35, 35, 83, 85, 83, 50, 56, 37, 38, 31, 37, 37,
         56, 11, 37, 37, 37, 31, 11, 37, 94, 37, 56, 31, 36, 37, 85, 31, 53, 37,
         24, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 38, 31, 37, 37, 83, 37, 85, 49, 37, 59, 37, 94, 50, 85,
         37, 32, 17, 24, 83, 49, 83, 11, 37, 88, 83, 34, 32, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 31, 37, 49, 37, 37, 24, 37, 37, 28, 10, 11, 37, 37, 24, 37,
         37, 77, 35, 35, 77, 37, 85, 31, 77, 37, 56, 11, 38, 88, 11, 38, 35, 35,
         11,  6, 38, 85, 83, 49, 37, 37, 28, 32, 11, 83],
        [88, 37, 37, 85, 37, 11, 29, 35, 11, 83, 37, 85, 37, 37, 28, 37, 85, 38,
         35, 77,  9, 49, 37, 37, 37, 37,  9, 11, 50, 85, 77, 37, 38, 35, 35, 83,
         32, 37, 37, 37, 50, 37, 77, 11, 83, 37, 37, 37],
        [37, 11, 37, 50, 32, 37, 38, 37, 50, 38, 35, 77, 37, 85, 83, 50, 50, 37,
         85, 29,  2, 37, 37, 37, 37, 32, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 94, 37, 56, 85, 88, 50, 37, 37, 33, 94, 37, 38,  6, 49, 37, 83, 37,
         29, 31, 56, 37, 38,  6, 37, 49, 37,  9,  2, 37,  9, 37, 37, 38,  6, 37,
         49, 37, 16, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 38, 85, 37, 85, 85, 49, 37, 50, 37, 24, 37, 38, 85, 31, 37, 83,
         16, 37, 37,  9, 37, 11, 37, 85, 38, 37, 37, 38, 85, 77, 83, 49, 37,  2,
         23, 37, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83, 77, 37, 38, 28, 37, 28, 38, 35, 35, 37, 85, 31, 37, 37,  9,
         11, 37, 85, 38, 38, 35, 49, 37, 38, 35, 35, 50, 28, 28, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 19, 37, 37, 94, 38, 37, 56, 11, 37, 37, 32, 37, 59, 37,
         56, 37, 32,  2, 23, 77, 11, 37, 88, 37, 38,  6, 59, 50, 37, 85, 77, 83,
         59, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:2'), 'lengths': tensor([38, 38, 45, 36, 29, 37, 39, 40, 33, 48, 45, 29, 41, 41, 34, 39],
       device='cuda:2'), 'ntokens': 612}, 'target': tensor([[ 441,   40,  542,  332,  239,   36,    9, 4686, 1820, 1190,  500,  901,
            4, 9179,    4,  171, 2763,   15,    4,    9,   23, 2855, 1203, 1792,
           28,   56, 3613,    5,   68,  379,   65,   92, 1242,    4,  231, 5617,
          127,  308,  680, 1055,  360,  894,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 674,  806,   44, 6614,   45,   31,   60,   23, 1401,   61, 8206,  280,
            4,  814,   31,    9,   14, 7634,    4,   16, 2279,   40, 1278,   46,
           38, 3855,  200, 4171,   49,  972,  438,   16, 1812, 2350,  112,   30,
         2295,   15,  344, 2910, 3593,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  41, 1443,   61, 6805,   15, 1096, 8815,    4,  113,   61,  141, 1208,
           15, 4904,    4,   16,   43, 3534,   14, 3388,   23, 5117,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 147, 7881, 1660,  184, 1203,  973,   60, 5856,  122, 2965, 1660,    4,
           14, 2146,   59,   45,  356, 1128,  156,   57, 5279,   22,   16,   14,
          201,   40,  905, 2582,   20,  380,    4,   30,   27, 4681,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 520,   14, 5678, 1332,  195,  902,  543,  522, 3874,   75,    4,   50,
          462, 6545,   23, 1923,  242, 1240,  236,  191,  118, 5398,   15, 5926,
          658,   18, 1795,  318, 3552,  471,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,   31,  317,  334,  145,    4,   38,  592,  235,  153,   56, 9216,
           15,  137,   64,   58, 6193,   49, 1864,   22,  706, 3821,  145,    5,
           72,  638,    4,   32,   83,  231,  433, 1864,   22,  706, 4352,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,  566,    4,  189, 1959,   41,   30, 2281,   23, 5816,   15, 1476,
            6,  200,  569,   15,   28,  208,    4, 5983, 1397, 1731,   90, 4785,
           18, 2325,  411,  481, 9771,    6,  119,  932,  165,   16, 8592,   35,
         1055,  551,   22, 3372,  290,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [1924,  129, 3758,  280,  911,  741, 4830,   29,  306,  285, 8031,    4,
           50,  273, 9183,   15,   95,  243,  315,  530,   18,  319,   16,   90,
           30, 3444,    4, 2607,   75,  273, 1190,   45,   45,  500,  429,  466,
           16, 1744, 2022,   52, 5513, 4348,  978,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 520,   32,   43,  189, 5145,    4,   74,  275,   43, 6590,  681,    4,
           88,  669, 4496, 3030,  678,   37,   49,  177,  392,  332,   28, 1626,
            4,  319,   36,  149, 1536, 3131,   35, 7782,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  64,  268,   32,  105,  550,  364,  259,  129, 7044,   22, 3105, 4761,
            6, 3292,    4,   28,   23,  259,    4,   90,   14,  685,  200, 1409,
            6, 2208,  119,   57,  656,  491,    9,   14, 2926, 2004,    4, 1457,
           32,    4, 1980,   45,   45,   45,    4,  454,  776,   32,  582,   97,
         3986, 5438, 1959,    5,    2],
        [3048,  307,    4,  258,   30,  267, 3690,  408, 1807, 4117,    5,  504,
           27,  113,   40, 1092,  234,  756,   60, 1589,  311, 1194,   98,  102,
         5297,  971,  530,    4,  644, 2389, 5876,   16,   60, 1980,  315, 3637,
         3484,   22, 2164,   61,   23, 6965,   22, 8230,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [ 147,   78,  981,  965,    4,   58,   32,   16,  331,   61, 4858,   22,
            4,  178,   36,  196,  306,  216,    4,   14, 5603, 2189,  127,    4,
         4008,  129, 5675,   22, 1133,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [1235,  649,   15, 1867,   27,   36,  198,  184, 2817,   15,    4,   60,
          337,  579,   15,   28,  701,    4,   50,   32,   28, 5922,  364,  202,
         4183,   49, 4545, 4316,   15,  196,  331, 4163,   40, 5530,  123,    4,
          385,   23, 2265,   78, 3672,   20,  831, 3520,   16,   43, 4952, 2630,
         5421,  123,    5,    2,    1],
        [ 228,   58,  542, 4094,    4,   14,   31,  196,  209,    4,  449,   31,
         1489,  112,   58, 1092,  128,  363,  843,    4,    9,  102,   32,  263,
           52, 1053,  260,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,   41,    9,   52, 2218,   35,  124, 1756,  121,   22,  793, 1283,
         8325, 4128,  210, 1177,   15,    4,   14,   60,  102, 5362, 8103,   27,
            4,  127,   41,   61, 2777,  627,  216, 8430,  510, 4985,  421,  900,
           15,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 147,  257,  196, 2376,  405, 3453,   23,  201,   16,  273, 9428,    4,
          550,   37,   90,   56, 9089, 2776, 5935,   28,  208,    4,   16,   29,
         4443,   36,  107, 1164,    4,  107,  355,  263,   96, 2119, 7299,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:2'), 'target_lengths': tensor([44, 44, 24, 36, 32, 37, 43, 45, 34, 53, 46, 32, 52, 29, 39, 37],
       device='cuda:2'), 'ntokens': 627, 'nsentences': 16}
##################### {'id': tensor([ 80536,  88814,  91368,  94396, 147870, 115585, 149572,  35481,  29467,
         73915, 167320, 122383, 102659,  93968,   9705, 136463,   2027, 187372,
        117350,  18460,  71077,  83792,  43725,  76867,  72773,   5165, 129679,
        155459, 162051,   6803, 217648, 116891], device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 2.4414e-04,  1.2207e-04,  5.1880e-04,  ..., -1.8616e-03,
         -1.7090e-03, -1.4343e-03],
        [-3.7842e-03, -2.5024e-03,  6.0730e-03,  ...,  1.6693e-02,
          6.3782e-03,  7.3242e-04],
        [ 2.6947e-02,  2.6886e-02,  2.6581e-02,  ...,  6.1035e-04,
         -1.2512e-03, -1.7090e-03],
        ...,
        [ 7.7393e-02,  8.2458e-02,  8.3008e-02,  ..., -1.0339e-01,
         -1.0486e-01, -1.0596e-01],
        [ 3.3569e-04,  1.2207e-04, -3.0518e-05,  ..., -1.6479e-03,
         -1.4954e-03,  0.0000e+00],
        [-6.1035e-05,  1.8311e-04,  7.3242e-04,  ...,  3.8452e-03,
          3.4180e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080,
        74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080,
        74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080, 74080,
        74079, 74079], device='cuda:1'), 'prev_output_tokens': tensor([[   2,  504,  208,  ...,    1,    1,    1],
        [   2,   64,   14,  ...,    1,    1,    1],
        [   2,  576,  328,  ...,    1,    1,    1],
        ...,
        [   2,  504, 1637,  ...,    1,    1,    1],
        [   2,   72,  209,  ...,    1,    1,    1],
        [   2, 1555, 1627,  ...,    1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[ 168,   24,   66,  ...,    1,    1,    1],
        [   8,    7,  279,  ...,    1,    1,    1],
        [   8,   17,   11,  ...,    1,    1,    1],
        ...,
        [  33,   34,   38,  ...,    1,    1,    1],
        [  19, 1157, 3494,  ...,    1,    1,    1],
        [  19,  506,  100,  ...,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 38, 85,  ..., 37, 37, 37],
        [37, 37, 50,  ..., 37, 37, 37],
        [37, 37, 85,  ..., 37, 37, 37],
        ...,
        [37, 85, 38,  ..., 37, 37, 37],
        [38, 88, 50,  ..., 37, 37, 37],
        [38,  6, 37,  ..., 37, 37, 37]], device='cuda:1'), 'lengths': tensor([17, 21, 21, 23, 19, 28, 21, 26, 32, 29, 29, 26, 23, 26, 24, 21, 17, 23,
        14, 18, 17, 27, 25, 20, 18, 14, 19, 19, 19, 24, 21, 24],
       device='cuda:1'), 'ntokens': 705}, 'target': tensor([[ 504,  208,   32,  ...,    1,    1,    1],
        [  64,   14,  997,  ...,    1,    1,    1],
        [ 576,  328,  734,  ...,    1,    1,    1],
        ...,
        [ 504, 1637, 3663,  ...,    1,    1,    1],
        [  72,  209, 4048,  ...,    1,    1,    1],
        [1555, 1627,   31,  ...,    1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([25, 25, 22, 24, 20, 43, 26, 29, 35, 23, 25, 23, 19, 25, 20, 25, 13, 17,
        17, 13, 20, 31, 18, 23, 19, 19, 15, 20, 19, 31, 24, 23],
       device='cuda:1'), 'ntokens': 731, 'nsentences': 32}
##################### {'id': tensor([ 54884, 115172, 137446, 198054, 131156,  75948, 136085, 200841, 169127,
         99242, 127428, 220696, 129300,  47498, 223938, 219967],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 4.2114e-03,  5.0964e-03,  6.5613e-03,  ..., -2.9907e-03,
         -6.1035e-05,  7.3242e-04],
        [-1.7700e-03, -1.1292e-03,  6.1035e-05,  ...,  1.0681e-03,
         -1.2207e-04,  3.6621e-04],
        [-1.5332e-01, -1.3855e-01, -1.1877e-01,  ...,  3.2654e-03,
         -5.4932e-04,  4.2725e-04],
        ...,
        [ 4.2847e-02,  4.9347e-02,  5.3131e-02,  ...,  5.5542e-03,
          5.9814e-03,  0.0000e+00],
        [-3.0933e-01, -2.8296e-01, -2.4866e-01,  ..., -2.2888e-03,
         -1.5259e-03,  0.0000e+00],
        [-1.7487e-02, -1.9318e-02, -2.0294e-02,  ..., -2.9602e-03,
         -2.9297e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([144640, 144640, 144640, 144640, 144640, 144640, 144640, 144640, 144640,
        144640, 144640, 144640, 144639, 144639, 144639, 144639],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2,   72,  313,  173,    4,   88,  112,   14, 1642,  799,  997,   28,
         1561,    5,  104,   83, 1939, 5643,    4,   50,   32,   14, 1818,   83,
            4,  441, 1632,   35, 3176, 2471,  153,    9, 7166,   28, 4263,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 7366,  646, 5106,  930,  443,  187,   16,  102, 9635,   22,
         4465, 1788,   16,   58, 3356,   22, 2480,   27,   29, 1836,   74,   14,
         7366,  646, 1659,  806,   16,   58, 1270,   16, 1063, 3333,  634,   16,
         2867,   22,   96,  634,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   30, 2832,   20,   31,   78, 1238,  259,    4,   16,  582,
           83,   14, 3068,   16,   14,  157,   75,  863,  897, 5817,    4,   61,
           14, 6841,    4,   14, 4277,   20,  326,   39, 2112,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  396,  435,    4,   14,  617,   46,   12,   18,  845,  262,  617,
           46,  482,  364,  201,  990,    4,  127,  344, 2040,  550, 7353,  186,
            4,  273, 5741,   22, 4088,    4,   43,  127, 4954,   22, 5580,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  222,  310,    9,   23, 1595,   18,  249,  390, 3879,    4,  730,
         1939,   14,    6,   44, 4181,    4,   43,  667,   77,   30,  757,   98,
           16,  260, 5218,   15,    4,   16, 3446,    6,    4,   77,  295, 1958,
           16,  196,   29, 2306,   15, 9773,   15,  615,   28,  448,   16,  516,
          757,   56,  936,  969,    5,    1,    1,    1,    1],
        [   2,   72,  638,  253,  579,   39,   14,   38,  710, 1486,    6,  891,
          373,  980,   74,  880,  152, 1902,   75, 4934,   16,   56, 6199,   22,
            4,   74,   43,   40, 1934, 1371,   15,   16,  189,   56, 7636,   81,
           30, 5434,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41,  130,  163,  182, 1842,  236, 1330, 1358,  311, 1779,   16,
          364, 6575,   20,  329,   43,   44,   38,  748, 1512,   15,   56, 8300,
           20,   31,   52, 3682,  253, 2171,    9,   48,  481,  489,    5, 1186,
           32,  119,  217, 5696, 2581, 1685,   16,  316,   51, 3935,  119,   52,
         2665,   20,  137,    1,    1,    1,    1,    1,    1],
        [   2,  147,   88,   30,  109,  303, 1867,   28,  260,    4,   27,   36,
          167,  766,   28,  725,    4,   74,   30, 1857,   15, 2908, 1035,    4,
           74,   36,   60,  102,  871, 1696,  652,  398,   16,   74,   30,  696,
           60,  102, 1857,   15, 2908,   56, 3935,  500,  797,  398,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 4647, 4859, 2571,  173,  139,   52, 2330,    4,  428, 8855,
          223, 4647, 4859,  130,  611,  210, 6397,    4,   14,   13, 1537,    6,
         3732,  732, 6594,   49, 2265, 9563,   22,   28,   51,  243,  152,   48,
          444,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  871,  784, 4170,  161,   78,  157,    9,  328, 4886,  167, 1467,
            5,   64,  182,  302,  382, 1130,  332, 8299,   81, 4251,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4706, 1158,  240,  507,  340,  356,    4,  704, 1731,   90, 1807,
            5, 1196,  335,    6,    4,  915,   75,  306, 1253, 3614,   15,  437,
          315,  530,  491,    9,  405,   45,   40, 1285,   15, 3363,   97, 1264,
         2044,   15,   18,  234,   45,   97, 1654,   15,  580,  405,    6, 1680,
            6,    9, 1140, 2408, 3574,    4, 5811,   98,    5],
        [   2,  738, 2824, 3034, 1089, 1432,  156, 1753,   27,   23, 2160,    4,
           14, 2031,   28, 8473,    4,   14, 1578,   15, 6971,   15, 1540,   28,
         5840,    4,   88,   41,  892,   39, 5239,   78, 5270,  293, 3104,   28,
          260,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  559,  232,   45, 1068,  900,  329,   44,   38, 2195,  314,  161,
         1821,    4,  114,   32, 9288,    4,  268,   36,   40, 5046,   27,    4,
           50,   32,  112,  107, 2680,  247, 4741,   76,  137,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 9849,  163,  363,   90, 9121,   22,  157,    4,  149,  644,
           58, 6194,   15, 3346,    6,  221, 1619,    4,   16,   31,  705,   47,
            4,   50,   36, 6176,  864,  760, 4278,  784,    6,  178,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  912,  320,    4,   50,   36, 1497,  394,    4,   30, 4850,   28,
         6057,    9, 2255,   45, 4707,   20,   74,   28, 1166,    4,   75,  177,
         8621,   45,   28, 4088,    4,  280,   52,  167,   51,  668,  176,  662,
         6399,   61,  163,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1356,  163,  171, 5050,   18,   14, 9643,   14, 9639,  646,  102,
            4,   34,   32,   61,   23, 2821,  208,   16,  102,    4,   34,  410,
          599,  730,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1')}, 'transcript': {'tokens': tensor([[  19,   11,   45,  168,   10,  456,   80,    7,  558,  488,  279,    4,
          125,   70,   24,   11,   57, 3101,  126,   26,   17,   24,   66,   33,
         4774,   10, 2508, 2576, 2068,   18,  687, 3078,    6,   12,   70,   11,
            6,  142,   69,    9,  475,  183,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [   7, 4719,  629, 2769,  930,  443,  187,    8,    7, 1384, 8341,    8,
            7, 1384, 1224,   26,   79,  488,   79,    7, 4719,  629,    7,  832,
            5,  156,    5,    8,    7,  832,    5,    6,    5,    8, 1339, 3333,
          407,    8,  269,  340,  407,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   33,   26,   70,   19,  474,   55,   13,  535, 2760,   12,  183,
            4,    8,   17,   11,    6,    9,  409,   70, 3023,    8,   94,   66,
         5112,   69,  923,   13,  523,    4,    7, 6949,   17,   87,  999,  214,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7, 4059,   17,  596,    4,  294,   12,  134,  740,  596,    4,   63,
         1057,  440,    4,  164,   91,  383, 4938,  108, 9824,    4, 2103,  108,
         8689,    6,    4,  229,  132,  108, 4823, 3457,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  70, 1148,  120,   94, 1997,    7,  325,  249,   93,   26,    4,   91,
            4,   53, 1744,   77,    7,  839,    8,  205,  199,  384, 1630,  224,
            8,  248,    4,   77,   12,  159, 1431,    8, 1459,   53,   11,  121,
          700, 1618,  446,  134,    8, 7416,  134,   55,  839,    5,    2,    1,
            1,    1,    1],
        [  19,  154,   12,  100,    4, 2575,  373,    4,  100,  138, 6951,    6,
          985,    8,  180,   53, 5424,    4,   53, 5424,    9,    4,    8,  180,
           25, 1387,   17, 6951,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 225, 1742,  110,   39,    9,   48,  300,  380,   18, 6087,    4,    8,
           79, 7935,  445,    4,  225,  246,    4,   38,  412,   45,  240, 2405,
           19,   11,   45, 4313,   13, 2092,   69, 4290, 1261,    4,    8,   25,
           63, 2202,    9,   21,    4,    8,   19,   11,   45, 6815,   54,   25,
          137,    2,    1],
        [  67,   10,   87,   33, 8289,    4,   21,   11,    6,  133,  528,   10,
          661,  138,    7, 3954,  128, 7830, 1429,    4,  138,   21, 2895,    6,
           71,    7,  955,    4,    8,  138,    7,  572, 4477,    6,   71,    7,
         3954,  128, 7830,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,    9,  409,    4, 3432, 2233,  188,   13, 2883,   10,  722,  168,
            4,  125, 3432, 2233, 4579,  188, 6358,   48,   10,  255,   45, 4068,
            7, 9702, 6952,    6,   12, 1402, 5558,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [2395, 3782, 2882,  133, 1623,   55,   94,   71,   33, 4716,    4,    8,
         3465,  432,  248,   10,  785,  215,    4,   25,   14,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7, 1158,  240,  184,  340,  356,    4,  509, 2134,   79,  903,    5,
          987,  335,    6,    4,  101, 2484,   62,  132,  294,   12,  284, 1248,
         5708,    6,    9,   13, 9649,   51,  158,   10, 1556, 2100,   17,  101,
          144,    9,    7,  270,   12,  284, 1318,    9, 1067, 2464, 3574,    4,
         4809,    5,    2],
        [  91, 4514, 1579,  140,  816,   26,   10,  780,   10, 2828,  108,  639,
            4,   10,  203, 4596,  108, 1578, 5445,    6,    4,   29,   79,   10,
          229,  134,  908, 1930,    6,  140, 2021, 2158,   10, 6447, 2041,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1747,  510, 1068,  900,  246,    4,   38, 5203, 1559,  916,  120,   24,
         4214,    4,  125,   21,   11,    6,   13, 1964,   17,   24,   11,  121,
          227,  234, 2323,   62, 1469,  137,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  19, 2807, 1222,   13,  133, 7446,  723,    4,    8,  929,    4,   25,
          135,    4,    7, 7013, 3334,  461,    4,    8,   19,  164,  450,   25,
           44,   19,  192,   11,   18,  703,   84,   11,    6,  995,  291,   22,
         2124,  128,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [4619,   17,   33,   26,   80, 1974,  532,   54,    7,  324,  116,   79,
          261,   79,  752,   10, 8257, 1835,  106,    7,  999,  144,   13,  133,
         2595,   45,   54, 2958,   69,  110,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  10,  110,    4,    7, 8224,  172, 1290,  804, 3245,    6,   33, 9230,
          629,   70,   24,  150,   69,    7, 2085,    8,   70,   11,    6,  142,
           69, 7396,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[38, 85, 35, 37, 37, 16, 37, 37, 37,  2, 50, 11, 37, 50, 38, 85, 77, 59,
         37, 85, 37, 38, 85, 37, 94, 37, 32, 47, 35, 35, 35, 32, 37, 37, 50, 85,
         37, 49, 37, 37,  2, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 33, 37, 38, 35, 35, 35, 37, 37, 31, 28, 37, 37, 31, 56, 85, 37,  2,
         37, 37, 33, 37, 37, 38, 11, 35, 11, 37, 37, 38, 11, 37, 11, 37, 38, 35,
         35, 37, 79, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 50, 38, 31, 37, 37, 83, 23, 37, 24, 11, 37, 37, 85, 37, 37,
         32, 50, 94, 37, 56, 85, 31, 37, 83, 37, 83, 11, 37, 56, 37, 85,  2, 56,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 56, 37, 56, 11, 50, 37, 37, 49, 56, 11, 85, 49, 83, 11, 85, 50, 24,
         49, 37, 94, 11, 29, 37,  9, 37, 11, 49, 37, 37, 94, 23, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 85, 37, 56, 38, 37, 83, 77, 35, 85, 11, 50, 11, 37, 49, 50, 37, 32,
         37, 85, 37, 38, 77, 11, 37, 34, 11, 50, 37, 37, 56, 37, 50, 37, 85, 35,
         50, 31, 59, 37, 37,  9, 37, 37, 32, 11, 83, 37, 37, 37, 37],
        [38, 59, 37, 37, 11, 29, 56, 11, 37, 37,  9, 37,  2, 37, 37, 37, 29, 11,
         37, 29, 37, 11, 37, 37, 37, 83, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 31, 37, 38, 37, 31, 35, 77, 35,  9, 11, 37, 37, 29, 35, 11, 37, 88,
         11, 38, 35, 35, 35, 35, 38, 85, 35, 49, 37, 23, 37, 28, 94, 11, 37, 37,
         85, 59, 37, 37, 11, 37, 38, 85, 35, 23, 49, 37, 11, 83, 37],
        [37, 37, 85, 37, 83, 11, 37, 85, 37, 83,  2, 37, 59, 37, 37, 38, 35,  9,
         56, 11, 37, 37, 36, 37, 37, 37,  9, 11, 37, 37, 37, 47, 16, 37, 37, 37,
         38, 35,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 32, 11, 22, 49, 85, 37, 94, 37, 49, 37, 11, 37, 22, 49,  9, 85,
         49, 31, 37, 38, 35, 49, 37, 94,  9, 37, 37,  9, 56, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [ 2, 94, 85, 83,  2, 37, 56, 37, 37, 32, 11, 37, 83, 37, 34, 37, 34, 24,
         11, 37, 38, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 35, 35, 38, 35, 77, 11,  2, 31, 37, 38, 11, 38, 35, 37, 11, 38,  9,
         31, 37, 50, 37, 37,  2, 94, 37, 37, 37,  2, 38, 35, 37, 35,  9, 37, 38,
         85, 37, 37, 37, 37, 37,  9, 37, 38, 38, 35, 11, 28, 11, 83],
        [50,  2, 38, 35, 35, 85, 37, 88, 37, 29, 37, 94, 11, 37, 38, 35, 37, 28,
         94, 37, 11, 83, 37, 37, 49, 37, 50, 38, 37, 35, 31, 77, 37, 28, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 35, 35, 88, 11, 38, 35, 85,  2, 37, 38, 29, 11, 37, 37, 85, 37,
         37, 32, 37, 38, 85, 35, 38, 35, 35, 31, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 88, 37, 37, 83, 28, 94, 11, 37, 50, 11, 37, 59, 11, 37, 31, 94, 32,
         11, 37, 38, 85, 88, 37, 82, 38, 85, 85, 35, 88, 37, 85, 37, 50, 38, 35,
         35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [59, 37, 37, 85, 37, 38, 77, 49, 37,  2, 83, 37, 83, 37, 49, 37,  9, 37,
         37, 37,  2, 85, 37, 83, 29, 35, 49, 32, 37, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 11, 37, 28, 83, 38, 35, 35, 37, 37, 33, 37, 50, 38, 59, 37, 37,
         94, 37, 50, 85, 37, 49, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:1'), 'lengths': tensor([44, 43, 38, 34, 47, 30, 50, 41, 33, 23, 51, 37, 31, 40, 32, 28],
       device='cuda:1'), 'ntokens': 602}, 'target': tensor([[  72,  313,  173,    4,   88,  112,   14, 1642,  799,  997,   28, 1561,
            5,  104,   83, 1939, 5643,    4,   50,   32,   14, 1818,   83,    4,
          441, 1632,   35, 3176, 2471,  153,    9, 7166,   28, 4263,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146, 7366,  646, 5106,  930,  443,  187,   16,  102, 9635,   22, 4465,
         1788,   16,   58, 3356,   22, 2480,   27,   29, 1836,   74,   14, 7366,
          646, 1659,  806,   16,   58, 1270,   16, 1063, 3333,  634,   16, 2867,
           22,   96,  634,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   30, 2832,   20,   31,   78, 1238,  259,    4,   16,  582,   83,
           14, 3068,   16,   14,  157,   75,  863,  897, 5817,    4,   61,   14,
         6841,    4,   14, 4277,   20,  326,   39, 2112,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 396,  435,    4,   14,  617,   46,   12,   18,  845,  262,  617,   46,
          482,  364,  201,  990,    4,  127,  344, 2040,  550, 7353,  186,    4,
          273, 5741,   22, 4088,    4,   43,  127, 4954,   22, 5580,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 222,  310,    9,   23, 1595,   18,  249,  390, 3879,    4,  730, 1939,
           14,    6,   44, 4181,    4,   43,  667,   77,   30,  757,   98,   16,
          260, 5218,   15,    4,   16, 3446,    6,    4,   77,  295, 1958,   16,
          196,   29, 2306,   15, 9773,   15,  615,   28,  448,   16,  516,  757,
           56,  936,  969,    5,    2,    1,    1,    1,    1],
        [  72,  638,  253,  579,   39,   14,   38,  710, 1486,    6,  891,  373,
          980,   74,  880,  152, 1902,   75, 4934,   16,   56, 6199,   22,    4,
           74,   43,   40, 1934, 1371,   15,   16,  189,   56, 7636,   81,   30,
         5434,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  41,  130,  163,  182, 1842,  236, 1330, 1358,  311, 1779,   16,  364,
         6575,   20,  329,   43,   44,   38,  748, 1512,   15,   56, 8300,   20,
           31,   52, 3682,  253, 2171,    9,   48,  481,  489,    5, 1186,   32,
          119,  217, 5696, 2581, 1685,   16,  316,   51, 3935,  119,   52, 2665,
           20,  137,    2,    1,    1,    1,    1,    1,    1],
        [ 147,   88,   30,  109,  303, 1867,   28,  260,    4,   27,   36,  167,
          766,   28,  725,    4,   74,   30, 1857,   15, 2908, 1035,    4,   74,
           36,   60,  102,  871, 1696,  652,  398,   16,   74,   30,  696,   60,
          102, 1857,   15, 2908,   56, 3935,  500,  797,  398,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146, 4647, 4859, 2571,  173,  139,   52, 2330,    4,  428, 8855,  223,
         4647, 4859,  130,  611,  210, 6397,    4,   14,   13, 1537,    6, 3732,
          732, 6594,   49, 2265, 9563,   22,   28,   51,  243,  152,   48,  444,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 871,  784, 4170,  161,   78,  157,    9,  328, 4886,  167, 1467,    5,
           64,  182,  302,  382, 1130,  332, 8299,   81, 4251,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [4706, 1158,  240,  507,  340,  356,    4,  704, 1731,   90, 1807,    5,
         1196,  335,    6,    4,  915,   75,  306, 1253, 3614,   15,  437,  315,
          530,  491,    9,  405,   45,   40, 1285,   15, 3363,   97, 1264, 2044,
           15,   18,  234,   45,   97, 1654,   15,  580,  405,    6, 1680,    6,
            9, 1140, 2408, 3574,    4, 5811,   98,    5,    2],
        [ 738, 2824, 3034, 1089, 1432,  156, 1753,   27,   23, 2160,    4,   14,
         2031,   28, 8473,    4,   14, 1578,   15, 6971,   15, 1540,   28, 5840,
            4,   88,   41,  892,   39, 5239,   78, 5270,  293, 3104,   28,  260,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 559,  232,   45, 1068,  900,  329,   44,   38, 2195,  314,  161, 1821,
            4,  114,   32, 9288,    4,  268,   36,   40, 5046,   27,    4,   50,
           32,  112,  107, 2680,  247, 4741,   76,  137,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 9849,  163,  363,   90, 9121,   22,  157,    4,  149,  644,   58,
         6194,   15, 3346,    6,  221, 1619,    4,   16,   31,  705,   47,    4,
           50,   36, 6176,  864,  760, 4278,  784,    6,  178,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 912,  320,    4,   50,   36, 1497,  394,    4,   30, 4850,   28, 6057,
            9, 2255,   45, 4707,   20,   74,   28, 1166,    4,   75,  177, 8621,
           45,   28, 4088,    4,  280,   52,  167,   51,  668,  176,  662, 6399,
           61,  163,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1356,  163,  171, 5050,   18,   14, 9643,   14, 9639,  646,  102,    4,
           34,   32,   61,   23, 2821,  208,   16,  102,    4,   34,  410,  599,
          730,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1'), 'target_lengths': tensor([36, 41, 34, 36, 53, 39, 51, 47, 38, 23, 57, 38, 33, 35, 40, 27],
       device='cuda:1'), 'ntokens': 628, 'nsentences': 16}
##################### {'id': tensor([ 88198,  74312, 209385, 121127, 163549, 117335,  68171, 141627, 136408,
         26822,  51649,  26706,  10325, 185924,  63756, 196756, 148331, 188135,
        100782, 124320, 169166, 176996, 104112, 153269, 176520,  54047, 194540,
        122037, 151066,  82844,  21226,  26857,  61419,  74250,  90702,  43230,
        193258, 163937,  38643,  74981], device='cuda:3'), 'net_input': {'src_tokens': tensor([[ 0.0028,  0.0026,  0.0018,  ...,  0.0030,  0.0033,  0.0037],
        [ 0.0093,  0.0009, -0.0056,  ...,  0.0061,  0.0064,  0.0026],
        [-0.0037, -0.0036, -0.0036,  ...,  0.0012,  0.0032,  0.0057],
        ...,
        [ 0.0005,  0.0006,  0.0009,  ...,  0.0005, -0.0003,  0.0000],
        [-0.0050, -0.0053, -0.0052,  ...,  0.0161,  0.0155,  0.0000],
        [ 0.0048,  0.0029,  0.0033,  ..., -0.0035, -0.0004,  0.0000]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880,
        58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880,
        58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880, 58880,
        58880, 58879, 58879, 58879, 58879, 58879, 58879, 58879, 58879, 58879],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,  312,  580,  ..., 7640, 4977,    5],
        [   2,   64,  393,  ...,    1,    1,    1],
        [   2,  342,  960,  ...,    1,    1,    1],
        ...,
        [   2,  441,  423,  ...,    1,    1,    1],
        [   2,   64,   14,  ...,    1,    1,    1],
        [   2, 2480,   60,  ...,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[ 461,   12,  110,  ...,   91,    5,    2],
        [   8,    4,  554,  ...,    1,    1,    1],
        [  67, 4495, 7374,  ...,    1,    1,    1],
        ...,
        [  80,  423,  215,  ...,    1,    1,    1],
        [  21,  689,   11,  ...,    1,    1,    1],
        [1224,   71,  811,  ...,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[32, 37, 37,  ..., 50, 11, 83],
        [37, 11, 83,  ..., 37, 37, 37],
        [37, 83, 94,  ..., 37, 37, 37],
        ...,
        [37, 34, 24,  ..., 37, 37, 37],
        [37, 85, 85,  ..., 37, 37, 37],
        [56, 37, 38,  ..., 37, 37, 37]], device='cuda:3'), 'lengths': tensor([28, 17, 10, 11, 21, 14, 12, 21, 20, 16, 14, 14, 19, 19, 24, 16, 25, 22,
        14, 17, 15, 18, 16, 14, 12, 18, 16, 22, 17, 19, 22, 20, 18, 16, 21, 16,
        18, 16, 22, 19], device='cuda:3'), 'ntokens': 709}, 'target': tensor([[ 312,  580,   49,  ..., 4977,    5,    2],
        [  64,  393, 3355,  ...,    1,    1,    1],
        [ 342,  960,  195,  ...,    1,    1,    1],
        ...,
        [ 441,  423,  332,  ...,    1,    1,    1],
        [  64,   14,  966,  ...,    1,    1,    1],
        [2480,   60, 9317,  ...,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([31, 17, 14, 11, 24, 11, 12, 26, 17, 15, 16, 17, 21, 18, 28, 10, 20, 27,
        19, 21, 14, 16, 16, 15, 12, 17, 14, 20, 15, 19, 17, 20, 25, 14, 17, 13,
        17, 13, 21, 20], device='cuda:3'), 'ntokens': 710, 'nsentences': 40}
##################### {'id': tensor([178199, 148188, 224513,  30640, 103416,  82113,  23760,  36497],
       device='cuda:3'), 'net_input': {'src_tokens': tensor([[-0.0045, -0.0045, -0.0042,  ..., -0.0045, -0.0039, -0.0038],
        [-0.0550, -0.0432, -0.0355,  ...,  0.0010,  0.0000, -0.0013],
        [ 0.0006,  0.0008,  0.0009,  ..., -0.0017, -0.0009, -0.0007],
        ...,
        [ 0.0009,  0.0012,  0.0014,  ...,  0.0307,  0.0234,  0.0065],
        [-0.0052, -0.0052, -0.0060,  ...,  0.0132,  0.0201,  0.0489],
        [ 0.0479,  0.0365,  0.0225,  ...,  0.0209,  0.0239,  0.0384]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([208160, 208160, 208160, 208160, 208160, 208160, 208160, 208160],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,   41,  459,  128, 5278,   47,  648,  669, 1494,   35,  592,  233,
           48, 7609,   40,    4,   43, 2178,  153,  632,   40, 1278,  653,    4,
           43,  459, 3870,  139,   47,    4,   43, 3911,  317,  149,  499,  255,
           16,  190,   49,  805, 7324,  721,   16, 7790, 3112, 1371,  153,   28,
          198,  112,    5,    1],
        [   2,  402,  354,   30, 2818, 1852,  344, 9191,   96,  363,    4,  344,
          421, 5148,  241,  756,  962,    4, 6456, 9191,   96,  107,  196,  216,
          259,  667,    4,   16, 1786, 3386,   14, 1818,    4,   58, 3906,   28,
          171, 3010,   16,  847,  196,  216, 9191,   20,   28,  605,    5,    1,
            1,    1,    1,    1],
        [   2,  840,  263, 2294, 3021,   28,  186,    4,  309,   32,  725,    4,
          258,  560,  105, 2880, 2004,    4,   16,  823,  796,  534,    4,   74,
           32,  702,   16,  107,   51, 1685,  776,    4,   43,   60,   75,  459,
           45, 5246, 1194,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   72, 4687,    4,   50,   23,  734,  805,  590, 3998,  721,   23,
           27,    4,   50,    4,  382,   36,   47,   52,  421,  338, 2224, 5935,
            9,  891,  398,   37, 3300,    9,   23, 1521,  178,    4, 5337,   60,
          507,  381,  477, 1126,  127,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  228, 1787, 1612, 1499,    6, 4216,   15,  123,  441, 2506,    6,
         2950, 1240,  539, 3701,   37,   30,  599,   97,  304, 1040,  795,   16,
           36, 1640,  418,  177,   23, 1442, 4591,  223, 4062, 4088,    4,  644,
          295,  599, 1240,   20,   28, 3645,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  222,   32,  326,   98, 6280,   15,  516,    4,  815,  680,    4,
          817,    4,   50,   32, 1131, 5302,   15,   97,  817, 5984,   27,  361,
          167,  766,    4,  428,   32,  123, 2698, 2305,    4,   47,    9, 1056,
          680,    4,   47,    9, 6256,   45, 1056,  680,    4,  519,    9, 3712,
           45,  815,  680,    5],
        [   2,  966, 3507,    4, 8382,   20,  157,   76,  317,  286, 1821,   15,
         6095,   15,    5,   68,  379,   65,   41,  667, 4203,   15,    6, 1225,
         2367,   35,  920,  620, 8476,  318,    5,   68,  379,   65,   68,  431,
           65,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  612, 1718,  443, 2378,  674,  803,  153,   44,   72, 2279,    6,
           20,   43,   75,  363, 1245,  351, 1748,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[ 225,  465,   11,   18, 1042, 1393,   69,  267, 1228, 5625,    4,  225,
          492, 6953,  126,   13, 1227,    4,  225,  465,   11,   18,  276,  205,
           10, 2544,    4,  225,  116, 2693,  499,    4,    8,  250,   12,  267,
         9656,    8, 2595,   45,  172,   97, 3134,   62, 1584,   10,  110,    5,
            2,    1,    1,    1,    1,    1],
        [   8,   29,  116,    7, 1529,   12, 9095, 1584,    4,    8, 7572,   62,
            4,  475, 9095,    4,  169,  508,  170,  276,  143,  183,    4,  169,
         2156, 1102,  926,    6,  276, 1978,   10, 2551,  126,    7, 3454,    8,
         1914,  276,  143, 9095,  346,    7, 2397,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19,  154,   10,   51, 3584, 2294,  111, 3021,    4,   24,  296,   10,
          661,  206,  251, 1289,   66,  367,  106,    4,    8,   70, 1288,   80,
          138,   24, 7674,   10,  618,    8, 7493,   53,   63,  227,   45, 5246,
          810, 1585,   71,  134,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19, 1873,   17,    7, 1043,   53,   11,   57,   86,   84,   26,   17,
         1325,   24,   66,   13, 3547, 2239,   12,    9,  891,   62, 4518,    9,
          108,  447, 4621,    4, 5911,    6,  164,  175,  755,   71, 8565,    6,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   9,  185, 1224,    4, 8459,  563,  230,    6, 2215,  373,   73, 1516,
          159,  563,    9,    7, 5690, 1025, 3666,  111, 2103,   54,   21,  106,
         1573,    4,    8, 6433,   54,  159,  563,  230,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   8,  115,    4,  103,   24,  213,   10, 4575,  993,    4,  815,   48,
            4,  672,    4,    7,  479,   17,   24,   11,   57, 2839,   54, 1860,
            9,  475,  672, 2882,  172,  528,  125,   24,   73, 1914,    9,    4,
           86,    9, 1056,   48,    4,   86,    9, 7290, 1056,   48,    4,   67,
            9, 4129,  815,   48,    5,    2],
        [2292,   94,   71, 1738,  841,   87,   86,  229,  916, 2232,    6,    5,
           68,  194,   65,   53,  288,  229,  324,  774,   37,  851, 1032,   96,
            5,   68,  194,   65,   68,  386,   65,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1396,  443, 2378, 1950,   44,   19,   11,   45,  142,   10,  339,  267,
         7032, 8420,   10, 1308,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 85, 85, 35, 83, 40, 37, 37, 32, 29, 11, 37, 50, 31, 37, 37,  9, 11,
         37, 85, 85, 35, 83, 85, 37,  9, 11, 37, 83, 31, 83, 11, 37, 50, 37, 37,
          2, 37, 29, 35, 83, 38, 35, 31, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37],
        [37, 83, 83, 37, 49, 37,  9, 37, 11, 37, 49, 31, 11,  2,  9, 11, 85, 88,
         37, 83, 50, 24, 11, 85,  6, 83, 94, 37, 83, 83, 37, 29, 37, 37,  9, 37,
         49, 83, 50,  9, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 59, 37, 38, 83,  2, 83,  2, 11, 38, 49, 37, 59, 37, 50, 56, 85, 85,
         37, 11, 37, 50, 56, 37, 37, 38, 83, 37, 49, 37, 88, 37, 85, 38, 35, 35,
         35, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 86, 37, 37, 32, 37, 85, 77, 83, 37, 85, 37, 24, 38, 85, 37,  2, 23,
         37, 37, 35, 31, 56, 37, 37, 37, 56, 11, 28, 37, 85, 85, 37, 37, 94, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 56, 11,  2,  9, 37, 37, 49, 56,  6, 29, 37,  9, 37, 37,  9, 24,
         28, 83, 29, 49, 37, 37, 50, 11, 37, 49, 49, 37,  9, 37, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 38, 88, 37, 29, 32, 11, 17, 31, 11,  9, 11, 37, 94, 37,
         38, 85, 77, 29, 49, 56, 37,  2,  9, 85, 83,  2, 37, 38,  6, 49, 37, 11,
         83, 37, 17, 31, 11, 83, 37,  2, 17, 31, 11, 37, 37, 83, 17, 31, 11, 83],
        [ 2, 56, 37,  2, 32, 85, 83, 49,  2,  9, 37, 11, 38,  9, 11, 37, 83, 49,
          2, 38, 77, 38,  2, 77, 11, 38,  9, 11, 38, 28, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [32, 35, 77,  2, 82, 38, 85, 35, 49, 37, 49, 37, 88, 37, 37, 50, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:3'), 'lengths': tensor([49, 45, 42, 38, 34, 54, 32, 18], device='cuda:3'), 'ntokens': 312}, 'target': tensor([[  41,  459,  128, 5278,   47,  648,  669, 1494,   35,  592,  233,   48,
         7609,   40,    4,   43, 2178,  153,  632,   40, 1278,  653,    4,   43,
          459, 3870,  139,   47,    4,   43, 3911,  317,  149,  499,  255,   16,
          190,   49,  805, 7324,  721,   16, 7790, 3112, 1371,  153,   28,  198,
          112,    5,    2,    1],
        [ 402,  354,   30, 2818, 1852,  344, 9191,   96,  363,    4,  344,  421,
         5148,  241,  756,  962,    4, 6456, 9191,   96,  107,  196,  216,  259,
          667,    4,   16, 1786, 3386,   14, 1818,    4,   58, 3906,   28,  171,
         3010,   16,  847,  196,  216, 9191,   20,   28,  605,    5,    2,    1,
            1,    1,    1,    1],
        [ 840,  263, 2294, 3021,   28,  186,    4,  309,   32,  725,    4,  258,
          560,  105, 2880, 2004,    4,   16,  823,  796,  534,    4,   74,   32,
          702,   16,  107,   51, 1685,  776,    4,   43,   60,   75,  459,   45,
         5246, 1194,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  72, 4687,    4,   50,   23,  734,  805,  590, 3998,  721,   23,   27,
            4,   50,    4,  382,   36,   47,   52,  421,  338, 2224, 5935,    9,
          891,  398,   37, 3300,    9,   23, 1521,  178,    4, 5337,   60,  507,
          381,  477, 1126,  127,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 228, 1787, 1612, 1499,    6, 4216,   15,  123,  441, 2506,    6, 2950,
         1240,  539, 3701,   37,   30,  599,   97,  304, 1040,  795,   16,   36,
         1640,  418,  177,   23, 1442, 4591,  223, 4062, 4088,    4,  644,  295,
          599, 1240,   20,   28, 3645,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 222,   32,  326,   98, 6280,   15,  516,    4,  815,  680,    4,  817,
            4,   50,   32, 1131, 5302,   15,   97,  817, 5984,   27,  361,  167,
          766,    4,  428,   32,  123, 2698, 2305,    4,   47,    9, 1056,  680,
            4,   47,    9, 6256,   45, 1056,  680,    4,  519,    9, 3712,   45,
          815,  680,    5,    2],
        [ 966, 3507,    4, 8382,   20,  157,   76,  317,  286, 1821,   15, 6095,
           15,    5,   68,  379,   65,   41,  667, 4203,   15,    6, 1225, 2367,
           35,  920,  620, 8476,  318,    5,   68,  379,   65,   68,  431,   65,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 612, 1718,  443, 2378,  674,  803,  153,   44,   72, 2279,    6,   20,
           43,   75,  363, 1245,  351, 1748,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([51, 47, 40, 42, 43, 52, 37, 20], device='cuda:3'), 'ntokens': 332, 'nsentences': 8}
##################### {'id': tensor([ 23484,  41266, 203608,  40927, 214263,  89365,  86251,  41249],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[-0.0452, -0.0538, -0.0520,  ...,  0.0388,  0.0419,  0.0409],
        [-0.0150, -0.0092, -0.0013,  ...,  0.0095, -0.0082, -0.0188],
        [ 0.0021,  0.0025,  0.0034,  ..., -0.0031, -0.0031, -0.0038],
        ...,
        [-0.0011, -0.0009, -0.0008,  ..., -0.0020, -0.0014, -0.0016],
        [ 0.0023,  0.0021,  0.0008,  ...,  0.0095,  0.0112,  0.0104],
        [-0.0016,  0.0037,  0.0062,  ..., -0.0195, -0.0212, -0.0246]],
       device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([196160, 196160, 196160, 196160, 196160, 196160, 196160, 196160],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2, 6041, 9574,    4,   50,   40,   97, 1076,  797, 1547,    6, 2171,
           49, 1664, 3308,   27,    5,  396,  167, 1856,  303,  441, 4362,   15,
            4,   14,   32, 1036,   83,   44, 4016,    9, 1437,    4, 3671,  559,
         1533,  741, 6653, 4177,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1046,  114,   31,  915,    4,   50,   31, 4646,   28, 3217,  354,
            4, 3933,   31,  924,  257,  149, 1238, 1279,  548,    4,  382,   31,
          406,  153,   50,   31, 7535,    4,   34,   95,  334,  354,    4,   16,
          189, 3933,   31,   61,   28,  425, 3217,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 1204,   14, 3279,   15, 4612,  152,  819,  444,   39,    4,
           23,   15,  202, 2342,    6,   37,   47, 4009,   82,    4,   14,   28,
         5343,  319,    4,   88,  377, 4642,   49, 1442,   18,  152, 2435,  165,
           28,  701,  224,   14,   28,  275,   28, 1238,  184,  122, 3475, 1630,
          471,    4,   88,  361,   28,  302,  181, 1194,    5],
        [   2,  298,  685, 1040,    4,   32,  127,   52,  599,  265,  365,  416,
           15,  243,  237, 1170,   98,   23, 1014,  102, 1921,   18,   59,  272,
            5,   68,  379,   65,  504,    4,  615,   41,   39,   14, 8735,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,    4,   31,  638,    5,    5,    5,  104,  471,   52, 1238,
          655,   35, 3723, 9311,  129, 8270,    6,   60,  872, 7163,   22, 4175,
           15,   16,   60, 1640, 3811, 1134,    6,  156,  338,  525, 1347,    4,
           92,   82, 1238,  273,  403,   37,  426, 8810,    5,   99,   27,  257,
          196,  766,    5,    1,    1,    1,    1,    1,    1],
        [   2, 3492,  158,  356,  364, 9319,   22, 1668,   16,   58, 6595,   15,
         2126,  769,   52, 3289,   20, 1668, 2363, 2668,   15,   16,   32,  776,
          273, 5162,   97, 4237, 2157,   74,   14, 9319,   22, 5162,  171, 7941,
           15,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   31,  354, 1700,  467,   15,   60,  151, 3047, 3963, 1105,
           35,  949,   62, 1895,    5,   38, 9206,    4, 2279,    6,  107,   78,
          648, 1958,  186,  224, 2279,    6,  107,   30,  314, 6585,  260,  224,
         2279,    6,  107, 1774, 1499,   16,  507, 4965,   20,  186,  224,   14,
         1062, 1582,   47,  151, 2631, 6238,  137,    1,    1],
        [   2,   64,   36,   82,   52,  799,  997,    9,  493,  953, 4633, 2098,
          160,   18,  472,   93,   96,  612,  271,    9,  228,  352,  687,    9,
         5811,    4,  268,  517,   97, 7061,  149,  761, 8255,  157, 6114,  193,
         3596,  564,  895,  820,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4')}, 'transcript': {'tokens': tensor([[  25,  135,    4,   19,   11,   45, 7602,  131,  138,   91,   12,    7,
           19,  362, 1838,  235,  134,   96,   12, 1366,   26, 2952,    4,  117,
          133, 1944, 8827,    6,   24,   11,  121,  116, 1110,   44, 3538,    9,
         1146,    4, 3398, 1747,  160,  741,  473, 1303,    5,    2,    1,    1,
            1,    1,    1],
        [ 125,   70,   19,  619,   10,   87,    4,  120,   19,  474,   19,   34,
         3976,    4,   34,   19,  169, 2632,  116,  890,   10, 1510,   70,   94,
          144,   10,  289,    8,  154,   17,   19,  220,   46,   19, 1425,   70,
           53,  162,  142,   10,  289,    4,    8,   29,   19, 4609, 3976,    5,
            2,    1,    1],
        [  19, 1260,   85,    7, 1362,  345,  703, 1118, 4355,  227, 4151,  240,
          144,   86,  367,    4,  148,  162,  593, 5592,   10,  575,  419, 1964,
            6,   12, 8870,  445,    4,  148,  144, 5523,  593,  261,    8,   55,
          593,  535,   10,  498, 6449,   54,  115,    5,    2,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,  742, 1040,    4,   24,   11,   57,  142,   10, 6960,   13,
          563, 5202, 3040,  106,    7,  858,    5,   68,  194,   65,   29,  168,
            4,  367,   69,  132,   10,    7, 1416,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,    4,   19,  154,    5,    5,    5,   25,  135,    4,   24,  144,
           13,  535,  655,   35, 1933, 2760,   12, 6354,   71,  108, 3753, 1195,
            8, 3666, 3634,  338,  525,  271,    4,    8,   17,   34,  108, 1219,
         5114,  429,   55,   13,  535,  183,    8,   21,  499,   26,  528,    5,
            2,    1,    1],
        [1585,   71,  126, 1820, 2394,    8, 2244,   12, 2212,    4,   84,  451,
           51,    9, 1820, 2394,    8, 2027,   15,   54,   12,  108, 1259, 3051,
            6,   79,  238,   79,  108,  126, 1820, 3051,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   19,  169,  100,   10, 5640,   71,   39,  801, 1930, 1105, 5726,
           44,   38, 1355,   20,    4,  339,  170,   51, 1431,   55, 1042,  224,
          339,  170,  229,  282, 1829,   69,  170,  224,  339,  170,   51,  570,
         1118,    8, 3532, 1649,  224,    7,  984, 6932,   51,  859,   10,  211,
           91,  137,    2],
        [   8,   21,   34,   13,  488,  279,    9,   89,  277, 1237,   12,  613,
          203,   93,   96, 4127,    9,    9,  352,  687,    4, 4809,    4,  125,
           84,  162,  288,   80, 8255,   94,   84,    9,    7, 6852,  193,   33,
           34,  270,    9,  501,  895,  820,  115,    5,    2,    1,    1,    1,
            1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[37, 59, 11, 38, 85, 35, 31, 37, 37, 50, 37, 37, 38, 35, 35, 35, 37, 77,
         37, 28, 85, 32, 11, 37, 83, 49, 94, 37, 38, 85, 35, 83, 59, 82, 28, 37,
         28, 11,  9, 38, 35, 35, 37, 24, 11, 83, 37, 37, 37, 37, 37],
        [37, 50, 38, 31, 37, 85, 11, 37, 38, 31, 38, 85, 59, 11, 85, 38, 85, 59,
         83, 83, 37, 59, 50, 56, 85, 37, 88, 37, 59, 37, 38,  6, 11, 38, 31, 50,
         37, 85, 49, 37, 88, 11, 37, 83, 38, 31, 59, 11, 83, 37, 37],
        [38, 59, 37, 37, 38, 77, 88, 56, 88, 38, 35, 35, 85, 83, 85, 11, 50, 85,
         83,  2, 37, 88, 50, 32, 37, 37,  2, 35, 11, 50, 85, 31, 83, 83, 37, 37,
         83, 83, 37, 49, 32, 49, 83, 11, 83, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 35, 11, 38, 85, 77, 49, 37, 88, 37,  9, 94, 76, 37, 37, 94,
         11, 38,  9, 11, 83, 37, 11, 85, 37, 37, 37, 37, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 11, 38, 59, 11, 11, 11, 37, 59, 11, 38, 85, 37, 83, 34, 38, 24, 23,
         37, 49, 37, 37, 28, 56, 37, 28, 33, 35, 35, 44, 11, 37, 37, 85, 37, 38,
         83, 94, 37, 37, 83, 24, 37, 37, 83, 85,  2, 11, 83, 37, 37],
        [37, 37, 37, 35, 94, 37, 29, 37, 94, 11, 37, 85, 38, 37, 35, 94, 37,  2,
         77, 49, 37, 37,  9, 36, 37, 37, 83, 37, 37, 37, 35, 36, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 37, 37, 49, 37, 38,  2, 38, 35, 32, 82, 38, 35, 77, 11, 49,
         37, 38, 56, 37, 83, 11, 49, 37, 49, 32,  2, 37, 37, 11, 49, 37, 38, 94,
         56, 37, 31, 50, 11, 37, 94, 83, 38, 31, 37, 50, 50, 11, 83],
        [37, 37, 85, 37,  2, 50, 37, 37, 50, 94, 37, 32, 38, 35, 77,  9, 37, 37,
         35, 35, 11, 28, 11, 37, 37, 85, 83, 37, 34, 56, 37, 37, 37,  9, 11, 37,
         85, 37, 37, 38, 73, 73, 83, 11, 83, 37, 37, 37, 37, 37, 37]],
       device='cuda:4'), 'lengths': tensor([46, 49, 45, 33, 49, 35, 51, 45], device='cuda:4'), 'ntokens': 353}, 'target': tensor([[6041, 9574,    4,   50,   40,   97, 1076,  797, 1547,    6, 2171,   49,
         1664, 3308,   27,    5,  396,  167, 1856,  303,  441, 4362,   15,    4,
           14,   32, 1036,   83,   44, 4016,    9, 1437,    4, 3671,  559, 1533,
          741, 6653, 4177,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1046,  114,   31,  915,    4,   50,   31, 4646,   28, 3217,  354,    4,
         3933,   31,  924,  257,  149, 1238, 1279,  548,    4,  382,   31,  406,
          153,   50,   31, 7535,    4,   34,   95,  334,  354,    4,   16,  189,
         3933,   31,   61,   28,  425, 3217,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 1204,   14, 3279,   15, 4612,  152,  819,  444,   39,    4,   23,
           15,  202, 2342,    6,   37,   47, 4009,   82,    4,   14,   28, 5343,
          319,    4,   88,  377, 4642,   49, 1442,   18,  152, 2435,  165,   28,
          701,  224,   14,   28,  275,   28, 1238,  184,  122, 3475, 1630,  471,
            4,   88,  361,   28,  302,  181, 1194,    5,    2],
        [ 298,  685, 1040,    4,   32,  127,   52,  599,  265,  365,  416,   15,
          243,  237, 1170,   98,   23, 1014,  102, 1921,   18,   59,  272,    5,
           68,  379,   65,  504,    4,  615,   41,   39,   14, 8735,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,    4,   31,  638,    5,    5,    5,  104,  471,   52, 1238,  655,
           35, 3723, 9311,  129, 8270,    6,   60,  872, 7163,   22, 4175,   15,
           16,   60, 1640, 3811, 1134,    6,  156,  338,  525, 1347,    4,   92,
           82, 1238,  273,  403,   37,  426, 8810,    5,   99,   27,  257,  196,
          766,    5,    2,    1,    1,    1,    1,    1,    1],
        [3492,  158,  356,  364, 9319,   22, 1668,   16,   58, 6595,   15, 2126,
          769,   52, 3289,   20, 1668, 2363, 2668,   15,   16,   32,  776,  273,
         5162,   97, 4237, 2157,   74,   14, 9319,   22, 5162,  171, 7941,   15,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   31,  354, 1700,  467,   15,   60,  151, 3047, 3963, 1105,   35,
          949,   62, 1895,    5,   38, 9206,    4, 2279,    6,  107,   78,  648,
         1958,  186,  224, 2279,    6,  107,   30,  314, 6585,  260,  224, 2279,
            6,  107, 1774, 1499,   16,  507, 4965,   20,  186,  224,   14, 1062,
         1582,   47,  151, 2631, 6238,  137,    2,    1,    1],
        [  64,   36,   82,   52,  799,  997,    9,  493,  953, 4633, 2098,  160,
           18,  472,   93,   96,  612,  271,    9,  228,  352,  687,    9, 5811,
            4,  268,  517,   97, 7061,  149,  761, 8255,  157, 6114,  193, 3596,
          564,  895,  820,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'target_lengths': tensor([41, 44, 57, 36, 51, 38, 55, 41], device='cuda:4'), 'ntokens': 363, 'nsentences': 8}
##################### {'id': tensor([173112, 193988,  29242, 194650, 125507,  59170, 128006, 101121],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 3.0518e-04, -3.6621e-04, -7.9346e-04,  ...,  2.7466e-03,
          4.3945e-03,  4.4556e-03],
        [-3.0823e-03, -2.9907e-03, -2.9602e-03,  ...,  2.8687e-03,
          1.8311e-03,  1.3428e-03],
        [ 1.5869e-03,  1.9226e-03,  2.6245e-03,  ...,  1.0620e-02,
          1.1383e-02,  7.3853e-03],
        ...,
        [ 1.8311e-04,  4.5776e-04,  9.1553e-05,  ..., -3.0518e-05,
         -3.0518e-05,  0.0000e+00],
        [-2.0752e-03, -2.0142e-03, -1.9836e-03,  ...,  3.0212e-03,
          2.3804e-03,  0.0000e+00],
        [-9.0027e-03, -8.9417e-03, -9.0027e-03,  ..., -1.2207e-04,
          1.2817e-03,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([166080, 166080, 166080, 166080, 166080, 166079, 166079, 166079],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2,   41, 1765,  295, 7068,   47,   29, 1138,    4,  312, 4360, 2362,
         1527, 4373, 7792,  112,   14, 3063,   28, 3240,    4,  136,  295, 5754,
           20, 2543,  130, 3341,   96,    4, 2114,    6, 1702,  364, 5440,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  404, 2140,   14, 2779, 3518,   18, 1949,  152, 5392, 2176,   18,
          699,  160,    4,   14,   51, 1090,   45,    9, 3712, 8927,   15,  184,
         3952,   18,  127,  145,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  312,  580,   23, 1916,   82,    4,   28, 1166,    4, 9468,   16,
          817,   28,  725,    5,    9,  631,   31,   47,  149,  256, 3705,  343,
         1096, 2408,  930,  237,  272,   27,  275,  874, 7321,  343,  519,   58,
         9468, 1984,  871,    6,   16,   23,  880, 3170,    4,   16,   14,  304,
          152,  158,   20,   60,  770,  880, 3170,   22,   28, 5014,    5],
        [   2,  228,  328, 1003,   56, 6110,  153,   75, 2578,   30,  824,   22,
          436, 1294,   20, 3239,   15,   16, 2785,  191,    4,   14, 5285,  174,
           59, 3185,   16,  677, 7160,  119, 1328,   20, 5757,    5,  939, 9922,
         3005,  140,  612, 2207,   97, 1641,   65,   72,  145,   36,   47,   56,
         2843,    5,  834,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   81,  547,  118,  953, 1092,  234,  756,   61,  243,  375,
         1515,   18,    4,   27,   36,    9,   22,  856, 1942, 9681,  973,  236,
           74,    9,  308,    5,  222,   81,  118, 3047, 1092,  234,  756,   61,
          243,  375, 1515,   18,    4,   27,   36,  167, 2239,  673,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1173,  933,    5,   68,  431,   65,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 8554,   44,  146, 6718, 1577, 6724,   40, 6922,    6, 6809, 1305,
          502, 1048,   37, 4275, 1305,   15,    9,  382,   28, 1498, 6541,   15,
         3445, 4215,  728,   22, 4049,  536, 2533,   20,  381, 8076,   22,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   30,   27,   34,   32,  260,  127, 1096, 1286, 1311,  112,
           30,   31, 3251,    4,  102,  677,  315,  726,  335, 1311,    4,  210,
          102,   32, 1166,    4, 9175, 4170,   15,  466,   28,  990,    4,  374,
            9,  151, 1615,    4,   29,   50,   23, 7056,  129,  312,   15,   23,
          966,  902,   59, 2162,  344, 4062,   22,  161,    5,    1,    1]],
       device='cuda:1')}, 'transcript': {'tokens': tensor([[ 115,    4,   53,  192,   11,   18, 2923, 2645,  429,   10,    7,  613,
           12, 3499,   54,    7, 4659, 2233, 4925,    6,   12,  277,  801, 2060,
          430, 1004,    7, 2291,    4,   67,  159, 3480,   48, 1422, 3318,    9,
         3849,    4,   29,  609,  457, 1588,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,   25,  368,    7,  775, 3518,  412,   35,  140,  234,  729, 1255,
          523,  699,  160,    4,  166,   26, 5029, 6035,   48,   55,  475,   35,
         9473, 3841,  729,  609,   96,    8, 2700,  923,   13,  747, 5912,   12,
         8604,  429,   10,   21,    6, 6463,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 461,   12,    7, 2020,   34,   10,  780,   10,  661, 7557,    8,  672,
          802,   86,  116,   89, 1860,   46,  125,   13,  325,   12, 2266, 5246,
          810,   26,  874,   35,  240,  634, 1011,   46,   67,  802,    7, 7557,
           12,   89,  955,    8, 2360,    4,    8, 1206,  810,    7, 3158,    6,
           71,   89, 2360,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,    9,   17,  765,    4,   77,  251, 1345,   12, 6338,    4, 4111,
            4,   77,    7, 1715,  174,  234,   22,    4, 7720,  523,   96,   46,
         3111,    4,   53,   11,   57,   77, 2539,   21,    5,   68,   45, 1558,
         5060,    9, 1819,   65, 1851,   89,  205, 1098,    4,   19,   73,   11,
           18,  703,   21,  408,  834,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,  103,   25, 1897,  985,   13,  277, 5495,    4,   21,   11,    6,
          133,  851,  399,  122,   93, 1117,    4,  100,   13,    5,    8,  103,
           25, 1897,  199,   39, 3563, 5495,    4,   21,   11,    6,  133, 3024,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 476,   25,  133,  261,    5,   68,  386,   65,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  67, 3695,  469,  982,    4, 4812,   48,    4,   53,  229,  132,   13,
         4690, 2541, 1305,   20,   12, 1254, 1479,    6,    9,  132,   10, 1498,
         6874,    4, 1809, 2124,   54, 2743,    6, 2816,  108, 2533,  608, 4715,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   17,   11,    6,   70,   24,   11,   57,  401,   69,    7,  558,
         1039,   19,   11,   45,  142,   10,  456,   80,    4,    7,  824,  726,
          335, 1039,    4,  206,   24,   11,   57,  752,   10,  875,  540,   13,
          800,   12, 6880,    4,   77, 1241,   91, 1009,    4,   29,   17,    7,
         3301,  106,   91,   73,   51,    7, 2073, 1015,   15,   18,   55,  486,
            5,    2]], device='cuda:1'), 'cluster_tokens': tensor([[83, 11, 37, 85, 85, 35, 49, 28, 94, 37, 37, 32, 37, 49, 49, 37,  9, 49,
          9, 37, 37, 50,  2, 38, 35, 37, 37, 94, 11, 37, 37, 29, 31, 94, 56, 37,
          2, 11, 83, 35,  2, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 49, 37, 38, 35, 35, 38, 35, 35, 77, 35, 83, 35, 35, 11, 37, 85,
         83, 29, 31, 37,  2, 38, 35, 29, 77, 35, 77, 37, 88, 83, 37, 30, 23, 37,
          2, 94, 37, 37, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [32, 37, 37, 94, 85, 37, 88, 37, 59,  9, 37,  9, 49, 83, 83, 37, 56, 11,
         37, 37, 83, 37, 38, 35, 35, 85, 38, 38, 35, 77, 31, 11, 37, 49, 37,  9,
         37, 37,  9, 37, 24, 11, 37, 29, 35, 37,  9, 37, 37, 37, 24, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 24, 11, 50, 50, 24, 37, 94, 11, 49, 11, 50, 37, 94, 35, 35,
         35, 11,  9, 83, 77, 11, 83, 11, 37, 85, 77, 50, 88, 37, 11, 38, 35, 35,
          9, 37,  9, 11, 38, 37, 85, 35, 11, 38,  6, 85, 35, 88, 37, 11, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 37, 31,  2, 37, 50, 28, 11, 37, 85, 37, 83, 38, 35, 35, 35, 37,
         11, 37, 37, 11, 37, 37, 37, 31, 37, 38,  2, 28, 11, 37, 85, 37, 83,  2,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 83, 83, 11, 38, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 35,  2, 11, 36, 31, 11, 37, 49, 37, 37,  2, 38, 35, 77, 37,  6,
          9, 37, 37, 37, 37, 34, 23, 11, 38, 35, 49, 88, 37, 37, 37, 28, 75, 94,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 50, 38, 85, 77, 49, 37, 37, 37, 32, 38, 85, 35, 49, 37,
         16, 37, 11, 37, 38, 35, 35, 32, 11, 37, 38, 85, 77, 49, 37, 49, 36, 37,
         23, 37, 56, 11, 50, 37, 50, 49, 11, 83, 37, 37, 29, 37, 50,  6, 38, 37,
         38, 35, 77, 35, 37, 50, 11, 83]], device='cuda:1'), 'lengths': tensor([44, 44, 53, 54, 38,  9, 38, 62], device='cuda:1'), 'ntokens': 342}, 'target': tensor([[  41, 1765,  295, 7068,   47,   29, 1138,    4,  312, 4360, 2362, 1527,
         4373, 7792,  112,   14, 3063,   28, 3240,    4,  136,  295, 5754,   20,
         2543,  130, 3341,   96,    4, 2114,    6, 1702,  364, 5440,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 404, 2140,   14, 2779, 3518,   18, 1949,  152, 5392, 2176,   18,  699,
          160,    4,   14,   51, 1090,   45,    9, 3712, 8927,   15,  184, 3952,
           18,  127,  145,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 312,  580,   23, 1916,   82,    4,   28, 1166,    4, 9468,   16,  817,
           28,  725,    5,    9,  631,   31,   47,  149,  256, 3705,  343, 1096,
         2408,  930,  237,  272,   27,  275,  874, 7321,  343,  519,   58, 9468,
         1984,  871,    6,   16,   23,  880, 3170,    4,   16,   14,  304,  152,
          158,   20,   60,  770,  880, 3170,   22,   28, 5014,    5,    2],
        [ 228,  328, 1003,   56, 6110,  153,   75, 2578,   30,  824,   22,  436,
         1294,   20, 3239,   15,   16, 2785,  191,    4,   14, 5285,  174,   59,
         3185,   16,  677, 7160,  119, 1328,   20, 5757,    5,  939, 9922, 3005,
          140,  612, 2207,   97, 1641,   65,   72,  145,   36,   47,   56, 2843,
            5,  834,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 222,   81,  547,  118,  953, 1092,  234,  756,   61,  243,  375, 1515,
           18,    4,   27,   36,    9,   22,  856, 1942, 9681,  973,  236,   74,
            9,  308,    5,  222,   81,  118, 3047, 1092,  234,  756,   61,  243,
          375, 1515,   18,    4,   27,   36,  167, 2239,  673,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1173,  933,    5,   68,  431,   65,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [8554,   44,  146, 6718, 1577, 6724,   40, 6922,    6, 6809, 1305,  502,
         1048,   37, 4275, 1305,   15,    9,  382,   28, 1498, 6541,   15, 3445,
         4215,  728,   22, 4049,  536, 2533,   20,  381, 8076,   22,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   30,   27,   34,   32,  260,  127, 1096, 1286, 1311,  112,   30,
           31, 3251,    4,  102,  677,  315,  726,  335, 1311,    4,  210,  102,
           32, 1166,    4, 9175, 4170,   15,  466,   28,  990,    4,  374,    9,
          151, 1615,    4,   29,   50,   23, 7056,  129,  312,   15,   23,  966,
          902,   59, 2162,  344, 4062,   22,  161,    5,    2,    1,    1]],
       device='cuda:1'), 'target_lengths': tensor([36, 28, 59, 51, 47,  7, 36, 57], device='cuda:1'), 'ntokens': 321, 'nsentences': 8}
##################### {'id': tensor([113300,  40738,  44192, 148214,  25665, 189470, 119411],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[ 1.7700e-03,  4.6082e-03,  5.8289e-03,  ..., -6.8665e-03,
         -1.0651e-02, -9.0027e-03],
        [-7.4829e-02, -6.5918e-02, -7.1167e-02,  ..., -2.1375e-01,
         -2.2339e-01, -2.5293e-01],
        [-3.2654e-03, -5.2185e-03, -6.7139e-03,  ...,  1.2756e-02,
          4.8248e-02,  3.5706e-02],
        ...,
        [ 7.3242e-04, -4.3854e-02, -5.3345e-02,  ..., -1.4038e-02,
         -5.1880e-03,  3.2349e-03],
        [ 2.4414e-04,  2.3499e-03,  9.5825e-03,  ..., -2.0752e-03,
         -1.4343e-03, -2.5330e-03],
        [-3.0121e-02, -2.7618e-02, -2.5085e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([320960, 320960, 320960, 320960, 320960, 320960, 320800],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,  228,   18,  389, 1182,  855, 5686,   16, 2294,   20, 2596,   60,
         1000,  331,   45,   46, 1554,   60,  141, 1024,  129,  351, 4730,    6,
            4,   14,  216,  262,  387,  662,    4, 2995,  809,   59,  219,  311,
          784,    4, 2290,  794,  265, 3729,   96, 3519,  262, 4487,   20, 1557,
          307,    5,   68,  348,   65,   64, 6696,  178,   36, 3198,   28,  363,
           37, 1934,  683,  249,  437,  219,  951,  357,  721,  410, 5648,   35,
          360, 1079,  303,  191,    5,    1],
        [   2, 1595,    6,  394,  501,    6,    5, 2537,  431,   65,  553,  748,
         2642,   92, 1494,  130,  217, 1924,  414, 1035,   16,   31,  514,   47,
          782,  193, 1272, 1035,   36,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   56,  431,   78,  495,    5,   68,  431,   65,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  280,  632,  534, 7975,    4,   50,   36,  139, 6779,  121,
           22,   18,  673,  186,  145,    4,  382,   31,  761,  423,   82,   16,
            9,  771,  314, 4923,   61, 4923,   52, 2557,   49, 2164, 3444,    4,
          263,  877, 4151,   37, 1089,  326,    4,   14,  406,  314,   61,   58,
         1441, 4919,    4,   16, 2578,  280,   31,   58, 1441, 3445, 2105,    4,
         3445, 3655,   37, 4650,    4,   60,  628,   31,   47,   88, 3387, 1904,
            5,    1,    1,    1,    1,    1],
        [   2,   92,   27,   23, 5800,    4,  114,   31,   61,  176,  315,   57,
            4,   78, 2870,   28,  186,    5,   64,   30,  836, 2977,    4,   50,
          707,  265,   59, 1029,  302,  751, 2013, 1099, 7243,   78,   58, 1641,
           38, 5142, 1196, 2286,  307,  197,  676,  130,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,   82,  177, 4447,  510,   61,  102,  201, 3501,    6, 1865,
          502,   16, 2411,   60, 3278, 5074,  357,    4,   14, 1444,    9, 1668,
         6989,   83,    5,   72, 2069,   43,   44,   38, 3437,   56, 6026,   18,
          355, 4071, 5975,   16, 4071,   22, 6743,  177,   77,  212, 2597,  358,
           41, 3921,   15,   75, 5532,   39,   16, 1457,  743,   40,  119,  389,
           45,  236,   44,   38, 2759, 6590,  714,  137,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  312, 4945, 7991,   35, 2507,  219,  562,    9, 8886, 2166,  198,
         6769,   16,  329,    4,   38, 4122,  776,   29,  306,  157,   74, 1048,
            9, 3233,   20, 5270, 1461,  510,  303,   16,  342,  443, 2686,  715,
            6,   15, 5397,   16, 1487,   40,  141,  285,  119, 1612,   93,   35,
          885,  233, 1010,   20, 1354, 3094,  795,  137,   68,  379,   65,   68,
          431,   65,   72, 2166,  328, 3216, 2752,  420,   16,  329,    4,   38,
         3344,    4,   30,   27, 8507,    5]], device='cuda:5')}, 'transcript': {'tokens': tensor([[   9,   18,  389, 3085,  818, 2395,    4, 2294, 3051,   71, 1482,  994,
           46,    8, 2603,   71, 1482,   12,    7, 5059, 2314,  148, 2700,  518,
          217,  174,  236,  241, 1032,    4,  521,  587,  607, 2553,   93,    4,
         2290,  794,  265, 3729,   96, 2109, 3413,    6,    5,   68,  194,   65,
            8,  333,  464,   84,   11,    6, 1221,  691,   69, 1244,   35,   57,
         1411,   62, 2951,   93,  687, 2584, 2900, 1613,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 168,   24,  205,    5,   68,  386,   65, 1052,   45,   44,    7, 1228,
         1639,  230,   55,    7,  245,  555,    8,   19,  192,   11,   18,  135,
          347,   21,   46,   84,   21, 1143,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 508,  565,   13,  488,  801,  874,    5,   68,  386,   65,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  144,   22,   11,   18,  172,  474,   17,   21,  220,   51,  746,
           12, 3560, 1197,    9, 1377,    4, 1325,   19,   34,   80,  423,    4,
          120,   13,  800,   12,  214,  956,    9,   89,  282,    9,  923, 4454,
         2786,  369,    4,  172, 3795,  214,  166,  116, 6582, 2077,   89,  282,
          132, 1763,  346,    8,   77,   12,   13, 5827,   19,   34,    9,  569,
          922,   71,  474,    6,    4,    9,  569,  922,   71, 1623, 4734,   17,
           19,  465,   11,   18,  135,  138,   10, 4346,   20,   71,    5,    2],
        [3296,    4,   19,  100, 1868,   59, 1029,   46,   19,  100,  267, 2088,
         6523,   93,   35,  687,    4,   19,  100,  267, 4172, 2787,    4,   19,
          100,  138,  225,   11,    6, 2575,   62,  456, 4528,    4,   19,  100,
          138,  225,   11,    6, 2393, 3696,  270,   10, 1491,   46,   67,   84,
           34,  250,   17,  956,    7,  473,  248, 2168,   17,   34,    5,    5,
            5,   19,  583,   21,    7, 2392,   35,   93,  187,  765,   44,   21,
           26,    7,  765,  120,   19, 1985, 2277, 1766,   54, 1183,    5,    2],
        [  19,   34,   85,    7,  179, 1519,   55,  502,   86,  535,  581,  952,
           10, 7926, 9829,    6,  148,   66, 3024, 6183,    9,    7, 2892,  179,
            8,   19,   34,  116, 2659,  134,    4,   38, 3179,   87,   25, 1816,
         2103,   77,  155,   94,    8, 6668,  106,   77,    7, 3079,  358,    8,
           53, 1260,   85,  545,  218,    4,    8,   53,  246,    4, 6244,  111,
            9,  291,  187,  650,    4,   38,  533, 1713,   21,  137,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  13,  747,  670, 1920,    9, 8603, 2396,  110,    9, 6769,    8,  246,
            4,   38, 1969,  451,  175,   79,  294,   94,   79, 1254,   10,  388,
           69, 1912, 1116,  614,   56, 7256,    6,    8,  421,  443, 2686, 3109,
           18,    6,    8,  205,  199,   13,  772, 1713,    8, 1109,  336,  137,
           68,  194,   65,   68,  386,   65,   29,   19, 2396,   33,  747,  670,
         1920,  270, 4173,    8,   19,  246,    4,   38,   93,   96,    4,   25,
           63, 5128,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'cluster_tokens': tensor([[37, 35, 35, 94, 88,  2, 11,  2, 36, 37, 50, 50, 11, 37, 83, 37, 50, 37,
         37, 36, 28, 50, 88, 37, 38, 35, 35, 35,  2, 11, 38, 35, 35, 35, 35, 11,
         38, 35, 35, 35, 77, 35, 32, 37, 11, 38,  9, 11, 37, 50, 24, 37, 85, 37,
         94, 31, 37, 32, 38, 77, 35, 31, 38, 35, 35, 36,  9, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 11, 38, 28, 11, 38, 35, 82, 37, 32, 31, 37, 37, 37, 83, 50,
         37, 38, 85, 85, 35, 59, 83, 37, 11, 37, 37, 85, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [88, 37, 37,  2,  2, 38, 11, 38, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 85, 35, 83, 31, 37, 37,  6, 38, 83, 37, 29, 77, 37, 94, 11,
         24, 38, 85, 37, 34, 11, 37, 37, 23, 37, 56, 31, 37, 37, 32, 37, 83, 83,
         32, 44, 11, 83,  2, 56, 37, 83, 38, 31, 37, 32, 37, 35, 37, 37, 50, 37,
         37, 83, 38, 85, 37, 35, 31, 37, 31, 37, 11, 37, 35, 31, 37,  2, 56, 37,
         38, 85, 85, 35, 59, 37, 37, 38, 77, 37, 11, 83],
        [83, 11, 38, 37, 38, 35, 35, 11, 38, 37, 37,  9, 35, 35, 38, 35, 11, 38,
         37, 37, 23, 56, 11, 38, 37, 37, 37, 85, 37, 29, 31, 16, 12, 11, 38, 37,
         37, 37, 85, 37, 31, 59, 37, 37, 28, 11, 37, 37, 85, 50, 37, 31, 37, 37,
         34, 24, 37, 85, 11, 11, 11, 38, 88, 37, 37, 83, 38, 35, 35, 24, 82, 37,
         85, 37, 24, 37, 38,  6, 49, 49, 49, 50, 11, 83],
        [38, 85, 37, 37, 94, 28, 37, 35, 83, 83, 83, 16, 37, 36, 32, 37, 50, 85,
          2, 56, 37, 37, 49, 94, 37, 38, 85, 83, 88, 37, 11, 38, 35, 85, 37, 56,
         29, 50, 37, 56, 37, 32, 37, 50, 37, 94, 11, 37, 37, 59, 37, 50, 50, 11,
         37, 37, 88, 11, 83, 83, 37, 38, 35, 35, 11, 38, 35, 49, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 30, 94,  9, 37, 28, 31, 37, 37, 25, 37, 88, 11, 38, 37, 85, 85, 37,
         50, 56, 37,  6, 37, 31, 37,  2, 38, 35, 38,  9, 37, 37, 38, 35, 35, 38,
         35, 37, 37, 85, 37, 37, 75, 49, 37, 53, 37, 11, 38,  9, 11, 38, 28, 11,
         83, 38, 31, 37, 30, 94,  9, 37, 83, 37, 38, 88, 11, 38, 35, 77, 11, 37,
         85, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([70, 32, 11, 84, 84, 71, 76], device='cuda:5'), 'ntokens': 428}, 'target': tensor([[ 228,   18,  389, 1182,  855, 5686,   16, 2294,   20, 2596,   60, 1000,
          331,   45,   46, 1554,   60,  141, 1024,  129,  351, 4730,    6,    4,
           14,  216,  262,  387,  662,    4, 2995,  809,   59,  219,  311,  784,
            4, 2290,  794,  265, 3729,   96, 3519,  262, 4487,   20, 1557,  307,
            5,   68,  348,   65,   64, 6696,  178,   36, 3198,   28,  363,   37,
         1934,  683,  249,  437,  219,  951,  357,  721,  410, 5648,   35,  360,
         1079,  303,  191,    5,    2,    1],
        [1595,    6,  394,  501,    6,    5, 2537,  431,   65,  553,  748, 2642,
           92, 1494,  130,  217, 1924,  414, 1035,   16,   31,  514,   47,  782,
          193, 1272, 1035,   36,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  56,  431,   78,  495,    5,   68,  431,   65,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  280,  632,  534, 7975,    4,   50,   36,  139, 6779,  121,   22,
           18,  673,  186,  145,    4,  382,   31,  761,  423,   82,   16,    9,
          771,  314, 4923,   61, 4923,   52, 2557,   49, 2164, 3444,    4,  263,
          877, 4151,   37, 1089,  326,    4,   14,  406,  314,   61,   58, 1441,
         4919,    4,   16, 2578,  280,   31,   58, 1441, 3445, 2105,    4, 3445,
         3655,   37, 4650,    4,   60,  628,   31,   47,   88, 3387, 1904,    5,
            2,    1,    1,    1,    1,    1],
        [  92,   27,   23, 5800,    4,  114,   31,   61,  176,  315,   57,    4,
           78, 2870,   28,  186,    5,   64,   30,  836, 2977,    4,   50,  707,
          265,   59, 1029,  302,  751, 2013, 1099, 7243,   78,   58, 1641,   38,
         5142, 1196, 2286,  307,  197,  676,  130,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,   82,  177, 4447,  510,   61,  102,  201, 3501,    6, 1865,  502,
           16, 2411,   60, 3278, 5074,  357,    4,   14, 1444,    9, 1668, 6989,
           83,    5,   72, 2069,   43,   44,   38, 3437,   56, 6026,   18,  355,
         4071, 5975,   16, 4071,   22, 6743,  177,   77,  212, 2597,  358,   41,
         3921,   15,   75, 5532,   39,   16, 1457,  743,   40,  119,  389,   45,
          236,   44,   38, 2759, 6590,  714,  137,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 312, 4945, 7991,   35, 2507,  219,  562,    9, 8886, 2166,  198, 6769,
           16,  329,    4,   38, 4122,  776,   29,  306,  157,   74, 1048,    9,
         3233,   20, 5270, 1461,  510,  303,   16,  342,  443, 2686,  715,    6,
           15, 5397,   16, 1487,   40,  141,  285,  119, 1612,   93,   35,  885,
          233, 1010,   20, 1354, 3094,  795,  137,   68,  379,   65,   68,  431,
           65,   72, 2166,  328, 3216, 2752,  420,   16,  329,    4,   38, 3344,
            4,   30,   27, 8507,    5,    2]], device='cuda:5'), 'target_lengths': tensor([77, 30,  9, 73, 45, 68, 78], device='cuda:5'), 'ntokens': 380, 'nsentences': 7}
##################### {'id': tensor([  5074,  27108,  34516,  11300, 222990], device='cuda:6'), 'net_input': {'src_tokens': tensor([[ 0.0196,  0.0125, -0.0276,  ..., -0.0123, -0.0161, -0.0104],
        [ 0.0034,  0.0038,  0.0003,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0068, -0.0058, -0.0039,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0053,  0.0066, -0.0015,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0019,  0.0022,  0.0020,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([458240, 458080, 458080, 457920, 457920], device='cuda:6'), 'prev_output_tokens': tensor([[   2,  222,   81,   75,   30,   61,  151, 7336,   15, 9726,   15,   39,
         1915,   18,    4,  745,   36,   29,   98,    4,   90,  403,  374, 1292,
         5782,  730,   27,    4,  136,  470,  285, 1967, 1170,   37,  334,    4,
           38, 6543,    4, 4447, 5226,   56, 2916,  398,  149, 4451,   61,  337,
         9726,   15,    4,   14,   61,   52,  647, 4262, 4242,  137,  298, 2357,
           31,  798, 1447, 4191,   22,   49,  766,   15, 5813,  357,    4,   74,
           14,  330,   22, 1255,  140, 3576,   62,  407, 7138,  221,   22, 2956,
            4,   30, 1191,  803,    6, 1198,  481, 5433,    4, 3863,  237, 1092,
         3850,    6,  938,    6,   45,  515,  869,  232, 1454,    4,   16,  105,
          310, 1770,  566,   47,  406, 6598, 4095,    4,   14,    6,   76,  149,
         4191,   22,   49,  472,  181,   37, 1869, 3951,    4,   16,   30,   27,
            4,   34,   43,   90, 4133,  626,  445,   20,    9, 4569,   59,   16,
         8139,   59, 3388,  208,    5],
        [   2,   64,  173,   27,  547,  406, 5502,   44,   72, 7432,  198,    4,
           50,   41,  210,   23,  437, 2097,  165,    4,   23,  312, 4393,   16,
           23, 8169,  141, 3946,   59,  455,  129, 3308,    6, 1176,  193, 7870,
           49,  141, 1624, 6393,  345, 5813,   37,   98,   58,  462,   13, 1672,
          443,  910,  515, 3346,   15,    4, 3124,  303, 3551,    4, 2640,  191,
         3551,   16, 6780,    4,   16, 7182,   61,   30, 2570,   20, 4060,   23,
         4453,   15,   15, 4318,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,   99,  394,   47, 1497,    4,   52, 8139, 2234, 5135,    4,   36,
           18,  394, 1497,    4,   41,   28,  171, 2297,   28,  190,    4,   30,
           41,  269,  123,    4,   28,  190,    4,   30,  252,  184, 2764,  161,
            4,  190,    4,   30,  295,  732,  247,  365,   37,   95, 4753,  161,
            4,  190,    4,   30,   41,   75,   29, 1919,  795,  161,    4,   90,
         2203,   41,    9,  141,  351,  201,  193,   29,   74,  186, 4671, 1337,
           35, 3736, 2362,  234,  480,    9, 1357, 1784,    4,   30,  611,   14,
           22,   18,    4,   41,   49,  102, 2467, 1929,    9, 1357, 1784, 5515,
          364,  437, 2586,  721, 4644,    6,   28,  990,   16,  364, 2204,   20,
         1854,   23, 4211,  515, 5636,    5, 1193, 4818,  374, 9283,   27,    4,
          395,   36,   74, 4184, 9658, 2655, 1701,    4,  329,   23, 6743,   37,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 1209,  392,    5, 5904,    4,  217, 3713, 1984,   43, 1630,   15,
         7547,   96,  836,   31,    9,   14, 6561, 4450,    4,  258,  256, 1145,
           30, 5500,  551,   59,  318,  200, 2435,   16,  406, 1667, 5344, 2279,
          124,   29,    4,   16,   31, 2800,  163,  102, 1921,  587,   18,  673,
            9,   14, 3345,   16,   43, 1457,   44,   38,  949, 3775, 3713,    5,
         2732, 4850,  253, 7547,  137,   64,   31,  329,   44,   38,  967,  313,
          361, 2681,  137, 1462, 1667,   56, 1358, 1150, 2545,   16,  329,   44,
           38,  967, 3025,    4,  316,  514,   18,    4,   34,   30,  855,  358,
           64,   31,  329,   44,   38, 3344,    4,   36,  178,   52, 8798,    4,
          118, 2389,  544,   16,  306, 6622,   20,  358, 1462, 1667,  329,   44,
           38, 2195,  139,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,   30,  314,    9,  512,   45, 3748,  149,   47,   29,  909,
          156,  683,  578,    4,  114,   36,   52, 2889,   61, 7915, 2111,  253,
         4540, 5792,    4,  124,  118, 5450,   15, 2151,    4,  114,   41,   16,
          512, 4218,   22,   47,  640,  950, 2726,  259,   60,  599, 5391, 4441,
         2203,    5,  222,   14,  840, 3218,  317,   40,  905,  702,    6, 6273,
         3811, 2203,    5, 7167,   14, 2234, 1846,  173,    9, 1257, 2181, 3206,
           42,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[ 115,  131,    7,  207,    4,  103,   25,  274,   85,   33,   69,   13,
         7336, 5562,    4,   21, 1321,  100,  778,  188,  116,  956,    4,   67,
          185, 6337,   59, 1119,    4,   38, 1367,    4, 1489, 5226,  116,  388,
         3773,   69,   33, 5562,   17, 2322,   69,   17, 4481, 1375,  137,   29,
            4,   19,  842,  798,  341, 2884,    6,  106, 1890,  154,  373,    4,
          100,    7,   56,   15, 1255,  140, 3576,   62,  407,  862,  235,  221,
           22, 2956,    4,    7, 4098,   12, 1745, 1261,    4,  595,  237, 3153,
         3850,   11,    6,  415,    6, 3784, 2595,  856,  293,   69,    7,  370,
           46,    8,  117,   94,  162,   86,  752,   10,  229,   89,  613,  224,
          117,  162,  116, 2884,    6,    9, 7421, 1429,    4,    8,   19,  154,
           17,   11,    6,   70,   53,  474,    7, 1890, 2792,    6,  162,    9,
         4325, 2569,    8, 7118, 2569,    5,    2],
        [   8,  115,    4,  168,   11,    6,   89, 3013,   44,   19, 3013,   17,
           25,  169,  601,   71,    7, 5708,    4, 5900,    8, 3411,  652,  271,
           12,   13, 6143,   37,   55, 2952,    4, 8597,   62,  131,   13, 1361,
           12, 7003,  128,  154,  373,  106,    7,  391,   13, 1672, 2689,  266,
         5000,    6,   12, 1546, 1151, 1144,    4, 6983,  429,    8, 3967,    4,
            8, 2219,   69,    7, 2570, 3676,   12,    7, 3213,   15, 3900,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6,   86,   10,  719,   13, 7118, 2780,    4,   21,   11,
            6,   10,  987, 1050,  430,   25,  199,  250,   17,   25,   73,   87,
            4,  199,  250,   17,  164, 2993,   25,    4,  250,   17,  164, 6147,
          155, 5289,    6,    4,  250,   17,  164,  229,   25,  598,   79,  103,
           63,    9,  486,  179,   46,  860,   79,  284,  211, 1337, 5743,    9,
          264, 1736,    4,  166,   26, 3263,   10,  305,   25,  106,    7, 1747,
          387,  249,   12,  264, 1736,  942,   10,    7, 8681,   12, 4211,    8,
            7,  417, 1875,  833,   12, 6871, 5000,    5,   38,  200,  969,   21,
           11,    6,   77,  246,    8,  691,    4,   21,   11,    6,  278,   10,
          274,  100, 1580,  533,   62,  438,  246,    7,  447,   37,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  69, 7739,  392,    4,    7, 2223,   12,   89, 1646,  322, 7530,    4,
           19,  552,  346, 2362,  551,    6,   10,    7, 6787,    4,  206,   89,
         1276,   34,   34,  176,   54,    7, 7169,   96,    8,   89, 1970,   34,
         3696,    7, 1780,  109,  250,    4,    8,   19,  746,   12, 2082,   62,
         1222,   10,  134,    9,    7, 2657, 1408,    4,    8,   53,  246,    4,
           38, 6435,    4, 1767, 7530, 2236,    8,   19,  246,    4,   38,  187,
           11,   45, 1646,  137,    8,   89, 1970, 6087,   48,    8,  246,    4,
           38, 1367,    4,   25,  135,   70,   17,  818,    4,  192,   11,   18,
           25,  358,    8,   19,  246,    4,   38, 8566,    4,   17,   19,   11,
           45,  142,   10,   66,   13, 4657,    8,   13,  682,  636,    8,  175,
           13,  325,   12, 2082,    6,  358,    8,   89, 3806,  246,    4,   38,
         1367,    4, 1586,    5,    2,    1,    1],
        [ 103,  282,    9,  155, 2822, 3994,   11,   18,   29,  909, 2536, 1563,
            4,  103,   84,   34,   13,  207,   10, 1057,  890,  896,   10,  175,
          131,    4,  109, 1057,   13, 6125, 1329,   46,  103,   25,    8,  155,
         4197,    6,  465,   11,   18,   66,   10, 1744,  640,  439,   12,  159,
         2503, 1778, 1551, 1809,   18,  311,   54,  563,    4,  103, 3530,  162,
          116,   13,  277,  143, 1320,  809,  235,  457,    5,    5,    5,  220,
            7, 2780,   51,  230,  168,    9,  108,   29,  233,   42,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[83, 37, 37, 83, 11, 37, 37, 59, 37, 37, 37, 37,  2, 32, 11, 37, 59, 37,
         50, 85, 83, 31, 11, 37, 50, 59, 35, 88, 11, 38, 35, 11, 38, 35, 83, 31,
         56, 37, 37, 32, 37, 29, 37, 37, 83, 94, 11, 83, 11, 38, 31, 34, 33, 94,
         37, 37, 32, 59, 56, 11, 37, 37, 38, 77, 35, 35, 35, 31, 35, 38, 35, 35,
         35, 35, 11, 37,  9, 37,  2, 94, 11,  9, 35, 38, 35, 85, 37, 38, 37, 35,
         29, 58, 35, 37, 37,  4, 11, 37, 37, 56, 85, 83, 49, 37, 49, 37, 32, 11,
         37, 85, 83, 94, 37, 37, 32, 56, 11, 37, 38, 59, 37, 85, 37, 50, 37, 31,
         37, 32, 32, 37, 85, 37, 28, 94, 37, 28, 94, 11, 83],
        [37, 83, 11, 37, 85, 37, 37, 88, 82, 38, 88, 37, 37, 85, 49, 37, 37, 94,
         11, 49, 37, 38, 35, 44, 37, 37, 94, 77, 37, 32, 11, 32, 31, 37, 37, 94,
         37, 94, 35, 59, 56, 37, 37, 34, 37, 35, 35, 35, 94, 37, 37, 38, 35, 32,
         11, 28, 94, 37, 28, 11, 37, 83, 37, 37,  2, 32, 37, 37, 28, 77, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 37, 49, 37, 28, 94, 11, 37, 85, 37, 37, 38, 35, 35, 37,
         37, 50, 37, 37,  6, 85, 11, 37, 50, 37, 85, 83, 37, 11, 50, 37, 85, 29,
         37,  9, 37, 11, 50, 37, 85, 49, 37, 59, 37, 37, 85, 37, 50, 94, 11, 83,
         37, 37, 50, 35,  9, 37,  2, 28, 11, 37, 85, 88, 37, 49, 37, 37, 37, 38,
         35, 77, 37,  2, 28, 94, 37, 37, 94, 37, 28, 37, 37, 38, 35, 35, 37, 28,
         94, 11, 38, 35, 77, 37, 85, 37, 50, 88, 37, 31, 11, 37, 85, 37, 31, 37,
         59, 37,  9, 35, 31, 82, 88, 37, 37, 77, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 24, 17, 11, 37, 24, 37, 37, 34, 35, 24, 11, 38, 85, 37, 35, 69, 37,
         37, 37, 94, 11, 37, 37, 94, 85, 85, 35, 49, 37, 29, 77, 37, 37,  9, 85,
         59, 37,  9, 37, 50, 11, 37, 38, 83, 37, 88, 31, 37, 37, 37, 37, 37, 94,
         35, 11, 37, 37, 88, 11, 38, 83, 11,  2, 24, 11, 37, 38, 88, 11, 38, 35,
         85, 35, 34, 11, 37, 37,  9,  9, 31, 37, 88, 11, 38, 35, 11, 37, 59, 50,
         37, 88, 11, 85, 85, 35, 37, 11, 37, 38, 88, 11, 38, 35, 11, 37, 38, 85,
         35, 49, 37, 85, 37, 94, 37, 37, 38, 77, 37, 85, 37, 83, 37, 88, 37, 11,
         37, 37,  9, 88, 11, 38, 35, 11, 83, 11, 83, 37, 37],
        [37, 32, 37, 37,  9, 85, 85, 35, 83, 38, 35,  2, 11, 37, 37, 85, 37, 83,
         37, 49, 83,  9, 37, 85, 37, 11, 37, 49, 37, 49, 32, 11, 37, 37, 37, 37,
         94, 37, 85, 85, 35, 85, 37, 49, 34, 24, 37, 37, 38, 35, 24, 38, 35, 35,
         49,  9, 11, 37, 56, 85, 83, 37, 50, 50, 38, 35, 35,  2, 11, 11, 11,  6,
         37, 94, 38, 37, 37, 37, 37, 83, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:6'), 'lengths': tensor([139,  73, 120, 137,  83], device='cuda:6'), 'ntokens': 552}, 'target': tensor([[ 222,   81,   75,   30,   61,  151, 7336,   15, 9726,   15,   39, 1915,
           18,    4,  745,   36,   29,   98,    4,   90,  403,  374, 1292, 5782,
          730,   27,    4,  136,  470,  285, 1967, 1170,   37,  334,    4,   38,
         6543,    4, 4447, 5226,   56, 2916,  398,  149, 4451,   61,  337, 9726,
           15,    4,   14,   61,   52,  647, 4262, 4242,  137,  298, 2357,   31,
          798, 1447, 4191,   22,   49,  766,   15, 5813,  357,    4,   74,   14,
          330,   22, 1255,  140, 3576,   62,  407, 7138,  221,   22, 2956,    4,
           30, 1191,  803,    6, 1198,  481, 5433,    4, 3863,  237, 1092, 3850,
            6,  938,    6,   45,  515,  869,  232, 1454,    4,   16,  105,  310,
         1770,  566,   47,  406, 6598, 4095,    4,   14,    6,   76,  149, 4191,
           22,   49,  472,  181,   37, 1869, 3951,    4,   16,   30,   27,    4,
           34,   43,   90, 4133,  626,  445,   20,    9, 4569,   59,   16, 8139,
           59, 3388,  208,    5,    2],
        [  64,  173,   27,  547,  406, 5502,   44,   72, 7432,  198,    4,   50,
           41,  210,   23,  437, 2097,  165,    4,   23,  312, 4393,   16,   23,
         8169,  141, 3946,   59,  455,  129, 3308,    6, 1176,  193, 7870,   49,
          141, 1624, 6393,  345, 5813,   37,   98,   58,  462,   13, 1672,  443,
          910,  515, 3346,   15,    4, 3124,  303, 3551,    4, 2640,  191, 3551,
           16, 6780,    4,   16, 7182,   61,   30, 2570,   20, 4060,   23, 4453,
           15,   15, 4318,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  99,  394,   47, 1497,    4,   52, 8139, 2234, 5135,    4,   36,   18,
          394, 1497,    4,   41,   28,  171, 2297,   28,  190,    4,   30,   41,
          269,  123,    4,   28,  190,    4,   30,  252,  184, 2764,  161,    4,
          190,    4,   30,  295,  732,  247,  365,   37,   95, 4753,  161,    4,
          190,    4,   30,   41,   75,   29, 1919,  795,  161,    4,   90, 2203,
           41,    9,  141,  351,  201,  193,   29,   74,  186, 4671, 1337,   35,
         3736, 2362,  234,  480,    9, 1357, 1784,    4,   30,  611,   14,   22,
           18,    4,   41,   49,  102, 2467, 1929,    9, 1357, 1784, 5515,  364,
          437, 2586,  721, 4644,    6,   28,  990,   16,  364, 2204,   20, 1854,
           23, 4211,  515, 5636,    5, 1193, 4818,  374, 9283,   27,    4,  395,
           36,   74, 4184, 9658, 2655, 1701,    4,  329,   23, 6743,   37,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [1209,  392,    5, 5904,    4,  217, 3713, 1984,   43, 1630,   15, 7547,
           96,  836,   31,    9,   14, 6561, 4450,    4,  258,  256, 1145,   30,
         5500,  551,   59,  318,  200, 2435,   16,  406, 1667, 5344, 2279,  124,
           29,    4,   16,   31, 2800,  163,  102, 1921,  587,   18,  673,    9,
           14, 3345,   16,   43, 1457,   44,   38,  949, 3775, 3713,    5, 2732,
         4850,  253, 7547,  137,   64,   31,  329,   44,   38,  967,  313,  361,
         2681,  137, 1462, 1667,   56, 1358, 1150, 2545,   16,  329,   44,   38,
          967, 3025,    4,  316,  514,   18,    4,   34,   30,  855,  358,   64,
           31,  329,   44,   38, 3344,    4,   36,  178,   52, 8798,    4,  118,
         2389,  544,   16,  306, 6622,   20,  358, 1462, 1667,  329,   44,   38,
         2195,  139,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,   30,  314,    9,  512,   45, 3748,  149,   47,   29,  909,  156,
          683,  578,    4,  114,   36,   52, 2889,   61, 7915, 2111,  253, 4540,
         5792,    4,  124,  118, 5450,   15, 2151,    4,  114,   41,   16,  512,
         4218,   22,   47,  640,  950, 2726,  259,   60,  599, 5391, 4441, 2203,
            5,  222,   14,  840, 3218,  317,   40,  905,  702,    6, 6273, 3811,
         2203,    5, 7167,   14, 2234, 1846,  173,    9, 1257, 2181, 3206,   42,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([149,  77, 133, 124,  73], device='cuda:6'), 'ntokens': 556, 'nsentences': 5}
##################### {'id': tensor([ 62795, 222846, 201907, 196109,  17508,  65464,    655,  54605,  20838,
         92111,  11918, 180649, 156737, 158108,  12573, 177970],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[-0.0005, -0.0005, -0.0004,  ..., -0.0008, -0.0008, -0.0006],
        [-0.0029, -0.0034, -0.0028,  ...,  0.0098,  0.0112,  0.0078],
        [-0.0027, -0.0011, -0.0008,  ..., -0.0026,  0.0002, -0.0084],
        ...,
        [-0.0013,  0.0008,  0.0019,  ..., -0.0004, -0.0015, -0.0020],
        [-0.0023, -0.0007,  0.0013,  ...,  0.0036,  0.0018,  0.0000],
        [ 0.0017,  0.0021,  0.0009,  ..., -0.0011, -0.0016,  0.0000]],
       device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([125440, 125440, 125440, 125440, 125440, 125440, 125440, 125440, 125440,
        125440, 125440, 125440, 125440, 125440, 125439, 125439],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,  146, 2155,  997,    4,   14,   32,  260,  309,    4,   27,  317,
           40, 1857, 2664,   61,   30,    4,   34,   32,    9,  141,   29, 1489,
           15,  259, 4261,   20, 1517, 2505,   83,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 6703, 2173,  398,   30, 4153,  938,  158,  975,  673, 7277, 9073,
           98,   58, 5801,   15,   23, 3852, 4321,  410, 1929,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   43,  280,  302, 4612,  152,    6,   37,   49,  328, 6241,
         1092,  527,   61,   23, 7629,  533,   15, 3134,   93,  175, 5189,  861,
            4,   16, 1513,  145,  328, 1092,  527,  433, 2995, 3094,   42,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 5939,   28,  320,   27,  136,    4,   50,   14,  559, 1018,  992,
          360,  754, 1018,   35, 8809,   40, 4625,   78, 1973, 5942,   15,   27,
            4,   29, 3290,   32,  299, 1281,   83,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41,  320,   36,    4,   31, 5751,   36,    4,  136,   32,  776,
          286,  259, 3645,    4,  273,  259,    4,  112,  105, 2692,   28,  843,
            4,  428,   32,  681,   58, 1083,  623,  385, 4583,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  520,   31,  337, 2758, 3371,   20,    4,  915,   31,  198,   44,
           38,  360, 1328,   37,  313,   31,   47,   23, 1542,  919,    4,   23,
           75,  118, 1876,   78,   75,  363, 1205, 1398,  137,  298,  209,   31,
           40, 1538,  182,  247, 1865,  243,   18,    5,    1,    1],
        [   2,  526,    4,   34,   31,   47, 1904,    4,   16,   34,   32, 8722,
           15,    4,   82,   46,  105,  310,    4,   43,  123,  410,  337,  840,
         3218,   22,   47,  594,   29,  190,   74, 2630, 1561,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  504,   76,  302, 6776,    4,   14,  632,  190,   49,  330, 4436,
          297,   48,    6, 3492,  158,  356,   15, 7988, 1353,   45, 1388,   83,
            4,   14,   47, 3417,    4,   50,   81,   36,   47, 5437,  666,    4,
           16,   14,   30, 3776,  485,  414,  548, 4602,   15,    5],
        [   2,  104,   83,   14, 8875, 6363,   16, 4870,  153,   18,    4,   50,
           23, 4066,  399, 1564,  354,    4,   16,   56, 8081, 2607,   95,   30,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   30,   76, 1128, 6323, 1283, 6589, 6948,   37,    4,   14,
           75,   52, 4367, 1099,   60,  141, 1044,  548, 2387,   16,   43,   28,
          805, 4444, 1098,  365,  240,  390,   51, 6152,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  564,  957,  584,  573,   36,  263,   52, 2557,   49, 2499,
          173,    5,   92,  319, 3830, 5092,   60,  953, 2165,   16,  151, 4842,
          314,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 8727,    4,  363,  114,   32,  105, 7095,  940,    4,  113, 1673,
           56, 9552, 1348,    6,   56, 9272,   14,  201,    4,  178,   36,  139,
          433,   40,  496,   44, 1135, 3875, 1673,   42,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,  354,   75,   47,  149, 8399,   61,  654,  643,   98, 5404,
            4,  519,  273, 1521,  184, 1240,   37,   16, 3718,   37,  260,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4695, 1130, 2284,  981, 4438, 2976,   32,    9,  151,  423,   45,
           35,  806,  411, 3902, 1486, 2730,   16,  702,    4, 6993,   16,  845,
          258,  544, 1294,   61, 4184,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92, 5272,  263, 2756,    4,  136,    9,   58,  808, 1130,  382,
         2777,  332,    4,  798,  332,    4,   74, 2606,  316,   14, 2798, 7383,
            4, 2833,  316,   52,  331, 3177, 4551, 1023,  119,    4, 4824,  314,
         2057, 1229,  578,   42,    1,    1,    1,    1,    1,    1],
        [   2, 1061,  895,  852,   27, 1162, 2407,  974,   22,  724, 1063, 3036,
          167,  112,   30, 1735,   38, 1344,  551, 2256,  197,  939, 3176,  247,
          718,   18,  721,  834, 6826,    4,   78,  495,   40, 3786,   96, 1735,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7')}, 'transcript': {'tokens': tensor([[   7,  744,  279,   24,  296,   10,   87,   26,   24,  296,   10,  116,
          274,  270,   85,  138, 1019,   24,   66,  367,    9,  860,   13, 1706,
         2760,   12,  183,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [1250,    4,   33, 2285, 4328, 1066, 1588,   26, 7201, 6164,  111,  106,
            7, 4506,    6,   12,   91, 1390,    8,  486,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  225,  144, 5544,  156,  248, 3805,   96,   12,   17, 1665, 1546,
         2658,   85,    7, 4468, 1949,   20,   15, 4657,    4,    8,   19,  641,
            4,  148,   73,  203,    6,  365,   17, 1665, 1546, 2658,    4,  230,
           42,    2,    1,    1,    1,    1,    1,    1],
        [  67,   21,   11,    6,  528,   10,  135,   17,    7,  775,  340,  265,
           59,  639, 2700,  170,   13, 3550,   10,  229,  860, 2317,    4, 1042,
           17, 2410, 2882, 2875,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  25,  135,   21,    4,   19,  135,   21,    4,   67,  339,   11,    6,
           86, 3301,  108,  183,  952,   80,  117, 4113,    6,  125,   24,   11,
          158, 1744,   77,  383,  168,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  79,   19,   34, 1009,   33,  672,    4,   19,  474,   10, 1222,    4,
           38,    6, 1049,  111,   19,   11,   45,   86,    7,  288, 1300,   10,
           66,   10,   66,  595,  121,   48,  126,   13,  672,   55,  284,  447,
          137,   29,   19,  323,  185, 1221,    5,    2],
        [ 238,    4,   70,   19,  465,   11,   18,  135,   34,    4,    8,   70,
           24,  591,  126,   34,   46,  117, 1816,    4,   53,   73,   11,   18,
          276,  100,  456,   10,  545,  218,  850,  251, 3530,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 168,   11,    6,  248, 5558,  148,   11,  121,  492, 1346,   12, 4617,
          140,  297,   48,   11,    6, 6731, 1850, 5366,   46,  465,   11,   18,
          135,   21,   34, 3756,   10, 1051,  416,  436,    4,    8,   53,   11,
           57, 1948,  893,   69,   71,   21,    5,    2],
        [   8,   24,  162,  116, 3221,   54,  333, 3763,    4, 6316,   54,   17,
            7, 7755,  169, 2215,  540,    4,  166,    4, 6667,  111,    4,   21,
          323,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   33,   26, 4803, 4405, 3726, 3395,  373,  148, 2456,  346,   55,
           91, 3350,   71,   13, 1365,    8,  884,  267,   80,  939,  560,  834,
         4460, 1261,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  564,  957,  584,    4,   84,   34,  172,   13, 1361,   12, 1075,
          168,   17,   34, 4174, 1181, 1075,    4,    8,   53,  144,  822, 3373,
            8,  535,  931,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 131,    7,  207,    4,  276,  103,   24,   66,   33, 6270,    4, 1440,
           56, 9552, 1155,   56, 9272,    7,  179,    4,   84,   11,    6, 1220,
           13,  524,   44,  347,  568, 1440, 1620,   42,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  33, 2220,   11,   18,  116,  229,  170,   13,  143, 3150,  753,    5,
           21,  169,  113,  229,  170,   13,  143, 3718,    8,  116,   91,    4,
          593,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24,  205,  126,   55,   80,  785, 1345,  333, 4267,    9,   13,
          423,   35, 2404, 2562, 3902, 1486,    4,    8,   24,  618,    4, 2544,
            8,  283,   85, 1580,   55, 2168,   85,   13,  183,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   17, 2728,  172, 6478,    4,   67,    9,    7,  473,  785,  109,
          392,  215,    4,   66,   84,  226,  185, 4012,   17,  103,   25,   11,
           48,  442,   13,  341, 3486,    4,  155,  282,  169,   51, 1501,  341,
           42,    2,    1,    1,    1,    1,    1,    1],
        [  29,  168,   26,  384,  221,  101,   22,  724, 1339, 3036,    9, 1061,
          895,  852,    4,  148,   34,  133, 5988,   17,   38, 1344,  551, 2256,
          197,   26,  172,   13, 4416, 1455,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:7'), 'cluster_tokens': tensor([[37, 24, 50, 38, 49, 37, 85, 85, 38, 49, 37, 83, 59, 37, 37, 37, 83, 38,
         85, 85, 37, 83, 37,  2, 23, 37, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 37,  2, 28, 47, 32, 85, 49,  2, 83, 37, 37, 36, 37, 37, 50,  9,
         37, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 38, 35, 34,  9, 77, 37, 37, 38, 38, 35, 37, 37,  9, 35, 77,
         77, 94, 11, 37, 38, 88, 11, 50,  6, 38, 37, 35, 37, 38, 38, 35, 11, 37,
         11, 83, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37,  2, 37, 59, 37, 37, 38, 35, 35, 35, 94, 88, 37, 37, 32,
         37, 49, 83, 56, 11, 83, 37, 32, 85, 31, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 59, 37, 11, 38, 59, 37, 11, 37, 49, 85, 37, 83, 29, 37, 24, 16, 37,
         37, 32, 37, 37, 38, 85, 35, 49, 50, 24, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 49, 37,  9, 11, 38, 31, 37, 37, 11, 38, 37, 77, 83, 38, 85,
         35, 83, 37, 83,  9, 37, 85, 37, 85,  9, 35, 31, 37, 37,  9, 37, 37, 37,
         11, 83, 38, 85, 50, 94, 11, 83],
        [83, 11, 50, 38, 85, 85, 35, 59, 85, 11, 37, 50, 38, 31, 37, 85, 11, 37,
         56, 11, 37,  6, 85, 35, 83, 37, 16, 37, 50, 50, 37, 50, 56, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 34, 56, 50, 85, 35, 50, 59, 37, 38, 35, 35, 31, 85, 37,  4,
         38, 35, 11, 85, 85, 35, 59, 37, 85,  6, 37, 38, 35, 77, 11, 37, 37, 85,
         77, 83, 49, 37, 37, 37, 11, 83],
        [37, 38, 85, 83, 29, 49, 50,  9, 11, 32, 49, 37, 37,  9, 85, 49, 36, 11,
         37, 11,  2, 83, 11, 37, 85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 83, 20, 28, 16, 56, 50, 38, 37, 37, 50, 24, 37, 37, 94, 37,
         88, 37, 37, 38, 35, 11, 94, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 34, 73, 73, 11, 37, 85, 83, 37, 94, 37, 56, 37, 37, 85, 28, 31, 56,
         11, 37, 37, 85,  2, 56, 37, 83, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83, 11, 83, 37, 38, 85, 37, 94, 11,  9, 38, 83, 50, 38, 83, 37,
         94, 11, 37, 85, 37, 83, 37, 32, 82, 83, 85,  9, 85, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 85, 35, 83, 49, 37, 37, 50,  2,  9, 11, 37, 85, 83, 49, 37, 37,
         50,  2, 37, 83, 50, 11, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 85, 37, 37, 37, 34, 24, 50, 24, 37, 37, 34, 38, 23, 94, 35, 35,
         11, 37, 38, 49, 11,  9, 37, 49, 37,  9, 37, 24, 37, 37, 24, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 56, 83,  2, 11, 37, 37, 37, 37, 34, 37, 17, 24, 11, 85, 37, 85,
         50, 56, 37, 37, 37, 85, 31, 31, 37, 33, 94, 11, 37, 32, 85, 38, 83, 33,
         11, 83, 37, 37, 37, 37, 37, 37],
        [83, 37, 85, 38, 35, 38, 35, 35, 38, 35, 37, 84, 73, 73, 11, 50, 85, 83,
          2, 37, 38, 77, 69, 94, 82, 85, 83, 37,  2, 32, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:7'), 'lengths': tensor([29, 22, 38, 30, 31, 44, 35, 44, 27, 28, 29, 33, 27, 35, 38, 32],
       device='cuda:7'), 'ntokens': 522}, 'target': tensor([[ 146, 2155,  997,    4,   14,   32,  260,  309,    4,   27,  317,   40,
         1857, 2664,   61,   30,    4,   34,   32,    9,  141,   29, 1489,   15,
          259, 4261,   20, 1517, 2505,   83,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [6703, 2173,  398,   30, 4153,  938,  158,  975,  673, 7277, 9073,   98,
           58, 5801,   15,   23, 3852, 4321,  410, 1929,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   43,  280,  302, 4612,  152,    6,   37,   49,  328, 6241, 1092,
          527,   61,   23, 7629,  533,   15, 3134,   93,  175, 5189,  861,    4,
           16, 1513,  145,  328, 1092,  527,  433, 2995, 3094,   42,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [5939,   28,  320,   27,  136,    4,   50,   14,  559, 1018,  992,  360,
          754, 1018,   35, 8809,   40, 4625,   78, 1973, 5942,   15,   27,    4,
           29, 3290,   32,  299, 1281,   83,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  41,  320,   36,    4,   31, 5751,   36,    4,  136,   32,  776,  286,
          259, 3645,    4,  273,  259,    4,  112,  105, 2692,   28,  843,    4,
          428,   32,  681,   58, 1083,  623,  385, 4583,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 520,   31,  337, 2758, 3371,   20,    4,  915,   31,  198,   44,   38,
          360, 1328,   37,  313,   31,   47,   23, 1542,  919,    4,   23,   75,
          118, 1876,   78,   75,  363, 1205, 1398,  137,  298,  209,   31,   40,
         1538,  182,  247, 1865,  243,   18,    5,    2,    1,    1],
        [ 526,    4,   34,   31,   47, 1904,    4,   16,   34,   32, 8722,   15,
            4,   82,   46,  105,  310,    4,   43,  123,  410,  337,  840, 3218,
           22,   47,  594,   29,  190,   74, 2630, 1561,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 504,   76,  302, 6776,    4,   14,  632,  190,   49,  330, 4436,  297,
           48,    6, 3492,  158,  356,   15, 7988, 1353,   45, 1388,   83,    4,
           14,   47, 3417,    4,   50,   81,   36,   47, 5437,  666,    4,   16,
           14,   30, 3776,  485,  414,  548, 4602,   15,    5,    2],
        [ 104,   83,   14, 8875, 6363,   16, 4870,  153,   18,    4,   50,   23,
         4066,  399, 1564,  354,    4,   16,   56, 8081, 2607,   95,   30,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   30,   76, 1128, 6323, 1283, 6589, 6948,   37,    4,   14,   75,
           52, 4367, 1099,   60,  141, 1044,  548, 2387,   16,   43,   28,  805,
         4444, 1098,  365,  240,  390,   51, 6152,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  564,  957,  584,  573,   36,  263,   52, 2557,   49, 2499,  173,
            5,   92,  319, 3830, 5092,   60,  953, 2165,   16,  151, 4842,  314,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [8727,    4,  363,  114,   32,  105, 7095,  940,    4,  113, 1673,   56,
         9552, 1348,    6,   56, 9272,   14,  201,    4,  178,   36,  139,  433,
           40,  496,   44, 1135, 3875, 1673,   42,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92,  354,   75,   47,  149, 8399,   61,  654,  643,   98, 5404,    4,
          519,  273, 1521,  184, 1240,   37,   16, 3718,   37,  260,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [4695, 1130, 2284,  981, 4438, 2976,   32,    9,  151,  423,   45,   35,
          806,  411, 3902, 1486, 2730,   16,  702,    4, 6993,   16,  845,  258,
          544, 1294,   61, 4184,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92, 5272,  263, 2756,    4,  136,    9,   58,  808, 1130,  382, 2777,
          332,    4,  798,  332,    4,   74, 2606,  316,   14, 2798, 7383,    4,
         2833,  316,   52,  331, 3177, 4551, 1023,  119,    4, 4824,  314, 2057,
         1229,  578,   42,    2,    1,    1,    1,    1,    1,    1],
        [1061,  895,  852,   27, 1162, 2407,  974,   22,  724, 1063, 3036,  167,
          112,   30, 1735,   38, 1344,  551, 2256,  197,  939, 3176,  247,  718,
           18,  721,  834, 6826,    4,   78,  495,   40, 3786,   96, 1735,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'target_lengths': tensor([32, 22, 35, 32, 34, 44, 34, 46, 25, 33, 26, 32, 24, 30, 40, 37],
       device='cuda:7'), 'ntokens': 526, 'nsentences': 16}
##################### {'id': tensor([170328,  84442,  40213,  94867,  69393,  49686, 192789, 134192,  39078,
        199114, 180483,  31005,  69166,  91536, 208978, 123081,  52724,  80734,
         70021, 128348, 108830,  50861, 122570,  95557, 184707, 152049,  39665,
        208413, 127976,  68658, 184892, 208957], device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 4.5776e-04, -1.8311e-04,  2.4414e-04,  ...,  4.2419e-03,
          3.1128e-03,  2.5024e-03],
        [ 1.3733e-03,  1.6785e-03,  1.3123e-03,  ..., -3.9825e-02,
         -4.1199e-02, -4.6600e-02],
        [ 3.6011e-03,  3.2043e-03,  4.6387e-03,  ..., -1.9531e-03,
         -2.0142e-03, -1.1292e-03],
        ...,
        [-7.6294e-04, -7.9346e-04, -1.1292e-03,  ...,  1.8005e-03,
          1.7395e-03,  0.0000e+00],
        [ 7.9041e-03,  6.4697e-03,  5.0354e-03,  ...,  7.6294e-04,
          9.1553e-04,  0.0000e+00],
        [-3.0518e-05, -3.0518e-05, -6.1035e-05,  ..., -3.4790e-03,
          8.0566e-03,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800,
        64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800,
        64800, 64800, 64800, 64800, 64800, 64800, 64800, 64800, 64799, 64799,
        64799, 64799], device='cuda:0'), 'prev_output_tokens': tensor([[   2, 1414,   97, 7881, 1548,   76, 1134,  152,  191,   52,  350,  243,
          200, 4171,   49,  259,   16,  972,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  504,  605,   41,   14,  217, 1013,  381, 7509, 2335, 2580, 1928,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   41, 3251,  191,  534,    4,   50,  295, 4496, 9603,   20,   14,
         6540,   35,  360,  511,  200,  960,   45,   37,  319,    5,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 1419,   41,   75,  363,    4,  403,  299, 1444,   75, 8273, 5630,
          171, 4065,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  928,  309, 2087,   14, 5458,  253, 3606,  272,  141, 4046, 1521,
         4425,  127,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  147,   32,  459,  241, 3319,  191,   16, 2512,   15,  847, 1577,
          936, 6156,    6,    4,  317,   88,  190,   78,   30, 8957,   28,   83,
            5,    1,    1,    1,    1,    1],
        [   2,  312,  579, 2203, 1140,  819,  620, 2435,   57, 1172,    4, 8778,
           23, 1840, 3964,   22,   16, 2316, 1098,  219,  530,   37,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64, 3361, 3391,   75,   30,  167, 4661,   39,    4,  167, 3919,
          849,    4,  414,  247,   45,  539,   18,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 2640,  113, 2638,  163,    4,  470, 5191,   15,   60, 4395,    4,
           16,   30, 4284,   31, 1892,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64,  921,   27,   36,   47, 1279,    4,   88,   58, 6281,   22,
           23,  157,   16,  628,   23, 2089,  184, 1240,   28,  127,    4,   14,
           14,  157, 4095,    5,    1,    1],
        [   2, 6377, 1697,   45,  356,  610,   16, 1097,  158,  494,  272,   60,
         3259, 3985,   15, 4523,   22,  427, 4367,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  202,  573,   58,  674,  683, 1324,   14, 9609,    4,  105, 2030,
           28,  260,    4,   16,   43, 3417,    4,   50, 1844, 2691,    9,   30,
          350, 3688, 4254, 1126,  354,    5],
        [   2,  104,   83,   58, 1627,  515,  304, 1675,  412,  530,    9, 1299,
           49, 3672,   45,  973,   16,  349,   96,  699,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,  471,  612, 2097,  356, 7503,   60, 1309,  870,  588,    5,
          104,  471,   52,  435, 1309,  870,   45,   35, 8009,  174, 3165, 8001,
         1302,    5,    1,    1,    1,    1],
        [   2,  396, 1022,  122,  620,   18,  412,    6,   83,   75,   90,  475,
           37, 1476,    6, 1900, 2763,   20,   95, 3678,    6,   15,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  520,   31,   43, 2638,    4,   14,  392, 9407,    6, 3283,  466,
          425, 2843,    4, 2997,   36,   75,  470, 2177,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  312,  919,   56, 2478,   18,    4,   38, 5799,  543,  501,    6,
          791,  300, 2236,  146, 2970,   20,  421,   22,  234,  729,  101,  156,
         2472,    4,    1,    1,    1,    1],
        [   2,  147,   29,   74,   32,   36,    9,   58, 1270, 7912,    4, 5920,
           32, 6700,    4,   50,   43,   36,   51, 1471,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 5503,  776,   32,   14, 4762,    6,   15,  233, 7710,  190,  171,
          539, 2616,   15,    4,  189, 7452,   32,   30,  173, 4182,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64,  863, 3277, 3130,   75,   14,  751, 8333,   98,  337, 1280,
         3055, 3438,   15,  466,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  228,   23, 2500,    4,  123,   43, 4861,   14, 1725,  181,   57,
         1090,   22,  195,    4,   14,  577,  533, 1895,    4,   16, 6077,   14,
         5102, 1669,    5,    1,    1,    1],
        [   2,   92,   76,   14, 3427, 1268,  343,  423,    5, 7456,    4,   38,
         3306, 3282,  317,   29,  306,  197,  707,   38,    6, 3366,    4,   74,
           36, 3386,  178,    5,    1,    1],
        [   2,   64,  686, 1697, 1304,   49,   23, 3063,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   41,   76,  714, 1756,  195,  763,  398,    4,   75,   49,  141,
         7973,   28,   95, 5391,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  376,  507,   35,   16, 4994,  174, 3886,  212, 2863, 9127,   75,
           47,  149,   61,   14, 1270,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92, 1138,   20, 2316,    6,  713,   49, 1207, 1801,  399,  634,
           56, 1304, 1779,   75,    9, 5839,   22,   88,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64,   30,  161,   78,   14, 2309,   23, 1092,  614, 1315,   15,
         2834,  186,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 2235, 2674,   27,   36,    4,   14, 8535,   15, 2369, 6280,   15,
           16,   43,   28,   56,  530, 3322,  357,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  633,  105, 1419,  173, 6426,  355,  286, 1463, 1152,    4,  255,
           43, 7020,   76,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 3219,   22, 1327,  311, 1353,   27, 1246,  406, 3858,  174,  426,
            6, 1514,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   27, 5025,   23,  734,    4,  782, 3199,   37,  182,   18,
            6,  286, 4204,  119,  216,  253,  576,  983,   83,    5,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  146, 3224,   59,   37, 4352,   15, 6468,  223, 2029,   15, 4383,
           16, 6421, 2002,   15,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[ 276,   85,   21,    6,  772,    4,   14,  945,   26,   13, 3301,   12,
          183,    8,  941,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  33,   26,  206,   25,   11,  158,  446,    7,  743,  608, 2288,  963,
         1682,    6,   12,    7,  179,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  53,  162,  952,   80,  138,  159, 2911, 2232,    6,  162,    7, 4601,
         3839, 7101,    6,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 884, 1835,    4,   26,   33, 1484,   51,  176, 6868,    9,   13,  837,
          111, 5555,  207,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  67,   12,  538,    7, 3487,   26,   10,  719,    7, 4140,   17,  229,
           17,  913, 1504,  283,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  67,   24,  619, 1771,   12, 7808,    6,    8, 1706, 4562,    6,    5,
           24, 1223,  388,  250,  540,   10,  175,  359,    7, 3321,    5,    2,
            1,    1,    1,    1,    1,    1,    1],
        [  29,   55,  663,    4,  305, 2101,  901,   48,  494,    6,    4,  166,
           63, 5955,    6,   12,  775, 1026,  307,    6,    8, 6012, 3430,  737,
            6,    5,    2,    1,    1,    1,    1],
        [   8,   85,  245,   17, 2728,  133, 2292,    4,  133,   51,   22,  236,
           22,    4,  238,   35,  160,  191,   48,   62,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 115,    4, 3108,  323,  884,  110,   10,  875,  185, 4233,    6,   71,
          110,    4,   29,   19,   11,  121,  691,   17,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  67,   17,   26, 3761,    9, 9192,   10, 3536,    7, 1833,   12,    7,
           94,    8, 3536,    7, 1833,   12,    7, 1075,   17,   63, 1766,   54,
            7,   94,    5,    2,    1,    1,    1],
        [6508,  110,   59,  247,    4,   53,  415,  158, 1515,   85, 2386,   12,
         1655,   12, 2602,  690, 3350,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 101, 1742,    7, 7037,    6,  690, 2921,   10,   87,  251,  214,    4,
            8,   53, 1425, 2684,   34,  700,  142,   10,  367,  346,   10,   17,
          316,   22,  247,  399,    5,    2,    1],
        [  24,   66,    7, 3212, 1116,   59, 6729, 1116,   18,    9,    7,  774,
           12,   56, 2561,   45,  973,    8, 2076,    6,  699,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  24,  144,  203,  372,   93, 3753,    6,   71,  521,  870,   45,    6,
            4,   24,  144,  708,   11,    6,  521,  870,   45,   35,  174, 3007,
           54, 8823, 2419,    5,    2,    1,    1],
        [  33, 1103,  620,   18,  412, 1181, 3135, 1144, 4075,   48,   10,   51,
           13,  830, 1409, 2158,  909,  140,  234,    6,  240,   12,   82,    5,
            2,    1,    1,    1,    1,    1,    1],
        [   8,  120,   19, 1060,  134,   10, 3720,   45,  293, 1115,    7,  392,
         1366,  456,    6,   85,    7,  370,  183,    4,  185,  842,    7, 1829,
         7018,  126,    5,    2,    1,    1,    1],
        [  13,   81, 2951, 2611,   54,    4,   38, 1098,  387,  132, 2236,    7,
         2918,    6, 2084,  480, 3358,  227,   22,  293,  810,    4,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  33,   26,  113,  250,   17,    4,    7,  207,   24, 2572,   21,    9,
            7,  832,    5,    6,    5,   77,   67, 8711,    6,   53, 1704,   11,
           18,  203,   18, 1617,   21,    5,    2],
        [ 238,    4,  339,   11,    6,  245,   12,   77, 1487,  362,  297,  181,
           93,    7, 2154,    6,   96, 7223,    4,  229,    7,  279,   69,    7,
          230,    5,    2,    1,    1,    1,    1],
        [   8,  976, 2392,    7,  733, 1682,   26,  204, 1661,  794,   62,   12,
          117,  264, 1629, 3438,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 204,    4,   25,   73,  113,  468,    7,  664,   57, 1090,   22, 1255,
           12,    7, 1404, 1028,  126,    8, 4547,    7, 4157,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  33,   26,   91,  359,  423,    5,  558,    4,   38,  469,   93,  116,
          508,   25,   79,  294, 1267,   11,    6,   79,   84,   63, 2672,    6,
            5,    2,    1,    1,    1,    1,    1],
        [   8, 1308, 4606,   62,  106,    7, 2291,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  53,   11,   57, 2770,   10, 4971,  106,   39, 9028,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   7,  368,    6,    8, 6440,    6,   12,   33,  639, 2924,   11,   18,
         5985,   10,    7, 1384, 1224,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   7, 4690, 6012,  713,    6,   12, 3861, 6106,   22,  407,   63, 5413,
           10, 4987,   79,   25,  150,  168,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   8,   17,   11,    6,  142,   10,   51, 8791,   55,    7, 2340,   12,
            7,   29,  614, 1315,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 108, 1329,   26,   10, 2213,    7, 7175, 1649,    8, 2270,  121,  244,
          134,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  24,   11,   57,  142,   10, 2238,   69, 1532,  206,   25,   73,   11,
           18, 1082,    7, 4548,  125,   53,   11,   57, 7449,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [5590, 1327,  311, 1353,   26,  914,   91,   12,   89,  772,  694, 3781,
            4,   89, 2911,   91,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  19,   11,   48,  100,   10,  154,   17,   11,    6,  347, 8371,    6,
          192,   11,   18,  172, 1102,   37,  142,   69, 1303,    6,  126, 3903,
            5,    2,    1,    1,    1,    1,    1],
        [7723,   22,    6,   66, 6107,    7, 9589,   12,  985, 3585,    8, 4927,
         3295,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[83, 37, 37, 37, 75, 11, 38, 77, 85, 37, 29, 37, 24, 37, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 85, 35, 59, 37, 83, 75, 49,  2, 23, 37, 37, 37, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 16, 37, 37, 37, 32,  9, 37, 85, 37,  2,  9,  9, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [88, 37, 11, 85, 37, 94, 38, 35, 49, 37, 37, 28, 83,  2, 83, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83, 37, 94, 85, 37, 49, 37, 56, 37, 49, 37, 28, 94, 49, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 50, 37, 29, 37, 37,  2, 35, 37, 11, 38, 83, 31, 50, 36, 37,
         85, 37, 37, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 32, 11, 49, 38, 35, 31, 35, 37, 11, 37, 85, 36, 37, 37, 38, 35,
         77, 37, 37,  9, 35, 35, 37, 11, 83, 37, 37, 37, 37],
        [37, 37, 83, 37, 56, 83,  2, 11, 83, 38, 35, 35, 35, 11, 83, 38, 35, 77,
         31, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 28, 85, 88, 37, 37, 49, 50, 28, 37, 37, 37, 11, 83, 38, 85, 35,
         31, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 83, 37,  2, 37, 16, 37, 56, 37, 37, 56, 37, 16, 37, 56, 37,
         37, 56, 37, 85, 49, 49, 37, 56, 11, 83, 37, 37, 37],
        [56, 37, 35, 77, 11, 37, 38, 35, 92, 37, 34, 37, 24, 37, 24, 38, 24, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 37,  9, 37, 38, 94, 37, 85, 50, 56, 11, 37, 37, 31, 50, 85, 50,
         49, 37, 85, 37, 37, 37, 38, 35, 77, 35, 11, 83, 37],
        [38, 85, 37, 28, 38, 35, 35, 38, 35, 37, 37, 38, 37, 38, 35, 35, 35, 37,
         38, 37, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 38, 35, 35, 28, 37, 37, 38, 35, 35, 37, 11, 38, 85, 56, 85, 37,
         38, 35, 35, 38, 35, 35, 49, 32, 35, 11, 83, 37, 37],
        [37, 38, 77, 35, 35, 31, 28, 32, 88, 31, 37, 38, 37, 62, 35, 77, 38, 35,
         35, 37, 35, 37, 53, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 31, 37, 37, 38, 35, 35, 37, 37, 17, 28, 16, 37, 37, 37,  4,
         24, 11, 50, 31, 37,  2, 94, 37, 11, 83, 37, 37, 37],
        [37, 38, 38, 35, 49, 11, 38, 35, 35, 37, 11, 37,  9, 37, 38, 35, 83, 38,
         35, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83, 50, 37, 11, 37, 83, 38, 88, 37, 37, 37, 38, 11, 37, 11, 50,
         37, 88, 37, 37, 31, 85, 35, 38, 35, 35, 37, 11, 83],
        [83, 11, 49, 85, 37, 83, 37, 50, 38, 35, 35, 35, 35, 37, 38, 37, 77, 94,
         11, 49, 37, 50, 37, 37, 37, 11, 83, 37, 37, 37, 37],
        [37, 83, 83, 37, 50, 23, 85, 83, 36, 35, 31, 37, 37,  2, 38, 32, 37, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 37,  6, 83, 29, 37, 38, 77, 35, 35, 35, 37, 37, 94, 49, 37, 37,
          6, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 50, 37, 34, 11, 37, 11, 38, 35, 35, 83, 88, 37, 37, 50, 38, 85,
         37, 37, 37, 85, 94, 37, 11, 83, 37, 37, 37, 37, 37],
        [37, 50, 29, 31, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 77, 31, 37, 29, 37, 38, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 49, 37, 37, 29, 37, 37, 37, 94, 85, 85, 35,  5, 37, 37, 31, 56, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  2,  9, 35, 37, 37, 38, 35, 35, 35, 85, 40, 37, 94, 37, 37, 59, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 49, 37, 38,  2, 37, 37, 94, 37, 37, 83, 35, 35, 37, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 85, 37, 49, 37,  2, 50, 37, 38, 35, 37, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 77, 49, 37, 29, 37, 56, 37, 37,  6, 85, 35, 59, 37, 56, 37, 37,
         85, 77,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 35, 35, 85, 83, 50, 37, 37, 75, 32, 56, 11, 37, 32, 50, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 31, 37, 37, 59, 37, 85, 37, 83, 28, 37, 85, 85, 35, 83, 83, 77,
         49, 37, 24, 37, 37, 83, 11, 83, 37, 37, 37, 37, 37],
        [28, 35, 37, 85, 31, 37,  9, 37,  2,  9, 37,  2, 56, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([17, 19, 17, 17, 18, 24, 27, 22, 22, 28, 19, 30, 23, 29, 25, 28, 23, 31,
        27, 19, 23, 26,  9, 11, 19, 20, 19, 15, 23, 18, 26, 15],
       device='cuda:0'), 'ntokens': 689}, 'target': tensor([[1414,   97, 7881, 1548,   76, 1134,  152,  191,   52,  350,  243,  200,
         4171,   49,  259,   16,  972,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 504,  605,   41,   14,  217, 1013,  381, 7509, 2335, 2580, 1928,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  41, 3251,  191,  534,    4,   50,  295, 4496, 9603,   20,   14, 6540,
           35,  360,  511,  200,  960,   45,   37,  319,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [1419,   41,   75,  363,    4,  403,  299, 1444,   75, 8273, 5630,  171,
         4065,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 928,  309, 2087,   14, 5458,  253, 3606,  272,  141, 4046, 1521, 4425,
          127,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 147,   32,  459,  241, 3319,  191,   16, 2512,   15,  847, 1577,  936,
         6156,    6,    4,  317,   88,  190,   78,   30, 8957,   28,   83,    5,
            2,    1,    1,    1,    1,    1],
        [ 312,  579, 2203, 1140,  819,  620, 2435,   57, 1172,    4, 8778,   23,
         1840, 3964,   22,   16, 2316, 1098,  219,  530,   37,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [  64, 3361, 3391,   75,   30,  167, 4661,   39,    4,  167, 3919,  849,
            4,  414,  247,   45,  539,   18,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2640,  113, 2638,  163,    4,  470, 5191,   15,   60, 4395,    4,   16,
           30, 4284,   31, 1892,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  64,  921,   27,   36,   47, 1279,    4,   88,   58, 6281,   22,   23,
          157,   16,  628,   23, 2089,  184, 1240,   28,  127,    4,   14,   14,
          157, 4095,    5,    2,    1,    1],
        [6377, 1697,   45,  356,  610,   16, 1097,  158,  494,  272,   60, 3259,
         3985,   15, 4523,   22,  427, 4367,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 202,  573,   58,  674,  683, 1324,   14, 9609,    4,  105, 2030,   28,
          260,    4,   16,   43, 3417,    4,   50, 1844, 2691,    9,   30,  350,
         3688, 4254, 1126,  354,    5,    2],
        [ 104,   83,   58, 1627,  515,  304, 1675,  412,  530,    9, 1299,   49,
         3672,   45,  973,   16,  349,   96,  699,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,  471,  612, 2097,  356, 7503,   60, 1309,  870,  588,    5,  104,
          471,   52,  435, 1309,  870,   45,   35, 8009,  174, 3165, 8001, 1302,
            5,    2,    1,    1,    1,    1],
        [ 396, 1022,  122,  620,   18,  412,    6,   83,   75,   90,  475,   37,
         1476,    6, 1900, 2763,   20,   95, 3678,    6,   15,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 520,   31,   43, 2638,    4,   14,  392, 9407,    6, 3283,  466,  425,
         2843,    4, 2997,   36,   75,  470, 2177,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 312,  919,   56, 2478,   18,    4,   38, 5799,  543,  501,    6,  791,
          300, 2236,  146, 2970,   20,  421,   22,  234,  729,  101,  156, 2472,
            4,    2,    1,    1,    1,    1],
        [ 147,   29,   74,   32,   36,    9,   58, 1270, 7912,    4, 5920,   32,
         6700,    4,   50,   43,   36,   51, 1471,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [5503,  776,   32,   14, 4762,    6,   15,  233, 7710,  190,  171,  539,
         2616,   15,    4,  189, 7452,   32,   30,  173, 4182,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [  64,  863, 3277, 3130,   75,   14,  751, 8333,   98,  337, 1280, 3055,
         3438,   15,  466,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 228,   23, 2500,    4,  123,   43, 4861,   14, 1725,  181,   57, 1090,
           22,  195,    4,   14,  577,  533, 1895,    4,   16, 6077,   14, 5102,
         1669,    5,    2,    1,    1,    1],
        [  92,   76,   14, 3427, 1268,  343,  423,    5, 7456,    4,   38, 3306,
         3282,  317,   29,  306,  197,  707,   38,    6, 3366,    4,   74,   36,
         3386,  178,    5,    2,    1,    1],
        [  64,  686, 1697, 1304,   49,   23, 3063,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  41,   76,  714, 1756,  195,  763,  398,    4,   75,   49,  141, 7973,
           28,   95, 5391,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 376,  507,   35,   16, 4994,  174, 3886,  212, 2863, 9127,   75,   47,
          149,   61,   14, 1270,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92, 1138,   20, 2316,    6,  713,   49, 1207, 1801,  399,  634,   56,
         1304, 1779,   75,    9, 5839,   22,   88,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  64,   30,  161,   78,   14, 2309,   23, 1092,  614, 1315,   15, 2834,
          186,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2235, 2674,   27,   36,    4,   14, 8535,   15, 2369, 6280,   15,   16,
           43,   28,   56,  530, 3322,  357,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 633,  105, 1419,  173, 6426,  355,  286, 1463, 1152,    4,  255,   43,
         7020,   76,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [3219,   22, 1327,  311, 1353,   27, 1246,  406, 3858,  174,  426,    6,
         1514,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   27, 5025,   23,  734,    4,  782, 3199,   37,  182,   18,    6,
          286, 4204,  119,  216,  253,  576,  983,   83,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 146, 3224,   59,   37, 4352,   15, 6468,  223, 2029,   15, 4383,   16,
         6421, 2002,   15,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([19, 13, 22, 15, 15, 25, 23, 20, 18, 28, 20, 30, 21, 26, 23, 21, 26, 21,
        23, 17, 27, 28,  9, 17, 18, 21, 15, 20, 16, 15, 22, 17],
       device='cuda:0'), 'ntokens': 651, 'nsentences': 32}
##################### {'id': tensor([ 78330,  70600,  70340,  25837, 110492,  55336, 102072, 174422],
       device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 0.0065,  0.0055,  0.0029,  ..., -0.0009, -0.0002,  0.0002],
        [-0.0030, -0.0040, -0.0040,  ...,  0.0095,  0.0108, -0.0014],
        [-0.0014, -0.0010, -0.0084,  ..., -0.0141, -0.0121, -0.0101],
        ...,
        [ 0.0584,  0.0806,  0.0759,  ..., -0.0108, -0.0132, -0.0139],
        [-0.0008, -0.0010, -0.0007,  ...,  0.0005,  0.0007,  0.0000],
        [-0.0005, -0.0013, -0.0023,  ..., -0.0114, -0.0144,  0.0000]],
       device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([173280, 173280, 173280, 173280, 173280, 173280, 173279, 173279],
       device='cuda:1'), 'prev_output_tokens': tensor([[   2,   72,   82, 2733,   39,   23,  796,  129,   11, 1135,  501,  569,
           11,  400,  501,    5,   72,  666,   52,  585,  489,    4,   52,  585,
         5174,  165,    9,   23, 1407, 4056,   16,   52,  585, 5174,  165,    9,
           23,  201, 2489,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  750,  129, 2111,    6,  280,   31,   30, 1550,    4,  393,
            9, 4559,   28,  186,    4, 1096, 9452,   60,  151, 3624,   98,   23,
         4097,  124,  151, 4917, 6924,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   43, 1204,  163,   39,    4,   16,   36,   82,   74,   40,
         2717,   96, 2118,   48, 1188,   15,    4,   16, 2844, 7819,   20,   43,
          198,  118, 4632,   15, 5925,   49, 1474,  314,    4,   74,   36,  263,
           82,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104,  605,  231, 1468,   49, 3710,  173,   14,   40, 2155,    6,
         8986, 5138,   83,  124,   40, 3809,    6,   49, 4048,  560,    4, 1210,
          642, 5718, 4592,  365,  678,   15,    9,  149,  141, 5485,   28,  141,
         3710, 8269,   48,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  915,   44,   38, 3437,  161,   30, 2281,  493, 1145,   39,
          493,  285,   37,   48, 1597, 2655,  358,   72, 1398,   60,  493, 4452,
          466, 3957,   15,   16,  355,  334,   44,   38,  360,  287,  745,   36,
           98,  137, 1001, 2441,   82,  210,  355,    5,    1,    1,    1],
        [   2,  928,  915,   31,    4, 3458, 3458,    4,   31,  769,  255,  317,
          846, 1169,  537,   16,   31,  363,  186,   16,   29,  843,    4,   74,
           31,  263, 4864,    4,  428, 8494,   27,   14,    6,   14, 3276,   20,
         1442,  176,  219,  158,  165,    5,    1,    1,    1,    1,    1],
        [   2, 6041, 6995,   14, 2530,    4,   50,   31,  163,   47, 2600, 4320,
           39,   14, 2225,   23, 2910,   20,   16, 4754, 3215,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2773, 1204,   36,   98,    4,   90, 1602, 2656,   45,  240,  352,
          156,  152,  241,  181,   37,   49,   23, 4649,  407, 4873, 1027,  764,
         1966,  589,  355, 2457, 3588, 2757,    4,   16,  764, 1966,  589, 1023,
         1121,   44,   38, 2759,  940,  374,  477,  137,   68,  379,   65]],
       device='cuda:1')}, 'transcript': {'tokens': tensor([[  19,   34, 2091,    9,    7,  479,   12,  347,    8,  138,   19,  220,
          719,   13,  264,  546,    4,   13,  264, 5898,    9,  998, 1261,    8,
           13,  264, 5898,    9,    7,  179,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   8,   79,   24,  162, 5208,    4,   19,  144,    7, 6734, 1790,   17,
           19,   34,  270,    9,    7,  942,   12, 4517,    4, 1057, 5826,   71,
           13, 5996, 2535,   37,  109,   39, 5767,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   8,  225, 1260,   85,  110,    4,    8,   21,   34,  100,    7, 3150,
         1266,   35,  200,   57,  119,  232,    4,    8,  180,    4,  432,   17,
            4,  225, 3067,   62,   39, 3586, 3078,   12,   70,  267,  282,  172,
           34,  100,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  24,  446,   77, 1587,   12, 1369,   17,   66, 1828,  132,   13,  744,
         8452,  109,   13, 1575,   91,  106, 3494,    4,   13, 4999, 1655,   12,
          264, 1420,  235,    6,    9,   13,  744,   10,   17, 1369,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  19,  474,    4,   38, 1871,   11,    6,   89, 1276,   11,    6,  970,
          142,   10,  274,  100,   69,    7,  383,   12,   89, 2079,   37,  128,
          358,   19,  144,   10, 2456,  346,   71,   89, 3636,    8,  289,    4,
           38,  560,   20,   11,    6,    7, 2196,  137,  267, 2988, 6523,   34,
           71,  267,    5,    2],
        [   8,  180,   19,  474,  211,    4,  211,    5,   19,  451,  116,  175,
          132,   84,    8,   51, 1222,    8,  116,  456,    7,  207,   19,  172,
          456,  125,    4,  432,   77,    4,   33,   26,    7,  453,  291,  121,
          233,   54,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  19,  217, 1333,  500, 1011,  131,    7,  409,   17,   19,  211, 1978,
         1008,    7, 1187,    6,   12,    7, 2678,    6,    8,    7, 3833,    6,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   9,  409,    4,   21, 1260,  100,    7, 1719,  589,  207, 1943, 1755,
         2263,   96,  684, 2721,  132,   71,  284, 4709, 1227,    4, 2721,   21,
           10,  144,   59,  589,    4,    8,  144,   59,  589,  246,    4,   38,
          533,   11,  158,  305,   77,   12,   21,  137,   68,  194,   65,    2,
            1,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[38, 85, 32, 37, 37, 94, 37, 83, 37, 37, 38,  6, 49, 37,  2, 18, 11, 37,
          2, 18, 37, 94, 94, 37, 37,  2, 18, 37, 37, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 85, 49, 11, 38, 85, 37, 33, 32, 37, 38, 85, 37, 37, 37, 94,
         37, 28, 11, 49,  9, 37, 37,  9, 94, 77, 37, 38, 28, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 59, 37, 37, 11, 37, 37, 85, 37, 37,  2,  9, 38, 35, 77, 75, 77,
         11, 37, 37, 11, 37, 37, 11, 37, 49, 31, 38,  2, 32, 37, 50, 37, 32, 83,
         85, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 59, 50, 50, 37, 56, 37, 85, 31, 37, 37, 24, 28, 37, 37, 28, 50, 37,
         50, 11, 37, 49, 24, 37,  2, 38, 35, 37, 37, 37, 24, 37, 37, 56, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 11, 38, 83, 85, 37, 37, 94, 85, 37, 32, 49, 37, 59, 37, 37, 37,
         24, 37, 37, 38, 77, 35, 11, 38, 85, 37, 38, 37, 37, 37, 94, 37, 88, 11,
         38, 35, 77, 85, 37, 37, 94, 11, 37,  9, 35, 85, 37, 37, 11, 83],
        [37, 37, 38, 31, 50, 11, 50, 11, 38, 85, 83, 85, 37, 37, 37, 38, 37, 37,
         83, 16, 37, 83, 38, 83, 16, 37, 11, 37, 50, 11, 37, 85, 37,  2, 38, 35,
         35, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 38, 38, 35, 31, 37, 37, 32, 37, 38, 50, 83, 59, 37, 32, 37, 37, 37,
          9, 37, 37, 37, 29, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 11, 37, 59, 37, 37, 38, 35, 83, 38, 77, 38, 77, 35, 88, 37, 37,
         37, 32,  9, 11, 88, 37, 37, 85, 35, 35, 11, 37, 85, 35, 35, 88, 11, 38,
         35, 85, 35, 49, 50, 37, 37, 11, 38,  9, 11, 83, 37, 37, 37, 37]],
       device='cuda:1'), 'lengths': tensor([32, 33, 40, 36, 52, 40, 26, 48], device='cuda:1'), 'ntokens': 307}, 'target': tensor([[  72,   82, 2733,   39,   23,  796,  129,   11, 1135,  501,  569,   11,
          400,  501,    5,   72,  666,   52,  585,  489,    4,   52,  585, 5174,
          165,    9,   23, 1407, 4056,   16,   52,  585, 5174,  165,    9,   23,
          201, 2489,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  64,  750,  129, 2111,    6,  280,   31,   30, 1550,    4,  393,    9,
         4559,   28,  186,    4, 1096, 9452,   60,  151, 3624,   98,   23, 4097,
          124,  151, 4917, 6924,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   43, 1204,  163,   39,    4,   16,   36,   82,   74,   40, 2717,
           96, 2118,   48, 1188,   15,    4,   16, 2844, 7819,   20,   43,  198,
          118, 4632,   15, 5925,   49, 1474,  314,    4,   74,   36,  263,   82,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104,  605,  231, 1468,   49, 3710,  173,   14,   40, 2155,    6, 8986,
         5138,   83,  124,   40, 3809,    6,   49, 4048,  560,    4, 1210,  642,
         5718, 4592,  365,  678,   15,    9,  149,  141, 5485,   28,  141, 3710,
         8269,   48,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  72,  915,   44,   38, 3437,  161,   30, 2281,  493, 1145,   39,  493,
          285,   37,   48, 1597, 2655,  358,   72, 1398,   60,  493, 4452,  466,
         3957,   15,   16,  355,  334,   44,   38,  360,  287,  745,   36,   98,
          137, 1001, 2441,   82,  210,  355,    5,    2,    1,    1,    1],
        [ 928,  915,   31,    4, 3458, 3458,    4,   31,  769,  255,  317,  846,
         1169,  537,   16,   31,  363,  186,   16,   29,  843,    4,   74,   31,
          263, 4864,    4,  428, 8494,   27,   14,    6,   14, 3276,   20, 1442,
          176,  219,  158,  165,    5,    2,    1,    1,    1,    1,    1],
        [6041, 6995,   14, 2530,    4,   50,   31,  163,   47, 2600, 4320,   39,
           14, 2225,   23, 2910,   20,   16, 4754, 3215,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2773, 1204,   36,   98,    4,   90, 1602, 2656,   45,  240,  352,  156,
          152,  241,  181,   37,   49,   23, 4649,  407, 4873, 1027,  764, 1966,
          589,  355, 2457, 3588, 2757,    4,   16,  764, 1966,  589, 1023, 1121,
           44,   38, 2759,  940,  374,  477,  137,   68,  379,   65,    2]],
       device='cuda:1'), 'target_lengths': tensor([40, 30, 38, 40, 44, 42, 22, 47], device='cuda:1'), 'ntokens': 303, 'nsentences': 8}
##################### {'id': tensor([152946, 214652,  64024,  10290,  84814,  36407,  92089,  72118],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[-1.4954e-03,  2.0752e-03,  5.3406e-03,  ...,  4.3945e-03,
          4.0588e-03,  2.4719e-03],
        [ 4.2725e-04,  1.0681e-03,  2.1362e-04,  ..., -9.1553e-04,
         -6.4087e-04, -4.8828e-04],
        [-9.4604e-04, -5.4932e-04, -8.5449e-04,  ..., -2.2888e-03,
         -1.7090e-03, -1.8311e-04],
        ...,
        [ 9.4604e-04, -9.1553e-05, -1.6785e-03,  ..., -6.5002e-03,
         -7.2327e-03, -6.2866e-03],
        [-1.8005e-03, -1.4038e-03,  1.8616e-03,  ..., -7.3242e-04,
          3.9673e-04,  0.0000e+00],
        [-3.2959e-02, -2.9877e-02, -2.6306e-02,  ..., -1.2512e-03,
         -1.1292e-03,  0.0000e+00]], device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([228640, 228640, 228640, 228640, 228640, 228640, 228639, 228639],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,  400,   41,  208,    4,  145,   23, 4156, 1175, 4550,  167, 1156,
          951,  186,   16, 3384, 3502,  971,   57,  221,  357,   14, 1483, 1338,
            5,  147,  306, 2437,    5, 4086, 1204,   31,  531, 5783,   97, 4156,
         7846,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3734,    6,  783,  737,  191,  334,  611, 5794,   44,  222, 3409,
         6257,    9, 1078, 1517, 5941,   15, 5882, 5235,    4, 4443,   36,   58,
          157, 1164,    4,  585, 6257,   28,   51, 1188, 1842,  444,    4,  114,
           43,  112,   40,  496, 2934,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,  624,   82, 3075,  187, 2124, 3104,    5,   92,  285,  200,
          152,    6,    6, 2301, 2935, 1398,   29, 2755,  186,    4,   50,   40,
         2295,   37,  149,  118, 6615,  356,  176,  975,  293, 1565,  398,    4,
          139,  114,   95,  118, 1083, 9852,  130,    4,  268,   36,   28, 3053,
           59, 1480,  160,  181, 2342, 1177,  856,   27,    4,  374,    4,   34,
           81,  130,    4,   61,    6, 1606,   28, 3230,    5],
        [   2,  764,   18,   81,   30,  374, 1292,  627,  466, 6116,    4,  178,
           36, 1078,  734,    4,  782,   81,   47,  600,  118, 2368,   78,   77,
           30,   83,  769,    4,   61,  102,   43,   77,  105,  377,  936,  969,
          883,  243, 1633, 1556,  303,  123,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104,   83,  139,   52, 1053, 3660,   78,   10,  153,  304,  236,
         7698,   15, 2525,    4,   14,    9,  231, 3822, 3125, 8216,   88,  247,
         1304, 1779, 2221,   76,    4,  306, 3419,    4,  306, 6521,   22,    4,
           16,  306, 7634,   15,    4,   74,  105,  173,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146,  624,  645,   27,    4,   16,  454, 2251,   41,   43,   61,
            4, 4470,   61,   40, 7510, 3113,    4, 9906,    4,  124,   61,   40,
         6618,    6, 7510,    9, 1474, 1441,    4,   16,    4,   78, 6744,   28,
         3091,   20,    4,   41,  123,   30,  139,   98,  927,  174,  272,   44,
          312, 2820, 3828,   15, 4294,   22,   74, 1282,  743,  671,    4,   16,
           40, 3747,   74, 1282,  167,  275,    4,  947,   42],
        [   2, 2540,   41,    4,   32,  309,   14, 3099,  226,  303,    4,  202,
         4946,    4, 4730,    4,   14, 2324,   49, 1145,   16, 1041,    4, 7368,
           15, 5014,    4,   14, 2039, 4088,   16, 1928,  646, 2499, 1225, 5162,
         1205,    4,    9,  686, 6517,    4,   49, 2065, 5010, 4789,  382,   28,
         4383,    6,  242, 4946,   15,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   14, 1463,   82, 1264, 1895,    4,   14,   90, 1309, 7729,
           49,  966,  272,  352, 2940, 4694,   22,    6,  152, 1049,  156,   59,
          365, 1021,   20,   97, 1083,  871, 6155,    4,  217,  731,    9,   58,
          507, 1374,  861,    4,  258, 6284,   23, 4708,   96,  122, 4151,  128,
           47,  216, 6998,  666,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:6')}, 'transcript': {'tokens': tensor([[  79,   25,   73,  150,    4,    7, 3421,   73,   51,  133, 7677,   85,
         1905, 3773,    4, 2156,   54, 2193, 6248,   22,    6,   10, 2829,  111,
         3221,    5,   67,  294,   14,    5, 1275,    4,   19, 1095, 2429, 3500,
         8457,  346,    7, 3421,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,    4, 3802,    6, 3698,    6,  450,  170,   17,  120,  409,    6,
           87,   86, 2906,   71,    7, 2875, 5848,    6,    4,   94,   66,   13,
         1623,  183,    9,  140, 4013,  240,  829,  264,  409,    6,  199,  159,
          207,   12,  826,   80,   13,  524,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  245,   91,   34, 3955, 2124, 2041,    5,    7,  903,  763,   19,
           59, 2687,  271,  567,  144,   10,   51,  822,  890,   17,   13, 2980,
           37,  288,  144,   10, 1565,   13, 6897,   13,  140,   57,    4,  276,
          103,  101,  144,  248,    4,  125,   21,   34,  593,  664, 2836,   15,
           54,    4, 1800,   77,   17,  101,  144,   85, 1449,  636,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1],
        [1042,   25,   66,   77,   12,   17,  388,  540,    4,   84,   11,    6,
           86,   91, 1043,  347,   25, 1608,   11,   18,  204,   66,   13, 1232,
         4529,   55,   77,   12,   17,    4,  206,   25, 1985,  838,  265, 1782,
           12,   77,   12,  251, 7487,    6,    9,   13,  976, 4454,  207,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  24,  113,  591,   13,  325,   12, 3302,   12, 2429,  488,   35, 5995,
         3008,    6,   17,   66,  226, 6816,   62,  199,   77, 3868,   12, 1237,
           35,    6,   37,  586,   54,  368,    6,   79,  238,   46, 1771,   12,
         3061,    4, 1771,   12, 5694,   96,    8, 1771,   12, 1291, 1672, 2334,
          100,   33,   91,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  29,    7,  245,  630,    4,    8,   25,  506,  213,   10, 2153,   33,
          346,    4, 2129,   69,   13,  523,   12, 1780,    4, 7100,    4,  109,
           13, 3996, 1472,   12, 1780,    9,  155,  906,    5,    8,    4,   55,
         1466,  373,   85,  637,    4,   25,   73,  780,   33,   79,  238,    5,
           13,  277,  150,   48, 7618,    6,  558,   10, 1155,    8,   13, 3601,
         7618,    6,   13,  325,    4,  230,   42,    2],
        [ 274,  168,   46,   25,   66,   10,  467, 3039,    4, 1370,    4, 5086,
            4, 1269,    8,  886, 1324,  128,  958,    4, 1206, 6898,    6,    4,
         2103,    7, 1422,    8,  175,    7,  324,  913, 3142,  629, 5151,    9,
          333,   13, 2515,  106, 4793,   10, 3585,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   21,  552,  346,   10,  250,  434,  205,  387,    4,  166,    4,
           79,   13, 2173,   12, 1920, 2739, 2033, 6665,   26,  204,  832, 1775,
         7195, 9096,    6, 3907,    7,  955,    4,    8, 3394,    9,    7, 2802,
           18,    6,    4,  166,  442,    7, 1103,  443,  338,  128,  291,  457,
           10, 7102,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 37,  6, 59, 11, 37,  9,  6, 38, 83,  5, 37, 50, 56, 11,  6, 49, 28,
         28, 35, 37, 37, 32, 83, 29, 11, 37, 50, 38, 11, 83, 11, 38, 59,  2, 56,
          8, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 16, 37, 32, 37, 88, 37, 37, 37, 32, 37, 85, 83, 49, 37, 37, 31,
          9, 37, 11, 56, 85, 37,  2, 24, 37, 35, 35, 35, 49,  2, 32, 37, 37, 37,
         83, 37, 59, 37, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 50, 85,  9, 35, 94, 11, 37, 38, 35, 38, 35, 35, 44, 32, 85, 37,
         38,  2, 83, 37, 37, 23, 77, 83, 85, 37, 32, 37,  9, 37, 35, 77, 11, 83,
         37, 38, 85, 34, 11, 37, 37, 85, 83, 38, 35, 77, 49, 11, 31, 50, 37, 38,
         85, 37, 38, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 85, 50, 37, 37, 31, 36, 11, 37, 85, 37, 83, 50, 32, 83, 37,  6,
         85, 35, 83, 85, 37,  9, 35, 37, 50, 37, 37, 11, 37, 37,  6, 33, 35, 77,
         37, 50, 37, 50, 36, 37, 37, 37, 83, 83, 83, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 83, 31, 37, 83, 37, 56, 37,  2,  2, 38, 35,  9, 37, 37, 85, 85, 29,
         31, 37, 50, 50, 37, 94, 38, 37, 77, 35, 49, 49, 37, 37, 83, 11, 50, 37,
         56, 11, 50, 37, 94, 77, 37, 50, 37, 38, 35, 56, 37, 37, 50, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 83, 94, 11, 37, 37,  6, 88, 37, 49, 37, 37, 11, 50, 37, 37, 83,
         37,  9, 11, 83, 11, 37, 37, 28, 32, 37,  9, 37, 37,  9, 11, 37, 11, 37,
         19, 56, 37, 37, 11, 37,  6, 88, 37, 37, 83, 11, 37, 50, 59, 31, 29, 37,
         37, 37, 50, 37, 37,  9, 29, 37, 37, 83, 11, 37, 11, 83],
        [59, 37, 11, 37, 85, 37, 38, 94, 11, 94, 11, 32, 11,  9, 37, 38, 77, 35,
         94, 11, 29, 94, 37, 11, 29, 37, 94, 37, 85, 37,  2, 28, 36, 37, 56, 37,
         50, 37, 32, 37, 94, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 37, 50, 31, 85, 35, 11, 37, 11, 37, 37, 32, 37,  9, 35,
         29, 29, 85, 83, 38, 35,  2,  9, 37, 37, 37,  9, 11, 37,  2, 37, 37, 49,
         35, 37, 11, 37, 31, 37, 38, 35, 35, 35, 38,  2, 37,  8, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:6'), 'lengths': tensor([42, 44, 60, 49, 53, 68, 45, 52], device='cuda:6'), 'ntokens': 413}, 'target': tensor([[ 400,   41,  208,    4,  145,   23, 4156, 1175, 4550,  167, 1156,  951,
          186,   16, 3384, 3502,  971,   57,  221,  357,   14, 1483, 1338,    5,
          147,  306, 2437,    5, 4086, 1204,   31,  531, 5783,   97, 4156, 7846,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3734,    6,  783,  737,  191,  334,  611, 5794,   44,  222, 3409, 6257,
            9, 1078, 1517, 5941,   15, 5882, 5235,    4, 4443,   36,   58,  157,
         1164,    4,  585, 6257,   28,   51, 1188, 1842,  444,    4,  114,   43,
          112,   40,  496, 2934,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92,  624,   82, 3075,  187, 2124, 3104,    5,   92,  285,  200,  152,
            6,    6, 2301, 2935, 1398,   29, 2755,  186,    4,   50,   40, 2295,
           37,  149,  118, 6615,  356,  176,  975,  293, 1565,  398,    4,  139,
          114,   95,  118, 1083, 9852,  130,    4,  268,   36,   28, 3053,   59,
         1480,  160,  181, 2342, 1177,  856,   27,    4,  374,    4,   34,   81,
          130,    4,   61,    6, 1606,   28, 3230,    5,    2],
        [ 764,   18,   81,   30,  374, 1292,  627,  466, 6116,    4,  178,   36,
         1078,  734,    4,  782,   81,   47,  600,  118, 2368,   78,   77,   30,
           83,  769,    4,   61,  102,   43,   77,  105,  377,  936,  969,  883,
          243, 1633, 1556,  303,  123,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104,   83,  139,   52, 1053, 3660,   78,   10,  153,  304,  236, 7698,
           15, 2525,    4,   14,    9,  231, 3822, 3125, 8216,   88,  247, 1304,
         1779, 2221,   76,    4,  306, 3419,    4,  306, 6521,   22,    4,   16,
          306, 7634,   15,    4,   74,  105,  173,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146,  624,  645,   27,    4,   16,  454, 2251,   41,   43,   61,    4,
         4470,   61,   40, 7510, 3113,    4, 9906,    4,  124,   61,   40, 6618,
            6, 7510,    9, 1474, 1441,    4,   16,    4,   78, 6744,   28, 3091,
           20,    4,   41,  123,   30,  139,   98,  927,  174,  272,   44,  312,
         2820, 3828,   15, 4294,   22,   74, 1282,  743,  671,    4,   16,   40,
         3747,   74, 1282,  167,  275,    4,  947,   42,    2],
        [2540,   41,    4,   32,  309,   14, 3099,  226,  303,    4,  202, 4946,
            4, 4730,    4,   14, 2324,   49, 1145,   16, 1041,    4, 7368,   15,
         5014,    4,   14, 2039, 4088,   16, 1928,  646, 2499, 1225, 5162, 1205,
            4,    9,  686, 6517,    4,   49, 2065, 5010, 4789,  382,   28, 4383,
            6,  242, 4946,   15,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   14, 1463,   82, 1264, 1895,    4,   14,   90, 1309, 7729,   49,
          966,  272,  352, 2940, 4694,   22,    6,  152, 1049,  156,   59,  365,
         1021,   20,   97, 1083,  871, 6155,    4,  217,  731,    9,   58,  507,
         1374,  861,    4,  258, 6284,   23, 4708,   96,  122, 4151,  128,   47,
          216, 6998,  666,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:6'), 'target_lengths': tensor([38, 42, 69, 43, 45, 69, 54, 53], device='cuda:6'), 'ntokens': 413, 'nsentences': 8}
##################### {'id': tensor([   186,  65273, 223280, 102823, 183775, 118705, 197019, 172494, 223558,
        203953, 117023,  60898, 179643, 156516, 110684, 112147, 171136, 178122,
        136688,  29899,  71098, 176118,  94676,  51449], device='cuda:3'), 'net_input': {'src_tokens': tensor([[ 6.7139e-04,  4.2725e-04, -3.0518e-05,  ..., -9.1553e-05,
         -3.0518e-04, -1.8311e-04],
        [ 3.0518e-05, -5.7983e-04, -1.8311e-04,  ...,  3.3569e-04,
         -7.6294e-04, -1.4648e-03],
        [-7.9346e-04, -1.3123e-03, -1.1292e-03,  ...,  1.0681e-03,
         -1.5564e-03, -2.9297e-03],
        ...,
        [-1.5594e-02,  1.8311e-04,  1.4282e-02,  ..., -4.9438e-03,
          3.3569e-04,  0.0000e+00],
        [ 9.7656e-04,  7.3242e-04,  4.8828e-04,  ..., -3.8757e-03,
         -3.6926e-03,  0.0000e+00],
        [-4.5776e-04, -2.7466e-04, -3.0518e-05,  ...,  7.6599e-03,
          8.3618e-03,  0.0000e+00]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960,
        96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960, 96960,
        96960, 96959, 96959, 96959], device='cuda:3'), 'prev_output_tokens': tensor([[   2, 5628, 1364,  ...,    1,    1,    1],
        [   2,  327,  578,  ...,  491, 4087,   42],
        [   2,   72,  280,  ...,    1,    1,    1],
        ...,
        [   2,  376, 6538,  ...,    1,    1,    1],
        [   2,  520, 3273,  ...,    1,    1,    1],
        [   2,  104, 2716,  ...,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[   9, 4936,    4,    7, 7885, 4489,   48,  106,   17, 3537,  699,  128,
           26, 1056, 5890,  759, 1086,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  70,  103,   89,  964, 3147, 1425,   80,   89, 1968,  111,  217, 3237,
         1563, 4234, 3450,  494,   37,    4,  148,  188,  116,  487,  267,  447,
         1201, 2823,   54, 4234, 9373,    6,   42,    2,    1,    1,    1,    1,
            1,    1,    1],
        [  19,   11,   48, 5707,   62,   13, 4546,   11,    6, 5912,    9, 1827,
         3719,    8,  144,   13, 6381,   12,  747,   35,  927, 1105,  232, 3254,
            9,    7, 1819,    8, 4528, 8860,    5,    2,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   24,  180,   73,  203,   35,  737,  181, 1792,    7,  618,   59,
           71, 1247,    4, 6767,   54,    7, 2011, 6504, 3601,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  19,   11,  121,  492,  226,  224,  635,  558,  464,    5,   68,  194,
           65,  109,  635,    7,  464,  432,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  29,    7,  801, 1113,  490, 1578, 3742,  120,   25,  162,  269,   54,
            9,  155, 3742,    8,   25, 1346,   38, 2286, 5507,  656,  156,  156,
          197,   69,    7, 4127,   25,  692,   10, 1510,    4,   17,   34,    7,
         4579,    5,    2],
        [  19,  591,   13,  341,  630,   10,  884, 1508,    5,  148,   63,   25,
           42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,   79, 4618,  866,  693,    4,   10, 4576, 6249, 8221,    6,   26,
           10, 4576,    7, 4950,   17,   25,   73,   87,   71,  134,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 180,   19,  169, 1730,   51,  529,   10, 1945,   10,   89, 1276,   89,
          998,   71,  475, 2348,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 101,  568,  283,   69,    7,   19,  262, 2992,    8, 4244,    8, 2645,
            6,   12,  341,   94,   10,  150,  138,   53,  876, 2933,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [3719,  575,   17,   94,  148,   63,  244,  262,  249,  525,   62,    9,
          159,   58, 1010,  164,  203,    6, 1632,   10,   55,  627, 1552,  254,
            9,  891,  128, 1234,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 101,  568,    4, 1445,    4,   66,   13,  277,  523,   12,  688,  346,
            9,    7, 2008,   17,  188,   13,  133, 1986, 6711,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [3286, 1370, 4609,  378,   13,  230,   55,   77,    8, 1505,   13, 7099,
           55,    7,  555,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7,  245,   26,   33,    4,   17,  422, 3772,   63, 7200,  341,    8,
         7287,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  91,   12,  108,   56, 7038,  693,    9,    7, 1227,   26,   17,  211,
         7169,   26,  172,    9, 1015,   22,    6, 3358,  419,  509,  254,  419,
          218, 7169,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   9, 1954,  122,  160,  206,   19,   34, 4594,    9, 1651,  584,    4,
            7, 3019,  608,  958, 5808,   34, 1241,  391, 1113, 1570,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 185,  215,  581,    4,   13,  264, 2720,  445, 2947,   62,   69,    7,
         1232, 4529,   44,    7, 7031,   12,    7,   82, 1486,  901, 2760,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,   94,  148,  192,   11,   18, 5506,  159, 2734,   45, 1197,
          768,    6,    9,  835, 4388,   63, 8638,  373,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  25,  135,    4,   56, 1628,    7,  269,  340,  589, 2078,    4,  227,
         2227,  737,    6, 6464,   71,    7, 7887,  162, 6355,  291, 3029,   62,
         1613,    9,    7, 2291,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  24,   11,   57,  142,   10, 3231,   39, 4748, 3432,  200,   57,  656,
            4,   13, 2290,  287,   15,  266,  589,  518, 4928,    4,  109,   13,
          264, 3164,  774,  271,    4,   13,  264,  282,    5,    2,    1,    1,
            1,    1,    1],
        [   8,  346,  168,    4,    8,   53, 6852,  346,  168,  939,  160, 6687,
         1146,  834,    5, 2285,    5,   33,   26,    7,  281, 3586, 9874,   12,
          419, 5353,   12,  909,   93,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7, 2636, 2964,  164,   51,    9,   48,  365,   54,  241, 1410,  457,
          106,    7,  422,    4,    8,   17, 4028,   96,  170,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   9, 3071,    4,  391, 6786,    6, 2912,  131,    7, 1067,  971,  455,
         8418, 1665, 4272, 2838,   62,    8, 9412,   62,    7,  170, 6577,    4,
          294,  825,  244,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  24, 1505, 3277,   35,  804,  607,   62,    4, 5832,  111,  890,  224,
           55,   91, 1043,  109,  486,    4,   53,  465, 1631,  830,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 83, 11, 37, 32, 49, 31, 37, 37, 38, 35, 35, 85, 17, 73, 24, 32, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [50, 37, 37,  9, 35, 31, 37, 37,  2, 83, 38, 35,  2,  9, 38, 35, 77, 11,
         50, 85, 83, 31, 37, 37, 32, 49, 49,  9, 29, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 31, 49, 31, 37, 32, 85, 37, 23, 37, 56, 56, 37, 85, 37, 38, 37,
         30, 38, 35, 35, 77, 56, 37, 37,  9, 37, 12, 56, 11, 83, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 37,  6, 38, 38, 35, 35, 77, 37, 49, 35, 37, 56, 11, 29, 49, 37,
          9, 22,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 35, 50, 85, 11,  6, 37, 24, 11, 38,  9, 11, 37,  6, 37, 24, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37,  2, 24, 37, 28, 12, 37, 37, 85, 79, 49, 37, 37, 12, 37, 37, 59,
         38, 35, 35, 35, 35, 35, 82, 37, 37,  9, 37, 85, 37, 59, 11, 37, 85, 37,
          9, 11, 83],
        [38, 31, 37, 33, 94, 37, 88, 56, 11, 50, 85, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 94, 35, 56, 11, 37, 88, 94,  9, 37, 85, 37, 88, 37, 56, 37, 37,
          6, 85, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 85, 83, 38,  6, 37, 88, 37, 37, 94, 37, 94, 37,  2, 23, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 49, 37, 37, 38, 77, 94, 37, 56, 37, 28, 37, 37, 33, 56, 37, 59,
         37, 37, 38, 33, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [56, 88, 37, 56, 50, 85, 37, 77, 77, 35, 31, 37, 37, 38, 35, 85, 38, 37,
         35, 37, 37, 35, 83, 37, 37, 35, 35, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 11, 37, 11, 85, 37, 50, 83, 37,  9, 37, 37, 37, 28, 37, 85, 37,
         83,  2, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [ 2, 94, 31, 49, 37, 37, 37, 50, 37, 85, 37, 32, 37, 37, 50, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 83, 85, 37, 11, 37, 28, 56, 85, 83, 33, 37,  2, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [50, 37, 37, 38, 35, 56, 37, 37,  9, 85, 37, 50, 29, 85, 83, 37, 35, 35,
         37, 83, 50,  2, 37, 50, 50, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 35, 35, 37, 38, 85,  2, 37, 34, 73, 11, 37, 37, 75, 94, 94, 85,
         37, 34, 24, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [50, 24, 83, 11, 37,  2, 49, 35, 88, 31, 37, 37,  9, 35, 82, 37, 23, 37,
         37, 53, 35, 35, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 56, 50, 85, 85, 35, 94, 37, 38, 35, 77, 94, 37, 37,  2, 56, 85,
          8, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 59, 11, 38, 37, 37, 79, 35, 35, 94, 11, 38, 35, 35, 37, 36, 37, 37,
         32, 85, 10, 38, 35, 31, 56, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85, 77, 49, 37, 88, 38,  2, 22, 35, 77, 35, 11, 37, 38, 35, 77, 35,
         35, 37, 28, 11, 37, 37,  2,  9, 38, 44, 11, 37,  2, 32, 11, 83, 37, 37,
         37, 37, 37],
        [37, 37, 37, 11, 37, 37,  9, 37, 37, 38, 35, 28, 28, 11, 11,  2, 11, 37,
         85, 37, 75,  2, 94, 37, 50,  9, 37, 38, 35, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37,  2,  9, 85, 38, 37, 31, 35, 49, 35, 35,  2, 37, 37, 28, 11, 37, 37,
          2, 77, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 94, 11, 34,  9, 37, 31, 37, 37, 38, 81, 35,  9, 38, 94, 29, 31, 37,
         29, 31, 37, 37, 94, 11, 50, 24, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [38, 85,  9, 38, 35, 35, 31, 11,  2, 83, 83, 11, 37, 50, 32, 37, 50, 11,
         37, 85, 85, 62, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:3'), 'lengths': tensor([19, 32, 32, 23, 20, 39, 14, 24, 18, 24, 30, 23, 17, 15, 28, 24, 25, 22,
        30, 34, 31, 23, 29, 24], device='cuda:3'), 'ntokens': 600}, 'target': tensor([[5628, 1364,   23,  ...,    1,    1,    1],
        [ 327,  578,    4,  ..., 4087,   42,    2],
        [  72,  280,  118,  ...,    1,    1,    1],
        ...,
        [ 376, 6538, 1804,  ...,    1,    1,    1],
        [ 520, 3273,  897,  ...,    1,    1,    1],
        [ 104, 2716,  273,  ...,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([22, 46, 26, 25, 20, 44, 14, 24, 15, 25, 27, 21, 17, 14, 19, 24, 22, 22,
        29, 34, 36, 18, 35, 23], device='cuda:3'), 'ntokens': 602, 'nsentences': 24}
##################### {'id': tensor([149230, 143556,  99738,   1640, 153757,  68140,  10949,  41347],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[-1.2207e-04, -1.1902e-03, -9.1553e-05,  ..., -2.4139e-02,
         -2.5146e-02, -2.2064e-02],
        [-4.8828e-04, -6.1035e-04, -5.1880e-04,  ..., -7.9346e-04,
         -5.1880e-04, -3.6621e-04],
        [ 3.0090e-02,  3.6102e-02,  3.9337e-02,  ...,  1.4648e-03,
          1.6174e-03,  6.4087e-04],
        ...,
        [ 2.4414e-04,  9.1553e-05, -1.5259e-04,  ..., -3.3356e-02,
         -3.6224e-02,  0.0000e+00],
        [-1.4343e-03, -9.4604e-04, -6.7139e-04,  ..., -2.4109e-03,
         -3.6316e-03,  0.0000e+00],
        [-4.0405e-02, -4.6356e-02, -5.0690e-02,  ..., -1.0071e-03,
         -1.9226e-03,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([209120, 209120, 209120, 209120, 209119, 209119, 209119, 209119],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,   99,  130, 1016,  397,  184, 4729,   18,    4,  382,  212, 6400,
           75,  223, 2491,   20,    4,   60,  193,    9, 8352,  193,  151,  351,
         1641,    4,    9,  102,   40, 3627,   98, 7326,   16,   40, 3627,   60,
          275, 2661,  158,   40, 1340, 8056,   83,    4,    9,  631,   43,   75,
           74,   14, 7952,   15,  129, 6425,   96,  171, 7165, 2520,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,  182, 1992, 1709, 5950,   37,  507,    6, 1409,    6, 8354,
           22, 1812,   95,  653,    4,   50,   14, 1351,    9,   23, 2005,   82,
            4,   14,  696,   20, 1253, 1676,   56, 3481,  200,  932, 1867, 1540,
           28,  171,  156, 5210,   22,   16,   40, 1343, 2025,  662,    6, 7022,
         6378,    9,   23, 5835,  974, 1326, 6428,   28, 2489,    4,   88,   14,
          437,  152,  303,   23, 6401,   28, 1097,  362,   15,    6,  272,    5],
        [   2,   72, 3844,  252,  302, 2824, 7562,   44,   14,  624,   27,    4,
           50,   23, 2249, 3827, 2206,   78, 8364, 5779,   27,    4,   14, 2899,
         5392,   23, 5306,   22, 6005,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2401,   36,  113, 1048,  343,  114,   36,  139, 1138,  267, 9076,
         5272,  343,   50,   32,    9, 1014, 1607,  139,   90,   52,  353, 7240,
         5664,  792,   42,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2119,   41,   39,   14, 1200,    4,   14,  273, 1506,   97,  423,
            5, 2289,   28, 2186, 5775,    4,   74,  742,    5,  304,    5, 1541,
            6,    6, 1660,    4, 3241, 1660,    4,  124,   30, 2171,  299, 4535,
           44, 1235,   45, 7126,  726,   20,    5,   92,   76, 1467,   20, 5838,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  222,  316,   39,  151,  674, 1502, 3613, 2581,   22,  389,   45,
          119,    4,   56, 7637,   20,  408,   46,  428,  114,  316,   56, 7637,
          119,    4,  161, 4824,   41,  247,    6,  371, 2435,  102, 1209, 3496,
            6,  407,   23, 9687, 2014,   74,  671, 1549,    5,   38,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   32,  123,   29,  275,  334,   44,  146, 7947, 5096, 1577,
           19,   59,   48,  515, 7131,  112,  426,  236,   18,  193, 1246,  193,
           14, 1245, 1590,  962,  732,  466,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   31,  329,   44,   38,  967,  395,  105, 4080, 6370,  137,
           64,   31, 2357,  406, 1196,  907,  804,  959,   16,  987,  907,  153,
          382,    9,   14,  869,  338,  726,  156,   46,   36,   82,   47,  263,
          406, 1196,  907,  804,  959,    4,   31, 3490,  149,  897,   46,   72,
         2505,   20, 1458,   15,   20,  425,   20,  372,   16, 4511, 1633,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7')}, 'transcript': {'tokens': tensor([[  55,  901,  215, 1065,   34,  120,    7, 5540,  172, 5853,   69,    4,
           71,    4,  916,  111,    4,  486, 2496,   17, 4825,   48,   13, 5933,
         1300,    8,   13, 3053, 3832, 1300,  203,    6, 1236,   54,   13, 2088,
          131, 5610,   54,  132,   79,    7, 8522,   11,    6, 7037,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  432, 1992, 1551,   12, 5950,   20, 2327,   54, 3974,    6,    4,
          101,  591,   17,    7, 1298,   34,  529,   10, 2318,  203, 2751,   20,
            7, 3257,   12,  284, 2116,    8,  719,   13, 6340, 1434, 1032, 4340,
         1740,    9,  159,  230, 9271,   10, 1661,   15,    6,  436,   55,    7,
          859, 9271,   11,    6, 4821,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   11,  158,  508,   25,  248, 4454, 1649,    5,    7,  245,   26,
           17,    7,  281,  528, 1880, 2070,   55,    7, 2932,   26,  291,  429,
            4,   26,    7, 2248,  191,  833,   12, 2932, 5099,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  276,   10,  205,  106,   84,    4,   21,   11,    6, 1254,    4,
         3942, 1019,   35,  616,   18,  311,   62,    4,   17,    9,    7,  858,
           24,  220, 1120,  154,   12, 1167,  378,  619,   79,   13, 7289,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   25,  154,   80,    7, 2787,  108, 1848, 2096,   10, 2026,    9,
            7,  423,  322, 1910,    4, 2787,  100,  883,  140, 1144,    4,  109,
         2314, 1144,    4,  109,    7, 2517,   17,   24,   11,  121,  226, 5803,
            9,   33, 1910,    4, 1320,   45, 7126,  174,  407,    4,  251,   63,
          835, 2787,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,   25,  722,    9,   13, 3753,    4, 1997,  408,   46,  125,  120,
           25, 1997,    4,    7,  811, 5084,  293,  271,   12, 1051, 2553,   93,
           26,    7, 1387,  119,   25,  164,  367,   10,    7,  217, 3496,    6,
          407,   12,    7, 1440,    6,    5,   38,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   33,  261,   24,   73,  289,   44,    7, 6608,   12, 3857,   69,
            7,  943,    9, 7393,  811,  430,   62,    6,    4,  109,   26, 2676,
           10,  811,  430,   62,    4,   17,    9,   77,   12,    7, 1590,   12,
          282, 4812,   48,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   19,  246,    4,   38, 1367,    4,   19,   11,   45,  142,   10,
           66,   10, 2551,   17, 2187,  137,    8,   19,  278,    9,   89, 7615,
          804,  411,    4, 7615,   62,   77,    7,  207,  359,    7,  595, 1331,
          242,  221,   46,   21, 1359,   11,   18,  172,   89, 7615,  804,  411,
            4,   19,  321,   12, 1639,   69,   17, 4515,   46,  278,   10, 2200,
          375,  425,   20,  372,    8,   19,  487, 3045,    5,    2]],
       device='cuda:7'), 'cluster_tokens': tensor([[37, 35, 24, 24, 85, 37, 37, 32, 83, 31, 37, 11, 37, 11,  2, 83, 11, 50,
          9, 37, 32, 31, 37, 28,  9, 37, 37, 38, 35,  9, 38, 37, 35, 49, 37,  9,
         37, 49, 49, 37, 37, 37, 32, 85, 37,  9, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 34, 24, 37,  2, 77, 38, 49, 94, 37, 11, 38, 31, 37, 37, 94, 85,
          6, 37, 83, 38, 35, 77, 37, 47, 37, 37, 56, 37, 49, 37, 28, 35,  2, 16,
          9, 37, 37, 37, 94, 37, 36, 77, 37, 77, 37, 37, 31, 94, 85, 37, 29, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 88, 37, 34, 83, 50, 11, 37, 83, 85, 37, 37, 75,  2, 28, 32,
         37, 37, 28, 85, 38, 94, 11, 85, 37, 83, 77, 35, 37, 28, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 83, 37, 85, 37, 37, 11, 37, 85, 37,  6, 11, 83, 83, 38, 77, 35, 35,
         31, 11, 37, 37, 37, 94, 38,  6, 83, 59, 37, 26, 49, 31, 37, 37, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 59, 37, 37, 56, 37, 56, 31, 37, 29, 37, 37, 34, 35, 24, 11, 56,
         37, 38, 35, 32, 11, 37, 28, 32, 11, 37, 37, 32, 37, 38, 85, 35, 85, 76,
         37, 37, 24, 11, 38, 35, 35, 35, 35, 11, 50, 85,  2, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 49, 37, 37, 28, 11, 38, 11, 11, 37, 37, 37, 38, 11, 37, 38, 35,
         35, 44, 37, 38, 35, 35, 85, 37, 83, 75, 37, 85, 85, 37, 37, 38, 35, 37,
         35, 37, 37,  9, 37, 11, 38, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83, 38,  6, 88, 82, 37, 23, 37, 47, 37, 37,  9, 37, 56, 38, 35,
         31, 37, 11, 37, 85, 83, 37, 38, 35, 31, 11, 37, 37, 50, 37, 37, 38, 37,
         32, 36, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 88, 11, 38, 35, 11, 38, 85, 35, 49, 37, 85, 37, 29, 37, 94, 11,
         37, 38, 31, 37, 37,  9, 35, 35, 11,  9, 31, 50, 37, 83, 37, 37,  9, 43,
         77, 35, 11, 37, 85, 85, 35, 83, 37,  9, 35, 35, 11, 38, 38, 37, 31, 37,
         37, 22, 11, 31, 37, 38, 77, 35, 77, 35, 37, 38, 31, 49, 11, 83]],
       device='cuda:7'), 'lengths': tensor([49, 55, 35, 37, 52, 44, 41, 70], device='cuda:7'), 'ntokens': 383}, 'target': tensor([[  99,  130, 1016,  397,  184, 4729,   18,    4,  382,  212, 6400,   75,
          223, 2491,   20,    4,   60,  193,    9, 8352,  193,  151,  351, 1641,
            4,    9,  102,   40, 3627,   98, 7326,   16,   40, 3627,   60,  275,
         2661,  158,   40, 1340, 8056,   83,    4,    9,  631,   43,   75,   74,
           14, 7952,   15,  129, 6425,   96,  171, 7165, 2520,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,  182, 1992, 1709, 5950,   37,  507,    6, 1409,    6, 8354,   22,
         1812,   95,  653,    4,   50,   14, 1351,    9,   23, 2005,   82,    4,
           14,  696,   20, 1253, 1676,   56, 3481,  200,  932, 1867, 1540,   28,
          171,  156, 5210,   22,   16,   40, 1343, 2025,  662,    6, 7022, 6378,
            9,   23, 5835,  974, 1326, 6428,   28, 2489,    4,   88,   14,  437,
          152,  303,   23, 6401,   28, 1097,  362,   15,    6,  272,    5,    2],
        [  72, 3844,  252,  302, 2824, 7562,   44,   14,  624,   27,    4,   50,
           23, 2249, 3827, 2206,   78, 8364, 5779,   27,    4,   14, 2899, 5392,
           23, 5306,   22, 6005,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2401,   36,  113, 1048,  343,  114,   36,  139, 1138,  267, 9076, 5272,
          343,   50,   32,    9, 1014, 1607,  139,   90,   52,  353, 7240, 5664,
          792,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2119,   41,   39,   14, 1200,    4,   14,  273, 1506,   97,  423,    5,
         2289,   28, 2186, 5775,    4,   74,  742,    5,  304,    5, 1541,    6,
            6, 1660,    4, 3241, 1660,    4,  124,   30, 2171,  299, 4535,   44,
         1235,   45, 7126,  726,   20,    5,   92,   76, 1467,   20, 5838,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 222,  316,   39,  151,  674, 1502, 3613, 2581,   22,  389,   45,  119,
            4,   56, 7637,   20,  408,   46,  428,  114,  316,   56, 7637,  119,
            4,  161, 4824,   41,  247,    6,  371, 2435,  102, 1209, 3496,    6,
          407,   23, 9687, 2014,   74,  671, 1549,    5,   38,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   32,  123,   29,  275,  334,   44,  146, 7947, 5096, 1577,   19,
           59,   48,  515, 7131,  112,  426,  236,   18,  193, 1246,  193,   14,
         1245, 1590,  962,  732,  466,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   31,  329,   44,   38,  967,  395,  105, 4080, 6370,  137,   64,
           31, 2357,  406, 1196,  907,  804,  959,   16,  987,  907,  153,  382,
            9,   14,  869,  338,  726,  156,   46,   36,   82,   47,  263,  406,
         1196,  907,  804,  959,    4,   31, 3490,  149,  897,   46,   72, 2505,
           20, 1458,   15,   20,  425,   20,  372,   16, 4511, 1633,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'target_lengths': tensor([59, 72, 30, 27, 49, 46, 31, 60], device='cuda:7'), 'ntokens': 374, 'nsentences': 8}
##################### {'id': tensor([ 36717, 145355, 182299, 158001, 136654, 108483, 107938, 127359, 208466,
        166701, 160009,  96471, 218841, 193917,  54946, 196354, 149740, 200544,
         72064, 119812, 132635, 156584, 104646,  42894], device='cuda:5'), 'net_input': {'src_tokens': tensor([[-0.0042, -0.0046, -0.0038,  ..., -0.0016, -0.0017, -0.0025],
        [-0.0010, -0.0009, -0.0009,  ...,  0.0011,  0.0009,  0.0009],
        [-0.0004, -0.0018, -0.0020,  ...,  0.0014,  0.0026,  0.0031],
        ...,
        [ 0.0010,  0.0017,  0.0014,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0869,  0.0904,  0.0891,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0999, -0.0593, -0.0121,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([86560, 86560, 86560, 86560, 86560, 86560, 86560, 86560, 86560, 86560,
        86560, 86560, 86559, 86559, 86400, 86400, 86400, 86400, 86400, 86400,
        86400, 86399, 86399, 86399], device='cuda:5'), 'prev_output_tokens': tensor([[   2,  147,   39,  151, 2624,   27,   30, 8531,    4,   50,   14, 2785,
         2321,    6, 6394,  167, 3992,   76,   16,  210, 2064,  184, 2006,   18,
          161,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   88,   14, 2176,   15,   20, 9406,   28,  208,   16,   43,
          263, 6846,   28,  123,    4,  395,   81,  190, 3178,  548, 1883,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,   27,   52,   23,   56,  152, 2545,  381, 5698,   15,   23,
          201,   44,   40, 1716, 1196,  597,   20,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  394,   88,   14, 1316, 2617,   48,  426,  353,    4,   61,
           14, 2002,  124,   14, 1521, 3659,   28,  940,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  882,  414, 2725,  256,   31,    4,   81,  769, 1225, 4413,   83,
            4,  428,  897,  161,  216,  428,  728,  184, 1170,  307,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   61,  648, 3292,  470,  167, 2928, 5678,    9,   23,  201,
          129, 2324, 2935,    6,   28,  334,   44,   38, 1007,  973,  307,  594,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   14, 1572, 2714,   20,   28,    4,   30,   16,  671, 1549,
           28,  260,   16,  273,  972,  897,   28, 4589,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  720, 1627,  252, 3525, 1783, 3034,  177, 1126,    4,  136,   78,
          107,   82,   30, 3931,   52,  331,  353,  129, 3105,    6,  539,    6,
            5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  400,    9, 8322,    4,  258,   32,  107, 5145,    4,  403,   52,
          585, 6498, 1176,  503,    4,   14,  559, 1534,   20,  371,   20,  777,
          631,  390,   28,  226,  303,    5,    1,    1,    1],
        [   2,   92,   27, 2890,   90, 2898,   16, 2310,  466,    9, 8079,   45,
          757,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92, 1908,  364, 1776, 3822, 3229,    6,  891,   16,   43,  702,
         1925,  382,   39,    6,  844,  805, 2095,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41, 6573,    4,   58, 8411,  129, 1690, 8330,    6,   28,  605,
            4,   16,   30,    9,  151,  342,  152,  181,  236,   60, 3132,   22,
         6973,   22,    4,  382,   28,  392, 6973,   22,    5],
        [   2,   99,  178,  190,  216,  617,   90, 1438,   61,   23,  201,    4,
          761, 1185,  584,  950,   23,  201,  242, 6018,  165,   76,   24, 1331,
          418,    5,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1493,   14, 3749,   15,  420,  983,    4,  664, 2628,   22,   32,
          196,  216, 5888,    4, 1877,   20,   16, 4297, 4408,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  312, 1087, 4556,   16,   40, 8071,   37, 1725, 2506,    4,   40,
         3920,  235,  975,  399,  481,    6,  590, 1761,  191,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1394, 3624, 4742,   15,   43,  139,   16, 1457,  355, 1528,   15,
         3234,   61, 1926,  541,  625,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99, 9285, 8134,    4, 8448,   16, 2624,   20,   16,  888,  252,
            4,   98, 4613, 2282,  512, 1642, 2889,   22, 2149, 1126,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 1277,    4,   52,   49,  628,   28,  127,    4,   14,  917,
           90,  190, 4978, 5226,  662,    6,    4,   56, 7560,   22,  481,    6,
           16,  312, 1285,   96, 1378, 4789,    5,    1,    1],
        [   2,  104, 1166,  257,  196,   28,  725,   16, 2625,    4,   34,   23,
         2569,  152,   57, 4190,  477,   27,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   27,  113,   30, 2635,   78,  273, 2144,    4,   74,  105,
          732,  352, 5284,   59,  165, 1048,   27,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104, 1561,   12,   18,   49,  157,   60, 1225,   45, 6218,    4,
           90,  578,   36,   52, 4124,  285, 2605,  165,    4,  136,   30, 2714,
           29,   47,    5,    1,    1,    1,    1,    1,    1],
        [   2,   41,   83,  118,  862,   20,  235,   56, 7976,   15, 5094,   78,
           14, 2086,    4,   23,   14, 7188, 4332,   15,    4, 4472,   16,   14,
          342,  219,   22,  426,   40, 7636,    5,    1,    1],
        [   2,  202,  266,  674,  803,   18, 1558,   57,   44,   72, 3862,  252,
          275,  627,    6,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104, 4687,   22,    4,   50,   32,   39,  462, 4334,   15,  496,
         3604,  357,  845, 2081,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[  67,  103,   25,  388,  132,   13, 5334,    4,    7, 1284,  279,   26,
            4,   25,  135,    4,   21,   11,    6,   13,  133,  822, 2248,  191,
          833, 1809,   20,    4,    8,   25, 1703,   69, 2786,    5,    2],
        [  67,   10,  172,  150,    7, 3201,    6,   12,    7,   51,   20,    4,
            8,  172, 6784,   70,   21,   26,    4,   25,   66,   10,  274,   13,
          277,  523, 4616,    5,    2,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6,   91,   12,    7,  179,   11,    6,  801,  608, 6180,
            6,   44,   13, 1598,   12,   29, 1034,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6,   80, 3429,   54,  155, 1237,  109,  155, 1504,    9,
            7,  281, 2694,  366,  207,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,    4,  131,  697, 4939,   19,  641,    4,   25,  296,   10,   66,
          324, 2070,    4,  125, 2070,   26, 2808,   48,  100,  492,  490,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   77,   12,   13, 5827,    4,  185,  133,  528, 1732,    6,    9,
            7,  179,   12, 1136,  958,  487,   10,  289,    4,   38,  176, 1409,
           69,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,    7, 1381, 2990,   48,   10,   87,   17,    8,   86,   87,  995,
          994,    4,    8, 2238,  108,  941,   69,   17,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   33,  506, 1511, 2667,    6, 1327, 1010,   10,   25,    4,   67,
           55,  170,   21,   34,  172,  116,   13,  341,  207,   12,  378,  837,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 100,    9, 8084,    4,  206,   24, 1060,  103,   13,  264, 2406,  220,
          601,  467,    7, 6568,   12,  452, 1534,   20,  371,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,   17,   11,    6, 3028,  254, 2627,    8, 1491,  388,  540,    9,
          440,   11,    6,  839,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 125,   53,   63,   77, 4767,    4, 1042, 1800,    7, 4269,    4,   53,
         2231,  324, 1381,    8,  618, 1333, 1059,  187,  111,  700,  432,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21, 1082,    6,  138,   10,  446,    7, 3978, 5227,    9,   13,  682,
          247,   71, 2869, 3189,    6,    4,  132,   10,  392, 3189,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  84,   11,    6, 4779,  143,  596,  254,  889,    9,    7,  179,    4,
           80, 1185,  584,  439,   12,    7,  179,   11,    6, 1682,   26, 3726,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   79, 3899,  384,  249, 1353, 1906,    6,    4,   24, 2699,  276,
          143, 1710,    4,  979,    4, 1794,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  13, 2033,   12,  688,    8, 1404,    4,   39, 9337, 2582, 1811,   12,
          183,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  89, 4492,  113, 3082,   62,    8,  246,  976, 1289,   10,  267,    9,
         4357,  266,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21, 7394,    6, 4749,    8, 4139,    8, 3035,  266,   54,    8, 3565,
           25,  206,  155,  558, 3228,   12, 5277,   63, 1028,  106,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   19,  487,   10,   51,   91,   12,  251,   94,  148, 1831,   17,
         2930,   63, 7716,    8, 5459,    8, 9649,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,   11,   57,  499,  752,   10, 1945,    8,  367,   10, 2047,   71,
           70,   26,    7, 7372, 5542,   12,   33,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   17,   11,    6,    7, 2695,  168,   55,  138,   24,  154,   33,
          282, 9373, 2122, 1620,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24, 1149,  456,   80,   94,   71,  453, 7471,   79, 1445,   21,  162,
          185,  746,   12,   39,    9,   22,  436, 4102,    4,   67,   17,   26,
           86,    7, 1165,    5,    2,    1,    1,    1,    1,    1,    1],
        [  53,   66,   13,  133, 5168, 2205,   10, 1370,    4,  166, 4333,    6,
          422, 1611,    4, 2395, 1370,    4,    7,  998,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  95,  266, 4656,   18, 1558,   57,   44,  476,   25,  133,    4,  133,
          261,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24, 9268, 1873,   24,   66,  391, 3795,  694, 8826,    6,   10,  283,
           69,   71,   33,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'cluster_tokens': tensor([[37, 37, 37, 31, 37, 37, 32, 11, 37,  2, 50, 85, 11, 37, 59, 11, 37, 85,
         37, 37, 83,  2, 83, 77, 35, 38, 77, 11, 37, 37, 49, 37, 32, 11, 83],
        [37, 37, 83, 59, 37, 32, 37, 37, 37, 38, 77, 11, 37, 83, 59, 50, 37, 85,
         11, 37, 85, 37, 59, 37, 50, 83, 36, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 50, 37, 37, 94, 85, 37,  2, 75, 94, 37, 82, 37, 38, 37, 83,
         35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37,  1, 49, 37, 94, 37, 37, 94, 37, 37, 75, 32, 77, 83, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 37, 38, 35, 38, 88, 11, 37, 49, 37, 85,  2, 32, 11, 37, 32, 85,
         32, 31, 37, 50, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 37, 37, 83, 11, 50, 83,  2, 94, 37, 37, 37, 94, 37, 28, 94, 31,
         37, 88, 11, 38, 35, 35, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 88, 31, 37, 85, 37, 37, 83, 85, 50, 50, 11, 37, 29, 37, 94,
         37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37,  6,  9, 38, 37, 35, 35, 37, 37, 11, 37, 37, 37, 37, 85, 83, 83,
         37, 33, 83, 37, 49, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 28, 11, 37, 38, 31, 37, 37,  2,  9,  6, 49, 38, 37, 94, 37, 38,
         35, 77, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 85, 37,  2, 37, 28, 37, 28, 31, 36, 37, 83, 85, 37, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 50,  2, 11, 83, 31, 37, 94, 11, 37, 49,  2, 94, 37, 49, 38,
         35, 35, 83, 50, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 59, 37, 37, 37, 59, 37, 32, 29, 37, 37, 38, 77, 37, 50,  9, 37, 11,
         37, 37, 17,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 50, 56, 37, 56, 37, 37, 94, 11, 37, 17, 73, 24, 37, 37,
         94, 85, 37, 23, 85, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 38, 77, 35, 77, 37, 11, 38, 49, 83, 50, 94, 11, 32, 11, 56,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 29, 37,  9, 37, 94, 11, 38, 28, 38, 35, 37, 24, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 56, 83, 49, 31, 37, 88, 83, 56, 37, 37, 37, 28, 35, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 29, 37, 49, 37, 88, 37, 38, 35, 49, 37, 88, 37, 37, 37, 37, 94, 37,
         56, 85, 49, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 38, 50, 37, 50, 56, 50, 31, 37, 56, 85,  2, 37, 28, 37,
          2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 77, 83, 49, 37, 88, 37, 85, 37, 32, 37, 50, 85, 37, 28, 32, 37,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 85, 37, 37, 32, 37, 37, 37, 38, 59, 37, 32, 29, 94, 85, 37, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 83, 16, 37, 56, 37,  2, 56, 37, 37, 37, 85, 50, 83, 37, 38, 37, 35,
         77, 32, 11, 37, 37, 85, 83, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83,  2, 32, 37, 94, 11, 37, 49, 37, 28, 56, 11,  2, 94, 11,
         37, 94, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 38, 35, 35, 77, 82, 83, 37, 83, 11, 83, 83, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 83, 86, 38, 85, 34,  2, 32, 32, 37, 37, 49, 37, 37, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:5'), 'lengths': tensor([35, 29, 21, 19, 25, 27, 22, 26, 23, 18, 25, 25, 26, 20, 15, 16, 24, 21,
        21, 19, 29, 23, 15, 17], device='cuda:5'), 'ntokens': 541}, 'target': tensor([[ 147,   39,  151, 2624,   27,   30, 8531,    4,   50,   14, 2785, 2321,
            6, 6394,  167, 3992,   76,   16,  210, 2064,  184, 2006,   18,  161,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [ 147,   88,   14, 2176,   15,   20, 9406,   28,  208,   16,   43,  263,
         6846,   28,  123,    4,  395,   81,  190, 3178,  548, 1883,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,   27,   52,   23,   56,  152, 2545,  381, 5698,   15,   23,  201,
           44,   40, 1716, 1196,  597,   20,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99,  394,   88,   14, 1316, 2617,   48,  426,  353,    4,   61,   14,
         2002,  124,   14, 1521, 3659,   28,  940,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 882,  414, 2725,  256,   31,    4,   81,  769, 1225, 4413,   83,    4,
          428,  897,  161,  216,  428,  728,  184, 1170,  307,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   61,  648, 3292,  470,  167, 2928, 5678,    9,   23,  201,  129,
         2324, 2935,    6,   28,  334,   44,   38, 1007,  973,  307,  594,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   14, 1572, 2714,   20,   28,    4,   30,   16,  671, 1549,   28,
          260,   16,  273,  972,  897,   28, 4589,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 720, 1627,  252, 3525, 1783, 3034,  177, 1126,    4,  136,   78,  107,
           82,   30, 3931,   52,  331,  353,  129, 3105,    6,  539,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 400,    9, 8322,    4,  258,   32,  107, 5145,    4,  403,   52,  585,
         6498, 1176,  503,    4,   14,  559, 1534,   20,  371,   20,  777,  631,
          390,   28,  226,  303,    5,    2,    1,    1,    1],
        [  92,   27, 2890,   90, 2898,   16, 2310,  466,    9, 8079,   45,  757,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92, 1908,  364, 1776, 3822, 3229,    6,  891,   16,   43,  702, 1925,
          382,   39,    6,  844,  805, 2095,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  41, 6573,    4,   58, 8411,  129, 1690, 8330,    6,   28,  605,    4,
           16,   30,    9,  151,  342,  152,  181,  236,   60, 3132,   22, 6973,
           22,    4,  382,   28,  392, 6973,   22,    5,    2],
        [  99,  178,  190,  216,  617,   90, 1438,   61,   23,  201,    4,  761,
         1185,  584,  950,   23,  201,  242, 6018,  165,   76,   24, 1331,  418,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [1493,   14, 3749,   15,  420,  983,    4,  664, 2628,   22,   32,  196,
          216, 5888,    4, 1877,   20,   16, 4297, 4408,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 312, 1087, 4556,   16,   40, 8071,   37, 1725, 2506,    4,   40, 3920,
          235,  975,  399,  481,    6,  590, 1761,  191,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1394, 3624, 4742,   15,   43,  139,   16, 1457,  355, 1528,   15, 3234,
           61, 1926,  541,  625,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99, 9285, 8134,    4, 8448,   16, 2624,   20,   16,  888,  252,    4,
           98, 4613, 2282,  512, 1642, 2889,   22, 2149, 1126,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 1277,    4,   52,   49,  628,   28,  127,    4,   14,  917,   90,
          190, 4978, 5226,  662,    6,    4,   56, 7560,   22,  481,    6,   16,
          312, 1285,   96, 1378, 4789,    5,    2,    1,    1],
        [ 104, 1166,  257,  196,   28,  725,   16, 2625,    4,   34,   23, 2569,
          152,   57, 4190,  477,   27,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92,   27,  113,   30, 2635,   78,  273, 2144,    4,   74,  105,  732,
          352, 5284,   59,  165, 1048,   27,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104, 1561,   12,   18,   49,  157,   60, 1225,   45, 6218,    4,   90,
          578,   36,   52, 4124,  285, 2605,  165,    4,  136,   30, 2714,   29,
           47,    5,    2,    1,    1,    1,    1,    1,    1],
        [  41,   83,  118,  862,   20,  235,   56, 7976,   15, 5094,   78,   14,
         2086,    4,   23,   14, 7188, 4332,   15,    4, 4472,   16,   14,  342,
          219,   22,  426,   40, 7636,    5,    2,    1,    1],
        [ 202,  266,  674,  803,   18, 1558,   57,   44,   72, 3862,  252,  275,
          627,    6,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104, 4687,   22,    4,   50,   32,   39,  462, 4334,   15,  496, 3604,
          357,  845, 2081,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'target_lengths': tensor([26, 24, 20, 21, 23, 25, 21, 25, 30, 14, 20, 33, 26, 22, 22, 18, 23, 31,
        19, 20, 27, 31, 16, 17], device='cuda:5'), 'ntokens': 554, 'nsentences': 24}
##################### {'id': tensor([152262,  54251,  87266, 208505, 146258, 111993,  94454, 212347,  16728,
        137632, 186473,   6852,  66712, 102806, 165610,  58676],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[ 1.8311e-04, -1.2207e-04, -1.8311e-04,  ..., -2.7771e-03,
         -5.7068e-03, -7.5073e-03],
        [ 1.0284e-02,  9.7046e-03,  9.1553e-03,  ..., -5.0659e-03,
         -5.4016e-03, -6.3171e-03],
        [ 2.1362e-04,  6.1035e-05,  2.4414e-04,  ...,  1.9836e-03,
          1.9531e-03,  2.6855e-03],
        ...,
        [-1.5259e-03, -1.5564e-03, -2.2278e-03,  ..., -1.6785e-03,
         -1.5259e-03,  0.0000e+00],
        [-9.6130e-03, -6.7444e-03, -8.8196e-03,  ...,  3.3875e-03,
          0.0000e+00,  0.0000e+00],
        [ 4.6997e-03,  5.2795e-03,  4.5776e-03,  ...,  6.5918e-03,
          5.7373e-03,  0.0000e+00]], device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([150080, 150080, 150080, 150080, 150080, 150080, 150080, 150080, 150080,
        150080, 150080, 150080, 150080, 150079, 150079, 150079],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2,   72, 1904,    4,   50,   31,  256,  550,   60, 6202,   49,  640,
         1389,   15,   47,  701, 1398,    4,  136,  256, 4296,   82, 3880,    4,
           90,   95,  163, 9020,   39,    6, 1029,    4,   16,   31,  198,  915,
           44,   38, 2507, 3475,   37,   90,   23, 5134,    6,  174,  683,    4,
         1926,  243,  614,  311,  137],
        [   2, 2235, 3624,   97, 5358,   78, 6915,   35, 3736,  311, 2412,   16,
           38,  360,  777,   22,   18, 1252,  266,    6,  980, 4245,   60, 8477,
           22,   14,  582,   20, 1162,  971,  176, 2648,  195,    9,  151, 3852,
         4002,  549,   35,  360,  777,   22,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  298,  161,   14,  972,  177, 1093,   16,   14, 5300, 5265,   97,
         6570,   77,  337, 1280, 2863, 5498,    4,    9,  141,  353,   28, 1697,
           45,  356,  610,    4,   14,  210,  777,  356,  849,   27,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  228,   58, 1286,  332,  161,  212, 1093, 3369, 1845,  477,  529,
          380,    4,   74, 1342,  212,  507,  303,  622, 2398, 1194,   28,  247,
         1124, 1430,   16, 5836,    9,   58,  285,  878,   59,  861,   61, 2298,
          161,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  882,  212, 3076,  145, 1342, 2295,  373, 6690,   14, 1258,  176,
         5116,  634,   51, 3951,    4,  478,   74,   43,   36,    9,   58,   58,
         1030,    4, 9476,   15, 4192,  260,    5, 2558,  145,  385,  201, 7047,
           35,  592, 2845,   15,   97, 1129, 4956, 5171, 4664,    5,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  327, 8608,  537,  145,   27,    4,   50,  177,  151,  497, 3961,
          787,  129, 1083, 2368,    6,    9,  149, 1130, 1596, 7917,   76,    4,
           43, 3888,   22,   36,   58, 1483, 3488,   35,  899,   59, 3488,   49,
         1056,   44, 3497, 3271,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 2660,   76,   32,   78,   58, 2943,   49, 5855,  548,   35,   16,
          420,  247,   57,  365,   16,   83,  847,  761,   14, 2803,  536,  259,
            9,  304,  762,  390, 1190,  500,  901, 5217,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  912, 5922,   76,   32,   39,  102, 1389,    4,  258,  402, 1865,
           18, 2746, 4393,  344, 1163,  121,   35, 2137,  809,   59,  152,  311,
            6,   47,  149, 1048,    4,  519, 1210,  497,  704,  161,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  146, 2367, 1411,   20,   76,    9,   58, 4845, 1737,  357, 2038,
          184, 2764,   46,   16,   30, 5373,  863,  478,   60,   23,  590, 4591,
           23, 1280, 4016, 7368,   15,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  104,  123,  547,   14, 3242,  141, 8233,  119,   57, 2594,    4,
           30, 7137, 2451,  344, 2379,  940,   16,  182, 1787, 2467, 7503,   22,
          123,   32,  582,   58, 1013,  381,  758,  223,  105, 8501,  605,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,   99,   27,   52, 2530,    4,   50,  600,   97,  184, 4965,   15,
         6519,    4,  102, 4036,  381, 1093,   23,  201,    4,  435,   98,   38,
         5551, 2061,  197, 5798, 2319, 4103,   18,  127,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2, 1046, 4408,  695,    4,   50,   30, 2615,  426, 4472, 6531,   23,
          201,   30, 1235, 1792,  349,  443,   18, 3026,  322, 1612,  233,   18,
           95, 2491,    4,    9,  631,   36,  302, 6748,   20, 3052, 5722,   22,
         5518,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  327,   82,  113, 1791,   39,  102, 3922,  322,  794,    4,   16,
           39, 2009,  177, 6920,   15, 2119,    4,   16,   34,  113, 1571,  189,
           58, 5064,   15, 2190,   42,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  504,   27,   30, 2635,   44,  222,   41,   40,   95,  156, 2150,
         1485,  124, 7242,   96, 4486,   83,    4,  940,   32,   40, 3810,   96,
         1716,  129, 5533,    6,    4, 2132,   90,   52, 5513, 5155, 2908,   20,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  222,   41, 1654,   14, 4923,  658,  233,   15, 1989,    4,  127,
           41, 7475,    4,   50,   14,  157,   23, 7585,   16,   58, 5337,   22,
         1138, 4508,  319,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [   2,  882,  151,   56, 7292,  500,  510,  530, 1533,   48,  962, 1676,
           16,  151,  574,   37,  233,   15,  707,  754,   82,  374, 1048,    4,
          182, 1743,  573,   36,  286, 3467,  216,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[  19, 1425,   19,  465,   11,   18,   66,   10, 2215,  132,   89, 1780,
           12, 6202,  126,   12,  640,    4,   67,   89, 2693,  340,  181, 1625,
          369,   34, 3768,  120,  101, 1260,   85,  110,    4, 6159,   48,    4,
            8,   19,  474,   10, 1222,    4,   38,    6,   45,  973,   37,  254,
            7, 2313, 3848,    4, 1276, 2470, 3637,  137,    2],
        [ 108, 4492,    9,    7, 1740,   55, 6315, 7652,    8, 3954,   18, 1252,
          266,    6,   63,  204, 8634,   71,  159, 2279,  373, 2585, 1461,   37,
         1068,    9,   13, 1127, 4312,   22, 3954,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,    7, 7771,   12,    7,  768,    8,    7, 5113, 2068,   48,  322,
            9,    7, 1422,  164, 2156,   77,   12,  117,  264, 2671,   10,  521,
          352,  247,    9,   13,   81,  706,   17,   26,  116, 9410,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 244,    7,  558,  555,  215,    4,   33, 2696,  164, 3848, 6853,    4,
           79,  545,   12,  117, 2771,  373,   26, 5186,   62,    8, 1051,    6,
         1331,  111,  561,   48,    9,  251, 2937,  693,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   9,   33, 1677,    4,  419, 6562, 1365,   73, 4432,    7,  370,  883,
          200, 3422,   17,   53,   63,  979,   54,    9,    7, 9476, 2685,    4,
         2307,   73,  229,   13,  179,   35,  140, 2706, 1122,  265, 4866,   85,
          155,  876,   22,   54, 4468,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  70,  220,  205, 1226,   26,   17,   13,  464,  581,    4, 2703,  439,
           12,    7, 1711, 1232,  116, 4606,    6,    9,  785, 1601,    4,    8,
           53,  434,   21,    7, 7622, 5471,   12, 1056,   44, 3497,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   85,    7,  183,   12,  378, 6036,  346,   84,    4,   24,  162,
         2219,    9, 1954, 6935,    4,    8,   29,   24,  162,  142,  270,    8,
         4404,   55, 1223,    7, 1590,   12, 5855,    4, 5275,   80,  854,  108,
          183,    9,   56, 3256,  390, 2937,   93,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   69, 1219,   12,   17,    4,   21,   11,    6,   85,    7,  613,
          206, 6605, 8899,   12,  618, 4340,   26,   86,  288, 1254,    4,   67,
           21, 1559,  509,  333,  464,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 159,  811, 1411,    6,  513,  346,   13,  325,    9,    7, 1666, 5611,
            6,   46,    8,  204,   17, 6982, 3744,  132,  172,    4,  172, 1387,
          111,   71,   33, 6982,    9,  264, 3538, 6898,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,    4,   24,   73,  305,   13, 1636,   12,   13, 3753, 2839,    4,
           24,   73,  305,   13, 6602, 1478,   12,   13,  595,    4,    8,   71,
          185,   21,   37,  271,    4,   24,   73,  204,  446,    7,  743,  608,
          207,  336,   17, 2839,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   33,   26,    7, 1874,    4,   17,  276,    9,  108,   51,  614,
          121,   48, 5170,    4,    7,  281, 1968,  561,    9,    7,  179,    4,
          708,   63,  378, 6440,   48,  125,   12,   13, 1507,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 125,   69, 1219,   12,   17,    4,    7,  179,   11,    6, 2237,  608,
          227, 1411,    6, 1543,   26,  203, 4030,  140,   54,    7, 1318,   17,
           56,  668,  322, 1405,  131, 4777,   54,  248,  238,   35,  614,  121,
           48, 1237, 2102,    6,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   70,   34, 1226,   71,   17, 5969,    4,    8,   71,   77,  909,
           35,    6,  609,   15,   18,  597,  266,  826,    4,    8,   70,    4,
          180,    4,  442,   17,  765, 1032, 1878,   42,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,    7, 2695,  168,   44,   29,  103,   25,   87,   66,   13, 2585,
           20,  484,   62,  109,    9, 3196, 1314, 3337,    4,   24,  305,   13,
          133,  822, 1472,   12,   17, 4826,    4,  908,  254,  854,    7, 1951,
           12,   13, 1850,  709, 1449,  362,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,  103,   25, 4101, 4653,    7,  906, 1386,    6,    4, 1445,    4,
           25,   11,  158,  150,   17,    7,   94,  162, 1019, 4324,   12,    7,
         3791,    4, 1019, 4324,   12,    7, 5911,    6,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  71,    7, 2745,    9,    6,   15,    6,  235,  366,   10, 3454,    4,
            8,   13,  574,   37, 1691, 6101, 1726,   77,   51,   18,    6,  162,
          518,    4,    7, 3253,   34,    7, 3755,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:0'), 'cluster_tokens': tensor([[38, 31, 38, 85, 85, 35, 85, 37, 49, 37, 37,  9, 37, 34, 37, 37, 34, 11,
         37, 37, 31, 35, 35, 35, 44, 85,  2, 37, 38, 59, 37, 37, 11, 32, 31, 11,
         37, 38, 31, 37, 37, 11, 38, 37, 35, 35, 77, 37, 37, 83,  9, 11, 94, 52,
         77, 11, 83],
        [37, 56, 37, 37,  9, 37, 28, 94, 37, 38, 35, 35, 35, 37, 85, 83, 49, 37,
         37, 38, 56, 29, 35, 77, 35, 37, 37, 50, 28, 35, 38, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 94, 37, 37, 94, 37, 37, 36, 35, 31, 35, 37, 37, 94, 85,  6, 50,
         37, 37,  2, 56, 37, 38, 35, 77, 37, 37, 38, 77, 37, 85, 83,  2, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 37, 50, 24, 11, 37, 23, 85,  9, 59, 11, 37, 50, 37, 37, 32, 56,
         85, 88, 31, 37, 38, 37, 43, 83,  9, 31, 37, 50, 23, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 94, 11, 50, 28, 94,  6, 49, 37,  4, 38, 35, 56, 37, 37, 85, 32,
         49, 37, 37, 28, 94, 11, 50,  6, 49, 37, 94, 38, 35, 35, 38, 35, 35, 37,
         37, 38, 35, 49,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [50,  6, 85,  2, 85, 37, 37, 24, 83, 11, 34, 24, 37, 37, 50,  9, 83, 29,
         37, 37, 34, 24, 11, 37, 37, 31, 37, 37, 29, 29, 37, 17, 82, 34, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 37, 24, 37, 49, 31, 37, 37, 11, 38, 85, 83, 37, 38, 28, 11, 37,
         83, 38, 85, 49, 37, 37, 37, 37, 83, 37, 38, 37, 25, 11, 49, 37, 53, 37,
         24, 37, 38, 39, 77, 23, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 38, 37, 37, 11, 37, 85, 37, 37, 37, 32, 37, 83, 94, 37, 49, 16,
         85, 83, 83,  6, 11, 37, 37, 85,  2, 50, 24, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 38, 35, 37, 85, 37, 37, 83, 37, 37, 83, 25, 37, 11, 37, 83, 37, 29,
         56, 37, 83, 11, 83, 83, 83, 37, 37, 29, 37,  2, 28, 94, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 11, 38,  6, 49, 37, 94, 37, 37, 28, 29, 11, 38,  6, 49, 37, 28, 32,
         37, 37,  9, 11, 37, 37, 50, 37, 77, 44, 11, 38,  6, 83, 59, 37, 83, 75,
         83, 37, 37, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 85, 37, 94, 11, 37, 83, 37, 37, 38, 35, 35, 31, 28, 11, 37, 75,
          2,  9, 37, 37, 94, 11, 56, 85, 49, 29, 31, 37, 37, 37, 94, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37, 38, 37, 37, 11, 37, 94, 85, 37,  2, 75, 38, 35, 37,  9, 85, 38,
         35, 35, 49, 37,  9, 37, 38, 35, 35, 31, 37, 29, 49, 34, 83, 38, 35, 35,
         31, 94,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 50, 85,  2, 37, 37, 32, 11, 37, 37, 50, 38, 38, 37, 35, 77, 35, 35,
         35, 59, 11, 37, 50, 11, 37, 11, 31, 37, 24,  2, 33, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 32, 37, 82, 83, 37, 37, 85, 85, 37, 29, 77, 35, 31, 37, 37, 35,
         31,  9, 11, 38, 49, 37, 83,  2, 32, 37, 37,  9, 11, 50, 37, 53, 37, 23,
         37, 37, 38, 35, 38, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [83, 37, 37, 29, 37, 37,  9, 35, 37, 11, 37, 11, 37, 85, 35, 59, 37, 37,
         56, 85, 83, 83, 37, 37, 94, 11, 83, 83, 37, 37, 28, 37, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37],
        [37, 37,  9, 37, 37, 77, 37, 35, 77, 37,  9, 11, 37, 37, 38, 77, 77, 49,
         32, 50, 38, 35, 37, 85, 37, 11, 37,  9, 85, 37,  5, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37]], device='cuda:0'), 'lengths': tensor([57, 33, 36, 34, 43, 36, 45, 31, 35, 42, 35, 42, 33, 44, 34, 33],
       device='cuda:0'), 'ntokens': 613}, 'target': tensor([[  72, 1904,    4,   50,   31,  256,  550,   60, 6202,   49,  640, 1389,
           15,   47,  701, 1398,    4,  136,  256, 4296,   82, 3880,    4,   90,
           95,  163, 9020,   39,    6, 1029,    4,   16,   31,  198,  915,   44,
           38, 2507, 3475,   37,   90,   23, 5134,    6,  174,  683,    4, 1926,
          243,  614,  311,  137,    2],
        [2235, 3624,   97, 5358,   78, 6915,   35, 3736,  311, 2412,   16,   38,
          360,  777,   22,   18, 1252,  266,    6,  980, 4245,   60, 8477,   22,
           14,  582,   20, 1162,  971,  176, 2648,  195,    9,  151, 3852, 4002,
          549,   35,  360,  777,   22,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 298,  161,   14,  972,  177, 1093,   16,   14, 5300, 5265,   97, 6570,
           77,  337, 1280, 2863, 5498,    4,    9,  141,  353,   28, 1697,   45,
          356,  610,    4,   14,  210,  777,  356,  849,   27,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 228,   58, 1286,  332,  161,  212, 1093, 3369, 1845,  477,  529,  380,
            4,   74, 1342,  212,  507,  303,  622, 2398, 1194,   28,  247, 1124,
         1430,   16, 5836,    9,   58,  285,  878,   59,  861,   61, 2298,  161,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 882,  212, 3076,  145, 1342, 2295,  373, 6690,   14, 1258,  176, 5116,
          634,   51, 3951,    4,  478,   74,   43,   36,    9,   58,   58, 1030,
            4, 9476,   15, 4192,  260,    5, 2558,  145,  385,  201, 7047,   35,
          592, 2845,   15,   97, 1129, 4956, 5171, 4664,    5,    2,    1,    1,
            1,    1,    1,    1,    1],
        [ 327, 8608,  537,  145,   27,    4,   50,  177,  151,  497, 3961,  787,
          129, 1083, 2368,    6,    9,  149, 1130, 1596, 7917,   76,    4,   43,
         3888,   22,   36,   58, 1483, 3488,   35,  899,   59, 3488,   49, 1056,
           44, 3497, 3271,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [2660,   76,   32,   78,   58, 2943,   49, 5855,  548,   35,   16,  420,
          247,   57,  365,   16,   83,  847,  761,   14, 2803,  536,  259,    9,
          304,  762,  390, 1190,  500,  901, 5217,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 912, 5922,   76,   32,   39,  102, 1389,    4,  258,  402, 1865,   18,
         2746, 4393,  344, 1163,  121,   35, 2137,  809,   59,  152,  311,    6,
           47,  149, 1048,    4,  519, 1210,  497,  704,  161,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 146, 2367, 1411,   20,   76,    9,   58, 4845, 1737,  357, 2038,  184,
         2764,   46,   16,   30, 5373,  863,  478,   60,   23,  590, 4591,   23,
         1280, 4016, 7368,   15,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 104,  123,  547,   14, 3242,  141, 8233,  119,   57, 2594,    4,   30,
         7137, 2451,  344, 2379,  940,   16,  182, 1787, 2467, 7503,   22,  123,
           32,  582,   58, 1013,  381,  758,  223,  105, 8501,  605,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [  99,   27,   52, 2530,    4,   50,  600,   97,  184, 4965,   15, 6519,
            4,  102, 4036,  381, 1093,   23,  201,    4,  435,   98,   38, 5551,
         2061,  197, 5798, 2319, 4103,   18,  127,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [1046, 4408,  695,    4,   50,   30, 2615,  426, 4472, 6531,   23,  201,
           30, 1235, 1792,  349,  443,   18, 3026,  322, 1612,  233,   18,   95,
         2491,    4,    9,  631,   36,  302, 6748,   20, 3052, 5722,   22, 5518,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 327,   82,  113, 1791,   39,  102, 3922,  322,  794,    4,   16,   39,
         2009,  177, 6920,   15, 2119,    4,   16,   34,  113, 1571,  189,   58,
         5064,   15, 2190,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 504,   27,   30, 2635,   44,  222,   41,   40,   95,  156, 2150, 1485,
          124, 7242,   96, 4486,   83,    4,  940,   32,   40, 3810,   96, 1716,
          129, 5533,    6,    4, 2132,   90,   52, 5513, 5155, 2908,   20,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 222,   41, 1654,   14, 4923,  658,  233,   15, 1989,    4,  127,   41,
         7475,    4,   50,   14,  157,   23, 7585,   16,   58, 5337,   22, 1138,
         4508,  319,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1],
        [ 882,  151,   56, 7292,  500,  510,  530, 1533,   48,  962, 1676,   16,
          151,  574,   37,  233,   15,  707,  754,   82,  374, 1048,    4,  182,
         1743,  573,   36,  286, 3467,  216,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([53, 43, 35, 38, 46, 41, 33, 35, 30, 36, 33, 38, 29, 37, 28, 32],
       device='cuda:0'), 'ntokens': 587, 'nsentences': 16}
##################### {'id': tensor([ 28398, 123286,  65376,  34379, 136662,  93416, 147159, 108153, 219425,
        156184,  15768,  34771, 127053,  64949, 162910, 204018, 159165, 100278,
        116516, 208637, 215351, 118160, 195195, 165197, 224094, 171979, 128372,
        179581, 119415,  40974,  40975,  17917,  68660, 125513,  59082, 147188,
         52116, 127584,  67193,  47542, 187883,  38857, 138075,  99446, 190662,
        114131,  71681, 174590, 219285, 198841,  57269, 156000, 147596,  97345,
         71327,  32115], device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 0.0023,  0.0017,  0.0019,  ...,  0.0305,  0.0231,  0.0052],
        [-0.0005, -0.0012, -0.0016,  ...,  0.0040,  0.0052,  0.0046],
        [-0.0014, -0.0006, -0.0003,  ..., -0.0114, -0.0139, -0.0152],
        ...,
        [-0.0062, -0.0030, -0.0016,  ...,  0.0065,  0.0056,  0.0000],
        [-0.0027,  0.0016, -0.0004,  ..., -0.0037, -0.0050,  0.0000],
        [-0.0236, -0.0269, -0.0222,  ..., -0.0024, -0.0025,  0.0000]],
       device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560,
        38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560,
        38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560,
        38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560,
        38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560, 38560,
        38560, 38560, 38559, 38559, 38559, 38559], device='cuda:2'), 'prev_output_tokens': tensor([[   2, 3192,   32,  ...,    1,    1,    1],
        [   2, 8951, 1121,  ...,    1,    1,    1],
        [   2,  285, 1689,  ...,    1,    1,    1],
        ...,
        [   2, 8204,   27,  ...,    1,    1,    1],
        [   2, 2915,  221,  ...,    1,    1,    1],
        [   2,   72,  421,  ...,    1,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[  24,  205,   10,  ...,    1,    1,    1],
        [   7, 2196,    4,  ...,    1,    1,    1],
        [ 954,  155, 1893,  ...,    1,    1,    1],
        ...,
        [1094,    4,   21,  ...,    1,    1,    1],
        [  29,    4,  832,  ...,    1,    1,    1],
        [   8,   19, 6380,  ...,    1,    1,    1]], device='cuda:2'), 'cluster_tokens': tensor([[38, 85, 37,  ..., 37, 37, 37],
        [37, 94, 11,  ..., 37, 37, 37],
        [49, 37, 47,  ..., 37, 37, 37],
        ...,
        [83, 11, 37,  ..., 37, 37, 37],
        [83, 11, 38,  ..., 37, 37, 37],
        [37, 38, 88,  ..., 37, 37, 37]], device='cuda:2'), 'lengths': tensor([14, 12, 15, 17,  9, 10, 10, 17, 13, 17, 17, 11, 14, 12, 12, 10, 11, 10,
        10, 10, 12, 16, 10,  8, 18, 11, 16, 14, 11, 16, 14, 19, 13, 10, 16, 11,
        23, 11, 16, 15, 15, 20, 15,  9, 16, 13, 13, 12, 11, 14,  8, 16, 13, 17,
        17, 17], device='cuda:2'), 'ntokens': 757}, 'target': tensor([[3192,   32,  107,  ...,    1,    1,    1],
        [8951, 1121,   27,  ...,    1,    1,    1],
        [ 285, 1689,   15,  ...,    1,    1,    1],
        ...,
        [8204,   27,   36,  ...,    1,    1,    1],
        [2915,  221,    4,  ...,    1,    1,    1],
        [  72,  421, 9173,  ...,    1,    1,    1]], device='cuda:2'), 'target_lengths': tensor([10,  9, 20, 39, 12, 11, 10, 15, 14, 11, 20, 14, 13, 10, 10,  8, 10, 15,
         9,  8, 11, 10,  9, 14, 15, 12, 20, 17, 18, 23, 18, 19, 18, 11, 15, 10,
        21, 12, 13, 14, 10, 14, 15, 11, 16, 12, 10, 13, 10, 13,  9, 12, 15, 19,
        15, 18], device='cuda:2'), 'ntokens': 780, 'nsentences': 56}
##################### {'id': tensor([111642,  10958,  33873, 198827,  81933,   8305, 138209,  39631, 219651,
        119645, 198891, 156466, 127319, 193724, 135963, 157171,  33915, 185441,
         16929, 135113,  33638,  14515,  11782,  29247, 205982, 104765,    109,
        210929,  20121, 198079, 198733,  19806], device='cuda:2'), 'net_input': {'src_tokens': tensor([[-0.0015, -0.0027, -0.0047,  ..., -0.0108, -0.0070, -0.0044],
        [-0.0018, -0.0018, -0.0015,  ..., -0.0009,  0.0005,  0.0021],
        [-0.0022, -0.0003,  0.0021,  ..., -0.0024, -0.0049, -0.0071],
        ...,
        [ 0.0027,  0.0020,  0.0003,  ...,  0.0002,  0.0017,  0.0000],
        [-0.0359, -0.0422, -0.0269,  ..., -0.0017, -0.0006,  0.0000],
        [-0.0151, -0.0153, -0.0147,  ..., -0.0102, -0.0098,  0.0000]],
       device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([64960, 64960, 64960, 64960, 64960, 64960, 64959, 64959, 64959, 64959,
        64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959,
        64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959, 64959,
        64959, 64959], device='cuda:2'), 'prev_output_tokens': tensor([[   2,   99,   27,   52, 4900,   20, 5344,    4,  136,  334,   41,   30,
           58, 1652, 3701,  357,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 2899,  176,   57, 7880,  551,   48,  481,    4,   14,   98,  102,
          201, 1021,   28,  107, 4009,   76,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   64,   88, 1593,   28, 1176,    4,   56, 7609,   20,   31,   14,
         3453,  318,    4,  385, 1844,  745,    4,   34,  316, 4930,  119,    5,
            1,    1,    1,    1],
        [   2,   92,  578,  113,   40, 4641, 1924,    5,   40,  167,    4,  167,
         1954,  527,   37,   46,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   68, 3504,   65,  377,   48,  189,   83,   36,   40,  542,  310,
           98, 4686, 1824,  111,   22, 1036,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 2609, 1364,   30, 5843,  716,    4,   50,   23, 4185,   29, 1225,
         1684,  130,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  441,  141, 1493,   20, 3159,   31,  118, 2742,   15, 2978,    9,
         4559,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  402,   76,  113,  470, 5195, 4008, 1319,   18,  233,   37, 2039,
         8348,   15, 8894,   59,   90,  331,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  202,  161, 4470,    9, 1012, 1716,   20, 2996,  124,  863, 1013,
          186,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   64,   31,  209,  177,   49,  141, 2649,  763,  812,   28,  498,
           15,    4,   74,   49,  141, 2649,  763,  812, 2101,   18, 1034,  300,
           18,  398,    5,    1],
        [   2, 5196, 1000,   40,  330,  187,  986,   14,  301, 4125,   18,  160,
          481,  869,  265, 1283, 6022,    4,  681,   32,  231,  223, 8777,    5,
            1,    1,    1,    1],
        [   2,   92, 5880, 4642, 3142,   76,  302, 2865,   20,  112, 1929,  184,
          119,  219,  237,  265,   18,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  402, 3290,   81,  514,    4,   74,   81,    9,  141, 1299,  271,
         8732,    4,  145,   81,  139, 2276, 5401,   39, 4753,    5,    1,    1,
            1,    1,    1,    1],
        [   2, 6974,  239,   23, 9888,  389,  530, 2162,  382,   28,  328, 4180,
           47, 3436, 1349,   42,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  327,   27,   23,   98, 2857, 1500,  262, 3492, 2404,    4,   23,
           14,   49,  198, 9176,   20, 5102,   56, 4385,   18,   42,    1,    1,
            1,    1,    1,    1],
        [   2,   72, 2140,   20,  304,  232,  311, 1199,  729,    4,  382,   31,
           52, 5069,  437, 1539,   98,  771, 3363,  421, 3475,  153,    5,    1,
            1,    1,    1,    1],
        [   2, 5813,  119,  316,    4,   50,   14, 4164,  410,   23, 6401, 1131,
          124,  410,   23, 5835,   27,   42,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  146, 6947, 6644,   22,   36,    4, 3191,   60, 3654,   15,   28,
         3913,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   92,   76,   14, 2588,    6, 4735, 1863, 2089,    4,   14,  299,
         2635,   60,  262, 2172,  272,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  146, 5263,  344, 1379,    4,   61,  102, 1517, 1614, 1524,  157,
          702,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 1207,    6, 4434,  239,   23, 5531,   23, 5903, 6005, 2531,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   64,   43, 6370,   75,  167, 1013,    4,  600,   98,    6,   37,
         1054,  174,   23, 1270,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   41, 2004,   97, 4757,   15, 8376,  564,  820,  584,  217, 5270,
           39,    4,  149,   88,   14, 2734, 1689,  481, 7413,  433,  517,   28,
          208,    5,    1,    1],
        [   2,   72,  449,  113,   28,  725, 1166,   74,   31,  223, 2031,   60,
          102,  817,   40,    6,  557,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3390, 1687, 2512,   30, 4203,   20, 8612,   39, 2031,    4,   88,
         1407, 5135,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  104,   56, 2305,   39,    4,   16,   32,  127,  171,   22, 1895,
          307,    5,   72,  256,   44,  171,   22, 1895,  307,   39, 1093,   16,
         3670,    5,    1,    1],
        [   2,   99,   27,   40, 1311,   60,  102, 7229,    4,  118, 4979, 3659,
           61,   23, 1083,  201,   28,   83,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3510,  462,   44, 3670,  231,  157, 7814,    4,  318,   16,   39,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  376, 3514, 5041, 4443,    4, 2742,   74, 1096, 1926,  128,    6,
           20,   20,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   38,  967, 3490, 8923,   90, 3204, 7931,   37,   16,  342,  315,
          311,  160,    4,  761, 4116, 1709,  427, 2257,    5,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   99, 2835,  139,   28,    4,  114,   32,   60,  872, 5864,  549,
          466,   76,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  147,  114,   31,   39,  256, 5660,  420,  303,  636,  193,  208,
           41,    4,   31,  313,    9,  141, 2161, 2470, 9395,    9, 1196,  411,
           18,  232, 7328,    5]], device='cuda:2')}, 'transcript': {'tokens': tensor([[  21,   11,    6,   39, 5709, 6073,    4,   67,  450,   17,   10,    7,
           94,    9, 4092,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [1301, 7079,    6,    4, 6389,    6,   17, 6565,  106,  126,   37,  672,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 421,  174,   44, 1586,    4,    8,  116,   10,  601,   25,  126,    4,
           19,   11,  158, 2477,  134,  106, 1466,    4,   29, 2684,   73,  150,
           70,   25,   11,   57,  401,    5,    2],
        [  29,   17,  169,   51,   13,  324,  561,   10,  498,    5,  133,    4,
          133, 8756,   46,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  68, 3439,   65,    8,  180,  185,   94,  106,  862, 5608,  111,   22,
         1095,   21,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  12,  538,    4,   17,   11,    6, 2248,  111,  125, 2127,  468,  188,
          324, 2986,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  19, 1742,   13,  456,  100,   33,    9, 4517,   13, 1025,  270,   80,
           33,  613,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  29,    4,  185, 4621,    4,   55, 8548, 3925, 2826,    4,   63,  143,
         8894,  254, 1573,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6, 2129,  142,   10,  227,   45, 3488,  199, 2768, 3675,
          109,  205,  923,  743,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   8,   19, 1757,   10,  498,  106,   13, 1747, 3059,    4,  100, 2562,
         1034,  300, 1011,  106,   13, 1747, 3059,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 103, 1183,   34,   10, 3172,   39, 5901,   85,    7,  227,  365,  881,
         2346, 4374,    4,   24,   11,   48,   77,  205, 3310,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   7, 2232,   69,    7,  859,   26,  248, 3144,    6, 8164,   62,   69,
         1219,   12,  545,  218,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  29, 1042,   25,  135,  138,   10, 2618,    9,  774,  271,    4,   25,
           73,  204, 2213,  132, 3648,  452, 5729, 1197,  111,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 347,   26,   21,   17,    7, 9864, 6409, 1359,   11,   18, 5030, 2534,
           85,   33,  613,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 166,   26,    7, 4298, 2994, 2404,  166, 2700,  110,   13, 7039,   48,
         4157,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  19,   34,  802,  117, 5933,  225,  293,    6, 1325,   19, 5824,  232,
           13, 5931,  106,    7, 2100,   17,   19, 1639,   85,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  87,   25,  154,    7,  851,  678,   20,   26,  850,  155,  859,  109,
          155,  230,  874,   42,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 461,  266,  763,  480,    6,  113,  570,   10, 6126, 7471,   10, 1427,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  25,  135,    4,  117,   63,    7,   10, 1556,   54, 1075,   17,  321,
           12, 4091,   33, 2695,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   7, 4620,    6,   12,   13,  943,   71, 1614, 1072,   94,    8, 2937,
           54,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [2270,    6, 4434,  188,  226,  434,    7, 5410,   12, 1885, 5099,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   8,   53, 2551,    4,  204,    4,  133, 2117,    4,  276, 1663,    7,
          832,    5,    6,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  53,  278,   10,    7, 6708, 2402, 8338,  564,  820,  584,   10,  446,
           13, 2734, 1689,  589, 5714, 1220,   84,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   8,   29,   70,   19,   11,   48,  100,   10,   87,   26,  780,   10,
         1531,  126,  138,   10, 2802,   71,    7,  672,  359,    7, 4814,    5,
            2,    1,    1,    1,    1,    1,    1],
        [ 333, 5099,    4,  164,  368,    7,  886, 1674,   45,  502, 1648,   12,
          639, 2875,   10,  229,  998,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  24,  954, 2433,    4,    8,   24,  175, 2345, 2077,  126,   46,   19,
          641,    4, 2345, 2077,  126, 4173,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6,   13, 1039,   17,  188,    7, 2463,   10,  229,   13,
         1523, 2302,  336,    7,  179,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 800,  391,    4, 2993,   77,   12,    7,   94,  185,   12,    7,  183,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   7, 1648,   26, 3424, 2233,    4, 1552,  100,    7,   13, 1643, 1580,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  38,  187, 1639,   79,   13, 1598,  191,  345,    8, 3673,    4, 2313,
           12, 4116, 1551,   13, 1822, 1025, 7623,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 166,   26,  113, 2244,   48,  120,   24,   11,   57,   71,  108,  596,
         1431,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  67,  665,  207,  270,    4,  120,   19,   34,   13, 1269,   46,   25,
          150,    4,   19, 3367,  132,    9,   13,   10, 2470, 6412,    9, 3981,
           18,  232,    5,    2,    1,    1,    1]], device='cuda:2'), 'cluster_tokens': tensor([[37, 85, 37, 38,  2, 94, 11, 37, 88, 37, 37, 37, 56, 37, 29, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [ 2, 28, 37, 11, 23, 37, 37, 31, 37, 37, 77,  9, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 82, 83, 11, 37, 83, 37, 49, 37, 37, 11, 38, 85, 35,  9, 37, 37,
         19, 11, 83, 50,  6, 59, 50, 37, 85, 77, 49, 11, 83],
        [83, 37, 85, 38, 37,  2,  9, 37, 49, 11, 83, 11, 83,  2, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 28, 11, 37, 37, 50, 56, 37, 38, 35, 83, 35, 59, 37, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 85, 37, 83, 83, 37,  9, 29, 85,  2, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 37, 16, 37, 37, 37, 28, 37, 24, 37, 37, 37, 32, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 50, 56, 11, 37,  2, 94, 56, 11, 85, 50,  2, 37, 50, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 50, 49, 37, 38, 35, 35, 37,  2, 56, 37, 85, 83, 83, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 32, 37, 49, 37, 37, 38, 35, 11, 37, 94, 35, 35, 31, 37, 37, 38,
         35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 85, 37, 49, 38,  9, 37, 37, 38, 35, 77, 38, 35, 11, 38, 85, 31,
         50, 85,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  9, 37, 37, 31, 85, 34,  9, 37, 29, 31, 37, 38, 37, 50, 50, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 83, 37, 59, 37, 37,  8, 37, 38, 44, 11, 37,  6, 83, 49, 37, 56, 38,
         35, 77, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 85, 37, 37, 37, 28,  9, 85, 85, 35, 83, 31, 37, 37, 32, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 49, 38, 23, 37, 88, 37, 37, 59, 31, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 49, 37, 28, 37, 35, 37, 24, 38, 38, 77, 37,  9, 37, 37,  9, 37,
         38, 31, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [85, 37, 59, 37, 38, 35, 77, 85, 37, 37, 31, 37, 37, 37, 38, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [32, 35, 35, 35, 37, 83, 94, 37, 36, 56, 37, 56, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 59, 11, 37, 85, 37, 37, 35, 49, 56, 37, 38, 37, 29, 37, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 37, 37, 37,  9, 37, 17, 24, 56, 37, 23, 49, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 37, 35, 85, 85, 31, 37,  9, 37, 28, 94, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 29, 11, 83, 11, 83, 83, 11, 83, 37, 37, 38, 11, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 31, 37, 37,  9, 83, 24, 34, 73, 73, 37, 59, 37, 38, 35, 35, 94, 83,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 50, 38, 85, 31, 37, 37, 85, 85, 88, 37, 94, 37, 37, 37, 49, 37,
         37,  9, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37],
        [50, 94, 11, 85, 49, 37, 38, 54, 35, 35, 23, 37, 94, 31, 37, 49, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 49, 37, 11, 37, 38, 85, 38, 31, 37, 11, 38, 88, 11, 38, 31, 37, 83,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 32, 37, 85, 37,  6, 37, 49, 37,  2,  1, 37, 37, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [23, 34, 11, 83, 50, 37, 37, 56, 50, 37, 37, 24, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 23, 85, 29, 49, 11, 83, 37, 37, 37, 35,  9, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 31, 37, 37, 38, 77, 77, 37, 49, 11, 83, 37, 34, 24, 37, 24, 24,
         28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83, 29, 31, 37, 38, 85, 77, 37, 37, 56, 56, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 59, 83, 37, 11, 37, 38, 85, 37,  9, 11, 37, 59, 11, 38, 31, 37, 37,
         37, 37, 52, 94, 37,  9, 35, 77, 11, 83, 37, 37, 37]], device='cuda:2'), 'lengths': tensor([17, 14, 31, 16, 16, 16, 16, 17, 18, 21, 23, 18, 23, 17, 15, 23, 17, 14,
        18, 15, 13, 17, 21, 25, 19, 20, 19, 14, 14, 21, 15, 28],
       device='cuda:2'), 'ntokens': 591}, 'target': tensor([[  99,   27,   52, 4900,   20, 5344,    4,  136,  334,   41,   30,   58,
         1652, 3701,  357,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [2899,  176,   57, 7880,  551,   48,  481,    4,   14,   98,  102,  201,
         1021,   28,  107, 4009,   76,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  64,   88, 1593,   28, 1176,    4,   56, 7609,   20,   31,   14, 3453,
          318,    4,  385, 1844,  745,    4,   34,  316, 4930,  119,    5,    2,
            1,    1,    1,    1],
        [  92,  578,  113,   40, 4641, 1924,    5,   40,  167,    4,  167, 1954,
          527,   37,   46,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  68, 3504,   65,  377,   48,  189,   83,   36,   40,  542,  310,   98,
         4686, 1824,  111,   22, 1036,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [2609, 1364,   30, 5843,  716,    4,   50,   23, 4185,   29, 1225, 1684,
          130,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 441,  141, 1493,   20, 3159,   31,  118, 2742,   15, 2978,    9, 4559,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 402,   76,  113,  470, 5195, 4008, 1319,   18,  233,   37, 2039, 8348,
           15, 8894,   59,   90,  331,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 202,  161, 4470,    9, 1012, 1716,   20, 2996,  124,  863, 1013,  186,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  64,   31,  209,  177,   49,  141, 2649,  763,  812,   28,  498,   15,
            4,   74,   49,  141, 2649,  763,  812, 2101,   18, 1034,  300,   18,
          398,    5,    2,    1],
        [5196, 1000,   40,  330,  187,  986,   14,  301, 4125,   18,  160,  481,
          869,  265, 1283, 6022,    4,  681,   32,  231,  223, 8777,    5,    2,
            1,    1,    1,    1],
        [  92, 5880, 4642, 3142,   76,  302, 2865,   20,  112, 1929,  184,  119,
          219,  237,  265,   18,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 402, 3290,   81,  514,    4,   74,   81,    9,  141, 1299,  271, 8732,
            4,  145,   81,  139, 2276, 5401,   39, 4753,    5,    2,    1,    1,
            1,    1,    1,    1],
        [6974,  239,   23, 9888,  389,  530, 2162,  382,   28,  328, 4180,   47,
         3436, 1349,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 327,   27,   23,   98, 2857, 1500,  262, 3492, 2404,    4,   23,   14,
           49,  198, 9176,   20, 5102,   56, 4385,   18,   42,    2,    1,    1,
            1,    1,    1,    1],
        [  72, 2140,   20,  304,  232,  311, 1199,  729,    4,  382,   31,   52,
         5069,  437, 1539,   98,  771, 3363,  421, 3475,  153,    5,    2,    1,
            1,    1,    1,    1],
        [5813,  119,  316,    4,   50,   14, 4164,  410,   23, 6401, 1131,  124,
          410,   23, 5835,   27,   42,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 146, 6947, 6644,   22,   36,    4, 3191,   60, 3654,   15,   28, 3913,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  92,   76,   14, 2588,    6, 4735, 1863, 2089,    4,   14,  299, 2635,
           60,  262, 2172,  272,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 146, 5263,  344, 1379,    4,   61,  102, 1517, 1614, 1524,  157,  702,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [1207,    6, 4434,  239,   23, 5531,   23, 5903, 6005, 2531,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  64,   43, 6370,   75,  167, 1013,    4,  600,   98,    6,   37, 1054,
          174,   23, 1270,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  41, 2004,   97, 4757,   15, 8376,  564,  820,  584,  217, 5270,   39,
            4,  149,   88,   14, 2734, 1689,  481, 7413,  433,  517,   28,  208,
            5,    2,    1,    1],
        [  72,  449,  113,   28,  725, 1166,   74,   31,  223, 2031,   60,  102,
          817,   40,    6,  557,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3390, 1687, 2512,   30, 4203,   20, 8612,   39, 2031,    4,   88, 1407,
         5135,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 104,   56, 2305,   39,    4,   16,   32,  127,  171,   22, 1895,  307,
            5,   72,  256,   44,  171,   22, 1895,  307,   39, 1093,   16, 3670,
            5,    2,    1,    1],
        [  99,   27,   40, 1311,   60,  102, 7229,    4,  118, 4979, 3659,   61,
           23, 1083,  201,   28,   83,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3510,  462,   44, 3670,  231,  157, 7814,    4,  318,   16,   39,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 376, 3514, 5041, 4443,    4, 2742,   74, 1096, 1926,  128,    6,   20,
           20,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  38,  967, 3490, 8923,   90, 3204, 7931,   37,   16,  342,  315,  311,
          160,    4,  761, 4116, 1709,  427, 2257,    5,    2,    1,    1,    1,
            1,    1,    1,    1],
        [  99, 2835,  139,   28,    4,  114,   32,   60,  872, 5864,  549,  466,
           76,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 147,  114,   31,   39,  256, 5660,  420,  303,  636,  193,  208,   41,
            4,   31,  313,    9,  141, 2161, 2470, 9395,    9, 1196,  411,   18,
          232, 7328,    5,    2]], device='cuda:2'), 'target_lengths': tensor([17, 19, 24, 16, 19, 15, 14, 19, 14, 27, 24, 18, 22, 16, 22, 23, 18, 14,
        18, 14, 12, 16, 26, 18, 15, 26, 19, 13, 15, 21, 15, 28],
       device='cuda:2'), 'ntokens': 597, 'nsentences': 32}
##################### {'id': tensor([ 26749,  49581, 138840, 113698,  31419,  26402, 188627, 207437, 204029,
         61579, 193298,  39089,  90376, 124057,  21278, 127745,  90596, 170712,
        145603,  70710,  20292, 195427, 125001, 127063], device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 3.4180e-03,  2.4109e-03,  0.0000e+00,  ..., -6.3171e-03,
         -3.9673e-03, -7.9346e-04],
        [-2.5024e-03, -9.1553e-05,  3.6621e-04,  ..., -1.8005e-03,
         -5.4626e-03, -8.4229e-03],
        [-3.6621e-04, -7.9346e-04, -3.9673e-04,  ..., -5.1575e-03,
         -7.6294e-03, -6.7139e-03],
        ...,
        [ 1.6785e-03,  3.6011e-03,  5.5847e-03,  ...,  9.3567e-02,
          1.0297e-01,  0.0000e+00],
        [-3.4302e-02, -3.1738e-02, -3.0304e-02,  ..., -8.1482e-03,
         -1.0071e-02,  0.0000e+00],
        [-2.4109e-03, -2.5330e-03, -2.0142e-03,  ..., -1.0956e-02,
         -1.0406e-02,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840,
        87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840, 87840,
        87840, 87839, 87839, 87839], device='cuda:1'), 'prev_output_tokens': tensor([[   2, 2046, 4384,  ...,    1,    1,    1],
        [   2,  104,   76,  ...,    1,    1,    1],
        [   2, 6703,  638,  ...,    1,    1,    1],
        ...,
        [   2,  460,   22,  ...,    1,    1,    1],
        [   2,  147, 1292,  ...,    1,    1,    1],
        [   2,  882,   23,  ...,    1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[  29,    4,  116,    9,  467,   54,    4,  339,  110,  289,    7,  288,
           94,  148,   73, 2828, 1146,   63, 5426,   62,  963, 2593,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,   63,   86,    7, 5590,  760, 3769,   12, 2569,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1250,    4,   19,   11,   45,  826,   80,   17, 6977,   12, 5330,   19,
         7833,  111,  296,   10, 6108,  110,  132,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1992,  439, 8570,    9, 3079,   46,    9,   70, 1459,  246,   34, 1501,
         3756,    8,   25, 1608,   11,   18,   87,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 568,   21,  172, 2141,   10,   13, 1127,   39,  430,    6, 1198,  185,
          423,    4, 1450, 1274,  215,  581,   42,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  25,  205,  850,   33, 4638,   85,   80, 5411, 2602,   39, 3350,    4,
            8,   84,   11,    6,  486, 4638,  168,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 991,   13, 2353,  128,    9, 3562, 5869,   12, 8218,    9, 5036,    4,
           39, 5036,   35, 1203,  140,  597,  266, 1237,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 2535, 3665, 1118,  169,    9,   48,  300,  247,  170,   55,  640,
           35,  887,  852, 4299,  490,  583,   54, 3069,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,  192,   11,   18,   66,   10,  618,    9,   13,  179,  206, 4780,
          439,   12, 5320, 2120,  175,  755,   71,   21,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 413,    7, 3253,   26,    7, 3755,    8,   19,   73,   11,   18,   51,
         4609,  131,  211,   91,  413,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 1874,   26,   17,  294, 1950, 4039,   63,   13,  649,  457,    8,
          321,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67, 1759,  868,  439,   12, 3374,  192,   11,   18,   66,  419,  886,
           18, 1049, 3819, 9335,    4,   29,   21,   11,    6,  116,   86, 1301,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  67,  276, 5833,    7, 2885,  126,   12,   21,    4,   84,   11,    6,
          499,   13,  325,  143,  378, 6899, 1314,  254,  116, 1289,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,    9,  409,    4,  125,   24,   73,  719, 2267,   57, 2028,   71,
          214,    7, 3927,   63,  923, 2318,  961, 1574,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 4129, 7447, 4749,   54,    7, 1266,   34, 7069,   48,    4,   34,
         1897,    4,  131,  289,    4,   13, 4148, 1255, 3769, 4292,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7,  528,  613,   26,   17,  117,  370,  217, 1076, 7489, 6382,    6,
          164, 4877,  440,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8, 2414, 1288,   73,   51,  619,    4,   55, 4212,    4,   10, 3978,
         6484,   12,  214,  100, 2201, 3549,    6,    9,    7, 2892,  179,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 934,   17, 2958,   12,   73,   48,  232, 2653,   69,   17, 2085,    5,
           69,    7, 4779,  291,   20,  121,   22, 7104,    4,   69,    7, 1284,
         3213,    5,    2,    1,    1,    1,    1,    1,    1],
        [  29,   71,   17, 1478,    4,   19,  180, 3401,   35, 8309,    7, 8147,
           12,    7,  427, 6034, 1167, 4445,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2464,    6, 1898,  290, 6215,   62,  284, 1269,   35,    6, 1178,  756,
            6,   10, 7647,  107,  812, 1161,  457, 5154,    6,    4,    8, 9098,
           48,  284, 6215,   71,  453, 7370,  429,    5,    2],
        [1730,    4, 1244,   35, 9338, 1794,    4,   80,  166,    4,  554,    4,
           19, 1704,   11,   18,  289,  593,  261,  125,   25,   11,  121,  226,
         5031,   77,   80,   21,    5,    2,    1,    1,    1],
        [   8,   29,  255,   22, 2666,   62,   10,  110,    4,   38, 1969,  135,
            4,  635,   21, 1382,   11,   18,   13, 7007,  524,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   21, 1359,   11,   18, 1325,   19,  552, 1004,   13, 2135,  119,
         5001, 2084, 2383, 1801,   11,    6, 8321,   46,  101,  903, 2592,   33,
         1862,    9, 1061,  957,  868,    5,    2,    1,    1],
        [ 244,  183,    4,   24, 5748,   20,   69, 1335, 1508,    4,    8,    9,
           13, 1580,   17,  818,    7,  488, 1390,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:1'), 'cluster_tokens': tensor([[83, 11, 83, 37, 38, 49, 11, 49, 37, 88, 37, 83, 56, 50,  6, 29, 28, 85,
         32, 31,  2, 28, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 83, 37, 38, 35, 35, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 85, 35, 59, 37, 37,  9, 37,  9, 38, 83, 83, 49, 37, 49, 37,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [34, 24, 29, 37, 94, 11, 37, 50, 50, 88, 85, 83,  6, 37, 37,  6, 85, 35,
         85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [85, 37, 83, 49, 37, 37, 50, 38, 35, 37, 35, 50, 34, 11, 34, 60, 24, 83,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 94, 37, 37, 34, 24, 38, 24, 11, 37, 37, 85, 37, 50, 94,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [49, 37, 23, 35, 37, 94,  6, 37, 94, 37, 28, 11, 38, 28, 38, 35, 35, 35,
         35, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 49, 56, 85, 37, 31, 35, 77, 37, 37, 34, 38, 73, 73, 24, 37, 88,
         49, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 85, 35, 85, 37, 49, 37, 37, 94, 37, 34, 24, 37, 29, 56, 85, 37,
         37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [11, 37,  9, 85, 37,  5, 37, 38,  6, 85, 35, 38, 31, 37, 50, 50, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 85, 37, 50,  2, 56, 85, 37, 35,  2, 37, 38, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 17, 73, 24, 37, 56, 85, 85, 35, 85, 50, 38, 35, 77, 32, 50, 11, 83,
         37, 85, 37, 83, 83,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 49, 37,  9, 37, 37, 37, 11, 37, 85, 37, 83, 37, 83, 50, 49, 12,
         31, 37, 83, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 32, 11, 37, 38,  6, 49, 38, 77, 56, 37, 56, 37, 56, 85, 83, 83,
         49, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83,  9, 49, 49, 37,  9, 85,  2, 31, 11, 85, 31, 11, 37, 88, 11, 37,
         28, 35, 35, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  2, 32, 85, 37, 37,  4, 38, 35, 29, 32, 37, 85, 85, 83, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  4, 56,  6, 38, 31, 11, 37, 32, 11, 37, 32, 94, 37, 56, 37,  9,  9,
         37, 37, 37, 49, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [88, 37, 32, 37,  6, 31, 77, 32, 37, 37, 94, 11, 37, 37, 83, 38, 77, 35,
         35, 28, 11, 37, 37,  2, 28, 11, 83, 37, 37, 37, 37, 37, 37],
        [83, 37, 37, 32, 11, 38, 37,  2, 38, 31, 37,  9, 37, 37, 38, 35, 26, 94,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 37, 35, 35, 32, 31, 37,  9, 38, 37, 35, 77, 37, 37, 32, 38, 35, 35,
          2, 32, 37, 11, 37, 29, 31, 37, 32, 37,  2,  2, 94, 11, 83],
        [83, 11, 32, 38, 49, 56, 11, 37, 37, 11, 83, 11, 38, 31, 85, 35, 88, 83,
         83, 37, 37, 85, 35, 85, 59, 50, 37, 37, 11, 83, 37, 37, 37],
        [37, 83, 38, 35, 88, 31, 37, 37, 11, 38, 37, 59, 11,  6, 37, 85, 85, 35,
         37, 28, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 85, 35, 24, 38, 85, 37, 37, 38, 75, 35, 38, 35, 35, 85, 37,
         94, 11, 38, 38, 35, 37, 94, 37, 84, 73, 73, 11, 83, 37, 37],
        [37, 24, 11, 38, 29, 77, 37,  2, 56, 11, 37, 37, 37,  9, 37, 88, 37,  2,
          9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:1'), 'lengths': tensor([25, 11, 21, 21, 20, 21, 22, 22, 22, 18, 15, 26, 24, 22, 24, 17, 25, 27,
        20, 33, 30, 23, 31, 21], device='cuda:1'), 'ntokens': 541}, 'target': tensor([[2046, 4384,  449,  ...,    1,    1,    1],
        [ 104,   76,   47,  ...,    1,    1,    1],
        [6703,  638,   31,  ...,    1,    1,    1],
        ...,
        [ 460,   22,  329,  ...,    1,    1,    1],
        [ 147, 1292,   90,  ...,    1,    1,    1],
        [ 882,   23,  259,  ...,    1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([22, 13, 21, 28, 19, 22, 29, 45, 23, 18, 15, 27, 22, 20, 39, 22, 27, 29,
        27, 44, 28, 20, 26, 20], device='cuda:1'), 'ntokens': 606, 'nsentences': 24}
##################### {'id': tensor([201403, 136471, 137969, 148610, 145609, 128606, 223111, 160407],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0133,  0.0148,  0.0135],
        [ 0.0023,  0.0011,  0.0007,  ...,  0.0006,  0.0014,  0.0016],
        [ 0.0002,  0.0014,  0.0023,  ..., -0.0001, -0.0004, -0.0005],
        ...,
        [ 0.0035,  0.0056,  0.0036,  ...,  0.0018,  0.0020,  0.0005],
        [-0.0008, -0.0006, -0.0006,  ...,  0.0040,  0.0014, -0.0006],
        [ 0.0008,  0.0010,  0.0006,  ..., -0.0006, -0.0009, -0.0009]],
       device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([255680, 255680, 255680, 255680, 255680, 255680, 255680, 255680],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,   72, 6189,  198,  253,  579,   40,   56, 3581,   96, 1133,  177,
            4, 5631,   37,   90,   52, 5514,  195, 1338,    4,    9,  102, 3341,
           37,    4, 1925,   37,    4,  749, 3637,   37, 2492, 5565,    4,   60,
          905,  124,  286,   45, 7056,    4,  743,  286,   45,  972,   35,   16,
          599, 6836,    4, 4783,   45, 7872,   16, 8339,  510, 4154,  541, 2440,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  397, 1071,  239,   23,  919,   98,  212, 3587,   15,  531, 2045,
         6997,   28,  102,  919,    9,   23, 3587,   15,  869,  265, 1783,    9,
           23, 4164,  141, 7231,    4,   23, 9011,    9,   58, 6571, 6695,  239,
            4,   23,  624,   49,  107,    4,   23, 2691, 6574,   58, 1379, 7296,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   31,  449,  252, 1700,   39,    6, 1699, 4417,    4,   50,
           32,   30, 1448, 4568,   56, 7729,  398,   83,    4,   50,   32,  374,
          112,   14,   56, 6969,   23, 3004,    4,   14, 1834,   23, 3004,    4,
           30, 8445,  242,   18,   23, 3004,  320,    5, 9769,  320,   32,  671,
            4, 1213,  671,  112,   14, 1834,   16,   30, 8445,  242,   18,   23,
         1299,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  298,  915,   31,   44,   38,  967, 5650,  163,    4,   34,  730,
            4,  114,   31, 2452,    6, 1097,   45, 3264,  756,   20,  358,   68,
          348,   65,   68,  431,   65,   64,   30, 3220,    4,   23, 1530, 2950,
           35, 1018,  287,  158,    6, 1079, 1739,    4,  130,  163,  750,   23,
          808, 2681,  397,   61,   14, 3478,  426, 2253, 3202,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   32, 5121,   15,   51,  443,   59,   59,  418,   16, 6371,
         3497, 1047, 1438,  611,    4,   75,  437,   22,  234, 3352,  683,  153,
         3669,   28,  795,   16,  466, 7209,   15,   32, 1185,  887, 2709,  978,
           16, 1744, 2520,  981, 4536,   39,   14,  911, 6034,  559,  833,   59,
         3074,  569,  271,   12,  576,  587, 5731,   16,   30,   82, 2163,   14,
         2249, 5163, 6738,   20,    4,   14,   43, 2691, 1773,  471,    5],
        [   2,   41,  604, 1246,    4,   30,   82,  406, 4444,    6, 4688,    5,
           68,  348,   65,  147, 3458,    4,   30,   82,  564,  584,  828,    5,
          147, 1989,   32,   61,  564,  820,  584,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 3137, 5073,   15, 1826, 1399, 2944, 5391,   27,   52, 5298, 3749,
            4,  428,   30, 3384,  107,  742,    5,  592,    5,   14,   28, 6330,
            4,   14,  414,    9,   23, 1401,   76,   16,  189, 3341,    4, 1925,
          124, 2615,  127,   60,  628,    4,   14,  275,  216, 4787,  309,    5,
          928,  123,   32,   14, 7968,   20, 2350,  223, 2280,  739,   16, 4264,
            4,  782,  295,  314, 1229,  171, 3870,   15,    5,    1,    1],
        [   2,  202,  573,  767,   49,  978,   98,    4,   88,  118, 7780,   22,
         3533, 1537,  543,   28, 1205,   16,   14, 2779,  315, 2412,  299, 2389,
         2545,    6,   82,   14,  202, 4183,  141, 1230, 2741, 5641,    4,  171,
          122, 1178, 2520, 1589, 1079,   20, 1253,  363,    4,   14, 5343,   61,
          102, 2113, 2916,   23, 2113, 4335, 1109,   16,   75,  102, 4364,   23,
         3186,  577, 2416,  856, 4047,   20,    5,    1,    1,    1,    1]],
       device='cuda:7')}, 'transcript': {'tokens': tensor([[  19,  934,    4,   55,  663,    4,   13, 6083,  567,   17,   11,    6,
         3657,   54,  143, 5243,  111,  254, 4565, 2980,   54,    4,  206,   25,
           73, 2231, 3849,    4, 1767,    4,  384, 1838, 1563, 1390,   71,  277,
          109,  211,  417,  181, 3312,   15,   18,    4, 1120,  211,  941,    8,
         1120,  211,  563,    8,   13, 1745, 3018,   71,   13, 8339, 8340,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 215, 1065,    4,    7, 2988,  106,   17,  775, 5296,   62, 1720,   48,
         2184,   18,  169, 1754,  132,   10,   51,    7,   81,    9,   17,  775,
         5296,   62, 2902,    6,  300,   20,   69,    7, 6082,   12,   13, 6361,
          148, 5825,   62,   10,   51, 6532,  199,  126,   37,  672,    4,    7,
          245,   91,   12,  419,   12,  170,   10,  172, 7100, 1516,   33,  943,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   8,   19,   11,   48,  100,   10, 1319,  910,   10,   25,   17,   24,
           66, 4658,   48,    7,  422, 4221,    4,   24,  135,  778,   80,    7,
         4658,   12,    7, 2372,    4,    7, 1234,   12,    7, 2372,    4,    7,
         1339,  265, 3701,  307,   12,    7, 2372,    4,   67,   24,  135, 1155,
            4,   67, 1155,    4,   80,    7, 1234,    8, 1339,  265, 3701,  307,
           12,  774,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  29,   19,  474,    4,   38,  187, 2743,   70,   11,  158, 1085,  103,
           19,  388,    7,  248,  540,  358,   68,  194,   65,   68,  386,   65,
            8,    7, 7396, 9195,   17,  188, 2173,   62,  188, 1828,  110,   69,
            7,  281, 1248, 3046,  244,    7,  473, 1646,  215,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   8,   24,  690,    6,  365,   62,    4,    8,   24,  278, 3497, 1047,
         1816, 2288, 1412, 4117,    6,    4,    8,  540,   24, 5443, 1185,  887,
         1274, 1086,    4,    8,   24,  192,  922,  333,   56, 2109,   12,   17,
           10,    7,  427, 6034, 1167, 4445,   12, 5170,    4,    8,   17, 2015,
           62,   85,    7,  183,    7, 1127, 3187,  192,  271,   53,   11,   48,
          700, 5692,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  25,   11,   57,  914,  826,   17,   34,   89, 4460,  464,    5,   68,
          194,   65,   21, 1359,   11,   18,    5,   21,   34,  564,  584,  828,
            5,   67,  205,  270,   10,  564,  820,  584,    4,  736,  215,  581,
            4,    8,  274,   85,   17,  613,   70,   24,    4,  108,  753,    4,
           34,  970,   48,   71,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2861,   54,  813,   69, 1655,   12,  708,   26,   13,  172, 1894,  279,
           10,   87,    4,  125,   21,  818,   24,   73, 5892,    7, 1649,  148,
          289,    4,   87,  238,   85,  670,  109,  467,  132, 3849,  109, 1767,
          109, 4488,   93,   79, 5474,    4,    8,    7, 1649,  148, 4640,  261,
          143,    4,    8,  180,   24,   73, 1487,  527,  359,   77,    7,  813,
           24,   11,  121, 2861,   62,    8,  780,   10,  283,  126,  347,  159,
          931, 1932,  126,  341,    5,    2],
        [ 101, 2138, 2518,   12, 1086, 2567,   13, 7780, 1392,  429, 2973,  543,
            4,    8,  284,  452, 2405,   22,   54, 2264, 3157,   34,    7, 1009,
           12,   13, 1016,   35, 6937,   35,  176,  236,  176, 3213,   35, 1076,
          922, 1449, 1079,   20,   12, 4115,  166, 6225, 5592,  111,    9,    7,
         3979,   11,    6, 3612, 3275,    8, 2546,  922,   10, 2679,    7, 1715,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:7'), 'cluster_tokens': tensor([[38, 88, 11, 37, 32, 11, 37, 31, 32, 37, 85, 37, 49, 49, 50,  2, 83, 37,
         28, 23, 49, 11, 37, 37,  6, 49,  2, 11,  2, 11, 38, 35,  2,  9, 37, 50,
         37, 50, 38, 35, 35, 77, 35, 11, 83, 50, 94, 37, 83, 50,  9, 37, 37,  2,
         49, 37, 37,  2, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [24, 24, 11, 37,  9, 37, 37, 38, 35, 31, 38, 31, 38, 35, 85, 49, 37, 37,
         38, 37, 38, 37, 37, 38, 35, 31, 38, 37, 35, 77, 37, 37, 38, 37, 37, 94,
         50, 28, 31, 37, 38, 31, 37, 37, 77,  9, 11, 37, 83, 50, 37, 50, 37, 37,
         37, 83, 83, 29, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 38, 85, 31, 37, 37, 38, 35, 37, 37, 37, 38, 85, 94, 31, 37, 28, 47,
         11, 38, 59, 50, 37, 37, 94, 37, 37, 47, 11, 37, 94, 37, 37, 47, 11, 37,
         38, 35, 35, 77, 37, 37, 47, 11, 37, 38, 59, 50, 11, 37, 50, 11, 37, 37,
         94, 37, 38, 35, 35, 77, 37, 38, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [83, 38, 31, 11, 38, 35, 88, 50, 85, 35, 85, 37, 38, 31, 37, 34, 36, 11,
         38,  9, 11, 38, 28, 11, 37, 37, 28,  9, 37, 85, 32, 31, 85, 31, 37, 37,
         37, 75,  2, 94, 37, 37, 37, 34, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 38, 38, 37, 35, 31, 11, 37, 38, 31, 34, 73, 56, 49,  6, 27, 37, 11,
         37, 36, 38, 31, 17, 73, 60, 32, 11, 37, 38, 85, 31, 50, 38, 35, 37, 37,
         37, 37, 38, 35, 26, 94, 37, 28, 11, 37, 37, 36, 31, 37, 37, 24, 37, 50,
         75, 85, 44, 37, 85, 31, 50, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 77, 83, 59, 37, 85, 37, 94, 24, 11, 38,  9, 11, 37, 85, 85, 35,
         11, 37, 85, 34, 73, 73, 11, 37, 85, 37, 37, 34, 73, 73, 11, 34, 24, 83,
         11, 37, 59, 37, 37, 32, 50, 38, 11, 37,  9, 11, 85, 32, 31, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [49, 49, 94, 37, 24, 37, 56, 85, 37, 83,  2, 50, 37, 85, 11, 37, 37, 88,
         38,  6, 36, 37, 50, 50, 88, 11, 85, 83, 37, 94, 37, 38, 37,  2, 37,  2,
         37,  9, 35, 37, 56, 11, 37, 37, 50, 50, 76, 83, 50, 11, 37, 37, 38,  6,
         38, 77, 37, 50, 37, 94, 38, 85, 35, 49, 31, 37, 88, 37, 49, 37, 83, 37,
         37, 40, 37, 33, 11, 83],
        [38, 31, 50, 37, 32, 49, 37,  2, 28, 94, 38, 66, 11, 37, 37, 38, 35, 35,
         49, 38, 35, 85, 37, 49, 37, 37, 34, 38, 23, 38, 35, 35, 35, 28, 38, 35,
         31, 38, 35, 77, 37, 37, 37, 31,  2, 83, 37, 37, 28, 85, 37, 28,  9, 37,
         38, 31, 37, 49, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:7'), 'lengths': tensor([61, 62, 64, 47, 64, 54, 78, 62], device='cuda:7'), 'ntokens': 492}, 'target': tensor([[  72, 6189,  198,  253,  579,   40,   56, 3581,   96, 1133,  177,    4,
         5631,   37,   90,   52, 5514,  195, 1338,    4,    9,  102, 3341,   37,
            4, 1925,   37,    4,  749, 3637,   37, 2492, 5565,    4,   60,  905,
          124,  286,   45, 7056,    4,  743,  286,   45,  972,   35,   16,  599,
         6836,    4, 4783,   45, 7872,   16, 8339,  510, 4154,  541, 2440,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 397, 1071,  239,   23,  919,   98,  212, 3587,   15,  531, 2045, 6997,
           28,  102,  919,    9,   23, 3587,   15,  869,  265, 1783,    9,   23,
         4164,  141, 7231,    4,   23, 9011,    9,   58, 6571, 6695,  239,    4,
           23,  624,   49,  107,    4,   23, 2691, 6574,   58, 1379, 7296,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   31,  449,  252, 1700,   39,    6, 1699, 4417,    4,   50,   32,
           30, 1448, 4568,   56, 7729,  398,   83,    4,   50,   32,  374,  112,
           14,   56, 6969,   23, 3004,    4,   14, 1834,   23, 3004,    4,   30,
         8445,  242,   18,   23, 3004,  320,    5, 9769,  320,   32,  671,    4,
         1213,  671,  112,   14, 1834,   16,   30, 8445,  242,   18,   23, 1299,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 298,  915,   31,   44,   38,  967, 5650,  163,    4,   34,  730,    4,
          114,   31, 2452,    6, 1097,   45, 3264,  756,   20,  358,   68,  348,
           65,   68,  431,   65,   64,   30, 3220,    4,   23, 1530, 2950,   35,
         1018,  287,  158,    6, 1079, 1739,    4,  130,  163,  750,   23,  808,
         2681,  397,   61,   14, 3478,  426, 2253, 3202,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   32, 5121,   15,   51,  443,   59,   59,  418,   16, 6371, 3497,
         1047, 1438,  611,    4,   75,  437,   22,  234, 3352,  683,  153, 3669,
           28,  795,   16,  466, 7209,   15,   32, 1185,  887, 2709,  978,   16,
         1744, 2520,  981, 4536,   39,   14,  911, 6034,  559,  833,   59, 3074,
          569,  271,   12,  576,  587, 5731,   16,   30,   82, 2163,   14, 2249,
         5163, 6738,   20,    4,   14,   43, 2691, 1773,  471,    5,    2],
        [  41,  604, 1246,    4,   30,   82,  406, 4444,    6, 4688,    5,   68,
          348,   65,  147, 3458,    4,   30,   82,  564,  584,  828,    5,  147,
         1989,   32,   61,  564,  820,  584,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [3137, 5073,   15, 1826, 1399, 2944, 5391,   27,   52, 5298, 3749,    4,
          428,   30, 3384,  107,  742,    5,  592,    5,   14,   28, 6330,    4,
           14,  414,    9,   23, 1401,   76,   16,  189, 3341,    4, 1925,  124,
         2615,  127,   60,  628,    4,   14,  275,  216, 4787,  309,    5,  928,
          123,   32,   14, 7968,   20, 2350,  223, 2280,  739,   16, 4264,    4,
          782,  295,  314, 1229,  171, 3870,   15,    5,    2,    1,    1],
        [ 202,  573,  767,   49,  978,   98,    4,   88,  118, 7780,   22, 3533,
         1537,  543,   28, 1205,   16,   14, 2779,  315, 2412,  299, 2389, 2545,
            6,   82,   14,  202, 4183,  141, 1230, 2741, 5641,    4,  171,  122,
         1178, 2520, 1589, 1079,   20, 1253,  363,    4,   14, 5343,   61,  102,
         2113, 2916,   23, 2113, 4335, 1109,   16,   75,  102, 4364,   23, 3186,
          577, 2416,  856, 4047,   20,    5,    2,    1,    1,    1,    1]],
       device='cuda:7'), 'target_lengths': tensor([61, 49, 62, 58, 71, 32, 69, 67], device='cuda:7'), 'ntokens': 469, 'nsentences': 8}
##################### {'id': tensor([74575, 74252, 19208, 47055, 62205, 42395, 14977, 99405],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[-0.0039, -0.0030, -0.0008,  ..., -0.0039, -0.0078, -0.0067],
        [ 0.0005,  0.0023,  0.0021,  ...,  0.0051,  0.0053,  0.0046],
        [-0.0734, -0.0759, -0.0734,  ...,  0.0000, -0.0012,  0.0025],
        ...,
        [ 0.0322,  0.0708,  0.0141,  ...,  0.0200,  0.0150,  0.0506],
        [-0.0139, -0.0105, -0.0075,  ..., -0.0493, -0.0405, -0.0356],
        [-0.0003, -0.0001, -0.0002,  ...,  0.0005,  0.0005,  0.0006]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([244000, 244000, 244000, 244000, 244000, 244000, 244000, 244000],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,   92, 1190,  416,   20,  716,   27,    4,   50,   36,   47,  149,
         1497,  394,    4,   14, 5536, 6862,   23,  201,   60,  102,   28, 7159,
            4,   34,   14,  377, 3160,   59,  611,  210, 4385,   22,    4,  519,
           50,   29,  139,   14, 5695,   78,  308, 1265,  445,   62,   35, 3736,
          128,  429,   56, 4439,  161,    4,   49,   23,   31,  252, 1343,  216,
          701,  557,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   64,   88,  385,    9, 4727,   28,   56, 1903,    4,   60,  151,
         3483,    4,   30,  105, 5715,   14, 1473,   76,   13,  122,  272, 2344,
            4,  701, 2344,   34,   43,  269,  123,   60,  553,  236,  445,   15,
           16, 4305,   74,   40, 2909,    4,  714,   27,   30,   40, 4641, 3408,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  402,  695,   40,  301,  156, 2021,  797, 1660,  393,   61,    4,
           23, 6331, 7917,   82,    4,   50, 3055,   35, 1888, 2879,   59,  152,
          387,   37,   16, 3055,   35, 2507,  152,   48,  810,   20,   75,  112,
           14, 2218, 5131, 1928, 6370,   16,   97, 1378,  381, 3759,   58, 1734,
           22, 8530, 1900, 1879,   23,  201,    9,  421,  960,  658,  532,  259,
         6824,  792,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   99, 6691,   39,    4,   78,  163, 1971,   28,   95, 1500,  193,
           34, 2149,  394,   27,  349,   20,  236,    4,   34, 2730, 3690,   27,
         5570,  193,  124,   36,  394, 6139, 2149,    4,   16,  695,   10,   18,
          653,    5, 7365,  840, 1304, 2817,    5, 6242,  840, 1304, 2817,    4,
         6139,   28,   10,   18,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 4282,  477,   76, 6473,    4,   29,   74,   14, 7734, 7788,    4,
           14, 1498, 1047, 1045, 2849,  130,    4,   14, 7788,   12,    7,  349,
          803,   59,   48,  308,  247,    4,    9,   23, 2824,  425,   52, 5513,
         4348, 3279,   37,  157,  331, 3279,   20,  157, 7670,  224,   16,   29,
         6572,   20,  326,   74, 1139, 1837, 8667,   22,  253,  301,  356,  571,
           35, 2507, 5005,   15,    4,   74, 7022, 6111,   20,   16, 3419,   78,
         2114, 5282,    5],
        [   2, 3823,    4,  308,  551,  174,  652,    6,   98, 6154,    5, 4799,
           48,   98, 7662,    5, 2904,    5,  104,   83,  361,   40,  773,    5,
         2715,   20, 1029,  408,  559,  920,   44,   92,   27,    4,   34, 1433,
           97, 9041, 6378,    9, 1235,  335,  741,  730,   27,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 1063, 3595,   57, 5751,   36,    5,  657, 4060,  374,    5,   99,
          178,  286, 1981, 6704,    9,  301, 1996,   18,  249, 8647,   22,    5,
         2558, 3971,    5,  312, 7545, 1795,   23, 3269, 3948,  517,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  222,   32,   61,   14,  796,  615,    4,   52, 2756,   20, 9075,
         5135,    4,  940,   32, 4762, 1537,   15,   16,   56, 4142, 1322,    4,
           16, 2583,  176,  272, 5469,   20,   98,  102, 2181,    4,   16,   95,
          803,   18,  610,    4,  171,  122,  597,  191,   16, 1697, 2428,  610,
            4,  136,   32,   83,   52, 2756,   20, 9075, 6470,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[  67,   70,   11,    6, 1475,   80,   33,   26,   17,    4,   86,  288,
           26,   21,   13, 1265,  445,   54,   33, 2326, 2015,  271,   12,    7,
          179,   71,  214,   17,   63, 1028,    9,  106, 6463,    4,   67,   21,
          113,   26,    7, 4445,   55,   13, 1265,  445,   62, 1874,    4,    8,
           17,   11,    6,  250,   17,   19,   11,  158,   51, 3243,   25,  143,
           12,    9,  116,   13,  765,    5,    2,    1,    1,    1,    1],
        [   8,   10, 5766,   71,   21,    4,   71,   13, 3180,   17,  339,    6,
          117, 4906,   17,   63, 3266, 1529,    8,  575,   70,   53,   73,   87,
            4, 2385,  134, 4700,  445,    8, 3765,  116,  100,   39, 2420,    4,
           21,   11,    6,   13,  324,   77,   93,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  33,  875,    6,  270,   13, 8822, 1144,   17,  188, 2107,  755, 2523,
            4,   17, 1629,  533,   62,    6,    8, 1629,  812,  119,    6,  220,
         2551,  336,    7,  179,    4,  106, 2058, 7525,   93,    4,   17, 2318,
          220, 4777,    7,  179,   11,    6,  896, 4749,    9,  133, 1706, 1296,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  21,   11,    6, 2439,   10,  229,  841,   10,  110,   46,   70, 1143,
            9,   26,   87, 4476,    4,   70,  925,  126,   26, 5852,   46,  109,
           21, 1143,    9, 3754,    4,  925,  126, 2429,    5, 1575, 6105,    5,
          245, 6105,    4, 3754,   10, 2429,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 185, 3818, 1649,  100,    7,  985, 2811,    4,  166,  188, 1498, 3431,
         1613,    4,    7, 2811,   12,    7, 1575, 1137,    4,  166,  188, 4712,
          854,   13,  759, 3563,   94, 4313,  218, 3563,   94,    4,   79,  238,
           79, 3643,  214,  100,  876,   93, 1213,  709,    6,    8, 1234, 3744,
            8, 3061,   55,  837, 4456,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1189,    4, 7758,    7, 1404,  174,  652,    6,    5,  985,    5, 2421,
            5,   24,   66,   13, 1153,  230,  115,    5, 1768,  408,  452,   20,
           44,   17,   11,    6,   80,   70,  956,    9,    7, 1320,  335,  741,
         5317,  964,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  84,   11,    6,  211,  291,   20,  362,  614,   93,  445,    9,  227,
         1996,   18,  249, 1884,    5, 1459, 1429,    5,   91,   35,    6, 4125,
          322,   12, 3649,   26,   84,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,  103,   24,  213,   10,  229,  250,  835,    4,   24,  289,    4,
           38,  187,  135,  408,   19,   11,   45,  142,   10,  229,   13,  835,
         8829,    5,   19,  135,  408,   19,   11,   45,  142,   10,  175, 9134,
            6,    8, 3053,   59,  760,  430,    6,    8, 5525,  993,  126,   12,
            7, 2059,    8,  175,  214, 3139,    8, 8454,    8, 3727,  387,   20,
            5,    5,    5,   67,   19,  278,   33,  835,  279, 2236,    2]],
       device='cuda:6'), 'cluster_tokens': tensor([[37, 50, 85, 37,  2, 37, 37, 85, 37, 11, 83, 83, 85, 37, 37, 35, 35, 49,
         37, 28, 36, 44, 37, 37, 94, 37, 56, 37, 85, 49, 37, 37, 56, 11, 37, 37,
         83, 85, 37, 94, 37, 37, 35, 35, 31, 94, 11, 37, 37, 85, 37, 50, 37, 38,
         85, 35, 38, 88, 37, 50, 37, 37, 83, 37, 24, 11, 83, 37, 37, 37, 37],
        [37, 37, 94, 37, 37, 11, 37, 37, 32, 37, 49, 37, 37, 56, 37, 85, 50, 49,
         37, 88, 50, 37,  6, 85, 11, 49, 37,  9, 35, 37, 94, 83, 37, 38,  9, 11,
         37, 85, 37, 37,  2, 50, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 49, 37, 37, 37, 28, 32, 37, 85, 31, 37, 83, 11, 37, 38, 35, 31, 37,
         37, 38, 35, 75, 37,  6, 29, 37, 37, 94, 11, 37, 28, 28, 35, 11, 37, 83,
          6, 29, 37, 94, 85, 37,  9, 49, 37, 83,  2, 49, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 49, 37, 49, 32, 37, 37, 11, 50, 85, 37, 85, 85, 35, 11, 50,
         85, 37, 85,  9, 11, 37, 37, 85, 37,  2, 11, 85, 37,  2, 11, 28, 94, 11,
         83, 94, 11,  2, 37,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50,  2, 50, 37, 37,  2, 94, 11, 37, 85, 34, 60, 56, 11, 37, 94, 37, 37,
         28, 24, 11, 37, 85, 83, 53, 37, 24,  2, 56, 49, 50,  2, 56, 11, 37, 83,
         37,  2, 56, 37, 38, 35, 38, 35, 37, 37, 94, 56, 37, 56, 37, 28, 28, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 49, 37, 94, 35, 35, 37, 11,  2, 11, 94, 11, 38, 85, 37, 32, 37,
         83, 11, 83, 11, 38, 77, 82, 37, 85, 37, 37, 50, 31, 37, 37, 38, 35, 35,
         49,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 50, 38, 77, 35, 35, 35, 35, 37, 38, 35, 35, 77, 56, 11, 50,
         56, 11, 50, 38, 37, 35, 35, 37, 94, 85, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 88, 37, 49, 50,  2, 11, 38, 88, 11, 38, 35, 59, 11, 38, 85,
         35, 49, 37, 49, 37,  2, 94, 11, 38, 59, 11, 38, 85, 35, 49, 37, 85,  9,
         37, 37, 38, 35, 35, 35, 37, 37, 29, 32, 37, 37, 37, 23, 37, 85, 56,  2,
         37,  9, 37, 94, 35, 77, 11, 11, 11, 37, 38, 31, 37,  2, 50, 11, 83]],
       device='cuda:6'), 'lengths': tensor([67, 45, 50, 44, 56, 40, 31, 71], device='cuda:6'), 'ntokens': 404}, 'target': tensor([[  92, 1190,  416,   20,  716,   27,    4,   50,   36,   47,  149, 1497,
          394,    4,   14, 5536, 6862,   23,  201,   60,  102,   28, 7159,    4,
           34,   14,  377, 3160,   59,  611,  210, 4385,   22,    4,  519,   50,
           29,  139,   14, 5695,   78,  308, 1265,  445,   62,   35, 3736,  128,
          429,   56, 4439,  161,    4,   49,   23,   31,  252, 1343,  216,  701,
          557,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  64,   88,  385,    9, 4727,   28,   56, 1903,    4,   60,  151, 3483,
            4,   30,  105, 5715,   14, 1473,   76,   13,  122,  272, 2344,    4,
          701, 2344,   34,   43,  269,  123,   60,  553,  236,  445,   15,   16,
         4305,   74,   40, 2909,    4,  714,   27,   30,   40, 4641, 3408,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 402,  695,   40,  301,  156, 2021,  797, 1660,  393,   61,    4,   23,
         6331, 7917,   82,    4,   50, 3055,   35, 1888, 2879,   59,  152,  387,
           37,   16, 3055,   35, 2507,  152,   48,  810,   20,   75,  112,   14,
         2218, 5131, 1928, 6370,   16,   97, 1378,  381, 3759,   58, 1734,   22,
         8530, 1900, 1879,   23,  201,    9,  421,  960,  658,  532,  259, 6824,
          792,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  99, 6691,   39,    4,   78,  163, 1971,   28,   95, 1500,  193,   34,
         2149,  394,   27,  349,   20,  236,    4,   34, 2730, 3690,   27, 5570,
          193,  124,   36,  394, 6139, 2149,    4,   16,  695,   10,   18,  653,
            5, 7365,  840, 1304, 2817,    5, 6242,  840, 1304, 2817,    4, 6139,
           28,   10,   18,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [4282,  477,   76, 6473,    4,   29,   74,   14, 7734, 7788,    4,   14,
         1498, 1047, 1045, 2849,  130,    4,   14, 7788,   12,    7,  349,  803,
           59,   48,  308,  247,    4,    9,   23, 2824,  425,   52, 5513, 4348,
         3279,   37,  157,  331, 3279,   20,  157, 7670,  224,   16,   29, 6572,
           20,  326,   74, 1139, 1837, 8667,   22,  253,  301,  356,  571,   35,
         2507, 5005,   15,    4,   74, 7022, 6111,   20,   16, 3419,   78, 2114,
         5282,    5,    2],
        [3823,    4,  308,  551,  174,  652,    6,   98, 6154,    5, 4799,   48,
           98, 7662,    5, 2904,    5,  104,   83,  361,   40,  773,    5, 2715,
           20, 1029,  408,  559,  920,   44,   92,   27,    4,   34, 1433,   97,
         9041, 6378,    9, 1235,  335,  741,  730,   27,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [1063, 3595,   57, 5751,   36,    5,  657, 4060,  374,    5,   99,  178,
          286, 1981, 6704,    9,  301, 1996,   18,  249, 8647,   22,    5, 2558,
         3971,    5,  312, 7545, 1795,   23, 3269, 3948,  517,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 222,   32,   61,   14,  796,  615,    4,   52, 2756,   20, 9075, 5135,
            4,  940,   32, 4762, 1537,   15,   16,   56, 4142, 1322,    4,   16,
         2583,  176,  272, 5469,   20,   98,  102, 2181,    4,   16,   95,  803,
           18,  610,    4,  171,  122,  597,  191,   16, 1697, 2428,  610,    4,
          136,   32,   83,   52, 2756,   20, 9075, 6470,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([63, 49, 63, 53, 75, 46, 35, 58], device='cuda:6'), 'ntokens': 442, 'nsentences': 8}
##################### {'id': tensor([ 49715, 213052, 222293, 134837, 120872,  45681,  85613, 223541,   9836,
        195852, 197005, 221223, 143030, 157503,  95472,  35126, 186950, 107382,
        146070, 190002, 192952,  61237,  27659,  20993,  20994, 151050,  52398,
        223100, 106385, 128037,  54276, 207102], device='cuda:0'), 'net_input': {'src_tokens': tensor([[-0.0084, -0.0057, -0.0062,  ..., -0.0504, -0.0599, -0.0605],
        [-0.0006, -0.0011, -0.0013,  ..., -0.0008, -0.0006, -0.0020],
        [ 0.0317,  0.0327,  0.0311,  ...,  0.0110,  0.0109,  0.0119],
        ...,
        [-0.0002, -0.0003, -0.0002,  ...,  0.0039,  0.0043,  0.0000],
        [ 0.0003, -0.0001,  0.0003,  ...,  0.0050,  0.0056,  0.0000],
        [ 0.0014,  0.0013,  0.0023,  ...,  0.0046,  0.0038,  0.0000]],
       device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640,
        72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640,
        72640, 72640, 72640, 72640, 72640, 72640, 72640, 72640, 72639, 72639,
        72639, 72639], device='cuda:0'), 'prev_output_tokens': tensor([[   2,   64,   14,  ...,    1,    1,    1],
        [   2,   72,  209,  ...,    1,    1,    1],
        [   2,   99,   82,  ...,    1,    1,    1],
        ...,
        [   2, 7330, 3444,  ...,    1,    1,    1],
        [   2,   72, 3452,  ...,    1,    1,    1],
        [   2, 5818,  878,  ...,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[   8,  180,   39,  389,  866,    6,   73,  305,    7,  660,   12,    7,
         5563,   12,  251, 2771,  373,    8, 4432,  134,   10,   13, 1192,   35,
          380,   37,  922, 2232,    5,    2],
        [1025,   19,   73,   11,   18,  289,   19,   66, 1850,   35,  587,  241,
         5188, 3611, 5465,    4,   19,   11,  121,  492,  226,   13, 5543,   10,
           21,    5,    2,    1,    1,    1],
        [   8,   21,   34,  321,   12,   39, 1290,  712,  371,    6,    6,   54,
          111, 2294, 1064,   85,  245,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  24,   73,  150,    4,  765,  131,  765,    4,   70,  708,   63, 8253,
           71,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 115,   24,   11,  121,  226,  401,  185, 3719,   10,  172,  175,   13,
          841,   12,   70, 1511, 3316,   26,  100,   55,  117, 7225, 6463,    5,
            2,    1,    1,    1,    1,    1],
        [  84,   26,   21,  128,  589, 2932,  896,    4,  206,   53,  192,   11,
           18,   66, 8285, 3673,  693,    4,   29,   53, 3860,   56, 4406,  184,
          372,  412,    5,    2,    1,    1],
        [  53,  192,   11,   18,  276, 5687,   10,  415,   59, 1643,    7, 1947,
          206,   21,   26,  281, 5748,   62,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  67,   19,   73,  450,   25,   53,  442,  185,  976,    4,  976,    4,
         3315,    4,  976, 3158,    6,   93,  830,   35, 7256,    6,    5,    2,
            1,    1,    1,    1,    1,    1],
        [ 487,    9,   21,  128,   93,    4,   67,  188, 2551, 1004,    7,  179,
            4,    8,  115,  188, 6628, 4973,    9,  655, 1075,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 138,   26,   21,   17,    7, 3360, 1478, 1505,  108, 7599,   55, 2519,
         1221,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [2266,  140,   44,   79,   24, 6480,   62,  108, 3687,  709,    4,   70,
           24, 1873,   26,   17,   24,  162, 3381,   13,  570,  546,    5,    2,
            1,    1,    1,    1,    1,    1],
        [ 225, 1764,   20,  556,   62,   71,  267, 5955,    6,   86,   10,  205,
           10,  862,  335, 1783,    6,  883,  233, 1408, 4127,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 115,  339,  110,  575,   25,  117, 4257, 1636,    6,   12, 7414,   10,
          150,  138,    9,    6,  221,   20,  111,  743,   21,   11,    6, 2288,
            5,    2,    1,    1,    1,    1],
        [  67,   19,  213,   10, 1945,   10,   25,    7,  775,  235,   37,  407,
           17,   24, 5248,   55, 4506,  694,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  21,   11,    6,   39, 1402, 2445,  266, 5764,   17, 3474,    6,    9,
          183,    8,  672,   69,   13, 6536,  128, 5052,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  70,   24,   11,   57,  752,   10,   87,   26, 5802,   13, 1037, 3601,
           55, 1308, 3754,  440,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  33,  442,  110, 2252,   17,   89, 1039,   34,  204,  261, 5746,   10,
         2252,  254,   19, 6291,  111,  144,  474,   21,   10,   51,    5,    2,
            1,    1,    1,    1,    1,    1],
        [   8,  180,   24,  368,   33,   10,   87,   13, 6608,   12,  214,   46,
          100,    4,   55,  663,    4,   33, 1819,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  25, 9090,   48,    7,  245, 1361,    5,   68,  194,   65,   25,   11,
           57,  204,   13,  277,  523, 7467,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 115,    4, 6603, 1488, 3328,  619,   10,   51,   91,  723,   55,  282,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 125,    7,  179,  169, 3584,   51,   13,  341,  561,  103, 2193,  162,
          346,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  71,  423, 1072, 1086,    4, 1459,   73,   66, 2214,   10, 2426, 4058,
           54,  563,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  24,   73,  468,  214,    4,   67,   24,   66,   10, 4414,  111,  468,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  19,   34, 5307,  890,   10,   51, 1501, 6265,   48,    4,  166,   26,
           13, 8974,  279,    4,  204,    4,   19,  213,   10,  450,   25,    5,
            2,    1,    1,    1,    1,    1],
        [  29,    4,   19,   34,  529,   10, 1501,  383,   48,   57,  727,   89,
          207,  359,   89,  282,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  79,   24, 2056,  230,  115,    4, 1230,  852, 2352,  164,  492,   51,
         1720,   18,  233,  922,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 101, 1608,   11,   18,  175,   69,    7, 4446,    4,  101,  144,   10,
          205,  637,    8,  175, 2736,   62,  132,   10,  175,   10,    7, 8145,
            5,    2,    1,    1,    1,    1],
        [1239,    4,   19,  192,   11,   18,  150,  593,  294, 1860,  142,  132,
           69,   17,  744,   91,    4,    8,   17,   11,    6,   89,  521,  181,
         3211,    4,  593,    5,    2,    1],
        [  21,   11,    6,    4,   12,  538,    4, 5985,  131,  948,    4,  131,
          639,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 432,   77,    4,   21,   11,    6,  288,  956, 1042,   69,  984,    9,
          717, 1072,  215,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   8,   19, 2096,   10,  367,  132,   55, 1404,    4,    8,   89, 3646,
          270, 1988,    7, 2354,   12,    7, 3289, 6069,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   7, 4893,   12,  909,  609,    6,  369, 1136,  958,   26,   10,  875,
          117,  248,  179,    6,  540,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 37, 38, 35, 35, 37,  6, 49, 37, 56, 37, 37, 94, 37, 50, 32, 56, 37,
         49, 37, 37, 37,  9, 38, 77, 77, 31,  9, 11, 83],
        [24, 38,  6, 85, 35, 88, 38, 85, 38, 38, 35, 35, 35,  9, 94, 11, 38, 85,
         35, 50, 85, 37,  2, 37, 37, 11, 83, 37, 37, 37],
        [37, 37, 85, 38, 37, 38, 38, 35, 35, 37, 37, 49, 83,  2, 32, 37, 83, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38,  6, 59, 11, 24, 37, 24, 11, 50, 56, 85, 49, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 85, 35, 85, 49, 50, 56, 37, 83, 85, 37, 32, 37, 50,  9, 94, 85,
         37, 37, 37, 29, 56, 11, 83, 37, 37, 37, 37, 37],
        [37, 85, 37, 35, 35, 28,  9, 11, 37, 37, 85, 85, 35, 85, 32, 49, 56, 11,
         83, 37, 49, 38, 35, 38, 35, 35, 11, 83, 37, 37],
        [37, 85, 85, 35, 83, 32, 37, 38, 35, 35, 37,  9, 37, 37, 85, 75, 29, 31,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38,  6, 88, 37, 37, 31, 50, 83, 11, 83, 11,  2, 11, 83,  9, 37, 35,
         62, 38,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37],
        [31, 37, 37, 35, 35, 11, 37, 85, 29, 37, 37, 94, 11, 37, 83, 85, 34, 56,
         37, 34, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 37, 37, 28, 32, 85, 37, 32, 37, 28, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 82, 37, 38, 12, 31, 37, 24, 35, 11, 50, 38, 86, 85, 37, 38, 85,
         59, 37, 94, 18, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 38, 77, 35, 31, 37, 37, 36, 37, 83, 37, 85, 37, 38, 35, 35, 37, 38,
         35, 35,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [83, 49, 37, 88, 37, 37, 94, 94, 37, 37, 28, 37, 59, 37, 37, 37, 35, 77,
         83, 83, 37, 85, 37, 49, 11, 83, 37, 37, 37, 37],
        [37, 38, 88, 37, 88, 37, 37, 37, 38, 35, 77, 35, 37, 38, 31, 37, 36, 32,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 38,  9, 35, 35, 32, 37, 29, 37, 37, 24, 37,  9, 37, 37, 24,
         35, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 38, 85, 77, 49, 37, 85, 85, 36, 37, 94,  9, 37, 50,  2, 83, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 31, 37, 86, 37, 37, 32, 85, 83, 83,  2, 37, 86, 37, 38, 28, 83, 85,
         31, 37, 37, 38, 11, 83, 37, 37, 37, 37, 37, 37],
        [37, 37, 38, 49, 37, 37, 85, 37, 23, 37, 56, 11, 37, 11, 37, 32, 11, 37,
          9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 29, 31, 37, 83, 94, 11, 38,  9, 11, 37, 85, 77, 83, 37, 50, 83,  2,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 28, 35, 35, 31, 37, 38, 50, 94, 37, 32, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 94, 85, 83, 38, 37, 33,  9, 37, 28, 85, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 34, 24, 32, 11, 50,  6, 85, 49, 37,  2, 49, 49,  9, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38,  6, 29, 56, 11, 37, 38, 85, 37,  2, 83, 29, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85,  2, 83, 37, 38, 83, 29, 31, 11, 37, 85, 37,  2, 50, 11, 83, 11,
         38, 88, 37, 88, 37, 11, 83, 37, 37, 37, 37, 37],
        [83, 11, 38, 85,  6, 37, 83, 24, 31, 77, 35, 37, 83, 37, 37, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 16, 37, 83, 11, 17, 73, 56, 85, 50, 38, 38, 35, 35, 31, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38,  6, 85, 35, 85, 37, 37,  9, 11, 38, 85, 37, 85, 37, 37, 85, 29, 31,
         37, 37, 85, 37, 37,  9, 11, 83, 37, 37, 37, 37],
        [28, 11, 38, 85, 85, 35, 59, 83, 50, 56, 49, 37, 37, 37, 24, 50, 11, 37,
         37, 85, 37, 37, 38, 35, 23, 11, 83, 11, 83, 37],
        [37, 85, 37, 11, 37, 83, 11,  5, 37, 94, 11, 37, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 11, 37, 85, 37, 83, 31, 83, 37, 94, 37, 34, 24, 24, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 85, 37, 37, 94, 11, 37, 37,  2, 37, 31, 37, 23, 37, 37,
         28,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 88, 37, 38, 35, 37, 44, 28, 94, 85, 37, 49, 37, 34, 94, 37, 36, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([30, 27, 19, 15, 25, 28, 20, 24, 23, 15, 24, 23, 26, 20, 22, 18, 24, 21,
        20, 14, 15, 16, 14, 25, 18, 18, 26, 29, 15, 17, 22, 19],
       device='cuda:0'), 'ntokens': 672}, 'target': tensor([[  64,   14,  917,  ...,    1,    1,    1],
        [  72,  209,  286,  ...,    1,    1,    1],
        [  99,   82,   52,  ...,    1,    1,    1],
        ...,
        [7330, 3444,   36,  ...,    1,    1,    1],
        [  72, 3452,  182,  ...,    1,    1,    1],
        [5818,  878,    6,  ...,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([23, 23,  9, 16, 26, 36, 27, 24, 21, 17, 22, 22, 27, 16, 22, 18, 18, 23,
        14, 17, 13, 14, 13, 26, 24, 19, 18, 19, 10, 14, 27, 22],
       device='cuda:0'), 'ntokens': 640, 'nsentences': 32}
##################### {'id': tensor([116244, 121226,   9866,  95660, 166180,  75150, 114091, 161643],
       device='cuda:3'), 'net_input': {'src_tokens': tensor([[-0.0402, -0.0443, -0.0395,  ..., -0.0051, -0.0036, -0.0027],
        [-0.0213, -0.0238, -0.0229,  ...,  0.0110,  0.0090,  0.0111],
        [-0.0016, -0.0007,  0.0010,  ..., -0.0071, -0.0067, -0.0037],
        ...,
        [-0.0137, -0.0097, -0.0088,  ..., -0.0635, -0.0572, -0.0307],
        [ 0.0045,  0.0037,  0.0032,  ...,  0.0076,  0.0076,  0.0088],
        [-0.0015, -0.0011, -0.0007,  ...,  0.0008,  0.0005,  0.0000]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([192000, 192000, 192000, 192000, 192000, 192000, 192000, 191999],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,   72,  145,   36,  334,    4,  566,    9,   23, 2500,    4,   36,
           27,   52,    4,  268,  212, 7389, 3168,    4,   74,   32,    9, 2682,
           22, 1036,   83,    4,   16,   74,   32,   36,    9, 1209,  160,  794,
          152,  234,   15, 1036,   83,    4,   47,  263,  766,   27,  847,    4,
           74,   81,   14, 2543, 1453,    4,   36,   27,  167, 5288,  224,   36,
          161,   14, 2039,  393, 5041,   22,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  313,  198,  831,  470,   49,  252,   83,  477, 1388,    5,
           92, 1035,   29,    5, 1952,   41,   75,  177,    4,   41, 1721,   30,
         1287,   16,  208,   40, 2358,  754,  710,  899, 1055,  483,   30,   43,
           40,  905,  417,  444,  973,  236,  605,    4,   29,   74,   14,    6,
         2358,  754,  710,  899, 1055,  483,    5,   68,  710,  783,   18,   44,
         5816,   37, 2161,  290,  532,   65,  928,  776,   41,  477,  118,  301,
          140,   57,   15,    6,  715,   18,  260,    5],
        [   2,   72,  313, 7686,   16,  256, 5660, 7191,   20, 3031,   23, 1536,
           37,    4,   16,  114,   31,  198,   14,  435,   49,  482,   13, 5295,
         2594,    4,  313,   31, 9112,    4,   74,   43,  385, 5437,    4,   60,
          216, 9898,    4,  216, 1214, 4247,    4,  216, 1235, 1993,  693,    4,
           90,   32,  107, 1602, 1748,  123,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99,  178,   52, 1100,    4,   14, 3842,    4,   50, 8928,   20,
           30,  844,   23, 3714,   96,  855,    4,   16,   36,  178,   52, 1100,
            4,   14, 3842,    4,   50, 8928,   20,   14,  437, 2097,  165,   49,
         3419,   16, 1981, 6392,   22,  855,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  520,   31,   40, 4846,  239,    4, 3874,   75,    4,   50,  105,
         6719,   97, 1185,    5, 7088,    9,   52, 2338,   20, 2312, 5209,   45,
           88,  247, 1304, 1779, 2221,   82,    5, 7545,  124, 2681, 9678,  877,
          290,  381,  517,    4,  258, 4251,   30, 4956, 5171, 2589,  578,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  147,  789,   83,   32,  118,  758,    4,   88,   36,  361,  421,
         5148,  241,  756,  418,   28, 4245,    4,   60,  151,  301,   15,    6,
          240,    4,   23, 2121,  425, 3637, 6554,    5,   72,  256,    4,   36,
           27,  766,    4,  268,   32, 4042,  737,  122,  111,  156,  152,   45,
          390,   61, 4858,   22,  123,    4,   14, 3041,   47, 2431,  354,    4,
           16,  139, 4042,  603,  122,  111,  156,  152,   45,  390,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1356,  330,  121,  330,   22,    6,  562,    4,   14,   41, 1071,
          196, 1626,  127,    4,  239,  212, 4886, 3478, 2710,    9,  355, 2920,
          398,  223,   14, 1813,  599,  129,  531,  494,   15,    6,    4,   14,
           43,  223,  243,  200,  389,  588, 1398,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4898, 7902,    4,   14,  167, 8983,  314, 3789,  516,    4,   76,
         1473, 6155,    4, 3377,   43,  210,  151, 1280, 2665, 2478,  374, 1443,
           16, 3206,  795,    4,  548, 3613,    4,   16,  314, 3789,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[  19,   73,  450,   25, 3098,   21,   26,    4,  125,   33, 2475,   12,
         7125,    4,  116,  100,   70,   25,   11,  121, 1110,    9, 2262,    4,
            8,  116,  100,   70,   25,   11,  121, 1110,    9,   13,  525,  287,
         7195,    6,    4,   21,  689,   11,   18,  172,  988,  138,   25,  468,
            7, 1422,    4,   21,   11,    6,  133, 7199,    4,   21,   11,    6,
          142,   10, 3982,    7, 1422,    5,    2,    1],
        [  19,   11,   45, 1123,  185,   12,   25,   66, 1346,   80,   21,    5,
          168,   11,    6,  138,   21, 1429,    5,  934,   25,   11,   57,  802,
            7, 1465,    8,   25,  150,   13, 2902,   18, 5693,   17,   25,  154,
           26,  185, 1871, 2035, 1236,  297,  293,    4,  100,   33, 2902,   18,
         5693,    5,  939,  160, 2329, 2158,   10,  290,  532,  834,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   11,   45, 7686,    4,    8,   89, 5671, 3699,    9,    7, 4235,
           35,  501, 7015,    6,    4,    8,   19,  274,   85,  807,  115,    4,
            8,   19,   11,   45,  116, 9693,  131,    7,  207,   53, 3753,  336,
           71,  143,  637, 3455,    4,  143, 2000,  240,   54,    4,  143, 2583,
          140,  234, 1775, 2130,    6,  254,   24,  169,  700,   66,  521,  430,
          366,   48,   12,   13, 2042,  581,    5,    2],
        [  84,   26,   13,  926,   17,  154,    6,   17, 2922,   26,    7,  467,
           12, 5803,    4,    8,   84,   26,   13,  926,   17,  154,    6,   17,
         2922,   26,    7,   13,   59,  338, 2460,   12, 3061,    8, 3254,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,   19,   34,  339,    9,    4,   21, 2947,   62,   17,   33, 8598,
           35,  181,  614,  240, 7145,   34,  378, 2575,   62,  199,   13, 3768,
         2375, 2980,    4,  206, 1111,  109, 1646, 5987,    6, 6225,  877, 6167,
           54,    9,   70, 5422,  169,   51,    7, 1074,  964,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   12,  538,   24,   66,   13,  207,   10, 2032,   17,  115,   69,
           13, 8148, 5052,    4,   71,   13, 4273,   17, 3412,    6, 2011, 2264,
          241,  140, 1782,    4,    8,   21,   11,    6,  528,  125,   24,  220,
         3412, 5591,  122,  111,  430,   45,  407,   17, 5422, 2220,   11,   18,
           51, 2134,    4,    8,  113, 7522,  122,  111,  430,   45,  407,    5,
            2,    1,    1,    1,    1,    1,    1,    1],
        [ 417,  121,   56,   15,    6,  562,    4,  148,   45,   25,   11,  158,
         1510, 1065,    4,  188,  144,   17, 4716, 8491,   48, 1248,  111,    9,
          267,  359,    7, 4531,  563,    6,   12, 5187,   17,  225,  188,  226,
          359,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24,   66, 1655,   12, 5825,    6,  148,   63, 7105,   80, 4586,
          931,    4,    8,   53,   11,   57, 2551,   77,  336,    4,   29,  120,
         3326,   13,  583,  925,    9,    4,   53,  116, 1233,  778,    8,  205,
            8, 1202,    8, 2554,   13,  282,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[38,  6, 88, 37, 83, 37, 85, 11, 37, 37, 38, 37,  9, 11, 83, 37, 50, 37,
         85, 35, 59, 37, 56, 11, 37, 83, 37, 50, 37, 85, 35, 59, 37, 37, 35, 35,
          2, 37, 11, 37, 85, 85, 35, 83, 23, 37, 37, 29, 37, 94, 11, 37, 85, 37,
         83,  2, 11, 37, 85, 37, 49, 37, 29, 37, 94, 11, 83, 37],
        [38, 85, 35, 83, 50, 37, 37, 85, 59, 37, 37, 11, 37, 85, 37, 37, 37, 56,
         11, 88, 37, 85, 77, 49, 37,  9, 37, 37, 59, 37, 38, 35, 35, 37, 37, 59,
         85, 50, 83, 38, 35, 35, 35, 11, 37, 37, 38, 35, 35, 11, 38, 35, 35, 77,
         37, 35, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 35, 34, 11, 37, 37, 94, 31, 37, 37, 24, 38, 38, 73, 37, 11, 37,
         38, 59, 37, 56, 83, 11, 37, 38, 85, 35, 83,  2, 37, 37, 83, 37, 28, 37,
         37, 50, 37, 32, 11, 50, 79, 35, 49, 11, 50, 83, 35, 35, 35, 35, 37, 37,
         38, 85, 50, 85, 38, 35, 77, 31, 37, 37, 94, 83, 11, 83],
        [37, 85, 37, 94, 37, 59, 37, 37,  9, 85, 37, 38, 37, 76, 11, 37, 37, 85,
         37, 94, 37, 59, 37, 37,  9, 85, 37, 37, 35, 35, 35, 37, 56, 37, 56, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 49, 37, 11, 37, 88, 31, 37, 37, 24, 38, 35, 35, 35, 94, 85,
         49, 29, 31, 37, 37,  2,  9, 23, 11, 37, 34, 37, 34, 94, 37, 31, 38, 35,
         49, 37, 50, 83, 85, 38, 37, 49,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83, 38, 85, 37, 83, 37, 23, 37, 83, 37, 37, 29, 23, 11, 37, 37,
          9, 37, 29, 37,  9, 38, 35, 35, 77, 11, 37, 37, 85, 37,  2, 37, 38,  6,
         29,  9, 35, 83, 35, 35, 35, 37, 83, 85, 85, 35, 38, 31, 11, 37, 83, 38,
         35, 83, 35, 35, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 38, 77, 37, 77, 11, 50, 35, 37, 85, 35, 59, 24, 11, 85, 85, 37,
         32, 49, 31,  2, 83, 37, 37, 37, 37, 50,  9, 37, 37, 76, 37, 37, 85, 85,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 85, 24, 37, 28, 37, 50, 85,  2, 37, 49, 37, 11, 37, 37, 85, 77,
         29, 50, 37, 11, 83, 37, 50, 37, 88, 85, 37, 11, 37, 83, 29, 50, 37, 85,
         37, 49, 37, 49, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:3'), 'lengths': tensor([67, 59, 68, 37, 47, 61, 39, 44], device='cuda:3'), 'ntokens': 422}, 'target': tensor([[  72,  145,   36,  334,    4,  566,    9,   23, 2500,    4,   36,   27,
           52,    4,  268,  212, 7389, 3168,    4,   74,   32,    9, 2682,   22,
         1036,   83,    4,   16,   74,   32,   36,    9, 1209,  160,  794,  152,
          234,   15, 1036,   83,    4,   47,  263,  766,   27,  847,    4,   74,
           81,   14, 2543, 1453,    4,   36,   27,  167, 5288,  224,   36,  161,
           14, 2039,  393, 5041,   22,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  313,  198,  831,  470,   49,  252,   83,  477, 1388,    5,   92,
         1035,   29,    5, 1952,   41,   75,  177,    4,   41, 1721,   30, 1287,
           16,  208,   40, 2358,  754,  710,  899, 1055,  483,   30,   43,   40,
          905,  417,  444,  973,  236,  605,    4,   29,   74,   14,    6, 2358,
          754,  710,  899, 1055,  483,    5,   68,  710,  783,   18,   44, 5816,
           37, 2161,  290,  532,   65,  928,  776,   41,  477,  118,  301,  140,
           57,   15,    6,  715,   18,  260,    5,    2],
        [  72,  313, 7686,   16,  256, 5660, 7191,   20, 3031,   23, 1536,   37,
            4,   16,  114,   31,  198,   14,  435,   49,  482,   13, 5295, 2594,
            4,  313,   31, 9112,    4,   74,   43,  385, 5437,    4,   60,  216,
         9898,    4,  216, 1214, 4247,    4,  216, 1235, 1993,  693,    4,   90,
           32,  107, 1602, 1748,  123,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  99,  178,   52, 1100,    4,   14, 3842,    4,   50, 8928,   20,   30,
          844,   23, 3714,   96,  855,    4,   16,   36,  178,   52, 1100,    4,
           14, 3842,    4,   50, 8928,   20,   14,  437, 2097,  165,   49, 3419,
           16, 1981, 6392,   22,  855,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 520,   31,   40, 4846,  239,    4, 3874,   75,    4,   50,  105, 6719,
           97, 1185,    5, 7088,    9,   52, 2338,   20, 2312, 5209,   45,   88,
          247, 1304, 1779, 2221,   82,    5, 7545,  124, 2681, 9678,  877,  290,
          381,  517,    4,  258, 4251,   30, 4956, 5171, 2589,  578,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 147,  789,   83,   32,  118,  758,    4,   88,   36,  361,  421, 5148,
          241,  756,  418,   28, 4245,    4,   60,  151,  301,   15,    6,  240,
            4,   23, 2121,  425, 3637, 6554,    5,   72,  256,    4,   36,   27,
          766,    4,  268,   32, 4042,  737,  122,  111,  156,  152,   45,  390,
           61, 4858,   22,  123,    4,   14, 3041,   47, 2431,  354,    4,   16,
          139, 4042,  603,  122,  111,  156,  152,   45,  390,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [1356,  330,  121,  330,   22,    6,  562,    4,   14,   41, 1071,  196,
         1626,  127,    4,  239,  212, 4886, 3478, 2710,    9,  355, 2920,  398,
          223,   14, 1813,  599,  129,  531,  494,   15,    6,    4,   14,   43,
          223,  243,  200,  389,  588, 1398,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [4898, 7902,    4,   14,  167, 8983,  314, 3789,  516,    4,   76, 1473,
         6155,    4, 3377,   43,  210,  151, 1280, 2665, 2478,  374, 1443,   16,
         3206,  795,    4,  548, 3613,    4,   16,  314, 3789,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([67, 80, 55, 43, 48, 71, 44, 35], device='cuda:3'), 'ntokens': 443, 'nsentences': 8}
##################### {'id': tensor([ 39728, 143717, 165959, 101812,  81977, 156830], device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 1.6357e-02,  2.5757e-02, -5.1880e-04,  ..., -1.3306e-02,
         -2.0172e-02, -2.4475e-02],
        [-1.2207e-04, -4.2725e-04, -4.2725e-04,  ...,  3.3875e-03,
          5.0049e-03,  4.6997e-03],
        [ 6.0120e-03,  5.6458e-03,  5.7983e-03,  ...,  5.3711e-03,
          4.7913e-03,  4.2419e-03],
        [ 1.0681e-03,  4.5776e-04,  9.1553e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-7.3120e-02, -9.4971e-02, -1.1804e-01,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-9.1553e-04, -1.2207e-03, -1.4954e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([376000, 376000, 376000, 375680, 375680, 375680], device='cuda:2'), 'prev_output_tokens': tensor([[   2,   64,  114,   81,   74,  212,  919,   29,    9,  337, 4571,   40,
         1685,  303, 1877,  171, 7565,   27,    4,  190, 3092,   28, 2489,    4,
          189,  130,   95,   47, 7915, 3385, 5881,    4,   88,   28, 3534,    4,
           74,   75,  186,  871, 9362,    4,  124,   14, 1200,   28, 1680,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 1297,   18,  239,   47,   90, 5433,   78, 4816, 1407,   98,
         4439,    4,  519,   90,   56, 1869,   93,  156, 3576,  152,   48,  481,
            6, 5433,   16,  482,    4, 1802, 1047,  397, 1071,    4,   27,  105,
         5393, 4421, 3185,   59,   18, 4508, 4915,   48,    4,  268,   32,    9,
          141,  201, 3445, 5600,   22,   16, 1916,   15,  702,    4,  628,   32,
          223,   14, 2528,   35,  360,   18,  569,   15,   35, 3176, 2471,  249,
         5021,  165,   98, 2622,   76,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  147,   31,  705,    4,   50,   14, 1270,   16,   14, 7921,   22,
         2480,    4,   88,  669, 1928,   15, 3659,   28,   51, 1471,    4,  454,
          534, 2934,  309,    4, 1489,  181,   59,  365,  236,   28,  421, 5729,
          272,    4,   88, 1756,  156,  234,   59,  272,   28,  123,   16, 4053,
          309,   43,   75,  454, 7176,   37,   61,   14, 3543,   22, 2064,   20,
         4589,    4,   88,  611,  210,  425, 3960,    4,   52, 1983, 4144,   28,
         1205,   16,   29,  910,   14, 1572,  364, 4423, 3086,   28,  123,   16,
           14, 3037,   28, 3598,    4,   14,   32,  263,  516,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  222,  113,   23, 5528, 1434,   20,    4,   58,   56, 7632,  344,
         1676,   39, 1915,   18,    4,  210,  102,   52, 1084,  491,   15, 1310,
          219, 1217,  165, 6558,   18,  161,    4,  730,   36,    4,   50,   43,
         2012,   14,  377, 4642,  141, 1084,  491,   15, 1310,  219, 1217,  165,
           61,  102,   56, 7632, 1496,    4,   43,  136,   97, 1378,  381, 3759,
          129, 3234,    6, 6000,    4,  463, 4408, 4915,   46,   16,  847,   58,
         1607,  112, 1883,   23,   40,  542, 9545,  463, 2349,    9,   58, 1084,
          491,  129, 1676, 5774,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 9836, 1496,  173,  113,   52, 2747, 9566,  129, 8623,    6,
           39,    4,   58, 7230,   78, 6743,    4,   14,  377, 6304,   78,   58,
         2915,  620,  571,    4,   58,  472,   45, 4125,   37,    4,   58, 6743,
           37,    4,   58,  330,  444,   18,  219,   45,   37,    4,   58,  228,
         3701,   37,  129, 1190,  265,   93, 2836,  212, 1332,    6,  927,  544,
         2038,   15, 4427,   20,  173,    4,   14,   47,   49,  141, 2222,   49,
         7040,  265, 6546,   59,   22,  615,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2, 1046,   14, 2663, 5701,  418,  381, 2017, 1669,   14,  353,    4,
           74,   40,  580,   23,  201,   39,   75, 1035,    4,   43,  269,  374,
           34,   81,  269,  145,    5,  146, 1776, 2909, 7159,   14, 2126,  344,
         8674,    6,    5, 1033,  686,  196,   29, 3655,   15, 2674,    4,  403,
           81,   40, 7083,  124, 6115, 3456,   27,    4,  124,  403,   81,   40,
         1041,   61, 4522,   18,  193,  374,    4,   34, 3655,   27,  193, 2582,
           59, 1282, 1916,   15,    4,   14,   47,   60,  191,   48, 1942, 6883,
          127,    5,   16,   81,  651,   36,   47,  263,  414,    4,  382,   81,
          334,  145,   44,   38, 1307,  806,    4,   32,  127,   36,  317, 5361,
         2668,   15,    4, 4737,   27, 2812,    4,   50,  304,  936, 8954,   20,
           78,   30, 4968,   15,  676,   76,    5]], device='cuda:2')}, 'transcript': {'tokens': tensor([[ 238,    4,  120,   25,   63,  172, 3006,    9,   33, 1501, 8253,  979,
           12, 2567,  250,  264,    4,   79,   33,   81,   26,    4,  101,  689,
           11,   18,   66,  890, 2303,  859,  244,   10, 5625,  138,  284,  955,
          598,    6,    4,  109,  284, 1195,   85,  637,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7, 1618,   34, 1017,  132,   86,   79,   13, 4098,   12, 1793,  998,
            4,   67,   12,   39,   56,   15, 1255,  140, 3576,   62,  266, 4098,
            4,    8,  440,    4, 1802, 1047,  215, 1065,    4,   17, 2805,   26,
           79,  909,    6,  609,   15,   18,   79,  700,    4,  125,    4,   12,
          538,    4,   24,  618,    9,   13,  179,   12, 3741,    4,   12, 2020,
            4,    8,   24,   11,   57, 8425,   10,   21,  359,    7, 2528, 2007,
         1614, 1569,   57,  356,    6,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  67,   19,  388,   21,   10,   25,   17,  103,    7, 1384, 1224,    8,
         5316, 1075,  213,   10, 3320,  913,  111,    9, 3312,   15,   18, 1010,
            4,   53,  659,   66,   10, 2807,  452, 5729,  829,    9,    7, 1706,
         3506,    9, 1296,   10, 7119,    4,    8,  131,   17,    4,   53,  506,
           66,   10, 2238,  143, 7176,   20,  111,   69, 1519, 5204,    6,   10,
          601,  719,    7, 1403, 2092,    8, 4005,   51,  529,   10, 2215, 1381,
         3078,  457,    8,  719,    7,  102, 1327,  371,  609,   96,   17,   24,
          172,  213,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  29,  103,   13, 3742, 1434,  365,   26,  665,   85,    7, 3327,   12,
           13, 2745,   71, 7777,   62, 1052, 4322, 1315,  407,    4,  289,    4,
           70, 1148,   26,   17,    4,  103,   53,  150, 2808,   12, 1052, 4322,
         1315,  407,   69,    7, 3327,    4,   53, 2318, 1233,  665,   85,   21,
           46,   84, 1859, 5054,    7, 4675, 2202,  391,    9, 1150,    6, 4653,
           69,    7, 2745,   11,    6, 6089,    6,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  29,    7,  613,   26,    7, 7168,  221,    6,  168, 2613,   17,   84,
           11,    6,   13, 1905,  296,   12, 9585,    4,   13, 3835,   55, 9585,
            4,    7, 3835,   24,  451,  508,    7, 9265,    4,    7,  203,   45,
         4125,   37,    4,    7,  447,   37,    4,    7, 6668,  447,   37,    4,
            7, 4585, 2836,  447,   37,   12,   33, 2583, 9646, 1894,  993,    4,
            8,   86,   13, 2042,   12, 1452,  140, 2566,  737,    6,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 125,    7,  281, 6563, 2245,   63,  172,  116,  321,   12, 2750,   54,
            7,  207,    7,  179, 1584, 1429,    4, 2750,   54,   70,  988,   73,
           87,    4,    7,  281, 6563, 2420,    6,   63,  116, 2750,   54,    7,
         7465,    4,    8,  419,   56, 9192,  111, 3816, 3487,    4, 1179,   25,
           11,   57,   13, 3673,  109,   13,  595, 2461,  249,  109,   25,   11,
           57, 8254,   13, 1269,   46,  995,   17,   11,    6, 3816,   46,  925,
          132,   71, 1195,   17, 2924,   11,   18, 2026,   48,    9,    7, 1403,
           12,   21,    4,    8,   25,   73,   11,   18,   87,   13,  324, 1329,
          893,   21,  691, 5784,   25,   73,  289,    4,   38, 1824, 2142,    4,
          238,   24,   11,   57,  116,  142,   10,   66,   10,  203, 5749,   20,
           33,    5,    2]], device='cuda:2'), 'cluster_tokens': tensor([[83, 11, 37, 37, 85, 83, 36, 37, 37, 83, 49, 32, 37, 49, 50,  2, 11, 37,
         37, 38, 85, 11, 38, 85, 85, 35, 85, 83, 94, 31, 37, 37, 29, 37, 37,  9,
         59, 37, 11, 37, 37, 56, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 31, 85, 31, 37, 83, 37, 37,  9, 37, 28, 94, 11, 37, 37, 38, 38, 77,
         35, 35, 35, 31, 35,  9, 11, 37, 83, 11, 34, 73, 24, 24, 11, 37, 94, 85,
         37, 38, 37, 35, 77, 35, 37, 50, 11, 37, 11, 37, 83, 11, 38, 49, 37, 37,
         94, 37, 94, 11, 37, 94, 11, 37, 38, 85, 77, 31, 37, 37, 37, 37, 34, 11,
         17, 56, 77, 77, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 37, 37, 37, 37, 37, 31, 56, 37, 28, 56, 88, 37, 29, 28,
         83, 37, 35, 77, 35, 35, 11, 37,  6, 85, 37, 88, 38, 35, 49, 37, 37,  2,
         32, 37, 49, 37, 76, 11, 37, 37, 37, 11, 37,  6, 85, 37, 29, 50,  2, 77,
         83, 37, 28, 32, 37, 37, 49, 49, 37, 28, 23, 37, 83, 38,  6, 37, 49, 94,
         32,  2, 37, 49, 37, 38, 35, 35, 35, 77, 37, 38, 83, 88, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 37, 12, 35, 35, 85, 59, 37, 37,  9, 37, 37,  9, 37, 88, 31, 38,
         97, 35, 35, 11, 88, 11, 50, 85, 85, 37, 11, 37, 37, 59, 32, 37, 38, 97,
         35, 35, 37, 37,  9, 11, 37, 83, 29, 59, 37, 37, 11, 37, 35, 49, 37,  9,
         59, 34, 37, 77, 37, 37, 37, 37,  9, 85, 37, 94, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 32, 85, 37, 28, 35, 37, 37, 86, 37, 37, 85, 37, 37, 50, 49, 37,
         32, 11, 37, 36, 37, 32, 11, 37, 36, 38, 85, 88, 37,  9, 11, 37, 38, 35,
         35, 77, 11, 37, 37, 77, 11, 37, 32, 37, 77, 11, 37, 29, 35, 37, 77, 37,
         37, 83, 83,  2, 32, 11, 37, 83, 37, 94, 37, 88, 35, 35, 35, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 75,  2, 56, 85, 83, 83, 38, 37, 29, 49, 37, 83, 37, 94, 37, 56,
         11, 29, 49, 50, 23,  6, 85, 11, 37, 75,  2,  9, 37, 85, 83, 29, 49, 37,
         32, 11, 37, 50, 38,  2, 83,  2, 94, 11, 37, 37, 85, 77, 37, 49, 37, 37,
          9, 77, 77, 37, 37, 85, 77, 49, 37,  9, 11, 50, 37, 85, 37,  2, 11, 85,
         37, 37, 56, 37, 85, 85, 35, 29, 31, 37, 37, 28, 37, 37, 11, 37, 37,  6,
         85, 35, 85, 37,  2, 32, 49, 37, 31, 83, 37,  6, 88, 11, 38, 35, 35, 11,
         83, 38, 85, 77, 83, 49, 37, 85, 37, 38, 35, 77, 37, 11, 83]],
       device='cuda:2'), 'lengths': tensor([ 46,  79,  88,  69,  72, 123], device='cuda:2'), 'ntokens': 477}, 'target': tensor([[  64,  114,   81,   74,  212,  919,   29,    9,  337, 4571,   40, 1685,
          303, 1877,  171, 7565,   27,    4,  190, 3092,   28, 2489,    4,  189,
          130,   95,   47, 7915, 3385, 5881,    4,   88,   28, 3534,    4,   74,
           75,  186,  871, 9362,    4,  124,   14, 1200,   28, 1680,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 146, 1297,   18,  239,   47,   90, 5433,   78, 4816, 1407,   98, 4439,
            4,  519,   90,   56, 1869,   93,  156, 3576,  152,   48,  481,    6,
         5433,   16,  482,    4, 1802, 1047,  397, 1071,    4,   27,  105, 5393,
         4421, 3185,   59,   18, 4508, 4915,   48,    4,  268,   32,    9,  141,
          201, 3445, 5600,   22,   16, 1916,   15,  702,    4,  628,   32,  223,
           14, 2528,   35,  360,   18,  569,   15,   35, 3176, 2471,  249, 5021,
          165,   98, 2622,   76,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 147,   31,  705,    4,   50,   14, 1270,   16,   14, 7921,   22, 2480,
            4,   88,  669, 1928,   15, 3659,   28,   51, 1471,    4,  454,  534,
         2934,  309,    4, 1489,  181,   59,  365,  236,   28,  421, 5729,  272,
            4,   88, 1756,  156,  234,   59,  272,   28,  123,   16, 4053,  309,
           43,   75,  454, 7176,   37,   61,   14, 3543,   22, 2064,   20, 4589,
            4,   88,  611,  210,  425, 3960,    4,   52, 1983, 4144,   28, 1205,
           16,   29,  910,   14, 1572,  364, 4423, 3086,   28,  123,   16,   14,
         3037,   28, 3598,    4,   14,   32,  263,  516,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 222,  113,   23, 5528, 1434,   20,    4,   58,   56, 7632,  344, 1676,
           39, 1915,   18,    4,  210,  102,   52, 1084,  491,   15, 1310,  219,
         1217,  165, 6558,   18,  161,    4,  730,   36,    4,   50,   43, 2012,
           14,  377, 4642,  141, 1084,  491,   15, 1310,  219, 1217,  165,   61,
          102,   56, 7632, 1496,    4,   43,  136,   97, 1378,  381, 3759,  129,
         3234,    6, 6000,    4,  463, 4408, 4915,   46,   16,  847,   58, 1607,
          112, 1883,   23,   40,  542, 9545,  463, 2349,    9,   58, 1084,  491,
          129, 1676, 5774,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 146, 9836, 1496,  173,  113,   52, 2747, 9566,  129, 8623,    6,   39,
            4,   58, 7230,   78, 6743,    4,   14,  377, 6304,   78,   58, 2915,
          620,  571,    4,   58,  472,   45, 4125,   37,    4,   58, 6743,   37,
            4,   58,  330,  444,   18,  219,   45,   37,    4,   58,  228, 3701,
           37,  129, 1190,  265,   93, 2836,  212, 1332,    6,  927,  544, 2038,
           15, 4427,   20,  173,    4,   14,   47,   49,  141, 2222,   49, 7040,
          265, 6546,   59,   22,  615,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [1046,   14, 2663, 5701,  418,  381, 2017, 1669,   14,  353,    4,   74,
           40,  580,   23,  201,   39,   75, 1035,    4,   43,  269,  374,   34,
           81,  269,  145,    5,  146, 1776, 2909, 7159,   14, 2126,  344, 8674,
            6,    5, 1033,  686,  196,   29, 3655,   15, 2674,    4,  403,   81,
           40, 7083,  124, 6115, 3456,   27,    4,  124,  403,   81,   40, 1041,
           61, 4522,   18,  193,  374,    4,   34, 3655,   27,  193, 2582,   59,
         1282, 1916,   15,    4,   14,   47,   60,  191,   48, 1942, 6883,  127,
            5,   16,   81,  651,   36,   47,  263,  414,    4,  382,   81,  334,
          145,   44,   38, 1307,  806,    4,   32,  127,   36,  317, 5361, 2668,
           15,    4, 4737,   27, 2812,    4,   50,  304,  936, 8954,   20,   78,
           30, 4968,   15,  676,   76,    5,    2]], device='cuda:2'), 'target_lengths': tensor([ 48,  78,  94,  89,  79, 127], device='cuda:2'), 'ntokens': 515, 'nsentences': 6}
##################### {'id': tensor([188087,  71804, 126402,  56923,  83333, 170398, 192179, 128865, 170307,
        165829, 215610,  33243, 136943,  76182, 176599, 172744],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-7.5378e-03, -7.5684e-03, -7.4158e-03,  ...,  3.5095e-03,
          3.5706e-03,  4.4250e-03],
        [-2.4414e-04,  1.0681e-03,  2.3193e-03,  ..., -1.8311e-03,
         -1.5564e-03, -2.3804e-03],
        [ 4.8828e-04,  1.5259e-04, -3.0518e-05,  ..., -1.6144e-02,
         -1.8097e-02, -2.1484e-02],
        ...,
        [-8.5144e-03, -4.6692e-03, -5.0964e-03,  ..., -1.2817e-03,
         -6.4392e-03, -1.0223e-02],
        [-6.1035e-05,  1.2207e-04,  1.8311e-04,  ..., -8.8501e-04,
         -9.7656e-04,  0.0000e+00],
        [ 1.7090e-03,  1.8921e-03,  1.4343e-03,  ..., -5.7983e-04,
         -2.0142e-03,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([120320, 120320, 120320, 120320, 120320, 120320, 120320, 120320, 120320,
        120320, 120320, 120320, 120320, 120320, 120319, 120319],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,  312, 2368,   27, 6539,    4,   61,  102,   14, 4236,  202, 2378,
         1966, 1597,   52, 2785,   20,   27,    4,   16, 7451,   52, 8769,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64,   34,  716,  414,   27,    4,  638,   31,    4,   27,    4,
           50,   36,   74,   40, 1003,   27,    4,   90,  403,   41,   75,   88,
          247, 7110,   16, 2578,  118, 8738, 2664, 1602,    4,   16,   90,  403,
           43,   30,  773,   60,  141, 8738,   35,  806,  727,   20,  371, 5138,
         1602,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   99, 7847,    4, 5235,   48,  253,   21,  128,  634,  515,  867,
         2471, 3481,    4,   30,   31,   98,  405,   45,  441, 3481,  577, 5723,
          209,    4,   38,  992,  181,  349,  803,    6,  285,  349,   57,  290,
          650,  197, 6450, 4818,   30,  350, 1879,   27,  197,  834,  312,  167,
         3537,  684, 1485,  531,    6, 3326,  122,   22, 2628,   22,    5],
        [   2,   99,  178,   52, 1600, 3177,    5,  327,  730,  547,   42,  146,
         7019,   23, 3309, 2344,   58, 1676,  547,  253, 1972,  219,  527,   37,
         2479,  537,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  938,   45, 3264,  398, 4944,  105, 1786, 5420,   15,   52,  331,
          353,   49, 1351,    4,   14,    9,  212,  353,   49,  301,  152, 1374,
          217, 1776,   32,  622,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1077, 1021,  605,   75, 2692,    4, 2692,   97, 6302,    4,   23,
         5961, 4426,  129,  869,  777,   18,  152,   22,    6,    4, 3154, 5219,
           20,   76, 2936,    9, 4184,  184,    6,  412,  544,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2235,  308,  322, 2856,   15,  127,  113,   28,   46,   41,   13,
          176,  549,   36,   46, 2810,   15, 1389,   15,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104, 1908,   15,   14,  674,  992,  360,  920,   35,  360, 1079,
         3245,  223,   46,  674,  992,  360,  920, 1634,   78, 2888,  174,  784,
            6,   35,  992,  243,  152,   45,  390,   35, 9542,    9,  330, 6127,
         1347,   46,   16,   31,   82,    9,   58,  808,  798,  332,   14,  441,
         3957, 1089,  212, 2727,    5,    1,    1,    1,    1,    1,    1],
        [   2,  222,   41,   75,   30,  112, 1418,   44,   92, 5305,   20, 3220,
           49, 1134,  152,  191,   27,    4,   50,   41,   61,   14, 9349, 1936,
         5042,   28, 1685,    4,   90,   41,  385,  318, 1685,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1235,  533,   93,   82,    9,   23, 2005,    4,   77,   14,    6,
           28,  269,    4,  268,   95,   30, 1013,   20, 8768,   35, 8014,   49,
          330,   35,  592, 5608,    6,  280,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4086, 1398,   31, 4437,   20, 1294,    4, 4367,   88, 4367,    4,
           30, 5319,   15,    4,   16,  149,   60,   58, 1506,   85,  588,  224,
          317,  186,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   64, 1433,   40, 6545,   23,  157, 3650,  337, 7061,    9, 5023,
           22,  430,  741,   39, 5981,   16,  342,  152, 2545,    4,  136, 3829,
         4084,   75,  716,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,  145,   14, 4904,  129,  301,  786,  371, 6169,    6, 1669,
           16,  495, 2546,  272,  795,    5,  202, 2810,   75, 1724,    9, 1253,
         1280, 4904,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72,   51, 1576,   18,   43,  690,  880, 2023,   49, 6550,  815,
           98,    4,   16,   32, 6542,   22,   14, 2865,  426, 1159,  267,  541,
            4,   14,   36,   98, 1963,   59, 2552, 4450, 1205, 1125,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2712,  736,  397, 1071,    4,  217,  392,    5, 9421, 9441,    4,
         7214,  105,  460,  458,    4, 3608,    6,  372, 1154,  301,  195,   93,
           45, 3285,    6, 1147,    4,   58, 7241,  679, 1368, 6237,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1805,   45,  424,    6, 3824,  239,   61,  301,   37,  352,   22,
            9, 2499,   61,   23, 1083,  201, 2525,    4,   49,  628,  306,  263,
           52, 4277,   20, 2176, 1567,  195,   61, 2617,   16,  350,  119,  315,
         1177,   20,  986,  157, 1240,   20, 1808,  380,   83,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[  13, 1232, 4529,  188, 4504,   48,  206, 1136, 3349,  233,  187,  271,
           26,   13,  415,   45,  626,   48,  429,    8, 6607,   26,   39, 2735,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   8,   70,   11,    6,  324,   80,   33,    4,   19,  154,    4,   26,
           17,   21,   11,    6,  100,   13,  765,    9,  183,    4,  100,   25,
           11,  121, 1932,  336,    4,   25,   11,  121,  278, 3089,   35, 3304,
         2805,    8,   25,   11,  121, 1828,   13, 1153,   71,    7, 3089,   35,
         3304, 2421,    5,    2],
        [  21,   11,    6,  434,   13,  927,  603,    6,   12,    7,   21,  128,
          589,   13,   48,  709,   17,   19, 6147,   62,  106,  284, 2433,    4,
           38,  597,   33,   51,  830,   57,  290,  650,  137,    8,   21,   11,
            6,   13, 3537,   45,   54, 1157,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  84,   26,   91,  143, 3486,    5,   70, 1148,  115,   42,    7, 5573,
           12,    7, 7495,    6,  115, 3265,   10,  339,    7, 2745,  205,   55,
           13, 6436, 4808,  445,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  29,  251,  248,  214, 4812,   48, 3463,   17,   13,  341,  321,   12,
         1298, 1639,  772,    9,  117,  321,   12, 4468,    6,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  84,   63, 6165,    6, 3266,    4, 6165,    6,    9,    7, 4006,    4,
           21,   11,    6,    7, 1226, 1187,   12,    7, 9744,    4,  185,   12,
            7, 4515,    6,  492,  204,  842,   10, 1580,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  29,   70,   24,   11,   57,  401,   26, 5413,  108, 9792,  199,   46,
           25,  914, 2574,   62,   21,   46, 1944, 6820,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   8,   24,  278,   10,   87,    7, 8342, 1435,   46,    8,    7, 8342,
         1109,    6,   55,  596,   11,    6,   19, 1199,   45,  407, 9414,  417,
         6127,  271,   46,    8,   19,   66, 4879,   62,   33, 1435,   55,    7,
          473,  798,  215,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 103,   25,  154,   80,   33,    4,    7, 5787, 5204,   12,   14,  945,
           26,   17,   25,   11,   57,  143, 2676,   10, 4624, 4172,    9,    7,
          535, 1202,  254,   10, 3121,   21,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  19,  154,  138, 2383,   34,  529,   10,   87,   77,   12,   33,  125,
          101,  144,    7, 4454, 6382,  567,   12,  417,   35, 7772,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [1275,   19,  144,   10, 2456,   55, 1113,    4, 1551,    8, 1551,    4,
          116, 3200,   54,   71,    7, 1848,  224,  116,  378,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   8,   80,   13, 6897,   12,   77,    7,   94,    9, 7744,  741,   14,
           48,   17, 6852,  106, 7491,    8, 3401,    4,   67, 2684, 1008,    6,
           17,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  19,   73, 8191,   21,    6, 3140,  100,   33,    4,    8, 2546,  436,
            4,    8,   21, 1363,  111,  954,    6,    9,   33,  264, 3140,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  19, 1742,  134, 3742, 7141,  106, 3539,  391,    4,    8,   24, 2955,
          346,    7, 4512,  373,   17,  220,  229,   21,  346,  850,  159,  447,
          768,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  91, 2960,  215, 1065,    4, 1456,    4,  204,    4, 9472,  392,    4,
         9441,    4,   33, 3537,   45,   54, 6207,    4, 2345,    6,  372, 1154,
          227,  195,   93,   45, 3285,    6, 1147,    4, 1704,    7,  211, 1368,
         5334,   55, 7308,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [1492,   45,  424,   11,    6, 3236,  188,  226, 9483,   69, 3860, 1118,
            9, 1075,  336,    7,  179,    4,  294,   71,  172,   85,  292,  140,
         1563, 2839, 1797,    6,    8,  422,  230,    6, 1051,  416, 1428,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:5'), 'cluster_tokens': tensor([[37,  9, 35, 85, 29, 31, 37, 28,  9, 35, 35, 44, 85, 37, 38, 35, 35, 31,
         94, 37, 94, 85, 38, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 85, 37,  2, 37, 37, 11, 38, 59, 11, 85, 37, 37, 85, 37, 37, 37,
         24, 37, 24, 11, 37, 37, 85, 35, 40, 37, 11, 37, 85, 35, 31, 38, 38, 35,
         94, 37, 37, 85, 35, 31, 37, 32, 37, 37, 38, 38, 35, 94, 11, 83],
        [37, 85, 37, 31, 37, 35, 35, 37, 37, 37, 37, 35, 35, 37, 31, 35, 37, 38,
         29, 31, 37, 37, 37, 11, 38, 35, 37, 38, 62, 77, 35, 35, 11, 37, 37, 85,
         37, 37, 38, 35, 49, 88, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 50, 50, 94, 11, 50, 85, 83, 11, 37, 94, 37, 37, 28, 37, 83, 88,
         37, 49, 37,  9, 85, 37, 37, 94, 29, 35, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 50, 34, 56, 36, 31, 31, 37, 37, 33, 38, 37, 94, 31, 75, 37, 37, 38,
         37,  9, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 32, 37, 50, 11, 32, 37, 37, 37, 32, 11, 37, 85, 37, 37,  2, 32,
         37, 37,  9, 11, 50, 37, 37, 22, 37, 50, 83, 31, 37,  9, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 50, 38, 85, 77, 49, 85, 40, 37, 56, 37, 11, 37, 83, 88, 31, 37, 11,
         49, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 85, 37,  2, 59, 11, 37, 37,  2, 53, 37, 37, 56, 85, 37,
         38, 77, 35, 35, 32, 38, 33, 44, 11, 37, 38, 85,  9, 31, 37, 59, 37, 37,
         37, 34, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 59, 37, 37, 11, 37, 83, 32, 37, 38, 77, 85, 37, 37, 85, 77, 50,
         83, 37, 49, 23, 37, 37, 83, 49, 37, 37, 29, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 59, 37, 35, 85,  6, 37, 85, 50, 37, 37, 37, 38, 85, 37, 83, 32, 32,
         37, 38, 38, 35, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 85, 37, 38, 37, 24, 11, 24, 37, 24, 11, 83, 49, 49, 37, 37, 56,
         11, 83, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37,  9, 37, 50, 37, 56, 37,  9, 35, 38, 31, 37,  9, 37,  9, 37,
          2, 11, 37, 50, 59, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38,  6, 29, 37, 37, 94, 37, 37, 11, 37, 38, 77, 11, 37, 37,  2, 83, 49,
         37, 37, 37,  2, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 31, 37, 12, 32, 37,  9, 34, 11, 37, 38, 31, 37, 37, 76, 56, 37,  6,
         49, 37, 37, 37, 37, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 34, 24, 24, 11, 83, 11, 83, 11, 24, 17, 11, 25, 11, 37, 38, 35, 49,
         94, 11, 38, 37, 35, 35, 38, 35, 35, 35, 35, 37, 35, 11, 31, 37, 50, 77,
         32, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 35, 85, 37, 94, 85, 85, 31, 37, 49, 56, 37, 56, 37, 37, 94, 11,
         50, 37, 83, 37, 35, 35,  2, 29, 23, 37, 37, 28, 37, 37, 38, 35, 44, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:5'), 'lengths': tensor([26, 52, 44, 30, 23, 34, 22, 41, 32, 25, 23, 27, 25, 27, 41, 37],
       device='cuda:5'), 'ntokens': 509}, 'target': tensor([[ 312, 2368,   27, 6539,    4,   61,  102,   14, 4236,  202, 2378, 1966,
         1597,   52, 2785,   20,   27,    4,   16, 7451,   52, 8769,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64,   34,  716,  414,   27,    4,  638,   31,    4,   27,    4,   50,
           36,   74,   40, 1003,   27,    4,   90,  403,   41,   75,   88,  247,
         7110,   16, 2578,  118, 8738, 2664, 1602,    4,   16,   90,  403,   43,
           30,  773,   60,  141, 8738,   35,  806,  727,   20,  371, 5138, 1602,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  99, 7847,    4, 5235,   48,  253,   21,  128,  634,  515,  867, 2471,
         3481,    4,   30,   31,   98,  405,   45,  441, 3481,  577, 5723,  209,
            4,   38,  992,  181,  349,  803,    6,  285,  349,   57,  290,  650,
          197, 6450, 4818,   30,  350, 1879,   27,  197,  834,  312,  167, 3537,
          684, 1485,  531,    6, 3326,  122,   22, 2628,   22,    5,    2],
        [  99,  178,   52, 1600, 3177,    5,  327,  730,  547,   42,  146, 7019,
           23, 3309, 2344,   58, 1676,  547,  253, 1972,  219,  527,   37, 2479,
          537,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 938,   45, 3264,  398, 4944,  105, 1786, 5420,   15,   52,  331,  353,
           49, 1351,    4,   14,    9,  212,  353,   49,  301,  152, 1374,  217,
         1776,   32,  622,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1077, 1021,  605,   75, 2692,    4, 2692,   97, 6302,    4,   23, 5961,
         4426,  129,  869,  777,   18,  152,   22,    6,    4, 3154, 5219,   20,
           76, 2936,    9, 4184,  184,    6,  412,  544,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2235,  308,  322, 2856,   15,  127,  113,   28,   46,   41,   13,  176,
          549,   36,   46, 2810,   15, 1389,   15,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104, 1908,   15,   14,  674,  992,  360,  920,   35,  360, 1079, 3245,
          223,   46,  674,  992,  360,  920, 1634,   78, 2888,  174,  784,    6,
           35,  992,  243,  152,   45,  390,   35, 9542,    9,  330, 6127, 1347,
           46,   16,   31,   82,    9,   58,  808,  798,  332,   14,  441, 3957,
         1089,  212, 2727,    5,    2,    1,    1,    1,    1,    1,    1],
        [ 222,   41,   75,   30,  112, 1418,   44,   92, 5305,   20, 3220,   49,
         1134,  152,  191,   27,    4,   50,   41,   61,   14, 9349, 1936, 5042,
           28, 1685,    4,   90,   41,  385,  318, 1685,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1235,  533,   93,   82,    9,   23, 2005,    4,   77,   14,    6,   28,
          269,    4,  268,   95,   30, 1013,   20, 8768,   35, 8014,   49,  330,
           35,  592, 5608,    6,  280,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [4086, 1398,   31, 4437,   20, 1294,    4, 4367,   88, 4367,    4,   30,
         5319,   15,    4,   16,  149,   60,   58, 1506,   85,  588,  224,  317,
          186,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  64, 1433,   40, 6545,   23,  157, 3650,  337, 7061,    9, 5023,   22,
          430,  741,   39, 5981,   16,  342,  152, 2545,    4,  136, 3829, 4084,
           75,  716,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,  145,   14, 4904,  129,  301,  786,  371, 6169,    6, 1669,   16,
          495, 2546,  272,  795,    5,  202, 2810,   75, 1724,    9, 1253, 1280,
         4904,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72,   51, 1576,   18,   43,  690,  880, 2023,   49, 6550,  815,   98,
            4,   16,   32, 6542,   22,   14, 2865,  426, 1159,  267,  541,    4,
           14,   36,   98, 1963,   59, 2552, 4450, 1205, 1125,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2712,  736,  397, 1071,    4,  217,  392,    5, 9421, 9441,    4, 7214,
          105,  460,  458,    4, 3608,    6,  372, 1154,  301,  195,   93,   45,
         3285,    6, 1147,    4,   58, 7241,  679, 1368, 6237,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1805,   45,  424,    6, 3824,  239,   61,  301,   37,  352,   22,    9,
         2499,   61,   23, 1083,  201, 2525,    4,   49,  628,  306,  263,   52,
         4277,   20, 2176, 1567,  195,   61, 2617,   16,  350,  119,  315, 1177,
           20,  986,  157, 1240,   20, 1808,  380,   83,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'target_lengths': tensor([24, 50, 59, 27, 29, 34, 21, 53, 34, 31, 27, 28, 27, 35, 35, 46],
       device='cuda:5'), 'ntokens': 560, 'nsentences': 16}
##################### {'id': tensor([ 75331,  90133,  39737, 211982,  59495, 184095,  81439, 110336,  67876,
        128431, 212870, 114435, 130887, 184094, 191281,   8776,  30835,  19745,
        184929,  29350, 222400, 110485,  63060, 106270, 141645, 128523, 104295,
        159654, 192542, 190457, 119766, 184789], device='cuda:4'), 'net_input': {'src_tokens': tensor([[-1.5259e-03,  9.1553e-05,  1.4343e-03,  ...,  2.1362e-03,
          6.1035e-04, -4.5776e-04],
        [-1.1902e-03, -1.1902e-03, -1.1597e-03,  ..., -1.5869e-03,
         -1.9531e-03, -2.1057e-03],
        [ 4.1504e-03,  1.0559e-02,  2.7466e-04,  ...,  7.9590e-02,
          2.5513e-02, -3.6743e-02],
        ...,
        [-1.1475e-02, -1.9165e-02, -1.9989e-02,  ...,  1.2512e-03,
         -3.2654e-03,  0.0000e+00],
        [-5.6152e-03, -5.9509e-03, -4.7607e-03,  ..., -1.4282e-02,
         -1.0315e-02,  0.0000e+00],
        [ 2.9602e-03,  2.7771e-03,  2.4719e-03,  ..., -9.3079e-03,
         -7.2327e-03,  0.0000e+00]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200,
        75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200, 75200,
        75200, 75200, 75200, 75200, 75200, 75199, 75199, 75199, 75199, 75199,
        75199, 75199], device='cuda:4'), 'prev_output_tokens': tensor([[   2, 8250,  145,  ...,    1,    1,    1],
        [   2,   64,  105,  ...,    1,    1,    1],
        [   2,   64,  114,  ...,    1,    1,    1],
        ...,
        [   2, 1186, 2886,  ...,    1,    1,    1],
        [   2,  579, 4662,  ...,    1,    1,    1],
        [   2,   72,  209,  ...,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[   8,  180,   25,  ..., 4041,    5,    2],
        [   8,  117, 3529,  ...,    1,    1,    1],
        [ 115,    4,  120,  ...,    1,    1,    1],
        ...,
        [  25, 2115,   62,  ...,    1,    1,    1],
        [  29,   55,  663,  ...,    1,    1,    1],
        [ 125,   19,   87,  ...,    1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[37, 37, 37,  ..., 35, 11, 83],
        [37, 37, 56,  ..., 37, 37, 37],
        [83, 11, 37,  ..., 37, 37, 37],
        ...,
        [37, 49, 31,  ..., 37, 37, 37],
        [83, 37, 32,  ..., 37, 37, 37],
        [37, 38, 85,  ..., 37, 37, 37]], device='cuda:4'), 'lengths': tensor([35, 25, 16, 30, 25, 22, 16, 22, 20, 31, 21, 25, 24, 18, 21, 34, 17, 28,
        27, 21, 21, 19, 21, 25, 21, 16, 30, 28, 23, 30, 29, 18],
       device='cuda:4'), 'ntokens': 759}, 'target': tensor([[8250,  145,   36,  ...,    1,    1,    1],
        [  64,  105, 3415,  ...,    1,    1,    1],
        [  64,  114,   30,  ...,    1,    1,    1],
        ...,
        [1186, 2886,   58,  ...,    1,    1,    1],
        [ 579, 4662,    4,  ...,    1,    1,    1],
        [  72,  209, 3664,  ...,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([15, 22, 18, 29, 27, 19, 21, 15, 21, 30, 23, 25, 19, 21, 17, 33, 26, 22,
        27, 22, 21, 23, 21, 29, 22, 15, 45, 23, 23, 29, 26, 14],
       device='cuda:4'), 'ntokens': 743, 'nsentences': 32}
##################### {'id': tensor([ 18053,  47205, 105850,  37507,  10001, 199193,  20285, 193025],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 0.0043,  0.0063,  0.0067,  ..., -0.0168, -0.0162, -0.0146],
        [ 0.0005,  0.0005,  0.0006,  ..., -0.0045, -0.0058, -0.0035],
        [-0.0008, -0.0002, -0.0003,  ..., -0.0006, -0.0013, -0.0019],
        ...,
        [ 0.0056,  0.0057,  0.0047,  ..., -0.0015, -0.0006,  0.0002],
        [-0.1301, -0.1381, -0.1292,  ...,  0.0472,  0.0406,  0.0248],
        [-0.0125, -0.0129, -0.0133,  ...,  0.0005,  0.0002,  0.0000]],
       device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([258240, 258240, 258240, 258240, 258240, 258240, 258240, 258239],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2, 1545,  642, 3145,   31,  252,   30, 1734,  773,    4,   30,   31,
         1651,  584, 1204,    4,   16, 2274,   41,    4,  114,   41,  112,  512,
         2330,    9, 1437, 2934,    4,  534, 2934,    4,   74,   41, 1087,   61,
          337, 5546,   15,  990,  123,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  912,   58, 5065,  255,  903,  904,    6,   15,   16,  771, 2300,
          145,   31,  466, 2843,   48,  334,    4,   50,  104,  127, 1925,   37,
            4,  114,   32,  273,  259,   16,  654,  757, 1657, 5355,  654, 8770,
          182,  308,  387,  969,   18,  797, 1182,   28,   51, 4406,  444,    5,
         1114,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  526,    4,  795,   41,  163,  190, 1481,  193,  124,  795,   41,
          163,   14,  645,   39,   41,   56, 2563,    4,  268,   41, 1846,  173,
         3355,   44,  400, 3582,   36,   75,   39,  193, 2294, 1036,  193,   74,
         3582,   36,   75,   39,    4,   75,   28, 5333,   22,   42, 1356,  951,
           37,  418,    5, 8875, 4254,    5, 2209,  160,  418,    5, 2139,    4,
         4036,    4,  414,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,   64,  114,   31,   36,  459, 2097,   20,    4,  127,   41,  217,
          844,  604,    4,  566,    4,   32,  123,   58, 3372, 1378,  260,    4,
           50,  374,    4,   34,  728, 3997,  174,  297, 4555,    4,  374,    4,
           34,  728,   78,   58,  350, 2133,  676,  239,    4, 1653,   61,   23,
          201, 6300,   27,    4,   23, 3235,   83,  449,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  104,   76,   97,  989,   20,    4,  361, 1615,   28, 1376,    4,
           14,  669, 1083, 3114,  363, 3821,    4,   14,  275,   49, 1474,  599,
          203, 1255,  140, 1194,    4,   14,  275, 1097,   45, 1865,   18,  457,
           59,   76,   90, 5011, 9077,    4,   14, 2040, 2586, 2024, 3694,    4,
           16,    5,    5,    5, 6987, 1036,  139,  892, 5998,    5, 5456,   20,
         1271,  152, 1902,    5, 5614, 5819,  680,  399, 4399, 2411, 6653,  318,
          856,  477,    4,  113,  557,   31,   47, 3178,  897,   40,  983,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 1033, 4227,   20,  231, 2186,   75,   97,  698, 3093,   61,    4,
          268,   28,  306,  911, 2868,   15,   98, 5457,  124,   14,  757, 5497,
           22,   23, 3198,  171, 2280,  380,    4,  124,   14, 4194,  318, 8350,
           18,  127,    4,  124,   43, 2437,   16, 3829, 3520,  217, 4066,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,   92, 3809,  580,   51,  587,  181,   14, 4413,    4,   16,  196,
          539,  627,    4,   88,   36, 1489,   28,  260,    4,   31, 3853,  118,
         2612,   60,  112, 2697, 1826,    9,  485, 1741,  223,    4,   16, 2069,
           43,   60, 2065,   49,  682,    5, 1581,  828, 1813, 3959,   35, 7321,
           15, 1419,  317,  182,  669, 2269,   15,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 1477,  949,   44,  504,   27,   40, 1494,   49,  198,    4,   40,
          580,  493, 8116,   38,  899,   59, 3488, 1190,  234,    6,   20,  197,
          112,   58,  202,  381, 7282,   44,   68, 4398,   65,  376, 7841,   20,
          734,   82,  789,   30,  308, 2490, 3668,    9, 1092,  371, 2862, 1184,
           61,   56, 4142,  532, 1788,    6,  202,  195,  560, 3528,  122, 1451,
          221,  195,  880,   37,   48,  160,  511,  217, 6202,    5,  957,    5,
          820, 1132,  820,  887,  223,   58,  853,    6,   22,  625,   35,  987,
         3352,  515, 3767, 1694, 1805,  586,  338,  614, 5023,   22,  140,  763,
            5]], device='cuda:4')}, 'transcript': {'tokens': tensor([[  33,  183,  939,  187,   11,  158,  834,  508,   25,    7, 1711, 1153,
           17,   19, 1095,    9, 1651,  584,    4,    8,  884,   25,   17,  120,
           25,  154,   80,   70,  155, 2883,   73,   51,    9, 1146,    4,  154,
           80,  155, 3046,    9, 2047,   12,  875,   54,  688,   10,   33, 4959,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,  180,   55,    7, 4995,    6,    4,   55, 1459,  994,    9,    7,
         1956,    4,  339,  110, 1948, 3720,   45,  293, 1115,   21,  131, 1211,
            4, 6231,    4,   70,   24,   46,   70,  164,  229,  170, 1767,    4,
           26, 5275,  108,  183,    8,  108,  839, 2693,  340,  181,   93,   54,
            7, 4854,   55, 8067,  429,    5,  476,   25,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,  339,  110,  884,   25, 1816,  250,   46,  109,  204,    4,  339,
          110,  884,   25, 1816,  250,    4,  125,   25,   11,   57,  230,  168,
           44,  138,  568,   21,  598,   46, 2294,  111,   46,  138,  568,   21,
          598,   10,   51, 1226,   42,  903,   20,  556, 1256,    5, 8120,    6,
          346,    5, 1290,  712,  371,    6,    6,   54,    5, 1189,    4, 1968,
            4,  453,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,  103,   19,   11,   45, 3150,    4,  180,   25,   11,  158,  204,
          367,  755,  826,    4, 1768,    4,   24,  220,  204, 3128,    7,  453,
         2805,   12,  778,  700, 4794,    4,  778,   17,   34,  700, 3463,   55,
         6484,    4, 2875,   10, 2881,    9,    7,  179,   17,   11,    6,  700,
          692,   10,   66, 2214,   10,   21,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  24,   11,   57,  529,   10,  115,  991, 3632,   17, 4489,   77,  159,
          447, 3867,    4,   17, 8549,  261,   12,  159,  563,    4,   17,   63,
          261,  143, 6128,  254, 3057, 3632,    4,  368,   77,   35,   22, 2124,
          128,  688,    4, 3694,    5,    4,    8,    4,  244,  183,    4, 1729,
          908,    5, 1849, 5124,    6,    5, 3515, 5829, 4014, 4399, 6686,   17,
          473, 1303,    4,   29,   19, 1704,   11,   18, 1088, 1367,   69,   17,
          593,  261,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1120,   77, 3357,   12,   33,  321, 2322, 4474, 1241,   13, 4430,  125,
          593,  294,   94, 3424,  126,   12,    7, 1435,    4,  109, 2872,   54,
           55,    7, 1221,  903,  693,  132,    4,  109,    7, 5873,  175, 8396,
           62,    4,  109,   53,   14,    4,    8, 2684,  954,    6,    7, 3158,
         3143,  346,    7, 1726,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   7, 1575, 1472,   34,   69, 4244,    4,    8,  554,    4,   10,  388,
           21,  133, 6160,  111,    4,   19, 5823,   62,   13, 1108,  244, 2697,
          708, 2551, 1004,   77,  244, 1662,    4,    8, 1060,  134,   46,   19,
         1742,  134,   80, 1581,  828,  341, 4244,   35,  240,  634, 1011, 1532,
            8, 1948, 1060,  134,  159, 5669,    6,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [2266,  122,   44,  109,  168,   11,    6,   13, 1228,   17,   19,  442,
           79,  461,   12,   89,  575,   38, 2286, 3488,  538,  438,  952,   80,
          179,   82,   19,   44,   68, 4077,   65,    7, 8781, 3420,   34,   12,
          538,    7,   79,    6,  484,    6,  160,  271,    9, 3153,  371, 2862,
         1184,   12,    7,   98, 1015,  221, 3920, 1050,  636, 4083,   22,  195,
          664,   37,   48,  160,  511,    4,   69, 1546,  375, 6202,    4,  564,
          820,  887,    4,  131,   13,  853,    6,   22,  589,   35,    6,   37,
          174, 1553,  365, 3335, 1492,  586,  338,  614, 3035,  160,  140,  763,
            5,    2]], device='cuda:4'), 'cluster_tokens': tensor([[37, 24, 38, 35, 85, 35, 11, 88, 37, 37, 50, 32, 37, 38, 59, 37, 34, 73,
         11, 37, 88, 37, 37, 37, 37, 59, 37, 50, 37, 94,  6, 38, 37, 28, 11, 59,
         37, 37, 94, 37, 32, 37, 49, 49,  9, 37, 37,  9, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 37,  9, 37, 11, 37, 50, 50, 37, 37, 32, 11, 49, 37, 83, 38,
         35, 35, 37, 37, 37, 88, 11, 83, 11, 50, 38, 11, 50, 85, 49, 37,  2, 11,
         85, 49, 37, 24, 37, 37, 32, 31, 35, 35, 35, 49, 37, 32, 37,  2, 94, 11,
         83, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 49, 37, 88, 37, 56, 50, 11, 37, 83, 11, 49, 37, 88, 37, 56, 50, 11,
         37, 37, 85, 77, 37, 37, 82, 37, 85, 37, 59, 11,  2, 83, 11, 37, 85, 37,
         59, 37, 38,  2, 11, 38, 77, 35,  2, 11,  9, 37, 37, 11, 38, 35, 35, 37,
         37, 49, 11, 83, 11,  2, 11,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 38, 85, 35,  2, 11, 37, 37, 85, 35, 83, 85, 37, 59, 11, 83, 11,
         38,  6, 83, 49, 37,  2, 94, 37, 50, 50, 31, 11, 50, 37, 85, 50, 31, 37,
         94, 11, 31, 37, 50, 37, 37, 94, 37, 85, 37, 50, 85, 37, 85, 49, 37, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 77,  6, 37, 83, 49, 56, 37, 49, 50, 37, 37,  9, 11, 37, 29, 83,
         37, 37,  9, 11, 37, 85, 83, 50,  2, 37, 23, 56, 11, 49, 50, 38, 35, 35,
         35,  9, 11, 83, 11, 11, 37, 11, 37, 24, 11, 56, 50, 11,  2,  9, 37, 11,
         32, 28, 35,  2, 31, 37, 37, 24, 11, 83, 38, 31, 85, 35, 38, 35, 37, 37,
         83, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [83, 50, 56, 37, 37, 38, 29, 33, 37, 37, 24, 37, 83, 50, 56, 29, 37, 37,
         37, 59, 11, 37, 32, 49, 37, 37, 94, 38, 56, 37, 11, 37, 37, 56, 85, 33,
         31, 11, 37, 37, 38, 11, 37, 50, 49, 37, 37,  9, 83, 37, 37, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 28, 32, 85, 37, 56, 11, 37, 83, 11, 37, 31, 37, 83, 83, 83, 11, 38,
         49, 31, 37, 32, 37, 34, 56, 29, 37, 50, 37, 28, 11, 37, 31, 37, 11, 38,
         31, 37, 37, 17, 73, 33, 56, 38, 35, 77, 31, 56, 37, 83, 31, 37, 37, 32,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 35, 82, 37, 37, 85, 37, 37, 32, 37, 38, 31, 37, 32, 37, 37, 88, 38,
         35, 35, 83, 82, 16, 37, 94, 53, 38, 82, 38, 24, 11, 37,  2, 32, 85, 37,
         83, 37, 37, 37, 35, 37, 35, 44, 37, 38, 35, 35, 35, 37, 37, 38, 35, 35,
         38, 35, 77, 38, 35, 35, 38, 77, 31, 35, 35, 11, 37, 38, 77, 34, 11, 34,
         73, 73, 11, 37, 37, 38, 37, 35, 35, 38, 37, 77, 35, 13, 35, 31, 38, 35,
         35, 35, 38, 35, 35, 35, 11, 83]], device='cuda:4'), 'lengths': tensor([50, 58, 64, 56, 76, 54, 57, 98], device='cuda:4'), 'ntokens': 513}, 'target': tensor([[1545,  642, 3145,   31,  252,   30, 1734,  773,    4,   30,   31, 1651,
          584, 1204,    4,   16, 2274,   41,    4,  114,   41,  112,  512, 2330,
            9, 1437, 2934,    4,  534, 2934,    4,   74,   41, 1087,   61,  337,
         5546,   15,  990,  123,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 912,   58, 5065,  255,  903,  904,    6,   15,   16,  771, 2300,  145,
           31,  466, 2843,   48,  334,    4,   50,  104,  127, 1925,   37,    4,
          114,   32,  273,  259,   16,  654,  757, 1657, 5355,  654, 8770,  182,
          308,  387,  969,   18,  797, 1182,   28,   51, 4406,  444,    5, 1114,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 526,    4,  795,   41,  163,  190, 1481,  193,  124,  795,   41,  163,
           14,  645,   39,   41,   56, 2563,    4,  268,   41, 1846,  173, 3355,
           44,  400, 3582,   36,   75,   39,  193, 2294, 1036,  193,   74, 3582,
           36,   75,   39,    4,   75,   28, 5333,   22,   42, 1356,  951,   37,
          418,    5, 8875, 4254,    5, 2209,  160,  418,    5, 2139,    4, 4036,
            4,  414,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  64,  114,   31,   36,  459, 2097,   20,    4,  127,   41,  217,  844,
          604,    4,  566,    4,   32,  123,   58, 3372, 1378,  260,    4,   50,
          374,    4,   34,  728, 3997,  174,  297, 4555,    4,  374,    4,   34,
          728,   78,   58,  350, 2133,  676,  239,    4, 1653,   61,   23,  201,
         6300,   27,    4,   23, 3235,   83,  449,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 104,   76,   97,  989,   20,    4,  361, 1615,   28, 1376,    4,   14,
          669, 1083, 3114,  363, 3821,    4,   14,  275,   49, 1474,  599,  203,
         1255,  140, 1194,    4,   14,  275, 1097,   45, 1865,   18,  457,   59,
           76,   90, 5011, 9077,    4,   14, 2040, 2586, 2024, 3694,    4,   16,
            5,    5,    5, 6987, 1036,  139,  892, 5998,    5, 5456,   20, 1271,
          152, 1902,    5, 5614, 5819,  680,  399, 4399, 2411, 6653,  318,  856,
          477,    4,  113,  557,   31,   47, 3178,  897,   40,  983,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [1033, 4227,   20,  231, 2186,   75,   97,  698, 3093,   61,    4,  268,
           28,  306,  911, 2868,   15,   98, 5457,  124,   14,  757, 5497,   22,
           23, 3198,  171, 2280,  380,    4,  124,   14, 4194,  318, 8350,   18,
          127,    4,  124,   43, 2437,   16, 3829, 3520,  217, 4066,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  92, 3809,  580,   51,  587,  181,   14, 4413,    4,   16,  196,  539,
          627,    4,   88,   36, 1489,   28,  260,    4,   31, 3853,  118, 2612,
           60,  112, 2697, 1826,    9,  485, 1741,  223,    4,   16, 2069,   43,
           60, 2065,   49,  682,    5, 1581,  828, 1813, 3959,   35, 7321,   15,
         1419,  317,  182,  669, 2269,   15,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [1477,  949,   44,  504,   27,   40, 1494,   49,  198,    4,   40,  580,
          493, 8116,   38,  899,   59, 3488, 1190,  234,    6,   20,  197,  112,
           58,  202,  381, 7282,   44,   68, 4398,   65,  376, 7841,   20,  734,
           82,  789,   30,  308, 2490, 3668,    9, 1092,  371, 2862, 1184,   61,
           56, 4142,  532, 1788,    6,  202,  195,  560, 3528,  122, 1451,  221,
          195,  880,   37,   48,  160,  511,  217, 6202,    5,  957,    5,  820,
         1132,  820,  887,  223,   58,  853,    6,   22,  625,   35,  987, 3352,
          515, 3767, 1694, 1805,  586,  338,  614, 5023,   22,  140,  763,    5,
            2]], device='cuda:4'), 'target_lengths': tensor([42, 50, 64, 57, 84, 48, 56, 97], device='cuda:4'), 'ntokens': 498, 'nsentences': 8}
##################### {'id': tensor([170579, 212432,  47725,  64276, 222941, 109985, 115627, 207072],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 4.5776e-04,  2.1362e-04,  1.5564e-03,  ...,  7.7759e-02,
          5.9387e-02,  3.6835e-02],
        [-8.2397e-04, -9.1553e-05,  5.1880e-04,  ..., -1.5564e-03,
         -6.1035e-04, -9.1553e-05],
        [-1.2115e-02, -1.0345e-02, -4.8828e-04,  ..., -3.3569e-04,
          5.7983e-04,  3.6621e-04],
        ...,
        [-2.1973e-03, -5.3711e-03,  6.1035e-05,  ...,  2.5635e-03,
          4.0894e-03,  5.0659e-03],
        [ 2.1362e-04,  2.7466e-04,  9.7656e-04,  ...,  6.7139e-04,
          2.6550e-03,  3.1433e-03],
        [-1.5869e-03, -5.1880e-04,  2.0752e-03,  ..., -4.4861e-03,
         -2.3193e-03,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([159200, 159200, 159200, 159200, 159200, 159200, 159200, 159199],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2, 5704,  101,  739,   41,  512, 1131,    4,  114,  252,   61,   23,
          550,  139,  433, 1121,  239,    4,   50,   41,   28,   13,  122,   57,
            6,    6,  673,   76,    5,   68,  348,   65,   99,  178,   36,   40,
          542,    4,  682,    5, 1185,  950,    5,    1,    1,    1,    1,    1,
            1,    1],
        [   2,   72,  209,   61,  102,  758,  470,    6, 2418,    4, 7977,   31,
          252, 3709, 1306,  449,    4,  268,   31,  705,    4,   50,   32,   14,
         4816, 3037, 2276,  704,   16, 5516,  260,  123,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   2,  222,   81,  472, 3312,  505,  707,   96,  781,  443,  122, 3027,
            6,  130,    4,  178,   36,  798, 3033,   15,    4,   64, 2408,   20,
          437,  626,  651,   36,   29,    4, 4331,  304, 3007,  651,   36, 1229,
           16,  671,  477, 1035,    4,   29,   27,   36,   60,  328, 1735,    4,
         2675,    5],
        [   2,   92, 4035,   47,  149, 2898,    4,  405, 9213,   49,  972,   98,
         7320,   28, 6275,    5,  222,   43,  136,  482,  182, 3502, 2398,   59,
         2241, 7505,    4, 1626,   43,  216,   16,  216,  157,  334,    4,   50,
           43,   75,  924,   47,  253, 9160,   22, 4905, 6918,    5,    1,    1,
            1,    1],
        [   2,  222,  113, 6540,   45, 2435, 1194,   49, 9689,   22, 6549,    4,
          145,   30,   40, 2785,   22, 4642,   78, 4194,  186,    4, 6615,   28,
          667,    4, 2742,  102, 2766, 3287,   15, 1184,  907,   97, 4880, 3083,
         1837,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   2,  104, 1765,  585,  377, 2133,    6,  119,   59, 2388,    4,   14,
         2379,    9,  686, 6517,   95,  243,  200,   54,  418,  260,   44,   56,
          315, 1707, 1526,  625,    4, 8273,   16, 7918,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   2, 7764,  615,   43,   16, 2625,    4,   34,   60,  198, 1633,   27,
           42, 1866,   27, 5630,   42, 6742,   23, 5314,  129, 1676,   16,   23,
           23, 3309,   97, 4338, 2664,   61,   14,  772, 4819,   20, 3503, 7943,
         2376,   40, 4073,   37, 9455,    5,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   2, 2467,  337, 9014,   22, 5094,  210,  151, 4052, 3482, 4175,  522,
           14, 4016,   35, 6624,  571,  587,  122,  491,   49, 5146,   22,   61,
         5182,   88,  743,  655,  950,    9,   58,  808, 1130,  332, 7429,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[2993, 3929,  155,  874,  103,   25,   11,  121,  226,  968,   25,   11,
           57,  593, 7176,   20,   85,  283,    5,   68,  194,   65,   84,   11,
            6,  735,   13,  555,    4,   21, 1202,    6,   80,  785,  439,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   19,   11,  121, 1385,   13,  555, 3974,    6, 1585,    7,  207,
           17,   19,  692,   10, 1452,   71,   25,    4,  125,   19,  154,   17,
          540,   24,   73,  229, 1793, 3226,  509,    8, 2183,   37,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 103,   25,   11,  121,  278,  203, 3312,  505, 1267,   96,  781,  443,
          122, 3027,    6,    4,   84,   63,  798, 8265,    6,    4,    8, 2464,
           20,  459,  626,  568,   21,   91,  207,    8,  164, 5164,  568,   21,
          486,  207,    4,    8, 3695,   12,  134,  283,    4,    8,   17,   11,
            6,    7,  207,   21,   26,   71,   33, 1455,    4, 1080,    5,    2],
        [  17,   86,  288,  601,    6, 2627,  876,  525, 1410,   21,    6,  203,
          297,  833,   69, 5071,   55,  941,    4,   67,  103,   25, 2115,   10,
         2193, 1146,  440,    4,   25,   11,  158, 1510,  143,    8,  143,   94,
         1211,   17,   53,  192,   11,   18,  172,  154,   12,  159, 2353,   79,
            7, 1403, 3156,    5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  29,  120, 4601, 1747,  727,    6,  498,   10, 4606,  106, 3943, 5834,
            6,    4,  159,  318,    6, 1068,   73, 3860,   79,   39, 8088,   51,
          158,   55, 2245,   10,  498, 6125, 2303,    4, 2414,   10,    7,   73,
         1020,    9,   13, 5428, 2483,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,   11,   57, 2892, 3993,  768,   18, 3056,    6,   17,   63,  142,
           10,  229, 2409, 3757,  457,    9,  333,  841,   12,    7, 1455,   46,
         1519, 1490,    4,  837,  111,    8, 3925,  111,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 120,   63,   53,  142,   10,  367,  131,    8, 1945,  214,   10,  110,
           42,  148,   11,    6,    9, 4092,   42,   84,   11,    6,   13,  475,
          838, 3196,   22,  140,  793,  629,    7, 2745,   11,    6, 5897,    8,
          108,  447, 5897,    6,   79, 7495,    6,   12,    7,  772, 2519, 1006,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  33,  909,  609,    6,  369, 2205,   10,   13, 1136,  958,  524,  188,
         1897,  131, 4712,  854, 3538, 2555, 2921,  106, 1276,    6,   10, 2610,
            9,    7,  473,  785,  215,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:7'), 'cluster_tokens': tensor([[83, 29, 37, 38, 37, 37, 85, 35, 85, 88, 37, 85, 77, 83,  2, 77, 37, 49,
         11, 38,  9, 11, 37, 85, 37, 83, 37, 50, 11, 37, 49, 37, 37, 34, 24, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 38, 85, 35, 31, 37, 50, 94, 37, 37, 37, 83, 37, 38, 85, 37, 88, 37,
         37, 11, 37, 38, 59, 37, 36, 38,  6, 49, 28, 94,  2, 37,  2, 77, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 37, 85, 35, 31, 38, 35, 35, 38, 77, 35, 35, 35, 90, 37, 11, 37, 85,
         34, 32, 37, 11, 37, 38, 77, 38, 35, 85, 37, 50, 83, 37, 85, 29, 85, 37,
         50, 83, 11, 37, 50, 37, 37, 49, 11, 37, 37, 85, 37, 37, 83, 37, 85, 37,
         37, 32, 11, 94, 11, 83],
        [37, 83, 83, 49, 37, 28, 38, 35, 35, 37, 37, 38, 35, 35, 37, 28, 37, 94,
         11, 37, 37, 37, 49, 37, 28, 28, 83, 11, 37, 85, 35, 59, 50, 37, 50, 56,
         88, 37, 37, 85, 85, 35, 83, 59, 37, 37, 23, 37, 37, 28, 28, 11, 83, 37,
         37, 37, 37, 37, 37, 37],
        [83, 37,  2, 38, 35, 37, 49, 37, 29, 37, 94,  9, 37, 11, 37, 38, 37, 35,
          6, 49, 37, 38,  9, 38, 35, 37, 56, 37, 49, 49, 94, 11,  4, 37, 37,  6,
         35, 37, 37, 28, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [38, 85, 77, 49, 94, 94, 35, 35, 37, 37, 85, 49, 37, 49, 56, 88,  2, 37,
         50, 32, 37, 37, 32, 11, 28, 83, 11, 28, 83, 37, 94, 83, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 85, 37, 49, 37, 85, 37, 37, 88, 56, 37, 37, 11, 50, 85, 37, 37, 29,
         11, 37, 85, 37, 37,  2, 33, 35, 35, 35, 35, 37, 37,  9, 85, 37, 94, 37,
         37, 37, 94, 37, 37, 28, 37, 37, 37, 75, 28, 94, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37],
        [37, 38, 35, 37, 44, 32, 37, 37, 28, 94, 32, 85, 31, 37, 83, 53, 28, 38,
         94, 37, 94, 37, 37,  9, 37, 37, 37, 34, 24, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37]], device='cuda:7'), 'lengths': tensor([37, 36, 60, 53, 43, 34, 50, 31], device='cuda:7'), 'ntokens': 344}, 'target': tensor([[5704,  101,  739,   41,  512, 1131,    4,  114,  252,   61,   23,  550,
          139,  433, 1121,  239,    4,   50,   41,   28,   13,  122,   57,    6,
            6,  673,   76,    5,   68,  348,   65,   99,  178,   36,   40,  542,
            4,  682,    5, 1185,  950,    5,    2,    1,    1,    1,    1,    1,
            1,    1],
        [  72,  209,   61,  102,  758,  470,    6, 2418,    4, 7977,   31,  252,
         3709, 1306,  449,    4,  268,   31,  705,    4,   50,   32,   14, 4816,
         3037, 2276,  704,   16, 5516,  260,  123,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 222,   81,  472, 3312,  505,  707,   96,  781,  443,  122, 3027,    6,
          130,    4,  178,   36,  798, 3033,   15,    4,   64, 2408,   20,  437,
          626,  651,   36,   29,    4, 4331,  304, 3007,  651,   36, 1229,   16,
          671,  477, 1035,    4,   29,   27,   36,   60,  328, 1735,    4, 2675,
            5,    2],
        [  92, 4035,   47,  149, 2898,    4,  405, 9213,   49,  972,   98, 7320,
           28, 6275,    5,  222,   43,  136,  482,  182, 3502, 2398,   59, 2241,
         7505,    4, 1626,   43,  216,   16,  216,  157,  334,    4,   50,   43,
           75,  924,   47,  253, 9160,   22, 4905, 6918,    5,    2,    1,    1,
            1,    1],
        [ 222,  113, 6540,   45, 2435, 1194,   49, 9689,   22, 6549,    4,  145,
           30,   40, 2785,   22, 4642,   78, 4194,  186,    4, 6615,   28,  667,
            4, 2742,  102, 2766, 3287,   15, 1184,  907,   97, 4880, 3083, 1837,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 104, 1765,  585,  377, 2133,    6,  119,   59, 2388,    4,   14, 2379,
            9,  686, 6517,   95,  243,  200,   54,  418,  260,   44,   56,  315,
         1707, 1526,  625,    4, 8273,   16, 7918,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [7764,  615,   43,   16, 2625,    4,   34,   60,  198, 1633,   27,   42,
         1866,   27, 5630,   42, 6742,   23, 5314,  129, 1676,   16,   23,   23,
         3309,   97, 4338, 2664,   61,   14,  772, 4819,   20, 3503, 7943, 2376,
           40, 4073,   37, 9455,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [2467,  337, 9014,   22, 5094,  210,  151, 4052, 3482, 4175,  522,   14,
         4016,   35, 6624,  571,  587,  122,  491,   49, 5146,   22,   61, 5182,
           88,  743,  655,  950,    9,   58,  808, 1130,  332, 7429,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:7'), 'target_lengths': tensor([43, 33, 50, 46, 38, 33, 42, 36], device='cuda:7'), 'ntokens': 321, 'nsentences': 8}
##################### {'id': tensor([105876, 118261, 212828, 142761, 156749, 156357, 215794,  70138],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-0.0004, -0.0011, -0.0011,  ...,  0.0029,  0.0028,  0.0021],
        [ 0.0028,  0.0039,  0.0024,  ...,  0.0093,  0.0103,  0.0091],
        [-0.0009, -0.0023, -0.0025,  ..., -0.0008, -0.0010, -0.0011],
        ...,
        [ 0.0011,  0.0010,  0.0006,  ...,  0.0039,  0.0010, -0.0015],
        [-0.0059, -0.0074, -0.0057,  ..., -0.0017,  0.0021,  0.0022],
        [ 0.0068, -0.0073,  0.0075,  ...,  0.0456,  0.0539,  0.0618]],
       device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([203840, 203840, 203840, 203840, 203840, 203840, 203840, 203840],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,   64,  306,   49,  107,  193,   16,   31, 6558,    4, 1554,  306,
           49,  107,    9,  328,  817,  193, 5067,  897,    4,    9,  631,   43,
          317, 1012, 6538,  312,    6,   37,   35, 2507,  219,  562,  127,    4,
         3897,  616, 2449, 1694,    4,  707,  352, 1040,  390,  352,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1419,   74,   44,   38, 1007,  293,   15,   41,  728, 3369,   20,
          344, 3881,   96,    4,   23,   14, 1270,  124,   40, 1549,  643,  459,
          556,   15,  503,  124,   83,  716, 2581, 2494,  358,   99,  695,  167,
           61,   14, 1963, 7188,  352, 5047,    9,   29,  141, 2258,   39,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   92, 4035,  139, 1676,   74,  330, 1898,   48,    4,   14,  105,
         8807,   20, 4134,  626, 5612,  894,    4,  385,   43,   47,  410,   58,
         4277,   15, 9768,   49, 3468,   22, 4832,    4,   14,  924, 1213,   47,
         1176,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1209,  844, 1984,  698, 3758,    9, 6726,    4,  836,   52, 7276,
          160,    4,   14,   75,   30,  751, 1196,  458,  532,   97, 7117,   47,
           28, 1735,  184, 8388,  280,    4,   16,   28,   23,   31, 1121,  280,
           44,   38, 5329,  395,   18, 1312, 9679,    4, 3041,  664,  152,  158,
          119,  316,  223,  137,    9,  406, 3363,    5,    1,    1,    1],
        [   2,   72, 3844,  299,   56, 9615,   47,   29,   74,   32,   56, 9616,
           56, 9615, 1451,  510,   48,  721,   56, 9616,    5, 1451,  510,  262,
           76,    9,   23, 4442, 1578,   35, 2097,  160,   15,  201, 2029, 1121,
         1213,   47,   30,  496,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2558, 1904,    4, 1513,   31,   82,    4,  113, 6613,   20,   31,
          198,   40,    4,   31, 1156, 1000, 2928,    6,    4,   31,  239,   51,
         6026,   18,    5,   64, 2211,  406, 1667,   58, 5324, 1984,  732,  385,
         6520,    4,    9,    6,   16,   98,  102, 3787,   28,  615,    4,  280,
           31,   52, 4315, 1145,    4,   14,  317, 2834, 4900,   82,    5],
        [   2,   72,   82,  647, 1145, 2813,   16,   52, 2335, 1541, 1993,  160,
         3103,    4,   97, 3826, 4688,  129, 3758, 6434,    4,   16,   14,  201,
         2891,    9,  437,   37,  739,    5, 1555, 2425,   41,   75,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  441, 2877,  332,  578,   95,  714,   61,   58,  437, 2037,  249,
         9255, 4009,    5,   68,  379,   65,   64,  361,   27,   36,   52,  796,
            5,   68,  379,   65,   99,   27, 2560,    5,   99,   27, 3614,    5,
          404, 4899,  470, 3626,  157,    4,  157,    4,   14,   14,  201,   60,
          485,  351, 1383,  208,    5,    1,    1,    1,    1,    1,    1]],
       device='cuda:5')}, 'transcript': {'tokens': tensor([[   8,   13,  325,   12,  170,   46,    8,   19, 7777,    4, 2603,   13,
          325,   12,  170,    9,   33,  964,   46, 1799,   71,  134,  131,  116,
         4015, 2636,  277,   13, 1613,    4, 2636,  369, 2120,    4,  244,   35,
         1040,  390, 1305,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1532,  100,   44,   38,  443,  121,   25,  700, 6853,   62,  109, 6757,
           48,    9,  419, 1529,   17,  659,   51,  384, 1015,  445,  128,   10,
            7, 1384, 1224,  109,   13, 5222, 4369,  358,    8,   25,  113,   66,
           10, 2807,    7, 1503,   12, 1066,   25,   11,   57,    9,  120,   25,
           11,   57,  401,   33,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   29,  113,   55, 2116,  100,  417, 1898,   48,   17,   63,  142,
          359,  117, 1122,    6,  901,    4, 1122,    6,  901, 1922,  626, 2071,
         1034,   93, 3058,    4,   55,  134,   86,   10, 5427,  359,  251, 1320,
           59,  729,   48, 1032,  926, 4608,   12,    7, 3058,  120,    7, 3058,
           63,    9,  409,   86,  276, 4867,  134,    5,    2,    1,    1,    1,
            1,    1],
        [  29,   85,    7,  467,   12,   89,  245,  464,   85, 6579,    4,   13,
         3173,  148,  144,   86, 2982,    9, 2092,    7, 1711,  987,  458,  532,
            4,  148,   19,  144,  246,    4,   38, 5034,    4,   25,   11,  121,
          278,  455, 6757,  109,  994,   25,   11,   57,  142,   10, 4214,  438,
          552,  199,   89, 2100,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  89, 7196,   55,   33, 2070,   12,  378,   71,   38, 4114,  100,  170,
          197,   26,   38,  119, 2315,   20,  687,  438,    8,   89,  613,   26,
           17,    9,  440,   11,    6, 1578,  111, 5950,   20,  179,    4, 5543,
            6,   63,  923, 7714,   86,    7,  613,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1459, 1425,  148,   19,   34,    4,   29,   19,  474,   19,   34,   13,
          976,  488, 1799,    4,    8,   19,   34, 2103,   62,    4,    8,  276,
         1445,   89, 3806, 2138,  281,   12,   89,  282,    9,    8,  126,   12,
         7053,    4,   19,  144,   39, 1248, 3181,  148,   34,  116, 2018,   37,
          430,  111, 5709,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  19,   34,   13,  264, 1276,    8,   13,  963, 8398,    9,    7, 3571,
           12, 6434,    8,    7,  179,   34,    9, 2769,   45, 1755,    6,    5,
          635,   25, 1008,    5,  333,  383,    4,   24, 1346,  384,  827,  119,
          829, 2508,    6,  106,    7,   82,    9, 5205,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [2877,  215,  581,  101,   11,   48,   66,  226, 3572,   18,   85,    7,
         1449,  636,   55,   17,    5,   68,  194,   65,    8,  115,   21,   11,
            6,   39,  479,    5,   68,  194,   65,   21,   11,    6,  453,    5,
           21,   11,    6, 4099,    5,   67,   25,   87, 2565,  185, 4099,   94,
            4,   94,  148,  274,   85,    7,  179,    9,   13, 3294,  341,  207,
            5,    2]], device='cuda:5'), 'cluster_tokens': tensor([[37, 37, 83, 37, 37, 11, 37, 38, 88, 11, 83, 37, 83, 37, 37, 37, 37,  9,
         11, 49, 37, 37, 37, 83, 49,  2, 50, 37, 56, 11,  2, 44, 56, 11, 37, 38,
         35, 77, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [56, 37, 82, 38, 35, 35, 37, 50, 59, 31, 37, 49, 31, 37, 50, 49, 37,  6,
         38, 38, 35, 35, 35, 37, 37, 31, 56, 37, 37, 28, 94, 11, 37, 37, 83, 85,
         37, 88, 37, 13, 37, 47, 37, 85, 77, 37, 37, 37, 85, 77, 49, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 83, 37, 56, 37, 38, 35, 31, 37, 85, 49, 37, 37, 38, 37, 35, 11,
         38, 37, 35, 38, 35, 35, 35, 35, 56, 11, 37, 37, 83, 37, 76, 37, 50, 38,
         35, 77, 31,  2, 94, 56, 37, 37, 56, 37, 37, 56, 85, 37, 32, 83, 83, 49,
         37, 11, 83, 37, 37, 37, 37, 37],
        [83, 37, 37, 38, 37, 37, 83, 24, 37, 28, 11, 37,  9, 50, 85, 83, 16, 37,
         23, 37, 50, 38, 77, 77, 11, 50, 38, 85, 88, 11, 38, 59, 11, 37, 85, 35,
         31, 35, 49, 37, 50, 37, 85, 77, 49, 37, 29, 82, 85, 37, 37,  9, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 32, 37, 37, 32, 37, 49, 37, 38, 35, 37, 37, 82, 85, 38, 75, 35, 77,
         35, 82, 37, 37, 32, 85, 37, 37, 83, 85, 37, 28, 83,  2, 77, 94, 11,  2,
         37, 85, 83, 83, 83, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [50, 31, 50, 38, 85, 11, 83, 38, 31, 38, 85, 37, 83,  2, 49, 11, 37, 38,
         85, 29, 31, 11, 37, 83, 37, 37,  9, 31, 75, 37, 37, 32, 37, 37, 37, 37,
          9, 11, 38, 85, 38,  2, 94, 50, 85, 83, 38, 77, 35, 83,  2, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 37,  2, 94, 37, 37,  2, 28, 37, 37, 38, 37, 25, 37, 37, 94, 85,
         37, 38, 35, 77, 37, 11,  6, 37, 59, 11, 50, 24, 11, 38, 59, 38, 35, 75,
         49, 32, 37, 37, 37, 53, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [34, 24, 83, 38, 85, 31, 85, 85, 29, 35, 37, 37, 38, 77, 37, 37, 11, 38,
          9, 11, 37, 83, 37, 85, 37, 38, 94, 11, 38,  9, 11, 37, 85, 37,  2, 11,
         37, 85, 37,  2, 11, 37, 37, 85, 49, 50,  2, 56, 11, 56, 50, 59, 37, 37,
         94, 37, 37, 83, 33, 83, 11, 83]], device='cuda:5'), 'lengths': tensor([41, 54, 57, 54, 45, 53, 46, 62], device='cuda:5'), 'ntokens': 412}, 'target': tensor([[  64,  306,   49,  107,  193,   16,   31, 6558,    4, 1554,  306,   49,
          107,    9,  328,  817,  193, 5067,  897,    4,    9,  631,   43,  317,
         1012, 6538,  312,    6,   37,   35, 2507,  219,  562,  127,    4, 3897,
          616, 2449, 1694,    4,  707,  352, 1040,  390,  352,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1419,   74,   44,   38, 1007,  293,   15,   41,  728, 3369,   20,  344,
         3881,   96,    4,   23,   14, 1270,  124,   40, 1549,  643,  459,  556,
           15,  503,  124,   83,  716, 2581, 2494,  358,   99,  695,  167,   61,
           14, 1963, 7188,  352, 5047,    9,   29,  141, 2258,   39,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  92, 4035,  139, 1676,   74,  330, 1898,   48,    4,   14,  105, 8807,
           20, 4134,  626, 5612,  894,    4,  385,   43,   47,  410,   58, 4277,
           15, 9768,   49, 3468,   22, 4832,    4,   14,  924, 1213,   47, 1176,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1209,  844, 1984,  698, 3758,    9, 6726,    4,  836,   52, 7276,  160,
            4,   14,   75,   30,  751, 1196,  458,  532,   97, 7117,   47,   28,
         1735,  184, 8388,  280,    4,   16,   28,   23,   31, 1121,  280,   44,
           38, 5329,  395,   18, 1312, 9679,    4, 3041,  664,  152,  158,  119,
          316,  223,  137,    9,  406, 3363,    5,    2,    1,    1,    1],
        [  72, 3844,  299,   56, 9615,   47,   29,   74,   32,   56, 9616,   56,
         9615, 1451,  510,   48,  721,   56, 9616,    5, 1451,  510,  262,   76,
            9,   23, 4442, 1578,   35, 2097,  160,   15,  201, 2029, 1121, 1213,
           47,   30,  496,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [2558, 1904,    4, 1513,   31,   82,    4,  113, 6613,   20,   31,  198,
           40,    4,   31, 1156, 1000, 2928,    6,    4,   31,  239,   51, 6026,
           18,    5,   64, 2211,  406, 1667,   58, 5324, 1984,  732,  385, 6520,
            4,    9,    6,   16,   98,  102, 3787,   28,  615,    4,  280,   31,
           52, 4315, 1145,    4,   14,  317, 2834, 4900,   82,    5,    2],
        [  72,   82,  647, 1145, 2813,   16,   52, 2335, 1541, 1993,  160, 3103,
            4,   97, 3826, 4688,  129, 3758, 6434,    4,   16,   14,  201, 2891,
            9,  437,   37,  739,    5, 1555, 2425,   41,   75,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 441, 2877,  332,  578,   95,  714,   61,   58,  437, 2037,  249, 9255,
         4009,    5,   68,  379,   65,   64,  361,   27,   36,   52,  796,    5,
           68,  379,   65,   99,   27, 2560,    5,   99,   27, 3614,    5,  404,
         4899,  470, 3626,  157,    4,  157,    4,   14,   14,  201,   60,  485,
          351, 1383,  208,    5,    2,    1,    1,    1,    1,    1,    1]],
       device='cuda:5'), 'target_lengths': tensor([47, 48, 38, 56, 41, 59, 35, 53], device='cuda:5'), 'ntokens': 377, 'nsentences': 8}
##################### {'id': tensor([220368, 164646, 162417, 186238,  63244,  43146, 216300,  80024],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 1.9531e-03,  2.1362e-03,  2.0447e-03,  ...,  3.8757e-03,
          3.4180e-03,  1.5564e-03],
        [ 1.3733e-03, -4.8828e-04, -6.7139e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.4932e-04,  6.1035e-05, -5.7983e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 2.8564e-02,  2.0142e-02,  1.3336e-02,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.7700e-03, -1.0986e-03, -7.9346e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.2512e-03, -1.1597e-03, -1.0376e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([186560, 186400, 186400, 186400, 186400, 186400, 186400, 186399],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2, 1815,  130,   75, 9813,    4, 9539, 3091, 3523,   35,  920, 2921,
           15,   28, 6275,    4,  136,  196, 3081,   27, 1253, 3332,   14,  840,
         1304, 2817,   23, 2309,  548,   28,  141,   56, 6836,   37, 7321,   15,
         1668,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  146, 8247,   22,  667,  173,  167, 2094,  576, 7237,  112,   30,
          582,   20, 4193,    6,   22,  366,  900,    4,  255,   43,   58, 3341,
           15,  157,  352,  989, 8443,    4,   58,   81,  210, 4193,    6, 1216,
          544,   39, 3160,   18,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1658,  566,    4,  789, 1721,   32, 8102,  330,  607,  650,    6,
         4612, 2356, 5296,   20,    4,   88,    9,   14, 2052, 2944,   45,  293,
          243,  272,  224,   32,   83,   14, 8588,   51, 2491,    4,   16,   97,
         7877,  212,  285, 2479,  165,   83,   32, 3898, 6700,   74,   52, 2521,
         4497,    5,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 2597, 5326,   97, 1309,  606,  177, 2009,  223, 4285, 3692,   20,
           39,   23, 5323,    4,   14,   49, 1670,   15, 4054,    6, 2921,   15,
           28,  905, 4219,  153,   18,  127,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  104, 5840, 2977,   14,  751, 5006,   90,   40, 1542,    6, 5634,
            4,   30, 2910, 4274,   98,   22,  241, 1733,    4,   88, 1442,    6,
          128,  195,  165,    6, 5722,   22,   28, 8168,    4,   16,   14, 8027,
           20,  444, 1302,   15,  129,  599,    6,    4,   88,   14, 1615,   28,
           51,  620,  797,   15,   16,   28,  421, 2356,   15,    5],
        [   2,  327,   32, 3262,    4,  319,  105, 9153,   15,    4,   14,  190,
          112,   14, 4902,    6,   20,   23, 3095,   23,  817,  790,   98, 2940,
         4463,  112,   58, 4696,  129, 2125,    6,   16,  534,    4,   74,   30,
         1698,    9,  405, 4953,   20, 1758,  171, 2491,  239,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1774,   59,   61, 3510,  831,  537,    5,   38, 3005,   22, 4881,
         2654,   18,  355, 8181,   16, 6574,   20, 9611,    4,   88,  197,   52,
         1225, 1145,   28,  186,   38,    5,  104,   56, 7640,  355,  286, 1129,
         2798,   28,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   72, 1204,  198,   14, 1963,  550,   39,    5,  146,  550,    4,
           14,   31, 1892,  280,    4,   14,  808,  392,  397,    4,  280,    9,
          743, 1245, 5550, 1281,    6,  242,  989, 5303,    4,   14,  157,   60,
          198, 7301,  471,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2')}, 'transcript': {'tokens': tensor([[1777,   26, 8064,   10, 9259, 7932, 2673, 6927,    4,   67,   70,   21,
            6, 3348, 1006,  276,  143,   80,   26, 6296,   54,  159, 2340,   10,
         4995,   35, 2482, 1519, 2394,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  19,  154,    7, 3727,    6,   63,  133,  999, 5971,    6,   10,    7,
         1648,   12, 2444,   17,  204, 1620,    6,    4,  125,   53,  780,   10,
          403,  297,  249,  436,    7,  324, 7955,   17, 1143,  199, 1764, 1558,
           54, 2444,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 238,    4,   12,  538,    4,   24,  368, 7984,  417,  607,  650,   11,
            6,  688, 9372,   10,    9,  827,  262,    7, 1303,    4,    8,   24,
           56, 1327, 1236,  777,   62,    7, 2072,    4,    8,    9,    7,  979,
           12,   33,   56, 1327,  140,  786,  271,    4,   24,   11,  121, 5973,
         2544,   79,   39, 6088,    4, 1120,    5,    2],
        [3079,    9,  521,  606,   26,    9, 1335,  461, 1927,   22,  131, 1749,
         2354,   35,  786, 3382,    6,   17, 1670, 2922, 3916,    6,   66, 5728,
           10,  601, 3536,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24,  204,  746,   12, 2770,    7, 1711, 3485,   79,   13, 1127,
         5475,    4, 8020,   54, 2678,  941,   10, 1927,    7,  129,  128,  160,
          271, 3529,    4,    8,   10,  368,    7,    7,   59,  627, 7147,   12,
          563,   10, 4257,    8, 1475,    7, 3632,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   70,   24, 1095,   34,    4,   24, 1095,  117, 7719,    6,    4,
            8,  180,   53,  968,  170,    7, 2829,    6,    4, 1102,   80,    7,
         1710,   12,  672,   35, 2371,    4,    8,   80,    7, 3819,    6,   12,
            7, 1479,    4,    8,   80,  138,    7, 1479,  487,    9,   21,    6,
         3573, 5563,    6,    5,    2,    1,    1,    1],
        [ 509, 2426,  254, 4701,    4,  230,   42,   38,    6,  620,   11,    6,
           58,  187,   62, 2827, 7127,    8,  853,  607,  111, 2848, 2050,   93,
          850,    7, 2135, 1638,   12,  197,   51,   13,  324, 1276,    5,   38,
          533,  192,   11,   18, 2444,  267,   10,  229,  267,  447, 4012,    5,
            2,    1,    1,    1,    1,    1,    1,    1],
        [  19,  487,  665,   85,   89,  447,  283,   44,    7,  283,   17,   19,
          144,  691,   55,    7, 5446,  392,  215,    4, 1120,  333,  183,    4,
          144, 4212,    6,   12, 2410,   17,   94,  144, 4240,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:2'), 'cluster_tokens': tensor([[28, 85, 31, 37, 29, 32,  9, 56, 11, 37, 50, 37, 37, 56, 94, 83, 50, 37,
         85, 29, 49, 37, 94, 37,  9, 38, 31, 28, 94, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [38, 59, 37, 94, 37, 85, 83,  2, 32, 37, 37, 37, 23, 37, 32, 37, 83, 85,
         37, 11, 37, 37, 88, 37, 38, 35, 77, 77, 37,  2, 32, 37, 85, 37, 38, 35,
         49, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 11, 37, 83, 11, 38, 49, 28, 38, 35, 35, 85, 37,  9, 94, 37, 37, 35,
         77, 37, 24, 11, 37, 38, 38, 35, 35, 67, 31, 37,  2, 11, 37, 37, 37, 32,
         37, 37, 38, 35, 35, 35, 44, 11, 38, 85, 35, 31,  9, 37, 38, 94, 11, 83,
         11, 83],
        [94, 37, 38, 35, 85, 37,  2, 32, 49, 35, 37, 28, 23, 38, 35,  9, 37, 37,
         28,  9, 32, 37, 85, 31, 37, 49, 16, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 38, 83, 83, 37, 31, 37, 50, 94, 37, 37, 50, 32, 11, 29, 49,  9, 94,
         37, 49, 37, 38, 35, 35, 44, 56, 11, 37, 37, 49, 37, 37, 35, 35, 56, 37,
          9, 37, 94, 37,  2, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 50, 38, 59, 85, 11, 38, 59, 37, 33, 37, 11, 37, 37, 37, 88, 37, 37,
         32, 37, 11, 83, 37, 37, 94, 37,  9, 38, 24, 11, 37, 37, 37, 32, 37, 37,
         37,  9, 11, 37, 37, 37, 37,  9, 31, 37, 37, 37, 28, 94, 37, 11, 83, 37,
         37, 37],
        [ 2,  2, 37, 88, 11, 37, 11, 38, 37, 77, 85, 37, 38, 35, 31,  2, 94, 37,
         38, 35, 83, 38, 35, 35, 37, 37, 38, 77, 37, 82, 38, 37,  2, 94, 11, 38,
         35, 85, 85, 35, 32, 37, 37, 49, 37, 37, 56, 11, 83, 37, 37, 37, 37, 37,
         37, 37],
        [38, 31, 59, 37, 37, 37, 49, 82, 37, 49, 37, 38, 85, 31, 37, 37, 31, 17,
         24, 11, 83, 50, 24, 11, 85, 32, 37, 37, 32, 37, 56, 85, 31, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37]], device='cuda:2'), 'lengths': tensor([31, 40, 56, 29, 45, 53, 49, 35], device='cuda:2'), 'ntokens': 338}, 'target': tensor([[1815,  130,   75, 9813,    4, 9539, 3091, 3523,   35,  920, 2921,   15,
           28, 6275,    4,  136,  196, 3081,   27, 1253, 3332,   14,  840, 1304,
         2817,   23, 2309,  548,   28,  141,   56, 6836,   37, 7321,   15, 1668,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 146, 8247,   22,  667,  173,  167, 2094,  576, 7237,  112,   30,  582,
           20, 4193,    6,   22,  366,  900,    4,  255,   43,   58, 3341,   15,
          157,  352,  989, 8443,    4,   58,   81,  210, 4193,    6, 1216,  544,
           39, 3160,   18,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1658,  566,    4,  789, 1721,   32, 8102,  330,  607,  650,    6, 4612,
         2356, 5296,   20,    4,   88,    9,   14, 2052, 2944,   45,  293,  243,
          272,  224,   32,   83,   14, 8588,   51, 2491,    4,   16,   97, 7877,
          212,  285, 2479,  165,   83,   32, 3898, 6700,   74,   52, 2521, 4497,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1],
        [2597, 5326,   97, 1309,  606,  177, 2009,  223, 4285, 3692,   20,   39,
           23, 5323,    4,   14,   49, 1670,   15, 4054,    6, 2921,   15,   28,
          905, 4219,  153,   18,  127,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 104, 5840, 2977,   14,  751, 5006,   90,   40, 1542,    6, 5634,    4,
           30, 2910, 4274,   98,   22,  241, 1733,    4,   88, 1442,    6,  128,
          195,  165,    6, 5722,   22,   28, 8168,    4,   16,   14, 8027,   20,
          444, 1302,   15,  129,  599,    6,    4,   88,   14, 1615,   28,   51,
          620,  797,   15,   16,   28,  421, 2356,   15,    5,    2],
        [ 327,   32, 3262,    4,  319,  105, 9153,   15,    4,   14,  190,  112,
           14, 4902,    6,   20,   23, 3095,   23,  817,  790,   98, 2940, 4463,
          112,   58, 4696,  129, 2125,    6,   16,  534,    4,   74,   30, 1698,
            9,  405, 4953,   20, 1758,  171, 2491,  239,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1774,   59,   61, 3510,  831,  537,    5,   38, 3005,   22, 4881, 2654,
           18,  355, 8181,   16, 6574,   20, 9611,    4,   88,  197,   52, 1225,
         1145,   28,  186,   38,    5,  104,   56, 7640,  355,  286, 1129, 2798,
           28,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  72, 1204,  198,   14, 1963,  550,   39,    5,  146,  550,    4,   14,
           31, 1892,  280,    4,   14,  808,  392,  397,    4,  280,    9,  743,
         1245, 5550, 1281,    6,  242,  989, 5303,    4,   14,  157,   60,  198,
         7301,  471,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:2'), 'target_lengths': tensor([38, 41, 50, 31, 58, 46, 39, 40], device='cuda:2'), 'ntokens': 343, 'nsentences': 8}
##################### {'id': tensor([ 81981,  21359, 100663, 206033,    142,  34994,  28537,  70715, 129895,
         92988,  71765, 110939, 113779,  61370, 124950,  78264,  82352, 155319,
        201353, 123163,  19284, 127613, 148515,  32654], device='cuda:1'), 'net_input': {'src_tokens': tensor([[-3.4485e-03, -4.8828e-04,  2.2888e-03,  ..., -3.2654e-03,
         -1.5167e-02,  3.9062e-03],
        [ 1.4343e-03, -2.4414e-04, -1.5259e-04,  ..., -1.8616e-03,
         -2.8381e-03, -5.4321e-03],
        [-1.8262e-01, -1.8213e-01, -1.6931e-01,  ...,  0.0000e+00,
         -1.1902e-03, -2.3804e-03],
        ...,
        [ 1.0681e-03,  1.8005e-03,  8.8501e-04,  ..., -4.8523e-03,
         -3.5095e-03,  0.0000e+00],
        [-4.0894e-03, -3.9673e-03, -3.3569e-03,  ..., -3.1433e-03,
         -3.2959e-03,  0.0000e+00],
        [ 1.0406e-02,  6.8359e-03,  1.0468e-02,  ..., -2.5238e-02,
         -2.5208e-02,  0.0000e+00]], device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960,
        84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960, 84960,
        84960, 84959, 84959, 84959], device='cuda:1'), 'prev_output_tokens': tensor([[   2,  377,   48,  ...,    1,    1,    1],
        [   2,   64, 2012,  ...,    1,    1,    1],
        [   2, 1896,  495,  ...,   28, 3086,    5],
        ...,
        [   2, 1673,    6,  ...,    1,    1,    1],
        [   2, 2400, 2996,  ...,    1,    1,    1],
        [   2,   72, 1904,  ...,    1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[   8,   55,   17, 4912, 3782,   10, 1085,    4,   24,   66,   10,   66,
          238,   35,  927,  153,  140, 1011,  672,    6,   12, 3718,  368,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   17,   26,    4,   84,   26,   39,  318,   22,  240,  627, 2372,
            4,   13, 8572,    9,    7, 2372,   17, 4750,   33,  318,   22,  240,
          627, 3221,   32,   54,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 339,  565,  205, 2346,    6,   20,  284,  447,   39,  153, 3576,   20,
            5,   38,  469, 2793,  188,  278,   10,   51,  529,   10, 9737,   21,
            6,  417,  606,    4,   51,  452, 5729, 1197,    4,    8, 3070,  540,
            5,    2],
        [ 378,   13, 2828,   37,    8,   13, 5577,   26, 1623,    8, 3975,    9,
         1492, 2723,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  70,   24,  692,   10,   87,   26,   24,  692,   10,  229,   13, 3399,
           17,  619,  250,   17,   34, 1157,  187,  111, 2875,   69,    7, 1749,
         1648,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,  115,   94,   73,  289,    4,   38,  187,  213, 1456,   33,    8,
           33,    8,   33,  438,    8,   25,   73,  205,  126,    8, 5424,   21,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 117, 4839,  162, 4803, 4050,    5,  276,  155, 4224, 3337,    6,  175,
          143, 2011, 3043,    4,   29,   25, 2244, 4224, 1116,  191, 1255,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  24,   13,  140, 1355, 3471,  187,   62, 2464,    6, 1898,  290,    4,
           79,  101, 4311,    7,  984,    4, 3082,   54, 2822,    6,  206,  101,
          144, 1042, 3561,    8, 5320,   62,    5,    2,    1,    1,    1,    1,
            1,    1],
        [  21,   26,   13, 1333,  678,  241,    4,  103,   25,  164,    4,   12,
            7,  546,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  53,  169,  229,   13,  277,  523,  143,  839,  224,  159, 3057,   12,
         1074,  169, 3474,    8,  169,  175,  509,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   7,  281, 1623,  214,   10, 3089,   35, 3304,    4,    7,  281, 5459,
          111, 7496,  214,   10, 3089,   35, 3304,   63,    7,  688,  608,  214,
            4,    7,  281,  384, 1838,  436,  214,    5,    2,    1,    1,    1,
            1,    1],
        [  33,   26,   13,   58,    6,   20, 9055,  417,   20,  122,  848,  338,
         2839,   54,  798,  957, 5831,    6,   12,  813,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  19,  368,   13,  325,   12, 4112,    6,    4,  166,  818,   17, 1275,
           19,   66,   10, 3858,   10,   25,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  24,   11,   57,  665,   85, 1009,  733, 1884,    9,  159, 6338, 5670,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [2027, 1117,   12,   25,    4,  333, 1127,   91,   12,   25,  188,    7,
          281, 1894, 3180, 2134,   10,   81,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   33,  733, 5475, 1359,   11,   18,  276, 2134,   80, 1325, 6985,
          215,  581,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  29,    4,   70,   11,    6, 3764,   80,    7, 2696,   26,   17,   21,
           11,    6, 8547,    4,    8,   21,  188,  211, 3238,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 305,  251,   94,    8,   53, 1157,   13,  133, 5787, 2901, 3924,  131,
           13,  423,   35, 1933,   35, 1178,  440,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  13, 1996, 1236,  543, 1049,   33,  464,    4,   55,    7,  245,  183,
            9, 1261,    4,  204, 2231,    6,  143,  254,   70,   24, 4342,  106,
            7, 2533,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  89, 1848, 5427,   62,  359,  294,  143,   12,   89,  948, 3718, 3357,
            4, 3448,   13, 5309, 8192, 9057,   73,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   53,   63,  205,  174, 4200,  132,  778,  336,  134,    4, 3448,
          688,    4,  166,   26,  347,   24,   73,   11,   18,  150,  134,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,  476,  324,  687,   24,  162,  116,  593,  963,    4,  203,  242,
          158, 1563,    8,  521,   18,   59, 4356,   85,    7,  183,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [9482,    4, 6486,  588, 2618,    9,   69, 5249,    6, 2366, 2223,    4,
           53,   87, 5656,   55,  248, 1113,    4,  180,   53, 2618,  637, 1911,
          234,    6, 2366, 7313,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1],
        [  19,  465,   11,   18,  135,  148,   21,   34,    4,   19,  465,   11,
           18,  135,   70,   53,  692,    4,    8, 1122,  455,    6,  443,  220,
          450,   53,  162, 2182,  588,  752,   10,  175,  170,  126,    5,    2,
            1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 37, 37, 49, 94, 37, 85, 11, 38, 85, 37, 85, 83, 38, 35, 77, 35, 31,
          9, 37, 37,  2, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 37, 85, 11, 37, 85, 38, 38, 35, 35, 35, 47, 11, 37, 94, 37, 37, 47,
         37, 88, 37, 38, 35, 35, 35, 29, 38, 49, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37],
        [49, 37, 85, 38, 37, 77, 37, 37, 38, 77, 35, 77, 11, 38, 35, 38, 85, 31,
         37, 38,  6, 37, 29, 37, 37, 38, 35, 11, 38, 38, 35, 77, 11, 37, 49, 36,
         11, 83],
        [49, 37, 29, 77, 37, 37, 28, 85,  2, 37,  2, 37, 38, 35, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [50, 38, 85, 37, 85, 85, 38, 85, 37, 49, 37,  9, 37, 31, 50, 37, 85, 88,
         35, 83, 31, 37, 37, 28, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 83, 56,  6, 88, 11, 38, 35, 88, 83, 37, 37, 37, 37, 37, 82, 37, 37,
          6, 85, 37, 37, 29, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 33, 85, 83,  2, 11, 83, 37, 28,  9, 37, 85, 50,  9, 29, 11, 83, 37,
         29, 28, 38, 77, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [38, 37, 35, 35, 35, 35, 31, 38, 37, 35, 35, 11, 37, 38, 31, 37, 94, 11,
         49, 49,  9, 37, 37, 38, 85, 83, 10, 37, 29, 31, 11, 83, 37, 37, 37, 37,
         37, 37],
        [37, 85, 37, 38, 35, 35, 11, 37, 37, 85, 11, 37, 37, 18, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 85, 49, 37, 50, 83, 50, 32, 11, 37, 23, 37, 49, 85, 29, 37, 85, 85,
          2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 75,  2, 56, 37, 38, 38, 35, 11, 37, 75, 28, 83,  2, 56, 37, 38, 38,
         35, 85, 37,  9, 75, 56, 11, 37, 75, 38, 35, 77, 56, 11, 83, 37, 37, 37,
         37, 37],
        [37, 85, 37, 38, 37, 77, 94, 38, 77, 35, 38, 35, 29, 49, 34, 73,  9, 37,
         37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [38, 49, 37, 83, 37, 32, 37, 11, 37, 88, 37, 83, 38, 85, 37, 38, 37, 37,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [38, 85, 77, 59, 37, 49, 50, 56, 37, 37, 94, 23, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [ 2, 37, 37, 37, 11, 50, 50, 50, 37, 37, 85, 37, 75,  2, 32, 31, 37, 38,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 37, 50, 32, 85, 85, 35, 83, 31, 37, 24, 34, 24, 83, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 11, 50, 85, 37,  2, 37, 37, 23, 85, 37, 37, 85, 37,  2, 11, 37, 37,
         85, 50, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [49, 50, 56, 37, 37, 88, 37, 83, 83,  9, 31, 37, 37, 34, 38, 24, 38, 35,
         83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 35, 35, 66, 77, 37, 24, 11, 37, 37, 83, 24, 37, 94, 11, 83, 49, 37,
         50, 37, 50, 38, 49, 37, 37, 28, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 56, 76, 31, 37, 50, 50, 37, 37, 94,  2, 56, 11, 83, 37,  2, 31,  9,
          6, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 37, 85, 85, 35, 35, 37, 50, 37, 37, 11, 83,  9, 11, 37, 85, 83, 38,
          6, 85, 35, 59, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [37, 83,  2, 35, 38, 85, 83, 83,  2, 11, 38, 77, 35,  2, 37, 38, 35, 35,
         28, 37, 37, 24, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37],
        [83, 11,  9, 77,  8, 37, 37, 79, 37, 24, 24, 11, 37, 85, 76, 37, 34, 24,
         11, 37, 37,  8, 37, 38, 35, 37, 24, 24, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37],
        [38, 85, 85, 35, 59, 50, 37, 85, 11, 38, 85, 85, 35, 59, 50, 37, 85, 11,
         37, 38, 35, 37, 35,  6, 88, 37, 85,  9, 77, 49, 37, 85, 37, 37, 11, 83,
         37, 37]], device='cuda:1'), 'lengths': tensor([25, 30, 38, 16, 27, 26, 25, 32, 16, 21, 33, 22, 20, 14, 20, 16, 23, 21,
        28, 21, 25, 24, 30, 36], device='cuda:1'), 'ntokens': 589}, 'target': tensor([[ 377,   48,  385,  ...,    1,    1,    1],
        [  64, 2012,  178,  ...,    1,    1,    1],
        [1896,  495,  921,  ..., 3086,    5,    2],
        ...,
        [1673,    6,   20,  ...,    1,    1,    1],
        [2400, 2996, 7112,  ...,    1,    1,    1],
        [  72, 1904,   47,  ...,    1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([21, 27, 43, 17, 26, 24, 34, 35, 14, 22, 32, 30, 22, 19, 18, 14, 24, 22,
        19, 27, 22, 25, 39, 35], device='cuda:1'), 'ntokens': 611, 'nsentences': 24}
##################### {'id': tensor([ 97145,  81331, 193653, 172151, 144456, 119106, 163151,  92252],
       device='cuda:3'), 'net_input': {'src_tokens': tensor([[ 9.7961e-03,  1.3519e-02,  9.3079e-03,  ...,  4.4250e-03,
          5.4932e-03,  7.2632e-03],
        [-1.3599e-01, -1.4795e-01, -1.6687e-01,  ..., -1.2543e-02,
         -1.5625e-02, -1.4038e-02],
        [-9.1553e-05,  0.0000e+00, -1.8311e-04,  ...,  3.0518e-04,
          5.4932e-04,  5.4932e-04],
        ...,
        [-1.3123e-03, -1.5259e-03, -1.5259e-03,  ...,  9.7656e-04,
          1.0986e-03,  7.9346e-04],
        [ 9.1553e-05, -8.2397e-04, -1.9226e-03,  ..., -1.8311e-04,
         -2.1362e-04, -3.6621e-04],
        [ 2.7466e-04, -4.5471e-03, -6.5613e-03,  ..., -5.4932e-04,
         -3.6621e-04, -1.2207e-04]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([204000, 204000, 204000, 204000, 204000, 204000, 204000, 204000],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,   64,  374,  112,   30,  482,  686, 3251,   18,    4,   27,   47,
         1048,    4,  114,   32,   39,  102, 2086, 2935, 1208, 1471,    4,   30,
          105, 2524,  128,  187,  152,  191,   47, 3959,  243,  152, 1733,    4,
          268,   32,   43,   60,  151, 3057, 2259,   15, 2612,   47, 4245,  123,
           16,   32,  615,  139,   47, 5452,   60,  141,  342,  300,  249,   23,
          118,  947,   15, 1463,    5,    1],
        [   2, 3167, 5810,   32,   60,  302, 4194, 6531,    6, 6731,   44,   30,
           52, 3490,   39,   58, 5923,   22,  496,   15,  224,   30,  331, 3452,
           75,    9,   23, 3724, 2019,   18,  271, 4571,   37, 8986,   15,  364,
         4679,  165, 5361, 2230,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  146, 2799,  493, 1624,    5,    5,    5,   72,  313,    4,   74,
         1121,    4, 3418, 8536,   37,   16, 1812,  653,    4,   50,   31,   30,
         4872,   20, 4625,  209,    4,   88, 6915,  458, 2619,  678,   61, 2972,
         1957,  375, 9893,    4,   16,   43,  139,    9,  351, 1876,   15, 5664,
          145,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72, 2794,  139,   52, 2557,   49, 3332,    6, 5078,   22,   98,
          102, 9151,   22, 1876,   14, 4875,  167, 6586,   37, 7044,   59, 3970,
          799, 4161,   61,   30,  201,  247, 1199,  969,  471,   16,   12,   18,
         7134,   20, 4011, 1717,   37,  466, 8578,   22,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  377,   23, 5835, 3739,   18,  153,   23, 5720, 1304,  522,   32,
          664,  219,   22, 1901,   44,   40, 1725,  809,  128,   18,    4,   16,
          255,  503,   38, 2579, 7786,   49,  377,  122,  803, 3287,  980,  124,
         3596,   23,  580,    4,   23,  184,  627,   18, 2221,   82,  193, 1939,
           38, 5417, 3714,   88,   14, 1424,  176,  375,  197,  193, 1330, 1124,
         1430, 2589,  186,    5,    1,    1],
        [   2,   92,   82, 6637,  243, 1604, 1324,   18,   78,  163,   16,   31,
         1277,  163,   28, 1481,    4,   74,   36,   88,  256, 3047, 1958, 1109,
            4,   14,  184, 8268,  543,   15, 1612,  158,   15,    4,   16,  139,
           88,  306,  306,  331, 1687,   37,  242, 8667,   22,   61,   23, 1083,
          201,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  520,   23, 3599,  181,  128, 4835,  301, 1996,   57,    9, 4559,
         1332, 6274,   15,  239,    4, 1812,   81,    4,   50,   23, 4156,  156,
          693, 2453,   49, 4852,   49,  966,  233,  530,   37,  303,    4, 1658,
         1098,  932,   22,  357,    4, 2204, 1987,  480,   15,    4, 4042,  152,
          549,   16, 8361,   82,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   64,  217, 4631, 1801,  239,   40, 1600,    6, 2928,    6, 5357,
            6,   37,  247,  174, 1845, 3999,  602,  228,    6,  235,  387,   20,
           12,  974,  128,  322, 1297,   18, 1775,    8,  330, 6127,  271,    9,
         1196,  411,   18,  232,    5,   99, 1171,    4,   50,  743,  655,  787,
           23,  184,    6, 2023,   15,   15,  435, 8652,   61,   14, 2086,   49,
          617,  420, 5266,  127,  145,    5]], device='cuda:3')}, 'transcript': {'tokens': tensor([[   8,  778,   17, 1308,   26,  952,   80,  440, 1382,   11,   18, 1254,
          103,   24, 1005, 1057,   39, 1370,  128,  567,   17,  568,   86, 2070,
          117, 9371,    4,  125,   24, 1704,   11,   18,  175,   84,   71,   13,
         3057, 1181, 1108,    4,    8,   24, 1704,   11,   18,  175,   84,   71,
           13, 1507,   12,   91,  230, 1141,    5,    2,    1,    1,    1,    1,
            1,    1],
        [  24,  144,  248, 1543,    6,  740,    9, 6731,   44,   91, 1543,   69,
            7, 6873,    4,    8,    7,  218,   69,  752,   10,   51,  529,   10,
         7288, 1711, 8452,    6,   10,  175,  264, 1247,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [1221, 8163,  126,  131,   89, 1361,   46,   29,   79,   19, 6179,    4,
           19,   11,   45,   13, 3169, 6984,    4,   67,   19,   11,  121, 1873,
           19,   11,  121,  278,  117, 2522,   12,  802, 6315, 9035,    9,   13,
          412, 3784, 2073,  140,  936,    4,    8,   29,   73, 4432,  251, 2522,
            9,  218, 2384,   79,  238,    5,    2,    1,    1,    1,    1,    1,
            1,    1],
        [  19,  113, 1618,   13,  800,   12, 1752, 7311, 3348,  148,    4, 4580,
          133, 5985, 3980, 2791,    4,  162,  961,   13, 1523, 2302,    9,    7,
          179,    4, 1149,  875,   54,  540, 2320,   54,   13,   48, 1305, 6325,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   24,  323,  446,  294,   69,    7,  230, 6951,   12,    7, 3156,
         1832,    4,   39, 1404, 4719,    4,    8,   17,   11,    6,  206,   24,
          703,   38,  469, 5656,   12,   39,  122,  803, 3287,  438,  109,   85,
         1686,    7,  461,   17,   24,  135,  188,  226, 3765,   62,    4,  166,
           26,  434,   38,  469, 3040,   55,    7, 3057,  438,  451,   51, 9483,
            5,    2],
        [  33, 3761,  384,  827,  119,  922,  110,    4,    8,   19, 1608,   11,
           18,  601,   67, 2743,   80,    7, 3577,   20,   12,   89,  801, 1431,
            4,    7, 1997, 2361, 5866,    6,    4,    8,    7, 3577,   20,   12,
            7,  294,    4,  294,  267,  235,  709, 2696,    6,   77,  244,    7,
          179,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [ 120, 2794,  128, 4835, 3275,    9, 4517,   34,  811, 1027,  586,  922,
            4,    7, 3421, 8156,  237,    6,   84,  162,  591,   10,   51,  993,
           62,   71,    7, 4222,    6,   12, 6436,  603,  603,  455, 3030,    4,
          846, 1397,  794,    4, 5918,    6,    4, 5932,   15,  484,    4, 7291,
            6,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1],
        [   8,   13,  133,  528, 1472,   12, 1221,  552,  126,   69, 9474,  106,
            7, 6142,   12,  958, 1618, 1775,    6,    8,  417, 6127,  271,    9,
         3981,   18,  232, 3243,   17, 1120,  655,  439,   12,    7, 2322,    9,
         1269, 7347,   73,   51, 9097,   48,   10, 3726, 1370,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 50, 37, 50, 85, 16, 37, 83, 85, 85, 35,  6, 37, 38, 49, 49, 38, 94,
         35, 32, 37, 85, 83, 32, 37, 56, 11, 37, 38, 31, 85, 35, 85, 37, 37, 37,
         23, 31, 32, 11, 37, 38, 31, 85, 35, 85, 37, 37, 37, 94, 37, 50, 37, 94,
         11, 83, 37, 37, 37, 37, 37, 37],
        [38, 85, 34,  9, 37, 49, 37,  4, 82, 50,  9, 37, 37, 94, 11, 37, 37, 50,
         37, 49, 37, 38,  6, 37, 12, 50, 28, 37, 37, 85,  2, 56, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [94, 31, 37, 37, 37, 94, 11, 83, 37, 38, 88, 11, 38, 85, 35, 37, 28, 28,
         11, 37, 38, 85, 35, 86, 38, 85, 35, 31, 37, 56, 37, 49, 28, 94, 37, 37,
         35, 35, 38, 35, 35, 11, 37, 83,  6, 49, 50, 56, 37, 50, 56, 37, 83, 11,
         83, 37, 37, 37, 37, 37, 37, 37],
        [38, 83, 31, 37, 23, 37, 38, 28, 56, 50, 11, 37, 83,  5, 28, 56, 11, 85,
         49, 37,  2,  1, 37, 37, 94, 11, 83, 49, 49, 36, 83, 49, 37, 31, 35, 56,
         11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 59, 50, 37, 37, 37,  9, 37, 37, 28, 94, 11, 38, 94, 33, 11,
         37, 37, 85, 37, 37, 38, 88, 38, 35, 76, 37, 38, 35, 35, 35, 82, 37, 37,
         83, 37, 32, 37, 38, 59, 85, 85, 94, 31, 11, 37, 85, 31, 38, 35, 76, 37,
         37, 23, 82, 85, 38, 31, 11, 83],
        [37, 83, 38, 35, 75, 31, 37, 11, 37, 38,  6, 85, 35, 49, 37, 88, 37, 37,
          2, 77, 37, 37,  2, 56, 11, 37, 38, 31, 29, 37, 11, 37, 37,  2, 77, 37,
         37, 50, 11, 50, 37, 35, 35, 23, 37, 50, 37, 37, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 53, 35, 35,  9, 37, 28, 85, 38, 35, 35, 31, 11, 37,  9,  9, 35, 37,
         37, 85, 31, 37, 38, 32, 31, 37, 37,  9, 37, 37, 94, 35, 35, 35, 35, 11,
         38, 35, 35, 11,  9, 37, 11, 38, 77, 35, 11,  9, 37, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 83,  2, 32, 37, 94, 85, 37, 37, 24, 37, 37, 32, 37, 94, 31, 35,
         37, 37, 38, 33, 44, 37,  9, 35, 77, 88, 37, 83, 34, 24, 37, 37, 29, 37,
          9, 94,  6, 38, 49, 31, 37, 28, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37]], device='cuda:3'), 'lengths': tensor([56, 34, 55, 38, 62, 51, 51, 47], device='cuda:3'), 'ntokens': 394}, 'target': tensor([[  64,  374,  112,   30,  482,  686, 3251,   18,    4,   27,   47, 1048,
            4,  114,   32,   39,  102, 2086, 2935, 1208, 1471,    4,   30,  105,
         2524,  128,  187,  152,  191,   47, 3959,  243,  152, 1733,    4,  268,
           32,   43,   60,  151, 3057, 2259,   15, 2612,   47, 4245,  123,   16,
           32,  615,  139,   47, 5452,   60,  141,  342,  300,  249,   23,  118,
          947,   15, 1463,    5,    2,    1],
        [3167, 5810,   32,   60,  302, 4194, 6531,    6, 6731,   44,   30,   52,
         3490,   39,   58, 5923,   22,  496,   15,  224,   30,  331, 3452,   75,
            9,   23, 3724, 2019,   18,  271, 4571,   37, 8986,   15,  364, 4679,
          165, 5361, 2230,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 146, 2799,  493, 1624,    5,    5,    5,   72,  313,    4,   74, 1121,
            4, 3418, 8536,   37,   16, 1812,  653,    4,   50,   31,   30, 4872,
           20, 4625,  209,    4,   88, 6915,  458, 2619,  678,   61, 2972, 1957,
          375, 9893,    4,   16,   43,  139,    9,  351, 1876,   15, 5664,  145,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72, 2794,  139,   52, 2557,   49, 3332,    6, 5078,   22,   98,  102,
         9151,   22, 1876,   14, 4875,  167, 6586,   37, 7044,   59, 3970,  799,
         4161,   61,   30,  201,  247, 1199,  969,  471,   16,   12,   18, 7134,
           20, 4011, 1717,   37,  466, 8578,   22,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 377,   23, 5835, 3739,   18,  153,   23, 5720, 1304,  522,   32,  664,
          219,   22, 1901,   44,   40, 1725,  809,  128,   18,    4,   16,  255,
          503,   38, 2579, 7786,   49,  377,  122,  803, 3287,  980,  124, 3596,
           23,  580,    4,   23,  184,  627,   18, 2221,   82,  193, 1939,   38,
         5417, 3714,   88,   14, 1424,  176,  375,  197,  193, 1330, 1124, 1430,
         2589,  186,    5,    2,    1,    1],
        [  92,   82, 6637,  243, 1604, 1324,   18,   78,  163,   16,   31, 1277,
          163,   28, 1481,    4,   74,   36,   88,  256, 3047, 1958, 1109,    4,
           14,  184, 8268,  543,   15, 1612,  158,   15,    4,   16,  139,   88,
          306,  306,  331, 1687,   37,  242, 8667,   22,   61,   23, 1083,  201,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 520,   23, 3599,  181,  128, 4835,  301, 1996,   57,    9, 4559, 1332,
         6274,   15,  239,    4, 1812,   81,    4,   50,   23, 4156,  156,  693,
         2453,   49, 4852,   49,  966,  233,  530,   37,  303,    4, 1658, 1098,
          932,   22,  357,    4, 2204, 1987,  480,   15,    4, 4042,  152,  549,
           16, 8361,   82,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  64,  217, 4631, 1801,  239,   40, 1600,    6, 2928,    6, 5357,    6,
           37,  247,  174, 1845, 3999,  602,  228,    6,  235,  387,   20,   12,
          974,  128,  322, 1297,   18, 1775,    8,  330, 6127,  271,    9, 1196,
          411,   18,  232,    5,   99, 1171,    4,   50,  743,  655,  787,   23,
          184,    6, 2023,   15,   15,  435, 8652,   61,   14, 2086,   49,  617,
          420, 5266,  127,  145,    5,    2]], device='cuda:3'), 'target_lengths': tensor([65, 41, 50, 45, 64, 50, 53, 66], device='cuda:3'), 'ntokens': 434, 'nsentences': 8}
##################### {'id': tensor([ 60843, 162038, 100653, 218418, 168022,  66735,  20473,  91190, 219559,
         63588, 108297,  51513,  41938,  98222, 100306, 198595],
       device='cuda:0'), 'net_input': {'src_tokens': tensor([[-0.0045, -0.0050, -0.0042,  ..., -0.0125, -0.0092, -0.0056],
        [-0.0089, -0.0060, -0.0022,  ...,  0.0104,  0.0067,  0.0001],
        [-0.0036, -0.0031, -0.0032,  ...,  0.0072,  0.0071,  0.0072],
        ...,
        [-0.0009, -0.0011, -0.0015,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0008,  0.0014,  0.0020,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0047, -0.0036, -0.0019,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([130880, 130880, 130880, 130880, 130880, 130879, 130720, 130720, 130720,
        130720, 130720, 130720, 130720, 130720, 130719, 130719],
       device='cuda:0'), 'prev_output_tokens': tensor([[   2,  147, 1815,  280,  632,    4, 3596, 2163,    4, 3652, 1349,    4,
           88,   58, 5771,  212, 1415, 2369,  243,  315,  530,   15,    4,   14,
         1818, 2772,  911, 1105,   18,   28, 6278,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  327,  123,   32,  466, 4264,   42,   38,  967,  705,   14, 6374,
           35,  128,    6,   35,  806, 1576,  122,   35,  748,  307, 1034,  560,
          548,  345,   18,  105,  351, 1468,   23,  441, 4887,   78,   40, 6374,
         8306,    5,    1,    1,    1,    1,    1],
        [   2,  404, 1391,   14,  617,   16, 3526,  221, 4741,  303,  847,  428,
            9,  302,  259, 3184,   15,  129,  732, 3716,  398,   81,  217,  731,
           49, 1160,   37,  515, 4985,   15,    4, 1939,   90,  499, 1089, 1145,
           16,   90, 3526,  221, 4741,  345,    5],
        [   2,  222,   41,  105, 4365,   98,  350, 8062, 2301,    4,  472,  160,
         1597,   16, 4545,   47,   39,    6, 1727,  951,    4,   76,   41,  385,
           47, 2631,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  864,  191, 3142,  208,   41,  118, 8361,    4,   23, 9674,   52,
         3526,  262,  657, 1203, 3165, 4755,    4,   16,   14, 1640,   20, 1100,
         1171,   58, 8847,  129, 8361,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  147,  173,  160,    4,    9,  102,  840,  989,    4,   50,   36,
          139,   52, 1225, 5887,   27,    4,   47,  317, 3193, 8589,    4, 1364,
           23, 4784,   20, 2190,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  228, 1437,   83,  157, 1439,    6,  497, 5371,  767, 6045, 5133,
          171,    6,  812,  365,   16,  302, 1524, 6842, 1612,  243, 9105, 1756,
         2391,  398,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  738, 2727,   39,  141, 4519, 2897, 1812,  653,    4,   50, 1185,
          820,  787,   23, 5449,    6,   20,  458,  532,  118, 8631,  243,  556,
           15,   83, 4008,   49, 5961,   45, 8127,   49, 1441,  176,  932,  357,
            5,    1,    1,    1,    1,    1,    1],
        [   2,  222,   41,  361, 1000, 5679,   44,   38, 7502,    4, 1513,  130,
          197, 4901,  237, 1063, 2658,   38, 9527,  358,    4,  123,   41,   75,
           47, 2425,    4,  268,   14, 3224,   22, 1034,    6,   20, 9250,  130,
          124, 6352,    5,    1,    1,    1,    1],
        [   2, 6703,   27,   36,    4,   90,  227,  152, 1177,   15,   32,  231,
          466,    9,  151, 6919,    4,  921,   32,  123,    9,  102, 1083, 1872,
         1368,  149,   14,  310, 7841,    9,  536, 4542,  208,    5,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  298,   83,   32,  299, 4969,  203,    6, 1806,  469,   18, 2259,
            5,  402,  421, 1294,   36,    5,  674,   20, 7760,   15,  374,    9,
         2968, 9403, 4450, 1096,  301,   54,   15,   16, 1096, 5123,  129,  301,
           54,   15,    6,    5,    1,    1,    1],
        [   2, 1462, 2927,  217,  285,   18,   59, 2628,   22, 1277,   90,  330,
           22, 1252,   14, 4033,   51,  587,   18,   16, 2578,  811, 1076, 1158,
         1350,   16,   31,  163,   28, 1481, 1277,    4,   34,  647,  730,   82,
            5,    1,    1,    1,    1,    1,    1],
        [   2,  441, 4447,  510,    4,   47,  485,   29, 4447,  510,    4,  177,
         8830, 1681, 3362,   78,   14, 4308, 3104,  141, 4054,  119,   59, 2174,
           20,   49, 6345, 2709,    4,   14,   75,   61,   58,  758,  651,    5,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  146,  377, 3998,  721,   49,  869,  458, 1374,    4, 2865,   15,
         5839,   22,  174, 5189,  549,   16, 4553,   22, 3016,  163,  420,   28,
          102,  497,    4,    9,  102,   31,   14,  301, 3110,  187, 5839,  223,
         1304,   37,  153,    5,    1,    1,    1],
        [   2,  504,  208,   41,   58, 4886,    4,   60,  350,  500,   57,  160,
         1597,   15,    9,  507,  237,  174,   16, 5456,    4, 1697,  297, 1870,
           18,  223,  337, 1280,  912, 5380,   16,   58, 5238,  303, 3514, 5041,
            5,    1,    1,    1,    1,    1,    1],
        [   2,  104, 7505,   49, 5012,  182, 5720,    4,  112, 3514, 4316,   20,
            4,   14,   61,  141, 1030, 3242,  671, 2940,   48, 2655,  681,    4,
          136, 3154,  212, 2865,   20,   76,   29, 1128,   74,   23, 9157,  330,
          352,  608,    5,    1,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[  67,    7, 2932,  492, 5332,   62,    4,   85, 1686,    9,   17, 2760,
            4, 4089, 3002,   55, 9695,    7, 2551,   12,  251, 1288,   46,   13,
         3716,  824,   18,  366,   17,  220,   66, 5150,   48,    7, 2551,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  70,   73,   24,  283,  126,  540,   42,   38,  187,  154,    7, 3397,
           35,  484,   35, 1761, 4976,    9,  803, 3237,    6,  251,  218, 1587,
           12,  203,    6,  416,  387, 1955,   10, 3397,  271,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  25,  296,    7,  596,    8,    7,   13,  870, 1212, 2109,    6,   84,
            4,  125,    7,  248,  825,    9,  155,  282,   25,  281, 3148,  106,
         2375, 4188,   26,  120,   25,   11,   57,   13,  149,    6,   54, 1276,
            8,   13, 2892,   13,  870, 1212, 2109,    5,    2],
        [ 115,    4,  103,   33,  567,   12,   51,  900,   18, 4577,    4, 9550,
            4, 6672,  689,   11,   18, 8518,   10,   25,    4,   25,   63,   86,
         2373,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 3646,  859, 2191,   13, 7291,  227, 2399,  132,   13,  267,   48,
           12,   97, 1203,  372,   55,   13, 2650,    4,    8,    7,  230, 2191,
           70,   19,  583,    7, 7291, 1466, 1098,   62,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,  115,    4,    7,  409,   17,   21,   11,    6,  113,   13,  324,
         7052,    4,  835,   10, 2154,  724,    4, 1073,    7, 8166, 1878,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   9, 1146,  473,  464,    4, 2593,    6,   85,   20, 5371,  759, 2533,
         1508,    4,    8, 6875,   48,  248, 1072, 7858, 4070,    6,   12, 7050,
         6293,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  91, 1435,   85,   39, 1793, 2811,  591,   17, 1581,  820,  439,   12,
         2900, 5966,  588,  144, 4821,   48, 5031,   79,   13, 2173,   12,  906,
         3602, 6440,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 115,  120, 1183,  884,    6,   25,    4,   38, 6435,    4,  148, 2396,
          501,    6, 6877,   13, 1838,   20,   42,   11,  197,   25,   73,   11,
           18, 1008,    4,  125,   17, 9835,   26, 2129, 4214,   54,  109, 2107,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [1250,    4,  554,    4,   21,   26,   79,  103,   24,   63,   77, 2202,
          540,    9,   13, 6292,    4,   67,   24,   73,  288,  150,  217,  494,
          119,    7, 1974,  122,    7,   94, 4173,  336,  170,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24,  203,    6, 1806,  469,    6, 1181,   33, 3297,    5,   33,
           26,   70,   17, 1511,   62,  100,    5,   24, 6604,  346,   77,    7,
         2216,   86,   96,    9,    7, 2327,   54,   79,  238,   79,    7, 1583,
          458,    6,    9,    7, 2327,   54,    5,    2,    1],
        [  29,    4,   89, 2837,    9, 7808,   54,  487,  120,   56,   15, 1252,
          552,   69,    7, 5082,    4, 9031,   48,   77,   12,   13, 5827,    4,
            8,   19,  487,  826,   80,   70,   26, 1592,  168,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8, 2523,    4,  109,  115,   86,   17, 2523,    4,   80, 1111, 1345,
          581,    4,    7, 4503, 2041,   12,   13, 2922, 7931,   54, 2509,   12,
         6345, 1274,   17,  164,  205,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   7, 7771,   12,  552,  237,    6,    4, 3144,    6,    4, 4987,  238,
            6,    8, 3571,    6,  842,  110,  270,   10,    7,  464,   19, 2138,
         5429,   54,    7,  227, 3110,  187, 4987,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,  168,   11,    6,   13, 1636,   12,   17, 4716,    4, 3243,    7,
          521,  455,  525,  480,    6,    9, 5087,    8, 1849,    4,  811, 1558,
           37,  174,  922,  131,   33,  264, 3043,   12, 7262,   35,    6,  234,
          247,    8, 1580,   35, 7227, 3667,    5,    2,    1],
        [  24,   11,   57, 2115,   54,  106, 3022,   10, 3156,    4,  244,  461,
           12,    7, 1402,   17,  169,  274, 4825,  982,   69,   13,  488,   35,
         6753, 1636,    4,   67,  204,  185,   12,  117, 3144,    6,   63,   79,
          488,   79,  700,  608,    5,    2,    1,    1,    1]],
       device='cuda:0'), 'cluster_tokens': tensor([[37, 37, 28, 50, 49, 31, 11, 37, 83, 37, 37, 23, 11,  2, 56, 37, 29, 37,
         29, 37, 50, 56, 11, 37, 32, 38, 35, 77, 37,  6, 85, 29, 31, 37, 29, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37],
        [50,  6, 38, 49, 37, 36, 11, 38, 35, 59, 37, 16, 38, 35, 38, 35, 94, 37,
         35, 35, 37, 50, 50, 50, 37, 38, 37, 35, 35, 44, 37, 16, 44, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 49, 37, 56, 37, 37, 37, 35, 77, 35, 37, 37, 11, 37, 37, 34, 24, 37,
         37, 32, 37, 75, 32, 37,  9, 28, 85, 37, 37, 85, 77, 37, 38, 37, 49, 94,
         37, 37, 49, 37, 35, 77, 35, 11, 83],
        [83, 11, 37, 37, 32, 37, 38, 35, 35, 94, 11, 56, 11, 32, 85, 85, 35, 29,
         37, 37, 11, 37, 85, 83, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  2, 31, 88, 37,  9, 38, 49, 37, 37, 37, 31, 37, 38, 35, 35, 37, 37,
         10, 11, 37, 37, 37, 88, 50, 38, 88, 37,  9, 19, 35, 31, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 32, 37, 37, 85, 37, 83, 37,  2, 94, 11,  2, 37, 38, 35,
         11, 85, 37,  2, 33, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 28, 37, 24, 11, 28, 37, 37, 77, 34, 24, 28, 56, 11, 37, 49, 31, 34,
         24, 24, 35, 37, 37,  9,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [50, 59, 37, 38, 28, 94, 31, 37, 17, 73, 24, 37,  9, 28, 77, 85, 29, 31,
         59, 37, 37, 32, 37,  9,  9, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 50, 88, 37, 37, 11, 38, 83, 11, 50, 31, 38, 37, 35, 37, 35, 77,
         11, 85, 82, 37,  6, 85, 35, 59, 11, 37, 37, 94, 85, 50, 29, 49, 37, 31,
         11, 83, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 83, 11, 37, 85, 37, 37, 38, 85, 50, 59, 36, 37, 37,  9, 11, 37,
         38,  6, 83, 59, 38, 35, 75, 37, 38, 35, 37, 56, 83, 37, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 38, 37, 35, 35, 37, 31, 37,  9, 11, 37, 85, 50, 37,  9, 31, 37,
         11, 38, 31, 37, 50, 37, 28, 83, 77, 37, 37, 38, 49, 37, 83, 37, 37,  9,
         77, 37, 37, 37, 38, 49, 11, 83, 37],
        [83, 11, 37, 32, 37, 29, 49, 31, 37, 38, 77, 35, 85, 37, 37, 94, 11, 29,
         31, 50, 37, 37, 83, 11, 37, 38, 31, 59, 37, 50, 85, 49, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 83, 11, 37, 83, 83, 37, 83, 11, 37, 34, 24, 83, 11, 37,  9, 94, 37,
         37,  9, 29, 49, 94, 37, 34, 60, 37, 85, 85, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 37, 85, 35, 37, 11,  9, 37, 11, 94, 83, 37, 37, 38, 37, 31, 37,
         37, 37, 37, 24, 38, 31,  8, 49, 37, 38, 28, 35, 94, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 37, 94, 37, 37, 32, 11, 88, 37, 38, 35, 35, 35, 37, 37,
          2, 37,  2, 11, 38, 35, 77, 35, 31, 37, 37,  2, 29, 37,  9, 38, 37, 35,
         77, 37,  9, 38, 23, 29, 11, 83, 37],
        [38, 85, 77, 49, 49, 37, 28, 37, 28, 11, 37, 32, 37, 37,  9, 37, 85, 59,
         32,  2, 37, 37,  2, 38, 23, 94, 11, 37, 83, 50, 37, 37,  9, 37, 85, 37,
          2, 37, 50, 75, 11, 83, 37, 37, 37]], device='cuda:0'), 'lengths': tensor([37, 35, 45, 27, 34, 25, 27, 28, 38, 35, 44, 35, 31, 33, 44, 42],
       device='cuda:0'), 'ntokens': 560}, 'target': tensor([[ 147, 1815,  280,  632,    4, 3596, 2163,    4, 3652, 1349,    4,   88,
           58, 5771,  212, 1415, 2369,  243,  315,  530,   15,    4,   14, 1818,
         2772,  911, 1105,   18,   28, 6278,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 327,  123,   32,  466, 4264,   42,   38,  967,  705,   14, 6374,   35,
          128,    6,   35,  806, 1576,  122,   35,  748,  307, 1034,  560,  548,
          345,   18,  105,  351, 1468,   23,  441, 4887,   78,   40, 6374, 8306,
            5,    2,    1,    1,    1,    1,    1],
        [ 404, 1391,   14,  617,   16, 3526,  221, 4741,  303,  847,  428,    9,
          302,  259, 3184,   15,  129,  732, 3716,  398,   81,  217,  731,   49,
         1160,   37,  515, 4985,   15,    4, 1939,   90,  499, 1089, 1145,   16,
           90, 3526,  221, 4741,  345,    5,    2],
        [ 222,   41,  105, 4365,   98,  350, 8062, 2301,    4,  472,  160, 1597,
           16, 4545,   47,   39,    6, 1727,  951,    4,   76,   41,  385,   47,
         2631,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 864,  191, 3142,  208,   41,  118, 8361,    4,   23, 9674,   52, 3526,
          262,  657, 1203, 3165, 4755,    4,   16,   14, 1640,   20, 1100, 1171,
           58, 8847,  129, 8361,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 147,  173,  160,    4,    9,  102,  840,  989,    4,   50,   36,  139,
           52, 1225, 5887,   27,    4,   47,  317, 3193, 8589,    4, 1364,   23,
         4784,   20, 2190,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 228, 1437,   83,  157, 1439,    6,  497, 5371,  767, 6045, 5133,  171,
            6,  812,  365,   16,  302, 1524, 6842, 1612,  243, 9105, 1756, 2391,
          398,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 738, 2727,   39,  141, 4519, 2897, 1812,  653,    4,   50, 1185,  820,
          787,   23, 5449,    6,   20,  458,  532,  118, 8631,  243,  556,   15,
           83, 4008,   49, 5961,   45, 8127,   49, 1441,  176,  932,  357,    5,
            2,    1,    1,    1,    1,    1,    1],
        [ 222,   41,  361, 1000, 5679,   44,   38, 7502,    4, 1513,  130,  197,
         4901,  237, 1063, 2658,   38, 9527,  358,    4,  123,   41,   75,   47,
         2425,    4,  268,   14, 3224,   22, 1034,    6,   20, 9250,  130,  124,
         6352,    5,    2,    1,    1,    1,    1],
        [6703,   27,   36,    4,   90,  227,  152, 1177,   15,   32,  231,  466,
            9,  151, 6919,    4,  921,   32,  123,    9,  102, 1083, 1872, 1368,
          149,   14,  310, 7841,    9,  536, 4542,  208,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 298,   83,   32,  299, 4969,  203,    6, 1806,  469,   18, 2259,    5,
          402,  421, 1294,   36,    5,  674,   20, 7760,   15,  374,    9, 2968,
         9403, 4450, 1096,  301,   54,   15,   16, 1096, 5123,  129,  301,   54,
           15,    6,    5,    2,    1,    1,    1],
        [1462, 2927,  217,  285,   18,   59, 2628,   22, 1277,   90,  330,   22,
         1252,   14, 4033,   51,  587,   18,   16, 2578,  811, 1076, 1158, 1350,
           16,   31,  163,   28, 1481, 1277,    4,   34,  647,  730,   82,    5,
            2,    1,    1,    1,    1,    1,    1],
        [ 441, 4447,  510,    4,   47,  485,   29, 4447,  510,    4,  177, 8830,
         1681, 3362,   78,   14, 4308, 3104,  141, 4054,  119,   59, 2174,   20,
           49, 6345, 2709,    4,   14,   75,   61,   58,  758,  651,    5,    2,
            1,    1,    1,    1,    1,    1,    1],
        [ 146,  377, 3998,  721,   49,  869,  458, 1374,    4, 2865,   15, 5839,
           22,  174, 5189,  549,   16, 4553,   22, 3016,  163,  420,   28,  102,
          497,    4,    9,  102,   31,   14,  301, 3110,  187, 5839,  223, 1304,
           37,  153,    5,    2,    1,    1,    1],
        [ 504,  208,   41,   58, 4886,    4,   60,  350,  500,   57,  160, 1597,
           15,    9,  507,  237,  174,   16, 5456,    4, 1697,  297, 1870,   18,
          223,  337, 1280,  912, 5380,   16,   58, 5238,  303, 3514, 5041,    5,
            2,    1,    1,    1,    1,    1,    1],
        [ 104, 7505,   49, 5012,  182, 5720,    4,  112, 3514, 4316,   20,    4,
           14,   61,  141, 1030, 3242,  671, 2940,   48, 2655,  681,    4,  136,
         3154,  212, 2865,   20,   76,   29, 1128,   74,   23, 9157,  330,  352,
          608,    5,    2,    1,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([32, 38, 43, 27, 30, 29, 27, 37, 39, 34, 40, 37, 36, 40, 37, 39],
       device='cuda:0'), 'ntokens': 565, 'nsentences': 16}
##################### {'id': tensor([112117,  87108, 184670,  14414, 220440, 128972,  72058, 216786,  24203,
          2639,  76815,  60402, 199864, 224405, 197731, 129055],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[-8.5449e-04,  3.4180e-03,  7.0496e-03,  ..., -6.7139e-04,
          2.5635e-03,  4.5166e-03],
        [-5.9814e-03, -5.8899e-03, -5.7373e-03,  ..., -9.2773e-03,
         -8.2092e-03, -5.7678e-03],
        [-4.2725e-04, -1.3428e-03, -2.9602e-03,  ..., -4.8828e-04,
         -1.8311e-03, -2.1667e-03],
        ...,
        [ 4.2725e-04,  2.7466e-04, -3.0518e-05,  ...,  0.0000e+00,
         -2.1362e-04, -6.4087e-04],
        [-5.7983e-04, -3.3569e-04, -6.4087e-04,  ...,  4.0283e-03,
          2.1362e-03,  2.6550e-03],
        [-8.2397e-04, -7.0190e-04,  8.2397e-04,  ..., -1.5839e-02,
         -2.5513e-02, -2.2552e-02]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([104960, 104960, 104960, 104960, 104960, 104960, 104960, 104960, 104960,
        104960, 104960, 104960, 104960, 104960, 104960, 104960],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2,  146,  645, 4806,   44, 1135,   76,   32, 2777,  397, 1071,  257,
          196,    9, 5022,   42,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,  127,  582,   10,  505,  481, 4161, 4096,    4,  136,   32,
          944,  306,    4,  306, 3408,   88,   36, 6716, 1796, 4392,   15,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   30,  751,  472, 3908, 3588,   78, 2424,   59,   18,
          236,  668,  191,    4, 2123,  887, 1709,    4,   61,  149,  141, 1100,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,   76, 5261,  986,   77,   58, 4983,    4,   23,   39,   58,
         1104, 8589,  536, 1687, 1354,  297,   20, 1282,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   41, 1960,  286, 6485,   15, 2798,    4,  268,   43, 6485,   76,
            4,  519,  268,   43,    9,  151, 5778,  702,    4,    9,  102,  686,
         6485,   20, 2798, 4899,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  209,   30,    9,  493, 6001,  709,  466, 6116,   16,  482,
           27,   36,    9,   23, 3740,   35,  885, 1161,  300, 2564,   23, 7788,
           12, 1872,  827, 1151,    9,  472,  679,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  280,   30, 8679,    4,    9,   23, 4542,  212, 4465,    6,
          971, 1672,   28,  186,    4,   14,   52, 4102,  662, 1840,  819,   15,
          959,  249, 7213,  280,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  104,    4,   74,  231,  351, 3710,   61,  328, 1379,    4,   76,
          291,   18,  729,   22,  712,   60,   23,  489, 1245,  732,  897, 4881,
         1967,   15,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  146,  796, 1654,  805,  550,   82,   30,   77, 4684,  200,  683,
           18,  662,  404,  587,   98, 1990,   59,  259,    4,   50,   81,  186,
          314,   61, 3010,  395,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  209,  257,  184,  200,  335,  119,    4,   50,   31,   40,
         2367,  737,  153,    9,  478,  141,  997,  313,    4, 1939,   40, 2367,
          737,  153,  112,  256, 1024,    4, 2782, 9039,   31,  534,    5,    1,
            1,    1,    1,    1,    1,    1],
        [   2,  738, 5478,   20,  997,   27,    4,   50,   36,  454,  912, 3218,
          129, 1977, 8994,    6,  178,    4,   61,   14,   32, 4349,   28, 2305,
            4,   61,   14,  149, 4228,  310,   28, 2305,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   72,  705,    4,   32,  702,  459, 2586, 1689,    9,  141, 1521,
            4,   14, 3409, 2294,   20, 7434,   15,   39,   14,  377,  176,  152,
          241,  181,  165,  886,  249,  390,  158,   37, 6749,   59,  184,  156,
           22,  219,  530,   18,  130,    5],
        [   2,  396, 7666,   15, 8993,   22, 3604,   37,   78, 4246, 1380,    4,
           74,   32,   98,   23,  880,  357,   20,   60,  157, 7058,   22,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 3167, 3582,   81,   75, 3917, 1353,    6,  114,   81,   52, 3880,
         5235,  262, 1935,  221,    6,   39, 4522,   18,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2, 5939,   27,    4,   14, 3897,  891,  833,   27,    5,    5,    5,
         1281,   41,    4,  231,  157,   83, 1413,  177,  317,   15, 2164,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   78,  163,   40, 6078, 6261,    9,   30,  314,  182,
          102, 2643,    4,  405, 1963,  285,   37,   48, 1597,   28,  208,   16,
         7814,   28,  186,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[   7,  630,   26,   44,  347,   63,   24,  499,    9, 4970,   91, 4430,
         1065,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  67,   24,   63,  204,  142,   10,   51, 8963,   54, 7377, 2302,    6,
            4,   67,   24,  296, 1771,    8, 1771,   12, 3883,    6,   10,   87,
           33, 3021,  111,    5,    2,    1,    1,    1,    1],
        [  29,   33,   26,  204,    7,  733, 2532, 1296,   55, 5262,  236,  668,
          191,    4, 2123,  887, 1551,    4,  116, 3924,   69,   91, 2672,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [  24,   66,   39, 5261,  429,   10,   77,   12,    7, 1546, 2879,   17,
         4433,  336,    7, 4389,    6,   12,  108, 1507,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  53,   11,   57,   86,  961, 9132, 4012,  125,   53,   63, 9132,    4,
           67,  125,   53,   11,   57, 1074,    9,   13, 3317,    9,  166, 2307,
          169,  229, 9132, 4012,    5,    2,    1,    1,    1],
        [   8,   19,   79,    6,  510, 1755,   48,   33,    9,   89, 1213,  709,
            4,    8,   21,  115,  931,    9,    7, 4141, 5670,   12,    7, 2811,
           12, 1644,  827, 1151,    4,  203,  679,    5,    2],
        [  19,  144,    7, 6530,   12,  378, 1387,   10,   33, 1335, 4940,  415,
         1672,  148,  144, 5853,   13, 2200, 2050, 1032, 2180,   18, 1051,  737,
            5,    2,    1,    1,    1,    1,    1,    1,    1],
        [  24,    4,  100,   77,  218, 1369,   69,   33,  943,    4,   63,    9,
          783,   18, 1775, 3042,  258,  121,   22,  199,    7, 1261,   12,  282,
           69,   33,  943,    5,    2,    1,    1,    1,    1],
        [   7,  479, 1708,  267,  283,   34,   17,   85,   17,  183,    4, 1308,
           34, 1211,   25,   66,   10,  172, 5039,  155,  282,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  19,   66,  735, 1446,   17,   19,   34,  142,   10,   51,   39, 3698,
           69,   91,  279,    4,    8,   19,  217,   39, 3698,   69,   33,  723,
            4,    8,   29,   19, 2153,   80,   21,    5,    2],
        [   8,   91,  279,   10, 3088,   26,   17, 1645,   84,   63, 1224,   12,
          422,  238,   35,  242,   54,   17,   24, 4733,  111, 2214,    4,   17,
          555,   94, 2214,    5,    2,    1,    1,    1,    1],
        [  19,  154,   24,  618,    9,   13, 1504,  166,  188, 1948, 2035,  122,
         2361, 1905, 2294, 5351,    6,   10,    7,   13,  140, 1841,    6, 2278,
           12, 2468,  324,    6,    5,    2,    1,    1,    1],
        [  24,  113,  703,   17,  117, 4889, 1862, 6297,    6,   73,  172,  468,
            7, 1081,   17,   24, 5309,  111, 9738,   71,   94,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  17,   11,    6,  347,   25,  598,  100,   13, 3164, 2145,  120,   25,
          388,   69,  251, 2636,   35, 1105,   18,  945,  728,  221,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 166,   26,  133,  528,    4,    7, 3899,   26,   46,   25,  135,    4,
           77,  422, 3772,   63,  735, 4493,   12,  133,  946,  214,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   17,   10,  110,   34,   13,  999,  498,   10,    7,  432, 5203,
            4, 1057,   10, 6853,  155,  447, 2079,   37,  128,    8,  598,   56,
         3856, 3267,    5,    2,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'cluster_tokens': tensor([[37, 94, 85, 82, 83, 85, 38, 83, 37, 28, 50, 24, 24, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 83, 49, 37, 38, 29, 49,  2,  1, 37, 11, 37, 38, 49, 50, 37,
         50, 37,  9, 37, 37, 85, 37,  2, 83, 11, 83, 37, 37, 37, 37],
        [83, 37, 85, 83, 37, 50, 49, 49, 37, 31, 35, 35, 77, 11, 34, 73, 24, 11,
         83, 31, 37, 50, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 38,  9, 94, 37, 50, 37, 37, 38, 35, 37, 85, 37, 37,  5, 37, 37,
         37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 77, 83, 49,  2, 56, 37, 37, 85,  2, 11, 37, 37, 37, 85, 77, 49,
         37, 37, 36, 37, 37, 50, 85, 49,  2, 56, 11, 83, 37, 37, 37],
        [37, 38, 37, 37, 35, 77, 31, 37, 37, 37, 38, 35, 11, 37, 37, 83, 37, 37,
         37, 94, 23, 37, 37, 94, 37, 38, 35, 35, 11, 38, 35, 11, 83],
        [38, 85, 37, 32, 37, 49, 83, 37, 37,  2,  9, 38, 35, 50, 85, 31, 37, 38,
         35,  2, 38, 35, 38, 35, 11, 83, 37, 37, 37, 37, 37, 37, 37],
        [38, 11, 37, 50, 50, 56, 37, 37,  9, 11, 85, 37, 35, 35, 35, 83, 38, 35,
         35, 37, 37, 94, 37, 32, 37, 37,  9, 11, 83, 37, 37, 37, 37],
        [37, 94, 37, 37, 49, 85, 37, 37, 37, 24, 11, 50, 85, 88, 37, 85, 37, 83,
         33, 37, 32, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [38, 85, 83, 31, 37, 38, 85, 49, 37, 38, 38, 32, 37, 50, 50, 11, 37, 38,
         38, 38, 32, 37, 37, 94, 11, 37, 83, 38, 49, 37, 37, 11, 83],
        [37, 50, 50, 37, 86, 85, 37,  6, 37, 85, 56, 37, 28, 83, 38, 77, 49, 37,
         38,  2, 83, 49, 11, 37, 50, 56, 49, 11, 83, 37, 37, 37, 37],
        [38, 59, 38, 49, 37, 37, 94, 37, 85, 83, 38, 35, 31, 50,  2, 94, 37, 37,
         37, 37, 35, 35, 37, 35, 37, 32,  2, 37, 11, 83, 37, 37, 37],
        [38, 83, 88, 37, 37,  2, 94, 88, 37,  6, 83, 29, 37, 56, 37, 38,  2, 83,
         36, 37, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 37, 59, 37, 37,  9, 38, 37, 37, 31, 37, 50,  2, 38, 35,
         35, 77, 38, 35, 37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83,  2, 11, 37, 94, 85, 11, 37, 59, 11, 50, 28, 56, 85, 83, 98,
         37, 83,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 37, 85, 37,  2, 49, 37, 37, 37, 35, 11, 49, 37, 59, 37, 37,
         38, 77, 35, 37, 59, 38, 35, 31, 11, 83, 37, 37, 37, 37, 37]],
       device='cuda:4'), 'lengths': tensor([15, 29, 25, 22, 30, 33, 26, 29, 23, 33, 29, 30, 23, 25, 24, 28],
       device='cuda:4'), 'ntokens': 424}, 'target': tensor([[ 146,  645, 4806,   44, 1135,   76,   32, 2777,  397, 1071,  257,  196,
            9, 5022,   42,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,  127,  582,   10,  505,  481, 4161, 4096,    4,  136,   32,  944,
          306,    4,  306, 3408,   88,   36, 6716, 1796, 4392,   15,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   27,   30,  751,  472, 3908, 3588,   78, 2424,   59,   18,  236,
          668,  191,    4, 2123,  887, 1709,    4,   61,  149,  141, 1100,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,   76, 5261,  986,   77,   58, 4983,    4,   23,   39,   58, 1104,
         8589,  536, 1687, 1354,  297,   20, 1282,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  41, 1960,  286, 6485,   15, 2798,    4,  268,   43, 6485,   76,    4,
          519,  268,   43,    9,  151, 5778,  702,    4,    9,  102,  686, 6485,
           20, 2798, 4899,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  209,   30,    9,  493, 6001,  709,  466, 6116,   16,  482,   27,
           36,    9,   23, 3740,   35,  885, 1161,  300, 2564,   23, 7788,   12,
         1872,  827, 1151,    9,  472,  679,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  280,   30, 8679,    4,    9,   23, 4542,  212, 4465,    6,  971,
         1672,   28,  186,    4,   14,   52, 4102,  662, 1840,  819,   15,  959,
          249, 7213,  280,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 104,    4,   74,  231,  351, 3710,   61,  328, 1379,    4,   76,  291,
           18,  729,   22,  712,   60,   23,  489, 1245,  732,  897, 4881, 1967,
           15,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [ 146,  796, 1654,  805,  550,   82,   30,   77, 4684,  200,  683,   18,
          662,  404,  587,   98, 1990,   59,  259,    4,   50,   81,  186,  314,
           61, 3010,  395,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  209,  257,  184,  200,  335,  119,    4,   50,   31,   40, 2367,
          737,  153,    9,  478,  141,  997,  313,    4, 1939,   40, 2367,  737,
          153,  112,  256, 1024,    4, 2782, 9039,   31,  534,    5,    2,    1,
            1,    1,    1,    1,    1,    1],
        [ 738, 5478,   20,  997,   27,    4,   50,   36,  454,  912, 3218,  129,
         1977, 8994,    6,  178,    4,   61,   14,   32, 4349,   28, 2305,    4,
           61,   14,  149, 4228,  310,   28, 2305,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  72,  705,    4,   32,  702,  459, 2586, 1689,    9,  141, 1521,    4,
           14, 3409, 2294,   20, 7434,   15,   39,   14,  377,  176,  152,  241,
          181,  165,  886,  249,  390,  158,   37, 6749,   59,  184,  156,   22,
          219,  530,   18,  130,    5,    2],
        [ 396, 7666,   15, 8993,   22, 3604,   37,   78, 4246, 1380,    4,   74,
           32,   98,   23,  880,  357,   20,   60,  157, 7058,   22,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [3167, 3582,   81,   75, 3917, 1353,    6,  114,   81,   52, 3880, 5235,
          262, 1935,  221,    6,   39, 4522,   18,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [5939,   27,    4,   14, 3897,  891,  833,   27,    5,    5,    5, 1281,
           41,    4,  231,  157,   83, 1413,  177,  317,   15, 2164,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1],
        [  92,   27,   78,  163,   40, 6078, 6261,    9,   30,  314,  182,  102,
         2643,    4,  405, 1963,  285,   37,   48, 1597,   28,  208,   16, 7814,
           28,  186,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([16, 24, 25, 21, 29, 32, 29, 27, 29, 35, 33, 42, 24, 21, 24, 28],
       device='cuda:4'), 'ntokens': 439, 'nsentences': 16}
##################### {'id': tensor([ 49055, 182923,  11203,  18842, 175653,  89808,  11845, 158266],
       device='cuda:2'), 'net_input': {'src_tokens': tensor([[ 0.0324,  0.0426, -0.0637,  ...,  0.0023,  0.0045,  0.0041],
        [-0.0007, -0.0004, -0.0007,  ...,  0.0419,  0.0591,  0.0769],
        [-0.0025, -0.0030, -0.0028,  ...,  0.1869,  0.1562,  0.1243],
        ...,
        [-0.0059, -0.0036, -0.0026,  ...,  0.0432,  0.0465,  0.0000],
        [ 0.0013,  0.0009,  0.0010,  ..., -0.0008, -0.0002,  0.0000],
        [-0.0052,  0.0089,  0.0112,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:2', dtype=torch.float16), 'src_lengths': tensor([154400, 154400, 154400, 154400, 154400, 154399, 154399, 154240],
       device='cuda:2'), 'prev_output_tokens': tensor([[   2,  400,   41,  113,  208,  123,    4, 1364,  256,  285,  247,  365,
         2301, 1657,    4,  585, 1937,   35, 5377,   45, 2446,   37,   35, 2507,
           22,  235,   18, 2112,   28, 1765,    4,   14,  704,   28,  102, 5235,
            4,   74,  273,  696,   20,   16,  871,  845,    5,    1,    1,    1,
            1,    1,    1],
        [   2, 1607, 6752,   15,   16, 7333,   22,   78, 3826, 6304,   16, 1607,
         1169, 1934,  683,  165,   16, 1607, 4682,   83, 1607, 1417, 2259,    4,
           16,   30,   27, 4036,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  402,  910, 5810,   32,  716,    4,   14, 8885,   23, 1981, 4397,
           20,   16,   14,  285,  243, 2097,  165,    6, 6092,   28, 3261,    4,
           16,   56, 3952,  191,   28,  151, 3798,   60, 3876,   62, 2687,   35,
         3005,   59,  380,    4, 1030, 1053,   22,    4, 2938,  831,   37,  285,
         2006,  165,    5],
        [   2,   99,  178,  306,  883,  649,  160, 1350, 4246,   49, 3462, 6276,
         6575,   15,   44, 4072, 3613,  217, 3704, 1029,  237,    4,  576,  533,
          494,   15,    4, 1104,  152,  345,   22,   49, 6548,   15, 5571,  184,
          195,   37,   59,   18,   28,  127,   16,   29,  463,    5,    1,    1,
            1,    1,    1],
        [   2,   64, 1210, 2968,  642,   82,   36,  171,   22, 1895,  856,    4,
           16, 1210, 2968,  642, 1398,   31,  163, 1481,    4,  403,   31,  317,
         6000,   16,  198,   58, 3906,   95,    6, 1803,   15,  769,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,   64,  454,  139, 1497,    4,   50,   36,   52, 4507,   20,  178,
            4,   74,   32,   60,  536,  171, 4294,  156,  381,    4, 8365, 2055,
           16, 3778,   15,  201,   97, 2199,    5, 2289, 5437,  776,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2,  396, 1423,    4, 1092,  338,  455,   16,  355,  919,    4, 6803,
           22,   52, 5779,   78,  798,  978,    4,  750,   43, 5232,    9,  151,
          437, 2174,   15,   60,  462, 7588,   22,   16,  674, 1243, 1755,  311,
           48, 1040, 6114,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   2, 6372,   18,   81,   75,   14, 6612,   37, 4253,   23,  808, 3093,
           20,   39,  193,   60,  351, 4685,    4, 1444,    6, 7637,   20,  193,
          745,   81,   43, 5238,   16,   32,  208,   43,  765,  221,   61,  151,
         2125,  790,  715,  311,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:2')}, 'transcript': {'tokens': tensor([[  29,    4,   79,   25,   73,  150,    4,   89, 4469,   26,   55,  961,
          264,  422,   35, 8485, 5766,    6,   17,   63,   13,  509, 4223,   10,
            7, 1081,  108, 3257,    8, 3500,  283,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [1167, 4491,    8,    7, 1927,   55, 1666, 2885,   54,    8, 1167, 7395,
            8, 1167, 1221,   66, 1417, 1181, 1167,    4,    8,   33,   26,   13,
         1968,  279,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   24, 1639,   69,   97,  927,  586,   54,    7, 8258,   12,    7,
         5317,    6,    8,    7, 4749, 5242,    4,    8,  513,   10,   13, 1962,
           35,   45,  293,  122,  160,    4,  747,   35, 1184,  675,  458,    4,
         2497, 1905,   35, 1203,   93,  445, 1201,    5,    2,    1,    1],
        [  84,  162, 2073,   45,   37, 1032,    9,  380, 1563, 3834,   12, 3462,
         2459, 3979, 7935,  445,   44, 3572,   54,   85,    7, 1449,  636,    4,
          838,  510,  804,  533,  810,    4, 2033,   54,   69,    7, 6162,    4,
          378, 6953, 4474,  131, 5689,    6,    8,   29,   69,    5,    2],
        [   8,   21,   34,  384,  827,  119,  829,  333, 1127,  183,    4,    8,
          333, 1127,  183,    4,   19,  144,   10,  884, 1222,  103,   19,  451,
          116, 1336,  235, 1025,   19,   34, 1708,    8,  508,  132,    8, 2267,
           57, 1222,   33, 3454,    5,    2,    1,    1,    1,    1,    1],
        [   8, 1645,  113,    4,   84,   11,    6,   13, 3974,   80,  138,   10,
         1799,   71,  108, 9161,   62,   35,  786,    4, 8365,   54,    8, 3975,
          179,   12,    7, 2199,  119, 1910,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  33, 1037,    4,  227, 3287,  455,    8,  267, 4856,    4, 5016,   13,
          798,   35, 8515, 4533,  120,   53,  162, 1074,    9,   13,   46, 2318,
           13,  391,   35, 2561, 2482,  749,  221,   35,  412,   71,   13,  415,
           59,   59, 1265,  922, 4371, 5124,    5,    2,    1,    1,    1],
        [ 103,   25,  274,  244,    7, 1406, 1323, 4021,   85,    7, 3447,    6,
           10, 3979,   46,    9,  218, 1289,    4, 7926, 3716,    6,   46,   24,
          150,  134,  142,  132,    4,    8,   24,  150,   17,   53,   11,   57,
          115,   85,   39,   77,   35, 2371,  747,    5,    2,    1,    1]],
       device='cuda:2'), 'cluster_tokens': tensor([[83, 11, 37, 37,  6, 59, 11, 37, 94, 85, 37, 49,  2, 28, 38,  9, 94, 37,
         37, 85, 37,  2, 36, 37, 37, 56, 37, 47, 37, 56, 49, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [26, 56, 37, 37, 49, 37, 83,  9, 49, 37, 26, 32, 37, 26, 94, 85,  2, 31,
         26, 11, 37, 37, 85, 37,  2, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 38, 31, 37, 38, 35, 35, 49, 37, 94, 37, 37, 49, 37, 37, 37, 49, 94,
         11, 37, 85, 37, 37,  2, 38, 35, 35, 35, 35, 11, 30, 38, 35, 35, 77, 11,
         83, 50, 38, 35, 35, 35, 32, 11, 83, 37, 37],
        [37, 85, 38, 35, 77,  2, 37, 77,  2, 56, 37,  2, 35, 28, 29, 35, 82, 29,
         49, 37, 37, 38, 77, 11, 33, 35, 35, 35, 35, 11, 29, 49, 37, 37,  9, 11,
         49, 31, 33, 37,  9, 37, 37, 83, 37, 11, 83],
        [37, 37, 85, 38, 35, 75, 49, 50, 50, 24, 11, 37, 50, 50, 24, 11, 38, 85,
         37, 88, 37, 37, 38, 85, 83, 38, 35, 24, 38, 85, 37, 37, 88, 37, 37, 38,
         77, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37],
        [37,  6, 83, 11, 37, 85, 37, 37, 94, 37, 37, 37, 49, 37, 37, 29, 31, 38,
         35, 11, 29, 49, 37,  2, 94, 37, 37, 34, 75, 24, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 11, 38, 35, 35, 37, 37,  9, 11, 31, 37, 34, 38, 35, 23, 37, 37,
         85, 49, 37, 37, 11, 83, 37, 34, 38, 35, 31, 38, 35, 38, 35, 37, 37, 38,
         35, 35, 35, 31, 28,  9, 11, 83, 37, 37, 37],
        [37, 37, 59, 37, 37, 37, 50, 24, 37, 37, 49, 37, 37, 28, 11, 37, 50, 56,
         11, 36, 32, 37, 11, 38, 59, 37, 49, 37, 11, 37, 38, 59, 37, 37, 85, 77,
         83, 37, 38, 50, 38, 24, 30, 11, 83, 37, 37]], device='cuda:2'), 'lengths': tensor([33, 28, 45, 47, 42, 32, 44, 45], device='cuda:2'), 'ntokens': 316}, 'target': tensor([[ 400,   41,  113,  208,  123,    4, 1364,  256,  285,  247,  365, 2301,
         1657,    4,  585, 1937,   35, 5377,   45, 2446,   37,   35, 2507,   22,
          235,   18, 2112,   28, 1765,    4,   14,  704,   28,  102, 5235,    4,
           74,  273,  696,   20,   16,  871,  845,    5,    2,    1,    1,    1,
            1,    1,    1],
        [1607, 6752,   15,   16, 7333,   22,   78, 3826, 6304,   16, 1607, 1169,
         1934,  683,  165,   16, 1607, 4682,   83, 1607, 1417, 2259,    4,   16,
           30,   27, 4036,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 402,  910, 5810,   32,  716,    4,   14, 8885,   23, 1981, 4397,   20,
           16,   14,  285,  243, 2097,  165,    6, 6092,   28, 3261,    4,   16,
           56, 3952,  191,   28,  151, 3798,   60, 3876,   62, 2687,   35, 3005,
           59,  380,    4, 1030, 1053,   22,    4, 2938,  831,   37,  285, 2006,
          165,    5,    2],
        [  99,  178,  306,  883,  649,  160, 1350, 4246,   49, 3462, 6276, 6575,
           15,   44, 4072, 3613,  217, 3704, 1029,  237,    4,  576,  533,  494,
           15,    4, 1104,  152,  345,   22,   49, 6548,   15, 5571,  184,  195,
           37,   59,   18,   28,  127,   16,   29,  463,    5,    2,    1,    1,
            1,    1,    1],
        [  64, 1210, 2968,  642,   82,   36,  171,   22, 1895,  856,    4,   16,
         1210, 2968,  642, 1398,   31,  163, 1481,    4,  403,   31,  317, 6000,
           16,  198,   58, 3906,   95,    6, 1803,   15,  769,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  64,  454,  139, 1497,    4,   50,   36,   52, 4507,   20,  178,    4,
           74,   32,   60,  536,  171, 4294,  156,  381,    4, 8365, 2055,   16,
         3778,   15,  201,   97, 2199,    5, 2289, 5437,  776,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 396, 1423,    4, 1092,  338,  455,   16,  355,  919,    4, 6803,   22,
           52, 5779,   78,  798,  978,    4,  750,   43, 5232,    9,  151,  437,
         2174,   15,   60,  462, 7588,   22,   16,  674, 1243, 1755,  311,   48,
         1040, 6114,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [6372,   18,   81,   75,   14, 6612,   37, 4253,   23,  808, 3093,   20,
           39,  193,   60,  351, 4685,    4, 1444,    6, 7637,   20,  193,  745,
           81,   43, 5238,   16,   32,  208,   43,  765,  221,   61,  151, 2125,
          790,  715,  311,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1]], device='cuda:2'), 'target_lengths': tensor([45, 29, 51, 46, 35, 35, 40, 41], device='cuda:2'), 'ntokens': 322, 'nsentences': 8}
##################### {'id': tensor([ 11656, 181471,  69328, 139276,  16193, 141932, 199401, 142711, 158478,
         10246,  64110,  89418,  59181,  26490,  35173, 161242,  75550, 138329,
         31623,  54264,  60882, 187629,  90877,  22671, 110427,  50339, 169906,
        167957, 197499, 173348, 224897,  49890, 210801, 216583,  33026,   4375,
        189944, 117690,  96746, 204217, 103759, 155272, 108961,  41677, 154945,
        119745,  40055, 112463,  11723,  82532, 175990,  72227,  23399, 115558,
        155899,  99987], device='cuda:6'), 'net_input': {'src_tokens': tensor([[ 0.0205,  0.0206,  0.0182,  ...,  0.0345,  0.0400,  0.0441],
        [-0.0007, -0.0005, -0.0007,  ..., -0.0014, -0.0015, -0.0014],
        [-0.0008, -0.0007, -0.0004,  ...,  0.0114,  0.0152,  0.0175],
        ...,
        [ 0.0110,  0.0112,  0.0030,  ..., -0.0171, -0.0158,  0.0000],
        [-0.0034, -0.0034, -0.0038,  ..., -0.0018, -0.0004,  0.0000],
        [ 0.0040,  0.0027,  0.0040,  ..., -0.0086, -0.0105,  0.0000]],
       device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200,
        39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200,
        39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200,
        39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200,
        39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200, 39200,
        39199, 39199, 39199, 39199, 39199, 39199], device='cuda:6'), 'prev_output_tokens': tensor([[   2,   64,   31,  ...,    1,    1,    1],
        [   2, 4885, 6114,  ...,    1,    1,    1],
        [   2,  228,   23,  ...,    1,    1,    1],
        ...,
        [   2,  228, 3788,  ...,    1,    1,    1],
        [   2,  202,  329,  ...,    1,    1,    1],
        [   2,  104, 1721,  ...,    1,    1,    1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[   8,   19,  192,  ...,    5,    2,    1],
        [ 251,  148,   66,  ...,    1,    1,    1],
        [1117,   12,    7,  ...,    1,    1,    1],
        ...,
        [   9, 1874,    4,  ...,    1,    1,    1],
        [ 101,  246,    4,  ...,  358,    2,    1],
        [  24,  368,    7,  ...,    1,    1,    1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 38, 85,  ..., 11, 83, 37],
        [50, 50, 85,  ..., 37, 37, 37],
        [37, 37, 37,  ..., 37, 37, 37],
        ...,
        [37, 94, 11,  ..., 37, 37, 37],
        [38, 88, 11,  ..., 11, 83, 37],
        [38, 49, 37,  ..., 37, 37, 37]], device='cuda:6'), 'lengths': tensor([17,  9, 12, 10,  8, 13, 15, 13, 16, 13, 11, 12, 11, 12, 14, 15, 14, 15,
        11, 11, 18, 10,  9,  9, 11, 16, 15, 11, 13, 13, 10, 16, 16, 16, 16, 17,
        14, 12,  9, 15, 12, 12, 16, 17, 12, 13, 12, 11, 12, 13, 16, 13, 15, 14,
        17,  8], device='cuda:6'), 'ntokens': 731}, 'target': tensor([[  64,   31,   51,  ...,    1,    1,    1],
        [4885, 6114, 4286,  ...,    1,    1,    1],
        [ 228,   23, 8326,  ...,    1,    1,    1],
        ...,
        [ 228, 3788,   27,  ...,    1,    1,    1],
        [ 202,  329,   44,  ...,    1,    1,    1],
        [ 104, 1721,  118,  ...,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([18, 10,  9,  8,  9, 14, 15, 15, 11, 20, 13, 17, 14, 13, 12, 27, 17, 15,
        11, 15, 11,  9,  9, 11,  9, 15, 19, 15, 10, 13, 12, 14, 13, 17, 14, 18,
        14, 20,  7, 16, 13, 11, 18, 21, 14, 17, 11, 11, 11, 16, 23, 12, 15, 13,
        16,  8], device='cuda:6'), 'ntokens': 779, 'nsentences': 56}
##################### {'id': tensor([ 57517, 137076, 203015, 201282, 199181,  64343, 223769, 122033],
       device='cuda:6'), 'net_input': {'src_tokens': tensor([[-7.6050e-02, -6.9214e-02, -7.1106e-02,  ..., -3.9673e-04,
          3.0518e-04, -1.2207e-04],
        [-1.9226e-03, -1.1597e-03,  2.2888e-03,  ...,  6.2561e-03,
          8.5449e-03,  8.0566e-03],
        [-8.5449e-04, -2.1362e-03, -2.3499e-03,  ..., -8.2397e-04,
         -3.6316e-03, -5.8289e-03],
        ...,
        [ 0.0000e+00, -3.0518e-05, -6.1035e-05,  ..., -3.0518e-05,
         -6.1035e-04, -7.0190e-04],
        [ 6.1035e-04,  3.6621e-04, -2.7466e-04,  ..., -1.3123e-03,
         -7.6294e-04, -2.2888e-03],
        [ 4.5776e-04, -1.5259e-04, -4.8828e-04,  ..., -2.1667e-03,
         -3.2654e-03, -2.3804e-03]], device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([205920, 205920, 205920, 205920, 205920, 205920, 205920, 205920],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2, 1555,  178,   36,  547,  590,  533, 1328,  491,   49,   23, 8740,
           15, 1668,   42,   38,  967,   82,   40,  905, 8011,    5, 1555,  268,
           14, 3096,   47,  947,  186,  792,    5,  147,   31, 2669,   30,  547,
         1517, 1091,  640,  332,    5,   64,   36, 5121,  257,  210,  212, 8740,
           15, 1668,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  882,   23, 3000,  141,  953, 2778,   49, 5633,   37, 4422, 1125,
         2218, 7525,   15, 2772,   52, 8557, 1031,  119, 1194,   16,   14, 7368,
           78,  157,   95,  232, 1895,  357,    4, 3377,   47, 4898, 2437,  681,
            4,  519,  742,  236,  767,    5,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 3390,   22, 3713, 3195,   15, 1433,   88,   14, 9354,  259, 2379,
           60,  731,    6,  149,  141, 1024,   49,   23,  633, 4859,    4,   16,
           43, 2976,  364,  550,    4,   43, 2976,   28, 1474, 1981, 2916,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  526,  209,   31, 4967,   16, 2064,   20,    9,  771, 4472,    4,
         3626, 3599,  160,   37,    4, 7230,   16, 5196,    4,   52, 2547, 2324,
            4,   16,   31,  574,   57,  242,   52, 4771,   90, 1024,  128,   35,
          710, 3056,   37,   39,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  342,  960,  195,  418,  573,   36,   52, 8247, 2054,   23,   38,
         2137,  706,  271, 2715,  980,    9,   23,   81,   43,  112,  295, 4723,
          732, 2795,   20,   51, 7838,   20,    4,   16,  112, 1536,  950, 6794,
           22,  344,   23, 4723,  732, 2795,   20,  578,   36,    4, 2615,   28,
          127,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2, 2708,  273, 3830, 7043,   75, 9293,  153,    4,  239, 1514,   28,
          151, 4074,   16, 5817,   20,   75,   61,   52,  257,  459,  627, 1539,
          531,  160, 1304,    4,  382,   36, 2542,   78, 2146,    6,  469, 1753,
           16,  657,  709,   16, 5481, 1109,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   2,  146,  201, 2344,   75,    9,  761, 1185,  895, 7251,  462, 2741,
          799, 5844,   20,  410, 3010,    5,  104, 2498,  653,    4,   50,   30,
         2880, 3588, 7915,  815,   35, 1007,  932,  249,   35,  806, 4599,  160,
         3107, 7322,    4,   88, 1653,  462, 2741, 1030, 5844,    4,  118, 4903,
           15, 2225,   60,  149,  462, 2880,   22,    4,   28, 3010,   28,  123,
            5],
        [   2,   99,   27,   98,  462,  912, 3668,   15,  676,   44, 1104, 4017,
           15,    4,  507,   59,  426,    4, 9434,    4,   16,   36, 2344,   75,
          582,   74,  764,  656, 9105,   28, 4302,   15,    4,  745,   98,   16,
          459,   45, 2748,   74,  764,  656, 9105,    4,   16,   47,  149,   30,
            4,   36, 2306,  139,  196,   14, 2389,  176,   98,   23, 7095,    5,
            1]], device='cuda:6')}, 'transcript': {'tokens': tensor([[ 635,   21,  321,   12,  465,   11,   18, 1917,   69,   33, 8291, 2694,
          369,    5,   38,  187,   34,   13,  277, 6385,  125,  635,    7,  660,
         2220,   11,   18,   51,  230,    4,   67,   19,   11,  121,  691,   33,
          115,   55,  640,  215,    4,    8,   21,  188, 1917,   62,   69,   33,
         8291, 2694,  369,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [5553,    4,  131, 1944,  336,   13,  822,  800,   12, 2753, 2317,    4,
          162,  529,   10, 8690, 1115,   21,    8,  229,   21,  261,  143, 1829,
           55,  422, 3772,   10, 4342,    4,   29,   17,   86, 1655,   12,   94,
          169,   14,    4,   67, 1953,    6,   12, 2518,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   8,  333, 2223,   85,   80,    7,  370,  183,    4, 2409, 3195,   12,
          126,  159, 1927, 1408,    4,  281,   12,  134,    4,   91,  723,    9,
            7,  595,    4,    8,   53,  205,   10,  283,    4,   53,  205,   10,
          159,  561,   12,  283,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [ 115,    4,   19,   66, 4989,    8, 3128, 2261,    9,   89,  227, 1411,
            4,  453,  415, 4117,    6,    4, 3835,    8, 8568,    4,  509,  958,
            4,    8,   19,  217, 3872,    6,  241,   54,   13, 3557,   79,   13,
         1392, 2365,   37,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  84,   34,   13, 4495, 5673,   12, 4400,   15,   22, 1010,    6, 2659,
          134,   70,  159,  281,  528,  282, 2476,    6,  162,    4,    8,  244,
         1536,  439,  246,   17,   13, 2767,  282, 2476,   55,  134,   34,   10,
          175, 2237,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  79,  108, 4174, 1504,  848, 2124,   62,    4,   29,  694, 1505,   13,
         6323,    8,   21, 5112,   69,   39,  700, 4100,   73,  827,    6, 1325,
           21,  552,   10, 1109,   55, 8929,    6,    4, 1683,    8, 5367,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [   7,  179, 5039,    6,  199,  336, 1185,  895, 5896,  391,   35, 2404,
         3275,    6,    4,    8,   24,  591,   17,   84,   63,  890, 6600,    6,
           12,  391, 8750, 1289,   17,   24,  220, 1187,  333,  391,   35, 2404,
         3275,    9,    7,  179, 3764,  111,   71,  116,  391, 1289,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1],
        [  33,   26,  442,  106,  391, 7470,    6,   44,   51,  307,    6,    4,
         1598, 2876,    4, 8251,    4,    8,   29,   21,  204, 3673,    6,  132,
          100, 1333,   45, 3884,   37, 6293,    4, 1321,    8, 5953,    6,  100,
         1333,   45, 3884,   37, 6293,    4,    8,   86,  288,   17,    4,   67,
           21,   11,    6, 1223,  203,   45, 2147,   54,    7, 5987,  106,    7,
         6270,    5,    2]], device='cuda:6'), 'cluster_tokens': tensor([[ 6, 37, 38, 37, 85, 85, 35, 49, 37, 37,  2, 32, 44, 11, 38, 35, 85, 37,
         50,  2, 37,  6, 37, 56, 85, 85, 35, 38, 37, 11, 37, 38, 85, 35, 31, 37,
         83, 37, 34, 24, 11, 37, 37, 85, 49, 31, 37, 37,  2, 32, 44, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [56, 11, 37, 49, 37, 37,  2, 23, 37, 28, 56, 11, 85,  6, 37, 94, 37, 37,
         37, 49, 37, 83, 50,  2, 37, 28, 56, 37, 49, 11, 83, 37, 83, 24, 37, 56,
         85, 38, 11, 37, 38, 37, 37, 50, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 50, 24, 37, 37, 37,  4, 24, 11, 56, 49, 37, 37, 37, 49, 35, 11, 75,
         37, 37, 11, 50, 94, 37, 37,  9, 11, 37, 37, 85, 37, 49, 11, 37, 85, 37,
         37,  9, 37, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 85, 56, 37, 49, 56, 37, 37, 38, 35, 11,  2, 38, 27, 37, 11,
         36, 37, 94, 11,  2, 94, 11, 37, 38, 38, 38, 37, 35, 49, 37, 94, 37, 37,
         28, 29, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 83, 94, 37, 24, 77, 35, 35, 37, 88, 37, 50, 37, 75,  2, 32,
         32, 37, 85, 11, 37, 37, 34, 24, 88, 37, 37, 75, 32, 32, 37, 37, 85, 37,
         85,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 28, 94, 38, 35, 31, 11, 83, 32, 85, 37, 32, 37, 37, 31, 37, 38,
         50,  2,  6, 35, 37, 24, 37, 85, 37, 53, 37, 28, 37, 11, 32, 37, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 94, 33, 37, 37, 37, 17, 73, 24, 34, 38, 23,  9, 37, 11, 37, 38, 31,
         37, 37, 85, 83, 36, 37, 37, 34,  9, 56, 37, 38,  6, 32, 50, 34, 38, 23,
          9, 37, 37, 94,  2, 83, 37, 83, 34, 56, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 31, 37, 34, 32, 37, 82, 38, 77, 37, 11, 38, 35, 11, 28, 11, 37,
         83, 37, 83, 49, 37, 37, 37, 38, 35, 35, 77,  9, 11, 59, 37, 29, 37, 37,
         38, 35, 35, 77,  9, 11, 37, 83, 83, 37, 11, 37, 37, 85, 37, 83, 38, 35,
         35, 49, 37, 94, 37, 37, 94, 11, 83]], device='cuda:6'), 'lengths': tensor([53, 46, 42, 41, 40, 37, 48, 63], device='cuda:6'), 'ntokens': 370}, 'target': tensor([[1555,  178,   36,  547,  590,  533, 1328,  491,   49,   23, 8740,   15,
         1668,   42,   38,  967,   82,   40,  905, 8011,    5, 1555,  268,   14,
         3096,   47,  947,  186,  792,    5,  147,   31, 2669,   30,  547, 1517,
         1091,  640,  332,    5,   64,   36, 5121,  257,  210,  212, 8740,   15,
         1668,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 882,   23, 3000,  141,  953, 2778,   49, 5633,   37, 4422, 1125, 2218,
         7525,   15, 2772,   52, 8557, 1031,  119, 1194,   16,   14, 7368,   78,
          157,   95,  232, 1895,  357,    4, 3377,   47, 4898, 2437,  681,    4,
          519,  742,  236,  767,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [3390,   22, 3713, 3195,   15, 1433,   88,   14, 9354,  259, 2379,   60,
          731,    6,  149,  141, 1024,   49,   23,  633, 4859,    4,   16,   43,
         2976,  364,  550,    4,   43, 2976,   28, 1474, 1981, 2916,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 526,  209,   31, 4967,   16, 2064,   20,    9,  771, 4472,    4, 3626,
         3599,  160,   37,    4, 7230,   16, 5196,    4,   52, 2547, 2324,    4,
           16,   31,  574,   57,  242,   52, 4771,   90, 1024,  128,   35,  710,
         3056,   37,   39,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 342,  960,  195,  418,  573,   36,   52, 8247, 2054,   23,   38, 2137,
          706,  271, 2715,  980,    9,   23,   81,   43,  112,  295, 4723,  732,
         2795,   20,   51, 7838,   20,    4,   16,  112, 1536,  950, 6794,   22,
          344,   23, 4723,  732, 2795,   20,  578,   36,    4, 2615,   28,  127,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [2708,  273, 3830, 7043,   75, 9293,  153,    4,  239, 1514,   28,  151,
         4074,   16, 5817,   20,   75,   61,   52,  257,  459,  627, 1539,  531,
          160, 1304,    4,  382,   36, 2542,   78, 2146,    6,  469, 1753,   16,
          657,  709,   16, 5481, 1109,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 146,  201, 2344,   75,    9,  761, 1185,  895, 7251,  462, 2741,  799,
         5844,   20,  410, 3010,    5,  104, 2498,  653,    4,   50,   30, 2880,
         3588, 7915,  815,   35, 1007,  932,  249,   35,  806, 4599,  160, 3107,
         7322,    4,   88, 1653,  462, 2741, 1030, 5844,    4,  118, 4903,   15,
         2225,   60,  149,  462, 2880,   22,    4,   28, 3010,   28,  123,    5,
            2],
        [  99,   27,   98,  462,  912, 3668,   15,  676,   44, 1104, 4017,   15,
            4,  507,   59,  426,    4, 9434,    4,   16,   36, 2344,   75,  582,
           74,  764,  656, 9105,   28, 4302,   15,    4,  745,   98,   16,  459,
           45, 2748,   74,  764,  656, 9105,    4,   16,   47,  149,   30,    4,
           36, 2306,  139,  196,   14, 2389,  176,   98,   23, 7095,    5,    2,
            1]], device='cuda:6'), 'target_lengths': tensor([51, 42, 36, 41, 50, 43, 61, 60], device='cuda:6'), 'ntokens': 384, 'nsentences': 8}
##################### {'id': tensor([ 63634, 121359, 177680,   3826, 126309, 217178, 116848,  49351],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[ 7.9956e-03,  4.4861e-03, -4.5776e-04,  ...,  1.2207e-04,
         -1.8311e-04, -3.0518e-05],
        [-1.3733e-03, -2.2278e-03, -2.3499e-03,  ...,  3.8757e-03,
          5.7373e-03,  6.5308e-03],
        [ 0.0000e+00, -1.5259e-04, -3.3569e-04,  ...,  6.7139e-04,
          9.1553e-05, -6.4087e-04],
        ...,
        [ 5.3711e-03,  7.4463e-03,  7.6294e-03,  ..., -3.8147e-03,
          4.5776e-04,  2.9297e-03],
        [ 8.5449e-04,  2.1057e-03,  3.2654e-03,  ..., -4.3335e-03,
         -7.4768e-03, -1.0223e-02],
        [-5.2185e-03, -3.9978e-03, -4.1809e-03,  ...,  1.2817e-02,
          1.3062e-02,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([160480, 160480, 160480, 160480, 160480, 160480, 160480, 160479],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,   64,  255,  178,   36,   52, 1624,  310,    4,   14,  118,   29,
           22,   22,  444,  623, 5613,  903, 3138, 4583,   16,   30, 2926, 9705,
           78,   14, 4541,  525,  365, 1879, 2169,   97, 3126,   51, 1471,    4,
           30,  139,   52, 7979,   35,  360,   20, 1547,   27,    4,   14,  686,
         7526,  272,  145,    5,    1,    1,    1],
        [   2,  840,  118, 4061,   28,   83,    4,  105, 2546,   20,  212, 9365,
           20,  304,  128,  861,  173, 1171,   14,  590,  809,  128, 2321,  129,
          157,  602, 6306,    4,  177,  647,  648, 2681,  767,  332,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   32,  448,   40, 1935,   18, 4392,   61, 2387,  124,  448,
          141, 7512,   74,  210,  151, 8334,   98, 2387,    4, 2431,   15,   32,
            4,   50,  295, 3880, 1907, 5619,   15, 4651,    4,   36,  448, 5498,
            4,   75,  363,   28, 5288, 2485,    4,  644,  355,  696,   28, 1721,
            5,    1,    1,    1,    1,    1,    1],
        [   2,   64,   95,  280,  118, 4979, 2161,  530, 3445, 3739,  430,  804,
           35,  754, 3964,   22,    4,   14,   43, 2063,   15,    4,   16,   95,
          329,   44,   38, 9206,   15,   41,    9,  141, 2257,  393,    4,  114,
           41,  196, 5467,   76,  137,  146,  731,   49,  448, 2004,   47,  420,
            4,  136,  470, 4280,   36,  921,    5],
        [   2,   64,   30, 5632,   82,   40, 6640,    4,   30,   30, 2382,  173,
           61,  102, 4992,   88, 4261,  153,    4,   16,   30, 1651,  397, 1099,
         5288, 5121,    4,  382,   36,   49, 1063,  783,  511,   37, 5518,  239,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   32,   39,   58, 4185,  604,    4,  604,   32, 1246,   47,
           39, 6540, 2374,  975,   15,    4, 9330,  904, 8723,  124, 5177,   20,
         5678,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,   92,   27,   14,  880,  820,  677, 1861,  308,  122,  335,  455,
            5,  308,  176,  176,  176,  176,    5,   41,   27,  263,  193,   31,
          256,    4,   31,  145,  252,   47, 2625,    4,   74,   98,   37, 1212,
           15,  299, 3378,   27,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [   2,  222,   81,  105,  326,  466, 6917,    4,  114,   81, 2230,    4,
         4569,    6, 5533, 9376,   54,   16, 1297, 2619,  678,  466, 6917,    4,
          615,  470,  263,  227,  156,  234,   59, 1691, 1419,   28, 2095,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:5')}, 'transcript': {'tokens': tensor([[   8,   84,   63,   13, 3631,   12,   94,  148,    4,   69,   13, 1715,
         1941,  383,    4,  169, 1552,   51, 1117,    8, 5625,   54,   33,    4,
            7,   13,   48,  525,  365,   59,  866,   11,    6, 3088, 3516,    4,
         1584,   13, 2345, 2686, 2672,   17, 2307,   73, 7526,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  10,  388,   17,  199, 3064,    4,   33, 1665, 7925, 1598,  168, 2771,
            6,    7, 7144,  122, 1068,  183,   12, 2048,  106, 6834,    6,    4,
           13,  110,   57, 1646,  759,  215,  581,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 120,   24,  388,   13,  728,   18, 2793,   69,  134,    4,  109,  508,
          134,   13,  690, 1079, 3352,  271,  100,   39, 8292,    4,   24, 2568,
           17,  159, 1968,  111,  269,   62, 4372, 2156,  134,   10, 1244,   35,
         5321,  233, 1115,  929,  802,  419,   12,  159,  572, 5952,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,  101,  144,   13,  488,  566,   59, 1722,   12,  561,  804, 6442,
            6,   17,  101,  169,  508,  134,    4,    8,  101,   11,   48,  289,
            4,   38, 1355,   20,  270,    9,   13, 1822,    4,  103,   25,  499,
          598, 1436,  335,   93,  137, 1239,    4,    8,  281,   12,  134,  169,
           86,  367,  270,    4,   67,  185,   12,  134,  169,  367,  270,    5,
            2],
        [   8,    7, 2173,   12,   17,   34,   39, 9025,   17, 4333,   48,    7,
         2384,   25,  150,   69,    7, 2885,    4,    8,  166, 3548,   48,   55,
         1651,  215,   12,  574, 2256, 1325,   21,   34, 2769,   18,  249,   62,
          131, 1339,  783,  511,   37,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 120,   24,  154,   80, 2127,  468,    4,   24,  914,  192,   11,   18,
          154,   80, 4601, 4565,    6,    8,   95,  786,  945, 2108,  237, 1027,
          679,   96,  109, 4810, 1732,    6,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   33,   26,    7,  664,  820,  848,  586,   13,  122,  335,  455,
            5,   13,  176,  176,  176,  176,    5,   21,   26,  172,   46,   19,
          641,    4,   19,   73,   11,   18, 4490,   10,   25,  138,  811, 1841,
            6, 1547,   33, 2987,   26,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   79,   25,  875,  117,  214,  540,    4,   79,   25,  875, 1247,
            4, 4325, 4826, 4429,    8, 9035,  540,    4,   25, 1772,   10,  175,
          185,  172, 5832, 1532,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:5'), 'cluster_tokens': tensor([[37, 37, 85, 37, 23, 37, 56, 50, 11, 37, 37, 94, 35, 24, 11, 85, 83, 38,
         37, 37, 29, 49, 37, 11, 37, 37, 31, 35, 35, 35, 35, 85, 37, 86, 23, 11,
         37, 37, 38, 35, 94, 37, 50,  6, 29, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 31, 37, 37, 19, 11, 37, 38,  2, 38, 37, 32, 37, 37, 33, 35, 35, 24,
         37, 56, 37, 28, 37, 11, 37, 37, 77, 34, 24, 24, 83, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 38, 35, 38, 37, 37, 11, 37, 88, 37, 37, 38, 35, 35, 44,
         37, 38,  9, 11, 38, 31, 37, 37,  2, 83, 79, 31, 56,  6, 37, 37, 32, 38,
         35, 35, 37, 50, 49, 50, 37, 37, 47, 94, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 85, 37,  2, 38, 35,  2, 37,  9, 35, 94, 37, 37, 38, 85, 88, 37,
         11, 37, 38, 85, 31, 88, 11, 38, 35, 77, 37, 37, 37, 24, 11, 37, 37, 83,
         59, 38, 35, 35, 11, 28, 11, 37, 75, 37, 37, 85, 83, 85, 37, 11, 37, 50,
         37, 37, 85, 85, 37, 11, 83],
        [37, 37, 32, 37, 37, 85, 38,  9, 37, 49, 31, 37, 56, 37, 59, 37, 37,  9,
         11, 37, 37, 29, 31, 37, 34, 24, 37, 38, 94, 24, 37, 85, 38, 35, 77, 31,
         37, 38, 35, 35, 77, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 59, 37,  9, 29, 11, 38, 83, 85, 85, 35, 59, 37,  2, 28, 37, 37,
         38, 35, 77, 38, 35, 35, 35, 77, 37,  2, 94, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 38, 73, 38, 35, 37, 35, 35, 35, 11, 37, 35, 35, 35, 35,
         11, 37, 85, 83, 11, 38, 88, 11, 38,  6, 85, 35, 10, 37, 37, 37, 38, 35,
         37, 77, 37, 32, 85, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 49, 37, 56, 36, 11, 37, 37, 49, 56, 11, 28,  9, 49, 37, 94,
         36, 11, 37, 49, 37, 85, 50, 83,  2, 56, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37]], device='cuda:5'), 'lengths': tensor([47, 33, 48, 61, 43, 32, 43, 30], device='cuda:5'), 'ntokens': 337}, 'target': tensor([[  64,  255,  178,   36,   52, 1624,  310,    4,   14,  118,   29,   22,
           22,  444,  623, 5613,  903, 3138, 4583,   16,   30, 2926, 9705,   78,
           14, 4541,  525,  365, 1879, 2169,   97, 3126,   51, 1471,    4,   30,
          139,   52, 7979,   35,  360,   20, 1547,   27,    4,   14,  686, 7526,
          272,  145,    5,    2,    1,    1,    1],
        [ 840,  118, 4061,   28,   83,    4,  105, 2546,   20,  212, 9365,   20,
          304,  128,  861,  173, 1171,   14,  590,  809,  128, 2321,  129,  157,
          602, 6306,    4,  177,  647,  648, 2681,  767,  332,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 222,   32,  448,   40, 1935,   18, 4392,   61, 2387,  124,  448,  141,
         7512,   74,  210,  151, 8334,   98, 2387,    4, 2431,   15,   32,    4,
           50,  295, 3880, 1907, 5619,   15, 4651,    4,   36,  448, 5498,    4,
           75,  363,   28, 5288, 2485,    4,  644,  355,  696,   28, 1721,    5,
            2,    1,    1,    1,    1,    1,    1],
        [  64,   95,  280,  118, 4979, 2161,  530, 3445, 3739,  430,  804,   35,
          754, 3964,   22,    4,   14,   43, 2063,   15,    4,   16,   95,  329,
           44,   38, 9206,   15,   41,    9,  141, 2257,  393,    4,  114,   41,
          196, 5467,   76,  137,  146,  731,   49,  448, 2004,   47,  420,    4,
          136,  470, 4280,   36,  921,    5,    2],
        [  64,   30, 5632,   82,   40, 6640,    4,   30,   30, 2382,  173,   61,
          102, 4992,   88, 4261,  153,    4,   16,   30, 1651,  397, 1099, 5288,
         5121,    4,  382,   36,   49, 1063,  783,  511,   37, 5518,  239,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 222,   32,   39,   58, 4185,  604,    4,  604,   32, 1246,   47,   39,
         6540, 2374,  975,   15,    4, 9330,  904, 8723,  124, 5177,   20, 5678,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [  92,   27,   14,  880,  820,  677, 1861,  308,  122,  335,  455,    5,
          308,  176,  176,  176,  176,    5,   41,   27,  263,  193,   31,  256,
            4,   31,  145,  252,   47, 2625,    4,   74,   98,   37, 1212,   15,
          299, 3378,   27,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1],
        [ 222,   81,  105,  326,  466, 6917,    4,  114,   81, 2230,    4, 4569,
            6, 5533, 9376,   54,   16, 1297, 2619,  678,  466, 6917,    4,  615,
          470,  263,  227,  156,  234,   59, 1691, 1419,   28, 2095,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1]], device='cuda:5'), 'target_lengths': tensor([52, 35, 49, 55, 37, 26, 41, 36], device='cuda:5'), 'ntokens': 331, 'nsentences': 8}
##################### {'id': tensor([112177,  42698, 160893,  70082,  86779,  77289,  26014,  82391],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[ 3.1738e-03,  2.8381e-03,  1.0986e-03,  ...,  7.3242e-04,
          2.8076e-03,  3.7537e-03],
        [-4.0588e-03, -4.4556e-03, -4.3030e-03,  ..., -2.5085e-02,
         -2.3804e-02, -2.1973e-02],
        [-9.1553e-05,  0.0000e+00, -3.0518e-05,  ...,  1.8005e-03,
          1.2207e-03,  8.2397e-04],
        ...,
        [ 1.2817e-03,  2.5330e-03,  3.6621e-03,  ..., -6.2927e-02,
         -6.0608e-02, -5.7922e-02],
        [ 3.2349e-03,  1.7700e-03,  8.8501e-04,  ...,  2.8992e-03,
          3.0518e-03,  3.0518e-03],
        [-1.5381e-02, -1.3977e-02, -7.1716e-03,  ..., -9.9182e-03,
         -7.3242e-03, -5.1880e-03]], device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([221760, 221760, 221760, 221760, 221760, 221760, 221760, 221760],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2,   92,   76,  157,    4,   14,  223, 1689, 9718, 1125,    4,   50,
           23, 8403,   23, 1668, 4247, 5022,  291, 3406,   37,   16,   47,  831,
           37, 1571,   46,   50,   14, 4922,   23,  633,  989,    6,  242,  156,
          152,   45,  530,  165,   47, 1035,   20,   16,   47, 2364,  354,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 4287, 3418, 5716,   27,  177, 2009,   40,    6,   44,   56, 2654,
          247,  797,  236,   16, 2953,    5,    5,    5,  312, 1378, 2131,  334,
         4874,    6, 1530, 2170,   15,   44,   52, 6701,   35, 3344,  718,   35,
         1888,  718,   28, 1205,    4,   14,  263,  112,  337, 4842,  259, 2325,
          414,   14,  259,   39,  658,  444,  145,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,   41,   83,   40, 6009,    4,   30,   43,   60,  669, 1506,   79,
          779,  878,  272,    4,   40, 1549,    4,   30,   43,   60, 1474,  732,
         3134,  706,   79,  779,  878,  272,   40, 3809,    6,    4, 2474,   60,
          102, 1093,    4,   39,  102,   43,  647,  702,   40, 8653,    6,    4,
           30,   60,  102, 1093,  805, 4967,  466,  176,  152,  930,   18,    4,
           16, 3132,  534, 2680,    5,    1,    1,    1],
        [   2,  327,  647,    9,   23, 5910, 4916,  730,    4,   27,   30,   44,
          738, 1238,  259,  319,  917, 1717,   20, 1343, 3785, 4722, 1217,   60,
         2164,   74,   38,  680, 2304,   45,  980,  210,  628,   81, 6986, 6259,
           16, 6986,  243,  390, 3661,    4,  167,   56, 4306, 2564,  662,   16,
         1013,   20, 5910,    5,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  376,  734, 2361, 2556,   20,  173,  221,   27,    4,   50,  330,
         2341,   75, 1748,  395,    4,   74,   30, 3378,   75,  182, 6697,    9,
           58,  437,  551,   45, 2810,    5,   99,  178,  118, 3116,    6, 4041,
          861,    4,   23,  112,   58,  437,  551,   45, 1566, 2729,   18,    4,
          750,   95,   30, 2000,    5,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2,  435,    4,   14,   98,   23, 4321, 1675, 4916,    9, 8611,   51,
         3721,   18,  522,    4,  127,   60,  669, 1506,  393, 9124,   16,  189,
           60,   58, 1506,  420,    9,  355, 3748, 3949,    4,   88,  517,  669,
         3543,   22, 6468,  393, 6838,    4,   29,   50,   43,  986,  350,    6,
         3014,  586,  165, 1907, 3406,   18,   76,    5,  590,    6,  416,  387,
           47,  216,  171,    6, 1934, 5001,  712,    5],
        [   2,   92,  573,  771,  314,   52,  799, 2608,    4,  428, 4437,    6,
         2746, 2345,   48, 1604,   20,   31,  163,  212, 2799,    5, 4177,    6,
           16,   39,   58, 2013, 1863,   82,   31,   90, 1356, 2416, 3103,   78,
           14,  966,  483,  748,  992,    4,   14, 3767, 2125,  187,  833,   69,
          677,   15,   18,  128,  937,  158,  687, 8142,    5,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [   2, 1272,    4, 1056, 2453,   20,  397, 2844,    4, 6295,  272,   43,
          257,  196,    5,   68,  379,   65,  298,   83,   32,  105,   56, 8305,
           15, 3711,    4,  105, 5323, 3711,    4,   14,   98,   23, 1100, 6864,
            5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:4')}, 'transcript': {'tokens': tensor([[ 117,   63,   94,  148,  162,  529,   10,  289, 8123,  111,   17,    7,
         2244,    9, 2394, 4793,   34,  961, 4970,  908, 7759,    4,   86,  143,
         7759,   46,   17,    7, 5574,   35, 2374,  234,  380, 1255, 5492,   34,
           86,  740,    8,  169,   86,  283,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 108, 4764, 1039,   26,   13, 1552,  217, 3237, 1563, 1974, 3174,   46,
           19, 6938,    4,   13, 5969,  266,  850,  455, 1778,   44,   10,  991,
           13, 5129,   35, 1933, 7339,   17,   73,  172, 1005,  324,  183,   55,
           17,  535,   13, 2760,    5,    2,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [   8,   53,   66,   91,  637, 6464,   71,  159, 1848,    4,   67,  486,
         6464,   71,  159, 3883,    6,    4,   13, 1575, 3364,  635,   71,    7,
          561,  206,   53, 1085,   10,   51,    4,   13, 5972, 3364,   71,    7,
          561,   53, 2484,   12,  378,    4,    8,  294,  143,   51, 1763,    6,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  33,   26,   70,   11,    6,  142,   69,    9,    7, 3374, 2735,  230,
          115,    5,  245,   12,   77,    4,   25,  135,    4,   55,   13,  535,
          183, 1192, 3374, 3463,  214,  100,   38,  870, 1526,  438,  206,   25,
           11,   57,  142,  336, 4502,   54,  214,    4,  133, 7648, 3374,    4,
          133,  743,    4,   13,  389,   62,   85, 5425, 4478,    5,  230,   42,
           17,   11,    6,  148,  722,    6, 1192, 3374,    5,    2],
        [1579,   22,  749,   44, 1189,    4,   29,  339,   11,    6, 3265,   38,
         4291,  158,  137,   29,    7,  479,  168,  115,   26,   17,  417, 2341,
         1833,   10,  934,    7, 2987, 1028, 2433,  199,    7, 2885,    4,    8,
           84,   11,    6,   13, 2694, 1598,   17,  164, 1566, 2729, 1004,    7,
         2885, 1025,  101,   11,    6,  401,   17,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [ 708, 7082,   48,  106, 8719,    9,    7, 1390,   54, 2735,    9, 8393,
            4,  203,  500,  235,   62,   71,  159, 1848,    4,    8,  180, 1828,
           71,  159, 1848,  270,   10,  159, 2822,    6,   10, 8286,  159, 1519,
          238,   35,  242,   54,   29,   17,   53,  873, 8869,   35,  927, 3149,
           46, 2497,  291,   15,    6,  372,  121,  457,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  29,   84,   34,   13,  325,   12, 3012,    9,   89,  282,  125,   19,
           34, 3657,   54,   33, 2475,   12, 1221,   56, 1628,    7,  383,    4,
           67,  180,    9,    7,  276,   54,    6,    8,   69,    7, 1822,  856,
            6,    4,   19, 2115,   62,   79,   39, 9235,   55, 1122, 1326,    4,
            7, 1553,   77,  187,  833,   69, 2702, 6088,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],
        [  53,   63,  499, 6295,   54,    5,   68,  194,   65,   29,   24,   11,
          121,  278,   33, 7933, 1361,   17,   11,    6,   33, 6012,  292,  959,
            6, 1361,   17,   11,    6,  367,  126,   12,    7, 2696,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],
       device='cuda:4'), 'cluster_tokens': tensor([[37, 85, 56, 50, 85,  6, 37, 88,  2, 83, 37, 37, 29, 37, 94, 94, 85, 49,
         28, 50,  2, 11, 83, 50,  2, 11, 37, 37, 36, 38, 56, 35, 77, 35, 94, 85,
         83, 49, 37, 85, 83, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37,  9, 32, 85, 37, 83, 38, 35,  2, 38, 35, 11, 38, 88, 11, 37, 32, 35,
         37, 35, 35, 82, 37, 49, 37, 34, 38, 24, 94, 37,  6, 83, 49,  2, 24, 37,
         37, 83, 37, 23, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 37, 85, 50, 37, 36, 37, 37, 56, 11, 37, 50, 36, 37, 37,  9, 37, 11,
         37, 28, 36,  6, 37, 37,  9, 37, 37, 85, 37, 38, 11, 37, 28, 36, 37, 37,
          9, 37,  9, 37, 49, 11, 37, 50, 50, 38, 35, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 50, 85, 37, 49, 37, 37, 37, 56, 94, 37, 83, 11, 83, 37, 50, 11,
         37, 59, 11, 37, 37, 83, 24,  9, 56, 31, 56, 37, 38, 35, 35, 82, 37, 37,
         85, 77, 49, 37, 49, 49, 56, 11, 83,  2, 56, 11, 83, 83, 11, 37, 35, 31,
         37,  9, 56, 11, 37, 11, 37, 85, 37, 50, 49, 37,  9, 56, 11, 83],
        [38, 35, 38, 82, 83, 11, 83, 49, 85, 37, 88, 38, 35, 35, 11, 83, 37, 94,
         37, 83, 85, 37, 38, 35, 56, 37, 88, 37, 32, 49, 37, 37, 37,  9, 11, 37,
         37, 85, 37, 37, 32, 38, 37, 85, 38, 35, 37, 37,  9, 24, 38, 85, 37, 49,
         37, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [56, 49, 31, 37, 94, 37, 37,  9, 49, 94, 37, 28, 11, 38, 35, 35, 31, 37,
         37, 56, 11, 37, 37, 31, 37, 37, 56, 37, 37, 37,  9, 37, 37, 29, 37, 28,
         83, 38, 77, 49, 83, 37, 37, 85,  9, 38, 35, 35, 11, 83, 38, 77, 37, 35,
         35,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [83, 37, 85, 37, 83, 37, 32, 37, 37, 32, 37, 38, 85, 49, 49, 37, 38, 37,
         94, 38, 37, 37, 24, 11, 37, 37, 37, 37, 83, 49, 37, 37, 37, 37, 24, 58,
         37, 11, 38, 49, 31, 37, 38, 36, 37, 38, 35, 11, 37, 13, 50, 35, 35, 37,
         87, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83, 32, 49, 11, 38,  9, 11, 83, 38, 85, 35, 31, 37, 32, 94, 37,
         85, 37, 37,  9, 35, 35, 37, 94, 37, 85, 37, 85, 37, 37, 37, 23, 11, 83,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]],
       device='cuda:4'), 'lengths': tensor([44, 42, 50, 70, 57, 58, 58, 36], device='cuda:4'), 'ntokens': 415}, 'target': tensor([[  92,   76,  157,    4,   14,  223, 1689, 9718, 1125,    4,   50,   23,
         8403,   23, 1668, 4247, 5022,  291, 3406,   37,   16,   47,  831,   37,
         1571,   46,   50,   14, 4922,   23,  633,  989,    6,  242,  156,  152,
           45,  530,  165,   47, 1035,   20,   16,   47, 2364,  354,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [4287, 3418, 5716,   27,  177, 2009,   40,    6,   44,   56, 2654,  247,
          797,  236,   16, 2953,    5,    5,    5,  312, 1378, 2131,  334, 4874,
            6, 1530, 2170,   15,   44,   52, 6701,   35, 3344,  718,   35, 1888,
          718,   28, 1205,    4,   14,  263,  112,  337, 4842,  259, 2325,  414,
           14,  259,   39,  658,  444,  145,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [  41,   83,   40, 6009,    4,   30,   43,   60,  669, 1506,   79,  779,
          878,  272,    4,   40, 1549,    4,   30,   43,   60, 1474,  732, 3134,
          706,   79,  779,  878,  272,   40, 3809,    6,    4, 2474,   60,  102,
         1093,    4,   39,  102,   43,  647,  702,   40, 8653,    6,    4,   30,
           60,  102, 1093,  805, 4967,  466,  176,  152,  930,   18,    4,   16,
         3132,  534, 2680,    5,    2,    1,    1,    1],
        [ 327,  647,    9,   23, 5910, 4916,  730,    4,   27,   30,   44,  738,
         1238,  259,  319,  917, 1717,   20, 1343, 3785, 4722, 1217,   60, 2164,
           74,   38,  680, 2304,   45,  980,  210,  628,   81, 6986, 6259,   16,
         6986,  243,  390, 3661,    4,  167,   56, 4306, 2564,  662,   16, 1013,
           20, 5910,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 376,  734, 2361, 2556,   20,  173,  221,   27,    4,   50,  330, 2341,
           75, 1748,  395,    4,   74,   30, 3378,   75,  182, 6697,    9,   58,
          437,  551,   45, 2810,    5,   99,  178,  118, 3116,    6, 4041,  861,
            4,   23,  112,   58,  437,  551,   45, 1566, 2729,   18,    4,  750,
           95,   30, 2000,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [ 435,    4,   14,   98,   23, 4321, 1675, 4916,    9, 8611,   51, 3721,
           18,  522,    4,  127,   60,  669, 1506,  393, 9124,   16,  189,   60,
           58, 1506,  420,    9,  355, 3748, 3949,    4,   88,  517,  669, 3543,
           22, 6468,  393, 6838,    4,   29,   50,   43,  986,  350,    6, 3014,
          586,  165, 1907, 3406,   18,   76,    5,  590,    6,  416,  387,   47,
          216,  171,    6, 1934, 5001,  712,    5,    2],
        [  92,  573,  771,  314,   52,  799, 2608,    4,  428, 4437,    6, 2746,
         2345,   48, 1604,   20,   31,  163,  212, 2799,    5, 4177,    6,   16,
           39,   58, 2013, 1863,   82,   31,   90, 1356, 2416, 3103,   78,   14,
          966,  483,  748,  992,    4,   14, 3767, 2125,  187,  833,   69,  677,
           15,   18,  128,  937,  158,  687, 8142,    5,    2,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1],
        [1272,    4, 1056, 2453,   20,  397, 2844,    4, 6295,  272,   43,  257,
          196,    5,   68,  379,   65,  298,   83,   32,  105,   56, 8305,   15,
         3711,    4,  105, 5323, 3711,    4,   14,   98,   23, 1100, 6864,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([48, 56, 65, 52, 53, 68, 57, 37], device='cuda:4'), 'ntokens': 436, 'nsentences': 8}
##################### {'id': tensor([172598, 185324, 187122,    107, 208972,  22428, 162296, 213754],
       device='cuda:7'), 'net_input': {'src_tokens': tensor([[-3.7231e-03, -3.6621e-03, -3.7537e-03,  ...,  6.6223e-03,
          1.1658e-02,  1.3458e-02],
        [ 3.9673e-04, -1.3123e-03, -7.9346e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-5.1880e-04, -3.9673e-04, -3.0518e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-1.9226e-03, -4.0894e-03, -4.5166e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0376e-03, -1.2207e-04,  3.6621e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.1035e-05, -3.0518e-05, -6.1035e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([228320, 228160, 228160, 228160, 228160, 228160, 228160, 228159],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,  147,   32,  309,  107,  789,  139, 1481,    4, 1513,  337, 3543,
           22,  308, 3637,  129, 3915,   51, 3306,    5, 5926,   18,  501,    6,
           42,  312,  643,  130,  306, 1264,  683,   18,  706,   16,  141,  212,
         1264,  683,   18,  706,   27,   14, 1572,    4,  113,  309,   32,  107,
         1481,   44,  400,  161,   40,  643,  203,  122,  398,   42,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  657, 4256,   15,  573,   36,  742,    5,  304,    5,   38,   62,
         4720,  980, 1334,   36,   30, 1735,   38,   62,  235,  197,  573,    5,
           38,  920,  607,   18,  197,  239,   49,   38,   62, 4720,  197,   56,
         6513,    5, 4086, 8882,  105, 1857, 5013,   15,  190, 1339,  571,   22,
           44,   38,  592,  241,  158,  870,  195,  373,  197,   28,   38, 1337,
          158,  870,  658,  980,   38, 3127,  562,    6,  197,   28,   38, 3127,
          232,  197,   16,   38, 3884,  372, 1118,  197,   28,   38, 3884,  232,
          857,   68,  348,   65],
        [   2,  441,  328, 4180,  573,   36,    9,  485, 1622,   93, 6789,  149,
          118,  435, 9070,    4,   23,   78,  112,  392, 2709,  435,   28, 3590,
           82,    5,  104, 7350,   15,   52, 8709,   16,  853,  191, 1292,  156,
         2706,  662, 3033,   15, 4900,   49,   23,  285, 2006,  165,   39,    5,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   72,  449,  252,   98,  102, 1876,   23, 5698,   15,   14,  489,
          344,  493, 3858,  174,  381, 4361, 1306,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  376, 1476,    9, 9297,  130,  306, 3639,    4,  136,   32,  776,
           47,  410,  243, 3887,   22,    4,   74,   23, 7536,   23, 1022,   16,
         4871,  247, 4593,   20,    4,  291, 9889, 4105,   14, 5270,  293, 3104,
           23, 4001,    6, 4183,   15,   16,  764,    6,    6,  184,   22,  902,
           59,   18,   83,    4,    9,  631,   43,  253, 5364,   49, 4672,   16,
         1414, 1170,  165,  210, 7837,   15,    5,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,   92, 3969,  584,  496,    4,   30, 3476, 4175,    4,  112,   30,
           32, 1388,   83,    4, 1453,  306,    6,    4, 2250, 2784,   15,    9,
           23,  972, 5131,    4,   14,   14,  330, 2921,   15, 6275,    5,  147,
           31,  638,    4,   36,   27,  291,  502,  122,  152,  930,  418,    4,
           50,   36,  107,  611, 2250,    4,  112, 3476,   16, 7046, 1707,   18,
         2729,   20, 3735,    4,  403,   32,   36,  516,  124,   47,    5,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2,  564,  828,  957,    4, 1238, 1334,   81, 1277,    4,  112,   56,
         4142,  156, 3403,   16, 2039, 4175,   20,   28, 1561,    4, 2971,   31,
           39,    4, 3113, 9592,   22,  253, 2295,   49, 1615,   22,   28, 1108,
           15,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [   2, 3192,   32,  107,  105, 2486, 7095,   39,   44, 3089,   56, 9552,
         3089,   56, 9272, 1056,   56, 9952, 3089,    5,   92,   27,   40, 4106,
            6, 2457,   16,   36, 2714,    4,  428, 1185,   56, 9552, 1185,   56,
         9272, 1056,   56, 9952, 1185,    4, 3694,    5,  104,   83,   30,  257,
          393, 1036,   16, 1175,   36,   29, 3366,    5,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:7')}, 'transcript': {'tokens': tensor([[  67,   24,  113,   66,   10,  884,    7,  630,    4,  148,   26, 2973,
          543,  673,  829,    7, 1519,   29,  233,   12,   13,  753,    4,  230,
           42,  238,    4,   13,  753,  188,  294, 5291,  373,    4,    8,   91,
           12,  134,   26,    7, 1381,    4,   29,   24,   66,   10,  884,    7,
          630,    4,  138,   26,   13,  753, 7420,   62,   42,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,   55,  663,    4,    9, 2781,   24,  144,    7, 1455,   38,   62,
         4720,  197,  490,   24,  144,    7, 1455,   38,   62,  235,  137,   38,
           62,  235,  197,   34,  774,   62,  106,   38,   62, 4720,  137, 1275,
          117,  270,   35,  891, 1428, 1511,   13,  277, 1487, 3174,   44, 5866,
          870,  195,  373, 5866,  870,  658,    4,   67,  562,    6,   67,  232,
            8,   56, 3884,  562,    6,   56, 3884,  232,    5,   68,  194,   65,
            2],
        [ 115,    4, 5114,   10,   17,  613,    4,   84,  144,  226,  288,   91,
         2035,  607,  411, 1775,  589,    9,   77,   12, 1031,   93, 6789,   10,
         3860,  143,  254, 5129,  708,    4,   29,   24,   56, 3728,   13, 2951,
           54,  232,    4,    8,   24,  162,  529,   10, 2293, 1219,   35, 2917,
          429, 1006, 6648,  982,   12, 2122,   10, 1703,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   9, 2047,   12, 6180,    4,   19,   11,   48,  100,   10,  450,   25,
            7, 1579,  232,   12,   91,   12,   89, 2911, 3357,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [1025,  294, 2826,  144, 2912,   10,    7, 7723,   22,   82,    4,   24,
          451,   22,   11,   18,  850,  608,  389,  436,    7,  207,    9,  166,
            4,  131,  521, 1015, 3127,   54,   10,    7, 4513,   12, 4828,    8,
         1244,   35,   57, 2515,    4, 3135,  742,  399,   54,    8, 2914,  122,
          241,  494,   62,    4,    9, 1898,  684,   20, 3717,   66,  149, 1079,
         1314,  987,  140,   18, 4356,  876, 5521,    6,    8,  130, 1314,    5,
            2],
        [  17,    7,  415,  584,  524,    4,    7, 2127,  524,   17,   24,   11,
          121, 1346,   80,    4,   26, 4298, 1771,   12,  214,   46, 2462,    6,
            9,    7,  941, 2671,   17,  164, 3814, 6927,   46,   67,  113,    4,
           19,  154,    4,    9,   20,  879,   18, 3042,    4,   21,  164, 1927,
          170, 2946,  826,   80, 2127,    8, 6383, 1206,    4, 1179,   24,  100,
           21,  109,   86,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 564,  828,  957,    4,  261,    4,  261, 1978,  490,   94,  487,  952,
           80, 9263, 2787,    8, 3925, 2787,    4,   19,  116,  487, 6501,    7,
         1780, 6069,    9, 1296,   10,  368,   33,   79,   13, 1009, 1710,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,  339,   11,    6,  116,  274,   85,   33,  946, 6270,    4, 3089,
           56, 9552, 3089,   56, 9272, 1056,   56, 9952, 3089,    5,   33,   26,
           13,  133, 2292, 3433,    4,    8,   21,   11,    6, 1301,    4,  125,
         1185,   56, 9552, 1185,   56, 9272, 1056,   56, 9952, 1185,    4, 3694,
            5,   24,   11,  121, 1110,   33,  244,    8,  244,    4,    8,   24,
         2015,   21,  100,   33,    5,    2,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:7'), 'cluster_tokens': tensor([[37, 38, 83, 85, 37, 88, 37, 94, 11, 50, 85, 38, 66, 35, 49, 37, 28, 83,
         35, 37, 37,  9, 11, 37, 11, 83, 11, 37,  9, 85, 50,  9, 56, 11, 37, 50,
         37, 37, 85, 37, 94, 11, 83, 38, 85, 37, 88, 37, 94, 11, 37, 85, 37,  9,
         29, 31, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 37, 32, 11, 37, 28, 38, 85, 37, 32, 38, 31, 35, 82, 37, 38, 85, 37,
         32, 38, 31, 35, 11, 38, 31, 35, 82, 85, 38, 31, 37, 38, 31, 35, 11, 83,
         37, 37, 38, 35, 44,  9, 37, 50, 38, 35, 82, 29, 35, 35, 56, 29, 35, 77,
         11, 37, 77, 37, 37, 77, 37, 38, 35, 77, 37, 38, 35, 77, 11, 38,  9, 11,
         83],
        [83, 11, 83, 37, 37, 32, 11, 37, 85, 85, 83, 50, 38, 35, 35, 35, 35, 37,
         50, 37, 38, 35, 35, 37, 49, 50, 37, 34, 56, 11, 83, 38, 38, 35, 37, 38,
         49, 77, 11, 37, 38, 85,  6, 37, 49, 38, 38, 35, 94, 94, 59,  2, 37, 94,
         37, 49, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [37, 32, 37, 94, 11, 38, 85, 31, 37, 37, 88, 37, 37, 38, 77, 37, 50, 37,
         37, 32, 56, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [24, 50, 56, 85, 31, 37, 37, 28, 35, 53, 11, 38, 85, 35, 85, 35, 37, 75,
         35, 77, 37, 83, 37, 37, 11, 37, 38, 35, 35, 49, 37, 37,  9, 37, 94, 37,
         32, 38, 77, 32, 11, 28, 38, 35, 49, 37, 38, 35, 35, 35, 31, 11, 37, 35,
         35, 77, 94, 85, 38, 35, 31, 38, 35, 35, 28, 38, 94, 37, 37, 72, 31, 11,
         83],
        [37, 37, 38, 73, 32, 11, 37,  9, 32, 37, 38, 85, 35, 59, 37, 11, 85, 49,
         50, 37, 56, 11, 94, 37, 37, 37, 94, 56, 37, 85,  5, 56, 11, 37, 83, 11,
         38, 59, 11, 37, 77, 35, 35, 83, 11, 37, 85, 49, 37, 37, 59, 37,  9, 37,
          9, 29, 11, 37, 38, 37, 37, 37, 83, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37],
        [34, 73, 73, 11, 83, 11, 83, 83, 37, 56, 31, 16, 37, 28, 56, 37, 94, 56,
         11, 38, 83, 31, 49, 37,  9,  9, 37, 49, 37, 49, 37, 37, 37, 49, 94, 11,
         83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37],
        [83, 49, 85, 37, 83, 59, 37, 37,  2, 94, 11, 38, 38, 83, 38, 38, 83, 17,
         38,  9, 38, 11, 37, 85, 37, 83,  2, 32, 11, 37, 37, 85, 37,  2, 11, 37,
         17, 38, 83, 17, 38, 83, 17, 38,  9, 17, 11, 83, 11, 38, 85, 35, 59, 37,
         37, 37, 37, 11, 37, 38, 36, 37, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37]], device='cuda:7'), 'lengths': tensor([58, 73, 58, 23, 73, 65, 37, 66], device='cuda:7'), 'ntokens': 453}, 'target': tensor([[ 147,   32,  309,  107,  789,  139, 1481,    4, 1513,  337, 3543,   22,
          308, 3637,  129, 3915,   51, 3306,    5, 5926,   18,  501,    6,   42,
          312,  643,  130,  306, 1264,  683,   18,  706,   16,  141,  212, 1264,
          683,   18,  706,   27,   14, 1572,    4,  113,  309,   32,  107, 1481,
           44,  400,  161,   40,  643,  203,  122,  398,   42,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 657, 4256,   15,  573,   36,  742,    5,  304,    5,   38,   62, 4720,
          980, 1334,   36,   30, 1735,   38,   62,  235,  197,  573,    5,   38,
          920,  607,   18,  197,  239,   49,   38,   62, 4720,  197,   56, 6513,
            5, 4086, 8882,  105, 1857, 5013,   15,  190, 1339,  571,   22,   44,
           38,  592,  241,  158,  870,  195,  373,  197,   28,   38, 1337,  158,
          870,  658,  980,   38, 3127,  562,    6,  197,   28,   38, 3127,  232,
          197,   16,   38, 3884,  372, 1118,  197,   28,   38, 3884,  232,  857,
           68,  348,   65,    2],
        [ 441,  328, 4180,  573,   36,    9,  485, 1622,   93, 6789,  149,  118,
          435, 9070,    4,   23,   78,  112,  392, 2709,  435,   28, 3590,   82,
            5,  104, 7350,   15,   52, 8709,   16,  853,  191, 1292,  156, 2706,
          662, 3033,   15, 4900,   49,   23,  285, 2006,  165,   39,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  72,  449,  252,   98,  102, 1876,   23, 5698,   15,   14,  489,  344,
          493, 3858,  174,  381, 4361, 1306,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 376, 1476,    9, 9297,  130,  306, 3639,    4,  136,   32,  776,   47,
          410,  243, 3887,   22,    4,   74,   23, 7536,   23, 1022,   16, 4871,
          247, 4593,   20,    4,  291, 9889, 4105,   14, 5270,  293, 3104,   23,
         4001,    6, 4183,   15,   16,  764,    6,    6,  184,   22,  902,   59,
           18,   83,    4,    9,  631,   43,  253, 5364,   49, 4672,   16, 1414,
         1170,  165,  210, 7837,   15,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [  92, 3969,  584,  496,    4,   30, 3476, 4175,    4,  112,   30,   32,
         1388,   83,    4, 1453,  306,    6,    4, 2250, 2784,   15,    9,   23,
          972, 5131,    4,   14,   14,  330, 2921,   15, 6275,    5,  147,   31,
          638,    4,   36,   27,  291,  502,  122,  152,  930,  418,    4,   50,
           36,  107,  611, 2250,    4,  112, 3476,   16, 7046, 1707,   18, 2729,
           20, 3735,    4,  403,   32,   36,  516,  124,   47,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [ 564,  828,  957,    4, 1238, 1334,   81, 1277,    4,  112,   56, 4142,
          156, 3403,   16, 2039, 4175,   20,   28, 1561,    4, 2971,   31,   39,
            4, 3113, 9592,   22,  253, 2295,   49, 1615,   22,   28, 1108,   15,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1],
        [3192,   32,  107,  105, 2486, 7095,   39,   44, 3089,   56, 9552, 3089,
           56, 9272, 1056,   56, 9952, 3089,    5,   92,   27,   40, 4106,    6,
         2457,   16,   36, 2714,    4,  428, 1185,   56, 9552, 1185,   56, 9272,
         1056,   56, 9952, 1185,    4, 3694,    5,  104,   83,   30,  257,  393,
         1036,   16, 1175,   36,   29, 3366,    5,    2,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1]], device='cuda:7'), 'target_lengths': tensor([58, 88, 48, 20, 67, 71, 38, 56], device='cuda:7'), 'ntokens': 446, 'nsentences': 8}
##################### {'id': tensor([ 10278, 118589, 193307,  71367, 136170, 161545, 146107,  72446, 217905,
        224488,  86508, 189907,  57562, 129794,  37402, 148722, 175300,   8213,
        213600, 100983, 103966, 175248,  93158, 104135], device='cuda:0'), 'net_input': {'src_tokens': tensor([[-0.0033, -0.0043,  0.0010,  ..., -0.0088,  0.0305,  0.0122],
        [-0.0010, -0.0002, -0.0023,  ...,  0.0128,  0.0096,  0.0005],
        [-0.0012, -0.0009, -0.0011,  ..., -0.0009, -0.0010, -0.0010],
        ...,
        [-0.0017, -0.0105, -0.0146,  ...,  0.0517,  0.0516,  0.0000],
        [ 0.0014,  0.0010,  0.0012,  ..., -0.0009, -0.0010,  0.0000],
        [-0.0002, -0.0002,  0.0001,  ...,  0.0113,  0.0104,  0.0000]],
       device='cuda:0', dtype=torch.float16), 'src_lengths': tensor([96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160,
        96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160, 96160,
        96160, 96159, 96159, 96159], device='cuda:0'), 'prev_output_tokens': tensor([[   2,   41,  260,  ...,    1,    1,    1],
        [   2,   64,  210,  ...,    1,    1,    1],
        [   2,  840,  423,  ...,    1,    1,    1],
        ...,
        [   2,   41,  161,  ...,    1,    1,    1],
        [   2, 1493,  654,  ...,    1,    1,    1],
        [   2,   92,   27,  ...,    1,    1,    1]], device='cuda:0')}, 'transcript': {'tokens': tensor([[ 25,  87,  21,  ...,   1,   1,   1],
        [  8,  69, 108,  ...,   1,   1,   1],
        [131, 423, 887,  ...,   1,   1,   1],
        ...,
        [ 21,  11,   6,  ...,   1,   1,   1],
        [125, 108, 414,  ...,   1,   1,   1],
        [ 33,  26,  13,  ...,   1,   1,   1]], device='cuda:0'), 'cluster_tokens': tensor([[37, 85, 37,  ..., 37, 37, 37],
        [37, 37, 37,  ..., 37, 37, 37],
        [37, 34, 73,  ..., 37, 37, 37],
        ...,
        [37, 85, 37,  ..., 37, 37, 37],
        [37, 37,  9,  ..., 37, 37, 37],
        [37, 85, 37,  ..., 37, 37, 37]], device='cuda:0'), 'lengths': tensor([31, 35, 16, 22, 21, 29, 23, 28, 26, 27, 25, 33, 23, 26, 29, 28, 23, 32,
        24, 27, 42, 22, 23, 27], device='cuda:0'), 'ntokens': 642}, 'target': tensor([[  41,  260,   30,  ...,    1,    1,    1],
        [  64,  210, 1257,  ...,    1,    1,    1],
        [ 840,  423,  887,  ...,    1,    1,    1],
        ...,
        [  41,  161,   75,  ...,    1,    1,    1],
        [1493,  654, 8362,  ...,    1,    1,    1],
        [  92,   27,   40,  ...,    1,    1,    1]], device='cuda:0'), 'target_lengths': tensor([29, 41, 16, 20, 20, 26, 24, 30, 24, 30, 59, 19, 26, 26, 21, 35, 26, 34,
        23, 22, 40, 22, 24, 27], device='cuda:0'), 'ntokens': 664, 'nsentences': 24}
2023-07-03 07:49:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset

/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

##################### {'id': tensor([157197,  38274,    875, 166567, 197999, 174975,  19280, 103227,  43293,
        188307,  31852, 204322, 219963,  70576, 157711,  22333, 194296, 186071,
         48003,  26751,  59418, 135028,  94266,  52035], device='cuda:1'), 'net_input': {'src_tokens': tensor([[ 0.0032,  0.0016, -0.0017,  ...,  0.0012,  0.0012, -0.0016],
        [ 0.0041,  0.0031,  0.0021,  ...,  0.0032,  0.0045,  0.0055],
        [-0.0317, -0.0021,  0.0120,  ..., -0.1658, -0.1702, -0.1477],
        ...,
        [-0.0132, -0.0187, -0.0207,  ...,  0.0017,  0.0074,  0.0148],
        [ 0.0019,  0.0010,  0.0005,  ...,  0.0009,  0.0016,  0.0000],
        [ 0.0046,  0.0017,  0.0048,  ...,  0.0005,  0.0006,  0.0000]],
       device='cuda:1', dtype=torch.float16), 'src_lengths': tensor([95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200,
        95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200, 95200,
        95200, 95200, 95199, 95199], device='cuda:1'), 'prev_output_tokens': tensor([[   2,  376, 1439,  ...,    1,    1,    1],
        [   2,  104,   76,  ..., 2525,  239,    5],
        [   2,  404,  130,  ...,    1,    1,    1],
        ...,
        [   2, 7167,   31,  ...,    1,    1,    1],
        [   2,  147,  493,  ...,    1,    1,    1],
        [   2,  376,  734,  ...,    1,    1,    1]], device='cuda:1')}, 'transcript': {'tokens': tensor([[   7,  473,   21,  ...,    1,    1,    1],
        [   8,   29,   24,  ...,    1,    1,    1],
        [  25,   73,   87,  ...,    1,    1,    1],
        ...,
        [ 220,   19,   66,  ...,    1,    1,    1],
        [  67,   19,  169,  ...,    1,    1,    1],
        [1223,    4,    7,  ...,    1,    1,    1]], device='cuda:1'), 'cluster_tokens': tensor([[37, 37, 37,  ..., 37, 37, 37],
        [37, 83, 38,  ..., 37, 37, 37],
        [37,  6, 85,  ..., 37, 37, 37],
        ...,
        [ 6, 38, 85,  ..., 37, 37, 37],
        [37, 38, 85,  ..., 37, 37, 37],
        [83, 11, 37,  ..., 37, 37, 37]], device='cuda:1'), 'lengths': tensor([25, 37, 24, 27, 16, 25, 42, 31, 18, 35, 25, 26, 14, 24, 24, 36, 32, 20,
        30, 20, 30, 18, 22, 25], device='cuda:1'), 'ntokens': 626}, 'target': tensor([[ 376, 1439, 2467,  ...,    1,    1,    1],
        [ 104,   76,  113,  ...,  239,    5,    2],
        [ 404,  130,  566,  ...,    1,    1,    1],
        ...,
        [7167,   31, 2274,  ...,    1,    1,    1],
        [ 147,  493, 2269,  ...,    1,    1,    1],
        [ 376,  734,    4,  ...,    1,    1,    1]], device='cuda:1'), 'target_lengths': tensor([24, 43, 38, 39, 17, 29, 33, 31, 17, 34, 36, 30, 16, 25, 27, 34, 35, 19,
        30, 28, 39, 22, 24, 29], device='cuda:1'), 'ntokens': 699, 'nsentences': 24}
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

##################### {'id': tensor([ 70651,   8259,  79725,  40712,  87063, 124015, 149027,  94917, 163142,
        195792, 202140,  48241,  37467,  39215, 202810,  79040,  75134,  43180,
        209410, 113512, 185302, 157064, 116010, 109498,  47315,  70194, 132370,
         50707,  57280, 188226, 155547, 221334,  23709,  38343, 117514, 218273,
          2067,  12654, 175063, 200614], device='cuda:3'), 'net_input': {'src_tokens': tensor([[-1.0071e-03, -2.0447e-03, -2.8992e-03,  ..., -1.3123e-03,
         -1.6174e-03, -2.8992e-03],
        [-2.1973e-03, -1.6174e-03, -4.9438e-03,  ...,  1.0181e-01,
          9.5215e-02,  7.7026e-02],
        [ 4.0558e-02,  4.4067e-02,  4.6875e-02,  ..., -1.1047e-02,
         -6.7444e-03, -5.8289e-03],
        ...,
        [ 4.4250e-03,  3.9978e-03,  3.0212e-03,  ...,  1.0925e-02,
          1.0437e-02,  0.0000e+00],
        [ 9.1553e-05, -1.2207e-04,  3.9673e-04,  ..., -1.7395e-03,
         -1.6174e-03,  0.0000e+00],
        [-1.0681e-03, -9.7656e-04, -8.5449e-04,  ...,  1.7395e-03,
          1.0376e-03,  0.0000e+00]], device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160,
        56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160,
        56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160, 56160,
        56160, 56160, 56160, 56160, 56160, 56160, 56160, 56159, 56159, 56159],
       device='cuda:3'), 'prev_output_tokens': tensor([[   2,  298,    4,  ...,    1,    1,    1],
        [   2,   92,  898,  ...,    1,    1,    1],
        [   2,  526,    4,  ...,    1,    1,    1],
        ...,
        [   2,   64,   23,  ...,    1,    1,    1],
        [   2, 8144,  937,  ...,    1,    1,    1],
        [   2,  937, 1007,  ...,    1,    1,    1]], device='cuda:3')}, 'transcript': {'tokens': tensor([[  29,    4,   25,  ...,    1,    1,    1],
        [   7, 5972,  772,  ...,    1,    1,    1],
        [  19,  130,   20,  ...,    1,    1,    1],
        ...,
        [   8,   19,  703,  ...,    1,    1,    1],
        [7779,   19,   26,  ...,    1,    1,    1],
        [1031,  297,   44,  ...,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[83, 11, 37,  ..., 37, 37, 37],
        [37, 28, 75,  ..., 37, 37, 37],
        [38, 72, 77,  ..., 37, 37, 37],
        ...,
        [37, 38, 88,  ..., 37, 37, 37],
        [28, 38, 85,  ..., 37, 37, 37],
        [38, 35, 82,  ..., 37, 37, 37]], device='cuda:3'), 'lengths': tensor([11, 12, 22, 16, 13, 12, 16, 20, 14, 15, 21, 19, 16, 23, 21, 17, 12, 19,
        13, 21, 13, 16, 13, 14, 14, 34, 14, 24, 14, 24, 14, 18, 20, 17, 16, 16,
        17, 18, 12,  8], device='cuda:3'), 'ntokens': 669}, 'target': tensor([[ 298,    4, 1496,  ...,    1,    1,    1],
        [  92,  898,   18,  ...,    1,    1,    1],
        [ 526,    4,   31,  ...,    1,    1,    1],
        ...,
        [  64,   23,  734,  ...,    1,    1,    1],
        [8144,  937, 5326,  ...,    1,    1,    1],
        [ 937, 1007,   44,  ...,    1,    1,    1]], device='cuda:3'), 'target_lengths': tensor([ 8, 14, 29, 18, 11,  7, 16, 23, 11, 15, 21, 17,  8, 19, 20, 17, 11, 17,
        11, 23, 12, 15, 20, 14, 19, 40, 13, 24, 17, 23, 13, 22, 28, 11, 17, 14,
        16, 22, 12,  7], device='cuda:3'), 'ntokens': 675, 'nsentences': 40}
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(

/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### {'id': tensor([ 637,  195, 1392,  553,  768, 1097,  232, 1087,  887, 1248, 1055,  702,
         609,  749,   30,  761,  660,  379, 1349, 1334, 1158,  434,  544, 1106,
         603, 1191, 1309,   52,  556,  970, 1246,  477,  785,  319,  470,  739,
        1117, 1275, 1216,    5], device='cuda:6'), 'net_input': {'src_tokens': tensor([[-1.4038e-03,  3.3569e-04,  9.4604e-04,  ...,  1.0986e-03,
          1.4648e-03,  1.9531e-03],
        [-9.1553e-05, -6.1035e-05, -1.8311e-04,  ..., -7.0190e-04,
         -2.1362e-04, -6.7139e-04],
        [-1.9836e-03,  4.8218e-03, -3.2349e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 8.5449e-04, -6.1035e-05, -2.2583e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.0142e-03, -1.4648e-03, -4.5776e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-6.4087e-03, -6.3477e-03, -4.7302e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:6', dtype=torch.float16), 'src_lengths': tensor([52320, 52320, 52000, 51840, 51840, 51680, 51680, 51680, 51520, 51520,
        51200, 51200, 51040, 50880, 50399, 50240, 50240, 50240, 50240, 50080,
        50080, 50080, 50080, 49920, 49920, 49919, 49600, 49280, 49119, 48960,
        48959, 48800, 48639, 48480, 48480, 48160, 48000, 47840, 47840, 47840],
       device='cuda:6'), 'prev_output_tokens': tensor([[   2,  404,  280,  ...,    1,    1,    1],
        [   2,   92,   27,  ...,    1,    1,    1],
        [   2,  298,  853,  ...,    1,    1,    1],
        ...,
        [   2,  330,  311,  ...,  247, 4035,    5],
        [   2,   41,  319,  ...,    1,    1,    1],
        [   2,  298,    4,  ...,    1,    1,    1]], device='cuda:6'), 'task': 'st'}, 'transcript': {'tokens': tensor([[  53,  465,   11,   18,   66,    7,  818,   10,   87,   21,    4,   29,
           24, 1621,  639,   10,   87,   21,    5,    2,    1,    1,    1,    1,
            1],
        [ 115,    4,   17,   11,    6,  116,   39, 8519, 3770,  224,   25, 1080,
           25,  192,   11,   18,  296,   10,   87,   17,    5,    2,    1,    1,
            1],
        [  29,   19, 2797,   62,   13, 5129, 6049, 5334,   12, 3236,   10,    7,
         1997,   22,   54, 1543,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [   8,    4, 1250,   12, 6354,  116,   71,  813,    4,   24,   73, 3918,
            6,   20,  126, 2410,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [ 115,    4,  101,   11,    6, 6903,   54,    7, 2483, 1643, 1833,   12,
           56, 4494,  412, 2019,  156,  741,    5,    2,    1,    1,    1,    1,
            1],
        [  33,   26,  179,  929, 1947,    5,   24,  442,   33, 1678,    9, 5448,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [4069,    4,   21,   11,    6,   86,  261,  509,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,  289,   24,   63, 3163,   55,  108,  447, 5486,  140, 1678,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  84,   26,   13, 4112,   25,   73,   87,   55,  155, 1431,    8, 4563,
            6,    5, 3940,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 101,  842,   91,   12,    7, 4615, 1566, 3392,  247,    6,   12,   81,
         4336,  755,  106,  170,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [ 115,    4,   19,  113, 2990,   17,   17,   26, 4767,    4,   55,  115,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,   34,    9,   13, 2549,   71,   33, 4268,   55, 2869, 1345,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  67,   19, 6980,  134,    5,   19,  246,    4,   38,  533,   11,   57,
          142,   10,  876,  121,   10,    7, 1106,   57,  656,    5,    2,    1,
            1],
        [  53, 5443,   51, 1987, 2562,   18,  232,   69,   70,   34, 3423,   24,
           18,  713,    6,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 914,    4,   91,   12,  117, 2348,   26,  142,   10,   66,   10,  175,
          976, 3019,   10, 3647,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [   7, 2980,   11,    6, 2285,    5,    2,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  67,   19,  113, 1385,   13,  325,   80, 5247,    5,    2,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 168,   63,  248, 2116,    4,  251,   63,  159, 1797,   54,    6,    5,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  21,   11,    6, 5472,    9,    7, 2082,  230,  115,    4,   67,   24,
           66,   39, 1248, 2212,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [   8,  180,   94,  169,   51,  529,   10, 2034,   21,    8,   53,   11,
           48,   51,  529,   10,   86,  205, 2639,    5,    2,    1,    1,    1,
            1],
        [   8,   17,   26,   39, 7221,  106,  284,   10,   59,  445,   62, 1503,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,   25,   73,  884,   44,  138, 1767,   26,    7, 9233, 1244,   42,
            2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   19,   73,  746,   12,  203, 7378,  185,  993,   17,   19,   34,
          665,   85, 3928,  440,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [  33,   26,   39, 1248,  546,    8, 8464,   55,   25,   10,  205,   69,
            5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   8,   24,  204,  323,   17,    8,   21, 1742,  170,   13, 9054, 5542,
           55,   13, 1025,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  17,  800,   11,    6, 8092,    4,    8,   21,   11,    6, 8092,  172,
         6896,    4,    8,   21,   11,    6,  838,  122,  371,  430, 1256,    5,
            2],
        [  84, 1359,   11,   18,  419,   73,  455,  614,  786,   20,    5,   68,
          194,   65,   84, 3994,   11,   18, 7581, 3379,    5,    2,    1,    1,
            1],
        [ 115,    4,  120,   19,  368,    7, 3506,   38, 1326,  371, 3769,  438,
           19,  192,   11,   18,  641,  250,   17,   11,    6, 3756,    5,    2,
            1],
        [  19, 3367,  132,   69,   13,  574,   20,  556,   93,   14,   18,   12,
          948, 6446,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  19,  192,   11,   18,  641,  116,  324,   79,    9, 3150,    4, 3942,
           17,   11,    6,  461,   12,   21,    5,    2,    1,    1,    1,    1,
            1],
        [   8,   21,   11,    6,  250,   24,  296,   10, 1082,    4,    8,   24,
          296,   10, 1082,   21,  172, 2392,    5,    2,    1,    1,    1,    1,
            1],
        [3623,   17,    4,   24,  175,   39, 2497, 5352, 1375,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [   7,  567,   26,   29, 3849,    4,   21,   11,    6, 3294, 1244,   35,
          729, 2592,   54,    5,    2,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  67,  103,   25,  884,  110,  440,    4,   19,   11,   45,   86,   29,
         1123,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  26,   17,  250,   25,   73, 1452, 1313,   25,   87,   66,   13,  555,
          765,    6,  859,  115,   42,    2,    1,    1,    1,    1,    1,    1,
            1],
        [  13, 5577, 1751,  144,  226,  952,   80,   33, 1390,   55,   13,  535,
          183,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  33,   26,   13, 1678,  691,   71,    7,  179, 2535, 6142,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [ 417,  311, 3110,  430,  290,    4,   13,  277, 2667, 5292,   48,  480,
           10,  175,   25,  142,    5,    2,    1,    1,    1,    1,    1,    1,
            1],
        [  53,  162, 1456,  100,    7,   94,    9,   33,  964,    5,    2,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1],
        [  29,    4,    7, 2127, 2317,  164,   51, 4416,   55,  134,    5,    2,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1]], device='cuda:6'), 'cluster_tokens': tensor([[37, 85, 85, 35, 85, 37, 88, 37, 85, 37, 11, 83, 38, 31, 94, 37, 85, 37,
         11, 83, 37, 37, 37, 37, 37],
        [83, 11, 37, 85, 37, 83, 38, 94, 94, 11, 37, 94, 37, 85, 85, 35, 49, 37,
         85, 37, 11, 83, 37, 37, 37],
        [83, 38, 88, 31, 37, 34,  9, 32, 37, 94, 37, 37, 38, 35, 49,  9, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 11, 83, 37, 49, 83, 37, 94, 11, 38,  6,  9, 37, 77, 37, 32, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 85, 37, 88, 49, 37, 37, 35, 56, 37, 38, 35, 35, 35, 35, 35,
         11, 83, 37, 37, 37, 37, 37],
        [37, 85, 94, 50,  9, 11, 38, 31, 37, 32, 37, 25, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 37, 85, 37, 83, 83,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [38, 88, 38, 85,  2, 37, 37, 37, 38, 35, 32, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 32, 37,  6, 85, 37, 37, 56, 37,  9, 37, 11, 83, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37],
        [38, 31, 50, 37, 37, 75, 38, 35, 77, 37, 37, 38, 94, 37, 37, 37, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 38, 83, 88, 37, 37, 85,  2, 11, 37, 83, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [38, 85, 37, 37, 36, 37, 37, 94, 37, 50, 24, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 31, 37, 11, 38, 88, 11, 38, 35, 85, 77, 49, 37, 38, 35, 37, 37,
         38, 77, 35, 11, 83, 37, 37],
        [37, 31, 38, 35, 94, 35, 77, 37, 50, 85, 83, 38, 35, 35, 37, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 50, 37, 37, 23, 85, 49, 37, 85, 37, 85, 83, 37, 37, 28, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 23, 85, 37,  2, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 83, 31, 37, 83, 37, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 34, 56, 11, 50, 85, 37, 23, 49, 37, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 31, 37, 37, 88, 37, 83, 11, 37, 38, 85, 38,  2, 94, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 37, 56, 85, 38,  6, 37, 49, 37, 37, 37, 85, 31, 38,  6, 37, 83, 85,
          2, 11, 83, 37, 37, 37, 37],
        [37, 37, 85, 38, 29, 37, 37, 37, 35, 35, 31, 13, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 37,  6, 88, 82, 37,  2, 85, 37, 49, 32, 11, 83, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38,  6, 83, 37, 38, 35, 50, 32, 37, 38, 85, 59, 37, 83, 83, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 38,  2, 18, 37, 32, 37, 37, 37, 85, 37, 11, 83, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 38, 83, 85, 37, 37, 37, 31, 37, 37, 76, 32, 37, 37, 24, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 23, 85, 37, 29, 11, 37, 37, 85, 37, 29, 83, 83, 11, 37, 37, 85, 37,
         33, 35, 35, 35,  2, 11, 83],
        [37, 85, 85, 35, 50,  6, 35, 35, 35, 77, 11, 38,  9, 11, 37, 85, 85, 35,
         28, 56, 11, 83, 37, 37, 37],
        [83, 11, 37, 38, 49, 37, 32, 38, 35, 35, 35, 82, 38, 85, 85, 35, 88, 50,
         37, 85, 37,  6, 11, 83, 37],
        [38, 31, 37, 37, 37, 38, 77, 35, 35, 38, 35, 37, 94, 94, 11, 83, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [38, 85, 85, 35, 88, 83,  2, 37, 37,  2, 11, 83, 37, 85, 37, 32, 37, 37,
         11, 83, 37, 37, 37, 37, 37],
        [37, 37, 85, 37, 50, 38, 49, 37, 59, 11, 37, 38, 49, 37, 59, 37, 83, 83,
         11, 83, 37, 37, 37, 37, 37],
        [37, 37, 11, 38, 85, 38, 83,  2, 94, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 32, 85, 83,  2, 11, 37, 85, 37, 83, 32, 38, 77, 35, 49, 11, 83, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 37, 37, 88, 37, 83, 11, 38, 85, 35, 83, 83, 83, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [85, 37, 50, 37,  6, 88, 37, 37, 85, 85, 37, 50, 24, 37, 31, 83, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 28,  9, 85, 85, 16, 37, 37,  9, 37, 37, 83, 24, 11, 83, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 37, 32, 31, 37, 37, 94, 94, 32, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [38, 35, 28, 35, 35, 11, 37, 50, 38, 35, 31, 35, 37, 85, 37, 49, 11, 83,
         37, 37, 37, 37, 37, 37, 37],
        [37, 85, 83, 37, 37, 56, 37, 37,  9, 11, 83, 37, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37],
        [83, 11, 37,  9, 56, 85, 38,  2, 37, 37, 11, 83, 37, 37, 37, 37, 37, 37,
         37, 37, 37, 37, 37, 37, 37]], device='cuda:6'), 'lengths': tensor([20, 22, 18, 18, 20, 14, 10, 13, 17, 18, 14, 13, 23, 17, 18,  7, 10, 13,
        18, 21, 14, 13, 18, 14, 17, 25, 22, 24, 16, 20, 20, 11, 17, 15, 18, 15,
        12, 18, 11, 12], device='cuda:6'), 'ntokens': 656}, 'target': tensor([[ 404,  280,  196,  ...,    1,    1,    1],
        [  92,   27,  149,  ...,    1,    1,    1],
        [ 298,  853,   18,  ...,    1,    1,    1],
        ...,
        [ 330,  311, 3110,  ..., 4035,    5,    2],
        [  41,  319,  478,  ...,    1,    1,    1],
        [ 298,    4,  161,  ...,    1,    1,    1]], device='cuda:6'), 'target_lengths': tensor([16, 20, 19, 18, 20, 16, 10, 15, 15, 18, 12, 12, 22, 21, 12,  6, 13, 12,
        16, 14, 18, 14, 18, 11, 21, 20, 24, 21, 15, 14, 16, 10, 16, 15, 23, 16,
        12, 26, 11, 13], device='cuda:6'), 'ntokens': 641, 'nsentences': 40}
##################### {'id': tensor([ 124,  315,  375, 1317, 1401, 1393,  407,  241,  954,  626, 1312,   47,
         535,  478, 1202,  877,  373, 1240, 1260,  440,   22,  546,  872, 1249,
         501, 1350,    6, 1225,   60, 1230, 1296,  912,   53, 1276,  286,  644,
         595,  718,  746, 1116,  281, 1215,    8,  895,  120,  127,  499, 1196],
       device='cuda:5'), 'net_input': {'src_tokens': tensor([[-3.0518e-04, -1.0376e-03, -1.9836e-03,  ...,  2.2278e-03,
          1.8921e-03,  1.1902e-03],
        [-4.8828e-04,  3.0518e-05, -6.1035e-05,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.3030e-03,  3.5706e-03,  3.0518e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [-2.7466e-04, -1.8311e-04, -1.8311e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.4932e-04,  6.7139e-04,  4.2725e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 6.2866e-03,  7.2937e-03,  6.6223e-03,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:5', dtype=torch.float16), 'src_lengths': tensor([47840, 47680, 47680, 47520, 47360, 47200, 47200, 47200, 47040, 47039,
        46880, 46720, 46719, 46560, 46400, 46400, 46400, 46400, 46240, 46240,
        46240, 46080, 46079, 45920, 45920, 45920, 45919, 45760, 45760, 45440,
        45440, 45120, 44960, 44960, 44640, 44640, 44640, 44640, 44480, 44480,
        44480, 44160, 44160, 44160, 44160, 44000, 44000, 43840],
       device='cuda:5'), 'prev_output_tokens': tensor([[   2,  400,  769,  ...,    1,    1,    1],
        [   2, 2540,   41,  ...,    1,    1,    1],
        [   2,   92,   76,  ...,    1,    1,    1],
        ...,
        [   2,   99,   27,  ...,    1,    1,    1],
        [   2,   92, 2370,  ...,    1,    1,    1],
        [   2,   72,  705,  ...,    1,    1,    1]], device='cuda:5'), 'task': 'st'}, 'transcript': {'tokens': tensor([[  70,  451,  108,  ...,    1,    1,    1],
        [ 150,    4,  903,  ...,    1,    1,    1],
        [ 251,   63, 4129,  ...,    1,    1,    1],
        ...,
        [  17,  172,   26,  ...,    1,    1,    1],
        [  33, 3550,   17,  ...,    1,    1,    1],
        [  19,  172,   87,  ...,    2,    1,    1]], device='cuda:5'), 'cluster_tokens': tensor([[50, 85, 37,  ..., 37, 37, 37],
        [59, 11, 38,  ..., 37, 37, 37],
        [50, 85, 83,  ..., 37, 37, 37],
        ...,
        [37, 83, 85,  ..., 37, 37, 37],
        [37, 32, 37,  ..., 37, 37, 37],
        [38, 83, 85,  ..., 83, 37, 37]], device='cuda:5'), 'lengths': tensor([ 9, 13, 12, 10, 15, 12, 17, 14, 11, 21, 15, 14, 21, 13, 21, 14,  9, 16,
        16, 14, 14, 18, 17, 15, 18, 12, 13, 11, 14, 18, 22, 18, 12, 13, 10, 10,
         9, 15, 18, 20,  9, 15, 13, 13, 11, 12, 14, 20], device='cuda:5'), 'ntokens': 691}, 'target': tensor([[ 400,  769,  654,  ...,    1,    1,    1],
        [2540,   41,    4,  ...,    1,    1,    1],
        [  92,   76, 3712,  ...,    1,    1,    1],
        ...,
        [  99,   27,  263,  ...,    1,    1,    1],
        [  92, 2370,    4,  ...,    1,    1,    1],
        [  72,  705,   30,  ...,    1,    1,    1]], device='cuda:5'), 'target_lengths': tensor([ 8, 14, 18, 14, 17, 14, 12, 13, 14, 24, 12, 15, 19, 13, 21, 16, 11, 17,
        18, 12,  7, 18, 20, 18, 13, 14, 11, 15, 16, 15, 23, 17,  9, 20, 11, 10,
         8, 19, 22, 13,  7, 18, 13, 16, 16, 12, 14, 15], device='cuda:5'), 'ntokens': 712, 'nsentences': 48}
##################### {'id': tensor([ 985,  634,  405,  173, 1111,  447,  748, 1041,  333, 1057,  153,  726,
           0,  101,  416,  350,  132, 1213, 1017,  454,  745, 1010,   82,  155,
         398,  806,  706,  792,  685,   86, 1195,   70,   38, 1252,  860, 1101,
         526, 1221,  420,  837], device='cuda:7'), 'net_input': {'src_tokens': tensor([[ 0.0017,  0.0017,  0.0008,  ..., -0.0044, -0.0027, -0.0004],
        [-0.0004,  0.0005,  0.0017,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0008,  0.0005,  0.0005,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0019, -0.0027, -0.0042,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0032, -0.0024, -0.0023,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0020, -0.0018, -0.0005,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:7', dtype=torch.float16), 'src_lengths': tensor([57759, 57600, 57280, 57119, 56960, 56800, 56800, 56800, 56639, 56480,
        56160, 56160, 56159, 56000, 55520, 55360, 54720, 54720, 54560, 54560,
        54400, 54400, 54240, 54240, 54239, 54080, 53920, 53600, 53440, 53440,
        53440, 53120, 53120, 53120, 53120, 52960, 52960, 52800, 52480, 52480],
       device='cuda:7'), 'prev_output_tokens': tensor([[   2,  147,  257,  ...,    1,    1,    1],
        [   2,  104, 4611,  ...,    1,    1,    1],
        [   2,  376, 2249,  ...,    1,    1,    1],
        ...,
        [   2,  404,  145,  ...,    1,    1,    1],
        [   2,   72,  256,  ...,    1,    1,    1],
        [   2,  738, 5756,  ...,    1,    1,    1]], device='cuda:7'), 'task': 'st'}, 'transcript': {'tokens': tensor([[  67,   21,   26,  ...,    1,    1,    1],
        [  24,  842,  277,  ...,    1,    1,    1],
        [   7, 3187, 1878,  ...,    1,    1,    1],
        ...,
        [  25,   73,  116,  ...,    1,    1,    1],
        [  19,  641,    4,  ...,    1,    1,    1],
        [  91, 1072,   94,  ...,    1,    1,    1]], device='cuda:7'), 'cluster_tokens': tensor([[37, 37, 85,  ..., 37, 37, 37],
        [38, 31, 50,  ..., 37, 37, 37],
        [37, 75, 33,  ..., 37, 37, 37],
        ...,
        [37,  6, 83,  ..., 37, 37, 37],
        [38, 88, 11,  ..., 37, 37, 37],
        [50, 24, 56,  ..., 37, 37, 37]], device='cuda:7'), 'lengths': tensor([23, 20, 14, 14, 16, 27, 22, 17, 19, 15, 17, 17, 13, 20, 11, 19, 13, 23,
        13, 15, 13, 18, 19, 13, 13, 27, 11, 13, 10, 14, 18, 21, 15, 16, 16, 20,
        16, 14, 12,  9], device='cuda:7'), 'ntokens': 656}, 'target': tensor([[ 147,  257,  217,  ...,    1,    1,    1],
        [ 104, 4611, 1012,  ...,    1,    1,    1],
        [ 376, 2249, 2190,  ...,    1,    1,    1],
        ...,
        [ 404,  145,  317,  ...,    1,    1,    1],
        [  72,  256,    4,  ...,    1,    1,    1],
        [ 738, 5756,  157,  ...,    1,    1,    1]], device='cuda:7'), 'target_lengths': tensor([17, 22, 12, 12, 29, 26, 20, 18, 28, 14, 16, 18, 11, 14, 15, 16, 13, 23,
        11, 15, 15, 21, 16, 14, 14, 22, 13, 13, 12, 18, 18, 23, 10, 20, 25, 19,
        15, 14, 15,  9], device='cuda:7'), 'ntokens': 676, 'nsentences': 40}
##################### {'id': tensor([ 396,  627,  118,  849,  752,  835,  549,  218,  481,  829,   98, 1001,
         598,  538,  977,  147,  630, 1147,  361,  123, 1022,  586,  511,   35,
         378, 1243,  723,  648, 1167,  803,  738,  437,  771,  397,  248,   65,
         722, 1328,  787,  324,  743, 1331,  138,  363,  505,   92,  827,  616],
       device='cuda:4'), 'net_input': {'src_tokens': tensor([[-0.0120, -0.0126, -0.0142,  ..., -0.0008, -0.0009, -0.0011],
        [ 0.0014, -0.0006, -0.0028,  ...,  0.0040,  0.0040,  0.0035],
        [-0.0005, -0.0002, -0.0003,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0003, -0.0007, -0.0004,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0121, -0.0121, -0.0112,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0041,  0.0044,  0.0061,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:4', dtype=torch.float16), 'src_lengths': tensor([43840, 43840, 43680, 43680, 43520, 43520, 43520, 43520, 43360, 43360,
        43200, 43200, 43040, 42880, 42720, 42720, 42720, 42720, 42720, 42560,
        42400, 42400, 42240, 42240, 42240, 42080, 42080, 42080, 41920, 41920,
        41920, 41760, 41759, 41600, 41440, 41440, 41280, 41120, 41120, 40960,
        40960, 40800, 40480, 40480, 40320, 40320, 40160, 40000],
       device='cuda:4'), 'prev_output_tokens': tensor([[   2,   99,  130,  ...,    1,    1,    1],
        [   2,  147,   31,  ...,    1,    1,    1],
        [   2,  504,   27,  ...,    1,    1,    1],
        ...,
        [   2,   99,  178,  ...,    1,    1,    1],
        [   2,   92, 1133,  ...,    1,    1,    1],
        [   2,   92,   82,  ...,    1,    1,    1]], device='cuda:4'), 'task': 'st'}, 'transcript': {'tokens': tensor([[  21,  188,  765,  ...,    1,    1,    1],
        [  67,   19, 1608,  ...,    1,    1,    1],
        [  19,   11,  121,  ...,    1,    1,    1],
        ...,
        [  29,   24,   11,  ...,    1,    1,    1],
        [   7,  567,   26,  ...,    1,    1,    1],
        [  86,   13, 2496,  ...,    1,    1,    1]], device='cuda:4'), 'cluster_tokens': tensor([[37, 85, 24,  ..., 37, 37, 37],
        [37, 38,  6,  ..., 37, 37, 37],
        [38, 85, 35,  ..., 37, 37, 37],
        ...,
        [83, 38, 85,  ..., 37, 37, 37],
        [37, 32, 85,  ..., 37, 37, 37],
        [83, 37,  9,  ..., 37, 37, 37]], device='cuda:4'), 'lengths': tensor([13, 15, 18, 12, 15, 14, 13, 22, 16, 17, 17, 11, 15, 13, 17, 11, 13, 20,
        13, 13, 13, 18, 13, 11, 13, 17, 16, 15, 24, 15, 14, 11, 13, 13, 20, 11,
        15, 15, 15, 13, 11, 15, 16, 12, 17, 11, 14, 15], device='cuda:4'), 'ntokens': 704}, 'target': tensor([[  99,  130, 5800,  ...,    1,    1,    1],
        [ 147,   31,  666,  ...,    1,    1,    1],
        [ 504,   27,   40,  ...,    1,    1,    1],
        ...,
        [  99,  178,  173,  ...,    1,    1,    1],
        [  92, 1133,   27,  ...,    1,    1,    1],
        [  92,   82,  621,  ...,    1,    1,    1]], device='cuda:4'), 'target_lengths': tensor([15, 18, 15, 11, 20, 14, 14, 15, 13, 21, 13, 10, 31, 13, 15, 11, 12, 21,
        14, 13, 14, 13, 13, 13, 16, 15, 16, 12, 26, 14, 15, 12, 19, 12, 18, 29,
        17, 13, 17, 13, 12, 14, 10, 11, 21, 13, 14, 17], device='cuda:4'), 'ntokens': 738, 'nsentences': 48}
##################### {'id': tensor([1045,  937,  842, 1386,  456, 1338,  845, 1268, 1286, 1159, 1345,  965,
         510,  767,  805,  560,  894, 1283, 1316,  550,  594,  262,  696, 1103,
          78, 1178,  419, 1325,  185, 1056,   23,  512,  778, 1122,  962,  214,
        1175,  459,  896,   85,  820, 1399, 1038, 1293,  134,  683, 1397,  589,
         328, 1300,  306,  258,  998, 1391, 1416, 1020], device='cuda:3'), 'net_input': {'src_tokens': tensor([[-0.0261, -0.0283, -0.0276,  ..., -0.0079, -0.0096, -0.0031],
        [-0.0936, -0.0921, -0.0812,  ...,  0.0025,  0.0043,  0.0024],
        [-0.0138, -0.0157, -0.0162,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0258,  0.0133, -0.0029,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0007, -0.0015, -0.0016,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0022, -0.0069, -0.0104,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:3', dtype=torch.float16), 'src_lengths': tensor([40000, 40000, 39840, 39840, 39680, 39680, 39520, 39520, 39200, 38880,
        38880, 38720, 38720, 38720, 38719, 38560, 38560, 38400, 38240, 38240,
        38080, 38080, 38080, 37920, 37600, 37440, 37440, 37440, 37440, 37280,
        37119, 36960, 36960, 36800, 36800, 36640, 36640, 36640, 36480, 36480,
        36000, 35999, 35680, 35680, 35680, 35520, 35360, 35360, 35360, 35200,
        35200, 35200, 35200, 35040, 34720, 34719], device='cuda:3'), 'prev_output_tokens': tensor([[  2,  92,  27,  ...,   1,   1,   1],
        [  2,  72, 354,  ...,   1,   1,   1],
        [  2,  92,  27,  ...,   1,   1,   1],
        ...,
        [  2,  72, 915,  ...,   1,   1,   1],
        [  2,  64,  30,  ...,   1,   1,   1],
        [  2, 504,  76,  ...,   1,   1,   1]], device='cuda:3'), 'task': 'st'}, 'transcript': {'tokens': tensor([[  17,   11,    6,  ...,    1,    1,    1],
        [  19,  169, 2736,  ...,    6,    5,    2],
        [  17,   11,    6,  ...,    1,    1,    1],
        ...,
        [  19,  474,    4,  ...,    1,    1,    1],
        [   8,   17,   73,  ...,    1,    1,    1],
        [ 168,   63,    7,  ...,    1,    1,    1]], device='cuda:3'), 'cluster_tokens': tensor([[37, 85, 37,  ..., 37, 37, 37],
        [38, 85, 29,  ..., 37, 11, 83],
        [37, 85, 37,  ..., 37, 37, 37],
        ...,
        [38, 31, 11,  ..., 37, 37, 37],
        [37, 37,  6,  ..., 37, 37, 37],
        [37, 85, 37,  ..., 37, 37, 37]], device='cuda:3'), 'lengths': tensor([14, 21, 15, 11, 12, 12, 16, 12, 15, 14, 16, 18, 16, 21, 14, 12, 14, 16,
        13, 11,  8, 12, 15, 14,  8, 10, 14, 18, 15, 14, 16,  9, 17, 12, 16,  9,
        17,  8, 16, 15, 15, 13,  9, 12, 12, 16, 11, 14, 14, 14, 13, 10, 12, 14,
         9, 11], device='cuda:3'), 'ntokens': 755}, 'target': tensor([[ 92,  27,  30,  ...,   1,   1,   1],
        [ 72, 354, 770,  ...,   1,   1,   1],
        [ 92,  27, 621,  ...,   1,   1,   1],
        ...,
        [ 72, 915,   4,  ...,   1,   1,   1],
        [ 64,  30, 145,  ...,   1,   1,   1],
        [504,  76,  14,  ...,   1,   1,   1]], device='cuda:3'), 'target_lengths': tensor([12, 21, 14, 10, 11,  9, 17, 13, 15, 14, 13, 20, 15, 14, 17, 15, 18, 17,
        10, 12, 10, 17, 14, 14, 10, 17, 15, 11, 11, 16, 11, 11, 23,  7, 13, 15,
        16,  8, 14, 11, 15, 13,  9, 14,  9, 10, 11, 13, 53, 13, 11, 11,  9, 13,
         9, 10], device='cuda:3'), 'ntokens': 774, 'nsentences': 56}
Traceback (most recent call last):
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 6 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 505, in validate
    trainer.valid_step(sample)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 1127, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 687, in valid_step
    loss, sample_size, logging_output = self._per_task_pair_valid_loss(per_task, model, criterion, sample)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 567, in _per_task_pair_valid_loss
    loss, sample_size, logging_output = criterion(model, sample[per_task], per_task)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT.py", line 242, in forward
    st_src_tokens, st_src_lengths, st_prev_output_tokens = sample['st']["net_input"].values()
ValueError: too many values to unpack (expected 3)

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 74 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15957
2023-07-03 07:53:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 07:53:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 07:53:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 07:53:21 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 07:53:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15957', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 07:53:23 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:53:23 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:53:23 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 07:53:23 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 07:53:23 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:53:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 07:53:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 07:53:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 07:53:29 | INFO | root | load pretrained hubert
2023-07-03 07:53:33 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:53:34 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:53:37 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:53:37 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 07:53:37 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 07:53:37 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 07:53:37 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 07:53:37 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 07:53:37 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 07:53:37 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 07:53:37 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:53:37 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:53:37 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:53:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:53:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 07:53:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 07:53:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 07:53:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:53:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:53:44 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 07:53:44 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 07:53:44 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:53:44 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:53:44 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 07:53:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:53:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:53:44 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:53:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:53:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:53:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:54:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 07:54:53 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 07:54:53 | INFO | fairseq_cli.train | Start iterating over samples
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
2023-07-03 07:55:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
2023-07-03 07:55:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens'])
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens', 'task'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens', 'task'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens', 'task'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens', 'task'])
##################### dict_keys(['src_tokens', 'src_lengths', 'prev_output_tokens', 'task'])
Traceback (most recent call last):
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 7 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 505, in validate
    trainer.valid_step(sample)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 1127, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 687, in valid_step
    loss, sample_size, logging_output = self._per_task_pair_valid_loss(per_task, model, criterion, sample)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 567, in _per_task_pair_valid_loss
    loss, sample_size, logging_output = criterion(model, sample[per_task], per_task)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT.py", line 242, in forward
    st_src_tokens, st_src_lengths, st_prev_output_tokens = sample['st']["net_input"].values()
ValueError: too many values to unpack (expected 3)

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 74 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19408
2023-07-03 07:57:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 07:57:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 07:57:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 07:57:35 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 07:57:37 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19408', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 07:57:37 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:57:37 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 07:57:37 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 07:57:37 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 07:57:37 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:57:42 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 07:57:42 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 07:57:42 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 07:57:44 | INFO | root | load pretrained hubert
2023-07-03 07:57:47 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 07:57:48 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:57:51 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 07:57:51 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 07:57:51 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 07:57:51 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 07:57:51 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 07:57:51 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 07:57:51 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 07:57:51 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 07:57:51 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:57:51 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:57:51 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:57:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:57:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 07:57:59 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 07:57:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 07:58:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 07:58:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 07:58:00 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 07:58:00 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 07:58:00 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:58:00 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 07:58:00 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 07:58:00 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 07:58:00 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:58:00 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 07:58:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:58:03 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:58:05 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 07:59:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 07:59:10 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 07:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 07:59:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 07:59:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Traceback (most recent call last):
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 7 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/workspace/fairseq-0.12.3/fairseq_cli/train.py", line 505, in validate
    trainer.valid_step(sample)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 1127, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 687, in valid_step
    loss, sample_size, logging_output = self._per_task_pair_valid_loss(per_task, model, criterion, sample)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 569, in _per_task_pair_valid_loss
    bleu = self._inference_with_bleu(self.sequence_generator, sample[per_task], model)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 652, in _inference_with_bleu
    gen_out = self.inference_step(generator, [model], sample, prefix_tokens=None)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 722, in inference_step
    return generator.generate(
  File "/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/sequence_generator.py", line 204, in generate
    return self._generate(sample, **kwargs)
  File "/workspace/fairseq-AT/fairseq/sequence_generator.py", line 221, in _generate
    net_input = sample["net_input"]
KeyError: 'net_input'

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 46 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11799
2023-07-03 08:02:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 08:02:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 08:02:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 08:02:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 08:02:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11799', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_val_loss_test', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=2, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', save_interval=1, save_interval_updates=10, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_val_loss_test', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 08:02:30 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 08:02:30 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 08:02:30 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 08:02:30 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 08:02:30 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 08:02:35 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 08:02:35 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 08:02:35 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 08:02:36 | INFO | root | load pretrained hubert
2023-07-03 08:02:40 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 08:02:43 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 08:02:47 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 08:02:47 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 08:02:47 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 08:02:47 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 08:02:47 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 08:02:47 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 08:02:47 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 08:02:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 08:02:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 08:02:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 08:02:47 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 08:02:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 08:02:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 08:02:53 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 08:02:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 08:02:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 08:02:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 08:02:53 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 08:02:53 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 08:02:53 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 08:02:53 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_last.pt
2023-07-03 08:02:53 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 08:02:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 08:02:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 08:02:53 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 08:02:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 08:02:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 08:02:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 08:04:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 08:04:03 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 08:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 08:04:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 08:04:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-03 08:04:55 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.972 | trans_loss 11.902 | nll_loss 10.819 | w2v_ctc_loss 17.308 | task_loss 39.223 | contrastive_loss 4.862 | total 4003.4 | n_correct 206.2 | ppl 1806.56 | accuracy 5.151 | uer 294.123 | wer 162.999 | raw_wer 162.999 | bleu 0 | wps 1400.5 | wpb 4003.4 | bsz 141.8 | num_updates 10
2023-07-03 08:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 10 updates
2023-07-03 08:04:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_10.pt
2023-07-03 08:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_10.pt
2023-07-03 08:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_10.pt (epoch 1 @ 10 updates, score 0.0) (writing took 5.8073037951253355 seconds)
2023-07-03 08:05:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 08:05:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:05:44 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.966 | trans_loss 11.898 | nll_loss 10.814 | w2v_ctc_loss 17.295 | task_loss 39.245 | contrastive_loss 4.861 | total 4003.4 | n_correct 206.6 | ppl 1800.89 | accuracy 5.161 | uer 294.062 | wer 162.201 | raw_wer 162.201 | bleu 0 | wps 1369.9 | wpb 4003.4 | bsz 141.8 | num_updates 20 | best_bleu 0
2023-07-03 08:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 20 updates
2023-07-03 08:05:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_20.pt
2023-07-03 08:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_20.pt
2023-07-03 08:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_20.pt (epoch 1 @ 20 updates, score 0.0) (writing took 7.963534309063107 seconds)
2023-07-03 08:05:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:06:33 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.957 | trans_loss 11.885 | nll_loss 10.8 | w2v_ctc_loss 17.282 | task_loss 39.342 | contrastive_loss 4.857 | total 4003.4 | n_correct 207.9 | ppl 1782.65 | accuracy 5.193 | uer 293.921 | wer 160.9 | raw_wer 160.9 | bleu 0 | wps 1393.7 | wpb 4003.4 | bsz 141.8 | num_updates 30 | best_bleu 0
2023-07-03 08:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 30 updates
2023-07-03 08:06:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_30.pt
2023-07-03 08:06:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_30.pt
2023-07-03 08:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_30.pt (epoch 1 @ 30 updates, score 0.0) (writing took 8.380511686671525 seconds)
2023-07-03 08:06:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:07:24 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.942 | trans_loss 11.864 | nll_loss 10.775 | w2v_ctc_loss 17.26 | task_loss 39.613 | contrastive_loss 4.851 | total 4003.4 | n_correct 207.7 | ppl 1752.46 | accuracy 5.188 | uer 293.709 | wer 159.651 | raw_wer 159.651 | bleu 0 | wps 1404.4 | wpb 4003.4 | bsz 141.8 | num_updates 40 | best_bleu 0
2023-07-03 08:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 40 updates
2023-07-03 08:07:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_40.pt
2023-07-03 08:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_40.pt
2023-07-03 08:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_40.pt (epoch 1 @ 40 updates, score 0.0) (writing took 7.9789150529541075 seconds)
2023-07-03 08:07:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:08:14 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.922 | trans_loss 11.837 | nll_loss 10.744 | w2v_ctc_loss 17.23 | task_loss 39.904 | contrastive_loss 4.845 | total 4003.4 | n_correct 210.5 | ppl 1715.56 | accuracy 5.258 | uer 293.661 | wer 158.085 | raw_wer 158.085 | bleu 0 | wps 1412 | wpb 4003.4 | bsz 141.8 | num_updates 50 | best_bleu 0
2023-07-03 08:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 50 updates
2023-07-03 08:08:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_50.pt
2023-07-03 08:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_50.pt
2023-07-03 08:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_50.pt (epoch 1 @ 50 updates, score 0.0) (writing took 8.283108527306467 seconds)
2023-07-03 08:08:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:09:04 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.9 | trans_loss 11.81 | nll_loss 10.713 | w2v_ctc_loss 17.194 | task_loss 40.225 | contrastive_loss 4.838 | total 4003.4 | n_correct 213.2 | ppl 1678.99 | accuracy 5.325 | uer 293.279 | wer 155.36 | raw_wer 155.36 | bleu 0 | wps 1411.8 | wpb 4003.4 | bsz 141.8 | num_updates 60 | best_bleu 0
2023-07-03 08:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 60 updates
2023-07-03 08:09:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_60.pt
2023-07-03 08:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_60.pt
2023-07-03 08:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_60.pt (epoch 1 @ 60 updates, score 0.0) (writing took 8.1038184822537 seconds)
2023-07-03 08:09:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:09:54 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.874 | trans_loss 11.779 | nll_loss 10.679 | w2v_ctc_loss 17.146 | task_loss 40.644 | contrastive_loss 4.831 | total 4003.4 | n_correct 216.2 | ppl 1639.41 | accuracy 5.4 | uer 292.854 | wer 152.492 | raw_wer 152.492 | bleu 0 | wps 1402.4 | wpb 4003.4 | bsz 141.8 | num_updates 70 | best_bleu 0
2023-07-03 08:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 70 updates
2023-07-03 08:09:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_70.pt
2023-07-03 08:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_70.pt
2023-07-03 08:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_70.pt (epoch 1 @ 70 updates, score 0.0) (writing took 8.688758161850274 seconds)
2023-07-03 08:10:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:10:44 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.842 | trans_loss 11.746 | nll_loss 10.642 | w2v_ctc_loss 17.086 | task_loss 41.105 | contrastive_loss 4.823 | total 4003.4 | n_correct 218.4 | ppl 1597.93 | accuracy 5.455 | uer 291.304 | wer 148.652 | raw_wer 148.652 | bleu 0 | wps 1424.3 | wpb 4003.4 | bsz 141.8 | num_updates 80 | best_bleu 0
2023-07-03 08:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 80 updates
2023-07-03 08:10:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_80.pt
2023-07-03 08:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_80.pt
2023-07-03 08:10:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_80.pt (epoch 1 @ 80 updates, score 0.0) (writing took 8.431790973991156 seconds)
2023-07-03 08:11:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:11:35 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.808 | trans_loss 11.722 | nll_loss 10.617 | w2v_ctc_loss 17.003 | task_loss 41.508 | contrastive_loss 4.817 | total 4003.4 | n_correct 222 | ppl 1570.15 | accuracy 5.545 | uer 272.044 | wer 135.334 | raw_wer 135.334 | bleu 0 | wps 1386.2 | wpb 4003.4 | bsz 141.8 | num_updates 90 | best_bleu 0
2023-07-03 08:11:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 90 updates
2023-07-03 08:11:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_90.pt
2023-07-03 08:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_90.pt
2023-07-03 08:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_90.pt (epoch 1 @ 90 updates, score 0.0) (writing took 8.973541195970029 seconds)
2023-07-03 08:11:50 | INFO | train_inner | epoch 001:    102 / 1474 loss=12.747, trans_loss=5.643, nll_loss=4.219, w2v_ctc_loss=13.809, task_loss=18.858, contrastive_loss=3.303, total=4194.74, n_correct=213.27, ppl=18.62, accuracy=5.084, wps=2714.8, ups=0.22, wpb=12531.3, bsz=465.1, num_updates=100, lr=4.098e-06, gnorm=0.667, clip=0, loss_scale=32, train_wall=68, gb_free=19, wall=537
2023-07-03 08:11:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:12:25 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.763 | trans_loss 11.69 | nll_loss 10.582 | w2v_ctc_loss 16.893 | task_loss 42.076 | contrastive_loss 4.81 | total 4003.4 | n_correct 223.2 | ppl 1533.37 | accuracy 5.575 | uer 186.224 | wer 105.313 | raw_wer 105.313 | bleu 0 | wps 1420.3 | wpb 4003.4 | bsz 141.8 | num_updates 100 | best_bleu 0
2023-07-03 08:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 100 updates
2023-07-03 08:12:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_100.pt
2023-07-03 08:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_100.pt
2023-07-03 08:12:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_100.pt (epoch 1 @ 100 updates, score 0.0) (writing took 8.438832061830908 seconds)
2023-07-03 08:12:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:13:15 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.704 | trans_loss 11.655 | nll_loss 10.546 | w2v_ctc_loss 16.742 | task_loss 42.741 | contrastive_loss 4.804 | total 4003.4 | n_correct 227.6 | ppl 1494.97 | accuracy 5.685 | uer 101.115 | wer 100.108 | raw_wer 100.108 | bleu 0 | wps 1381.3 | wpb 4003.4 | bsz 141.8 | num_updates 110 | best_bleu 0
2023-07-03 08:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 110 updates
2023-07-03 08:13:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_110.pt
2023-07-03 08:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_110.pt
2023-07-03 08:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_110.pt (epoch 1 @ 110 updates, score 0.0) (writing took 8.618116890080273 seconds)
2023-07-03 08:13:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:14:05 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.629 | trans_loss 11.623 | nll_loss 10.513 | w2v_ctc_loss 16.533 | task_loss 43.361 | contrastive_loss 4.798 | total 4003.4 | n_correct 232.8 | ppl 1460.78 | accuracy 5.815 | uer 99.926 | wer 100.034 | raw_wer 100.034 | bleu 0 | wps 1431.8 | wpb 4003.4 | bsz 141.8 | num_updates 120 | best_bleu 0
2023-07-03 08:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 120 updates
2023-07-03 08:14:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_120.pt
2023-07-03 08:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_120.pt
2023-07-03 08:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_120.pt (epoch 1 @ 120 updates, score 0.0) (writing took 8.655935454182327 seconds)
2023-07-03 08:14:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:14:55 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.53 | trans_loss 11.591 | nll_loss 10.48 | w2v_ctc_loss 16.242 | task_loss 44.079 | contrastive_loss 4.792 | total 4003.4 | n_correct 234.6 | ppl 1427.86 | accuracy 5.86 | uer 100.003 | wer 100.011 | raw_wer 100.011 | bleu 0 | wps 1415.5 | wpb 4003.4 | bsz 141.8 | num_updates 130 | best_bleu 0
2023-07-03 08:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 130 updates
2023-07-03 08:14:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_130.pt
2023-07-03 08:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_130.pt
2023-07-03 08:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_130.pt (epoch 1 @ 130 updates, score 0.0) (writing took 8.78862256417051 seconds)
2023-07-03 08:15:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:15:45 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.388 | trans_loss 11.543 | nll_loss 10.425 | w2v_ctc_loss 15.83 | task_loss 44.82 | contrastive_loss 4.786 | total 4003.4 | n_correct 240.9 | ppl 1375.23 | accuracy 6.017 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 1435.4 | wpb 4003.4 | bsz 141.8 | num_updates 140 | best_bleu 0
2023-07-03 08:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 140 updates
2023-07-03 08:15:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_140.pt
2023-07-03 08:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_140.pt
2023-07-03 08:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_140.pt (epoch 1 @ 140 updates, score 0.0) (writing took 8.988065802957863 seconds)
2023-07-03 08:16:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:16:45 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.205 | trans_loss 11.514 | nll_loss 10.398 | w2v_ctc_loss 15.255 | task_loss 45.592 | contrastive_loss 4.781 | total 4003.4 | n_correct 246.9 | ppl 1349.18 | accuracy 6.167 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 1004.9 | wpb 4003.4 | bsz 141.8 | num_updates 150 | best_bleu 0
2023-07-03 08:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 150 updates
2023-07-03 08:16:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_150.pt
2023-07-03 08:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_150.pt
2023-07-03 08:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_150.pt (epoch 1 @ 150 updates, score 0.0) (writing took 9.889783855061978 seconds)
2023-07-03 08:17:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:17:37 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 8.96 | trans_loss 11.499 | nll_loss 10.386 | w2v_ctc_loss 14.458 | task_loss 46.402 | contrastive_loss 4.777 | total 4003.4 | n_correct 249.6 | ppl 1338.07 | accuracy 6.235 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 1396.8 | wpb 4003.4 | bsz 141.8 | num_updates 160 | best_bleu 0
2023-07-03 08:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 160 updates
2023-07-03 08:17:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_160.pt
2023-07-03 08:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_160.pt
2023-07-03 08:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_160.pt (epoch 1 @ 160 updates, score 0.0) (writing took 8.727074764668941 seconds)
2023-07-03 08:17:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:18:51 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 8.63 | trans_loss 11.502 | nll_loss 10.397 | w2v_ctc_loss 13.353 | task_loss 47.156 | contrastive_loss 4.774 | total 4003.4 | n_correct 254 | ppl 1348.59 | accuracy 6.345 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 697.6 | wpb 4003.4 | bsz 141.8 | num_updates 170 | best_bleu 0
2023-07-03 08:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 170 updates
2023-07-03 08:18:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_170.pt
2023-07-03 08:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_170.pt
2023-07-03 08:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_170.pt (epoch 1 @ 170 updates, score 0.0) (writing took 10.181984062772244 seconds)
2023-07-03 08:19:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:20:48 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 8.176 | trans_loss 11.491 | nll_loss 10.392 | w2v_ctc_loss 11.853 | task_loss 47.854 | contrastive_loss 4.772 | total 4003.4 | n_correct 252.4 | ppl 1343.8 | accuracy 6.305 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 461.7 | wpb 4003.4 | bsz 141.8 | num_updates 180 | best_bleu 0
2023-07-03 08:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 180 updates
2023-07-03 08:20:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_180.pt
2023-07-03 08:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_180.pt
2023-07-03 08:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_180.pt (epoch 1 @ 180 updates, score 0.0) (writing took 9.486009499058127 seconds)
2023-07-03 08:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:22:46 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 7.635 | trans_loss 11.523 | nll_loss 10.439 | w2v_ctc_loss 10.014 | task_loss 48.493 | contrastive_loss 4.77 | total 4003.4 | n_correct 257.4 | ppl 1388.64 | accuracy 6.43 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 466.4 | wpb 4003.4 | bsz 141.8 | num_updates 190 | best_bleu 0
2023-07-03 08:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 190 updates
2023-07-03 08:22:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_190.pt
2023-07-03 08:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_190.pt
2023-07-03 08:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_190.pt (epoch 1 @ 190 updates, score 0.0) (writing took 10.093957100063562 seconds)
2023-07-03 08:23:11 | INFO | train_inner | epoch 001:    202 / 1474 loss=11.387, trans_loss=5.44, nll_loss=4.024, w2v_ctc_loss=11.882, task_loss=20.334, contrastive_loss=3.293, total=4125.46, n_correct=256.62, ppl=16.27, accuracy=6.22, wps=1811, ups=0.15, wpb=12321.8, bsz=461.7, num_updates=200, lr=8.096e-06, gnorm=2.253, clip=0, loss_scale=32, train_wall=89, gb_free=19, wall=1218
2023-07-03 08:23:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:24:43 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 7.083 | trans_loss 11.574 | nll_loss 10.511 | w2v_ctc_loss 8.115 | task_loss 49.063 | contrastive_loss 4.769 | total 4003.4 | n_correct 261.7 | ppl 1459.48 | accuracy 6.537 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 466.7 | wpb 4003.4 | bsz 141.8 | num_updates 200 | best_bleu 0
2023-07-03 08:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 200 updates
2023-07-03 08:24:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_200.pt
2023-07-03 08:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_200.pt
2023-07-03 08:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 0.0) (writing took 10.091551519930363 seconds)
2023-07-03 08:25:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:26:39 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 6.732 | trans_loss 11.607 | nll_loss 10.562 | w2v_ctc_loss 6.904 | task_loss 49.62 | contrastive_loss 4.77 | total 4003.4 | n_correct 259 | ppl 1511.92 | accuracy 6.47 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 466.3 | wpb 4003.4 | bsz 141.8 | num_updates 210 | best_bleu 0
2023-07-03 08:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 210 updates
2023-07-03 08:26:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_210.pt
2023-07-03 08:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_210.pt
2023-07-03 08:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_210.pt (epoch 1 @ 210 updates, score 0.0) (writing took 9.409565445967019 seconds)
2023-07-03 08:27:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:28:34 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 6.693 | trans_loss 11.634 | nll_loss 10.602 | w2v_ctc_loss 6.744 | task_loss 50.124 | contrastive_loss 4.77 | total 4003.4 | n_correct 251 | ppl 1553.86 | accuracy 6.27 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 467.9 | wpb 4003.4 | bsz 141.8 | num_updates 220 | best_bleu 0
2023-07-03 08:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 220 updates
2023-07-03 08:28:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_220.pt
2023-07-03 08:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_220.pt
2023-07-03 08:28:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_220.pt (epoch 1 @ 220 updates, score 0.0) (writing took 10.79538051597774 seconds)
2023-07-03 08:28:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 08:29:57 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 6.772 | trans_loss 11.659 | nll_loss 10.641 | w2v_ctc_loss 6.979 | task_loss 50.594 | contrastive_loss 4.77 | total 4003.4 | n_correct 240.1 | ppl 1597.2 | accuracy 5.997 | uer 100 | wer 100 | raw_wer 100 | bleu 0 | wps 851.8 | wpb 4003.4 | bsz 141.8 | num_updates 230 | best_bleu 0
2023-07-03 08:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 230 updates
2023-07-03 08:29:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_230.pt
2023-07-03 08:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_230.pt
2023-07-03 08:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_val_loss_test/checkpoint_1_230.pt (epoch 1 @ 230 updates, score 0.0) (writing took 8.573804825078696 seconds)
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 512 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
