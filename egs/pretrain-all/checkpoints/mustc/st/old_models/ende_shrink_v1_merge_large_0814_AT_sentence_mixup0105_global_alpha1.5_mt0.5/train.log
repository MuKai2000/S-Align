2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-15 01:26:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11353', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-15 01:26:48 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-15 01:26:53 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-15 01:26:53 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-15 01:26:53 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-15 01:26:56 | INFO | root | load pretrained hubert
2023-08-15 01:26:58 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-15 01:26:58 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-15 01:27:01 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-15 01:27:02 | INFO | root | share the sematic adapter and textual encoder
2023-08-15 01:27:02 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-15 01:27:02 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-15 01:27:02 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-15 01:27:02 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-15 01:27:02 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-15 01:27:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-15 01:27:02 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-15 01:27:02 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:27:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-15 01:27:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-15 01:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-15 01:27:08 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-15 01:27:08 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-15 01:27:08 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 01:27:08 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 01:27:08 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-15 01:27:08 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-15 01:27:08 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:08 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:27:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:28:00 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-15 01:28:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 01:28:00 | INFO | fairseq.trainer | begin training epoch 1
2023-08-15 01:28:00 | INFO | fairseq_cli.train | Start iterating over samples
None None None
2023-08-15 01:28:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
None None None
2023-08-15 01:28:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
None None None
2023-08-15 01:28:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 01:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
None None None
None None None
None None None
2023-08-15 01:29:22 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.046, trans_loss=5.871, nll_loss=4.679, w2v_ctc_loss=22.329, task_loss=1.768, contrastive_loss=3.272, total=4215.43, n_correct=123.12, ppl=25.61, accuracy=2.921, wps=18495.5, ups=1.47, wpb=12576.1, bsz=475.2, num_updates=100, lr=4.098e-06, gnorm=2.858, clip=0, loss_scale=8, train_wall=74, gb_free=18.6, wall=134
2023-08-15 01:29:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-15 01:30:28 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.574, trans_loss=5.85, nll_loss=4.678, w2v_ctc_loss=17.067, task_loss=1.713, contrastive_loss=3.233, total=4109.72, n_correct=115.54, ppl=25.59, accuracy=2.811, wps=18473.1, ups=1.51, wpb=12272.1, bsz=456.9, num_updates=200, lr=8.096e-06, gnorm=7.252, clip=18, loss_scale=4, train_wall=66, gb_free=19.4, wall=200
2023-08-15 01:31:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-15 01:31:33 | INFO | train_inner | epoch 001:    306 / 1474 loss=9.91, trans_loss=5.828, nll_loss=4.689, w2v_ctc_loss=6.887, task_loss=1.66, contrastive_loss=3.18, total=4081.87, n_correct=110.77, ppl=25.79, accuracy=2.714, wps=18688.3, ups=1.53, wpb=12194.5, bsz=440.2, num_updates=300, lr=1.2094e-05, gnorm=2.295, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=265
2023-08-15 01:32:38 | INFO | train_inner | epoch 001:    406 / 1474 loss=9.414, trans_loss=5.8, nll_loss=4.688, w2v_ctc_loss=6.118, task_loss=1.415, contrastive_loss=3.205, total=4172.39, n_correct=98.29, ppl=25.78, accuracy=2.356, wps=19258, ups=1.55, wpb=12458.9, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.495, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=330
2023-08-15 01:33:44 | INFO | train_inner | epoch 001:    506 / 1474 loss=9.259, trans_loss=5.797, nll_loss=4.707, w2v_ctc_loss=5.828, task_loss=1.27, contrastive_loss=3.302, total=4181.66, n_correct=93, ppl=26.11, accuracy=2.224, wps=19018.1, ups=1.52, wpb=12495.1, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.47, clip=0, loss_scale=2, train_wall=65, gb_free=19.2, wall=396
2023-08-15 01:34:50 | INFO | train_inner | epoch 001:    606 / 1474 loss=9.124, trans_loss=5.789, nll_loss=4.692, w2v_ctc_loss=5.677, task_loss=1.242, contrastive_loss=3.255, total=4137.35, n_correct=98.09, ppl=25.85, accuracy=2.371, wps=18629.3, ups=1.51, wpb=12337.2, bsz=474.5, num_updates=600, lr=2.4088e-05, gnorm=1.823, clip=3, loss_scale=2, train_wall=66, gb_free=18.7, wall=462
2023-08-15 01:35:54 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.045, trans_loss=5.772, nll_loss=4.674, w2v_ctc_loss=5.634, task_loss=1.312, contrastive_loss=3.139, total=4145.85, n_correct=94.41, ppl=25.52, accuracy=2.277, wps=19215.2, ups=1.55, wpb=12381.9, bsz=454.4, num_updates=700, lr=2.8086e-05, gnorm=1.145, clip=0, loss_scale=2, train_wall=64, gb_free=19.5, wall=526
2023-08-15 01:36:59 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.947, trans_loss=5.839, nll_loss=4.75, w2v_ctc_loss=5.466, task_loss=1.271, contrastive_loss=3.154, total=4129.2, n_correct=76.96, ppl=26.91, accuracy=1.864, wps=19054.1, ups=1.55, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.155, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=591
2023-08-15 01:38:03 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.836, trans_loss=5.936, nll_loss=4.871, w2v_ctc_loss=5.273, task_loss=1.291, contrastive_loss=3.057, total=4167.97, n_correct=68.7, ppl=29.26, accuracy=1.648, wps=19455.1, ups=1.56, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.492, clip=0, loss_scale=2, train_wall=63, gb_free=18.6, wall=655
2023-08-15 01:39:09 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.699, trans_loss=6.021, nll_loss=4.975, w2v_ctc_loss=5.007, task_loss=1.292, contrastive_loss=3.054, total=4137.5, n_correct=64.05, ppl=31.45, accuracy=1.548, wps=18717.7, ups=1.51, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.703, clip=0, loss_scale=2, train_wall=66, gb_free=19.3, wall=721
2023-08-15 01:40:14 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.501, trans_loss=6.094, nll_loss=5.06, w2v_ctc_loss=4.756, task_loss=1.327, contrastive_loss=2.956, total=4151.84, n_correct=55.05, ppl=33.36, accuracy=1.326, wps=19099.4, ups=1.54, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=1.729, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=786
2023-08-15 01:41:19 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.296, trans_loss=6.082, nll_loss=5.042, w2v_ctc_loss=4.565, task_loss=1.383, contrastive_loss=2.847, total=4123.25, n_correct=66.02, ppl=32.96, accuracy=1.601, wps=19037.7, ups=1.55, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.276, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=851
2023-08-15 01:42:23 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.149, trans_loss=6.084, nll_loss=5.045, w2v_ctc_loss=4.383, task_loss=1.302, contrastive_loss=2.803, total=4066.16, n_correct=64.56, ppl=33.01, accuracy=1.588, wps=18878.5, ups=1.56, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.542, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=915
2023-08-15 01:43:28 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8.037, trans_loss=6.133, nll_loss=5.114, w2v_ctc_loss=4.223, task_loss=1.324, contrastive_loss=2.869, total=4119.98, n_correct=57.3, ppl=34.62, accuracy=1.391, wps=18872.1, ups=1.53, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.409, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=980
2023-08-15 01:44:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
2023-08-15 01:44:53 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.395 | trans_loss 13.751 | nll_loss 13.558 | w2v_ctc_loss 5.482 | task_loss 7.545 | contrastive_loss 4.078 | total 4003.4 | n_correct 48.5 | ppl 12056.7 | accuracy 1.211 | uer 69.96 | wer 68.025 | raw_wer 68.025 | bleu 0 | wps 1149.1 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-15 01:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-15 01:44:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 01:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 01:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.962518582120538 seconds)
2023-08-15 01:45:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-15 01:45:00 | INFO | train | epoch 001 | loss 10.108 | trans_loss 5.929 | nll_loss 4.844 | w2v_ctc_loss 7.238 | task_loss 1.391 | contrastive_loss 3.085 | total 4138.38 | n_correct 83.6948 | ppl 28.72 | accuracy 2.022 | wps 18013.2 | ups 1.46 | wpb 12355.2 | bsz 458.6 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.27 | clip 1.4 | loss_scale 2 | train_wall 959 | gb_free 18.9 | wall 1072
2023-08-15 01:45:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 01:45:01 | INFO | fairseq.trainer | begin training epoch 2
2023-08-15 01:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 01:45:30 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.895, trans_loss=6.103, nll_loss=5.072, w2v_ctc_loss=4.067, task_loss=1.253, contrastive_loss=2.835, total=4165.61, n_correct=63.39, ppl=33.65, accuracy=1.522, wps=10203.8, ups=0.82, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.585, clip=0, loss_scale=2, train_wall=66, gb_free=18.7, wall=1102
2023-08-15 01:46:35 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.775, trans_loss=6.121, nll_loss=5.099, w2v_ctc_loss=3.976, task_loss=1.31, contrastive_loss=2.687, total=4153.7, n_correct=58.79, ppl=34.28, accuracy=1.415, wps=19125.8, ups=1.54, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.417, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1167
2023-08-15 01:47:39 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.675, trans_loss=6.103, nll_loss=5.08, w2v_ctc_loss=3.821, task_loss=1.144, contrastive_loss=2.75, total=4201.44, n_correct=64.75, ppl=33.83, accuracy=1.541, wps=19413, ups=1.55, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.449, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1231
2023-08-15 01:48:44 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.492, trans_loss=6.095, nll_loss=5.071, w2v_ctc_loss=3.765, task_loss=1.337, contrastive_loss=2.515, total=4130.13, n_correct=65.52, ppl=33.61, accuracy=1.586, wps=19194.3, ups=1.56, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.6, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1295
2023-08-15 01:49:49 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.351, trans_loss=6.089, nll_loss=5.067, w2v_ctc_loss=3.703, task_loss=1.468, contrastive_loss=2.334, total=4035.12, n_correct=62.66, ppl=33.52, accuracy=1.553, wps=18402.6, ups=1.53, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.637, clip=0, loss_scale=2, train_wall=65, gb_free=19, wall=1361
2023-08-15 01:50:53 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.268, trans_loss=6.052, nll_loss=5.016, w2v_ctc_loss=3.567, task_loss=1.268, contrastive_loss=2.476, total=4183.09, n_correct=77.21, ppl=32.37, accuracy=1.846, wps=19413.5, ups=1.56, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.554, clip=0, loss_scale=2, train_wall=64, gb_free=18.5, wall=1425
2023-08-15 01:50:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 01:51:35 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.696 | trans_loss 13.399 | nll_loss 13.12 | w2v_ctc_loss 4.631 | task_loss 7.545 | contrastive_loss 3.542 | total 4003.4 | n_correct 60.2 | ppl 8900.64 | accuracy 1.504 | uer 61.986 | wer 60.434 | raw_wer 60.434 | bleu 0 | wps 1134.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-15 01:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-15 01:51:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-15 01:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-15 01:52:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 58.091513980180025 seconds)
2023-08-15 01:53:37 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.129, trans_loss=6.055, nll_loss=5.018, w2v_ctc_loss=3.476, task_loss=1.301, contrastive_loss=2.29, total=4123.85, n_correct=69.79, ppl=32.41, accuracy=1.692, wps=7523.4, ups=0.61, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.498, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1589
2023-08-15 01:54:41 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.054, trans_loss=6.046, nll_loss=5.008, w2v_ctc_loss=3.412, task_loss=1.288, contrastive_loss=2.359, total=4148.13, n_correct=73.63, ppl=32.18, accuracy=1.775, wps=19327.2, ups=1.56, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.54, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1653
2023-08-15 01:55:46 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.957, trans_loss=6.024, nll_loss=4.982, w2v_ctc_loss=3.361, task_loss=1.301, contrastive_loss=2.311, total=4172.27, n_correct=75.88, ppl=31.61, accuracy=1.819, wps=19183.1, ups=1.54, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.408, clip=0, loss_scale=2, train_wall=65, gb_free=18.8, wall=1718
2023-08-15 01:56:51 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.819, trans_loss=6.025, nll_loss=4.981, w2v_ctc_loss=3.273, task_loss=1.362, contrastive_loss=2.225, total=4101.67, n_correct=70.05, ppl=31.59, accuracy=1.708, wps=18843.3, ups=1.54, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.301, clip=0, loss_scale=4, train_wall=65, gb_free=18.9, wall=1783
2023-08-15 01:57:55 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.724, trans_loss=6.011, nll_loss=4.963, w2v_ctc_loss=3.212, task_loss=1.324, contrastive_loss=2.114, total=4091.09, n_correct=71.7, ppl=31.19, accuracy=1.753, wps=18966.6, ups=1.55, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.163, clip=0, loss_scale=4, train_wall=64, gb_free=19.2, wall=1847
2023-08-15 01:59:01 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.7, trans_loss=6.01, nll_loss=4.962, w2v_ctc_loss=3.113, task_loss=1.149, contrastive_loss=2.336, total=4219.19, n_correct=74.89, ppl=31.17, accuracy=1.775, wps=19276.2, ups=1.53, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.142, clip=0, loss_scale=4, train_wall=65, gb_free=19, wall=1913
2023-08-15 02:00:05 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.592, trans_loss=5.994, nll_loss=4.94, w2v_ctc_loss=3.081, task_loss=1.21, contrastive_loss=2.146, total=4212.91, n_correct=75.64, ppl=30.7, accuracy=1.795, wps=19419.4, ups=1.54, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.094, clip=0, loss_scale=4, train_wall=64, gb_free=19.1, wall=1977
2023-08-15 02:01:11 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.486, trans_loss=5.988, nll_loss=4.938, w2v_ctc_loss=3.045, task_loss=1.271, contrastive_loss=1.928, total=4142.48, n_correct=77.37, ppl=30.64, accuracy=1.868, wps=18867.9, ups=1.52, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.116, clip=0, loss_scale=4, train_wall=65, gb_free=18.9, wall=2043
2023-08-15 02:02:16 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.394, trans_loss=5.981, nll_loss=4.927, w2v_ctc_loss=2.998, task_loss=1.386, contrastive_loss=1.988, total=4063.28, n_correct=73.8, ppl=30.41, accuracy=1.816, wps=18676.1, ups=1.54, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=2.063, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2108
2023-08-15 02:02:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:03:23 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.884 | trans_loss 13.06 | nll_loss 12.661 | w2v_ctc_loss 3.805 | task_loss 7.545 | contrastive_loss 2.693 | total 4003.4 | n_correct 84.5 | ppl 6474.55 | accuracy 2.111 | uer 53.449 | wer 52.541 | raw_wer 52.541 | bleu 0 | wps 1161.5 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-15 02:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-15 02:03:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:03:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 31.05997110903263 seconds)
2023-08-15 02:03:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-15 02:03:54 | INFO | train | epoch 002 | loss 7.029 | trans_loss 6.042 | nll_loss 5.003 | w2v_ctc_loss 3.416 | task_loss 1.292 | contrastive_loss 2.319 | total 4138.65 | n_correct 70.8351 | ppl 32.07 | accuracy 1.712 | wps 16069.6 | ups 1.3 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.353 | clip 0 | loss_scale 4 | train_wall 948 | gb_free 19 | wall 2206
2023-08-15 02:03:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:03:54 | INFO | fairseq.trainer | begin training epoch 3
2023-08-15 02:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:04:40 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.298, trans_loss=5.968, nll_loss=4.91, w2v_ctc_loss=2.947, task_loss=1.362, contrastive_loss=1.843, total=4048.67, n_correct=77.87, ppl=30.06, accuracy=1.923, wps=8401.7, ups=0.7, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.902, clip=0, loss_scale=4, train_wall=64, gb_free=18.8, wall=2252
2023-08-15 02:04:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-15 02:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-15 02:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-08-15 02:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-08-15 02:06:15 | INFO | train_inner | epoch 003:    162 / 1474 loss=5.708, trans_loss=5.054, nll_loss=3.729, w2v_ctc_loss=2.849, task_loss=0.896, contrastive_loss=1.936, total=4165.74, n_correct=479.89, ppl=13.26, accuracy=11.52, wps=13079.5, ups=1.05, wpb=12437.4, bsz=466, num_updates=3100, lr=0.000124038, gnorm=7.734, clip=22, loss_scale=0.25, train_wall=95, gb_free=16.7, wall=2347
2023-08-15 02:07:50 | INFO | train_inner | epoch 003:    262 / 1474 loss=4.941, trans_loss=4.352, nll_loss=2.807, w2v_ctc_loss=2.674, task_loss=0.93, contrastive_loss=1.77, total=4149.55, n_correct=1099.64, ppl=7, accuracy=26.5, wps=13095.9, ups=1.06, wpb=12397.1, bsz=463.2, num_updates=3200, lr=0.000128036, gnorm=8.109, clip=17, loss_scale=0.25, train_wall=94, gb_free=16.3, wall=2442
2023-08-15 02:09:23 | INFO | train_inner | epoch 003:    362 / 1474 loss=4.644, trans_loss=4.247, nll_loss=2.672, w2v_ctc_loss=2.552, task_loss=0.905, contrastive_loss=1.699, total=4175.96, n_correct=1253.99, ppl=6.37, accuracy=30.029, wps=13386.8, ups=1.07, wpb=12461.5, bsz=474.2, num_updates=3300, lr=0.000132034, gnorm=4.088, clip=6, loss_scale=0.25, train_wall=93, gb_free=16.3, wall=2535
2023-08-15 02:10:55 | INFO | train_inner | epoch 003:    462 / 1474 loss=4.336, trans_loss=4.176, nll_loss=2.581, w2v_ctc_loss=2.398, task_loss=0.923, contrastive_loss=1.386, total=4187.52, n_correct=1345.84, ppl=5.98, accuracy=32.139, wps=13484.2, ups=1.08, wpb=12498.8, bsz=463.6, num_updates=3400, lr=0.000136032, gnorm=2.803, clip=2, loss_scale=0.25, train_wall=92, gb_free=14, wall=2627
2023-08-15 02:12:28 | INFO | train_inner | epoch 003:    562 / 1474 loss=4.151, trans_loss=4.155, nll_loss=2.557, w2v_ctc_loss=2.282, task_loss=0.998, contrastive_loss=1.302, total=4083.21, n_correct=1342.2, ppl=5.89, accuracy=32.871, wps=13169.7, ups=1.08, wpb=12199, bsz=437.9, num_updates=3500, lr=0.00014003, gnorm=2.95, clip=1, loss_scale=0.25, train_wall=92, gb_free=15.6, wall=2720
2023-08-15 02:14:03 | INFO | train_inner | epoch 003:    662 / 1474 loss=4.06, trans_loss=4.137, nll_loss=2.529, w2v_ctc_loss=2.18, task_loss=0.866, contrastive_loss=1.365, total=4232.39, n_correct=1440.22, ppl=5.77, accuracy=34.029, wps=13319.2, ups=1.06, wpb=12618.9, bsz=487.6, num_updates=3600, lr=0.000144028, gnorm=2.388, clip=1, loss_scale=0.25, train_wall=94, gb_free=16.1, wall=2815
2023-08-15 02:15:35 | INFO | train_inner | epoch 003:    762 / 1474 loss=3.915, trans_loss=4.101, nll_loss=2.489, w2v_ctc_loss=2.133, task_loss=0.898, contrastive_loss=1.096, total=4155.31, n_correct=1450.07, ppl=5.61, accuracy=34.897, wps=13442, ups=1.08, wpb=12412.9, bsz=465.8, num_updates=3700, lr=0.000148026, gnorm=2.284, clip=0, loss_scale=0.25, train_wall=92, gb_free=16.1, wall=2907
2023-08-15 02:17:08 | INFO | train_inner | epoch 003:    862 / 1474 loss=3.821, trans_loss=4.095, nll_loss=2.479, w2v_ctc_loss=2.085, task_loss=0.93, contrastive_loss=1.026, total=4170.95, n_correct=1471.56, ppl=5.57, accuracy=35.281, wps=13395.5, ups=1.08, wpb=12453.7, bsz=458.1, num_updates=3800, lr=0.000152024, gnorm=2.448, clip=2, loss_scale=0.25, train_wall=92, gb_free=17.1, wall=3000
2023-08-15 02:18:41 | INFO | train_inner | epoch 003:    962 / 1474 loss=3.765, trans_loss=4.075, nll_loss=2.451, w2v_ctc_loss=2.052, task_loss=0.884, contrastive_loss=1.039, total=4174.19, n_correct=1518.81, ppl=5.47, accuracy=36.386, wps=13408, ups=1.08, wpb=12449.2, bsz=475.7, num_updates=3900, lr=0.000156022, gnorm=2.387, clip=1, loss_scale=0.25, train_wall=92, gb_free=13.4, wall=3093
2023-08-15 02:20:14 | INFO | train_inner | epoch 003:   1062 / 1474 loss=3.673, trans_loss=4.059, nll_loss=2.433, w2v_ctc_loss=2.04, task_loss=1.003, contrastive_loss=0.907, total=4049.41, n_correct=1484.14, ppl=5.4, accuracy=36.651, wps=12992.1, ups=1.07, wpb=12096, bsz=436.3, num_updates=4000, lr=0.00016002, gnorm=2.005, clip=1, loss_scale=0.25, train_wall=93, gb_free=16.1, wall=3186
2023-08-15 02:20:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:20:46 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.959 | trans_loss 7.093 | nll_loss 4.92 | w2v_ctc_loss 2.553 | task_loss 4.155 | contrastive_loss 1.245 | total 4003.4 | n_correct 1559.3 | ppl 30.28 | accuracy 38.949 | uer 35.45 | wer 35.051 | raw_wer 35.051 | bleu 1.9 | wps 1504.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 1.9
2023-08-15 02:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-15 02:20:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-15 02:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-15 02:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 1.9) (writing took 42.583586329594254 seconds)
2023-08-15 02:23:00 | INFO | train_inner | epoch 003:   1162 / 1474 loss=3.565, trans_loss=4.048, nll_loss=2.417, w2v_ctc_loss=1.964, task_loss=0.989, contrastive_loss=0.844, total=4044.1, n_correct=1509.82, ppl=5.34, accuracy=37.334, wps=7260.5, ups=0.6, wpb=12070.2, bsz=433.6, num_updates=4100, lr=0.000164018, gnorm=1.859, clip=0, loss_scale=0.25, train_wall=91, gb_free=15.4, wall=3352
2023-08-15 02:24:32 | INFO | train_inner | epoch 003:   1262 / 1474 loss=3.489, trans_loss=4.02, nll_loss=2.382, w2v_ctc_loss=1.918, task_loss=0.985, contrastive_loss=0.794, total=4065.1, n_correct=1550.21, ppl=5.21, accuracy=38.135, wps=13213.2, ups=1.09, wpb=12140.5, bsz=432.3, num_updates=4200, lr=0.000168016, gnorm=1.825, clip=0, loss_scale=0.25, train_wall=91, gb_free=16.9, wall=3444
2023-08-15 02:26:05 | INFO | train_inner | epoch 003:   1362 / 1474 loss=3.461, trans_loss=4.002, nll_loss=2.358, w2v_ctc_loss=1.882, task_loss=0.93, contrastive_loss=0.884, total=4132.35, n_correct=1615.33, ppl=5.13, accuracy=39.09, wps=13245.9, ups=1.07, wpb=12335.6, bsz=462.1, num_updates=4300, lr=0.000172014, gnorm=1.797, clip=0, loss_scale=0.25, train_wall=93, gb_free=17.4, wall=3537
2023-08-15 02:27:39 | INFO | train_inner | epoch 003:   1462 / 1474 loss=3.401, trans_loss=3.979, nll_loss=2.329, w2v_ctc_loss=1.854, task_loss=0.887, contrastive_loss=0.835, total=4206.88, n_correct=1685.65, ppl=5.02, accuracy=40.069, wps=13458.1, ups=1.07, wpb=12566, bsz=476, num_updates=4400, lr=0.000176012, gnorm=1.732, clip=0, loss_scale=0.25, train_wall=93, gb_free=14.7, wall=3631
2023-08-15 02:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:28:18 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.557 | trans_loss 6.728 | nll_loss 4.439 | w2v_ctc_loss 2.275 | task_loss 4.122 | contrastive_loss 1.026 | total 4003.4 | n_correct 1760 | ppl 21.69 | accuracy 43.963 | uer 32.931 | wer 32.579 | raw_wer 32.579 | bleu 5.04 | wps 1632.7 | wpb 4003.4 | bsz 141.8 | num_updates 4412 | best_bleu 5.04
2023-08-15 02:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4412 updates
2023-08-15 02:28:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4412 updates, score 5.04) (writing took 30.616793431341648 seconds)
2023-08-15 02:28:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-15 02:28:49 | INFO | train | epoch 003 | loss 4.15 | trans_loss 4.247 | nll_loss 2.676 | w2v_ctc_loss 2.231 | task_loss 0.945 | contrastive_loss 1.234 | total 4138.85 | n_correct 1325.37 | ppl 6.39 | accuracy 32.023 | wps 12150.7 | ups 0.98 | wpb 12356.3 | bsz 458.6 | num_updates 4412 | lr 0.000176492 | gnorm 3.109 | clip 3.6 | loss_scale 0.25 | train_wall 1345 | gb_free 16.2 | wall 3701
2023-08-15 02:28:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:28:49 | INFO | fairseq.trainer | begin training epoch 4
2023-08-15 02:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:30:18 | INFO | train_inner | epoch 004:     88 / 1474 loss=3.281, trans_loss=3.954, nll_loss=2.293, w2v_ctc_loss=1.823, task_loss=0.976, contrastive_loss=0.644, total=4082.27, n_correct=1674.94, ppl=4.9, accuracy=41.03, wps=7667.7, ups=0.63, wpb=12182.1, bsz=434.2, num_updates=4500, lr=0.00018001, gnorm=1.793, clip=2, loss_scale=0.25, train_wall=91, gb_free=17.6, wall=3790
2023-08-15 02:31:49 | INFO | train_inner | epoch 004:    188 / 1474 loss=3.215, trans_loss=3.917, nll_loss=2.247, w2v_ctc_loss=1.773, task_loss=0.882, contrastive_loss=0.653, total=4184.92, n_correct=1768.23, ppl=4.75, accuracy=42.252, wps=13604.6, ups=1.09, wpb=12496.9, bsz=470.3, num_updates=4600, lr=0.000184008, gnorm=1.396, clip=0, loss_scale=0.25, train_wall=91, gb_free=12.8, wall=3881
2023-08-15 02:33:22 | INFO | train_inner | epoch 004:    288 / 1474 loss=3.199, trans_loss=3.91, nll_loss=2.239, w2v_ctc_loss=1.761, task_loss=0.924, contrastive_loss=0.745, total=4150, n_correct=1771.38, ppl=4.72, accuracy=42.684, wps=13356.6, ups=1.08, wpb=12397.9, bsz=465.2, num_updates=4700, lr=0.000188006, gnorm=1.479, clip=0, loss_scale=0.25, train_wall=92, gb_free=16.6, wall=3974
2023-08-15 02:34:54 | INFO | train_inner | epoch 004:    388 / 1474 loss=3.137, trans_loss=3.896, nll_loss=2.218, w2v_ctc_loss=1.759, task_loss=0.973, contrastive_loss=0.57, total=4114.32, n_correct=1783.34, ppl=4.65, accuracy=43.345, wps=13321.5, ups=1.09, wpb=12277.1, bsz=440, num_updates=4800, lr=0.000192004, gnorm=2.176, clip=2, loss_scale=0.25, train_wall=92, gb_free=11.7, wall=4066
2023-08-15 02:36:28 | INFO | train_inner | epoch 004:    488 / 1474 loss=3.155, trans_loss=3.868, nll_loss=2.182, w2v_ctc_loss=1.693, task_loss=0.826, contrastive_loss=0.96, total=4239.74, n_correct=1883.99, ppl=4.54, accuracy=44.436, wps=13592.3, ups=1.07, wpb=12652.2, bsz=506.4, num_updates=4900, lr=0.000196002, gnorm=1.384, clip=0, loss_scale=0.25, train_wall=93, gb_free=16.7, wall=4160
2023-08-15 02:38:00 | INFO | train_inner | epoch 004:    588 / 1474 loss=3.065, trans_loss=3.846, nll_loss=2.154, w2v_ctc_loss=1.712, task_loss=0.876, contrastive_loss=0.601, total=4219.26, n_correct=1912.19, ppl=4.45, accuracy=45.321, wps=13643.4, ups=1.08, wpb=12596.5, bsz=483.8, num_updates=5000, lr=0.0002, gnorm=1.484, clip=0, loss_scale=0.25, train_wall=92, gb_free=15.9, wall=4252
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:0')
2023-08-15 02:39:34 | INFO | train_inner | epoch 004:    688 / 1474 loss=3.037, trans_loss=3.845, nll_loss=2.149, w2v_ctc_loss=1.7, task_loss=0.966, contrastive_loss=0.642, total=4171.93, n_correct=1907.01, ppl=4.44, accuracy=45.71, wps=13183.3, ups=1.06, wpb=12436.9, bsz=453.3, num_updates=5100, lr=0.00019803, gnorm=1.126, clip=1, loss_scale=0.25, train_wall=94, gb_free=15.3, wall=4346
2023-08-15 02:41:07 | INFO | train_inner | epoch 004:    788 / 1474 loss=2.989, trans_loss=3.822, nll_loss=2.123, w2v_ctc_loss=1.705, task_loss=1.012, contrastive_loss=0.501, total=4029.4, n_correct=1865.59, ppl=4.36, accuracy=46.299, wps=12989.8, ups=1.08, wpb=12032.2, bsz=423.7, num_updates=5200, lr=0.000196116, gnorm=1.037, clip=0, loss_scale=0.5, train_wall=92, gb_free=16, wall=4439
2023-08-15 02:42:39 | INFO | train_inner | epoch 004:    888 / 1474 loss=3.028, trans_loss=3.807, nll_loss=2.105, w2v_ctc_loss=1.704, task_loss=0.934, contrastive_loss=0.68, total=4175.28, n_correct=1950.66, ppl=4.3, accuracy=46.719, wps=13466.4, ups=1.08, wpb=12468.9, bsz=463.7, num_updates=5300, lr=0.000194257, gnorm=1.108, clip=1, loss_scale=0.5, train_wall=92, gb_free=15.3, wall=4531
2023-08-15 02:44:12 | INFO | train_inner | epoch 004:    988 / 1474 loss=2.945, trans_loss=3.787, nll_loss=2.079, w2v_ctc_loss=1.668, task_loss=0.949, contrastive_loss=0.538, total=4132.46, n_correct=1970.66, ppl=4.22, accuracy=47.687, wps=13280, ups=1.08, wpb=12343.2, bsz=455.3, num_updates=5400, lr=0.00019245, gnorm=0.965, clip=1, loss_scale=0.5, train_wall=92, gb_free=10.3, wall=4624
2023-08-15 02:45:45 | INFO | train_inner | epoch 004:   1088 / 1474 loss=2.905, trans_loss=3.781, nll_loss=2.07, w2v_ctc_loss=1.65, task_loss=0.996, contrastive_loss=0.498, total=4073.98, n_correct=1958.38, ppl=4.2, accuracy=48.07, wps=13090.1, ups=1.08, wpb=12161.7, bsz=437.9, num_updates=5500, lr=0.000190693, gnorm=0.866, clip=0, loss_scale=0.5, train_wall=92, gb_free=15.6, wall=4717
2023-08-15 02:47:18 | INFO | train_inner | epoch 004:   1188 / 1474 loss=2.905, trans_loss=3.763, nll_loss=2.049, w2v_ctc_loss=1.632, task_loss=0.862, contrastive_loss=0.597, total=4172.46, n_correct=2036.08, ppl=4.14, accuracy=48.798, wps=13439.7, ups=1.08, wpb=12459.8, bsz=487.1, num_updates=5600, lr=0.000188982, gnorm=0.863, clip=0, loss_scale=0.5, train_wall=92, gb_free=10.9, wall=4810
2023-08-15 02:48:50 | INFO | train_inner | epoch 004:   1288 / 1474 loss=2.866, trans_loss=3.745, nll_loss=2.026, w2v_ctc_loss=1.62, task_loss=0.899, contrastive_loss=0.55, total=4140.32, n_correct=2045.82, ppl=4.07, accuracy=49.412, wps=13420.1, ups=1.09, wpb=12365.2, bsz=467.7, num_updates=5700, lr=0.000187317, gnorm=0.823, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=4902
2023-08-15 02:50:22 | INFO | train_inner | epoch 004:   1388 / 1474 loss=2.808, trans_loss=3.732, nll_loss=2.008, w2v_ctc_loss=1.609, task_loss=0.963, contrastive_loss=0.416, total=4092.66, n_correct=2038.81, ppl=4.02, accuracy=49.816, wps=13377.3, ups=1.09, wpb=12224.9, bsz=436.3, num_updates=5800, lr=0.000185695, gnorm=0.832, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.2, wall=4994
2023-08-15 02:51:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:3')
2023-08-15 02:52:06 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.7 | trans_loss 5.865 | nll_loss 3.318 | w2v_ctc_loss 1.842 | task_loss 4.336 | contrastive_loss 0.615 | total 4003.4 | n_correct 2230.9 | ppl 9.97 | accuracy 55.725 | uer 27.444 | wer 28.47 | raw_wer 28.47 | bleu 13.7 | wps 1928.9 | wpb 4003.4 | bsz 141.8 | num_updates 5886 | best_bleu 13.7
2023-08-15 02:52:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5886 updates
2023-08-15 02:52:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5886 updates, score 13.7) (writing took 29.734384087845683 seconds)
2023-08-15 02:52:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-15 02:52:36 | INFO | train | epoch 004 | loss 3.021 | trans_loss 3.826 | nll_loss 2.129 | w2v_ctc_loss 1.692 | task_loss 0.93 | contrastive_loss 0.608 | total 4138.65 | n_correct 1908.78 | ppl 4.38 | accuracy 46.121 | wps 12758.9 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5886 | lr 0.000184334 | gnorm 1.207 | clip 0.5 | loss_scale 0.5 | train_wall 1356 | gb_free 14.5 | wall 5128
2023-08-15 02:52:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:52:36 | INFO | fairseq.trainer | begin training epoch 5
2023-08-15 02:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:52:57 | INFO | train_inner | epoch 005:     14 / 1474 loss=2.77, trans_loss=3.717, nll_loss=1.987, w2v_ctc_loss=1.556, task_loss=0.934, contrastive_loss=0.455, total=4073.09, n_correct=2058.18, ppl=3.96, accuracy=50.531, wps=7826.5, ups=0.64, wpb=12158.4, bsz=451.4, num_updates=5900, lr=0.000184115, gnorm=0.749, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.1, wall=5149
2023-08-15 02:54:30 | INFO | train_inner | epoch 005:    114 / 1474 loss=2.701, trans_loss=3.679, nll_loss=1.94, w2v_ctc_loss=1.5, task_loss=0.853, contrastive_loss=0.422, total=4233.69, n_correct=2197.94, ppl=3.84, accuracy=51.915, wps=13551.2, ups=1.07, wpb=12643.8, bsz=488.6, num_updates=6000, lr=0.000182574, gnorm=0.732, clip=0, loss_scale=0.5, train_wall=93, gb_free=15.5, wall=5242
2023-08-15 02:54:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:54:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.67 | trans_loss 5.85 | nll_loss 3.293 | w2v_ctc_loss 1.788 | task_loss 4.291 | contrastive_loss 0.6 | total 4003.4 | n_correct 2240.8 | ppl 9.8 | accuracy 55.972 | uer 27.325 | wer 28.28 | raw_wer 28.28 | bleu 13.76 | wps 2083 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 13.76
2023-08-15 02:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-15 02:54:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-15 02:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-15 02:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 13.76) (writing took 52.42412124015391 seconds)
2023-08-15 02:57:20 | INFO | train_inner | epoch 005:    214 / 1474 loss=2.731, trans_loss=3.681, nll_loss=1.94, w2v_ctc_loss=1.504, task_loss=0.868, contrastive_loss=0.627, total=4185.02, n_correct=2178.01, ppl=3.84, accuracy=52.043, wps=7364.3, ups=0.59, wpb=12486.5, bsz=485.7, num_updates=6100, lr=0.000181071, gnorm=0.704, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.4, wall=5412
2023-08-15 02:58:52 | INFO | train_inner | epoch 005:    314 / 1474 loss=2.698, trans_loss=3.664, nll_loss=1.924, w2v_ctc_loss=1.514, task_loss=0.948, contrastive_loss=0.482, total=4097.42, n_correct=2135.14, ppl=3.79, accuracy=52.109, wps=13331.5, ups=1.09, wpb=12251.6, bsz=448, num_updates=6200, lr=0.000179605, gnorm=0.742, clip=0, loss_scale=0.5, train_wall=91, gb_free=13.8, wall=5504
2023-08-15 03:00:25 | INFO | train_inner | epoch 005:    414 / 1474 loss=2.685, trans_loss=3.658, nll_loss=1.915, w2v_ctc_loss=1.479, task_loss=0.918, contrastive_loss=0.555, total=4135.49, n_correct=2171.18, ppl=3.77, accuracy=52.501, wps=13231, ups=1.07, wpb=12359.1, bsz=465.9, num_updates=6300, lr=0.000178174, gnorm=0.738, clip=0, loss_scale=0.5, train_wall=93, gb_free=17.2, wall=5597
2023-08-15 03:01:58 | INFO | train_inner | epoch 005:    514 / 1474 loss=2.646, trans_loss=3.657, nll_loss=1.911, w2v_ctc_loss=1.473, task_loss=1.01, contrastive_loss=0.485, total=4035.21, n_correct=2125.49, ppl=3.76, accuracy=52.674, wps=13037.8, ups=1.08, wpb=12051.5, bsz=427.7, num_updates=6400, lr=0.000176777, gnorm=0.7, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=5689
2023-08-15 03:03:30 | INFO | train_inner | epoch 005:    614 / 1474 loss=2.626, trans_loss=3.657, nll_loss=1.909, w2v_ctc_loss=1.472, task_loss=0.977, contrastive_loss=0.383, total=4117.64, n_correct=2180.22, ppl=3.76, accuracy=52.948, wps=13340.5, ups=1.09, wpb=12284.8, bsz=443.7, num_updates=6500, lr=0.000175412, gnorm=0.704, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=5782
2023-08-15 03:05:02 | INFO | train_inner | epoch 005:    714 / 1474 loss=2.64, trans_loss=3.648, nll_loss=1.899, w2v_ctc_loss=1.459, task_loss=0.896, contrastive_loss=0.492, total=4153.99, n_correct=2214.43, ppl=3.73, accuracy=53.309, wps=13408.2, ups=1.08, wpb=12400.6, bsz=476.1, num_updates=6600, lr=0.000174078, gnorm=0.681, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.4, wall=5874
2023-08-15 03:06:36 | INFO | train_inner | epoch 005:    814 / 1474 loss=2.6, trans_loss=3.634, nll_loss=1.88, w2v_ctc_loss=1.444, task_loss=0.939, contrastive_loss=0.416, total=4131.08, n_correct=2218.02, ppl=3.68, accuracy=53.691, wps=13195.6, ups=1.07, wpb=12332.3, bsz=455.1, num_updates=6700, lr=0.000172774, gnorm=0.664, clip=0, loss_scale=0.5, train_wall=93, gb_free=17.5, wall=5968
2023-08-15 03:08:08 | INFO | train_inner | epoch 005:    914 / 1474 loss=2.569, trans_loss=3.629, nll_loss=1.875, w2v_ctc_loss=1.436, task_loss=0.969, contrastive_loss=0.363, total=4109.29, n_correct=2217.13, ppl=3.67, accuracy=53.954, wps=13251.2, ups=1.08, wpb=12268.1, bsz=445.5, num_updates=6800, lr=0.000171499, gnorm=0.657, clip=0, loss_scale=0.5, train_wall=92, gb_free=11.6, wall=6060
2023-08-15 03:09:40 | INFO | train_inner | epoch 005:   1014 / 1474 loss=2.574, trans_loss=3.626, nll_loss=1.871, w2v_ctc_loss=1.43, task_loss=0.919, contrastive_loss=0.435, total=4163.73, n_correct=2255.75, ppl=3.66, accuracy=54.176, wps=13531.3, ups=1.09, wpb=12429.6, bsz=462.1, num_updates=6900, lr=0.000170251, gnorm=0.706, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.1, wall=6152
2023-08-15 03:11:14 | INFO | train_inner | epoch 005:   1114 / 1474 loss=2.592, trans_loss=3.622, nll_loss=1.864, w2v_ctc_loss=1.442, task_loss=0.932, contrastive_loss=0.449, total=4172.75, n_correct=2270.75, ppl=3.64, accuracy=54.419, wps=13201.3, ups=1.06, wpb=12448.4, bsz=464, num_updates=7000, lr=0.000169031, gnorm=0.686, clip=0, loss_scale=0.5, train_wall=94, gb_free=12.5, wall=6246
2023-08-15 03:12:48 | INFO | train_inner | epoch 005:   1214 / 1474 loss=2.528, trans_loss=3.613, nll_loss=1.852, w2v_ctc_loss=1.408, task_loss=0.941, contrastive_loss=0.339, total=4164.91, n_correct=2282.42, ppl=3.61, accuracy=54.801, wps=13281.4, ups=1.07, wpb=12422.5, bsz=455.7, num_updates=7100, lr=0.000167836, gnorm=0.66, clip=0, loss_scale=0.5, train_wall=93, gb_free=14.6, wall=6340
2023-08-15 03:14:21 | INFO | train_inner | epoch 005:   1314 / 1474 loss=2.507, trans_loss=3.608, nll_loss=1.848, w2v_ctc_loss=1.397, task_loss=0.951, contrastive_loss=0.31, total=4127.88, n_correct=2265.74, ppl=3.6, accuracy=54.889, wps=13248.7, ups=1.08, wpb=12320.7, bsz=445.3, num_updates=7200, lr=0.000166667, gnorm=0.642, clip=0, loss_scale=1, train_wall=93, gb_free=16, wall=6433
2023-08-15 03:15:53 | INFO | train_inner | epoch 005:   1414 / 1474 loss=2.508, trans_loss=3.604, nll_loss=1.844, w2v_ctc_loss=1.385, task_loss=0.941, contrastive_loss=0.359, total=4135.9, n_correct=2277.99, ppl=3.59, accuracy=55.078, wps=13392.7, ups=1.08, wpb=12351.8, bsz=456.9, num_updates=7300, lr=0.000165521, gnorm=0.631, clip=0, loss_scale=1, train_wall=92, gb_free=16.6, wall=6525
2023-08-15 03:16:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:17:15 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.441 | trans_loss 5.633 | nll_loss 3.024 | w2v_ctc_loss 1.594 | task_loss 4.429 | contrastive_loss 0.52 | total 4003.4 | n_correct 2373.1 | ppl 8.13 | accuracy 59.277 | uer 25.496 | wer 27.042 | raw_wer 27.042 | bleu 16.56 | wps 1831 | wpb 4003.4 | bsz 141.8 | num_updates 7360 | best_bleu 16.56
2023-08-15 03:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7360 updates
2023-08-15 03:17:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:17:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7360 updates, score 16.56) (writing took 32.769794806838036 seconds)
2023-08-15 03:17:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-15 03:17:48 | INFO | train | epoch 005 | loss 2.613 | trans_loss 3.64 | nll_loss 1.889 | w2v_ctc_loss 1.452 | task_loss 0.931 | contrastive_loss 0.438 | total 4138.65 | n_correct 2214.94 | ppl 3.7 | accuracy 53.518 | wps 12049.2 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 7360 | lr 0.000164845 | gnorm 0.688 | clip 0 | loss_scale 1 | train_wall 1359 | gb_free 16 | wall 6640
2023-08-15 03:17:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 03:17:48 | INFO | fairseq.trainer | begin training epoch 6
2023-08-15 03:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 03:18:34 | INFO | train_inner | epoch 006:     40 / 1474 loss=2.496, trans_loss=3.587, nll_loss=1.819, w2v_ctc_loss=1.385, task_loss=0.961, contrastive_loss=0.359, total=4114.92, n_correct=2285.83, ppl=3.53, accuracy=55.55, wps=7653.1, ups=0.62, wpb=12278.2, bsz=446.4, num_updates=7400, lr=0.000164399, gnorm=0.642, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=6685
2023-08-15 03:20:06 | INFO | train_inner | epoch 006:    140 / 1474 loss=2.45, trans_loss=3.561, nll_loss=1.789, w2v_ctc_loss=1.331, task_loss=0.929, contrastive_loss=0.397, total=4157.03, n_correct=2341.06, ppl=3.46, accuracy=56.316, wps=13362.6, ups=1.08, wpb=12418.5, bsz=455.9, num_updates=7500, lr=0.000163299, gnorm=0.611, clip=0, loss_scale=1, train_wall=92, gb_free=14.7, wall=6778
2023-08-15 03:21:40 | INFO | train_inner | epoch 006:    240 / 1474 loss=2.451, trans_loss=3.569, nll_loss=1.799, w2v_ctc_loss=1.358, task_loss=0.976, contrastive_loss=0.317, total=4121.73, n_correct=2310.22, ppl=3.48, accuracy=56.05, wps=13237.6, ups=1.08, wpb=12312.8, bsz=446.5, num_updates=7600, lr=0.000162221, gnorm=0.625, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=6871
2023-08-15 03:23:14 | INFO | train_inner | epoch 006:    340 / 1474 loss=2.476, trans_loss=3.559, nll_loss=1.786, w2v_ctc_loss=1.307, task_loss=0.879, contrastive_loss=0.59, total=4170.63, n_correct=2356.75, ppl=3.45, accuracy=56.508, wps=13197.8, ups=1.06, wpb=12451, bsz=486.5, num_updates=7700, lr=0.000161165, gnorm=0.64, clip=0, loss_scale=1, train_wall=94, gb_free=12.5, wall=6966
2023-08-15 03:24:46 | INFO | train_inner | epoch 006:    440 / 1474 loss=2.403, trans_loss=3.55, nll_loss=1.775, w2v_ctc_loss=1.314, task_loss=0.903, contrastive_loss=0.304, total=4147.89, n_correct=2359.66, ppl=3.42, accuracy=56.888, wps=13512.4, ups=1.09, wpb=12386.2, bsz=467, num_updates=7800, lr=0.000160128, gnorm=0.612, clip=0, loss_scale=1, train_wall=91, gb_free=16.8, wall=7057
2023-08-15 03:26:18 | INFO | train_inner | epoch 006:    540 / 1474 loss=2.409, trans_loss=3.555, nll_loss=1.78, w2v_ctc_loss=1.325, task_loss=0.936, contrastive_loss=0.297, total=4170.36, n_correct=2372.34, ppl=3.43, accuracy=56.886, wps=13406.1, ups=1.08, wpb=12447.9, bsz=455.9, num_updates=7900, lr=0.000159111, gnorm=0.602, clip=0, loss_scale=1, train_wall=92, gb_free=15.3, wall=7150
2023-08-15 03:27:50 | INFO | train_inner | epoch 006:    640 / 1474 loss=2.404, trans_loss=3.552, nll_loss=1.778, w2v_ctc_loss=1.303, task_loss=0.89, contrastive_loss=0.348, total=4144.5, n_correct=2361.91, ppl=3.43, accuracy=56.989, wps=13479.9, ups=1.09, wpb=12372.4, bsz=470, num_updates=8000, lr=0.000158114, gnorm=0.609, clip=0, loss_scale=1, train_wall=91, gb_free=17, wall=7242
2023-08-15 03:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:28:16 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.311 | trans_loss 5.503 | nll_loss 2.856 | w2v_ctc_loss 1.532 | task_loss 4.513 | contrastive_loss 0.468 | total 4003.4 | n_correct 2445.9 | ppl 7.24 | accuracy 61.096 | uer 23.42 | wer 24.995 | raw_wer 24.995 | bleu 17.99 | wps 2028.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.99
2023-08-15 03:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-15 03:28:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-15 03:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-15 03:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.99) (writing took 61.554183047264814 seconds)
2023-08-15 03:30:50 | INFO | train_inner | epoch 006:    740 / 1474 loss=2.397, trans_loss=3.551, nll_loss=1.776, w2v_ctc_loss=1.319, task_loss=0.948, contrastive_loss=0.3, total=4145.29, n_correct=2364.72, ppl=3.42, accuracy=57.046, wps=6883.6, ups=0.56, wpb=12375, bsz=454.7, num_updates=8100, lr=0.000157135, gnorm=0.598, clip=0, loss_scale=1, train_wall=92, gb_free=17.5, wall=7422
2023-08-15 03:32:23 | INFO | train_inner | epoch 006:    840 / 1474 loss=2.384, trans_loss=3.55, nll_loss=1.775, w2v_ctc_loss=1.311, task_loss=0.965, contrastive_loss=0.278, total=4131.83, n_correct=2358.74, ppl=3.42, accuracy=57.087, wps=13310.2, ups=1.08, wpb=12335.3, bsz=446.9, num_updates=8200, lr=0.000156174, gnorm=0.61, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=7515
2023-08-15 03:33:57 | INFO | train_inner | epoch 006:    940 / 1474 loss=2.415, trans_loss=3.556, nll_loss=1.782, w2v_ctc_loss=1.32, task_loss=1.003, contrastive_loss=0.377, total=4068.88, n_correct=2314.2, ppl=3.44, accuracy=56.876, wps=12916.1, ups=1.06, wpb=12145.6, bsz=436.9, num_updates=8300, lr=0.00015523, gnorm=0.606, clip=0, loss_scale=1, train_wall=94, gb_free=15.9, wall=7609
2023-08-15 03:35:28 | INFO | train_inner | epoch 006:   1040 / 1474 loss=2.408, trans_loss=3.541, nll_loss=1.763, w2v_ctc_loss=1.291, task_loss=0.875, contrastive_loss=0.452, total=4176.69, n_correct=2396.35, ppl=3.39, accuracy=57.374, wps=13585.2, ups=1.09, wpb=12465.8, bsz=480, num_updates=8400, lr=0.000154303, gnorm=0.652, clip=0, loss_scale=1, train_wall=91, gb_free=16.3, wall=7700
2023-08-15 03:37:00 | INFO | train_inner | epoch 006:   1140 / 1474 loss=2.375, trans_loss=3.538, nll_loss=1.76, w2v_ctc_loss=1.301, task_loss=1.013, contrastive_loss=0.303, total=4078.12, n_correct=2337.1, ppl=3.39, accuracy=57.308, wps=13232.2, ups=1.09, wpb=12175.4, bsz=435.5, num_updates=8500, lr=0.000153393, gnorm=0.596, clip=0, loss_scale=1, train_wall=91, gb_free=14.7, wall=7792
2023-08-15 03:38:33 | INFO | train_inner | epoch 006:   1240 / 1474 loss=2.409, trans_loss=3.53, nll_loss=1.752, w2v_ctc_loss=1.28, task_loss=0.931, contrastive_loss=0.567, total=4126.61, n_correct=2376.89, ppl=3.37, accuracy=57.599, wps=13299.5, ups=1.08, wpb=12325.4, bsz=463.4, num_updates=8600, lr=0.000152499, gnorm=0.6, clip=0, loss_scale=1, train_wall=92, gb_free=13.3, wall=7885
2023-08-15 03:40:05 | INFO | train_inner | epoch 006:   1340 / 1474 loss=2.336, trans_loss=3.529, nll_loss=1.747, w2v_ctc_loss=1.276, task_loss=0.921, contrastive_loss=0.256, total=4127.1, n_correct=2390.82, ppl=3.36, accuracy=57.93, wps=13441.4, ups=1.09, wpb=12313, bsz=454.8, num_updates=8700, lr=0.00015162, gnorm=0.595, clip=0, loss_scale=1, train_wall=91, gb_free=16.5, wall=7977
2023-08-15 03:41:37 | INFO | train_inner | epoch 006:   1440 / 1474 loss=2.337, trans_loss=3.522, nll_loss=1.74, w2v_ctc_loss=1.277, task_loss=0.925, contrastive_loss=0.262, total=4197.14, n_correct=2437.32, ppl=3.34, accuracy=58.071, wps=13539.9, ups=1.08, wpb=12529.7, bsz=463.5, num_updates=8800, lr=0.000150756, gnorm=0.58, clip=0, loss_scale=1, train_wall=92, gb_free=15.2, wall=8069
2023-08-15 03:42:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:42:33 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.242 | trans_loss 5.445 | nll_loss 2.788 | w2v_ctc_loss 1.461 | task_loss 4.496 | contrastive_loss 0.437 | total 4003.4 | n_correct 2474.8 | ppl 6.91 | accuracy 61.817 | uer 21.992 | wer 23.47 | raw_wer 23.47 | bleu 18.62 | wps 2006.2 | wpb 4003.4 | bsz 141.8 | num_updates 8834 | best_bleu 18.62
2023-08-15 03:42:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8834 updates
2023-08-15 03:42:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8834 updates, score 18.62) (writing took 34.4519123211503 seconds)
2023-08-15 03:43:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-15 03:43:08 | INFO | train | epoch 006 | loss 2.403 | trans_loss 3.547 | nll_loss 1.771 | w2v_ctc_loss 1.308 | task_loss 0.933 | contrastive_loss 0.359 | total 4138.65 | n_correct 2361.98 | ppl 3.41 | accuracy 57.071 | wps 11980.5 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 8834 | lr 0.000150465 | gnorm 0.609 | clip 0 | loss_scale 1 | train_wall 1357 | gb_free 14.8 | wall 8160
2023-08-15 03:43:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 03:43:08 | INFO | fairseq.trainer | begin training epoch 7
2023-08-15 03:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 03:44:17 | INFO | train_inner | epoch 007:     66 / 1474 loss=2.304, trans_loss=3.51, nll_loss=1.723, w2v_ctc_loss=1.246, task_loss=0.918, contrastive_loss=0.273, total=4099.48, n_correct=2399.59, ppl=3.3, accuracy=58.534, wps=7640.2, ups=0.62, wpb=12236.9, bsz=460.3, num_updates=8900, lr=0.000149906, gnorm=0.593, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=8229
2023-08-15 03:45:49 | INFO | train_inner | epoch 007:    166 / 1474 loss=2.307, trans_loss=3.503, nll_loss=1.714, w2v_ctc_loss=1.235, task_loss=0.942, contrastive_loss=0.343, total=4107.4, n_correct=2407.25, ppl=3.28, accuracy=58.608, wps=13431.9, ups=1.1, wpb=12263.9, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.595, clip=0, loss_scale=1, train_wall=91, gb_free=16.6, wall=8321
2023-08-15 03:47:21 | INFO | train_inner | epoch 007:    266 / 1474 loss=2.279, trans_loss=3.499, nll_loss=1.708, w2v_ctc_loss=1.23, task_loss=0.937, contrastive_loss=0.249, total=4137.13, n_correct=2434.34, ppl=3.27, accuracy=58.841, wps=13319.2, ups=1.08, wpb=12346.5, bsz=454.9, num_updates=9100, lr=0.00014825, gnorm=0.57, clip=0, loss_scale=1, train_wall=92, gb_free=16.2, wall=8413
2023-08-15 03:48:54 | INFO | train_inner | epoch 007:    366 / 1474 loss=2.328, trans_loss=3.5, nll_loss=1.71, w2v_ctc_loss=1.223, task_loss=0.9, contrastive_loss=0.507, total=4199.72, n_correct=2470.48, ppl=3.27, accuracy=58.825, wps=13492.4, ups=1.08, wpb=12534, bsz=480.8, num_updates=9200, lr=0.000147442, gnorm=0.57, clip=0, loss_scale=1, train_wall=92, gb_free=17.3, wall=8506
2023-08-15 03:50:26 | INFO | train_inner | epoch 007:    466 / 1474 loss=2.307, trans_loss=3.498, nll_loss=1.709, w2v_ctc_loss=1.219, task_loss=0.932, contrastive_loss=0.424, total=4149.08, n_correct=2439.73, ppl=3.27, accuracy=58.802, wps=13477.2, ups=1.09, wpb=12391, bsz=459, num_updates=9300, lr=0.000146647, gnorm=0.583, clip=0, loss_scale=2, train_wall=91, gb_free=16.8, wall=8598
2023-08-15 03:51:58 | INFO | train_inner | epoch 007:    566 / 1474 loss=2.267, trans_loss=3.495, nll_loss=1.703, w2v_ctc_loss=1.218, task_loss=0.917, contrastive_loss=0.253, total=4168.84, n_correct=2464.55, ppl=3.26, accuracy=59.118, wps=13514.8, ups=1.09, wpb=12436.4, bsz=460, num_updates=9400, lr=0.000145865, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=8690
2023-08-15 03:53:31 | INFO | train_inner | epoch 007:    666 / 1474 loss=2.257, trans_loss=3.489, nll_loss=1.696, w2v_ctc_loss=1.214, task_loss=0.923, contrastive_loss=0.239, total=4164.13, n_correct=2472.15, ppl=3.24, accuracy=59.368, wps=13348.3, ups=1.07, wpb=12427.2, bsz=458.5, num_updates=9500, lr=0.000145095, gnorm=0.573, clip=0, loss_scale=2, train_wall=93, gb_free=15.3, wall=8783
2023-08-15 03:55:04 | INFO | train_inner | epoch 007:    766 / 1474 loss=2.256, trans_loss=3.487, nll_loss=1.694, w2v_ctc_loss=1.215, task_loss=0.971, contrastive_loss=0.239, total=4126.5, n_correct=2441.72, ppl=3.24, accuracy=59.172, wps=13331.1, ups=1.08, wpb=12320.2, bsz=450.3, num_updates=9600, lr=0.000144338, gnorm=0.564, clip=0, loss_scale=2, train_wall=92, gb_free=15, wall=8876
2023-08-15 03:56:36 | INFO | train_inner | epoch 007:    866 / 1474 loss=2.251, trans_loss=3.492, nll_loss=1.7, w2v_ctc_loss=1.211, task_loss=0.958, contrastive_loss=0.244, total=4133.53, n_correct=2448.6, ppl=3.25, accuracy=59.238, wps=13328.1, ups=1.08, wpb=12333.5, bsz=453.5, num_updates=9700, lr=0.000143592, gnorm=0.567, clip=0, loss_scale=2, train_wall=92, gb_free=12.4, wall=8968
2023-08-15 03:58:09 | INFO | train_inner | epoch 007:    966 / 1474 loss=2.262, trans_loss=3.48, nll_loss=1.686, w2v_ctc_loss=1.197, task_loss=0.886, contrastive_loss=0.345, total=4144.45, n_correct=2469.54, ppl=3.22, accuracy=59.587, wps=13380, ups=1.08, wpb=12374.7, bsz=476.9, num_updates=9800, lr=0.000142857, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=15.8, wall=9061
2023-08-15 03:59:41 | INFO | train_inner | epoch 007:   1066 / 1474 loss=2.247, trans_loss=3.492, nll_loss=1.702, w2v_ctc_loss=1.215, task_loss=0.983, contrastive_loss=0.216, total=4100.65, n_correct=2431.08, ppl=3.25, accuracy=59.285, wps=13267.2, ups=1.08, wpb=12242.5, bsz=435.4, num_updates=9900, lr=0.000142134, gnorm=0.563, clip=0, loss_scale=2, train_wall=92, gb_free=15.5, wall=9153
2023-08-15 04:01:14 | INFO | train_inner | epoch 007:   1166 / 1474 loss=2.296, trans_loss=3.475, nll_loss=1.682, w2v_ctc_loss=1.199, task_loss=0.907, contrastive_loss=0.481, total=4138.96, n_correct=2469.95, ppl=3.21, accuracy=59.676, wps=13365.2, ups=1.08, wpb=12367.7, bsz=471.9, num_updates=10000, lr=0.000141421, gnorm=0.581, clip=0, loss_scale=2, train_wall=92, gb_free=16.4, wall=9246
2023-08-15 04:01:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:01:43 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.17 | trans_loss 5.374 | nll_loss 2.699 | w2v_ctc_loss 1.409 | task_loss 4.551 | contrastive_loss 0.418 | total 4003.4 | n_correct 2522.3 | ppl 6.49 | accuracy 63.004 | uer 21.315 | wer 23.049 | raw_wer 23.049 | bleu 19.24 | wps 1701.9 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.24
2023-08-15 04:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-15 04:01:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-15 04:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-15 04:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.24) (writing took 58.23552869819105 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 04:04:13 | INFO | train_inner | epoch 007:   1266 / 1474 loss=2.234, trans_loss=3.478, nll_loss=1.684, w2v_ctc_loss=1.196, task_loss=0.956, contrastive_loss=0.243, total=4120.42, n_correct=2455.52, ppl=3.21, accuracy=59.594, wps=6870.2, ups=0.56, wpb=12304.2, bsz=446.6, num_updates=10100, lr=0.00014072, gnorm=0.459, clip=0, loss_scale=2, train_wall=91, gb_free=15.2, wall=9425
2023-08-15 04:05:45 | INFO | train_inner | epoch 007:   1366 / 1474 loss=2.249, trans_loss=3.473, nll_loss=1.678, w2v_ctc_loss=1.203, task_loss=0.875, contrastive_loss=0.281, total=4186.45, n_correct=2505.4, ppl=3.2, accuracy=59.845, wps=13561.1, ups=1.08, wpb=12499.3, bsz=479.7, num_updates=10200, lr=0.000140028, gnorm=0.437, clip=0, loss_scale=2, train_wall=92, gb_free=11.7, wall=9517
2023-08-15 04:07:20 | INFO | train_inner | epoch 007:   1466 / 1474 loss=2.253, trans_loss=3.476, nll_loss=1.684, w2v_ctc_loss=1.197, task_loss=0.989, contrastive_loss=0.339, total=4117.01, n_correct=2457.17, ppl=3.21, accuracy=59.683, wps=13008.1, ups=1.06, wpb=12300.4, bsz=448.4, num_updates=10300, lr=0.000139347, gnorm=0.437, clip=0, loss_scale=2, train_wall=94, gb_free=15.8, wall=9611
2023-08-15 04:07:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
2023-08-15 04:07:50 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.154 | trans_loss 5.35 | nll_loss 2.668 | w2v_ctc_loss 1.425 | task_loss 4.56 | contrastive_loss 0.403 | total 4003.4 | n_correct 2541 | ppl 6.35 | accuracy 63.471 | uer 21.336 | wer 23.101 | raw_wer 23.101 | bleu 19.58 | wps 2237.6 | wpb 4003.4 | bsz 141.8 | num_updates 10308 | best_bleu 19.58
2023-08-15 04:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10308 updates
2023-08-15 04:07:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10308 updates, score 19.58) (writing took 30.374376825988293 seconds)
2023-08-15 04:08:20 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-15 04:08:20 | INFO | train | epoch 007 | loss 2.272 | trans_loss 3.489 | nll_loss 1.697 | w2v_ctc_loss 1.213 | task_loss 0.935 | contrastive_loss 0.313 | total 4138.65 | n_correct 2451.44 | ppl 3.24 | accuracy 59.233 | wps 12043.5 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 10308 | lr 0.000139293 | gnorm 0.549 | clip 0 | loss_scale 2 | train_wall 1356 | gb_free 12.8 | wall 9672
2023-08-15 04:08:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:08:20 | INFO | fairseq.trainer | begin training epoch 8
2023-08-15 04:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:09:54 | INFO | train_inner | epoch 008:     92 / 1474 loss=2.198, trans_loss=3.465, nll_loss=1.662, w2v_ctc_loss=1.165, task_loss=1.002, contrastive_loss=0.232, total=4097.76, n_correct=2473, ppl=3.17, accuracy=60.35, wps=7918.8, ups=0.65, wpb=12216.9, bsz=437, num_updates=10400, lr=0.000138675, gnorm=0.444, clip=0, loss_scale=2, train_wall=92, gb_free=15.6, wall=9766
2023-08-15 04:11:26 | INFO | train_inner | epoch 008:    192 / 1474 loss=2.196, trans_loss=3.455, nll_loss=1.651, w2v_ctc_loss=1.158, task_loss=1.017, contrastive_loss=0.255, total=4039, n_correct=2441.28, ppl=3.14, accuracy=60.443, wps=13103.7, ups=1.09, wpb=12046.3, bsz=428.9, num_updates=10500, lr=0.000138013, gnorm=0.437, clip=0, loss_scale=2, train_wall=91, gb_free=14.5, wall=9858
2023-08-15 04:12:58 | INFO | train_inner | epoch 008:    292 / 1474 loss=2.196, trans_loss=3.449, nll_loss=1.645, w2v_ctc_loss=1.161, task_loss=0.879, contrastive_loss=0.251, total=4210.6, n_correct=2552.45, ppl=3.13, accuracy=60.62, wps=13594.6, ups=1.08, wpb=12566.5, bsz=486.9, num_updates=10600, lr=0.000137361, gnorm=0.431, clip=0, loss_scale=2, train_wall=92, gb_free=15.7, wall=9950
2023-08-15 04:14:32 | INFO | train_inner | epoch 008:    392 / 1474 loss=2.203, trans_loss=3.452, nll_loss=1.648, w2v_ctc_loss=1.166, task_loss=0.973, contrastive_loss=0.272, total=4139.64, n_correct=2505.65, ppl=3.13, accuracy=60.528, wps=13133.8, ups=1.06, wpb=12350.6, bsz=447.4, num_updates=10700, lr=0.000136717, gnorm=0.429, clip=0, loss_scale=2, train_wall=93, gb_free=14.8, wall=10044
2023-08-15 04:16:05 | INFO | train_inner | epoch 008:    492 / 1474 loss=2.259, trans_loss=3.451, nll_loss=1.649, w2v_ctc_loss=1.153, task_loss=0.853, contrastive_loss=0.532, total=4189.5, n_correct=2532.54, ppl=3.14, accuracy=60.45, wps=13441.7, ups=1.07, wpb=12508.9, bsz=499.4, num_updates=10800, lr=0.000136083, gnorm=0.439, clip=0, loss_scale=2, train_wall=93, gb_free=12.3, wall=10137
2023-08-15 04:17:38 | INFO | train_inner | epoch 008:    592 / 1474 loss=2.189, trans_loss=3.446, nll_loss=1.646, w2v_ctc_loss=1.171, task_loss=1.018, contrastive_loss=0.205, total=4061.09, n_correct=2456.01, ppl=3.13, accuracy=60.477, wps=13130.4, ups=1.08, wpb=12140.1, bsz=427.7, num_updates=10900, lr=0.000135457, gnorm=0.434, clip=0, loss_scale=2, train_wall=92, gb_free=16.2, wall=10230
2023-08-15 04:19:10 | INFO | train_inner | epoch 008:    692 / 1474 loss=2.18, trans_loss=3.442, nll_loss=1.637, w2v_ctc_loss=1.163, task_loss=0.956, contrastive_loss=0.217, total=4144.17, n_correct=2523, ppl=3.11, accuracy=60.881, wps=13351, ups=1.08, wpb=12370.7, bsz=450.4, num_updates=11000, lr=0.00013484, gnorm=0.429, clip=0, loss_scale=2, train_wall=92, gb_free=13, wall=10322
2023-08-15 04:20:43 | INFO | train_inner | epoch 008:    792 / 1474 loss=2.195, trans_loss=3.438, nll_loss=1.636, w2v_ctc_loss=1.158, task_loss=0.958, contrastive_loss=0.302, total=4117.36, n_correct=2503.82, ppl=3.11, accuracy=60.811, wps=13333.4, ups=1.08, wpb=12305.6, bsz=448.1, num_updates=11100, lr=0.000134231, gnorm=0.437, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=10415
2023-08-15 04:22:15 | INFO | train_inner | epoch 008:    892 / 1474 loss=2.185, trans_loss=3.441, nll_loss=1.637, w2v_ctc_loss=1.138, task_loss=0.884, contrastive_loss=0.308, total=4182.5, n_correct=2550.91, ppl=3.11, accuracy=60.99, wps=13524.7, ups=1.08, wpb=12489.6, bsz=478.7, num_updates=11200, lr=0.000133631, gnorm=0.433, clip=0, loss_scale=2, train_wall=92, gb_free=17.2, wall=10507
2023-08-15 04:23:47 | INFO | train_inner | epoch 008:    992 / 1474 loss=2.161, trans_loss=3.44, nll_loss=1.635, w2v_ctc_loss=1.143, task_loss=0.897, contrastive_loss=0.211, total=4155.49, n_correct=2536.57, ppl=3.11, accuracy=61.041, wps=13513.9, ups=1.09, wpb=12408.4, bsz=464, num_updates=11300, lr=0.000133038, gnorm=0.423, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=10599
2023-08-15 04:25:20 | INFO | train_inner | epoch 008:   1092 / 1474 loss=2.203, trans_loss=3.443, nll_loss=1.637, w2v_ctc_loss=1.14, task_loss=0.939, contrastive_loss=0.428, total=4186.39, n_correct=2548.38, ppl=3.11, accuracy=60.873, wps=13427.1, ups=1.07, wpb=12493.6, bsz=461.7, num_updates=11400, lr=0.000132453, gnorm=0.424, clip=0, loss_scale=4, train_wall=93, gb_free=14.9, wall=10692
2023-08-15 04:26:52 | INFO | train_inner | epoch 008:   1192 / 1474 loss=2.168, trans_loss=3.435, nll_loss=1.631, w2v_ctc_loss=1.149, task_loss=0.889, contrastive_loss=0.22, total=4178.48, n_correct=2553.29, ppl=3.1, accuracy=61.106, wps=13567.4, ups=1.09, wpb=12482, bsz=472.1, num_updates=11500, lr=0.000131876, gnorm=0.422, clip=0, loss_scale=4, train_wall=91, gb_free=15.5, wall=10784
2023-08-15 04:28:23 | INFO | train_inner | epoch 008:   1292 / 1474 loss=2.171, trans_loss=3.438, nll_loss=1.634, w2v_ctc_loss=1.151, task_loss=0.984, contrastive_loss=0.238, total=4064.4, n_correct=2476.85, ppl=3.1, accuracy=60.94, wps=13288.5, ups=1.09, wpb=12140.7, bsz=436, num_updates=11600, lr=0.000131306, gnorm=0.426, clip=0, loss_scale=4, train_wall=91, gb_free=15.7, wall=10875
2023-08-15 04:29:55 | INFO | train_inner | epoch 008:   1392 / 1474 loss=2.18, trans_loss=3.438, nll_loss=1.634, w2v_ctc_loss=1.139, task_loss=0.894, contrastive_loss=0.303, total=4163.91, n_correct=2546.72, ppl=3.1, accuracy=61.162, wps=13537.5, ups=1.09, wpb=12433, bsz=472.8, num_updates=11700, lr=0.000130744, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=16.2, wall=10967
2023-08-15 04:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:31:34 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.087 | trans_loss 5.283 | nll_loss 2.58 | w2v_ctc_loss 1.379 | task_loss 4.628 | contrastive_loss 0.38 | total 4003.4 | n_correct 2582.2 | ppl 5.98 | accuracy 64.5 | uer 19.866 | wer 21.658 | raw_wer 21.658 | bleu 19.93 | wps 2155.7 | wpb 4003.4 | bsz 141.8 | num_updates 11782 | best_bleu 19.93
2023-08-15 04:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11782 updates
2023-08-15 04:31:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11782 updates, score 19.93) (writing took 30.62983792461455 seconds)
2023-08-15 04:32:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-15 04:32:05 | INFO | train | epoch 008 | loss 2.19 | trans_loss 3.445 | nll_loss 1.641 | w2v_ctc_loss 1.153 | task_loss 0.935 | contrastive_loss 0.289 | total 4138.65 | n_correct 2516.08 | ppl 3.12 | accuracy 60.795 | wps 12778.5 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11782 | lr 0.000130288 | gnorm 0.43 | clip 0 | loss_scale 4 | train_wall 1355 | gb_free 16.6 | wall 11097
2023-08-15 04:32:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:32:06 | INFO | fairseq.trainer | begin training epoch 9
2023-08-15 04:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:32:31 | INFO | train_inner | epoch 009:     18 / 1474 loss=2.176, trans_loss=3.435, nll_loss=1.628, w2v_ctc_loss=1.125, task_loss=0.93, contrastive_loss=0.396, total=4111.15, n_correct=2520.34, ppl=3.09, accuracy=61.305, wps=7895.7, ups=0.64, wpb=12269.8, bsz=460.9, num_updates=11800, lr=0.000130189, gnorm=0.419, clip=0, loss_scale=4, train_wall=92, gb_free=16.7, wall=11123
2023-08-15 04:34:03 | INFO | train_inner | epoch 009:    118 / 1474 loss=2.12, trans_loss=3.408, nll_loss=1.594, w2v_ctc_loss=1.101, task_loss=0.874, contrastive_loss=0.232, total=4186.63, n_correct=2599, ppl=3.02, accuracy=62.079, wps=13511.2, ups=1.08, wpb=12503, bsz=481.5, num_updates=11900, lr=0.000129641, gnorm=0.417, clip=0, loss_scale=4, train_wall=92, gb_free=16.2, wall=11215
2023-08-15 04:35:36 | INFO | train_inner | epoch 009:    218 / 1474 loss=2.106, trans_loss=3.411, nll_loss=1.597, w2v_ctc_loss=1.1, task_loss=1.012, contrastive_loss=0.186, total=4071.82, n_correct=2522.54, ppl=3.03, accuracy=61.951, wps=13125.7, ups=1.08, wpb=12157.1, bsz=430.9, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=4, train_wall=92, gb_free=16.3, wall=11308
2023-08-15 04:35:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:36:00 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.289 | nll_loss 2.585 | w2v_ctc_loss 1.363 | task_loss 4.583 | contrastive_loss 0.375 | total 4003.4 | n_correct 2581.2 | ppl 6 | accuracy 64.475 | uer 19.924 | wer 21.852 | raw_wer 21.852 | bleu 19.96 | wps 2147.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.96
2023-08-15 04:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-15 04:36:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-15 04:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-15 04:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 19.96) (writing took 55.65827392973006 seconds)
2023-08-15 04:38:29 | INFO | train_inner | epoch 009:    318 / 1474 loss=2.106, trans_loss=3.401, nll_loss=1.588, w2v_ctc_loss=1.086, task_loss=0.86, contrastive_loss=0.24, total=4167.06, n_correct=2595.17, ppl=3.01, accuracy=62.278, wps=7198.5, ups=0.58, wpb=12450.2, bsz=485.4, num_updates=12100, lr=0.000128565, gnorm=0.416, clip=0, loss_scale=4, train_wall=92, gb_free=14.6, wall=11481
2023-08-15 04:40:02 | INFO | train_inner | epoch 009:    418 / 1474 loss=2.111, trans_loss=3.417, nll_loss=1.605, w2v_ctc_loss=1.102, task_loss=0.94, contrastive_loss=0.197, total=4175.09, n_correct=2581.8, ppl=3.04, accuracy=61.838, wps=13307.8, ups=1.07, wpb=12466.4, bsz=457.5, num_updates=12200, lr=0.000128037, gnorm=0.417, clip=0, loss_scale=4, train_wall=93, gb_free=17, wall=11574
2023-08-15 04:41:35 | INFO | train_inner | epoch 009:    518 / 1474 loss=2.137, trans_loss=3.414, nll_loss=1.601, w2v_ctc_loss=1.12, task_loss=0.982, contrastive_loss=0.252, total=4118.47, n_correct=2547.22, ppl=3.03, accuracy=61.849, wps=13332.3, ups=1.08, wpb=12292.7, bsz=439.7, num_updates=12300, lr=0.000127515, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=17.2, wall=11667
2023-08-15 04:43:07 | INFO | train_inner | epoch 009:    618 / 1474 loss=2.128, trans_loss=3.407, nll_loss=1.596, w2v_ctc_loss=1.095, task_loss=0.939, contrastive_loss=0.31, total=4141.76, n_correct=2568.19, ppl=3.02, accuracy=62.007, wps=13373.2, ups=1.08, wpb=12378.7, bsz=462.3, num_updates=12400, lr=0.000127, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=16.7, wall=11759
2023-08-15 04:44:38 | INFO | train_inner | epoch 009:    718 / 1474 loss=2.118, trans_loss=3.413, nll_loss=1.603, w2v_ctc_loss=1.119, task_loss=0.972, contrastive_loss=0.196, total=4075.02, n_correct=2518.77, ppl=3.04, accuracy=61.81, wps=13337.2, ups=1.1, wpb=12176, bsz=443.4, num_updates=12500, lr=0.000126491, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=17.2, wall=11850
2023-08-15 04:46:12 | INFO | train_inner | epoch 009:    818 / 1474 loss=2.172, trans_loss=3.408, nll_loss=1.597, w2v_ctc_loss=1.105, task_loss=0.851, contrastive_loss=0.438, total=4214.28, n_correct=2607.52, ppl=3.03, accuracy=61.873, wps=13491.4, ups=1.07, wpb=12593.1, bsz=499.2, num_updates=12600, lr=0.000125988, gnorm=0.436, clip=0, loss_scale=4, train_wall=93, gb_free=16.5, wall=11944
2023-08-15 04:47:46 | INFO | train_inner | epoch 009:    918 / 1474 loss=2.148, trans_loss=3.413, nll_loss=1.597, w2v_ctc_loss=1.106, task_loss=0.959, contrastive_loss=0.412, total=4157.54, n_correct=2575.78, ppl=3.03, accuracy=61.954, wps=13153.5, ups=1.06, wpb=12400.4, bsz=452, num_updates=12700, lr=0.000125491, gnorm=0.414, clip=0, loss_scale=4, train_wall=94, gb_free=16, wall=12038
2023-08-15 04:49:18 | INFO | train_inner | epoch 009:   1018 / 1474 loss=2.107, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.107, task_loss=1.046, contrastive_loss=0.193, total=4093.77, n_correct=2533.16, ppl=3.04, accuracy=61.878, wps=13286, ups=1.09, wpb=12221, bsz=423.7, num_updates=12800, lr=0.000125, gnorm=0.421, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=12130
2023-08-15 04:50:50 | INFO | train_inner | epoch 009:   1118 / 1474 loss=2.11, trans_loss=3.417, nll_loss=1.602, w2v_ctc_loss=1.098, task_loss=0.892, contrastive_loss=0.219, total=4173.97, n_correct=2588.53, ppl=3.03, accuracy=62.016, wps=13480.9, ups=1.08, wpb=12442.6, bsz=471.4, num_updates=12900, lr=0.000124515, gnorm=0.425, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=12222
2023-08-15 04:52:24 | INFO | train_inner | epoch 009:   1218 / 1474 loss=2.114, trans_loss=3.412, nll_loss=1.6, w2v_ctc_loss=1.115, task_loss=0.983, contrastive_loss=0.199, total=4144.88, n_correct=2569, ppl=3.03, accuracy=61.98, wps=13264.3, ups=1.07, wpb=12376.1, bsz=450, num_updates=13000, lr=0.000124035, gnorm=0.423, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=12316
2023-08-15 04:53:56 | INFO | train_inner | epoch 009:   1318 / 1474 loss=2.136, trans_loss=3.404, nll_loss=1.589, w2v_ctc_loss=1.089, task_loss=0.854, contrastive_loss=0.388, total=4200.61, n_correct=2618.38, ppl=3.01, accuracy=62.333, wps=13553.8, ups=1.08, wpb=12534.4, bsz=490.7, num_updates=13100, lr=0.00012356, gnorm=0.42, clip=0, loss_scale=4, train_wall=92, gb_free=15.3, wall=12408
2023-08-15 04:55:28 | INFO | train_inner | epoch 009:   1418 / 1474 loss=2.103, trans_loss=3.419, nll_loss=1.607, w2v_ctc_loss=1.106, task_loss=1.004, contrastive_loss=0.178, total=4075.96, n_correct=2520.68, ppl=3.05, accuracy=61.843, wps=13288.8, ups=1.09, wpb=12161.1, bsz=430.6, num_updates=13200, lr=0.000123091, gnorm=0.415, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=12500
2023-08-15 04:56:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:56:42 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.047 | trans_loss 5.253 | nll_loss 2.548 | w2v_ctc_loss 1.334 | task_loss 4.57 | contrastive_loss 0.368 | total 4003.4 | n_correct 2599 | ppl 5.85 | accuracy 64.92 | uer 19.168 | wer 21.017 | raw_wer 21.017 | bleu 20.72 | wps 2102.5 | wpb 4003.4 | bsz 141.8 | num_updates 13256 | best_bleu 20.72
2023-08-15 04:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13256 updates
2023-08-15 04:56:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13256 updates, score 20.72) (writing took 29.309386936947703 seconds)
2023-08-15 04:57:12 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-15 04:57:12 | INFO | train | epoch 009 | loss 2.123 | trans_loss 3.411 | nll_loss 1.598 | w2v_ctc_loss 1.103 | task_loss 0.936 | contrastive_loss 0.266 | total 4138.65 | n_correct 2565.36 | ppl 3.03 | accuracy 61.986 | wps 12086.5 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 13256 | lr 0.000122831 | gnorm 0.421 | clip 0 | loss_scale 4 | train_wall 1357 | gb_free 11.2 | wall 12604
2023-08-15 04:57:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:57:13 | INFO | fairseq.trainer | begin training epoch 10
2023-08-15 04:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:58:01 | INFO | train_inner | epoch 010:     44 / 1474 loss=2.095, trans_loss=3.4, nll_loss=1.583, w2v_ctc_loss=1.075, task_loss=0.874, contrastive_loss=0.27, total=4112.83, n_correct=2571.19, ppl=3, accuracy=62.516, wps=8012.7, ups=0.65, wpb=12275.4, bsz=475.1, num_updates=13300, lr=0.000122628, gnorm=0.411, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=12653
2023-08-15 04:59:34 | INFO | train_inner | epoch 010:    144 / 1474 loss=2.052, trans_loss=3.384, nll_loss=1.564, w2v_ctc_loss=1.05, task_loss=0.903, contrastive_loss=0.192, total=4230.29, n_correct=2661.03, ppl=2.96, accuracy=62.904, wps=13596.3, ups=1.08, wpb=12634.2, bsz=472.7, num_updates=13400, lr=0.000122169, gnorm=0.406, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=12746
2023-08-15 05:01:06 | INFO | train_inner | epoch 010:    244 / 1474 loss=2.08, trans_loss=3.381, nll_loss=1.559, w2v_ctc_loss=1.058, task_loss=0.92, contrastive_loss=0.313, total=4131.59, n_correct=2602.35, ppl=2.95, accuracy=62.987, wps=13410.3, ups=1.09, wpb=12331.3, bsz=463.6, num_updates=13500, lr=0.000121716, gnorm=0.409, clip=0, loss_scale=8, train_wall=91, gb_free=9.6, wall=12838
2023-08-15 05:02:38 | INFO | train_inner | epoch 010:    344 / 1474 loss=2.06, trans_loss=3.381, nll_loss=1.562, w2v_ctc_loss=1.055, task_loss=0.943, contrastive_loss=0.228, total=4135.23, n_correct=2602.23, ppl=2.95, accuracy=62.928, wps=13355.2, ups=1.08, wpb=12360.3, bsz=454.8, num_updates=13600, lr=0.000121268, gnorm=0.41, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=12930
2023-08-15 05:04:12 | INFO | train_inner | epoch 010:    444 / 1474 loss=2.085, trans_loss=3.385, nll_loss=1.565, w2v_ctc_loss=1.045, task_loss=0.899, contrastive_loss=0.394, total=4197.95, n_correct=2642.1, ppl=2.96, accuracy=62.938, wps=13421.7, ups=1.07, wpb=12531.8, bsz=481.2, num_updates=13700, lr=0.000120824, gnorm=0.402, clip=0, loss_scale=8, train_wall=93, gb_free=15.2, wall=13024
2023-08-15 05:05:45 | INFO | train_inner | epoch 010:    544 / 1474 loss=2.069, trans_loss=3.397, nll_loss=1.577, w2v_ctc_loss=1.078, task_loss=1.017, contrastive_loss=0.179, total=4097.61, n_correct=2565.62, ppl=2.98, accuracy=62.613, wps=13107.6, ups=1.07, wpb=12219.2, bsz=434.6, num_updates=13800, lr=0.000120386, gnorm=0.412, clip=0, loss_scale=8, train_wall=93, gb_free=17.6, wall=13117
2023-08-15 05:07:18 | INFO | train_inner | epoch 010:    644 / 1474 loss=2.089, trans_loss=3.39, nll_loss=1.571, w2v_ctc_loss=1.067, task_loss=0.872, contrastive_loss=0.298, total=4187.04, n_correct=2628.14, ppl=2.97, accuracy=62.768, wps=13471.2, ups=1.08, wpb=12494.9, bsz=483.5, num_updates=13900, lr=0.000119952, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=16.2, wall=13210
2023-08-15 05:08:49 | INFO | train_inner | epoch 010:    744 / 1474 loss=2.07, trans_loss=3.388, nll_loss=1.568, w2v_ctc_loss=1.084, task_loss=0.951, contrastive_loss=0.175, total=4112.31, n_correct=2580.36, ppl=2.97, accuracy=62.747, wps=13394.9, ups=1.09, wpb=12277.4, bsz=448.4, num_updates=14000, lr=0.000119523, gnorm=0.425, clip=0, loss_scale=8, train_wall=91, gb_free=12, wall=13301
2023-08-15 05:08:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:09:13 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.05 | trans_loss 5.244 | nll_loss 2.53 | w2v_ctc_loss 1.377 | task_loss 4.65 | contrastive_loss 0.354 | total 4003.4 | n_correct 2600.7 | ppl 5.78 | accuracy 64.962 | uer 19.85 | wer 21.767 | raw_wer 21.767 | bleu 20.54 | wps 2154.4 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 20.72
2023-08-15 05:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-15 05:09:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-15 05:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-15 05:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 20.54) (writing took 42.75176669098437 seconds)
2023-08-15 05:11:31 | INFO | train_inner | epoch 010:    844 / 1474 loss=2.054, trans_loss=3.389, nll_loss=1.569, w2v_ctc_loss=1.061, task_loss=0.927, contrastive_loss=0.181, total=4135.95, n_correct=2596.12, ppl=2.97, accuracy=62.77, wps=7644.1, ups=0.62, wpb=12346.8, bsz=456.9, num_updates=14100, lr=0.000119098, gnorm=0.467, clip=0, loss_scale=8, train_wall=92, gb_free=15.5, wall=13463
2023-08-15 05:13:04 | INFO | train_inner | epoch 010:    944 / 1474 loss=2.061, trans_loss=3.384, nll_loss=1.562, w2v_ctc_loss=1.06, task_loss=0.892, contrastive_loss=0.219, total=4169.57, n_correct=2627.18, ppl=2.95, accuracy=63.008, wps=13411.4, ups=1.08, wpb=12439, bsz=473.3, num_updates=14200, lr=0.000118678, gnorm=0.407, clip=0, loss_scale=8, train_wall=92, gb_free=13.2, wall=13556
2023-08-15 05:14:36 | INFO | train_inner | epoch 010:   1044 / 1474 loss=2.056, trans_loss=3.386, nll_loss=1.565, w2v_ctc_loss=1.065, task_loss=1.024, contrastive_loss=0.186, total=4058.1, n_correct=2548.81, ppl=2.96, accuracy=62.808, wps=13182.9, ups=1.09, wpb=12115.2, bsz=430.4, num_updates=14300, lr=0.000118262, gnorm=0.417, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=13647
2023-08-15 05:16:07 | INFO | train_inner | epoch 010:   1144 / 1474 loss=2.067, trans_loss=3.392, nll_loss=1.574, w2v_ctc_loss=1.082, task_loss=1.052, contrastive_loss=0.17, total=4034.12, n_correct=2525.3, ppl=2.98, accuracy=62.599, wps=13148.2, ups=1.09, wpb=12044.8, bsz=418.2, num_updates=14400, lr=0.000117851, gnorm=0.416, clip=0, loss_scale=8, train_wall=91, gb_free=15.3, wall=13739
2023-08-15 05:17:40 | INFO | train_inner | epoch 010:   1244 / 1474 loss=2.053, trans_loss=3.378, nll_loss=1.56, w2v_ctc_loss=1.071, task_loss=0.955, contrastive_loss=0.168, total=4107.11, n_correct=2581.69, ppl=2.95, accuracy=62.859, wps=13273.1, ups=1.08, wpb=12283.5, bsz=446.4, num_updates=14500, lr=0.000117444, gnorm=0.415, clip=0, loss_scale=8, train_wall=92, gb_free=14.8, wall=13832
2023-08-15 05:19:12 | INFO | train_inner | epoch 010:   1344 / 1474 loss=2.056, trans_loss=3.385, nll_loss=1.566, w2v_ctc_loss=1.069, task_loss=0.94, contrastive_loss=0.18, total=4143.63, n_correct=2610.67, ppl=2.96, accuracy=63.004, wps=13351.3, ups=1.08, wpb=12373.1, bsz=457, num_updates=14600, lr=0.000117041, gnorm=0.413, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13924
2023-08-15 05:20:46 | INFO | train_inner | epoch 010:   1444 / 1474 loss=2.11, trans_loss=3.393, nll_loss=1.574, w2v_ctc_loss=1.049, task_loss=0.884, contrastive_loss=0.432, total=4183.87, n_correct=2624.11, ppl=2.98, accuracy=62.72, wps=13318.2, ups=1.07, wpb=12480.2, bsz=480.8, num_updates=14700, lr=0.000116642, gnorm=0.419, clip=0, loss_scale=8, train_wall=93, gb_free=12.9, wall=14018
2023-08-15 05:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:21:37 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.031 | trans_loss 5.23 | nll_loss 2.516 | w2v_ctc_loss 1.352 | task_loss 4.599 | contrastive_loss 0.35 | total 4003.4 | n_correct 2617.5 | ppl 5.72 | accuracy 65.382 | uer 18.799 | wer 20.715 | raw_wer 20.715 | bleu 21.2 | wps 2170.5 | wpb 4003.4 | bsz 141.8 | num_updates 14730 | best_bleu 21.2
2023-08-15 05:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14730 updates
2023-08-15 05:21:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 05:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 05:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14730 updates, score 21.2) (writing took 31.978072565048933 seconds)
2023-08-15 05:22:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-15 05:22:10 | INFO | train | epoch 010 | loss 2.07 | trans_loss 3.386 | nll_loss 1.567 | w2v_ctc_loss 1.062 | task_loss 0.936 | contrastive_loss 0.248 | total 4138.65 | n_correct 2600.62 | ppl 2.96 | accuracy 62.837 | wps 12163.7 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14730 | lr 0.000116524 | gnorm 0.416 | clip 0 | loss_scale 8 | train_wall 1356 | gb_free 17 | wall 14102
2023-08-15 05:22:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 05:22:10 | INFO | fairseq.trainer | begin training epoch 11
2023-08-15 05:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 05:23:21 | INFO | train_inner | epoch 011:     70 / 1474 loss=2.037, trans_loss=3.364, nll_loss=1.538, w2v_ctc_loss=1.034, task_loss=0.879, contrastive_loss=0.255, total=4162.14, n_correct=2647.73, ppl=2.9, accuracy=63.615, wps=8005.1, ups=0.64, wpb=12425.4, bsz=474.3, num_updates=14800, lr=0.000116248, gnorm=0.4, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=14173
2023-08-15 05:24:54 | INFO | train_inner | epoch 011:    170 / 1474 loss=2.019, trans_loss=3.364, nll_loss=1.54, w2v_ctc_loss=1.033, task_loss=0.958, contrastive_loss=0.175, total=4103.74, n_correct=2605.78, ppl=2.91, accuracy=63.498, wps=13246.8, ups=1.08, wpb=12261.3, bsz=450.5, num_updates=14900, lr=0.000115857, gnorm=0.413, clip=0, loss_scale=8, train_wall=92, gb_free=16.5, wall=14266
2023-08-15 05:26:26 | INFO | train_inner | epoch 011:    270 / 1474 loss=2.009, trans_loss=3.365, nll_loss=1.539, w2v_ctc_loss=1.026, task_loss=0.972, contrastive_loss=0.161, total=4114.56, n_correct=2612.41, ppl=2.91, accuracy=63.492, wps=13338.4, ups=1.09, wpb=12288.3, bsz=443.1, num_updates=15000, lr=0.00011547, gnorm=0.404, clip=0, loss_scale=8, train_wall=92, gb_free=15.3, wall=14358
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 05:27:35 | INFO | train_inner | epoch 011:    370 / 1474 loss=2.075, trans_loss=5, nll_loss=2.285, w2v_ctc_loss=0.768, task_loss=1.439, contrastive_loss=0.131, total=4094.93, n_correct=2602.06, ppl=4.87, accuracy=63.543, wps=11997.1, ups=1.46, wpb=8223.5, bsz=297, num_updates=15100, lr=0.000115087, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=11.8, wall=14427
2023-08-15 05:28:44 | INFO | train_inner | epoch 011:    470 / 1474 loss=2.099, trans_loss=5.038, nll_loss=2.316, w2v_ctc_loss=0.766, task_loss=1.458, contrastive_loss=0.249, total=4113.98, n_correct=2596.24, ppl=4.98, accuracy=63.108, wps=11777.4, ups=1.43, wpb=8228, bsz=302.3, num_updates=15200, lr=0.000114708, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=9.7, wall=14496
2023-08-15 05:29:54 | INFO | train_inner | epoch 011:    570 / 1474 loss=2.1, trans_loss=5.034, nll_loss=2.311, w2v_ctc_loss=0.781, task_loss=1.507, contrastive_loss=0.243, total=4074.83, n_correct=2575.1, ppl=4.96, accuracy=63.195, wps=11638.4, ups=1.43, wpb=8149.7, bsz=293.3, num_updates=15300, lr=0.000114332, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=15, wall=14566
2023-08-15 05:31:04 | INFO | train_inner | epoch 011:    670 / 1474 loss=2.097, trans_loss=5.021, nll_loss=2.295, w2v_ctc_loss=0.775, task_loss=1.362, contrastive_loss=0.304, total=4161.4, n_correct=2637.87, ppl=4.91, accuracy=63.389, wps=11898.9, ups=1.43, wpb=8322.8, bsz=311.9, num_updates=15400, lr=0.000113961, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=14636
2023-08-15 05:32:14 | INFO | train_inner | epoch 011:    770 / 1474 loss=2.089, trans_loss=5.034, nll_loss=2.312, w2v_ctc_loss=0.784, task_loss=1.442, contrastive_loss=0.129, total=4153.23, n_correct=2630.14, ppl=4.97, accuracy=63.328, wps=11974.1, ups=1.44, wpb=8306.5, bsz=301.5, num_updates=15500, lr=0.000113592, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=14706
2023-08-15 05:33:23 | INFO | train_inner | epoch 011:    870 / 1474 loss=2.09, trans_loss=5.036, nll_loss=2.315, w2v_ctc_loss=0.782, task_loss=1.468, contrastive_loss=0.12, total=4122.58, n_correct=2603.2, ppl=4.97, accuracy=63.145, wps=11941.9, ups=1.45, wpb=8245.2, bsz=293.8, num_updates=15600, lr=0.000113228, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=14775
2023-08-15 05:34:33 | INFO | train_inner | epoch 011:    970 / 1474 loss=2.084, trans_loss=5.029, nll_loss=2.305, w2v_ctc_loss=0.779, task_loss=1.415, contrastive_loss=0.133, total=4150.11, n_correct=2629.07, ppl=4.94, accuracy=63.349, wps=11905.2, ups=1.43, wpb=8300.2, bsz=304.8, num_updates=15700, lr=0.000112867, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=14845
2023-08-15 05:35:42 | INFO | train_inner | epoch 011:   1070 / 1474 loss=2.084, trans_loss=5.027, nll_loss=2.304, w2v_ctc_loss=0.776, task_loss=1.378, contrastive_loss=0.15, total=4146.14, n_correct=2630.65, ppl=4.94, accuracy=63.448, wps=11973.1, ups=1.44, wpb=8292.3, bsz=309.8, num_updates=15800, lr=0.000112509, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=14914
2023-08-15 05:36:51 | INFO | train_inner | epoch 011:   1170 / 1474 loss=2.084, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.776, task_loss=1.384, contrastive_loss=0.144, total=4182.57, n_correct=2651.36, ppl=4.95, accuracy=63.391, wps=12066.8, ups=1.44, wpb=8365.1, bsz=311.4, num_updates=15900, lr=0.000112154, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=14983
2023-08-15 05:38:01 | INFO | train_inner | epoch 011:   1270 / 1474 loss=2.095, trans_loss=5.029, nll_loss=2.307, w2v_ctc_loss=0.783, task_loss=1.382, contrastive_loss=0.197, total=4157.11, n_correct=2629.69, ppl=4.95, accuracy=63.258, wps=11945.6, ups=1.44, wpb=8314.2, bsz=308.6, num_updates=16000, lr=0.000111803, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=15053
2023-08-15 05:38:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 05:38:24 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.028 | trans_loss 5.223 | nll_loss 2.508 | w2v_ctc_loss 1.363 | task_loss 4.62 | contrastive_loss 0.345 | total 4003.4 | n_correct 2622.4 | ppl 5.69 | accuracy 65.504 | uer 18.791 | wer 20.704 | raw_wer 20.704 | bleu 20.84 | wps 2257.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.2
2023-08-15 05:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-15 05:38:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-15 05:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-15 05:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.84) (writing took 41.220497814938426 seconds)
2023-08-15 05:40:16 | INFO | train_inner | epoch 011:   1370 / 1474 loss=2.101, trans_loss=5.027, nll_loss=2.305, w2v_ctc_loss=0.769, task_loss=1.293, contrastive_loss=0.363, total=4192.31, n_correct=2655.84, ppl=4.94, accuracy=63.35, wps=6192.4, ups=0.74, wpb=8384.6, bsz=328.3, num_updates=16100, lr=0.000111456, gnorm=0.521, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=15188
2023-08-15 05:41:26 | INFO | train_inner | epoch 011:   1470 / 1474 loss=2.077, trans_loss=5.025, nll_loss=2.301, w2v_ctc_loss=0.773, task_loss=1.352, contrastive_loss=0.137, total=4162.97, n_correct=2645.19, ppl=4.93, accuracy=63.541, wps=11914.1, ups=1.43, wpb=8325.9, bsz=313, num_updates=16200, lr=0.000111111, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=15258
2023-08-15 05:41:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:41:52 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.016 | trans_loss 5.216 | nll_loss 2.494 | w2v_ctc_loss 1.338 | task_loss 4.627 | contrastive_loss 0.344 | total 4003.4 | n_correct 2629.4 | ppl 5.63 | accuracy 65.679 | uer 19.003 | wer 20.902 | raw_wer 20.902 | bleu 20.85 | wps 2267.5 | wpb 4003.4 | bsz 141.8 | num_updates 16204 | best_bleu 21.2
2023-08-15 05:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16204 updates
2023-08-15 05:41:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt
2023-08-15 05:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt
2023-08-15 05:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt (epoch 11 @ 16204 updates, score 20.85) (writing took 20.98008725605905 seconds)
2023-08-15 05:42:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-15 05:42:13 | INFO | train | epoch 011 | loss 2.071 | trans_loss 4.611 | nll_loss 2.113 | w2v_ctc_loss 0.839 | task_loss 1.287 | contrastive_loss 0.187 | total 4138.65 | n_correct 2623.22 | ppl 4.33 | accuracy 63.383 | wps 11056.4 | ups 1.22 | wpb 9025.9 | bsz 333.5 | num_updates 16204 | lr 0.000111097 | gnorm 0.503 | clip 0 | loss_scale 16 | train_wall 1079 | gb_free 16.9 | wall 15305
2023-08-15 05:42:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 05:42:13 | INFO | fairseq.trainer | begin training epoch 12
2023-08-15 05:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 05:43:27 | INFO | train_inner | epoch 012:     96 / 1474 loss=2.061, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.758, task_loss=1.347, contrastive_loss=0.167, total=4145.21, n_correct=2663, ppl=4.76, accuracy=64.243, wps=6846.1, ups=0.83, wpb=8290.4, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=15379
2023-08-15 05:44:36 | INFO | train_inner | epoch 012:    196 / 1474 loss=2.063, trans_loss=4.994, nll_loss=2.259, w2v_ctc_loss=0.761, task_loss=1.441, contrastive_loss=0.122, total=4124.1, n_correct=2639.02, ppl=4.79, accuracy=63.99, wps=11906.9, ups=1.44, wpb=8248.2, bsz=296.1, num_updates=16400, lr=0.000110432, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=15448
2023-08-15 05:45:46 | INFO | train_inner | epoch 012:    296 / 1474 loss=2.059, trans_loss=4.994, nll_loss=2.261, w2v_ctc_loss=0.749, task_loss=1.312, contrastive_loss=0.152, total=4208.07, n_correct=2699.42, ppl=4.79, accuracy=64.149, wps=12119.7, ups=1.44, wpb=8416.1, bsz=321.7, num_updates=16500, lr=0.000110096, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=11.9, wall=15518
2023-08-15 05:46:56 | INFO | train_inner | epoch 012:    396 / 1474 loss=2.065, trans_loss=5, nll_loss=2.267, w2v_ctc_loss=0.764, task_loss=1.384, contrastive_loss=0.135, total=4144.42, n_correct=2651.45, ppl=4.81, accuracy=63.976, wps=11872.4, ups=1.43, wpb=8288.8, bsz=305.3, num_updates=16600, lr=0.000109764, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=15588
2023-08-15 05:48:04 | INFO | train_inner | epoch 012:    496 / 1474 loss=2.072, trans_loss=5.01, nll_loss=2.282, w2v_ctc_loss=0.768, task_loss=1.429, contrastive_loss=0.142, total=4095.26, n_correct=2617.26, ppl=4.86, accuracy=63.909, wps=11907.9, ups=1.45, wpb=8190.5, bsz=299.8, num_updates=16700, lr=0.000109435, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=15656
2023-08-15 05:49:14 | INFO | train_inner | epoch 012:    596 / 1474 loss=2.076, trans_loss=5.003, nll_loss=2.272, w2v_ctc_loss=0.768, task_loss=1.327, contrastive_loss=0.209, total=4204.6, n_correct=2682.73, ppl=4.83, accuracy=63.805, wps=12024.6, ups=1.43, wpb=8409.2, bsz=319.2, num_updates=16800, lr=0.000109109, gnorm=0.56, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=15726
2023-08-15 05:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 05:50:24 | INFO | train_inner | epoch 012:    697 / 1474 loss=2.06, trans_loss=4.999, nll_loss=2.267, w2v_ctc_loss=0.756, task_loss=1.346, contrastive_loss=0.135, total=4175.27, n_correct=2675.61, ppl=4.81, accuracy=64.082, wps=12010.4, ups=1.44, wpb=8350.5, bsz=312.5, num_updates=16900, lr=0.000108786, gnorm=0.514, clip=0, loss_scale=8, train_wall=69, gb_free=15.1, wall=15796
2023-08-15 05:51:34 | INFO | train_inner | epoch 012:    797 / 1474 loss=2.067, trans_loss=4.997, nll_loss=2.264, w2v_ctc_loss=0.77, task_loss=1.438, contrastive_loss=0.13, total=4083.9, n_correct=2613.62, ppl=4.8, accuracy=63.998, wps=11726, ups=1.44, wpb=8167.8, bsz=296.3, num_updates=17000, lr=0.000108465, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=12.5, wall=15866
2023-08-15 05:52:43 | INFO | train_inner | epoch 012:    897 / 1474 loss=2.069, trans_loss=4.998, nll_loss=2.266, w2v_ctc_loss=0.761, task_loss=1.433, contrastive_loss=0.181, total=4168.41, n_correct=2670.14, ppl=4.81, accuracy=64.057, wps=12031.6, ups=1.44, wpb=8336.8, bsz=306.2, num_updates=17100, lr=0.000108148, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=15.3, wall=15935
2023-08-15 05:53:52 | INFO | train_inner | epoch 012:    997 / 1474 loss=2.072, trans_loss=5.003, nll_loss=2.272, w2v_ctc_loss=0.77, task_loss=1.433, contrastive_loss=0.191, total=4121.91, n_correct=2636.05, ppl=4.83, accuracy=63.952, wps=11905.8, ups=1.44, wpb=8243.8, bsz=301.5, num_updates=17200, lr=0.000107833, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=16004
2023-08-15 05:55:02 | INFO | train_inner | epoch 012:   1097 / 1474 loss=2.084, trans_loss=5.009, nll_loss=2.28, w2v_ctc_loss=0.773, task_loss=1.466, contrastive_loss=0.233, total=4055.97, n_correct=2588.37, ppl=4.86, accuracy=63.816, wps=11653.9, ups=1.44, wpb=8111.9, bsz=291.2, num_updates=17300, lr=0.000107521, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=11.8, wall=16074
2023-08-15 05:56:11 | INFO | train_inner | epoch 012:   1197 / 1474 loss=2.089, trans_loss=5.024, nll_loss=2.299, w2v_ctc_loss=0.785, task_loss=1.376, contrastive_loss=0.203, total=4187.55, n_correct=2660.14, ppl=4.92, accuracy=63.525, wps=12009.4, ups=1.43, wpb=8375.1, bsz=317.5, num_updates=17400, lr=0.000107211, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=16143
2023-08-15 05:57:20 | INFO | train_inner | epoch 012:   1297 / 1474 loss=2.072, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.776, task_loss=1.559, contrastive_loss=0.116, total=4075.32, n_correct=2599.26, ppl=4.84, accuracy=63.781, wps=11816.8, ups=1.45, wpb=8150.6, bsz=287, num_updates=17500, lr=0.000106904, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=16.9, wall=16212
2023-08-15 05:58:30 | INFO | train_inner | epoch 012:   1397 / 1474 loss=2.074, trans_loss=5.012, nll_loss=2.284, w2v_ctc_loss=0.761, task_loss=1.42, contrastive_loss=0.219, total=4137.07, n_correct=2637.14, ppl=4.87, accuracy=63.744, wps=11851.9, ups=1.43, wpb=8274.1, bsz=305.6, num_updates=17600, lr=0.0001066, gnorm=0.548, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=16282
2023-08-15 05:59:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:59:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.023 | trans_loss 5.21 | nll_loss 2.487 | w2v_ctc_loss 1.383 | task_loss 4.633 | contrastive_loss 0.345 | total 4003.4 | n_correct 2625.7 | ppl 5.6 | accuracy 65.587 | uer 18.682 | wer 20.54 | raw_wer 20.54 | bleu 21.18 | wps 2228.3 | wpb 4003.4 | bsz 141.8 | num_updates 17677 | best_bleu 21.2
2023-08-15 05:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17677 updates
2023-08-15 05:59:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt
2023-08-15 05:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt
2023-08-15 06:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt (epoch 12 @ 17677 updates, score 21.18) (writing took 22.721838489174843 seconds)
2023-08-15 06:00:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-15 06:00:10 | INFO | train | epoch 012 | loss 2.07 | trans_loss 5.003 | nll_loss 2.272 | w2v_ctc_loss 0.766 | task_loss 1.408 | contrastive_loss 0.165 | total 4136.79 | n_correct 2644.53 | ppl 4.83 | accuracy 63.927 | wps 11311.1 | ups 1.37 | wpb 8273.6 | bsz 304.9 | num_updates 17677 | lr 0.000106368 | gnorm 0.53 | clip 0 | loss_scale 8 | train_wall 1016 | gb_free 12.5 | wall 16382
2023-08-15 06:00:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:00:11 | INFO | fairseq.trainer | begin training epoch 13
2023-08-15 06:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:00:34 | INFO | train_inner | epoch 013:     23 / 1474 loss=2.069, trans_loss=5.005, nll_loss=2.275, w2v_ctc_loss=0.775, task_loss=1.446, contrastive_loss=0.124, total=4092.72, n_correct=2616.12, ppl=4.84, accuracy=63.921, wps=6626.7, ups=0.81, wpb=8185.4, bsz=296.2, num_updates=17700, lr=0.000106299, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=16406
2023-08-15 06:01:43 | INFO | train_inner | epoch 013:    123 / 1474 loss=2.053, trans_loss=4.978, nll_loss=2.239, w2v_ctc_loss=0.753, task_loss=1.401, contrastive_loss=0.139, total=4178.31, n_correct=2690.43, ppl=4.72, accuracy=64.39, wps=12004.5, ups=1.44, wpb=8356.6, bsz=304, num_updates=17800, lr=0.000106, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=16475
2023-08-15 06:02:53 | INFO | train_inner | epoch 013:    223 / 1474 loss=2.073, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.746, task_loss=1.315, contrastive_loss=0.353, total=4188.38, n_correct=2689.46, ppl=4.76, accuracy=64.212, wps=12007.2, ups=1.43, wpb=8376.8, bsz=326.5, num_updates=17900, lr=0.000105703, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=14.2, wall=16545
2023-08-15 06:04:03 | INFO | train_inner | epoch 013:    323 / 1474 loss=2.046, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.751, task_loss=1.464, contrastive_loss=0.118, total=4101.73, n_correct=2651.28, ppl=4.69, accuracy=64.638, wps=11824.1, ups=1.44, wpb=8203.5, bsz=293.4, num_updates=18000, lr=0.000105409, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=16615
2023-08-15 06:04:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:04:26 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.006 | trans_loss 5.215 | nll_loss 2.493 | w2v_ctc_loss 1.311 | task_loss 4.654 | contrastive_loss 0.351 | total 4003.4 | n_correct 2630.8 | ppl 5.63 | accuracy 65.714 | uer 18.86 | wer 20.976 | raw_wer 20.976 | bleu 21.42 | wps 2168.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.42
2023-08-15 06:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-15 06:04:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-15 06:04:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-15 06:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.42) (writing took 44.70576670207083 seconds)
2023-08-15 06:06:21 | INFO | train_inner | epoch 013:    423 / 1474 loss=2.051, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.752, task_loss=1.293, contrastive_loss=0.167, total=4205.54, n_correct=2712.05, ppl=4.72, accuracy=64.488, wps=6078.3, ups=0.72, wpb=8411.1, bsz=323.5, num_updates=18100, lr=0.000105118, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=16753
2023-08-15 06:07:31 | INFO | train_inner | epoch 013:    523 / 1474 loss=2.058, trans_loss=4.984, nll_loss=2.247, w2v_ctc_loss=0.754, task_loss=1.365, contrastive_loss=0.202, total=4185.31, n_correct=2690.2, ppl=4.75, accuracy=64.277, wps=11974.1, ups=1.43, wpb=8370.6, bsz=316.7, num_updates=18200, lr=0.000104828, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=16823
2023-08-15 06:08:40 | INFO | train_inner | epoch 013:    623 / 1474 loss=2.045, trans_loss=4.977, nll_loss=2.239, w2v_ctc_loss=0.752, task_loss=1.385, contrastive_loss=0.113, total=4157.86, n_correct=2686.78, ppl=4.72, accuracy=64.619, wps=12057.1, ups=1.45, wpb=8315.7, bsz=306.4, num_updates=18300, lr=0.000104542, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=16892
2023-08-15 06:09:49 | INFO | train_inner | epoch 013:    723 / 1474 loss=2.059, trans_loss=4.984, nll_loss=2.248, w2v_ctc_loss=0.765, task_loss=1.548, contrastive_loss=0.116, total=4099, n_correct=2633.57, ppl=4.75, accuracy=64.249, wps=11818.6, ups=1.44, wpb=8198, bsz=286.3, num_updates=18400, lr=0.000104257, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=16961
2023-08-15 06:10:59 | INFO | train_inner | epoch 013:    823 / 1474 loss=2.063, trans_loss=4.988, nll_loss=2.253, w2v_ctc_loss=0.764, task_loss=1.427, contrastive_loss=0.165, total=4122.84, n_correct=2643.16, ppl=4.77, accuracy=64.11, wps=11763.5, ups=1.43, wpb=8245.7, bsz=305.7, num_updates=18500, lr=0.000103975, gnorm=0.532, clip=0, loss_scale=8, train_wall=70, gb_free=16.8, wall=17031
2023-08-15 06:12:09 | INFO | train_inner | epoch 013:    923 / 1474 loss=2.051, trans_loss=4.981, nll_loss=2.245, w2v_ctc_loss=0.753, task_loss=1.435, contrastive_loss=0.124, total=4100.74, n_correct=2640.8, ppl=4.74, accuracy=64.398, wps=11825.6, ups=1.44, wpb=8201.5, bsz=296.8, num_updates=18600, lr=0.000103695, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=17101
2023-08-15 06:13:18 | INFO | train_inner | epoch 013:   1023 / 1474 loss=2.066, trans_loss=4.989, nll_loss=2.254, w2v_ctc_loss=0.765, task_loss=1.494, contrastive_loss=0.178, total=4080.72, n_correct=2616.02, ppl=4.77, accuracy=64.107, wps=11779.7, ups=1.44, wpb=8161.4, bsz=292.3, num_updates=18700, lr=0.000103418, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=17.2, wall=17170
2023-08-15 06:14:27 | INFO | train_inner | epoch 013:   1123 / 1474 loss=2.048, trans_loss=4.975, nll_loss=2.236, w2v_ctc_loss=0.748, task_loss=1.38, contrastive_loss=0.157, total=4103.17, n_correct=2647.6, ppl=4.71, accuracy=64.526, wps=11907.8, ups=1.45, wpb=8206.3, bsz=305.6, num_updates=18800, lr=0.000103142, gnorm=0.52, clip=0, loss_scale=8, train_wall=68, gb_free=17.4, wall=17239
2023-08-15 06:15:37 | INFO | train_inner | epoch 013:   1223 / 1474 loss=2.056, trans_loss=4.985, nll_loss=2.249, w2v_ctc_loss=0.764, task_loss=1.486, contrastive_loss=0.117, total=4124.88, n_correct=2653.92, ppl=4.75, accuracy=64.339, wps=11847.9, ups=1.44, wpb=8249.8, bsz=296.7, num_updates=18900, lr=0.000102869, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=17308
2023-08-15 06:16:46 | INFO | train_inner | epoch 013:   1323 / 1474 loss=2.055, trans_loss=4.975, nll_loss=2.237, w2v_ctc_loss=0.755, task_loss=1.386, contrastive_loss=0.212, total=4108.18, n_correct=2652.05, ppl=4.71, accuracy=64.555, wps=11799.3, ups=1.44, wpb=8216.4, bsz=308.4, num_updates=19000, lr=0.000102598, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=17378
2023-08-15 06:17:55 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.06, trans_loss=4.983, nll_loss=2.248, w2v_ctc_loss=0.746, task_loss=1.388, contrastive_loss=0.228, total=4171.47, n_correct=2685.09, ppl=4.75, accuracy=64.368, wps=12077.8, ups=1.45, wpb=8342.9, bsz=310.5, num_updates=19100, lr=0.000102329, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=17447
2023-08-15 06:18:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:18:54 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.994 | trans_loss 5.196 | nll_loss 2.466 | w2v_ctc_loss 1.328 | task_loss 4.635 | contrastive_loss 0.334 | total 4003.4 | n_correct 2647.8 | ppl 5.52 | accuracy 66.139 | uer 18.438 | wer 20.376 | raw_wer 20.376 | bleu 21.6 | wps 2129.8 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 21.6
2023-08-15 06:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-08-15 06:18:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 06:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 06:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 13 @ 19151 updates, score 21.6) (writing took 29.30767272040248 seconds)
2023-08-15 06:19:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-15 06:19:24 | INFO | train | epoch 013 | loss 2.055 | trans_loss 4.98 | nll_loss 2.243 | w2v_ctc_loss 0.755 | task_loss 1.405 | contrastive_loss 0.171 | total 4138.65 | n_correct 2665.2 | ppl 4.73 | accuracy 64.398 | wps 10579.3 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 19151 | lr 0.000102193 | gnorm 0.522 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 17.4 | wall 17536
2023-08-15 06:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:19:24 | INFO | fairseq.trainer | begin training epoch 14
2023-08-15 06:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:20:06 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.029, trans_loss=4.949, nll_loss=2.204, w2v_ctc_loss=0.739, task_loss=1.292, contrastive_loss=0.127, total=4182.69, n_correct=2723, ppl=4.61, accuracy=65.102, wps=6415.3, ups=0.77, wpb=8365.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=17578
2023-08-15 06:21:14 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.028, trans_loss=4.945, nll_loss=2.198, w2v_ctc_loss=0.74, task_loss=1.4, contrastive_loss=0.109, total=4086.4, n_correct=2662.63, ppl=4.59, accuracy=65.158, wps=11931.4, ups=1.46, wpb=8172.8, bsz=301.5, num_updates=19300, lr=0.000101797, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=17646
2023-08-15 06:22:24 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.043, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.74, task_loss=1.469, contrastive_loss=0.21, total=4103.37, n_correct=2661.74, ppl=4.64, accuracy=64.867, wps=11802.3, ups=1.44, wpb=8206.7, bsz=294, num_updates=19400, lr=0.000101535, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=17716
2023-08-15 06:23:33 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.031, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.732, task_loss=1.319, contrastive_loss=0.145, total=4168.35, n_correct=2710.74, ppl=4.64, accuracy=65.031, wps=12034.5, ups=1.44, wpb=8336.7, bsz=318.7, num_updates=19500, lr=0.000101274, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=17785
2023-08-15 06:24:43 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.033, trans_loss=4.961, nll_loss=2.218, w2v_ctc_loss=0.734, task_loss=1.383, contrastive_loss=0.127, total=4155.83, n_correct=2695.08, ppl=4.65, accuracy=64.851, wps=11939.2, ups=1.44, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=17855
2023-08-15 06:25:52 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.049, trans_loss=4.965, nll_loss=2.222, w2v_ctc_loss=0.762, task_loss=1.526, contrastive_loss=0.123, total=4064.87, n_correct=2629.91, ppl=4.67, accuracy=64.699, wps=11657.4, ups=1.43, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=17924
2023-08-15 06:27:02 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.045, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.742, task_loss=1.4, contrastive_loss=0.186, total=4167.34, n_correct=2696.94, ppl=4.67, accuracy=64.716, wps=11931.8, ups=1.43, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=17994
2023-08-15 06:28:11 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.036, trans_loss=4.952, nll_loss=2.208, w2v_ctc_loss=0.75, task_loss=1.377, contrastive_loss=0.119, total=4142.94, n_correct=2694.08, ppl=4.62, accuracy=65.028, wps=12050, ups=1.45, wpb=8285.9, bsz=308.6, num_updates=19900, lr=0.000100251, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=18063
2023-08-15 06:29:21 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.044, trans_loss=4.954, nll_loss=2.21, w2v_ctc_loss=0.74, task_loss=1.341, contrastive_loss=0.227, total=4173.06, n_correct=2708.65, ppl=4.63, accuracy=64.908, wps=11923.4, ups=1.43, wpb=8346.1, bsz=319.1, num_updates=20000, lr=0.0001, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=18133
2023-08-15 06:29:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:29:45 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.992 | trans_loss 5.187 | nll_loss 2.457 | w2v_ctc_loss 1.346 | task_loss 4.645 | contrastive_loss 0.327 | total 4003.4 | n_correct 2649.8 | ppl 5.49 | accuracy 66.189 | uer 18.095 | wer 19.988 | raw_wer 19.988 | bleu 21.35 | wps 2105.8 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.6
2023-08-15 06:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-15 06:29:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-15 06:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-15 06:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.35) (writing took 35.2795620765537 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 06:31:31 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.038, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.739, task_loss=1.402, contrastive_loss=0.161, total=4166.71, n_correct=2697.99, ppl=4.65, accuracy=64.751, wps=6407.9, ups=0.77, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=18263
2023-08-15 06:32:41 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.036, trans_loss=4.958, nll_loss=2.214, w2v_ctc_loss=0.74, task_loss=1.425, contrastive_loss=0.139, total=4145.57, n_correct=2694.32, ppl=4.64, accuracy=64.993, wps=11828.2, ups=1.43, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=18333
2023-08-15 06:33:51 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.067, trans_loss=4.963, nll_loss=2.222, w2v_ctc_loss=0.748, task_loss=1.326, contrastive_loss=0.412, total=4219.9, n_correct=2729.67, ppl=4.67, accuracy=64.686, wps=12102.8, ups=1.43, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=18403
2023-08-15 06:35:00 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.043, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.755, task_loss=1.629, contrastive_loss=0.1, total=4032.06, n_correct=2609.93, ppl=4.67, accuracy=64.729, wps=11642.6, ups=1.44, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=18472
2023-08-15 06:36:10 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.029, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.734, task_loss=1.332, contrastive_loss=0.117, total=4205.07, n_correct=2730.55, ppl=4.65, accuracy=64.935, wps=12089.6, ups=1.44, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18542
2023-08-15 06:37:19 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.041, trans_loss=4.965, nll_loss=2.225, w2v_ctc_loss=0.742, task_loss=1.403, contrastive_loss=0.155, total=4126.44, n_correct=2672.47, ppl=4.67, accuracy=64.765, wps=11947.6, ups=1.45, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=18611
2023-08-15 06:37:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 06:37:59 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.004 | trans_loss 5.185 | nll_loss 2.454 | w2v_ctc_loss 1.39 | task_loss 4.666 | contrastive_loss 0.337 | total 4003.4 | n_correct 2650.2 | ppl 5.48 | accuracy 66.199 | uer 18.86 | wer 20.76 | raw_wer 20.76 | bleu 21.51 | wps 2194.9 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.6
2023-08-15 06:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-15 06:37:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt
2023-08-15 06:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt
2023-08-15 06:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt (epoch 14 @ 20625 updates, score 21.51) (writing took 22.15944396518171 seconds)
2023-08-15 06:38:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-15 06:38:22 | INFO | train | epoch 014 | loss 2.04 | trans_loss 4.959 | nll_loss 2.216 | w2v_ctc_loss 0.743 | task_loss 1.405 | contrastive_loss 0.166 | total 4138.65 | n_correct 2684.66 | ppl 4.65 | accuracy 64.868 | wps 10719.4 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 16.1 | wall 18674
2023-08-15 06:38:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:38:22 | INFO | fairseq.trainer | begin training epoch 15
2023-08-15 06:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:39:21 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.035, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.734, task_loss=1.409, contrastive_loss=0.202, total=4090.99, n_correct=2662.89, ppl=4.6, accuracy=65.092, wps=6709.9, ups=0.82, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=18733
2023-08-15 06:40:30 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.02, trans_loss=4.935, nll_loss=2.184, w2v_ctc_loss=0.734, task_loss=1.452, contrastive_loss=0.11, total=4115.56, n_correct=2695.1, ppl=4.54, accuracy=65.486, wps=11864.6, ups=1.44, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=18802
2023-08-15 06:41:39 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.016, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.723, task_loss=1.366, contrastive_loss=0.104, total=4182.19, n_correct=2734.56, ppl=4.56, accuracy=65.386, wps=12119, ups=1.45, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=18871
2023-08-15 06:42:48 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.019, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.724, task_loss=1.402, contrastive_loss=0.128, total=4172.52, n_correct=2732.45, ppl=4.53, accuracy=65.487, wps=12050.8, ups=1.44, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=18940
2023-08-15 06:43:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 06:43:58 | INFO | train_inner | epoch 015:    476 / 1474 loss=2.013, trans_loss=4.932, nll_loss=2.179, w2v_ctc_loss=0.722, task_loss=1.521, contrastive_loss=0.095, total=4047.69, n_correct=2649.36, ppl=4.53, accuracy=65.454, wps=11593, ups=1.43, wpb=8095.4, bsz=284.6, num_updates=21100, lr=9.73585e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=19010
2023-08-15 06:45:07 | INFO | train_inner | epoch 015:    576 / 1474 loss=2.023, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.732, task_loss=1.44, contrastive_loss=0.131, total=4151.89, n_correct=2710.25, ppl=4.56, accuracy=65.278, wps=11998, ups=1.45, wpb=8303.8, bsz=302, num_updates=21200, lr=9.71286e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=13.2, wall=19079
2023-08-15 06:46:17 | INFO | train_inner | epoch 015:    676 / 1474 loss=2.031, trans_loss=4.935, nll_loss=2.184, w2v_ctc_loss=0.735, task_loss=1.435, contrastive_loss=0.177, total=4122.17, n_correct=2690.83, ppl=4.54, accuracy=65.277, wps=11860.9, ups=1.44, wpb=8244.3, bsz=304, num_updates=21300, lr=9.69003e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=19149
2023-08-15 06:47:26 | INFO | train_inner | epoch 015:    776 / 1474 loss=2.026, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.74, task_loss=1.404, contrastive_loss=0.115, total=4181.07, n_correct=2724.72, ppl=4.58, accuracy=65.168, wps=12039.8, ups=1.44, wpb=8362.1, bsz=307.1, num_updates=21400, lr=9.66736e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=19218
2023-08-15 06:48:35 | INFO | train_inner | epoch 015:    876 / 1474 loss=2.027, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.738, task_loss=1.521, contrastive_loss=0.106, total=4052.17, n_correct=2643.14, ppl=4.59, accuracy=65.228, wps=11785.9, ups=1.45, wpb=8104.3, bsz=286.4, num_updates=21500, lr=9.64486e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=19287
2023-08-15 06:49:44 | INFO | train_inner | epoch 015:    976 / 1474 loss=2.029, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.729, task_loss=1.4, contrastive_loss=0.195, total=4135.95, n_correct=2697.61, ppl=4.58, accuracy=65.223, wps=12023.5, ups=1.45, wpb=8271.9, bsz=304.3, num_updates=21600, lr=9.6225e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=19356
2023-08-15 06:50:55 | INFO | train_inner | epoch 015:   1076 / 1474 loss=2.046, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.728, task_loss=1.322, contrastive_loss=0.354, total=4187.18, n_correct=2722.33, ppl=4.6, accuracy=65.016, wps=11871.1, ups=1.42, wpb=8374.4, bsz=324.7, num_updates=21700, lr=9.60031e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=13.6, wall=19426
2023-08-15 06:52:04 | INFO | train_inner | epoch 015:   1176 / 1474 loss=2.015, trans_loss=4.938, nll_loss=2.19, w2v_ctc_loss=0.717, task_loss=1.266, contrastive_loss=0.156, total=4184.18, n_correct=2742.84, ppl=4.56, accuracy=65.553, wps=12134.2, ups=1.45, wpb=8368.4, bsz=328.4, num_updates=21800, lr=9.57826e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=19495
2023-08-15 06:53:13 | INFO | train_inner | epoch 015:   1276 / 1474 loss=2.026, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.744, task_loss=1.437, contrastive_loss=0.111, total=4141.39, n_correct=2704.13, ppl=4.55, accuracy=65.295, wps=11909, ups=1.44, wpb=8282.8, bsz=302.1, num_updates=21900, lr=9.55637e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=19565
2023-08-15 06:54:22 | INFO | train_inner | epoch 015:   1376 / 1474 loss=2.019, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.734, task_loss=1.451, contrastive_loss=0.099, total=4106.11, n_correct=2685.55, ppl=4.55, accuracy=65.404, wps=11837.1, ups=1.44, wpb=8212.2, bsz=294.2, num_updates=22000, lr=9.53463e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=19634
2023-08-15 06:54:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:54:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.185 | nll_loss 2.453 | w2v_ctc_loss 1.314 | task_loss 4.622 | contrastive_loss 0.322 | total 4003.4 | n_correct 2653.4 | ppl 5.47 | accuracy 66.279 | uer 18.262 | wer 20.223 | raw_wer 20.223 | bleu 21.76 | wps 2081.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.76
2023-08-15 06:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-15 06:54:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-15 06:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-15 06:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.76) (writing took 54.27956608496606 seconds)
2023-08-15 06:55:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 06:56:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:57:14 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.978 | trans_loss 5.184 | nll_loss 2.457 | w2v_ctc_loss 1.305 | task_loss 4.634 | contrastive_loss 0.333 | total 4003.4 | n_correct 2649.8 | ppl 5.49 | accuracy 66.189 | uer 18.286 | wer 20.141 | raw_wer 20.141 | bleu 21.54 | wps 2148.3 | wpb 4003.4 | bsz 141.8 | num_updates 22097 | best_bleu 21.76
2023-08-15 06:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22097 updates
2023-08-15 06:57:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt
2023-08-15 06:57:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt
2023-08-15 06:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt (epoch 15 @ 22097 updates, score 21.54) (writing took 23.58774878643453 seconds)
2023-08-15 06:57:38 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-15 06:57:39 | INFO | train | epoch 015 | loss 2.024 | trans_loss 4.939 | nll_loss 2.19 | w2v_ctc_loss 0.73 | task_loss 1.407 | contrastive_loss 0.154 | total 4136.64 | n_correct 2701.82 | ppl 4.56 | accuracy 65.314 | wps 10529.8 | ups 1.27 | wpb 8273.3 | bsz 305 | num_updates 22097 | lr 9.51368e-05 | gnorm 0.523 | clip 0 | loss_scale 8 | train_wall 1013 | gb_free 16.6 | wall 19830
2023-08-15 06:57:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:57:39 | INFO | fairseq.trainer | begin training epoch 16
2023-08-15 06:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:57:49 | INFO | train_inner | epoch 016:      3 / 1474 loss=2.03, trans_loss=4.947, nll_loss=2.201, w2v_ctc_loss=0.729, task_loss=1.348, contrastive_loss=0.189, total=4147.48, n_correct=2702.65, ppl=4.6, accuracy=65.164, wps=4021.6, ups=0.48, wpb=8295, bsz=314.7, num_updates=22100, lr=9.51303e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=19841
2023-08-15 06:58:57 | INFO | train_inner | epoch 016:    103 / 1474 loss=2.006, trans_loss=4.919, nll_loss=2.163, w2v_ctc_loss=0.716, task_loss=1.346, contrastive_loss=0.127, total=4116.45, n_correct=2704.65, ppl=4.48, accuracy=65.703, wps=11982.6, ups=1.46, wpb=8232.9, bsz=314.3, num_updates=22200, lr=9.49158e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=19909
2023-08-15 07:00:07 | INFO | train_inner | epoch 016:    203 / 1474 loss=1.999, trans_loss=4.91, nll_loss=2.153, w2v_ctc_loss=0.706, task_loss=1.443, contrastive_loss=0.102, total=4112.07, n_correct=2711.73, ppl=4.45, accuracy=65.946, wps=11801.5, ups=1.43, wpb=8224.1, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=19979
2023-08-15 07:01:17 | INFO | train_inner | epoch 016:    303 / 1474 loss=2.021, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.727, task_loss=1.399, contrastive_loss=0.178, total=4160.84, n_correct=2728.3, ppl=4.51, accuracy=65.571, wps=11852.2, ups=1.42, wpb=8321.7, bsz=308.1, num_updates=22400, lr=9.44911e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=70, gb_free=16.7, wall=20049
2023-08-15 07:02:27 | INFO | train_inner | epoch 016:    403 / 1474 loss=2.015, trans_loss=4.916, nll_loss=2.159, w2v_ctc_loss=0.721, task_loss=1.502, contrastive_loss=0.19, total=4066.97, n_correct=2673.49, ppl=4.47, accuracy=65.737, wps=11710.1, ups=1.44, wpb=8133.9, bsz=287, num_updates=22500, lr=9.42809e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=14.6, wall=20119
2023-08-15 07:03:37 | INFO | train_inner | epoch 016:    503 / 1474 loss=2.013, trans_loss=4.927, nll_loss=2.175, w2v_ctc_loss=0.717, task_loss=1.353, contrastive_loss=0.139, total=4168.86, n_correct=2733.09, ppl=4.52, accuracy=65.56, wps=11960.5, ups=1.43, wpb=8337.7, bsz=318.4, num_updates=22600, lr=9.40721e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=20188
2023-08-15 07:04:46 | INFO | train_inner | epoch 016:    603 / 1474 loss=2.008, trans_loss=4.924, nll_loss=2.17, w2v_ctc_loss=0.718, task_loss=1.394, contrastive_loss=0.099, total=4132.12, n_correct=2714.17, ppl=4.5, accuracy=65.685, wps=11950.3, ups=1.45, wpb=8264.2, bsz=300.3, num_updates=22700, lr=9.38647e-05, gnorm=0.516, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=20258
2023-08-15 07:05:54 | INFO | train_inner | epoch 016:    703 / 1474 loss=2.008, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.722, task_loss=1.43, contrastive_loss=0.1, total=4102.33, n_correct=2693.4, ppl=4.49, accuracy=65.655, wps=11926.5, ups=1.45, wpb=8204.7, bsz=298.1, num_updates=22800, lr=9.36586e-05, gnorm=0.514, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=20326
2023-08-15 07:07:04 | INFO | train_inner | epoch 016:    803 / 1474 loss=2.008, trans_loss=4.92, nll_loss=2.165, w2v_ctc_loss=0.708, task_loss=1.344, contrastive_loss=0.161, total=4176.5, n_correct=2746, ppl=4.48, accuracy=65.749, wps=12052.8, ups=1.44, wpb=8353, bsz=311.3, num_updates=22900, lr=9.34539e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=20396
2023-08-15 07:08:13 | INFO | train_inner | epoch 016:    903 / 1474 loss=2.013, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.715, task_loss=1.39, contrastive_loss=0.154, total=4150.45, n_correct=2722.92, ppl=4.5, accuracy=65.605, wps=12042, ups=1.45, wpb=8300.9, bsz=305.8, num_updates=23000, lr=9.32505e-05, gnorm=0.517, clip=0, loss_scale=8, train_wall=68, gb_free=11.3, wall=20465
2023-08-15 07:09:22 | INFO | train_inner | epoch 016:   1003 / 1474 loss=2.019, trans_loss=4.927, nll_loss=2.175, w2v_ctc_loss=0.732, task_loss=1.439, contrastive_loss=0.151, total=4118.26, n_correct=2697.93, ppl=4.52, accuracy=65.511, wps=11814.8, ups=1.43, wpb=8236.5, bsz=301.7, num_updates=23100, lr=9.30484e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=20534
2023-08-15 07:10:32 | INFO | train_inner | epoch 016:   1103 / 1474 loss=2.018, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.727, task_loss=1.486, contrastive_loss=0.127, total=4113.57, n_correct=2691.6, ppl=4.53, accuracy=65.432, wps=11784.4, ups=1.43, wpb=8227.1, bsz=296.2, num_updates=23200, lr=9.28477e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=20604
2023-08-15 07:11:43 | INFO | train_inner | epoch 016:   1203 / 1474 loss=2.025, trans_loss=4.932, nll_loss=2.181, w2v_ctc_loss=0.716, task_loss=1.433, contrastive_loss=0.225, total=4157.18, n_correct=2716.5, ppl=4.54, accuracy=65.345, wps=11752, ups=1.41, wpb=8314.4, bsz=306.3, num_updates=23300, lr=9.26482e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=20675
2023-08-15 07:12:53 | INFO | train_inner | epoch 016:   1303 / 1474 loss=2.025, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.733, task_loss=1.376, contrastive_loss=0.203, total=4150.54, n_correct=2718.29, ppl=4.52, accuracy=65.492, wps=11913.4, ups=1.44, wpb=8301.1, bsz=312.3, num_updates=23400, lr=9.245e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=12.5, wall=20745
2023-08-15 07:14:03 | INFO | train_inner | epoch 016:   1403 / 1474 loss=2.009, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.721, task_loss=1.33, contrastive_loss=0.13, total=4198.78, n_correct=2758.17, ppl=4.5, accuracy=65.69, wps=11996.1, ups=1.43, wpb=8397.6, bsz=322.4, num_updates=23500, lr=9.22531e-05, gnorm=0.515, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=20815
2023-08-15 07:14:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:15:17 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.982 | trans_loss 5.171 | nll_loss 2.436 | w2v_ctc_loss 1.354 | task_loss 4.669 | contrastive_loss 0.331 | total 4003.4 | n_correct 2659.1 | ppl 5.41 | accuracy 66.421 | uer 18.196 | wer 19.966 | raw_wer 19.966 | bleu 21.97 | wps 2057.1 | wpb 4003.4 | bsz 141.8 | num_updates 23571 | best_bleu 21.97
2023-08-15 07:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23571 updates
2023-08-15 07:15:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23571 updates, score 21.97) (writing took 31.604974687099457 seconds)
2023-08-15 07:15:49 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-15 07:15:49 | INFO | train | epoch 016 | loss 2.014 | trans_loss 4.923 | nll_loss 2.17 | w2v_ctc_loss 0.719 | task_loss 1.403 | contrastive_loss 0.158 | total 4138.65 | n_correct 2715.96 | ppl 4.5 | accuracy 65.624 | wps 11185.5 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 23571 | lr 9.21141e-05 | gnorm 0.52 | clip 0 | loss_scale 8 | train_wall 1018 | gb_free 15.1 | wall 20921
2023-08-15 07:15:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:15:50 | INFO | fairseq.trainer | begin training epoch 17
2023-08-15 07:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:16:18 | INFO | train_inner | epoch 017:     29 / 1474 loss=2.015, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.709, task_loss=1.448, contrastive_loss=0.269, total=4138.06, n_correct=2724.76, ppl=4.45, accuracy=65.846, wps=6124.5, ups=0.74, wpb=8276.1, bsz=300.4, num_updates=23600, lr=9.20575e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=70, gb_free=17.4, wall=20950
2023-08-15 07:17:27 | INFO | train_inner | epoch 017:    129 / 1474 loss=1.995, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.712, task_loss=1.443, contrastive_loss=0.1, total=4110.37, n_correct=2718.15, ppl=4.39, accuracy=66.129, wps=11858.8, ups=1.44, wpb=8220.7, bsz=295.6, num_updates=23700, lr=9.1863e-05, gnorm=0.516, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=21019
2023-08-15 07:18:36 | INFO | train_inner | epoch 017:    229 / 1474 loss=2.008, trans_loss=4.899, nll_loss=2.138, w2v_ctc_loss=0.698, task_loss=1.31, contrastive_loss=0.266, total=4181.59, n_correct=2763.02, ppl=4.4, accuracy=66.076, wps=12093.2, ups=1.45, wpb=8363.2, bsz=322.2, num_updates=23800, lr=9.16698e-05, gnorm=0.51, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=21088
2023-08-15 07:19:46 | INFO | train_inner | epoch 017:    329 / 1474 loss=2.013, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.707, task_loss=1.411, contrastive_loss=0.271, total=4157.97, n_correct=2740.1, ppl=4.44, accuracy=65.9, wps=11918.8, ups=1.43, wpb=8315.9, bsz=304, num_updates=23900, lr=9.14779e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=21158
2023-08-15 07:20:56 | INFO | train_inner | epoch 017:    429 / 1474 loss=1.99, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.702, task_loss=1.403, contrastive_loss=0.099, total=4135.12, n_correct=2738.51, ppl=4.41, accuracy=66.226, wps=11881.7, ups=1.44, wpb=8270.2, bsz=306.1, num_updates=24000, lr=9.12871e-05, gnorm=0.511, clip=0, loss_scale=8, train_wall=69, gb_free=12.4, wall=21228
2023-08-15 07:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:21:20 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.981 | trans_loss 5.178 | nll_loss 2.445 | w2v_ctc_loss 1.339 | task_loss 4.618 | contrastive_loss 0.321 | total 4003.4 | n_correct 2654.8 | ppl 5.44 | accuracy 66.314 | uer 18.318 | wer 20.253 | raw_wer 20.253 | bleu 21.55 | wps 2117.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.97
2023-08-15 07:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-15 07:21:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-15 07:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-15 07:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.55) (writing took 43.65551965683699 seconds)
2023-08-15 07:23:15 | INFO | train_inner | epoch 017:    529 / 1474 loss=2.005, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.715, task_loss=1.454, contrastive_loss=0.145, total=4185.81, n_correct=2757.39, ppl=4.45, accuracy=65.875, wps=6028.6, ups=0.72, wpb=8371.6, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=15.8, wall=21367
2023-08-15 07:24:24 | INFO | train_inner | epoch 017:    629 / 1474 loss=1.996, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.706, task_loss=1.407, contrastive_loss=0.097, total=4168.62, n_correct=2754.42, ppl=4.44, accuracy=66.075, wps=12078.9, ups=1.45, wpb=8337.2, bsz=303.2, num_updates=24200, lr=9.09091e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=69, gb_free=13.9, wall=21436
2023-08-15 07:25:33 | INFO | train_inner | epoch 017:    729 / 1474 loss=2.011, trans_loss=4.912, nll_loss=2.154, w2v_ctc_loss=0.726, task_loss=1.397, contrastive_loss=0.145, total=4167.34, n_correct=2743.27, ppl=4.45, accuracy=65.828, wps=11999.8, ups=1.44, wpb=8334.7, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=9.6, wall=21505
2023-08-15 07:26:42 | INFO | train_inner | epoch 017:    829 / 1474 loss=2, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.716, task_loss=1.42, contrastive_loss=0.108, total=4092.64, n_correct=2699.83, ppl=4.44, accuracy=65.968, wps=11862.2, ups=1.45, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=21574
2023-08-15 07:27:50 | INFO | train_inner | epoch 017:    929 / 1474 loss=1.993, trans_loss=4.904, nll_loss=2.146, w2v_ctc_loss=0.707, task_loss=1.377, contrastive_loss=0.103, total=4109.5, n_correct=2714.4, ppl=4.42, accuracy=66.052, wps=12024.1, ups=1.46, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=21642
2023-08-15 07:29:00 | INFO | train_inner | epoch 017:   1029 / 1474 loss=2, trans_loss=4.908, nll_loss=2.151, w2v_ctc_loss=0.716, task_loss=1.416, contrastive_loss=0.108, total=4098.36, n_correct=2703.56, ppl=4.44, accuracy=65.967, wps=11814.3, ups=1.44, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=21712
2023-08-15 07:30:09 | INFO | train_inner | epoch 017:   1129 / 1474 loss=1.994, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.702, task_loss=1.426, contrastive_loss=0.102, total=4100.14, n_correct=2706.73, ppl=4.43, accuracy=66.016, wps=11878.4, ups=1.45, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=21781
2023-08-15 07:31:19 | INFO | train_inner | epoch 017:   1229 / 1474 loss=2.03, trans_loss=4.917, nll_loss=2.163, w2v_ctc_loss=0.704, task_loss=1.351, contrastive_loss=0.405, total=4173.98, n_correct=2741.94, ppl=4.48, accuracy=65.691, wps=11860.8, ups=1.42, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=15.7, wall=21851
2023-08-15 07:32:28 | INFO | train_inner | epoch 017:   1329 / 1474 loss=1.995, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.702, task_loss=1.414, contrastive_loss=0.111, total=4146.07, n_correct=2739.27, ppl=4.44, accuracy=66.069, wps=11980.1, ups=1.44, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=21920
2023-08-15 07:33:38 | INFO | train_inner | epoch 017:   1429 / 1474 loss=1.996, trans_loss=4.909, nll_loss=2.151, w2v_ctc_loss=0.708, task_loss=1.423, contrastive_loss=0.101, total=4119.23, n_correct=2721.41, ppl=4.44, accuracy=66.066, wps=11851.7, ups=1.44, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=12.8, wall=21990
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 07:34:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
2023-08-15 07:34:33 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.98 | trans_loss 5.167 | nll_loss 2.431 | w2v_ctc_loss 1.359 | task_loss 4.664 | contrastive_loss 0.33 | total 4003.4 | n_correct 2657.2 | ppl 5.39 | accuracy 66.374 | uer 17.689 | wer 19.608 | raw_wer 19.608 | bleu 22.01 | wps 2122.7 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 22.01
2023-08-15 07:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-08-15 07:34:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 17 @ 25045 updates, score 22.01) (writing took 29.43081351555884 seconds)
2023-08-15 07:35:03 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-15 07:35:03 | INFO | train | epoch 017 | loss 2.002 | trans_loss 4.906 | nll_loss 2.148 | w2v_ctc_loss 0.709 | task_loss 1.405 | contrastive_loss 0.154 | total 4138.65 | n_correct 2731.29 | ppl 4.43 | accuracy 65.995 | wps 10572.9 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.518 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 16.1 | wall 22075
2023-08-15 07:35:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:35:04 | INFO | fairseq.trainer | begin training epoch 18
2023-08-15 07:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:35:50 | INFO | train_inner | epoch 018:     55 / 1474 loss=1.999, trans_loss=4.902, nll_loss=2.143, w2v_ctc_loss=0.718, task_loss=1.435, contrastive_loss=0.11, total=4128.93, n_correct=2728.33, ppl=4.42, accuracy=66.078, wps=6242.4, ups=0.76, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=22122
2023-08-15 07:36:59 | INFO | train_inner | epoch 018:    155 / 1474 loss=1.991, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.688, task_loss=1.333, contrastive_loss=0.23, total=4158.38, n_correct=2766.57, ppl=4.33, accuracy=66.53, wps=12037.1, ups=1.45, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=22191
2023-08-15 07:38:08 | INFO | train_inner | epoch 018:    255 / 1474 loss=1.983, trans_loss=4.885, nll_loss=2.12, w2v_ctc_loss=0.701, task_loss=1.361, contrastive_loss=0.1, total=4161.92, n_correct=2765.28, ppl=4.35, accuracy=66.442, wps=12043.7, ups=1.45, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=22260
2023-08-15 07:39:18 | INFO | train_inner | epoch 018:    355 / 1474 loss=1.987, trans_loss=4.891, nll_loss=2.127, w2v_ctc_loss=0.695, task_loss=1.431, contrastive_loss=0.115, total=4167.42, n_correct=2763.46, ppl=4.37, accuracy=66.311, wps=12038.1, ups=1.44, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=22330
2023-08-15 07:40:27 | INFO | train_inner | epoch 018:    455 / 1474 loss=1.999, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.7, task_loss=1.509, contrastive_loss=0.205, total=4075.78, n_correct=2699.25, ppl=4.38, accuracy=66.227, wps=11683.4, ups=1.43, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=22399
2023-08-15 07:41:37 | INFO | train_inner | epoch 018:    555 / 1474 loss=1.975, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.686, task_loss=1.255, contrastive_loss=0.112, total=4218.07, n_correct=2812.41, ppl=4.33, accuracy=66.675, wps=12145.9, ups=1.44, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=22469
2023-08-15 07:42:46 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.001, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.707, task_loss=1.452, contrastive_loss=0.184, total=4093.44, n_correct=2706.93, ppl=4.41, accuracy=66.128, wps=11877.9, ups=1.45, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=22538
2023-08-15 07:43:56 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.006, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.706, task_loss=1.338, contrastive_loss=0.275, total=4202.99, n_correct=2784.86, ppl=4.39, accuracy=66.259, wps=12042.4, ups=1.43, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=22608
2023-08-15 07:45:05 | INFO | train_inner | epoch 018:    855 / 1474 loss=1.988, trans_loss=4.894, nll_loss=2.131, w2v_ctc_loss=0.7, task_loss=1.412, contrastive_loss=0.1, total=4177.43, n_correct=2767.46, ppl=4.38, accuracy=66.248, wps=12032.9, ups=1.44, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=22677
2023-08-15 07:46:14 | INFO | train_inner | epoch 018:    955 / 1474 loss=1.982, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.695, task_loss=1.309, contrastive_loss=0.105, total=4138.23, n_correct=2746.95, ppl=4.36, accuracy=66.38, wps=12075, ups=1.46, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=22746
2023-08-15 07:46:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:46:37 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.173 | nll_loss 2.436 | w2v_ctc_loss 1.319 | task_loss 4.666 | contrastive_loss 0.321 | total 4003.4 | n_correct 2666.7 | ppl 5.41 | accuracy 66.611 | uer 18.207 | wer 20.119 | raw_wer 20.119 | bleu 21.82 | wps 2098.1 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.01
2023-08-15 07:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-15 07:46:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-15 07:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-15 07:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.82) (writing took 34.82252572849393 seconds)
2023-08-15 07:48:22 | INFO | train_inner | epoch 018:   1055 / 1474 loss=1.989, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.701, task_loss=1.479, contrastive_loss=0.1, total=4133.59, n_correct=2740.29, ppl=4.38, accuracy=66.293, wps=6426, ups=0.78, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=22874
2023-08-15 07:49:32 | INFO | train_inner | epoch 018:   1155 / 1474 loss=1.996, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.703, task_loss=1.326, contrastive_loss=0.207, total=4154.22, n_correct=2756.25, ppl=4.36, accuracy=66.348, wps=12011, ups=1.45, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=22943
2023-08-15 07:50:40 | INFO | train_inner | epoch 018:   1255 / 1474 loss=1.99, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.701, task_loss=1.504, contrastive_loss=0.094, total=4089.17, n_correct=2703.42, ppl=4.41, accuracy=66.112, wps=11876.5, ups=1.45, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=23012
2023-08-15 07:51:50 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.001, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.719, task_loss=1.503, contrastive_loss=0.123, total=4068.84, n_correct=2686.48, ppl=4.41, accuracy=66.026, wps=11754.3, ups=1.44, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=23082
2023-08-15 07:52:58 | INFO | train_inner | epoch 018:   1455 / 1474 loss=1.994, trans_loss=4.899, nll_loss=2.138, w2v_ctc_loss=0.71, task_loss=1.494, contrastive_loss=0.106, total=4113.23, n_correct=2723.38, ppl=4.4, accuracy=66.21, wps=11953.7, ups=1.45, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=23150
2023-08-15 07:53:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:53:35 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.978 | trans_loss 5.17 | nll_loss 2.434 | w2v_ctc_loss 1.359 | task_loss 4.661 | contrastive_loss 0.312 | total 4003.4 | n_correct 2666.1 | ppl 5.4 | accuracy 66.596 | uer 17.663 | wer 19.619 | raw_wer 19.619 | bleu 22.02 | wps 2119.5 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.02
2023-08-15 07:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-15 07:53:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26519 updates, score 22.02) (writing took 32.82808456942439 seconds)
2023-08-15 07:54:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-15 07:54:09 | INFO | train | epoch 018 | loss 1.992 | trans_loss 4.892 | nll_loss 2.13 | w2v_ctc_loss 0.701 | task_loss 1.405 | contrastive_loss 0.15 | total 4138.65 | n_correct 2743.74 | ppl 4.38 | accuracy 66.296 | wps 10653 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 15.7 | wall 23221
2023-08-15 07:54:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:54:09 | INFO | fairseq.trainer | begin training epoch 19
2023-08-15 07:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:55:12 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.983, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.693, task_loss=1.401, contrastive_loss=0.155, total=4107.26, n_correct=2736.88, ppl=4.31, accuracy=66.635, wps=6158.5, ups=0.75, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=12.4, wall=23284
2023-08-15 07:56:22 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.982, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.698, task_loss=1.313, contrastive_loss=0.147, total=4222.18, n_correct=2815.49, ppl=4.31, accuracy=66.683, wps=12077.8, ups=1.43, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=11.3, wall=23354
2023-08-15 07:57:31 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.973, trans_loss=4.87, nll_loss=2.1, w2v_ctc_loss=0.694, task_loss=1.377, contrastive_loss=0.09, total=4187.37, n_correct=2796.21, ppl=4.29, accuracy=66.777, wps=12016.9, ups=1.43, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=23423
2023-08-15 07:58:40 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.984, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.685, task_loss=1.386, contrastive_loss=0.197, total=4170.67, n_correct=2777.08, ppl=4.3, accuracy=66.586, wps=12096.3, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=23492
2023-08-15 07:59:49 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.983, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.702, task_loss=1.438, contrastive_loss=0.106, total=4115.22, n_correct=2735.2, ppl=4.33, accuracy=66.465, wps=11921.1, ups=1.45, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=23561
2023-08-15 08:00:58 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.976, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.682, task_loss=1.378, contrastive_loss=0.17, total=4129.22, n_correct=2756.19, ppl=4.29, accuracy=66.748, wps=11995.2, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=23630
2023-08-15 08:02:07 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.969, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.676, task_loss=1.279, contrastive_loss=0.096, total=4197.2, n_correct=2797.38, ppl=4.33, accuracy=66.649, wps=12146.4, ups=1.45, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=69, gb_free=14.3, wall=23699
2023-08-15 08:03:17 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.979, trans_loss=4.876, nll_loss=2.108, w2v_ctc_loss=0.698, task_loss=1.413, contrastive_loss=0.11, total=4142.6, n_correct=2759.92, ppl=4.31, accuracy=66.623, wps=11896.1, ups=1.44, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=23769
2023-08-15 08:04:26 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.98, trans_loss=4.883, nll_loss=2.117, w2v_ctc_loss=0.697, task_loss=1.434, contrastive_loss=0.093, total=4153.47, n_correct=2763.16, ppl=4.34, accuracy=66.527, wps=12012.3, ups=1.45, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=23838
2023-08-15 08:05:36 | INFO | train_inner | epoch 019:    981 / 1474 loss=2, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.688, task_loss=1.402, contrastive_loss=0.328, total=4101.29, n_correct=2723.29, ppl=4.36, accuracy=66.401, wps=11677.4, ups=1.42, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=23908
2023-08-15 08:05:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 08:06:46 | INFO | train_inner | epoch 019:   1082 / 1474 loss=1.985, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.691, task_loss=1.497, contrastive_loss=0.136, total=4039.69, n_correct=2683.71, ppl=4.36, accuracy=66.434, wps=11543.9, ups=1.43, wpb=8079.4, bsz=291.5, num_updates=27600, lr=8.51257e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=23978
2023-08-15 08:07:56 | INFO | train_inner | epoch 019:   1182 / 1474 loss=1.997, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.699, task_loss=1.44, contrastive_loss=0.22, total=4129.82, n_correct=2738.04, ppl=4.36, accuracy=66.299, wps=11884, ups=1.44, wpb=8259.6, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=24048
2023-08-15 08:09:05 | INFO | train_inner | epoch 019:   1282 / 1474 loss=1.982, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.69, task_loss=1.41, contrastive_loss=0.118, total=4147.96, n_correct=2757.48, ppl=4.35, accuracy=66.478, wps=11987.7, ups=1.45, wpb=8295.9, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=24117
2023-08-15 08:10:14 | INFO | train_inner | epoch 019:   1382 / 1474 loss=1.98, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.697, task_loss=1.435, contrastive_loss=0.102, total=4125.32, n_correct=2746.97, ppl=4.33, accuracy=66.588, wps=11960.4, ups=1.45, wpb=8250.6, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24186
2023-08-15 08:11:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:11:42 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.162 | nll_loss 2.424 | w2v_ctc_loss 1.392 | task_loss 4.614 | contrastive_loss 0.312 | total 4003.4 | n_correct 2666.7 | ppl 5.37 | accuracy 66.611 | uer 18.111 | wer 20.104 | raw_wer 20.104 | bleu 21.99 | wps 1954.3 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 22.02
2023-08-15 08:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-08-15 08:11:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt
2023-08-15 08:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt
2023-08-15 08:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt (epoch 19 @ 27992 updates, score 21.99) (writing took 20.373123195022345 seconds)
2023-08-15 08:12:03 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-15 08:12:03 | INFO | train | epoch 019 | loss 1.982 | trans_loss 4.878 | nll_loss 2.112 | w2v_ctc_loss 0.692 | task_loss 1.403 | contrastive_loss 0.148 | total 4138.65 | n_correct 2755.34 | ppl 4.32 | accuracy 66.576 | wps 11347.7 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.52 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 17.1 | wall 24295
2023-08-15 08:12:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:12:03 | INFO | fairseq.trainer | begin training epoch 20
2023-08-15 08:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:12:16 | INFO | train_inner | epoch 020:      8 / 1474 loss=1.98, trans_loss=4.872, nll_loss=2.105, w2v_ctc_loss=0.685, task_loss=1.41, contrastive_loss=0.188, total=4124.63, n_correct=2749.95, ppl=4.3, accuracy=66.671, wps=6757.9, ups=0.82, wpb=8249.3, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=24308
2023-08-15 08:12:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:12:40 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.165 | nll_loss 2.427 | w2v_ctc_loss 1.327 | task_loss 4.626 | contrastive_loss 0.313 | total 4003.4 | n_correct 2669.2 | ppl 5.38 | accuracy 66.673 | uer 18.045 | wer 20.178 | raw_wer 20.178 | bleu 21.98 | wps 2170.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.02
2023-08-15 08:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-15 08:12:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-15 08:12:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-15 08:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.98) (writing took 40.79153152927756 seconds)
2023-08-15 08:14:31 | INFO | train_inner | epoch 020:    108 / 1474 loss=1.96, trans_loss=4.856, nll_loss=2.082, w2v_ctc_loss=0.669, task_loss=1.354, contrastive_loss=0.109, total=4199.19, n_correct=2816.17, ppl=4.23, accuracy=67.065, wps=6246.9, ups=0.74, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=24443
2023-08-15 08:15:41 | INFO | train_inner | epoch 020:    208 / 1474 loss=1.97, trans_loss=4.861, nll_loss=2.089, w2v_ctc_loss=0.68, task_loss=1.459, contrastive_loss=0.161, total=4148.29, n_correct=2776.88, ppl=4.25, accuracy=66.94, wps=11857.3, ups=1.43, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=15.3, wall=24513
2023-08-15 08:16:49 | INFO | train_inner | epoch 020:    308 / 1474 loss=1.956, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.674, task_loss=1.266, contrastive_loss=0.098, total=4191.34, n_correct=2816.57, ppl=4.23, accuracy=67.2, wps=12190.5, ups=1.45, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=24581
2023-08-15 08:17:59 | INFO | train_inner | epoch 020:    408 / 1474 loss=1.96, trans_loss=4.852, nll_loss=2.077, w2v_ctc_loss=0.675, task_loss=1.421, contrastive_loss=0.098, total=4114.19, n_correct=2763.94, ppl=4.22, accuracy=67.181, wps=11837.2, ups=1.44, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=24651
2023-08-15 08:19:08 | INFO | train_inner | epoch 020:    508 / 1474 loss=1.974, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.673, task_loss=1.445, contrastive_loss=0.184, total=4108.2, n_correct=2745.06, ppl=4.28, accuracy=66.819, wps=11833.5, ups=1.44, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=24720
2023-08-15 08:20:17 | INFO | train_inner | epoch 020:    608 / 1474 loss=1.98, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.685, task_loss=1.475, contrastive_loss=0.19, total=4092.44, n_correct=2735.68, ppl=4.27, accuracy=66.847, wps=11871.8, ups=1.45, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=24789
2023-08-15 08:21:26 | INFO | train_inner | epoch 020:    708 / 1474 loss=1.971, trans_loss=4.868, nll_loss=2.098, w2v_ctc_loss=0.691, task_loss=1.406, contrastive_loss=0.092, total=4137.06, n_correct=2762.15, ppl=4.28, accuracy=66.766, wps=12098.9, ups=1.46, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24858
2023-08-15 08:22:35 | INFO | train_inner | epoch 020:    808 / 1474 loss=1.969, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.688, task_loss=1.388, contrastive_loss=0.093, total=4146.78, n_correct=2772.3, ppl=4.28, accuracy=66.854, wps=11984.2, ups=1.45, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=24927
2023-08-15 08:23:46 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.002, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.682, task_loss=1.336, contrastive_loss=0.396, total=4161, n_correct=2770.74, ppl=4.31, accuracy=66.588, wps=11749.2, ups=1.41, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=24998
2023-08-15 08:24:55 | INFO | train_inner | epoch 020:   1008 / 1474 loss=1.966, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.675, task_loss=1.399, contrastive_loss=0.1, total=4168.14, n_correct=2787.23, ppl=4.29, accuracy=66.87, wps=12001.1, ups=1.44, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=25067
2023-08-15 08:26:04 | INFO | train_inner | epoch 020:   1108 / 1474 loss=1.989, trans_loss=4.873, nll_loss=2.105, w2v_ctc_loss=0.687, task_loss=1.351, contrastive_loss=0.242, total=4166.49, n_correct=2776.56, ppl=4.3, accuracy=66.64, wps=12031.4, ups=1.44, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=25136
2023-08-15 08:27:14 | INFO | train_inner | epoch 020:   1208 / 1474 loss=1.977, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.702, task_loss=1.55, contrastive_loss=0.087, total=4029.18, n_correct=2686.62, ppl=4.27, accuracy=66.679, wps=11674.9, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=11.4, wall=25205
2023-08-15 08:28:23 | INFO | train_inner | epoch 020:   1308 / 1474 loss=1.973, trans_loss=4.873, nll_loss=2.106, w2v_ctc_loss=0.687, task_loss=1.477, contrastive_loss=0.093, total=4123.21, n_correct=2750.1, ppl=4.3, accuracy=66.698, wps=11858.5, ups=1.44, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=25275
2023-08-15 08:29:32 | INFO | train_inner | epoch 020:   1408 / 1474 loss=1.974, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.69, task_loss=1.478, contrastive_loss=0.092, total=4116.28, n_correct=2745.71, ppl=4.3, accuracy=66.704, wps=11873, ups=1.44, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=25344
2023-08-15 08:30:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:30:41 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.163 | nll_loss 2.421 | w2v_ctc_loss 1.318 | task_loss 4.628 | contrastive_loss 0.308 | total 4003.4 | n_correct 2670 | ppl 5.35 | accuracy 66.693 | uer 17.681 | wer 19.582 | raw_wer 19.582 | bleu 22.27 | wps 2131.5 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 22.27
2023-08-15 08:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-15 08:30:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 29466 updates, score 22.27) (writing took 31.56113838031888 seconds)
2023-08-15 08:31:14 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-15 08:31:14 | INFO | train | epoch 020 | loss 1.973 | trans_loss 4.866 | nll_loss 2.095 | w2v_ctc_loss 0.682 | task_loss 1.404 | contrastive_loss 0.146 | total 4138.65 | n_correct 2766.73 | ppl 4.27 | accuracy 66.851 | wps 10604.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.517 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 15.9 | wall 25446
2023-08-15 08:31:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:31:14 | INFO | fairseq.trainer | begin training epoch 21
2023-08-15 08:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:31:46 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.975, trans_loss=4.865, nll_loss=2.095, w2v_ctc_loss=0.673, task_loss=1.337, contrastive_loss=0.213, total=4152.26, n_correct=2778.38, ppl=4.27, accuracy=66.912, wps=6236.5, ups=0.75, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=25478
2023-08-15 08:32:55 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.967, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.674, task_loss=1.311, contrastive_loss=0.201, total=4195.08, n_correct=2819.67, ppl=4.2, accuracy=67.214, wps=12103.2, ups=1.44, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=25547
2023-08-15 08:33:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 08:34:04 | INFO | train_inner | epoch 021:    235 / 1474 loss=1.956, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.661, task_loss=1.346, contrastive_loss=0.157, total=4154.29, n_correct=2792.57, ppl=4.21, accuracy=67.221, wps=11949.2, ups=1.44, wpb=8308.6, bsz=312.2, num_updates=29700, lr=8.2061e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=25616
2023-08-15 08:35:14 | INFO | train_inner | epoch 021:    335 / 1474 loss=1.969, trans_loss=4.855, nll_loss=2.081, w2v_ctc_loss=0.683, task_loss=1.395, contrastive_loss=0.162, total=4157.2, n_correct=2784.25, ppl=4.23, accuracy=66.974, wps=11912.7, ups=1.43, wpb=8314.4, bsz=311.1, num_updates=29800, lr=8.19232e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=25686
2023-08-15 08:36:23 | INFO | train_inner | epoch 021:    435 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.672, task_loss=1.347, contrastive_loss=0.085, total=4181.07, n_correct=2814.25, ppl=4.21, accuracy=67.309, wps=12107.4, ups=1.45, wpb=8362.1, bsz=308.2, num_updates=29900, lr=8.17861e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=25755
2023-08-15 08:37:32 | INFO | train_inner | epoch 021:    535 / 1474 loss=1.956, trans_loss=4.843, nll_loss=2.065, w2v_ctc_loss=0.679, task_loss=1.456, contrastive_loss=0.084, total=4089.72, n_correct=2754.81, ppl=4.19, accuracy=67.359, wps=11831.4, ups=1.45, wpb=8179.4, bsz=295.7, num_updates=30000, lr=8.16497e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=25824
2023-08-15 08:37:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:37:55 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.969 | trans_loss 5.175 | nll_loss 2.437 | w2v_ctc_loss 1.325 | task_loss 4.634 | contrastive_loss 0.308 | total 4003.4 | n_correct 2671.7 | ppl 5.42 | accuracy 66.736 | uer 17.7 | wer 19.507 | raw_wer 19.507 | bleu 22.07 | wps 2257.4 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.27
2023-08-15 08:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-15 08:37:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-15 08:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-15 08:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.07) (writing took 25.492328878492117 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 08:39:32 | INFO | train_inner | epoch 021:    635 / 1474 loss=1.97, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.668, task_loss=1.388, contrastive_loss=0.255, total=4210.28, n_correct=2828.92, ppl=4.21, accuracy=67.191, wps=7060.7, ups=0.84, wpb=8420.6, bsz=315.7, num_updates=30100, lr=8.15139e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=25944
2023-08-15 08:40:41 | INFO | train_inner | epoch 021:    735 / 1474 loss=1.963, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.674, task_loss=1.404, contrastive_loss=0.116, total=4149.01, n_correct=2783.68, ppl=4.24, accuracy=67.093, wps=11998.2, ups=1.45, wpb=8298, bsz=307.4, num_updates=30200, lr=8.13788e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=26013
2023-08-15 08:41:50 | INFO | train_inner | epoch 021:    835 / 1474 loss=1.972, trans_loss=4.866, nll_loss=2.095, w2v_ctc_loss=0.681, task_loss=1.477, contrastive_loss=0.131, total=4075.99, n_correct=2724.19, ppl=4.27, accuracy=66.835, wps=11734.8, ups=1.44, wpb=8152, bsz=295.7, num_updates=30300, lr=8.12444e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=26082
2023-08-15 08:42:59 | INFO | train_inner | epoch 021:    935 / 1474 loss=1.962, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.679, task_loss=1.412, contrastive_loss=0.103, total=4091.88, n_correct=2743.39, ppl=4.23, accuracy=67.045, wps=11942.1, ups=1.46, wpb=8183.8, bsz=300, num_updates=30400, lr=8.11107e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=26151
2023-08-15 08:44:08 | INFO | train_inner | epoch 021:   1035 / 1474 loss=1.964, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.68, task_loss=1.427, contrastive_loss=0.1, total=4107.66, n_correct=2753.27, ppl=4.25, accuracy=67.028, wps=11919.6, ups=1.45, wpb=8215.3, bsz=299.5, num_updates=30500, lr=8.09776e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=14.3, wall=26220
2023-08-15 08:45:17 | INFO | train_inner | epoch 021:   1135 / 1474 loss=1.964, trans_loss=4.853, nll_loss=2.078, w2v_ctc_loss=0.683, task_loss=1.501, contrastive_loss=0.104, total=4118.94, n_correct=2765.82, ppl=4.22, accuracy=67.149, wps=11931.5, ups=1.45, wpb=8237.9, bsz=294.9, num_updates=30600, lr=8.08452e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=26289
2023-08-15 08:46:26 | INFO | train_inner | epoch 021:   1235 / 1474 loss=1.967, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.675, task_loss=1.347, contrastive_loss=0.155, total=4151.84, n_correct=2784.33, ppl=4.24, accuracy=67.063, wps=12021.1, ups=1.45, wpb=8303.7, bsz=309.1, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=26358
2023-08-15 08:47:35 | INFO | train_inner | epoch 021:   1335 / 1474 loss=1.96, trans_loss=4.853, nll_loss=2.081, w2v_ctc_loss=0.672, task_loss=1.362, contrastive_loss=0.117, total=4145.91, n_correct=2789.8, ppl=4.23, accuracy=67.29, wps=11923.4, ups=1.44, wpb=8291.8, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=26427
2023-08-15 08:48:45 | INFO | train_inner | epoch 021:   1435 / 1474 loss=1.982, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.698, task_loss=1.471, contrastive_loss=0.165, total=4136.27, n_correct=2764.38, ppl=4.27, accuracy=66.833, wps=11819.1, ups=1.43, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=26497
2023-08-15 08:49:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
2023-08-15 08:49:35 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.162 | nll_loss 2.422 | w2v_ctc_loss 1.319 | task_loss 4.651 | contrastive_loss 0.308 | total 4003.4 | n_correct 2677.5 | ppl 5.36 | accuracy 66.881 | uer 17.822 | wer 19.634 | raw_wer 19.634 | bleu 22.33 | wps 2288 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 22.33
2023-08-15 08:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-15 08:49:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 21 @ 30939 updates, score 22.33) (writing took 30.37798308953643 seconds)
2023-08-15 08:50:06 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-15 08:50:06 | INFO | train | epoch 021 | loss 1.965 | trans_loss 4.854 | nll_loss 2.08 | w2v_ctc_loss 0.677 | task_loss 1.404 | contrastive_loss 0.143 | total 4138.9 | n_correct 2777.71 | ppl 4.23 | accuracy 67.112 | wps 10765.7 | ups 1.3 | wpb 8277.8 | bsz 305.7 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.524 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 15.1 | wall 26578
2023-08-15 08:50:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:50:06 | INFO | fairseq.trainer | begin training epoch 22
2023-08-15 08:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:50:56 | INFO | train_inner | epoch 022:     61 / 1474 loss=1.956, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.679, task_loss=1.414, contrastive_loss=0.086, total=4133.81, n_correct=2786.51, ppl=4.19, accuracy=67.408, wps=6321.4, ups=0.76, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=26628
2023-08-15 08:52:06 | INFO | train_inner | epoch 022:    161 / 1474 loss=1.961, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.673, task_loss=1.431, contrastive_loss=0.165, total=4116.11, n_correct=2770.56, ppl=4.17, accuracy=67.31, wps=11760.2, ups=1.43, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=26698
2023-08-15 08:53:15 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.941, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.655, task_loss=1.227, contrastive_loss=0.107, total=4272.11, n_correct=2892.95, ppl=4.14, accuracy=67.717, wps=12398, ups=1.45, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=26767
2023-08-15 08:54:26 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.978, trans_loss=4.849, nll_loss=2.074, w2v_ctc_loss=0.676, task_loss=1.427, contrastive_loss=0.264, total=4178.4, n_correct=2804.44, ppl=4.21, accuracy=67.118, wps=11852.2, ups=1.42, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=26838
2023-08-15 08:55:35 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.963, trans_loss=4.844, nll_loss=2.067, w2v_ctc_loss=0.673, task_loss=1.476, contrastive_loss=0.148, total=4132.96, n_correct=2779.08, ppl=4.19, accuracy=67.242, wps=11953.1, ups=1.45, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=26907
2023-08-15 08:55:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 08:56:46 | INFO | train_inner | epoch 022:    562 / 1474 loss=1.951, trans_loss=4.839, nll_loss=2.06, w2v_ctc_loss=0.668, task_loss=1.414, contrastive_loss=0.094, total=4150.92, n_correct=2799.25, ppl=4.17, accuracy=67.437, wps=11710.1, ups=1.41, wpb=8301.8, bsz=306.9, num_updates=31500, lr=7.96819e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=26978
2023-08-15 08:57:55 | INFO | train_inner | epoch 022:    662 / 1474 loss=1.95, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.655, task_loss=1.334, contrastive_loss=0.181, total=4146.54, n_correct=2801.49, ppl=4.15, accuracy=67.562, wps=12046.7, ups=1.45, wpb=8293.1, bsz=311.9, num_updates=31600, lr=7.95557e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=12.9, wall=27047
2023-08-15 08:59:05 | INFO | train_inner | epoch 022:    762 / 1474 loss=1.952, trans_loss=4.838, nll_loss=2.059, w2v_ctc_loss=0.67, task_loss=1.443, contrastive_loss=0.095, total=4170.82, n_correct=2810.6, ppl=4.17, accuracy=67.387, wps=11934, ups=1.43, wpb=8341.6, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=11.5, wall=27116
2023-08-15 09:00:14 | INFO | train_inner | epoch 022:    862 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.672, task_loss=1.508, contrastive_loss=0.083, total=4077.65, n_correct=2739.29, ppl=4.2, accuracy=67.178, wps=11784.2, ups=1.44, wpb=8155.3, bsz=290.5, num_updates=31800, lr=7.93052e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=27186
2023-08-15 09:01:24 | INFO | train_inner | epoch 022:    962 / 1474 loss=1.95, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.664, task_loss=1.412, contrastive_loss=0.094, total=4136.66, n_correct=2787.54, ppl=4.17, accuracy=67.386, wps=11827.6, ups=1.43, wpb=8273.3, bsz=304.7, num_updates=31900, lr=7.91808e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=14.4, wall=27256
2023-08-15 09:02:32 | INFO | train_inner | epoch 022:   1062 / 1474 loss=1.955, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.653, task_loss=1.347, contrastive_loss=0.246, total=4152.13, n_correct=2804.78, ppl=4.16, accuracy=67.55, wps=12103.3, ups=1.46, wpb=8304.3, bsz=313.8, num_updates=32000, lr=7.90569e-05, gnorm=0.503, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=27324
2023-08-15 09:02:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:02:55 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.16 | nll_loss 2.422 | w2v_ctc_loss 1.32 | task_loss 4.623 | contrastive_loss 0.308 | total 4003.4 | n_correct 2675 | ppl 5.36 | accuracy 66.818 | uer 17.482 | wer 19.321 | raw_wer 19.321 | bleu 22.3 | wps 2232.9 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.33
2023-08-15 09:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-15 09:02:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-15 09:02:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-15 09:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.3) (writing took 42.399332424625754 seconds)
2023-08-15 09:04:48 | INFO | train_inner | epoch 022:   1162 / 1474 loss=1.968, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.679, task_loss=1.458, contrastive_loss=0.138, total=4102.27, n_correct=2749.47, ppl=4.25, accuracy=67.023, wps=6063.9, ups=0.74, wpb=8204.5, bsz=296.1, num_updates=32100, lr=7.89337e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=27460
2023-08-15 09:05:57 | INFO | train_inner | epoch 022:   1262 / 1474 loss=1.96, trans_loss=4.855, nll_loss=2.083, w2v_ctc_loss=0.67, task_loss=1.304, contrastive_loss=0.131, total=4179.1, n_correct=2807.7, ppl=4.24, accuracy=67.184, wps=12102.8, ups=1.45, wpb=8358.2, bsz=321.7, num_updates=32200, lr=7.8811e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=16.9, wall=27529
2023-08-15 09:07:06 | INFO | train_inner | epoch 022:   1362 / 1474 loss=1.957, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.664, task_loss=1.409, contrastive_loss=0.154, total=4061.14, n_correct=2733.14, ppl=4.19, accuracy=67.3, wps=11786.6, ups=1.45, wpb=8122.3, bsz=299.1, num_updates=32300, lr=7.86889e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=27598
2023-08-15 09:08:15 | INFO | train_inner | epoch 022:   1462 / 1474 loss=1.965, trans_loss=4.857, nll_loss=2.083, w2v_ctc_loss=0.683, task_loss=1.503, contrastive_loss=0.101, total=4083.08, n_correct=2740.28, ppl=4.24, accuracy=67.113, wps=11827.4, ups=1.45, wpb=8166.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=69, gb_free=16, wall=27667
2023-08-15 09:08:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:08:47 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.942 | trans_loss 5.157 | nll_loss 2.416 | w2v_ctc_loss 1.276 | task_loss 4.608 | contrastive_loss 0.306 | total 4003.4 | n_correct 2676.5 | ppl 5.34 | accuracy 66.856 | uer 17.328 | wer 19.235 | raw_wer 19.235 | bleu 21.73 | wps 2153.1 | wpb 4003.4 | bsz 141.8 | num_updates 32412 | best_bleu 22.33
2023-08-15 09:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-08-15 09:08:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 09:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 09:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt (epoch 22 @ 32412 updates, score 21.73) (writing took 15.687888592481613 seconds)
2023-08-15 09:09:03 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-15 09:09:03 | INFO | train | epoch 022 | loss 1.957 | trans_loss 4.843 | nll_loss 2.066 | w2v_ctc_loss 0.669 | task_loss 1.405 | contrastive_loss 0.141 | total 4138.62 | n_correct 2786.74 | ppl 4.19 | accuracy 67.335 | wps 10730.1 | ups 1.3 | wpb 8277.2 | bsz 305.7 | num_updates 32412 | lr 7.85529e-05 | gnorm 0.525 | clip 0 | loss_scale 8 | train_wall 1015 | gb_free 11.3 | wall 27714
2023-08-15 09:09:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:09:03 | INFO | fairseq.trainer | begin training epoch 23
2023-08-15 09:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:10:10 | INFO | train_inner | epoch 023:     88 / 1474 loss=1.943, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.664, task_loss=1.427, contrastive_loss=0.088, total=4093.3, n_correct=2772.57, ppl=4.12, accuracy=67.734, wps=7080.8, ups=0.86, wpb=8186.6, bsz=301.3, num_updates=32500, lr=7.84465e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=68, gb_free=15.9, wall=27782
2023-08-15 09:11:20 | INFO | train_inner | epoch 023:    188 / 1474 loss=1.94, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.658, task_loss=1.492, contrastive_loss=0.089, total=4116.26, n_correct=2792.72, ppl=4.1, accuracy=67.846, wps=11863.8, ups=1.44, wpb=8232.5, bsz=294.4, num_updates=32600, lr=7.8326e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=27852
2023-08-15 09:12:29 | INFO | train_inner | epoch 023:    288 / 1474 loss=1.953, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.657, task_loss=1.41, contrastive_loss=0.167, total=4148.03, n_correct=2799.69, ppl=4.16, accuracy=67.494, wps=11886.2, ups=1.43, wpb=8296.1, bsz=305.7, num_updates=32700, lr=7.82062e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=69, gb_free=17.1, wall=27921
2023-08-15 09:13:39 | INFO | train_inner | epoch 023:    388 / 1474 loss=1.936, trans_loss=4.818, nll_loss=2.033, w2v_ctc_loss=0.655, task_loss=1.454, contrastive_loss=0.079, total=4115.99, n_correct=2793.23, ppl=4.09, accuracy=67.863, wps=11912.8, ups=1.45, wpb=8232, bsz=294.1, num_updates=32800, lr=7.80869e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=27990
2023-08-15 09:14:48 | INFO | train_inner | epoch 023:    488 / 1474 loss=1.944, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.655, task_loss=1.374, contrastive_loss=0.136, total=4156.5, n_correct=2814.62, ppl=4.13, accuracy=67.716, wps=12026, ups=1.45, wpb=8313, bsz=312.2, num_updates=32900, lr=7.79681e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=28060
2023-08-15 09:15:56 | INFO | train_inner | epoch 023:    588 / 1474 loss=1.94, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.659, task_loss=1.322, contrastive_loss=0.086, total=4174.84, n_correct=2827.63, ppl=4.13, accuracy=67.73, wps=12148.2, ups=1.45, wpb=8349.7, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=28128
2023-08-15 09:17:06 | INFO | train_inner | epoch 023:    688 / 1474 loss=1.949, trans_loss=4.832, nll_loss=2.053, w2v_ctc_loss=0.662, task_loss=1.407, contrastive_loss=0.124, total=4139.68, n_correct=2800.47, ppl=4.15, accuracy=67.649, wps=11972.1, ups=1.45, wpb=8279.4, bsz=302.2, num_updates=33100, lr=7.77322e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.4, wall=28198
2023-08-15 09:18:14 | INFO | train_inner | epoch 023:    788 / 1474 loss=1.947, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.664, task_loss=1.414, contrastive_loss=0.104, total=4147.97, n_correct=2801.98, ppl=4.15, accuracy=67.551, wps=12049.3, ups=1.45, wpb=8295.9, bsz=305.8, num_updates=33200, lr=7.76151e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=28266
2023-08-15 09:19:24 | INFO | train_inner | epoch 023:    888 / 1474 loss=1.95, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.658, task_loss=1.281, contrastive_loss=0.186, total=4182.69, n_correct=2831.01, ppl=4.13, accuracy=67.684, wps=12092.4, ups=1.45, wpb=8365.4, bsz=325, num_updates=33300, lr=7.74984e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=28336
2023-08-15 09:20:33 | INFO | train_inner | epoch 023:    988 / 1474 loss=1.973, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.663, task_loss=1.405, contrastive_loss=0.346, total=4165.01, n_correct=2802.3, ppl=4.16, accuracy=67.282, wps=11992.9, ups=1.44, wpb=8330, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=17.4, wall=28405
2023-08-15 09:21:43 | INFO | train_inner | epoch 023:   1088 / 1474 loss=1.952, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.671, task_loss=1.494, contrastive_loss=0.092, total=4092.37, n_correct=2760.86, ppl=4.17, accuracy=67.464, wps=11736.8, ups=1.43, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=28475
2023-08-15 09:22:53 | INFO | train_inner | epoch 023:   1188 / 1474 loss=1.949, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.671, task_loss=1.398, contrastive_loss=0.085, total=4164.9, n_correct=2811.78, ppl=4.17, accuracy=67.511, wps=11902.5, ups=1.43, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=13.4, wall=28545
2023-08-15 09:24:02 | INFO | train_inner | epoch 023:   1288 / 1474 loss=1.943, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.66, task_loss=1.368, contrastive_loss=0.096, total=4136.96, n_correct=2793.99, ppl=4.15, accuracy=67.537, wps=11967.1, ups=1.45, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=28614
2023-08-15 09:25:11 | INFO | train_inner | epoch 023:   1388 / 1474 loss=1.959, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.665, task_loss=1.419, contrastive_loss=0.156, total=4142.84, n_correct=2789.47, ppl=4.2, accuracy=67.332, wps=11930.6, ups=1.44, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=28683
2023-08-15 09:26:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:26:35 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.156 | nll_loss 2.414 | w2v_ctc_loss 1.305 | task_loss 4.675 | contrastive_loss 0.305 | total 4003.4 | n_correct 2674.4 | ppl 5.33 | accuracy 66.803 | uer 17.384 | wer 19.235 | raw_wer 19.235 | bleu 22.08 | wps 2199.3 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 22.33
2023-08-15 09:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-15 09:26:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt
2023-08-15 09:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt
2023-08-15 09:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt (epoch 23 @ 33886 updates, score 22.08) (writing took 26.592188460752368 seconds)
2023-08-15 09:27:02 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-15 09:27:02 | INFO | train | epoch 023 | loss 1.95 | trans_loss 4.832 | nll_loss 2.052 | w2v_ctc_loss 0.661 | task_loss 1.404 | contrastive_loss 0.139 | total 4138.65 | n_correct 2796.92 | ppl 4.15 | accuracy 67.581 | wps 11303.7 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 13.4 | wall 28794
2023-08-15 09:27:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:27:02 | INFO | fairseq.trainer | begin training epoch 24
2023-08-15 09:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:27:20 | INFO | train_inner | epoch 024:     14 / 1474 loss=1.964, trans_loss=4.841, nll_loss=2.065, w2v_ctc_loss=0.658, task_loss=1.421, contrastive_loss=0.236, total=4084.21, n_correct=2749.85, ppl=4.18, accuracy=67.329, wps=6348.9, ups=0.78, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=28812
2023-08-15 09:28:30 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.942, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.64, task_loss=1.297, contrastive_loss=0.247, total=4168.61, n_correct=2833.02, ppl=4.07, accuracy=67.961, wps=11951.8, ups=1.43, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=11, wall=28882
2023-08-15 09:28:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:28:53 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.163 | nll_loss 2.42 | w2v_ctc_loss 1.31 | task_loss 4.666 | contrastive_loss 0.305 | total 4003.4 | n_correct 2666.5 | ppl 5.35 | accuracy 66.606 | uer 17.45 | wer 19.28 | raw_wer 19.28 | bleu 22.46 | wps 2239.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.46
2023-08-15 09:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-15 09:28:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-15 09:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-15 09:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.46) (writing took 53.71330666169524 seconds)
2023-08-15 09:30:58 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.95, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.639, task_loss=1.224, contrastive_loss=0.301, total=4252.53, n_correct=2887.72, ppl=4.1, accuracy=67.906, wps=5754.8, ups=0.68, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=29030
2023-08-15 09:32:07 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.931, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.648, task_loss=1.367, contrastive_loss=0.081, total=4138.44, n_correct=2813.93, ppl=4.08, accuracy=67.995, wps=11980.1, ups=1.45, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=29099
2023-08-15 09:33:17 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.959, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.666, task_loss=1.483, contrastive_loss=0.223, total=4153.83, n_correct=2811.64, ppl=4.09, accuracy=67.688, wps=11848.1, ups=1.43, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=70, gb_free=15.9, wall=29169
2023-08-15 09:34:26 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.943, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.656, task_loss=1.428, contrastive_loss=0.152, total=4141.88, n_correct=2810.02, ppl=4.09, accuracy=67.844, wps=11921.7, ups=1.44, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=29238
2023-08-15 09:35:36 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.937, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.649, task_loss=1.412, contrastive_loss=0.112, total=4162.06, n_correct=2821.44, ppl=4.1, accuracy=67.79, wps=12018, ups=1.44, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=29308
2023-08-15 09:36:45 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.942, trans_loss=4.824, nll_loss=2.041, w2v_ctc_loss=0.652, task_loss=1.453, contrastive_loss=0.127, total=4097.35, n_correct=2776.54, ppl=4.11, accuracy=67.764, wps=11822.9, ups=1.44, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=29377
2023-08-15 09:37:55 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.941, trans_loss=4.828, nll_loss=2.048, w2v_ctc_loss=0.657, task_loss=1.404, contrastive_loss=0.102, total=4124.25, n_correct=2793.12, ppl=4.13, accuracy=67.724, wps=11797.4, ups=1.43, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=29447
2023-08-15 09:39:03 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.946, trans_loss=4.827, nll_loss=2.044, w2v_ctc_loss=0.665, task_loss=1.562, contrastive_loss=0.079, total=4041.44, n_correct=2731.99, ppl=4.12, accuracy=67.599, wps=11779, ups=1.46, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=29515
2023-08-15 09:40:13 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.938, trans_loss=4.825, nll_loss=2.042, w2v_ctc_loss=0.652, task_loss=1.466, contrastive_loss=0.082, total=4128.8, n_correct=2799.61, ppl=4.12, accuracy=67.807, wps=11910.1, ups=1.44, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=29585
2023-08-15 09:41:22 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.942, trans_loss=4.816, nll_loss=2.032, w2v_ctc_loss=0.661, task_loss=1.354, contrastive_loss=0.126, total=4130.49, n_correct=2800.26, ppl=4.09, accuracy=67.795, wps=11919.7, ups=1.44, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=29654
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 09:42:32 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.94, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.651, task_loss=1.389, contrastive_loss=0.113, total=4157.47, n_correct=2814.75, ppl=4.12, accuracy=67.703, wps=11894.9, ups=1.43, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=29724
2023-08-15 09:43:41 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.946, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.668, task_loss=1.493, contrastive_loss=0.085, total=4107.23, n_correct=2779.07, ppl=4.13, accuracy=67.663, wps=11916, ups=1.45, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=29793
2023-08-15 09:44:50 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.943, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.666, task_loss=1.468, contrastive_loss=0.084, total=4094.39, n_correct=2773.88, ppl=4.13, accuracy=67.748, wps=11929.2, ups=1.46, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=29862
2023-08-15 09:45:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 09:45:54 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.161 | nll_loss 2.422 | w2v_ctc_loss 1.302 | task_loss 4.662 | contrastive_loss 0.306 | total 4003.4 | n_correct 2679.8 | ppl 5.36 | accuracy 66.938 | uer 17.495 | wer 19.328 | raw_wer 19.328 | bleu 22.08 | wps 2256.2 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 22.46
2023-08-15 09:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-15 09:45:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt
2023-08-15 09:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt
2023-08-15 09:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt (epoch 24 @ 35360 updates, score 22.08) (writing took 23.378317130729556 seconds)
2023-08-15 09:46:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-15 09:46:17 | INFO | train | epoch 024 | loss 1.942 | trans_loss 4.821 | nll_loss 2.038 | w2v_ctc_loss 0.654 | task_loss 1.405 | contrastive_loss 0.137 | total 4138.65 | n_correct 2805.79 | ppl 4.11 | accuracy 67.795 | wps 10559.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.9 | wall 29949
2023-08-15 09:46:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:46:18 | INFO | fairseq.trainer | begin training epoch 25
2023-08-15 09:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:46:52 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.927, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.645, task_loss=1.355, contrastive_loss=0.09, total=4165.57, n_correct=2840.85, ppl=4.07, accuracy=68.198, wps=6779, ups=0.81, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=69, gb_free=12.8, wall=29984
2023-08-15 09:48:02 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.921, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.64, task_loss=1.365, contrastive_loss=0.087, total=4135.43, n_correct=2822.59, ppl=4.02, accuracy=68.254, wps=11904.5, ups=1.44, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=30054
2023-08-15 09:49:12 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.931, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.65, task_loss=1.441, contrastive_loss=0.093, total=4116.13, n_correct=2796.2, ppl=4.06, accuracy=67.933, wps=11787.1, ups=1.43, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=30124
2023-08-15 09:50:21 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.93, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.643, task_loss=1.5, contrastive_loss=0.119, total=4141.49, n_correct=2820.6, ppl=4.04, accuracy=68.106, wps=11905.7, ups=1.44, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=30193
2023-08-15 09:51:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 09:51:32 | INFO | train_inner | epoch 025:    441 / 1474 loss=1.938, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.667, task_loss=1.505, contrastive_loss=0.081, total=4149.36, n_correct=2823.31, ppl=4.05, accuracy=68.042, wps=11744.9, ups=1.42, wpb=8298.7, bsz=290.1, num_updates=35800, lr=7.47435e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=30264
2023-08-15 09:52:41 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.934, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.649, task_loss=1.371, contrastive_loss=0.093, total=4154.79, n_correct=2820.91, ppl=4.1, accuracy=67.895, wps=11988.5, ups=1.44, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=30333
2023-08-15 09:53:51 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.936, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.648, task_loss=1.395, contrastive_loss=0.161, total=4156.33, n_correct=2824.16, ppl=4.05, accuracy=67.948, wps=11977.1, ups=1.44, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=30403
2023-08-15 09:53:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:54:15 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.16 | nll_loss 2.417 | w2v_ctc_loss 1.302 | task_loss 4.642 | contrastive_loss 0.308 | total 4003.4 | n_correct 2678.4 | ppl 5.34 | accuracy 66.903 | uer 17.368 | wer 19.082 | raw_wer 19.082 | bleu 22.47 | wps 1850.6 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.47
2023-08-15 09:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-15 09:54:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-15 09:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-15 09:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.47) (writing took 57.3581663146615 seconds)
2023-08-15 09:56:22 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.938, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.648, task_loss=1.416, contrastive_loss=0.155, total=4133.94, n_correct=2811.28, ppl=4.06, accuracy=68.005, wps=5455.2, ups=0.66, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=30554
2023-08-15 09:57:32 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.928, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.647, task_loss=1.303, contrastive_loss=0.098, total=4174.24, n_correct=2843.4, ppl=4.07, accuracy=68.118, wps=12001.8, ups=1.44, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=30624
2023-08-15 09:58:41 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.936, trans_loss=4.811, nll_loss=2.026, w2v_ctc_loss=0.649, task_loss=1.337, contrastive_loss=0.16, total=4154.13, n_correct=2826.87, ppl=4.07, accuracy=68.05, wps=11974, ups=1.44, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=10.5, wall=30693
2023-08-15 09:59:51 | INFO | train_inner | epoch 025:   1041 / 1474 loss=1.951, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.646, task_loss=1.396, contrastive_loss=0.269, total=4178.3, n_correct=2832.28, ppl=4.11, accuracy=67.785, wps=11950, ups=1.43, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=30763
2023-08-15 10:01:00 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.933, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.651, task_loss=1.51, contrastive_loss=0.075, total=4042.33, n_correct=2746.02, ppl=4.08, accuracy=67.932, wps=11752, ups=1.45, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=30832
2023-08-15 10:02:09 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.933, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.646, task_loss=1.43, contrastive_loss=0.085, total=4087.78, n_correct=2777.79, ppl=4.1, accuracy=67.954, wps=11829.3, ups=1.45, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=30901
2023-08-15 10:03:18 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.941, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.65, task_loss=1.373, contrastive_loss=0.178, total=4166.64, n_correct=2829.28, ppl=4.08, accuracy=67.903, wps=12041.4, ups=1.44, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=30970
2023-08-15 10:04:28 | INFO | train_inner | epoch 025:   1441 / 1474 loss=1.947, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.654, task_loss=1.429, contrastive_loss=0.148, total=4114.64, n_correct=2781.25, ppl=4.13, accuracy=67.594, wps=11755.7, ups=1.43, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=31040
2023-08-15 10:04:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:05:15 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.27 | task_loss 4.621 | contrastive_loss 0.299 | total 4003.4 | n_correct 2682.9 | ppl 5.33 | accuracy 67.016 | uer 17.272 | wer 19.272 | raw_wer 19.272 | bleu 22.46 | wps 2242.1 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 22.47
2023-08-15 10:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-15 10:05:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt
2023-08-15 10:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt
2023-08-15 10:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt (epoch 25 @ 36833 updates, score 22.46) (writing took 29.225748728960752 seconds)
2023-08-15 10:05:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-15 10:05:44 | INFO | train | epoch 025 | loss 1.935 | trans_loss 4.812 | nll_loss 2.026 | w2v_ctc_loss 0.649 | task_loss 1.407 | contrastive_loss 0.127 | total 4137.25 | n_correct 2812.26 | ppl 4.07 | accuracy 67.974 | wps 10445.3 | ups 1.26 | wpb 8274.5 | bsz 305.1 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.527 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 14 | wall 31116
2023-08-15 10:05:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:05:45 | INFO | fairseq.trainer | begin training epoch 26
2023-08-15 10:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:06:39 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.924, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.64, task_loss=1.328, contrastive_loss=0.112, total=4172.16, n_correct=2844.88, ppl=4.02, accuracy=68.187, wps=6399.4, ups=0.77, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=31171
2023-08-15 10:07:49 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.93, trans_loss=4.795, nll_loss=2.005, w2v_ctc_loss=0.622, task_loss=1.237, contrastive_loss=0.285, total=4265.22, n_correct=2919.59, ppl=4.01, accuracy=68.451, wps=12210.7, ups=1.43, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=31241
2023-08-15 10:08:58 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.935, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.646, task_loss=1.396, contrastive_loss=0.175, total=4123.94, n_correct=2811.75, ppl=4.02, accuracy=68.181, wps=11845.6, ups=1.44, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=31310
2023-08-15 10:10:07 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.927, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.639, task_loss=1.34, contrastive_loss=0.13, total=4168.11, n_correct=2843.9, ppl=4.03, accuracy=68.23, wps=12085.4, ups=1.45, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=31379
2023-08-15 10:11:16 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.931, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.648, task_loss=1.346, contrastive_loss=0.175, total=4167.53, n_correct=2848.77, ppl=4, accuracy=68.356, wps=12109.7, ups=1.45, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=13.7, wall=31448
2023-08-15 10:12:26 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.927, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.65, task_loss=1.414, contrastive_loss=0.095, total=4158.48, n_correct=2839.42, ppl=4.03, accuracy=68.28, wps=11889.7, ups=1.43, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=12.5, wall=31518
2023-08-15 10:13:35 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.922, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.635, task_loss=1.439, contrastive_loss=0.081, total=4129.11, n_correct=2815.99, ppl=4.03, accuracy=68.198, wps=11911.7, ups=1.44, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=13.5, wall=31587
2023-08-15 10:14:45 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.939, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.645, task_loss=1.413, contrastive_loss=0.196, total=4096.84, n_correct=2791.13, ppl=4.05, accuracy=68.129, wps=11818.9, ups=1.44, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=31657
2023-08-15 10:15:54 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.928, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.648, task_loss=1.399, contrastive_loss=0.097, total=4176.27, n_correct=2846.31, ppl=4.03, accuracy=68.154, wps=12109.9, ups=1.45, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=31726
2023-08-15 10:17:03 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.928, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.632, task_loss=1.447, contrastive_loss=0.148, total=4141.01, n_correct=2823.94, ppl=4.04, accuracy=68.194, wps=11888.7, ups=1.44, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=31795
2023-08-15 10:18:13 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.927, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.647, task_loss=1.483, contrastive_loss=0.082, total=4113.69, n_correct=2803.77, ppl=4.04, accuracy=68.157, wps=11853.6, ups=1.44, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=31865
2023-08-15 10:19:22 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.933, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.646, task_loss=1.464, contrastive_loss=0.12, total=4116.78, n_correct=2799.07, ppl=4.07, accuracy=67.992, wps=11826.7, ups=1.44, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31934
2023-08-15 10:19:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:19:46 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.16 | nll_loss 2.417 | w2v_ctc_loss 1.373 | task_loss 4.647 | contrastive_loss 0.294 | total 4003.4 | n_correct 2681.6 | ppl 5.34 | accuracy 66.983 | uer 17.477 | wer 19.414 | raw_wer 19.414 | bleu 22.55 | wps 2201.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.55
2023-08-15 10:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-15 10:19:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-15 10:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-15 10:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.55) (writing took 49.746575059369206 seconds)
2023-08-15 10:21:47 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.936, trans_loss=4.816, nll_loss=2.029, w2v_ctc_loss=0.659, task_loss=1.554, contrastive_loss=0.082, total=4001.06, n_correct=2718.19, ppl=4.08, accuracy=67.937, wps=5523.9, ups=0.69, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=32079
2023-08-15 10:22:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 10:22:58 | INFO | train_inner | epoch 026:   1368 / 1474 loss=1.924, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.634, task_loss=1.405, contrastive_loss=0.095, total=4157.05, n_correct=2832.57, ppl=4.06, accuracy=68.139, wps=11731, ups=1.41, wpb=8314.1, bsz=310.7, num_updates=38200, lr=7.23575e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=70, gb_free=13.4, wall=32150
2023-08-15 10:24:07 | INFO | train_inner | epoch 026:   1468 / 1474 loss=1.916, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.633, task_loss=1.342, contrastive_loss=0.089, total=4151.66, n_correct=2838.73, ppl=4.03, accuracy=68.376, wps=12032.2, ups=1.45, wpb=8303.3, bsz=315.5, num_updates=38300, lr=7.22629e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=32219
2023-08-15 10:24:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:24:35 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.26 | task_loss 4.611 | contrastive_loss 0.297 | total 4003.4 | n_correct 2675 | ppl 5.35 | accuracy 66.818 | uer 17.309 | wer 19.216 | raw_wer 19.216 | bleu 22.22 | wps 2128 | wpb 4003.4 | bsz 141.8 | num_updates 38306 | best_bleu 22.55
2023-08-15 10:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38306 updates
2023-08-15 10:24:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-15 10:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-15 10:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt (epoch 26 @ 38306 updates, score 22.22) (writing took 20.961894690990448 seconds)
2023-08-15 10:24:56 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-15 10:24:56 | INFO | train | epoch 026 | loss 1.929 | trans_loss 4.802 | nll_loss 2.012 | w2v_ctc_loss 0.642 | task_loss 1.404 | contrastive_loss 0.133 | total 4138.42 | n_correct 2822.66 | ppl 4.03 | accuracy 68.206 | wps 10583.3 | ups 1.28 | wpb 8276.8 | bsz 305.6 | num_updates 38306 | lr 7.22573e-05 | gnorm 0.524 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.7 | wall 32268
2023-08-15 10:24:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:24:57 | INFO | fairseq.trainer | begin training epoch 27
2023-08-15 10:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:26:08 | INFO | train_inner | epoch 027:     94 / 1474 loss=1.906, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.626, task_loss=1.501, contrastive_loss=0.069, total=4072.63, n_correct=2805.54, ppl=3.92, accuracy=68.888, wps=6715, ups=0.82, wpb=8145.3, bsz=284.2, num_updates=38400, lr=7.21688e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=32340
2023-08-15 10:27:18 | INFO | train_inner | epoch 027:    194 / 1474 loss=1.909, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.625, task_loss=1.345, contrastive_loss=0.095, total=4179.66, n_correct=2870.04, ppl=3.97, accuracy=68.667, wps=12077.5, ups=1.44, wpb=8359.3, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=32410
2023-08-15 10:28:28 | INFO | train_inner | epoch 027:    294 / 1474 loss=1.919, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.636, task_loss=1.4, contrastive_loss=0.082, total=4173.27, n_correct=2858.76, ppl=4, accuracy=68.502, wps=11915.8, ups=1.43, wpb=8346.5, bsz=307, num_updates=38600, lr=7.19816e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=32480
2023-08-15 10:29:38 | INFO | train_inner | epoch 027:    394 / 1474 loss=1.944, trans_loss=4.798, nll_loss=2.007, w2v_ctc_loss=0.642, task_loss=1.465, contrastive_loss=0.272, total=4078.73, n_correct=2780.79, ppl=4.02, accuracy=68.178, wps=11678, ups=1.43, wpb=8157.5, bsz=297.5, num_updates=38700, lr=7.18885e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=32550
2023-08-15 10:30:47 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.931, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.634, task_loss=1.285, contrastive_loss=0.202, total=4245.37, n_correct=2898.9, ppl=4.03, accuracy=68.284, wps=12176.8, ups=1.43, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=32619
2023-08-15 10:31:57 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.927, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.643, task_loss=1.381, contrastive_loss=0.142, total=4134.93, n_correct=2825.57, ppl=4, accuracy=68.334, wps=11946.7, ups=1.44, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=32688
2023-08-15 10:33:06 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.925, trans_loss=4.796, nll_loss=2.004, w2v_ctc_loss=0.64, task_loss=1.401, contrastive_loss=0.119, total=4162.17, n_correct=2840.69, ppl=4.01, accuracy=68.25, wps=11928.4, ups=1.43, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=32758
2023-08-15 10:34:15 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.924, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.646, task_loss=1.475, contrastive_loss=0.082, total=4107.17, n_correct=2803.99, ppl=4.01, accuracy=68.271, wps=11922.8, ups=1.45, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=11.2, wall=32827
2023-08-15 10:35:24 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.919, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.633, task_loss=1.456, contrastive_loss=0.075, total=4101.4, n_correct=2802.86, ppl=4.03, accuracy=68.339, wps=11885.5, ups=1.45, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=32896
2023-08-15 10:36:34 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.934, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.633, task_loss=1.361, contrastive_loss=0.26, total=4195.5, n_correct=2866.55, ppl=4.02, accuracy=68.324, wps=11977.4, ups=1.43, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=32966
2023-08-15 10:37:44 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.92, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.637, task_loss=1.409, contrastive_loss=0.092, total=4147.99, n_correct=2832, ppl=4.01, accuracy=68.274, wps=11937.2, ups=1.44, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=33036
2023-08-15 10:38:53 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.929, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.647, task_loss=1.471, contrastive_loss=0.096, total=4104.84, n_correct=2797.08, ppl=4.04, accuracy=68.141, wps=11867.7, ups=1.45, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=11.9, wall=33105
2023-08-15 10:40:02 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.928, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.638, task_loss=1.49, contrastive_loss=0.148, total=4062.86, n_correct=2775.7, ppl=4.02, accuracy=68.319, wps=11795.5, ups=1.45, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=33174
2023-08-15 10:41:11 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.923, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.634, task_loss=1.323, contrastive_loss=0.131, total=4157.6, n_correct=2840.31, ppl=4.03, accuracy=68.316, wps=12072.4, ups=1.45, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=33243
2023-08-15 10:42:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:42:29 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.163 | nll_loss 2.422 | w2v_ctc_loss 1.347 | task_loss 4.63 | contrastive_loss 0.299 | total 4003.4 | n_correct 2679.3 | ppl 5.36 | accuracy 66.926 | uer 17.575 | wer 19.708 | raw_wer 19.708 | bleu 22.48 | wps 2232.5 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 22.55
2023-08-15 10:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-15 10:42:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt
2023-08-15 10:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt
2023-08-15 10:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt (epoch 27 @ 39780 updates, score 22.48) (writing took 21.285217706114054 seconds)
2023-08-15 10:42:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-15 10:42:51 | INFO | train | epoch 027 | loss 1.923 | trans_loss 4.794 | nll_loss 2.002 | w2v_ctc_loss 0.636 | task_loss 1.404 | contrastive_loss 0.132 | total 4138.65 | n_correct 2829.47 | ppl 4.01 | accuracy 68.367 | wps 11354.5 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 17.5 | wall 33343
2023-08-15 10:42:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:42:51 | INFO | fairseq.trainer | begin training epoch 28
2023-08-15 10:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:43:12 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.91, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.623, task_loss=1.362, contrastive_loss=0.081, total=4107.3, n_correct=2813.97, ppl=3.99, accuracy=68.511, wps=6767.4, ups=0.82, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=33364
2023-08-15 10:44:21 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.908, trans_loss=4.77, nll_loss=1.97, w2v_ctc_loss=0.629, task_loss=1.468, contrastive_loss=0.076, total=4112.44, n_correct=2832.95, ppl=3.92, accuracy=68.887, wps=11944.6, ups=1.45, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=13.5, wall=33433
2023-08-15 10:45:30 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.904, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.622, task_loss=1.326, contrastive_loss=0.085, total=4193.3, n_correct=2886.84, ppl=3.95, accuracy=68.844, wps=12091.9, ups=1.44, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=33502
2023-08-15 10:45:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:45:53 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.16 | nll_loss 2.416 | w2v_ctc_loss 1.326 | task_loss 4.636 | contrastive_loss 0.298 | total 4003.4 | n_correct 2686 | ppl 5.34 | accuracy 67.093 | uer 17.601 | wer 19.488 | raw_wer 19.488 | bleu 22.63 | wps 2249.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.63
2023-08-15 10:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-15 10:45:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-15 10:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-15 10:46:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.63) (writing took 51.65023431368172 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 10:47:57 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.942, trans_loss=4.786, nll_loss=1.991, w2v_ctc_loss=0.622, task_loss=1.403, contrastive_loss=0.42, total=4138.69, n_correct=2830.32, ppl=3.98, accuracy=68.387, wps=5663.3, ups=0.68, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=70, gb_free=13, wall=33648
2023-08-15 10:49:05 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.915, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.639, task_loss=1.448, contrastive_loss=0.074, total=4089.84, n_correct=2807.3, ppl=3.96, accuracy=68.641, wps=11859.4, ups=1.45, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=33717
2023-08-15 10:50:15 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.909, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.625, task_loss=1.462, contrastive_loss=0.083, total=4098.92, n_correct=2816.07, ppl=3.95, accuracy=68.703, wps=11792.2, ups=1.44, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=33787
2023-08-15 10:51:24 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.914, trans_loss=4.789, nll_loss=1.995, w2v_ctc_loss=0.634, task_loss=1.416, contrastive_loss=0.085, total=4180.1, n_correct=2866.28, ppl=3.99, accuracy=68.57, wps=12112, ups=1.45, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=33856
2023-08-15 10:52:34 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.922, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.626, task_loss=1.269, contrastive_loss=0.194, total=4191.62, n_correct=2871.37, ppl=4, accuracy=68.503, wps=12043, ups=1.44, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=33926
2023-08-15 10:53:43 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.907, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.626, task_loss=1.387, contrastive_loss=0.076, total=4088.91, n_correct=2810.06, ppl=3.96, accuracy=68.724, wps=11782.1, ups=1.44, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=33995
2023-08-15 10:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 10:54:54 | INFO | train_inner | epoch 028:    921 / 1474 loss=1.925, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.637, task_loss=1.452, contrastive_loss=0.138, total=4120.11, n_correct=2815.54, ppl=4, accuracy=68.337, wps=11605.2, ups=1.41, wpb=8240.2, bsz=300.2, num_updates=40700, lr=7.01e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=71, gb_free=16.6, wall=34066
2023-08-15 10:56:03 | INFO | train_inner | epoch 028:   1021 / 1474 loss=1.929, trans_loss=4.79, nll_loss=1.996, w2v_ctc_loss=0.638, task_loss=1.372, contrastive_loss=0.193, total=4174.98, n_correct=2855.94, ppl=3.99, accuracy=68.406, wps=12055.1, ups=1.44, wpb=8350, bsz=310.9, num_updates=40800, lr=7.0014e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=34135
2023-08-15 10:57:13 | INFO | train_inner | epoch 028:   1121 / 1474 loss=1.913, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.631, task_loss=1.346, contrastive_loss=0.097, total=4222.19, n_correct=2891.02, ppl=3.98, accuracy=68.472, wps=12048.6, ups=1.43, wpb=8444.4, bsz=321.5, num_updates=40900, lr=6.99284e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=34205
2023-08-15 10:58:22 | INFO | train_inner | epoch 028:   1221 / 1474 loss=1.908, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.621, task_loss=1.387, contrastive_loss=0.083, total=4104.72, n_correct=2817.58, ppl=3.98, accuracy=68.642, wps=11905.5, ups=1.45, wpb=8209.4, bsz=305.5, num_updates=41000, lr=6.9843e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=34274
2023-08-15 10:59:32 | INFO | train_inner | epoch 028:   1321 / 1474 loss=1.919, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.638, task_loss=1.558, contrastive_loss=0.1, total=4074.43, n_correct=2791.04, ppl=3.98, accuracy=68.501, wps=11670.7, ups=1.43, wpb=8148.9, bsz=282.9, num_updates=41100, lr=6.9758e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=34344
2023-08-15 11:00:42 | INFO | train_inner | epoch 028:   1421 / 1474 loss=1.917, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.629, task_loss=1.451, contrastive_loss=0.122, total=4156.52, n_correct=2848.66, ppl=3.97, accuracy=68.535, wps=11998.1, ups=1.44, wpb=8313, bsz=300.8, num_updates=41200, lr=6.96733e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=34413
2023-08-15 11:01:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
2023-08-15 11:01:42 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.156 | nll_loss 2.411 | w2v_ctc_loss 1.342 | task_loss 4.666 | contrastive_loss 0.293 | total 4003.4 | n_correct 2685.9 | ppl 5.32 | accuracy 67.09 | uer 17.116 | wer 18.955 | raw_wer 18.955 | bleu 22.42 | wps 2179.7 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 22.63
2023-08-15 11:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-08-15 11:01:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt
2023-08-15 11:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt
2023-08-15 11:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt (epoch 28 @ 41253 updates, score 22.42) (writing took 38.97503117285669 seconds)
2023-08-15 11:02:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-15 11:02:24 | INFO | train | epoch 028 | loss 1.916 | trans_loss 4.784 | nll_loss 1.989 | w2v_ctc_loss 0.63 | task_loss 1.404 | contrastive_loss 0.13 | total 4138.81 | n_correct 2839.23 | ppl 3.97 | accuracy 68.6 | wps 10395.8 | ups 1.26 | wpb 8277.6 | bsz 305.7 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 16.2 | wall 34516
2023-08-15 11:02:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:02:24 | INFO | fairseq.trainer | begin training epoch 29
2023-08-15 11:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:03:04 | INFO | train_inner | epoch 029:     47 / 1474 loss=1.908, trans_loss=4.774, nll_loss=1.978, w2v_ctc_loss=0.63, task_loss=1.361, contrastive_loss=0.098, total=4169.02, n_correct=2872.51, ppl=3.94, accuracy=68.901, wps=5849.1, ups=0.7, wpb=8338, bsz=315.1, num_updates=41300, lr=6.95889e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=34556
2023-08-15 11:04:14 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.911, trans_loss=4.776, nll_loss=1.978, w2v_ctc_loss=0.629, task_loss=1.398, contrastive_loss=0.114, total=4110.03, n_correct=2827.63, ppl=3.94, accuracy=68.798, wps=11749.5, ups=1.43, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=34626
2023-08-15 11:05:24 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.907, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.611, task_loss=1.277, contrastive_loss=0.194, total=4197.89, n_correct=2895.32, ppl=3.91, accuracy=68.971, wps=12053.7, ups=1.44, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=34696
2023-08-15 11:06:33 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.915, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.641, task_loss=1.507, contrastive_loss=0.079, total=4094.4, n_correct=2811.74, ppl=3.96, accuracy=68.673, wps=11779.7, ups=1.44, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=34765
2023-08-15 11:07:43 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.897, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.62, task_loss=1.344, contrastive_loss=0.074, total=4157.41, n_correct=2872.2, ppl=3.88, accuracy=69.086, wps=11964.7, ups=1.44, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=14.4, wall=34835
2023-08-15 11:08:53 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.924, trans_loss=4.785, nll_loss=1.99, w2v_ctc_loss=0.626, task_loss=1.506, contrastive_loss=0.171, total=4149.27, n_correct=2840.36, ppl=3.97, accuracy=68.454, wps=11868.5, ups=1.43, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=34905
2023-08-15 11:10:02 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.917, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.622, task_loss=1.326, contrastive_loss=0.237, total=4145.39, n_correct=2853.74, ppl=3.93, accuracy=68.841, wps=11874.1, ups=1.43, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=34974
2023-08-15 11:11:13 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.91, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.621, task_loss=1.294, contrastive_loss=0.158, total=4242.46, n_correct=2921.33, ppl=3.93, accuracy=68.859, wps=12078.6, ups=1.42, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=35045
2023-08-15 11:11:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:11:36 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.161 | nll_loss 2.418 | w2v_ctc_loss 1.333 | task_loss 4.614 | contrastive_loss 0.292 | total 4003.4 | n_correct 2686.1 | ppl 5.35 | accuracy 67.095 | uer 17.294 | wer 19.365 | raw_wer 19.365 | bleu 22.62 | wps 2245.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.63
2023-08-15 11:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-15 11:11:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-15 11:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-15 11:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.62) (writing took 42.68160405755043 seconds)
2023-08-15 11:13:28 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.912, trans_loss=4.788, nll_loss=1.993, w2v_ctc_loss=0.624, task_loss=1.559, contrastive_loss=0.072, total=4027.03, n_correct=2756.03, ppl=3.98, accuracy=68.438, wps=5936.3, ups=0.74, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=35180
2023-08-15 11:14:38 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.911, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.634, task_loss=1.436, contrastive_loss=0.081, total=4086.72, n_correct=2808.87, ppl=3.96, accuracy=68.732, wps=11810.3, ups=1.44, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=35250
2023-08-15 11:15:47 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.911, trans_loss=4.775, nll_loss=1.979, w2v_ctc_loss=0.619, task_loss=1.4, contrastive_loss=0.157, total=4139.4, n_correct=2845.16, ppl=3.94, accuracy=68.734, wps=11909.7, ups=1.44, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=35319
2023-08-15 11:16:56 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.915, trans_loss=4.788, nll_loss=1.994, w2v_ctc_loss=0.634, task_loss=1.533, contrastive_loss=0.07, total=4072.33, n_correct=2789.31, ppl=3.98, accuracy=68.494, wps=11793, ups=1.45, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35388
2023-08-15 11:18:06 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.91, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.63, task_loss=1.423, contrastive_loss=0.077, total=4160.52, n_correct=2857.2, ppl=3.97, accuracy=68.674, wps=11976.6, ups=1.44, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=35458
2023-08-15 11:19:15 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.909, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.618, task_loss=1.383, contrastive_loss=0.138, total=4168.02, n_correct=2867.65, ppl=3.93, accuracy=68.801, wps=11946.2, ups=1.43, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=35527
2023-08-15 11:20:25 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.911, trans_loss=4.771, nll_loss=1.974, w2v_ctc_loss=0.625, task_loss=1.371, contrastive_loss=0.173, total=4166.06, n_correct=2872.1, ppl=3.93, accuracy=68.94, wps=12008.7, ups=1.44, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35597
2023-08-15 11:20:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:21:06 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.153 | nll_loss 2.407 | w2v_ctc_loss 1.329 | task_loss 4.623 | contrastive_loss 0.293 | total 4003.4 | n_correct 2690.7 | ppl 5.3 | accuracy 67.21 | uer 16.792 | wer 18.75 | raw_wer 18.75 | bleu 22.45 | wps 2144.6 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.63
2023-08-15 11:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-15 11:21:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt
2023-08-15 11:21:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt
2023-08-15 11:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt (epoch 29 @ 42727 updates, score 22.45) (writing took 40.345158483833075 seconds)
2023-08-15 11:21:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-15 11:21:47 | INFO | train | epoch 029 | loss 1.911 | trans_loss 4.776 | nll_loss 1.979 | w2v_ctc_loss 0.625 | task_loss 1.404 | contrastive_loss 0.128 | total 4138.65 | n_correct 2845.71 | ppl 3.94 | accuracy 68.759 | wps 10486.5 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 15.8 | wall 35679
2023-08-15 11:21:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:21:47 | INFO | fairseq.trainer | begin training epoch 30
2023-08-15 11:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:22:46 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.904, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.609, task_loss=1.337, contrastive_loss=0.187, total=4175.11, n_correct=2883.33, ppl=3.9, accuracy=69.06, wps=5935.1, ups=0.71, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=35737
2023-08-15 11:23:55 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.899, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.619, task_loss=1.312, contrastive_loss=0.117, total=4202.64, n_correct=2908.92, ppl=3.86, accuracy=69.216, wps=12086, ups=1.44, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=35807
2023-08-15 11:25:04 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.903, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.626, task_loss=1.451, contrastive_loss=0.071, total=4120.21, n_correct=2841.78, ppl=3.91, accuracy=68.972, wps=11906.9, ups=1.44, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15, wall=35876
2023-08-15 11:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 11:26:14 | INFO | train_inner | epoch 030:    374 / 1474 loss=1.892, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.611, task_loss=1.39, contrastive_loss=0.073, total=4180.19, n_correct=2893.31, ppl=3.88, accuracy=69.215, wps=11932.3, ups=1.43, wpb=8360.4, bsz=308.2, num_updates=43100, lr=6.81203e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=35946
2023-08-15 11:27:23 | INFO | train_inner | epoch 030:    474 / 1474 loss=1.902, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.61, task_loss=1.356, contrastive_loss=0.139, total=4121.08, n_correct=2843.12, ppl=3.91, accuracy=68.99, wps=12017.1, ups=1.46, wpb=8242.2, bsz=311.1, num_updates=43200, lr=6.80414e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=36015
2023-08-15 11:28:32 | INFO | train_inner | epoch 030:    574 / 1474 loss=1.902, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.621, task_loss=1.361, contrastive_loss=0.099, total=4162.58, n_correct=2869.03, ppl=3.91, accuracy=68.924, wps=11976.4, ups=1.44, wpb=8325.2, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=36084
2023-08-15 11:29:42 | INFO | train_inner | epoch 030:    674 / 1474 loss=1.91, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.63, task_loss=1.382, contrastive_loss=0.113, total=4192, n_correct=2881.88, ppl=3.92, accuracy=68.747, wps=12017.3, ups=1.43, wpb=8384, bsz=315.3, num_updates=43400, lr=6.78844e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=36154
2023-08-15 11:30:51 | INFO | train_inner | epoch 030:    774 / 1474 loss=1.921, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.633, task_loss=1.431, contrastive_loss=0.194, total=4103.26, n_correct=2817.3, ppl=3.94, accuracy=68.66, wps=11879.7, ups=1.45, wpb=8206.5, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=36223
2023-08-15 11:32:01 | INFO | train_inner | epoch 030:    874 / 1474 loss=1.908, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.627, task_loss=1.435, contrastive_loss=0.087, total=4111.51, n_correct=2830.68, ppl=3.93, accuracy=68.848, wps=11855.2, ups=1.44, wpb=8223, bsz=297.8, num_updates=43600, lr=6.77285e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=36293
2023-08-15 11:33:10 | INFO | train_inner | epoch 030:    974 / 1474 loss=1.91, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.631, task_loss=1.448, contrastive_loss=0.086, total=4125.95, n_correct=2832.46, ppl=3.95, accuracy=68.65, wps=11861.8, ups=1.44, wpb=8251.9, bsz=298.7, num_updates=43700, lr=6.7651e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=36362
2023-08-15 11:34:20 | INFO | train_inner | epoch 030:   1074 / 1474 loss=1.916, trans_loss=4.776, nll_loss=1.978, w2v_ctc_loss=0.621, task_loss=1.575, contrastive_loss=0.17, total=4096.17, n_correct=2814.1, ppl=3.94, accuracy=68.701, wps=11726.3, ups=1.43, wpb=8192.3, bsz=281.5, num_updates=43800, lr=6.75737e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=36432
2023-08-15 11:35:30 | INFO | train_inner | epoch 030:   1174 / 1474 loss=1.902, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.609, task_loss=1.345, contrastive_loss=0.145, total=4168.92, n_correct=2873.72, ppl=3.92, accuracy=68.932, wps=11992.5, ups=1.44, wpb=8337.8, bsz=314.8, num_updates=43900, lr=6.74967e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=36502
2023-08-15 11:36:39 | INFO | train_inner | epoch 030:   1274 / 1474 loss=1.909, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.631, task_loss=1.556, contrastive_loss=0.078, total=4038.68, n_correct=2777.63, ppl=3.94, accuracy=68.776, wps=11665.3, ups=1.44, wpb=8077.4, bsz=284.1, num_updates=44000, lr=6.742e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=36571
2023-08-15 11:36:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:37:03 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.158 | nll_loss 2.412 | w2v_ctc_loss 1.32 | task_loss 4.674 | contrastive_loss 0.297 | total 4003.4 | n_correct 2684.3 | ppl 5.32 | accuracy 67.051 | uer 17.118 | wer 18.981 | raw_wer 18.981 | bleu 22.7 | wps 2143 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.7
2023-08-15 11:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-15 11:37:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-15 11:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-15 11:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.7) (writing took 52.49361906014383 seconds)
2023-08-15 11:39:06 | INFO | train_inner | epoch 030:   1374 / 1474 loss=1.898, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.616, task_loss=1.321, contrastive_loss=0.089, total=4167.64, n_correct=2872.59, ppl=3.93, accuracy=68.926, wps=5684.7, ups=0.68, wpb=8335.3, bsz=321.9, num_updates=44100, lr=6.73435e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=36717
2023-08-15 11:40:15 | INFO | train_inner | epoch 030:   1474 / 1474 loss=1.913, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.609, task_loss=1.324, contrastive_loss=0.236, total=4117.91, n_correct=2828.63, ppl=3.94, accuracy=68.691, wps=11943, ups=1.45, wpb=8235.8, bsz=312.2, num_updates=44200, lr=6.72673e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=36786
2023-08-15 11:40:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:40:38 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.157 | nll_loss 2.412 | w2v_ctc_loss 1.293 | task_loss 4.616 | contrastive_loss 0.298 | total 4003.4 | n_correct 2685.1 | ppl 5.32 | accuracy 67.07 | uer 17.302 | wer 19.16 | raw_wer 19.16 | bleu 22.72 | wps 2175.5 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 22.72
2023-08-15 11:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-08-15 11:40:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 11:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 11:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 30 @ 44200 updates, score 22.72) (writing took 30.31017687357962 seconds)
2023-08-15 11:41:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-15 11:41:09 | INFO | train | epoch 030 | loss 1.906 | trans_loss 4.769 | nll_loss 1.97 | w2v_ctc_loss 0.62 | task_loss 1.402 | contrastive_loss 0.127 | total 4138.58 | n_correct 2850.98 | ppl 3.92 | accuracy 68.888 | wps 10495.7 | ups 1.27 | wpb 8277.2 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 16.9 | wall 36841
2023-08-15 11:41:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:41:09 | INFO | fairseq.trainer | begin training epoch 31
2023-08-15 11:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:42:27 | INFO | train_inner | epoch 031:    100 / 1474 loss=1.898, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.62, task_loss=1.478, contrastive_loss=0.081, total=4085.38, n_correct=2824.27, ppl=3.87, accuracy=69.131, wps=6181.4, ups=0.76, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=36919
2023-08-15 11:43:36 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.896, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.615, task_loss=1.449, contrastive_loss=0.092, total=4139.51, n_correct=2864.18, ppl=3.87, accuracy=69.191, wps=11943.5, ups=1.44, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=36988
2023-08-15 11:44:46 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.9, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.614, task_loss=1.437, contrastive_loss=0.142, total=4148.01, n_correct=2871.22, ppl=3.86, accuracy=69.219, wps=11876.9, ups=1.43, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=37058
2023-08-15 11:45:55 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.897, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.612, task_loss=1.531, contrastive_loss=0.076, total=4095.42, n_correct=2829.89, ppl=3.9, accuracy=69.099, wps=11800.4, ups=1.44, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=37127
2023-08-15 11:47:05 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.899, trans_loss=4.76, nll_loss=1.957, w2v_ctc_loss=0.619, task_loss=1.465, contrastive_loss=0.085, total=4115.61, n_correct=2840.69, ppl=3.88, accuracy=69.022, wps=11846.8, ups=1.44, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=37197
2023-08-15 11:48:14 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.897, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.617, task_loss=1.473, contrastive_loss=0.076, total=4075.9, n_correct=2818.53, ppl=3.88, accuracy=69.151, wps=11734.7, ups=1.44, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=37266
2023-08-15 11:49:24 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.89, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.61, task_loss=1.341, contrastive_loss=0.077, total=4208.99, n_correct=2917.27, ppl=3.86, accuracy=69.31, wps=12079.2, ups=1.43, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=37336
2023-08-15 11:50:34 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.905, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.613, task_loss=1.459, contrastive_loss=0.147, total=4104.19, n_correct=2830.7, ppl=3.9, accuracy=68.971, wps=11719.5, ups=1.43, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=15, wall=37406
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 11:51:43 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.898, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.619, task_loss=1.484, contrastive_loss=0.092, total=4099.13, n_correct=2833.03, ppl=3.86, accuracy=69.113, wps=11848.3, ups=1.45, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=37475
2023-08-15 11:52:52 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.906, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.613, task_loss=1.314, contrastive_loss=0.177, total=4186.81, n_correct=2888.3, ppl=3.92, accuracy=68.986, wps=12092.2, ups=1.44, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=37544
2023-08-15 11:54:02 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.9, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.612, task_loss=1.371, contrastive_loss=0.122, total=4149.25, n_correct=2865.86, ppl=3.9, accuracy=69.069, wps=12003, ups=1.45, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=37614
2023-08-15 11:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 11:55:11 | INFO | train_inner | epoch 031:   1201 / 1474 loss=1.905, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.607, task_loss=1.309, contrastive_loss=0.239, total=4185.5, n_correct=2892.98, ppl=3.89, accuracy=69.119, wps=11994.4, ups=1.43, wpb=8371, bsz=321, num_updates=45400, lr=6.63723e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=37683
2023-08-15 11:56:20 | INFO | train_inner | epoch 031:   1301 / 1474 loss=1.899, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.618, task_loss=1.267, contrastive_loss=0.082, total=4226.19, n_correct=2913.42, ppl=3.92, accuracy=68.937, wps=12259.8, ups=1.45, wpb=8452.4, bsz=325.1, num_updates=45500, lr=6.62994e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=37752
2023-08-15 11:57:30 | INFO | train_inner | epoch 031:   1401 / 1474 loss=1.919, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.614, task_loss=1.289, contrastive_loss=0.288, total=4192.11, n_correct=2892.21, ppl=3.91, accuracy=68.992, wps=12008.1, ups=1.43, wpb=8384.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=37822
2023-08-15 11:58:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
2023-08-15 11:58:44 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.287 | task_loss 4.638 | contrastive_loss 0.293 | total 4003.4 | n_correct 2684.3 | ppl 5.34 | accuracy 67.051 | uer 16.866 | wer 18.899 | raw_wer 18.899 | bleu 22.58 | wps 2163.8 | wpb 4003.4 | bsz 141.8 | num_updates 45673 | best_bleu 22.72
2023-08-15 11:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-08-15 11:58:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt
2023-08-15 11:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt
2023-08-15 11:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt (epoch 31 @ 45673 updates, score 22.58) (writing took 24.710560154169798 seconds)
2023-08-15 11:59:09 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-15 11:59:09 | INFO | train | epoch 031 | loss 1.901 | trans_loss 4.761 | nll_loss 1.959 | w2v_ctc_loss 0.615 | task_loss 1.405 | contrastive_loss 0.126 | total 4138.41 | n_correct 2859.15 | ppl 3.89 | accuracy 69.088 | wps 11287.4 | ups 1.36 | wpb 8276.8 | bsz 305.6 | num_updates 45673 | lr 6.61737e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 11.7 | wall 37921
2023-08-15 11:59:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:59:09 | INFO | fairseq.trainer | begin training epoch 32
2023-08-15 11:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:59:36 | INFO | train_inner | epoch 032:     27 / 1474 loss=1.896, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.619, task_loss=1.463, contrastive_loss=0.072, total=4051.41, n_correct=2803.04, ppl=3.88, accuracy=69.187, wps=6447.7, ups=0.8, wpb=8102.8, bsz=291.6, num_updates=45700, lr=6.61541e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=37948
2023-08-15 12:00:45 | INFO | train_inner | epoch 032:    127 / 1474 loss=1.88, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.598, task_loss=1.316, contrastive_loss=0.082, total=4208.32, n_correct=2928.58, ppl=3.81, accuracy=69.59, wps=12144.5, ups=1.44, wpb=8416.6, bsz=319.1, num_updates=45800, lr=6.60819e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=11.2, wall=38017
2023-08-15 12:01:55 | INFO | train_inner | epoch 032:    227 / 1474 loss=1.891, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.612, task_loss=1.34, contrastive_loss=0.092, total=4157.86, n_correct=2880.16, ppl=3.87, accuracy=69.27, wps=11949, ups=1.44, wpb=8315.7, bsz=320.3, num_updates=45900, lr=6.60098e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=38087
2023-08-15 12:03:04 | INFO | train_inner | epoch 032:    327 / 1474 loss=1.883, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.6, task_loss=1.336, contrastive_loss=0.086, total=4179.17, n_correct=2908.12, ppl=3.82, accuracy=69.586, wps=12017.2, ups=1.44, wpb=8358.3, bsz=313.4, num_updates=46000, lr=6.5938e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=38156
2023-08-15 12:03:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:03:28 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.166 | nll_loss 2.423 | w2v_ctc_loss 1.345 | task_loss 4.631 | contrastive_loss 0.289 | total 4003.4 | n_correct 2684 | ppl 5.36 | accuracy 67.043 | uer 17.126 | wer 18.94 | raw_wer 18.94 | bleu 22.51 | wps 2140.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.72
2023-08-15 12:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-15 12:03:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 12:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 12:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.51) (writing took 39.458953980356455 seconds)
2023-08-15 12:05:22 | INFO | train_inner | epoch 032:    427 / 1474 loss=1.887, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.609, task_loss=1.359, contrastive_loss=0.082, total=4179.5, n_correct=2901.88, ppl=3.83, accuracy=69.431, wps=6073.7, ups=0.73, wpb=8359, bsz=312.2, num_updates=46100, lr=6.58665e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=17.5, wall=38294
2023-08-15 12:06:32 | INFO | train_inner | epoch 032:    527 / 1474 loss=1.904, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.615, task_loss=1.381, contrastive_loss=0.166, total=4188.83, n_correct=2895.28, ppl=3.87, accuracy=69.119, wps=12004.5, ups=1.43, wpb=8377.7, bsz=313.9, num_updates=46200, lr=6.57952e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=38364
2023-08-15 12:07:42 | INFO | train_inner | epoch 032:    627 / 1474 loss=1.898, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.617, task_loss=1.477, contrastive_loss=0.089, total=4133.19, n_correct=2855.47, ppl=3.88, accuracy=69.086, wps=11752.4, ups=1.42, wpb=8266.4, bsz=298.7, num_updates=46300, lr=6.57241e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=38434
2023-08-15 12:08:52 | INFO | train_inner | epoch 032:    727 / 1474 loss=1.895, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.618, task_loss=1.414, contrastive_loss=0.074, total=4162.1, n_correct=2879.7, ppl=3.87, accuracy=69.189, wps=11888.8, ups=1.43, wpb=8324.2, bsz=304.3, num_updates=46400, lr=6.56532e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=15.6, wall=38504
2023-08-15 12:10:02 | INFO | train_inner | epoch 032:    827 / 1474 loss=1.89, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.608, task_loss=1.463, contrastive_loss=0.071, total=4107.86, n_correct=2845.55, ppl=3.86, accuracy=69.271, wps=11786.7, ups=1.43, wpb=8215.7, bsz=292.6, num_updates=46500, lr=6.55826e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=38574
2023-08-15 12:11:11 | INFO | train_inner | epoch 032:    927 / 1474 loss=1.888, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.605, task_loss=1.436, contrastive_loss=0.069, total=4146.9, n_correct=2873.97, ppl=3.86, accuracy=69.304, wps=11975.4, ups=1.44, wpb=8293.8, bsz=300.4, num_updates=46600, lr=6.55122e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=38643
2023-08-15 12:12:20 | INFO | train_inner | epoch 032:   1027 / 1474 loss=1.903, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.616, task_loss=1.395, contrastive_loss=0.164, total=4112.45, n_correct=2842.91, ppl=3.88, accuracy=69.129, wps=11904.5, ups=1.45, wpb=8224.9, bsz=304.3, num_updates=46700, lr=6.5442e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=38712
2023-08-15 12:13:30 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.901, trans_loss=4.754, nll_loss=1.949, w2v_ctc_loss=0.616, task_loss=1.671, contrastive_loss=0.107, total=4015.2, n_correct=2774.52, ppl=3.86, accuracy=69.1, wps=11510.4, ups=1.43, wpb=8030.4, bsz=269.7, num_updates=46800, lr=6.5372e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=38782
2023-08-15 12:14:40 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.914, trans_loss=4.766, nll_loss=1.967, w2v_ctc_loss=0.614, task_loss=1.376, contrastive_loss=0.218, total=4158.99, n_correct=2866.99, ppl=3.91, accuracy=68.935, wps=11888.3, ups=1.43, wpb=8318, bsz=312.1, num_updates=46900, lr=6.53023e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=38852
2023-08-15 12:15:48 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.894, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.617, task_loss=1.436, contrastive_loss=0.069, total=4079.56, n_correct=2820.04, ppl=3.87, accuracy=69.126, wps=11910.6, ups=1.46, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=38920
2023-08-15 12:16:57 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.919, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.623, task_loss=1.423, contrastive_loss=0.307, total=4107.37, n_correct=2834.63, ppl=3.89, accuracy=69.013, wps=11941.1, ups=1.45, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=38989
2023-08-15 12:17:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:17:53 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.154 | nll_loss 2.411 | w2v_ctc_loss 1.318 | task_loss 4.633 | contrastive_loss 0.293 | total 4003.4 | n_correct 2684.1 | ppl 5.32 | accuracy 67.046 | uer 17.033 | wer 18.922 | raw_wer 18.922 | bleu 22.82 | wps 2249.5 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 22.82
2023-08-15 12:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-08-15 12:17:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 12:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 12:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 32 @ 47147 updates, score 22.82) (writing took 29.111364552751184 seconds)
2023-08-15 12:18:22 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-15 12:18:22 | INFO | train | epoch 032 | loss 1.896 | trans_loss 4.753 | nll_loss 1.949 | w2v_ctc_loss 0.611 | task_loss 1.405 | contrastive_loss 0.124 | total 4138.65 | n_correct 2865.38 | ppl 3.86 | accuracy 69.235 | wps 10578.3 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.533 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 16.2 | wall 39074
2023-08-15 12:18:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 12:18:23 | INFO | fairseq.trainer | begin training epoch 33
2023-08-15 12:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 12:19:08 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.895, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.6, task_loss=1.333, contrastive_loss=0.173, total=4146.91, n_correct=2875.88, ppl=3.85, accuracy=69.35, wps=6355.5, ups=0.77, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=39120
2023-08-15 12:20:17 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.882, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.596, task_loss=1.506, contrastive_loss=0.062, total=4073.36, n_correct=2829.57, ppl=3.81, accuracy=69.465, wps=11797.4, ups=1.45, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=39189
2023-08-15 12:21:26 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.898, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.601, task_loss=1.191, contrastive_loss=0.237, total=4283.64, n_correct=2978.45, ppl=3.82, accuracy=69.531, wps=12341.6, ups=1.44, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=39258
2023-08-15 12:22:35 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.892, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.612, task_loss=1.43, contrastive_loss=0.089, total=4131.27, n_correct=2861.58, ppl=3.84, accuracy=69.266, wps=11974.2, ups=1.45, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=39327
2023-08-15 12:23:44 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.873, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.592, task_loss=1.335, contrastive_loss=0.068, total=4135.1, n_correct=2883.86, ppl=3.79, accuracy=69.741, wps=12012.8, ups=1.45, wpb=8270.2, bsz=309.7, num_updates=47600, lr=6.48204e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=39396
2023-08-15 12:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 12:24:54 | INFO | train_inner | epoch 033:    554 / 1474 loss=1.896, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.615, task_loss=1.458, contrastive_loss=0.092, total=4131.65, n_correct=2860.47, ppl=3.85, accuracy=69.233, wps=11774.9, ups=1.42, wpb=8263.3, bsz=294.4, num_updates=47700, lr=6.47524e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=14.6, wall=39466
2023-08-15 12:26:03 | INFO | train_inner | epoch 033:    654 / 1474 loss=1.895, trans_loss=4.756, nll_loss=1.951, w2v_ctc_loss=0.604, task_loss=1.447, contrastive_loss=0.124, total=4155.56, n_correct=2875.7, ppl=3.87, accuracy=69.201, wps=12000.9, ups=1.44, wpb=8311.1, bsz=300.4, num_updates=47800, lr=6.46846e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=39535
2023-08-15 12:27:12 | INFO | train_inner | epoch 033:    754 / 1474 loss=1.897, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.623, task_loss=1.505, contrastive_loss=0.07, total=4076.72, n_correct=2820.01, ppl=3.86, accuracy=69.174, wps=11852, ups=1.45, wpb=8153.4, bsz=289.6, num_updates=47900, lr=6.46171e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=39604
2023-08-15 12:28:22 | INFO | train_inner | epoch 033:    854 / 1474 loss=1.883, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.594, task_loss=1.347, contrastive_loss=0.14, total=4126.23, n_correct=2871.83, ppl=3.82, accuracy=69.599, wps=11875.8, ups=1.44, wpb=8252.5, bsz=314.4, num_updates=48000, lr=6.45497e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=39674
2023-08-15 12:28:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:28:45 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.332 | task_loss 4.628 | contrastive_loss 0.298 | total 4003.4 | n_correct 2681.3 | ppl 5.34 | accuracy 66.976 | uer 17.158 | wer 19.037 | raw_wer 19.037 | bleu 22.18 | wps 2201.9 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.82
2023-08-15 12:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-15 12:28:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 12:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 12:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.18) (writing took 21.901326628401875 seconds)
2023-08-15 12:30:17 | INFO | train_inner | epoch 033:    954 / 1474 loss=1.891, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.614, task_loss=1.383, contrastive_loss=0.084, total=4161.72, n_correct=2885.19, ppl=3.85, accuracy=69.327, wps=7218, ups=0.87, wpb=8323.4, bsz=312, num_updates=48100, lr=6.44826e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=39789
2023-08-15 12:31:27 | INFO | train_inner | epoch 033:   1054 / 1474 loss=1.897, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.607, task_loss=1.421, contrastive_loss=0.182, total=4134.8, n_correct=2868.27, ppl=3.82, accuracy=69.369, wps=11853.8, ups=1.43, wpb=8269.6, bsz=304.7, num_updates=48200, lr=6.44157e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=39859
2023-08-15 12:32:37 | INFO | train_inner | epoch 033:   1154 / 1474 loss=1.896, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.598, task_loss=1.414, contrastive_loss=0.174, total=4177.62, n_correct=2895.01, ppl=3.87, accuracy=69.298, wps=11989.9, ups=1.44, wpb=8355.2, bsz=309.6, num_updates=48300, lr=6.43489e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=39928
2023-08-15 12:33:46 | INFO | train_inner | epoch 033:   1254 / 1474 loss=1.887, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.609, task_loss=1.471, contrastive_loss=0.074, total=4115.15, n_correct=2859.72, ppl=3.83, accuracy=69.492, wps=11792.4, ups=1.43, wpb=8230.3, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=39998
2023-08-15 12:34:56 | INFO | train_inner | epoch 033:   1354 / 1474 loss=1.887, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.607, task_loss=1.38, contrastive_loss=0.092, total=4121.6, n_correct=2863.35, ppl=3.84, accuracy=69.472, wps=11774.2, ups=1.43, wpb=8243.2, bsz=311.7, num_updates=48500, lr=6.42161e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=40068
2023-08-15 12:35:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 12:36:06 | INFO | train_inner | epoch 033:   1455 / 1474 loss=1.899, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.6, task_loss=1.384, contrastive_loss=0.24, total=4136.35, n_correct=2864.88, ppl=3.85, accuracy=69.261, wps=11834.7, ups=1.43, wpb=8272.7, bsz=311, num_updates=48600, lr=6.415e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=40138
2023-08-15 12:36:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:36:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.16 | nll_loss 2.414 | w2v_ctc_loss 1.352 | task_loss 4.628 | contrastive_loss 0.289 | total 4003.4 | n_correct 2687.7 | ppl 5.33 | accuracy 67.135 | uer 16.887 | wer 18.802 | raw_wer 18.802 | bleu 22.4 | wps 2231.5 | wpb 4003.4 | bsz 141.8 | num_updates 48619 | best_bleu 22.82
2023-08-15 12:36:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48619 updates
2023-08-15 12:36:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 12:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 12:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48619 updates, score 22.4) (writing took 16.58786521665752 seconds)
2023-08-15 12:36:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-15 12:36:59 | INFO | train | epoch 033 | loss 1.891 | trans_loss 4.746 | nll_loss 1.94 | w2v_ctc_loss 0.605 | task_loss 1.403 | contrastive_loss 0.123 | total 4138.82 | n_correct 2872 | ppl 3.84 | accuracy 69.392 | wps 10914.8 | ups 1.32 | wpb 8277.6 | bsz 305.8 | num_updates 48619 | lr 6.41375e-05 | gnorm 0.533 | clip 0 | loss_scale 8 | train_wall 1015 | gb_free 17.6 | wall 40191
2023-08-15 12:36:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 12:36:59 | INFO | fairseq.trainer | begin training epoch 34
2023-08-15 12:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 12:38:04 | INFO | train_inner | epoch 034:     81 / 1474 loss=1.881, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.602, task_loss=1.407, contrastive_loss=0.075, total=4113.07, n_correct=2863.75, ppl=3.8, accuracy=69.626, wps=7011.3, ups=0.85, wpb=8226.1, bsz=298.8, num_updates=48700, lr=6.40841e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=40256
2023-08-15 12:39:13 | INFO | train_inner | epoch 034:    181 / 1474 loss=1.876, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.599, task_loss=1.466, contrastive_loss=0.075, total=4069.22, n_correct=2841.8, ppl=3.77, accuracy=69.836, wps=11694.3, ups=1.44, wpb=8138.4, bsz=295.5, num_updates=48800, lr=6.40184e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=12.3, wall=40325
2023-08-15 12:40:23 | INFO | train_inner | epoch 034:    281 / 1474 loss=1.903, trans_loss=4.746, nll_loss=1.939, w2v_ctc_loss=0.595, task_loss=1.302, contrastive_loss=0.285, total=4252.78, n_correct=2954.88, ppl=3.84, accuracy=69.481, wps=12168.4, ups=1.43, wpb=8505.6, bsz=331.2, num_updates=48900, lr=6.39529e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=40395
2023-08-15 12:41:32 | INFO | train_inner | epoch 034:    381 / 1474 loss=1.885, trans_loss=4.728, nll_loss=1.918, w2v_ctc_loss=0.595, task_loss=1.341, contrastive_loss=0.179, total=4151.69, n_correct=2895.11, ppl=3.78, accuracy=69.733, wps=12041.1, ups=1.45, wpb=8303.4, bsz=316.4, num_updates=49000, lr=6.38877e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=68, gb_free=15.6, wall=40464
2023-08-15 12:42:42 | INFO | train_inner | epoch 034:    481 / 1474 loss=1.886, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.608, task_loss=1.53, contrastive_loss=0.068, total=4078.14, n_correct=2835.3, ppl=3.81, accuracy=69.524, wps=11726, ups=1.44, wpb=8156.3, bsz=284.7, num_updates=49100, lr=6.38226e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=40534
2023-08-15 12:43:51 | INFO | train_inner | epoch 034:    581 / 1474 loss=1.875, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.594, task_loss=1.409, contrastive_loss=0.071, total=4130.95, n_correct=2885.43, ppl=3.78, accuracy=69.849, wps=11961.9, ups=1.45, wpb=8261.9, bsz=302, num_updates=49200, lr=6.37577e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=69, gb_free=17.3, wall=40603
2023-08-15 12:45:00 | INFO | train_inner | epoch 034:    681 / 1474 loss=1.881, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.601, task_loss=1.447, contrastive_loss=0.067, total=4110.04, n_correct=2857.74, ppl=3.81, accuracy=69.531, wps=11933.2, ups=1.45, wpb=8220.1, bsz=296.9, num_updates=49300, lr=6.3693e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=40672
2023-08-15 12:46:08 | INFO | train_inner | epoch 034:    781 / 1474 loss=1.893, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.598, task_loss=1.463, contrastive_loss=0.135, total=4079.01, n_correct=2826.77, ppl=3.87, accuracy=69.3, wps=11863.6, ups=1.45, wpb=8158, bsz=295.7, num_updates=49400, lr=6.36285e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=40740
2023-08-15 12:47:18 | INFO | train_inner | epoch 034:    881 / 1474 loss=1.888, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.606, task_loss=1.487, contrastive_loss=0.094, total=4092.48, n_correct=2841.77, ppl=3.83, accuracy=69.439, wps=11730, ups=1.43, wpb=8185, bsz=295.5, num_updates=49500, lr=6.35642e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=40810
2023-08-15 12:48:28 | INFO | train_inner | epoch 034:    981 / 1474 loss=1.887, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.608, task_loss=1.363, contrastive_loss=0.09, total=4185.89, n_correct=2907.72, ppl=3.83, accuracy=69.465, wps=11943, ups=1.43, wpb=8371.8, bsz=315, num_updates=49600, lr=6.35001e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=40880
2023-08-15 12:49:37 | INFO | train_inner | epoch 034:   1081 / 1474 loss=1.882, trans_loss=4.74, nll_loss=1.931, w2v_ctc_loss=0.606, task_loss=1.368, contrastive_loss=0.071, total=4142.31, n_correct=2881.8, ppl=3.81, accuracy=69.57, wps=12005.4, ups=1.45, wpb=8284.6, bsz=306.1, num_updates=49700, lr=6.34361e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=69, gb_free=17.6, wall=40949
2023-08-15 12:50:46 | INFO | train_inner | epoch 034:   1181 / 1474 loss=1.885, trans_loss=4.742, nll_loss=1.934, w2v_ctc_loss=0.603, task_loss=1.445, contrastive_loss=0.085, total=4101.07, n_correct=2849.57, ppl=3.82, accuracy=69.484, wps=11884.4, ups=1.45, wpb=8202.1, bsz=297.9, num_updates=49800, lr=6.33724e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=69, gb_free=14.5, wall=41018
2023-08-15 12:51:55 | INFO | train_inner | epoch 034:   1281 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.605, task_loss=1.416, contrastive_loss=0.069, total=4150.75, n_correct=2888.79, ppl=3.8, accuracy=69.597, wps=12043.7, ups=1.45, wpb=8301.5, bsz=301.4, num_updates=49900, lr=6.33089e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=41087
2023-08-15 12:53:05 | INFO | train_inner | epoch 034:   1381 / 1474 loss=1.895, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.612, task_loss=1.345, contrastive_loss=0.136, total=4194.17, n_correct=2906.59, ppl=3.84, accuracy=69.301, wps=11972.8, ups=1.43, wpb=8388.3, bsz=320.1, num_updates=50000, lr=6.32456e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=70, gb_free=15.5, wall=41157
2023-08-15 12:53:05 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-15 12:53:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:53:28 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.156 | nll_loss 2.408 | w2v_ctc_loss 1.322 | task_loss 4.63 | contrastive_loss 0.284 | total 4003.4 | n_correct 2687.4 | ppl 5.31 | accuracy 67.128 | uer 16.699 | wer 18.463 | raw_wer 18.463 | bleu 22.67 | wps 2242.5 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.82
2023-08-15 12:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-15 12:53:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 12:53:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 12:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.67) (writing took 40.37162771075964 seconds)
2023-08-15 12:54:10 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-15 12:54:10 | INFO | train | epoch 034 | loss 1.886 | trans_loss 4.739 | nll_loss 1.931 | w2v_ctc_loss 0.602 | task_loss 1.412 | contrastive_loss 0.11 | total 4132.8 | n_correct 2874.54 | ppl 3.81 | accuracy 69.554 | wps 11069.8 | ups 1.34 | wpb 8265.6 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.537 | clip 0 | loss_scale 8 | train_wall 951 | gb_free 15.5 | wall 41222
2023-08-15 12:54:10 | INFO | fairseq_cli.train | done training in 41170.4 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
