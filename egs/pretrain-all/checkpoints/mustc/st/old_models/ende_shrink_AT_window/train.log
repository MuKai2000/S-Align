2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12923
2023-07-11 14:35:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-11 14:35:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-11 14:35:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-11 14:35:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-11 14:35:43 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-11 14:35:43 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-11 14:35:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_window', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12923', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_window', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-11 14:35:45 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-11 14:35:45 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-11 14:35:45 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-11 14:35:45 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-11 14:35:45 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-11 14:35:50 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-11 14:35:50 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-11 14:35:50 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-11 14:35:51 | INFO | root | load pretrained hubert
2023-07-11 14:35:55 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-11 14:35:56 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-11 14:35:59 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-11 14:35:59 | INFO | root | share the sematic adapter and textual encoder
2023-07-11 14:35:59 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-11 14:35:59 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-11 14:35:59 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-11 14:35:59 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-11 14:35:59 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-11 14:35:59 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-11 14:35:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-11 14:35:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-11 14:35:59 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-11 14:35:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-11 14:36:06 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-11 14:36:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-11 14:36:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-11 14:36:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-11 14:36:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-11 14:36:07 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-11 14:36:07 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-11 14:36:07 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-11 14:36:07 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-11 14:36:07 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-11 14:36:07 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-11 14:36:07 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-11 14:36:07 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-11 14:36:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-11 14:36:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-11 14:36:13 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-11 14:37:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 14:37:18 | INFO | fairseq.trainer | begin training epoch 1
2023-07-11 14:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 14:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 14:38:31 | INFO | train_inner | epoch 001:    101 / 1474 loss=13.905, trans_loss=5.638, nll_loss=4.213, w2v_ctc_loss=15.061, task_loss=0.778, contrastive_loss=3.311, total=4200.41, n_correct=212.66, ppl=18.55, accuracy=5.063, wps=19364.4, ups=1.54, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.625, clip=0, loss_scale=64, train_wall=66, gb_free=19, wall=144
2023-07-11 14:39:34 | INFO | train_inner | epoch 001:    201 / 1474 loss=12.435, trans_loss=5.453, nll_loss=4.041, w2v_ctc_loss=12.97, task_loss=0.76, contrastive_loss=3.287, total=4127.38, n_correct=248.79, ppl=16.46, accuracy=6.028, wps=19447.3, ups=1.58, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=2.43, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=207
2023-07-11 14:40:37 | INFO | train_inner | epoch 001:    301 / 1474 loss=7.797, trans_loss=5.442, nll_loss=4.084, w2v_ctc_loss=5.895, task_loss=0.785, contrastive_loss=3.201, total=4079.62, n_correct=235.37, ppl=16.96, accuracy=5.769, wps=19373.6, ups=1.59, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=3.122, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=270
2023-07-11 14:41:40 | INFO | train_inner | epoch 001:    401 / 1474 loss=6.957, trans_loss=5.484, nll_loss=4.156, w2v_ctc_loss=4.567, task_loss=0.679, contrastive_loss=3.234, total=4174.14, n_correct=220.31, ppl=17.82, accuracy=5.278, wps=19784.6, ups=1.59, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.016, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=333
2023-07-11 14:42:44 | INFO | train_inner | epoch 001:    501 / 1474 loss=6.651, trans_loss=5.457, nll_loss=4.132, w2v_ctc_loss=4.124, task_loss=0.585, contrastive_loss=3.228, total=4176.18, n_correct=216.9, ppl=17.54, accuracy=5.194, wps=19793, ups=1.58, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=396
2023-07-11 14:43:46 | INFO | train_inner | epoch 001:    601 / 1474 loss=6.479, trans_loss=5.485, nll_loss=4.173, w2v_ctc_loss=3.882, task_loss=0.531, contrastive_loss=3.282, total=4147.79, n_correct=210.09, ppl=18.04, accuracy=5.065, wps=19661.7, ups=1.59, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.495, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=459
2023-07-11 14:44:49 | INFO | train_inner | epoch 001:    701 / 1474 loss=6.393, trans_loss=5.478, nll_loss=4.171, w2v_ctc_loss=3.818, task_loss=0.552, contrastive_loss=3.033, total=4152.1, n_correct=221.72, ppl=18.01, accuracy=5.34, wps=19877.6, ups=1.61, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=62, gb_free=19.5, wall=521
2023-07-11 14:45:51 | INFO | train_inner | epoch 001:    801 / 1474 loss=6.204, trans_loss=5.436, nll_loss=4.122, w2v_ctc_loss=3.659, task_loss=0.536, contrastive_loss=2.928, total=4123.83, n_correct=252.49, ppl=17.42, accuracy=6.123, wps=19752.5, ups=1.6, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=62, gb_free=19.1, wall=584
2023-07-11 14:46:53 | INFO | train_inner | epoch 001:    901 / 1474 loss=6.048, trans_loss=5.412, nll_loss=4.108, w2v_ctc_loss=3.552, task_loss=0.545, contrastive_loss=2.681, total=4163.61, n_correct=274.82, ppl=17.25, accuracy=6.601, wps=19954, ups=1.61, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.909, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=646
2023-07-11 14:47:56 | INFO | train_inner | epoch 001:   1001 / 1474 loss=5.857, trans_loss=5.389, nll_loss=4.085, w2v_ctc_loss=3.393, task_loss=0.547, contrastive_loss=2.538, total=4135.34, n_correct=297.19, ppl=16.97, accuracy=7.187, wps=19764.1, ups=1.6, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=708
2023-07-11 14:48:58 | INFO | train_inner | epoch 001:   1101 / 1474 loss=5.693, trans_loss=5.385, nll_loss=4.084, w2v_ctc_loss=3.268, task_loss=0.553, contrastive_loss=2.317, total=4147.38, n_correct=312.78, ppl=16.95, accuracy=7.542, wps=19803.1, ups=1.6, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.11, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=771
2023-07-11 14:50:01 | INFO | train_inner | epoch 001:   1201 / 1474 loss=5.532, trans_loss=5.364, nll_loss=4.062, w2v_ctc_loss=3.144, task_loss=0.577, contrastive_loss=2.109, total=4139.9, n_correct=325.99, ppl=16.7, accuracy=7.874, wps=19834.4, ups=1.6, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.165, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=833
2023-07-11 14:51:02 | INFO | train_inner | epoch 001:   1301 / 1474 loss=5.376, trans_loss=5.364, nll_loss=4.064, w2v_ctc_loss=3.01, task_loss=0.559, contrastive_loss=1.924, total=4046.58, n_correct=321.2, ppl=16.73, accuracy=7.938, wps=19573.8, ups=1.62, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.126, clip=0, loss_scale=64, train_wall=61, gb_free=19.7, wall=895
2023-07-11 14:52:05 | INFO | train_inner | epoch 001:   1401 / 1474 loss=5.267, trans_loss=5.356, nll_loss=4.067, w2v_ctc_loss=2.897, task_loss=0.547, contrastive_loss=1.997, total=4133.18, n_correct=332.42, ppl=16.76, accuracy=8.043, wps=19773, ups=1.61, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.136, clip=0, loss_scale=64, train_wall=62, gb_free=19.9, wall=957
2023-07-11 14:52:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-11 14:53:24 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 7.771 | trans_loss 10.947 | nll_loss 9.939 | w2v_ctc_loss 4.535 | task_loss 7.28 | contrastive_loss 2.322 | total 4003.4 | n_correct 373.3 | ppl 981.61 | accuracy 9.325 | uer 71.34 | wer 69.39 | raw_wer 69.39 | bleu 0.02 | wps 1455.9 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-11 14:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-11 14:53:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 14:53:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 14:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 4.8259642900084145 seconds)
2023-07-11 14:53:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-11 14:53:29 | INFO | train | epoch 001 | loss 7.092 | trans_loss 5.435 | nll_loss 4.109 | w2v_ctc_loss 5.12 | task_loss 0.605 | contrastive_loss 2.75 | total 4138.32 | n_correct 266.686 | ppl 17.25 | accuracy 6.444 | wps 18909.3 | ups 1.53 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.207 | clip 0 | loss_scale 64 | train_wall 919 | gb_free 19.2 | wall 1041
2023-07-11 14:53:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 14:53:29 | INFO | fairseq.trainer | begin training epoch 2
2023-07-11 14:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 14:53:53 | INFO | train_inner | epoch 002:     27 / 1474 loss=5.136, trans_loss=5.351, nll_loss=4.05, w2v_ctc_loss=2.759, task_loss=0.522, contrastive_loss=1.84, total=4162.95, n_correct=337.62, ppl=16.57, accuracy=8.11, wps=11458.9, ups=0.92, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.079, clip=0, loss_scale=64, train_wall=62, gb_free=19.6, wall=1066
2023-07-11 14:54:55 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.026, trans_loss=5.354, nll_loss=4.055, w2v_ctc_loss=2.676, task_loss=0.557, contrastive_loss=1.639, total=4155.98, n_correct=341.02, ppl=16.62, accuracy=8.206, wps=19909.4, ups=1.61, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.093, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1128
2023-07-11 14:55:58 | INFO | train_inner | epoch 002:    227 / 1474 loss=4.888, trans_loss=5.328, nll_loss=4.025, w2v_ctc_loss=2.532, task_loss=0.487, contrastive_loss=1.673, total=4179.21, n_correct=348.2, ppl=16.28, accuracy=8.332, wps=19950.6, ups=1.6, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1190
2023-07-11 14:57:01 | INFO | train_inner | epoch 002:    327 / 1474 loss=4.81, trans_loss=5.33, nll_loss=4.024, w2v_ctc_loss=2.482, task_loss=0.555, contrastive_loss=1.387, total=4146.1, n_correct=349.17, ppl=16.27, accuracy=8.422, wps=19675, ups=1.59, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=1253
2023-07-11 14:58:03 | INFO | train_inner | epoch 002:    427 / 1474 loss=4.722, trans_loss=5.318, nll_loss=4.015, w2v_ctc_loss=2.423, task_loss=0.608, contrastive_loss=1.205, total=4037.99, n_correct=336.42, ppl=16.17, accuracy=8.331, wps=19498.1, ups=1.61, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.998, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=1315
2023-07-11 14:59:05 | INFO | train_inner | epoch 002:    527 / 1474 loss=4.653, trans_loss=5.307, nll_loss=3.995, w2v_ctc_loss=2.316, task_loss=0.529, contrastive_loss=1.308, total=4176.97, n_correct=362.34, ppl=15.95, accuracy=8.675, wps=20090.2, ups=1.61, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.905, clip=0, loss_scale=64, train_wall=62, gb_free=19.6, wall=1377
2023-07-11 14:59:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 14:59:39 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 7.297 | trans_loss 10.804 | nll_loss 9.749 | w2v_ctc_loss 3.674 | task_loss 7.268 | contrastive_loss 1.628 | total 4003.4 | n_correct 397.9 | ppl 860.71 | accuracy 9.939 | uer 62.042 | wer 59.606 | raw_wer 59.606 | bleu 0.03 | wps 1453.2 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-07-11 14:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-11 14:59:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_2_2000.pt
2023-07-11 14:59:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_2_2000.pt
2023-07-11 14:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 10.163023869972676 seconds)
2023-07-11 15:00:51 | INFO | train_inner | epoch 002:    627 / 1474 loss=4.558, trans_loss=5.298, nll_loss=3.987, w2v_ctc_loss=2.246, task_loss=0.55, contrastive_loss=1.103, total=4126.49, n_correct=364.55, ppl=15.86, accuracy=8.834, wps=11546.8, ups=0.94, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.813, clip=0, loss_scale=128, train_wall=62, gb_free=19.2, wall=1484
2023-07-11 15:01:53 | INFO | train_inner | epoch 002:    727 / 1474 loss=4.493, trans_loss=5.279, nll_loss=3.966, w2v_ctc_loss=2.18, task_loss=0.537, contrastive_loss=1.203, total=4149.06, n_correct=375.35, ppl=15.63, accuracy=9.047, wps=19949.1, ups=1.61, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.754, clip=0, loss_scale=128, train_wall=62, gb_free=19.2, wall=1546
2023-07-11 15:02:56 | INFO | train_inner | epoch 002:    827 / 1474 loss=4.46, trans_loss=5.272, nll_loss=3.956, w2v_ctc_loss=2.143, task_loss=0.549, contrastive_loss=1.154, total=4175.4, n_correct=379.86, ppl=15.52, accuracy=9.098, wps=19977, ups=1.6, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.694, clip=0, loss_scale=128, train_wall=62, gb_free=19.8, wall=1608
2023-07-11 15:03:58 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.395, trans_loss=5.262, nll_loss=3.946, w2v_ctc_loss=2.078, task_loss=0.561, contrastive_loss=1.132, total=4104.2, n_correct=376.29, ppl=15.41, accuracy=9.168, wps=19673.3, ups=1.61, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.687, clip=0, loss_scale=128, train_wall=62, gb_free=19, wall=1671
2023-07-11 15:05:00 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.329, trans_loss=5.255, nll_loss=3.935, w2v_ctc_loss=2.023, task_loss=0.546, contrastive_loss=0.989, total=4102.5, n_correct=381.37, ppl=15.3, accuracy=9.296, wps=19816.1, ups=1.61, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.608, clip=0, loss_scale=128, train_wall=61, gb_free=19.2, wall=1733
2023-07-11 15:06:03 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.31, trans_loss=5.246, nll_loss=3.925, w2v_ctc_loss=1.973, task_loss=0.497, contrastive_loss=1.201, total=4187.61, n_correct=398.26, ppl=15.19, accuracy=9.51, wps=19847, ups=1.59, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.573, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1795
2023-07-11 15:07:05 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.258, trans_loss=5.239, nll_loss=3.917, w2v_ctc_loss=1.935, task_loss=0.5, contrastive_loss=1.122, total=4221.06, n_correct=410.2, ppl=15.11, accuracy=9.718, wps=20213.9, ups=1.61, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.541, clip=0, loss_scale=128, train_wall=62, gb_free=19.4, wall=1858
2023-07-11 15:08:07 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.2, trans_loss=5.219, nll_loss=3.897, w2v_ctc_loss=1.913, task_loss=0.528, contrastive_loss=0.835, total=4157.86, n_correct=414.53, ppl=14.9, accuracy=9.97, wps=20039.2, ups=1.61, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.516, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1920
2023-07-11 15:09:10 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.18, trans_loss=5.224, nll_loss=3.898, w2v_ctc_loss=1.883, task_loss=0.59, contrastive_loss=0.926, total=4054.34, n_correct=401.56, ppl=14.91, accuracy=9.904, wps=19241.4, ups=1.59, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.497, clip=0, loss_scale=128, train_wall=63, gb_free=19.4, wall=1983
2023-07-11 15:09:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 15:10:14 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 6.667 | trans_loss 10.29 | nll_loss 9.1 | w2v_ctc_loss 2.916 | task_loss 7.24 | contrastive_loss 0.991 | total 4003.4 | n_correct 507.2 | ppl 548.62 | accuracy 12.669 | uer 51.602 | wer 50.382 | raw_wer 50.382 | bleu 0.12 | wps 1438.3 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-07-11 15:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-11 15:10:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 8.216419213975314 seconds)
2023-07-11 15:10:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-11 15:10:22 | INFO | train | epoch 002 | loss 4.52 | trans_loss 5.28 | nll_loss 3.967 | w2v_ctc_loss 2.2 | task_loss 0.541 | contrastive_loss 1.208 | total 4138.65 | n_correct 374.602 | ppl 15.63 | accuracy 9.051 | wps 17972.2 | ups 1.45 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.761 | clip 0 | loss_scale 128 | train_wall 912 | gb_free 19.3 | wall 2055
2023-07-11 15:10:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 15:10:22 | INFO | fairseq.trainer | begin training epoch 3
2023-07-11 15:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 15:11:03 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.137, trans_loss=5.202, nll_loss=3.872, w2v_ctc_loss=1.853, task_loss=0.554, contrastive_loss=0.821, total=4071.2, n_correct=416.4, ppl=14.64, accuracy=10.228, wps=10762.8, ups=0.89, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.485, clip=0, loss_scale=128, train_wall=62, gb_free=19.1, wall=2096
2023-07-11 15:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 15:11:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 15:11:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 15:11:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-11 15:12:35 | INFO | train_inner | epoch 003:    157 / 1474 loss=3.662, trans_loss=4.469, nll_loss=2.914, w2v_ctc_loss=1.638, task_loss=0.47, contrastive_loss=0.685, total=4140.89, n_correct=1067.44, ppl=7.54, accuracy=25.778, wps=13387, ups=1.08, wpb=12365.4, bsz=455.4, num_updates=3100, lr=0.000124038, gnorm=1.155, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=2188
2023-07-11 15:14:06 | INFO | train_inner | epoch 003:    257 / 1474 loss=3.378, trans_loss=4.188, nll_loss=2.544, w2v_ctc_loss=1.46, task_loss=0.475, contrastive_loss=0.579, total=4146.68, n_correct=1376.09, ppl=5.83, accuracy=33.185, wps=13697.9, ups=1.1, wpb=12407.9, bsz=461.7, num_updates=3200, lr=0.000128036, gnorm=0.788, clip=0, loss_scale=8, train_wall=90, gb_free=15.4, wall=2279
2023-07-11 15:15:36 | INFO | train_inner | epoch 003:    357 / 1474 loss=3.285, trans_loss=4.097, nll_loss=2.424, w2v_ctc_loss=1.388, task_loss=0.465, contrastive_loss=0.654, total=4171.72, n_correct=1511.62, ppl=5.37, accuracy=36.235, wps=13875.5, ups=1.12, wpb=12430.3, bsz=468.1, num_updates=3300, lr=0.000132034, gnorm=0.794, clip=0, loss_scale=8, train_wall=89, gb_free=17.7, wall=2368
2023-07-11 15:17:06 | INFO | train_inner | epoch 003:    457 / 1474 loss=3.187, trans_loss=4.019, nll_loss=2.323, w2v_ctc_loss=1.33, task_loss=0.459, contrastive_loss=0.493, total=4200.59, n_correct=1634.95, ppl=5, accuracy=38.922, wps=13816.7, ups=1.1, wpb=12508.3, bsz=475.4, num_updates=3400, lr=0.000136032, gnorm=0.707, clip=0, loss_scale=8, train_wall=90, gb_free=12.8, wall=2459
2023-07-11 15:18:36 | INFO | train_inner | epoch 003:    557 / 1474 loss=3.116, trans_loss=3.978, nll_loss=2.265, w2v_ctc_loss=1.268, task_loss=0.504, contrastive_loss=0.46, total=4093.13, n_correct=1659.29, ppl=4.81, accuracy=40.538, wps=13666.6, ups=1.12, wpb=12255.6, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=0.693, clip=0, loss_scale=8, train_wall=89, gb_free=17.6, wall=2548
2023-07-11 15:20:07 | INFO | train_inner | epoch 003:    657 / 1474 loss=3.062, trans_loss=3.931, nll_loss=2.205, w2v_ctc_loss=1.223, task_loss=0.447, contrastive_loss=0.568, total=4222.97, n_correct=1791.29, ppl=4.61, accuracy=42.418, wps=13799.2, ups=1.1, wpb=12561.4, bsz=483.6, num_updates=3600, lr=0.000144028, gnorm=0.644, clip=0, loss_scale=8, train_wall=91, gb_free=17, wall=2639
2023-07-11 15:21:36 | INFO | train_inner | epoch 003:    757 / 1474 loss=3.009, trans_loss=3.9, nll_loss=2.165, w2v_ctc_loss=1.2, task_loss=0.454, contrastive_loss=0.336, total=4164.5, n_correct=1811.02, ppl=4.48, accuracy=43.487, wps=13936.4, ups=1.12, wpb=12455, bsz=470.6, num_updates=3700, lr=0.000148026, gnorm=0.645, clip=0, loss_scale=8, train_wall=89, gb_free=16.9, wall=2729
2023-07-11 15:23:06 | INFO | train_inner | epoch 003:    857 / 1474 loss=2.982, trans_loss=3.88, nll_loss=2.138, w2v_ctc_loss=1.173, task_loss=0.473, contrastive_loss=0.3, total=4165.03, n_correct=1843.94, ppl=4.4, accuracy=44.272, wps=13912.1, ups=1.12, wpb=12441.6, bsz=457.7, num_updates=3800, lr=0.000152024, gnorm=0.637, clip=0, loss_scale=8, train_wall=89, gb_free=14.9, wall=2818
2023-07-11 15:24:35 | INFO | train_inner | epoch 003:    957 / 1474 loss=2.965, trans_loss=3.856, nll_loss=2.106, w2v_ctc_loss=1.159, task_loss=0.459, contrastive_loss=0.332, total=4159.73, n_correct=1883.93, ppl=4.31, accuracy=45.29, wps=13815.3, ups=1.11, wpb=12402.6, bsz=467.1, num_updates=3900, lr=0.000156022, gnorm=0.633, clip=0, loss_scale=8, train_wall=89, gb_free=17.1, wall=2908
2023-07-11 15:26:04 | INFO | train_inner | epoch 003:   1057 / 1474 loss=2.947, trans_loss=3.846, nll_loss=2.093, w2v_ctc_loss=1.151, task_loss=0.51, contrastive_loss=0.275, total=4059.97, n_correct=1860.28, ppl=4.27, accuracy=45.82, wps=13664, ups=1.13, wpb=12137.3, bsz=438.4, num_updates=4000, lr=0.00016002, gnorm=0.629, clip=0, loss_scale=8, train_wall=88, gb_free=17.5, wall=2997
2023-07-11 15:26:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 15:26:36 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.439 | trans_loss 6.441 | nll_loss 3.999 | w2v_ctc_loss 1.735 | task_loss 4.051 | contrastive_loss 0.405 | total 4003.4 | n_correct 1942.6 | ppl 15.99 | accuracy 48.524 | uer 29.071 | wer 29.917 | raw_wer 29.917 | bleu 6.74 | wps 1583.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.74
2023-07-11 15:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-11 15:26:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_3_4000.pt
2023-07-11 15:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_3_4000.pt
2023-07-11 15:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.74) (writing took 9.795814751996659 seconds)
2023-07-11 15:28:15 | INFO | train_inner | epoch 003:   1157 / 1474 loss=2.915, trans_loss=3.835, nll_loss=2.078, w2v_ctc_loss=1.119, task_loss=0.506, contrastive_loss=0.285, total=4048.71, n_correct=1875.91, ppl=4.22, accuracy=46.334, wps=9249.8, ups=0.77, wpb=12091.3, bsz=437, num_updates=4100, lr=0.000164018, gnorm=0.61, clip=0, loss_scale=8, train_wall=89, gb_free=16.8, wall=3128
2023-07-11 15:29:44 | INFO | train_inner | epoch 003:   1257 / 1474 loss=2.898, trans_loss=3.818, nll_loss=2.056, w2v_ctc_loss=1.1, task_loss=0.501, contrastive_loss=0.252, total=4063.12, n_correct=1914.04, ppl=4.16, accuracy=47.108, wps=13696.5, ups=1.13, wpb=12146.3, bsz=433.7, num_updates=4200, lr=0.000168016, gnorm=0.603, clip=0, loss_scale=8, train_wall=88, gb_free=13.7, wall=3216
2023-07-11 15:31:13 | INFO | train_inner | epoch 003:   1357 / 1474 loss=2.881, trans_loss=3.795, nll_loss=2.03, w2v_ctc_loss=1.085, task_loss=0.474, contrastive_loss=0.366, total=4141.08, n_correct=1976.1, ppl=4.08, accuracy=47.719, wps=13759.5, ups=1.11, wpb=12348, bsz=463.4, num_updates=4300, lr=0.000172014, gnorm=0.605, clip=0, loss_scale=8, train_wall=89, gb_free=17.4, wall=3306
2023-07-11 15:32:43 | INFO | train_inner | epoch 003:   1457 / 1474 loss=2.855, trans_loss=3.783, nll_loss=2.014, w2v_ctc_loss=1.062, task_loss=0.447, contrastive_loss=0.348, total=4212.48, n_correct=2033.89, ppl=4.04, accuracy=48.282, wps=13985.8, ups=1.11, wpb=12581.1, bsz=478.2, num_updates=4400, lr=0.000176012, gnorm=0.588, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=3396
2023-07-11 15:32:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 15:33:30 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.331 | trans_loss 6.325 | nll_loss 3.84 | w2v_ctc_loss 1.567 | task_loss 3.916 | contrastive_loss 0.377 | total 4003.4 | n_correct 2029.2 | ppl 14.32 | accuracy 50.687 | uer 28.049 | wer 28.783 | raw_wer 28.783 | bleu 8.09 | wps 1571.9 | wpb 4003.4 | bsz 141.8 | num_updates 4417 | best_bleu 8.09
2023-07-11 15:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4417 updates
2023-07-11 15:33:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 3 @ 4417 updates, score 8.09) (writing took 8.685094946995378 seconds)
2023-07-11 15:33:39 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-11 15:33:39 | INFO | train | epoch 003 | loss 3.118 | trans_loss 4 | nll_loss 2.296 | w2v_ctc_loss 1.26 | task_loss 0.477 | contrastive_loss 0.441 | total 4139.74 | n_correct 1686.18 | ppl 4.91 | accuracy 40.731 | wps 13003.9 | ups 1.05 | wpb 12359.1 | bsz 458.8 | num_updates 4417 | lr 0.000176692 | gnorm 0.686 | clip 0 | loss_scale 8 | train_wall 1300 | gb_free 16.8 | wall 3452
2023-07-11 15:33:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 15:33:39 | INFO | fairseq.trainer | begin training epoch 4
2023-07-11 15:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 15:35:01 | INFO | train_inner | epoch 004:     83 / 1474 loss=2.817, trans_loss=3.757, nll_loss=1.979, w2v_ctc_loss=1.042, task_loss=0.493, contrastive_loss=0.202, total=4088.42, n_correct=2003.28, ppl=3.94, accuracy=48.999, wps=8851.3, ups=0.73, wpb=12184.2, bsz=437, num_updates=4500, lr=0.00018001, gnorm=0.584, clip=0, loss_scale=8, train_wall=89, gb_free=16.4, wall=3534
2023-07-11 15:36:30 | INFO | train_inner | epoch 004:    183 / 1474 loss=2.789, trans_loss=3.738, nll_loss=1.954, w2v_ctc_loss=1.019, task_loss=0.449, contrastive_loss=0.227, total=4183.38, n_correct=2081.74, ppl=3.87, accuracy=49.762, wps=14045, ups=1.12, wpb=12489.2, bsz=469.7, num_updates=4600, lr=0.000184008, gnorm=0.58, clip=0, loss_scale=8, train_wall=88, gb_free=16.8, wall=3623
2023-07-11 15:38:00 | INFO | train_inner | epoch 004:    283 / 1474 loss=2.805, trans_loss=3.739, nll_loss=1.957, w2v_ctc_loss=1.02, task_loss=0.472, contrastive_loss=0.356, total=4142.13, n_correct=2059.44, ppl=3.88, accuracy=49.719, wps=13735.2, ups=1.11, wpb=12379.5, bsz=463.3, num_updates=4700, lr=0.000188006, gnorm=0.584, clip=0, loss_scale=8, train_wall=90, gb_free=13.5, wall=3713
2023-07-11 15:39:29 | INFO | train_inner | epoch 004:    383 / 1474 loss=2.787, trans_loss=3.739, nll_loss=1.955, w2v_ctc_loss=1.01, task_loss=0.491, contrastive_loss=0.197, total=4132.81, n_correct=2066.39, ppl=3.88, accuracy=50, wps=13800.7, ups=1.12, wpb=12313.3, bsz=443.6, num_updates=4800, lr=0.000192004, gnorm=0.57, clip=0, loss_scale=8, train_wall=89, gb_free=14.9, wall=3802
2023-07-11 15:41:00 | INFO | train_inner | epoch 004:    483 / 1474 loss=2.788, trans_loss=3.72, nll_loss=1.934, w2v_ctc_loss=0.982, task_loss=0.433, contrastive_loss=0.585, total=4205.11, n_correct=2131.19, ppl=3.82, accuracy=50.681, wps=13899.2, ups=1.11, wpb=12541.4, bsz=493.7, num_updates=4900, lr=0.000196002, gnorm=0.564, clip=0, loss_scale=8, train_wall=90, gb_free=17.1, wall=3892
2023-07-11 15:42:30 | INFO | train_inner | epoch 004:    583 / 1474 loss=2.759, trans_loss=3.719, nll_loss=1.932, w2v_ctc_loss=0.997, task_loss=0.447, contrastive_loss=0.279, total=4224.38, n_correct=2144.39, ppl=3.81, accuracy=50.762, wps=14005.3, ups=1.11, wpb=12597.9, bsz=488.9, num_updates=5000, lr=0.0002, gnorm=0.568, clip=0, loss_scale=8, train_wall=89, gb_free=12.5, wall=3982
tensor(0.8446, device='cuda:0')
tensor(0.8288, device='cuda:0')
2023-07-11 15:44:01 | INFO | train_inner | epoch 004:    683 / 1474 loss=2.765, trans_loss=3.722, nll_loss=1.931, w2v_ctc_loss=0.982, task_loss=0.485, contrastive_loss=0.32, total=4182.18, n_correct=2128.5, ppl=3.81, accuracy=50.895, wps=13675.5, ups=1.1, wpb=12460.6, bsz=457.4, num_updates=5100, lr=0.00019803, gnorm=0.495, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=4073
2023-07-11 15:45:30 | INFO | train_inner | epoch 004:    783 / 1474 loss=2.757, trans_loss=3.716, nll_loss=1.924, w2v_ctc_loss=0.988, task_loss=0.527, contrastive_loss=0.188, total=4025.8, n_correct=2054.65, ppl=3.8, accuracy=51.037, wps=13441.2, ups=1.12, wpb=12047, bsz=419.8, num_updates=5200, lr=0.000196116, gnorm=0.496, clip=0, loss_scale=16, train_wall=89, gb_free=16.8, wall=4163
2023-07-11 15:46:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-11 15:47:02 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.734, trans_loss=3.7, nll_loss=1.908, w2v_ctc_loss=0.977, task_loss=0.486, contrastive_loss=0.2, total=4159.38, n_correct=2147.06, ppl=3.75, accuracy=51.62, wps=13536.8, ups=1.09, wpb=12419.8, bsz=454.2, num_updates=5300, lr=0.000194257, gnorm=0.483, clip=0, loss_scale=8, train_wall=91, gb_free=17.8, wall=4255
2023-07-11 15:48:32 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.725, trans_loss=3.692, nll_loss=1.897, w2v_ctc_loss=0.96, task_loss=0.478, contrastive_loss=0.23, total=4125.02, n_correct=2140.83, ppl=3.72, accuracy=51.899, wps=13714.4, ups=1.11, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.478, clip=0, loss_scale=8, train_wall=89, gb_free=13.1, wall=4344
2023-07-11 15:50:02 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.739, trans_loss=3.699, nll_loss=1.904, w2v_ctc_loss=0.967, task_loss=0.509, contrastive_loss=0.209, total=4075.6, n_correct=2113.58, ppl=3.74, accuracy=51.859, wps=13551.3, ups=1.11, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.485, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=4434
2023-07-11 15:51:31 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.727, trans_loss=3.69, nll_loss=1.895, w2v_ctc_loss=0.95, task_loss=0.447, contrastive_loss=0.318, total=4161.18, n_correct=2176.36, ppl=3.72, accuracy=52.302, wps=13938.4, ups=1.12, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.482, clip=0, loss_scale=8, train_wall=89, gb_free=16.9, wall=4524
2023-07-11 15:53:00 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.714, trans_loss=3.683, nll_loss=1.885, w2v_ctc_loss=0.941, task_loss=0.456, contrastive_loss=0.28, total=4156.53, n_correct=2188.44, ppl=3.69, accuracy=52.651, wps=13917.2, ups=1.12, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.476, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=4613
2023-07-11 15:54:29 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.704, trans_loss=3.68, nll_loss=1.881, w2v_ctc_loss=0.944, task_loss=0.489, contrastive_loss=0.158, total=4101.23, n_correct=2159.01, ppl=3.68, accuracy=52.643, wps=13816.9, ups=1.13, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.463, clip=0, loss_scale=8, train_wall=88, gb_free=15.8, wall=4702
2023-07-11 15:55:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8446, device='cuda:3')
tensor(0.8288, device='cuda:3')
tensor(0.8446, device='cuda:5')
tensor(0.8288, device='cuda:5')
tensor(0.8446, device='cuda:7')
tensor(0.8288, device='cuda:7')
tensor(0.8446, device='cuda:4')
tensor(0.8288, device='cuda:4')
tensor(0.8446, device='cuda:6')
tensor(0.8288, device='cuda:6')
tensor(0.8446, device='cuda:2')
tensor(0.8288, device='cuda:2')
tensor(0.8446, device='cuda:1')
tensor(0.8288, device='cuda:1')
2023-07-11 15:56:18 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.011 | trans_loss 5.953 | nll_loss 3.341 | w2v_ctc_loss 1.377 | task_loss 4.179 | contrastive_loss 0.31 | total 4003.4 | n_correct 2234.3 | ppl 10.14 | accuracy 55.81 | uer 22.626 | wer 23.985 | raw_wer 23.985 | bleu 14.46 | wps 1861 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 14.46
2023-07-11 15:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-11 15:56:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:56:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 15:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 4 @ 5890 updates, score 14.46) (writing took 8.355611582985148 seconds)
2023-07-11 15:56:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-11 15:56:26 | INFO | train | epoch 004 | loss 2.753 | trans_loss 3.711 | nll_loss 1.92 | w2v_ctc_loss 0.98 | task_loss 0.475 | contrastive_loss 0.267 | total 4137.18 | n_correct 2118.55 | ppl 3.78 | accuracy 51.207 | wps 13308.1 | ups 1.08 | wpb 12351.9 | bsz 457.8 | num_updates 5890 | lr 0.000184271 | gnorm 0.518 | clip 0 | loss_scale 8 | train_wall 1316 | gb_free 15 | wall 4819
2023-07-11 15:56:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 15:56:27 | INFO | fairseq.trainer | begin training epoch 5
2023-07-11 15:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 15:56:43 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.695, trans_loss=3.672, nll_loss=1.871, w2v_ctc_loss=0.93, task_loss=0.492, contrastive_loss=0.178, total=4037.7, n_correct=2145.26, ppl=3.66, accuracy=53.131, wps=8972.9, ups=0.74, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.474, clip=0, loss_scale=8, train_wall=89, gb_free=17, wall=4836
2023-07-11 15:58:14 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.624, trans_loss=3.62, nll_loss=1.805, w2v_ctc_loss=0.873, task_loss=0.431, contrastive_loss=0.187, total=4247.37, n_correct=2316.91, ppl=3.49, accuracy=54.549, wps=14062.8, ups=1.11, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.453, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=4926
2023-07-11 15:58:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 15:58:44 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 3.974 | trans_loss 5.93 | nll_loss 3.312 | w2v_ctc_loss 1.315 | task_loss 4.204 | contrastive_loss 0.302 | total 4003.4 | n_correct 2246.5 | ppl 9.93 | accuracy 56.115 | uer 22.151 | wer 23.634 | raw_wer 23.634 | bleu 14.65 | wps 1673.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.65
2023-07-11 15:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-11 15:58:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_5_6000.pt
2023-07-11 15:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_5_6000.pt
2023-07-11 15:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.65) (writing took 8.749714681995101 seconds)
2023-07-11 16:00:22 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.648, trans_loss=3.63, nll_loss=1.816, w2v_ctc_loss=0.881, task_loss=0.439, contrastive_loss=0.407, total=4189.85, n_correct=2275.6, ppl=3.52, accuracy=54.312, wps=9729.2, ups=0.78, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.454, clip=0, loss_scale=8, train_wall=89, gb_free=17.9, wall=5055
2023-07-11 16:01:51 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.655, trans_loss=3.63, nll_loss=1.819, w2v_ctc_loss=0.899, task_loss=0.486, contrastive_loss=0.254, total=4090.1, n_correct=2210.48, ppl=3.53, accuracy=54.045, wps=13732.7, ups=1.12, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.468, clip=0, loss_scale=8, train_wall=89, gb_free=16.4, wall=5144
2023-07-11 16:03:21 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.637, trans_loss=3.621, nll_loss=1.81, w2v_ctc_loss=0.869, task_loss=0.457, contrastive_loss=0.343, total=4147.17, n_correct=2263.53, ppl=3.51, accuracy=54.58, wps=13785.9, ups=1.11, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.46, clip=0, loss_scale=8, train_wall=89, gb_free=15.1, wall=5234
2023-07-11 16:04:51 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.633, trans_loss=3.634, nll_loss=1.821, w2v_ctc_loss=0.879, task_loss=0.536, contrastive_loss=0.132, total=4026.81, n_correct=2184.25, ppl=3.53, accuracy=54.243, wps=13456.2, ups=1.12, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.456, clip=0, loss_scale=8, train_wall=89, gb_free=17.5, wall=5323
2023-07-11 16:06:20 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.648, trans_loss=3.631, nll_loss=1.818, w2v_ctc_loss=0.873, task_loss=0.486, contrastive_loss=0.305, total=4107.75, n_correct=2232.33, ppl=3.53, accuracy=54.344, wps=13682.1, ups=1.12, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.465, clip=0, loss_scale=8, train_wall=89, gb_free=16.3, wall=5413
2023-07-11 16:07:50 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.623, trans_loss=3.622, nll_loss=1.809, w2v_ctc_loss=0.871, task_loss=0.452, contrastive_loss=0.282, total=4178.85, n_correct=2281.46, ppl=3.5, accuracy=54.595, wps=13922.7, ups=1.12, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.454, clip=0, loss_scale=8, train_wall=89, gb_free=17.8, wall=5502
2023-07-11 16:09:20 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.626, trans_loss=3.627, nll_loss=1.813, w2v_ctc_loss=0.868, task_loss=0.491, contrastive_loss=0.208, total=4127.73, n_correct=2257.75, ppl=3.51, accuracy=54.697, wps=13644.9, ups=1.11, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.451, clip=0, loss_scale=8, train_wall=90, gb_free=15.4, wall=5592
2023-07-11 16:10:49 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.618, trans_loss=3.621, nll_loss=1.807, w2v_ctc_loss=0.862, task_loss=0.492, contrastive_loss=0.168, total=4095.48, n_correct=2247.9, ppl=3.5, accuracy=54.887, wps=13732.2, ups=1.12, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.454, clip=0, loss_scale=8, train_wall=89, gb_free=15.8, wall=5682
2023-07-11 16:12:18 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.631, trans_loss=3.625, nll_loss=1.813, w2v_ctc_loss=0.867, task_loss=0.468, contrastive_loss=0.251, total=4165.12, n_correct=2285.13, ppl=3.51, accuracy=54.863, wps=13958.7, ups=1.12, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.448, clip=0, loss_scale=8, train_wall=89, gb_free=15.9, wall=5771
2023-07-11 16:13:48 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.628, trans_loss=3.621, nll_loss=1.805, w2v_ctc_loss=0.864, task_loss=0.47, contrastive_loss=0.25, total=4176.72, n_correct=2303.8, ppl=3.49, accuracy=55.158, wps=13773.5, ups=1.1, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.446, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=5861
2023-07-11 16:15:19 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.611, trans_loss=3.622, nll_loss=1.807, w2v_ctc_loss=0.855, task_loss=0.485, contrastive_loss=0.154, total=4164.13, n_correct=2297.78, ppl=3.5, accuracy=55.18, wps=13771.4, ups=1.11, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.45, clip=0, loss_scale=8, train_wall=90, gb_free=17.1, wall=5951
2023-07-11 16:16:49 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.598, trans_loss=3.616, nll_loss=1.798, w2v_ctc_loss=0.845, task_loss=0.485, contrastive_loss=0.124, total=4134.91, n_correct=2284.2, ppl=3.48, accuracy=55.242, wps=13739.6, ups=1.11, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.443, clip=0, loss_scale=8, train_wall=89, gb_free=16.6, wall=6041
2023-07-11 16:18:18 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.603, trans_loss=3.611, nll_loss=1.797, w2v_ctc_loss=0.848, task_loss=0.476, contrastive_loss=0.187, total=4134.37, n_correct=2282, ppl=3.48, accuracy=55.196, wps=13790.8, ups=1.12, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.448, clip=0, loss_scale=8, train_wall=89, gb_free=17.9, wall=6131
2023-07-11 16:19:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 16:19:47 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.893 | nll_loss 3.267 | w2v_ctc_loss 1.25 | task_loss 4.176 | contrastive_loss 0.312 | total 4003.4 | n_correct 2287.1 | ppl 9.63 | accuracy 57.129 | uer 22.042 | wer 23.59 | raw_wer 23.59 | bleu 14.76 | wps 1597.9 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 14.76
2023-07-11 16:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-11 16:19:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 16:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 16:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 5 @ 7364 updates, score 14.76) (writing took 8.230632116028573 seconds)
2023-07-11 16:19:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-11 16:19:55 | INFO | train | epoch 005 | loss 2.626 | trans_loss 3.623 | nll_loss 1.809 | w2v_ctc_loss 0.867 | task_loss 0.475 | contrastive_loss 0.233 | total 4138.65 | n_correct 2265.61 | ppl 3.5 | accuracy 54.743 | wps 12925.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.454 | clip 0 | loss_scale 16 | train_wall 1315 | gb_free 16.4 | wall 6228
2023-07-11 16:19:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 16:19:56 | INFO | fairseq.trainer | begin training epoch 6
2023-07-11 16:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 16:20:37 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.582, trans_loss=3.593, nll_loss=1.77, w2v_ctc_loss=0.834, task_loss=0.487, contrastive_loss=0.183, total=4115.45, n_correct=2303.64, ppl=3.41, accuracy=55.975, wps=8862.3, ups=0.72, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.456, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=6269
2023-07-11 16:22:07 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.546, trans_loss=3.568, nll_loss=1.739, w2v_ctc_loss=0.797, task_loss=0.476, contrastive_loss=0.226, total=4154.25, n_correct=2348.72, ppl=3.34, accuracy=56.538, wps=13787, ups=1.11, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.438, clip=0, loss_scale=16, train_wall=90, gb_free=15.7, wall=6359
2023-07-11 16:23:37 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.565, trans_loss=3.577, nll_loss=1.752, w2v_ctc_loss=0.826, task_loss=0.509, contrastive_loss=0.135, total=4112.66, n_correct=2306.38, ppl=3.37, accuracy=56.08, wps=13537.6, ups=1.1, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.444, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=6450
2023-07-11 16:25:09 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.568, trans_loss=3.567, nll_loss=1.74, w2v_ctc_loss=0.796, task_loss=0.44, contrastive_loss=0.443, total=4177.51, n_correct=2365.31, ppl=3.34, accuracy=56.62, wps=13617.1, ups=1.09, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.451, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6541
2023-07-11 16:26:38 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.543, trans_loss=3.57, nll_loss=1.743, w2v_ctc_loss=0.8, task_loss=0.456, contrastive_loss=0.154, total=4154.57, n_correct=2356.83, ppl=3.35, accuracy=56.729, wps=13899.1, ups=1.12, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.44, clip=0, loss_scale=16, train_wall=89, gb_free=16.3, wall=6631
2023-07-11 16:28:08 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.55, trans_loss=3.571, nll_loss=1.745, w2v_ctc_loss=0.807, task_loss=0.479, contrastive_loss=0.139, total=4167.79, n_correct=2365.05, ppl=3.35, accuracy=56.746, wps=13900.2, ups=1.12, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.44, clip=0, loss_scale=16, train_wall=89, gb_free=15.9, wall=6720
2023-07-11 16:29:37 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.542, trans_loss=3.575, nll_loss=1.746, w2v_ctc_loss=0.793, task_loss=0.453, contrastive_loss=0.194, total=4146.17, n_correct=2347.4, ppl=3.35, accuracy=56.616, wps=13900.2, ups=1.12, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.439, clip=0, loss_scale=16, train_wall=89, gb_free=16.7, wall=6809
2023-07-11 16:29:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 16:30:06 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 3.87 | trans_loss 5.816 | nll_loss 3.165 | w2v_ctc_loss 1.226 | task_loss 4.212 | contrastive_loss 0.282 | total 4003.4 | n_correct 2314.1 | ppl 8.97 | accuracy 57.803 | uer 20.458 | wer 22.318 | raw_wer 22.318 | bleu 16.26 | wps 1730.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 16.26
2023-07-11 16:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-11 16:30:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_6_8000.pt
2023-07-11 16:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_6_8000.pt
2023-07-11 16:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 16.26) (writing took 8.7642726849881 seconds)
2023-07-11 16:31:45 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.551, trans_loss=3.575, nll_loss=1.749, w2v_ctc_loss=0.809, task_loss=0.485, contrastive_loss=0.15, total=4148.65, n_correct=2350.59, ppl=3.36, accuracy=56.659, wps=9636.3, ups=0.78, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.44, clip=0, loss_scale=16, train_wall=90, gb_free=15.8, wall=6938
2023-07-11 16:33:16 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.558, trans_loss=3.58, nll_loss=1.754, w2v_ctc_loss=0.804, task_loss=0.498, contrastive_loss=0.131, total=4114.34, n_correct=2324.18, ppl=3.37, accuracy=56.49, wps=13593.6, ups=1.11, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.44, clip=0, loss_scale=16, train_wall=90, gb_free=15.3, wall=7028
2023-07-11 16:34:45 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.561, trans_loss=3.578, nll_loss=1.754, w2v_ctc_loss=0.808, task_loss=0.495, contrastive_loss=0.229, total=4081.53, n_correct=2306.02, ppl=3.37, accuracy=56.499, wps=13548.7, ups=1.11, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.447, clip=0, loss_scale=16, train_wall=89, gb_free=17.9, wall=7118
2023-07-11 16:36:15 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.556, trans_loss=3.571, nll_loss=1.745, w2v_ctc_loss=0.794, task_loss=0.451, contrastive_loss=0.303, total=4165.84, n_correct=2369.31, ppl=3.35, accuracy=56.875, wps=13888.6, ups=1.12, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.447, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=7208
2023-07-11 16:37:45 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.548, trans_loss=3.578, nll_loss=1.752, w2v_ctc_loss=0.799, task_loss=0.527, contrastive_loss=0.131, total=4072.29, n_correct=2309.87, ppl=3.37, accuracy=56.722, wps=13569.6, ups=1.12, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.438, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=7297
2023-07-11 16:39:15 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.56, trans_loss=3.57, nll_loss=1.744, w2v_ctc_loss=0.785, task_loss=0.461, contrastive_loss=0.449, total=4141.55, n_correct=2357.67, ppl=3.35, accuracy=56.927, wps=13762.1, ups=1.11, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.439, clip=0, loss_scale=16, train_wall=90, gb_free=13.5, wall=7387
2023-07-11 16:40:43 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.542, trans_loss=3.576, nll_loss=1.748, w2v_ctc_loss=0.789, task_loss=0.473, contrastive_loss=0.119, total=4125.31, n_correct=2354.76, ppl=3.36, accuracy=57.081, wps=13859.1, ups=1.13, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.439, clip=0, loss_scale=16, train_wall=88, gb_free=17.8, wall=7476
2023-07-11 16:42:15 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.533, trans_loss=3.565, nll_loss=1.738, w2v_ctc_loss=0.792, task_loss=0.474, contrastive_loss=0.125, total=4196.2, n_correct=2400.82, ppl=3.34, accuracy=57.214, wps=13731.2, ups=1.1, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.431, clip=0, loss_scale=16, train_wall=91, gb_free=11.8, wall=7567
2023-07-11 16:42:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 16:43:15 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 3.83 | trans_loss 5.772 | nll_loss 3.099 | w2v_ctc_loss 1.182 | task_loss 4.247 | contrastive_loss 0.284 | total 4003.4 | n_correct 2349.6 | ppl 8.57 | accuracy 58.69 | uer 19.345 | wer 21.095 | raw_wer 21.095 | bleu 17.14 | wps 1970.5 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.14
2023-07-11 16:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-11 16:43:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 16:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 16:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.14) (writing took 7.906611679994967 seconds)
2023-07-11 16:43:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-11 16:43:23 | INFO | train | epoch 006 | loss 2.55 | trans_loss 3.572 | nll_loss 1.746 | w2v_ctc_loss 0.8 | task_loss 0.475 | contrastive_loss 0.208 | total 4138.65 | n_correct 2347.31 | ppl 3.35 | accuracy 56.717 | wps 12934.3 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.441 | clip 0 | loss_scale 16 | train_wall 1319 | gb_free 15.3 | wall 7636
2023-07-11 16:43:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 16:43:24 | INFO | fairseq.trainer | begin training epoch 7
2023-07-11 16:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 16:44:28 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.505, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=0.767, task_loss=0.463, contrastive_loss=0.141, total=4108.19, n_correct=2371.16, ppl=3.26, accuracy=57.718, wps=9210.2, ups=0.75, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.437, clip=0, loss_scale=16, train_wall=89, gb_free=17.2, wall=7700
2023-07-11 16:45:57 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.505, trans_loss=3.535, nll_loss=1.698, w2v_ctc_loss=0.755, task_loss=0.48, contrastive_loss=0.217, total=4106.05, n_correct=2375.54, ppl=3.24, accuracy=57.855, wps=13706.4, ups=1.12, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.436, clip=0, loss_scale=16, train_wall=89, gb_free=16.9, wall=7790
2023-07-11 16:47:27 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.486, trans_loss=3.533, nll_loss=1.693, w2v_ctc_loss=0.755, task_loss=0.482, contrastive_loss=0.122, total=4129.3, n_correct=2396.11, ppl=3.23, accuracy=58.027, wps=13753.9, ups=1.12, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.432, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=7879
2023-07-11 16:48:57 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.505, trans_loss=3.539, nll_loss=1.703, w2v_ctc_loss=0.747, task_loss=0.458, contrastive_loss=0.383, total=4201.67, n_correct=2427.47, ppl=3.26, accuracy=57.774, wps=13896.7, ups=1.11, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.433, clip=0, loss_scale=16, train_wall=90, gb_free=15.6, wall=7970
2023-07-11 16:50:27 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.507, trans_loss=3.537, nll_loss=1.704, w2v_ctc_loss=0.753, task_loss=0.467, contrastive_loss=0.308, total=4155.31, n_correct=2401.49, ppl=3.26, accuracy=57.793, wps=13801.8, ups=1.11, wpb=12394.6, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.436, clip=0, loss_scale=16, train_wall=89, gb_free=16.9, wall=8059
2023-07-11 16:51:57 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.492, trans_loss=3.537, nll_loss=1.701, w2v_ctc_loss=0.755, task_loss=0.467, contrastive_loss=0.131, total=4165.88, n_correct=2419.96, ppl=3.25, accuracy=58.09, wps=13808.9, ups=1.11, wpb=12401.8, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.432, clip=0, loss_scale=32, train_wall=89, gb_free=17.3, wall=8149
2023-07-11 16:53:27 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.492, trans_loss=3.54, nll_loss=1.702, w2v_ctc_loss=0.747, task_loss=0.477, contrastive_loss=0.115, total=4149.29, n_correct=2408.81, ppl=3.25, accuracy=58.054, wps=13756.6, ups=1.11, wpb=12393.1, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.432, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=8239
2023-07-11 16:54:57 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.499, trans_loss=3.539, nll_loss=1.702, w2v_ctc_loss=0.755, task_loss=0.491, contrastive_loss=0.116, total=4134.54, n_correct=2403.61, ppl=3.25, accuracy=58.135, wps=13771.3, ups=1.11, wpb=12358.8, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.432, clip=0, loss_scale=32, train_wall=89, gb_free=14.1, wall=8329
2023-07-11 16:56:27 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.495, trans_loss=3.539, nll_loss=1.702, w2v_ctc_loss=0.751, task_loss=0.479, contrastive_loss=0.135, total=4151.77, n_correct=2410.38, ppl=3.25, accuracy=58.057, wps=13683.7, ups=1.1, wpb=12405.1, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.438, clip=0, loss_scale=32, train_wall=90, gb_free=15.1, wall=8420
2023-07-11 16:57:57 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.498, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=0.745, task_loss=0.456, contrastive_loss=0.232, total=4124.8, n_correct=2399.95, ppl=3.25, accuracy=58.183, wps=13757.2, ups=1.12, wpb=12316.5, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.441, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=8509
2023-07-11 16:59:27 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.49, trans_loss=3.546, nll_loss=1.711, w2v_ctc_loss=0.751, task_loss=0.499, contrastive_loss=0.098, total=4113.08, n_correct=2383.26, ppl=3.27, accuracy=57.943, wps=13622.1, ups=1.11, wpb=12291.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.43, clip=0, loss_scale=32, train_wall=90, gb_free=15, wall=8599
2023-07-11 17:00:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 17:00:58 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.502, trans_loss=3.534, nll_loss=1.703, w2v_ctc_loss=0.748, task_loss=0.473, contrastive_loss=0.309, total=4112.66, n_correct=2389.8, ppl=3.26, accuracy=58.108, wps=13473.1, ups=1.1, wpb=12274, bsz=460.2, num_updates=10000, lr=0.000141421, gnorm=0.441, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=8691
2023-07-11 17:00:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 17:01:23 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.791 | trans_loss 5.723 | nll_loss 3.04 | w2v_ctc_loss 1.16 | task_loss 4.261 | contrastive_loss 0.277 | total 4003.4 | n_correct 2375 | ppl 8.23 | accuracy 59.325 | uer 18.684 | wer 20.495 | raw_wer 20.495 | bleu 18.53 | wps 2282.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.53
2023-07-11 17:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-11 17:01:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_7_10000.pt
2023-07-11 17:01:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_7_10000.pt
2023-07-11 17:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.53) (writing took 8.633869751007296 seconds)
tensor(0.5900, device='cuda:0')
tensor(0.5648, device='cuda:0')
2023-07-11 17:03:02 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.481, trans_loss=3.532, nll_loss=1.697, w2v_ctc_loss=0.742, task_loss=0.481, contrastive_loss=0.126, total=4129.52, n_correct=2405.81, ppl=3.24, accuracy=58.259, wps=9982.4, ups=0.81, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.342, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8814
2023-07-11 17:04:31 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.49, trans_loss=3.529, nll_loss=1.693, w2v_ctc_loss=0.749, task_loss=0.445, contrastive_loss=0.162, total=4172.87, n_correct=2444.05, ppl=3.23, accuracy=58.57, wps=13900.1, ups=1.12, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.343, clip=0, loss_scale=16, train_wall=89, gb_free=17.3, wall=8904
2023-07-11 17:06:02 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.504, trans_loss=3.54, nll_loss=1.707, w2v_ctc_loss=0.75, task_loss=0.513, contrastive_loss=0.227, total=4109.42, n_correct=2390.9, ppl=3.27, accuracy=58.181, wps=13464.5, ups=1.1, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.35, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=8995
2023-07-11 17:06:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.5900, device='cuda:4')
tensor(0.5648, device='cuda:4')
tensor(0.5900, device='cuda:6')
tensor(0.5648, device='cuda:6')
tensor(0.5900, device='cuda:5')
tensor(0.5648, device='cuda:5')
tensor(0.5900, device='cuda:3')
tensor(0.5648, device='cuda:3')
tensor(0.5900, device='cuda:7')
tensor(0.5648, device='cuda:7')
tensor(0.5900, device='cuda:1')
tensor(0.5648, device='cuda:1')
tensor(0.5900, device='cuda:2')
tensor(0.5648, device='cuda:2')
2023-07-11 17:06:41 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.793 | trans_loss 5.733 | nll_loss 3.057 | w2v_ctc_loss 1.161 | task_loss 4.284 | contrastive_loss 0.266 | total 4003.4 | n_correct 2361.2 | ppl 8.32 | accuracy 58.98 | uer 18.979 | wer 20.823 | raw_wer 20.823 | bleu 16.9 | wps 1805.3 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.53
2023-07-11 17:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-11 17:06:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_16.9002.pt
2023-07-11 17:06:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_16.9002.pt
2023-07-11 17:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_16.9002.pt (epoch 7 @ 10311 updates, score 16.9) (writing took 5.481275734025985 seconds)
2023-07-11 17:06:47 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-11 17:06:47 | INFO | train | epoch 007 | loss 2.496 | trans_loss 3.537 | nll_loss 1.701 | w2v_ctc_loss 0.751 | task_loss 0.476 | contrastive_loss 0.19 | total 4137.22 | n_correct 2402.42 | ppl 3.25 | accuracy 58.068 | wps 12963.1 | ups 1.05 | wpb 12351.6 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.416 | clip 0 | loss_scale 16 | train_wall 1320 | gb_free 13.5 | wall 9039
2023-07-11 17:06:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 17:06:47 | INFO | fairseq.trainer | begin training epoch 8
2023-07-11 17:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 17:08:15 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.456, trans_loss=3.512, nll_loss=1.666, w2v_ctc_loss=0.719, task_loss=0.503, contrastive_loss=0.12, total=4116.25, n_correct=2427.29, ppl=3.17, accuracy=58.968, wps=9240.1, ups=0.75, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.344, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=9128
2023-07-11 17:09:45 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.467, trans_loss=3.515, nll_loss=1.67, w2v_ctc_loss=0.722, task_loss=0.515, contrastive_loss=0.143, total=4037.23, n_correct=2381.47, ppl=3.18, accuracy=58.988, wps=13436.2, ups=1.12, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.351, clip=0, loss_scale=16, train_wall=89, gb_free=13.1, wall=9217
2023-07-11 17:11:15 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.437, trans_loss=3.504, nll_loss=1.656, w2v_ctc_loss=0.706, task_loss=0.448, contrastive_loss=0.139, total=4207.78, n_correct=2498.79, ppl=3.15, accuracy=59.385, wps=13911.5, ups=1.11, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.338, clip=0, loss_scale=16, train_wall=90, gb_free=13.3, wall=9308
2023-07-11 17:12:46 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.47, trans_loss=3.513, nll_loss=1.668, w2v_ctc_loss=0.729, task_loss=0.504, contrastive_loss=0.164, total=4127.24, n_correct=2430.81, ppl=3.18, accuracy=58.897, wps=13495, ups=1.1, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.346, clip=0, loss_scale=16, train_wall=91, gb_free=12.1, wall=9399
2023-07-11 17:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-11 17:14:18 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.47, trans_loss=3.513, nll_loss=1.668, w2v_ctc_loss=0.713, task_loss=0.436, contrastive_loss=0.309, total=4188.76, n_correct=2473.69, ppl=3.18, accuracy=59.055, wps=13666.2, ups=1.09, wpb=12530.3, bsz=494.2, num_updates=10800, lr=0.000136083, gnorm=0.348, clip=0, loss_scale=8, train_wall=91, gb_free=13.2, wall=9491
2023-07-11 17:15:48 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.458, trans_loss=3.511, nll_loss=1.668, w2v_ctc_loss=0.722, task_loss=0.518, contrastive_loss=0.096, total=4065.55, n_correct=2392.62, ppl=3.18, accuracy=58.851, wps=13499.5, ups=1.11, wpb=12176.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.348, clip=0, loss_scale=8, train_wall=90, gb_free=16.3, wall=9581
2023-07-11 17:17:18 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.454, trans_loss=3.508, nll_loss=1.665, w2v_ctc_loss=0.726, task_loss=0.492, contrastive_loss=0.107, total=4135.41, n_correct=2453.01, ppl=3.17, accuracy=59.317, wps=13702.9, ups=1.11, wpb=12330.3, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.345, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=9671
2023-07-11 17:18:48 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.458, trans_loss=3.506, nll_loss=1.663, w2v_ctc_loss=0.716, task_loss=0.482, contrastive_loss=0.2, total=4128.86, n_correct=2443.75, ppl=3.17, accuracy=59.187, wps=13705.3, ups=1.11, wpb=12353.8, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.352, clip=0, loss_scale=8, train_wall=90, gb_free=16.6, wall=9761
2023-07-11 17:20:19 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.458, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=0.712, task_loss=0.457, contrastive_loss=0.212, total=4166.92, n_correct=2466.78, ppl=3.18, accuracy=59.199, wps=13790.9, ups=1.11, wpb=12450.6, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.35, clip=0, loss_scale=8, train_wall=90, gb_free=14.7, wall=9851
2023-07-11 17:21:48 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.443, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=0.708, task_loss=0.457, contrastive_loss=0.103, total=4150.39, n_correct=2463.94, ppl=3.16, accuracy=59.366, wps=13853.6, ups=1.12, wpb=12385.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.343, clip=0, loss_scale=8, train_wall=89, gb_free=17.4, wall=9941
2023-07-11 17:23:19 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.464, trans_loss=3.509, nll_loss=1.668, w2v_ctc_loss=0.711, task_loss=0.472, contrastive_loss=0.327, total=4197.39, n_correct=2479.08, ppl=3.18, accuracy=59.062, wps=13795.7, ups=1.1, wpb=12518.1, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.341, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=10031
2023-07-11 17:24:49 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.447, trans_loss=3.508, nll_loss=1.668, w2v_ctc_loss=0.713, task_loss=0.449, contrastive_loss=0.114, total=4180.55, n_correct=2478.36, ppl=3.18, accuracy=59.283, wps=13905.6, ups=1.11, wpb=12486.6, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.345, clip=0, loss_scale=8, train_wall=89, gb_free=17.4, wall=10121
2023-07-11 17:26:18 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.46, trans_loss=3.509, nll_loss=1.668, w2v_ctc_loss=0.721, task_loss=0.496, contrastive_loss=0.135, total=4062.6, n_correct=2401.44, ppl=3.18, accuracy=59.111, wps=13647.1, ups=1.12, wpb=12134.6, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.348, clip=0, loss_scale=8, train_wall=88, gb_free=13.3, wall=10210
2023-07-11 17:27:47 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.46, trans_loss=3.51, nll_loss=1.672, w2v_ctc_loss=0.714, task_loss=0.464, contrastive_loss=0.205, total=4159.11, n_correct=2465.27, ppl=3.19, accuracy=59.274, wps=13812.9, ups=1.11, wpb=12403.4, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.342, clip=0, loss_scale=8, train_wall=89, gb_free=13.5, wall=10300
2023-07-11 17:29:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 17:29:32 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.758 | trans_loss 5.689 | nll_loss 2.994 | w2v_ctc_loss 1.145 | task_loss 4.311 | contrastive_loss 0.255 | total 4003.4 | n_correct 2401.6 | ppl 7.97 | accuracy 59.989 | uer 18.13 | wer 19.824 | raw_wer 19.824 | bleu 17.5 | wps 1799.2 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 18.53
2023-07-11 17:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-07-11 17:29:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_17.5004.pt
2023-07-11 17:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_17.5004.pt
2023-07-11 17:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_17.5004.pt (epoch 8 @ 11784 updates, score 17.5) (writing took 5.330239227972925 seconds)
2023-07-11 17:29:38 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-11 17:29:38 | INFO | train | epoch 008 | loss 2.457 | trans_loss 3.509 | nll_loss 1.666 | w2v_ctc_loss 0.716 | task_loss 0.476 | contrastive_loss 0.175 | total 4137.78 | n_correct 2447.88 | ppl 3.17 | accuracy 59.159 | wps 13273.4 | ups 1.07 | wpb 12353.5 | bsz 457.9 | num_updates 11784 | lr 0.000130277 | gnorm 0.346 | clip 0 | loss_scale 8 | train_wall 1321 | gb_free 17.1 | wall 10410
2023-07-11 17:29:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 17:29:38 | INFO | fairseq.trainer | begin training epoch 9
2023-07-11 17:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 17:30:01 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.457, trans_loss=3.503, nll_loss=1.661, w2v_ctc_loss=0.702, task_loss=0.464, contrastive_loss=0.301, total=4121.25, n_correct=2454.05, ppl=3.16, accuracy=59.546, wps=9185.2, ups=0.75, wpb=12280.4, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.344, clip=0, loss_scale=8, train_wall=90, gb_free=17.8, wall=10434
2023-07-11 17:31:31 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.408, trans_loss=3.474, nll_loss=1.622, w2v_ctc_loss=0.677, task_loss=0.446, contrastive_loss=0.133, total=4191.82, n_correct=2529.72, ppl=3.08, accuracy=60.349, wps=13876.6, ups=1.11, wpb=12521.5, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.337, clip=0, loss_scale=8, train_wall=90, gb_free=16.1, wall=10524
2023-07-11 17:33:02 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.415, trans_loss=3.486, nll_loss=1.635, w2v_ctc_loss=0.682, task_loss=0.513, contrastive_loss=0.09, total=4061.27, n_correct=2436.94, ppl=3.11, accuracy=60.004, wps=13398.3, ups=1.1, wpb=12136, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.34, clip=0, loss_scale=8, train_wall=90, gb_free=17.7, wall=10614
2023-07-11 17:33:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 17:33:30 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.768 | trans_loss 5.705 | nll_loss 3.016 | w2v_ctc_loss 1.148 | task_loss 4.319 | contrastive_loss 0.267 | total 4003.4 | n_correct 2385.1 | ppl 8.09 | accuracy 59.577 | uer 18.323 | wer 20.07 | raw_wer 20.07 | bleu 17.75 | wps 1882.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.53
2023-07-11 17:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-11 17:33:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_9_12000.pt
2023-07-11 17:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_9_12000.pt
2023-07-11 17:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 17.75) (writing took 6.118215485999826 seconds)
2023-07-11 17:35:06 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.411, trans_loss=3.475, nll_loss=1.623, w2v_ctc_loss=0.674, task_loss=0.45, contrastive_loss=0.14, total=4146.43, n_correct=2506.42, ppl=3.08, accuracy=60.448, wps=9977.5, ups=0.8, wpb=12407.6, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.339, clip=0, loss_scale=8, train_wall=89, gb_free=16.8, wall=10739
2023-07-11 17:36:37 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.415, trans_loss=3.482, nll_loss=1.633, w2v_ctc_loss=0.685, task_loss=0.467, contrastive_loss=0.107, total=4194.84, n_correct=2516.6, ppl=3.1, accuracy=59.993, wps=13740.8, ups=1.1, wpb=12516.2, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.34, clip=0, loss_scale=8, train_wall=91, gb_free=16.3, wall=10830
2023-07-11 17:38:07 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.44, trans_loss=3.493, nll_loss=1.647, w2v_ctc_loss=0.702, task_loss=0.494, contrastive_loss=0.16, total=4124.3, n_correct=2462.72, ppl=3.13, accuracy=59.712, wps=13655.9, ups=1.11, wpb=12292.8, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.351, clip=0, loss_scale=8, train_wall=90, gb_free=12, wall=10920
2023-07-11 17:39:38 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.413, trans_loss=3.482, nll_loss=1.634, w2v_ctc_loss=0.68, task_loss=0.486, contrastive_loss=0.118, total=4120.96, n_correct=2479.36, ppl=3.1, accuracy=60.165, wps=13646.3, ups=1.11, wpb=12325.2, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.344, clip=0, loss_scale=8, train_wall=90, gb_free=16.3, wall=11010
2023-07-11 17:41:07 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.436, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=0.694, task_loss=0.484, contrastive_loss=0.201, total=4088.53, n_correct=2442.91, ppl=3.13, accuracy=59.75, wps=13728.7, ups=1.12, wpb=12225.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.349, clip=0, loss_scale=8, train_wall=89, gb_free=17.1, wall=11099
2023-07-11 17:42:37 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.444, trans_loss=3.479, nll_loss=1.634, w2v_ctc_loss=0.691, task_loss=0.428, contrastive_loss=0.343, total=4220.43, n_correct=2532.44, ppl=3.1, accuracy=60.004, wps=13928.1, ups=1.11, wpb=12596.8, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.345, clip=0, loss_scale=8, train_wall=90, gb_free=14.6, wall=11190
2023-07-11 17:44:08 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.433, trans_loss=3.488, nll_loss=1.641, w2v_ctc_loss=0.687, task_loss=0.491, contrastive_loss=0.325, total=4146.05, n_correct=2486.98, ppl=3.12, accuracy=59.984, wps=13562.6, ups=1.1, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.341, clip=0, loss_scale=8, train_wall=91, gb_free=17.9, wall=11281
2023-07-11 17:45:38 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.434, trans_loss=3.498, nll_loss=1.651, w2v_ctc_loss=0.693, task_loss=0.529, contrastive_loss=0.104, total=4101.48, n_correct=2448.4, ppl=3.14, accuracy=59.696, wps=13595.4, ups=1.11, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.343, clip=0, loss_scale=8, train_wall=90, gb_free=16.1, wall=11371
2023-07-11 17:47:08 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.421, trans_loss=3.489, nll_loss=1.64, w2v_ctc_loss=0.689, task_loss=0.449, contrastive_loss=0.129, total=4179.09, n_correct=2511.33, ppl=3.12, accuracy=60.093, wps=13812, ups=1.11, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.346, clip=0, loss_scale=16, train_wall=90, gb_free=15.5, wall=11461
2023-07-11 17:48:40 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.43, trans_loss=3.496, nll_loss=1.646, w2v_ctc_loss=0.693, task_loss=0.503, contrastive_loss=0.113, total=4140.66, n_correct=2481.24, ppl=3.13, accuracy=59.924, wps=13609.4, ups=1.1, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.343, clip=0, loss_scale=16, train_wall=91, gb_free=17.2, wall=11552
2023-07-11 17:50:09 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.42, trans_loss=3.481, nll_loss=1.632, w2v_ctc_loss=0.672, task_loss=0.434, contrastive_loss=0.306, total=4204.43, n_correct=2538.73, ppl=3.1, accuracy=60.382, wps=13972.9, ups=1.11, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.341, clip=0, loss_scale=16, train_wall=89, gb_free=17.8, wall=11642
2023-07-11 17:51:39 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.432, trans_loss=3.499, nll_loss=1.653, w2v_ctc_loss=0.696, task_loss=0.516, contrastive_loss=0.09, total=4069.19, n_correct=2432.53, ppl=3.14, accuracy=59.779, wps=13575.7, ups=1.12, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.347, clip=0, loss_scale=16, train_wall=89, gb_free=16.8, wall=11731
2023-07-11 17:52:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 17:52:56 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.739 | trans_loss 5.667 | nll_loss 2.969 | w2v_ctc_loss 1.141 | task_loss 4.324 | contrastive_loss 0.267 | total 4003.4 | n_correct 2408.3 | ppl 7.83 | accuracy 60.156 | uer 17.755 | wer 19.44 | raw_wer 19.44 | bleu 18.56 | wps 2138.9 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.56
2023-07-11 17:52:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-11 17:52:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 17:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 17:53:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 9 @ 13258 updates, score 18.56) (writing took 8.221016920986585 seconds)
2023-07-11 17:53:05 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-11 17:53:05 | INFO | train | epoch 009 | loss 2.425 | trans_loss 3.486 | nll_loss 1.638 | w2v_ctc_loss 0.687 | task_loss 0.476 | contrastive_loss 0.175 | total 4138.65 | n_correct 2484.48 | ppl 3.11 | accuracy 60.031 | wps 12946.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.344 | clip 0 | loss_scale 16 | train_wall 1322 | gb_free 12 | wall 11817
2023-07-11 17:53:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 17:53:05 | INFO | fairseq.trainer | begin training epoch 10
2023-07-11 17:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 17:53:50 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.413, trans_loss=3.481, nll_loss=1.63, w2v_ctc_loss=0.674, task_loss=0.454, contrastive_loss=0.187, total=4100.8, n_correct=2475.78, ppl=3.1, accuracy=60.373, wps=9326.7, ups=0.76, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.347, clip=0, loss_scale=16, train_wall=88, gb_free=16.4, wall=11863
2023-07-11 17:55:20 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.383, trans_loss=3.462, nll_loss=1.603, w2v_ctc_loss=0.653, task_loss=0.45, contrastive_loss=0.11, total=4247.35, n_correct=2591.52, ppl=3.04, accuracy=61.015, wps=14140.3, ups=1.11, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.336, clip=0, loss_scale=16, train_wall=89, gb_free=12.1, wall=11953
2023-07-11 17:56:50 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.392, trans_loss=3.455, nll_loss=1.599, w2v_ctc_loss=0.659, task_loss=0.471, contrastive_loss=0.23, total=4122.82, n_correct=2518.79, ppl=3.03, accuracy=61.094, wps=13642.6, ups=1.11, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.341, clip=0, loss_scale=16, train_wall=90, gb_free=16.4, wall=12043
2023-07-11 17:58:20 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.387, trans_loss=3.458, nll_loss=1.604, w2v_ctc_loss=0.657, task_loss=0.482, contrastive_loss=0.145, total=4138.27, n_correct=2522.53, ppl=3.04, accuracy=60.956, wps=13710.4, ups=1.11, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.336, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=12133
2023-07-11 17:59:51 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.396, trans_loss=3.462, nll_loss=1.608, w2v_ctc_loss=0.648, task_loss=0.458, contrastive_loss=0.32, total=4196.37, n_correct=2557.15, ppl=3.05, accuracy=60.937, wps=13744.3, ups=1.1, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.337, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=12224
2023-07-11 18:01:21 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.407, trans_loss=3.473, nll_loss=1.618, w2v_ctc_loss=0.673, task_loss=0.511, contrastive_loss=0.098, total=4102.8, n_correct=2489.62, ppl=3.07, accuracy=60.681, wps=13619.7, ups=1.11, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.342, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=12314
2023-07-11 18:02:51 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.405, trans_loss=3.472, nll_loss=1.619, w2v_ctc_loss=0.666, task_loss=0.452, contrastive_loss=0.215, total=4176.56, n_correct=2536.6, ppl=3.07, accuracy=60.734, wps=13874.9, ups=1.11, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.345, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=12404
2023-07-11 18:04:21 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.406, trans_loss=3.472, nll_loss=1.619, w2v_ctc_loss=0.678, task_loss=0.476, contrastive_loss=0.097, total=4125.87, n_correct=2499.99, ppl=3.07, accuracy=60.593, wps=13703.3, ups=1.11, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.346, clip=0, loss_scale=16, train_wall=89, gb_free=14.7, wall=12493
2023-07-11 18:04:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 18:04:49 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.746 | trans_loss 5.673 | nll_loss 2.973 | w2v_ctc_loss 1.159 | task_loss 4.347 | contrastive_loss 0.255 | total 4003.4 | n_correct 2402.6 | ppl 7.85 | accuracy 60.014 | uer 18.058 | wer 19.697 | raw_wer 19.697 | bleu 18.33 | wps 1902.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.56
2023-07-11 18:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-11 18:04:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_10_14000.pt
2023-07-11 18:04:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_10_14000.pt
2023-07-11 18:04:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.33) (writing took 6.2463464150205255 seconds)
2023-07-11 18:06:26 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.393, trans_loss=3.468, nll_loss=1.614, w2v_ctc_loss=0.659, task_loss=0.472, contrastive_loss=0.098, total=4128.44, n_correct=2507.95, ppl=3.06, accuracy=60.748, wps=9861.5, ups=0.8, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.343, clip=0, loss_scale=16, train_wall=90, gb_free=14.9, wall=12619
2023-07-11 18:07:55 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.401, trans_loss=3.466, nll_loss=1.614, w2v_ctc_loss=0.671, task_loss=0.457, contrastive_loss=0.139, total=4160.94, n_correct=2529.36, ppl=3.06, accuracy=60.788, wps=13913.7, ups=1.12, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.343, clip=0, loss_scale=16, train_wall=89, gb_free=15.6, wall=12708
2023-07-11 18:09:25 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.397, trans_loss=3.472, nll_loss=1.621, w2v_ctc_loss=0.67, task_loss=0.516, contrastive_loss=0.112, total=4067.53, n_correct=2464.93, ppl=3.08, accuracy=60.6, wps=13515, ups=1.11, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.348, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=12798
2023-07-11 18:10:55 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.406, trans_loss=3.475, nll_loss=1.625, w2v_ctc_loss=0.674, task_loss=0.528, contrastive_loss=0.093, total=4044.03, n_correct=2447.74, ppl=3.08, accuracy=60.527, wps=13452.3, ups=1.11, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.345, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=12887
2023-07-11 18:12:25 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.4, trans_loss=3.469, nll_loss=1.62, w2v_ctc_loss=0.671, task_loss=0.486, contrastive_loss=0.087, total=4110.41, n_correct=2495.34, ppl=3.07, accuracy=60.708, wps=13675.7, ups=1.11, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.345, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=12977
2023-07-11 18:13:54 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.394, trans_loss=3.469, nll_loss=1.618, w2v_ctc_loss=0.664, task_loss=0.485, contrastive_loss=0.1, total=4121.38, n_correct=2501.21, ppl=3.07, accuracy=60.689, wps=13722.3, ups=1.11, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.342, clip=0, loss_scale=16, train_wall=89, gb_free=14.3, wall=13067
2023-07-11 18:15:26 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.412, trans_loss=3.475, nll_loss=1.626, w2v_ctc_loss=0.655, task_loss=0.448, contrastive_loss=0.352, total=4192.39, n_correct=2541.77, ppl=3.09, accuracy=60.628, wps=13687.5, ups=1.1, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.344, clip=0, loss_scale=16, train_wall=91, gb_free=17.2, wall=13158
2023-07-11 18:15:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 18:16:23 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.738 | trans_loss 5.657 | nll_loss 2.952 | w2v_ctc_loss 1.137 | task_loss 4.305 | contrastive_loss 0.265 | total 4003.4 | n_correct 2419.3 | ppl 7.74 | accuracy 60.431 | uer 17.615 | wer 19.347 | raw_wer 19.347 | bleu 18.08 | wps 1853.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 18.56
2023-07-11 18:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-11 18:16:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_18.0809.pt
2023-07-11 18:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_18.0809.pt
2023-07-11 18:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_18.0809.pt (epoch 10 @ 14732 updates, score 18.08) (writing took 5.617863837978803 seconds)
2023-07-11 18:16:29 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-11 18:16:29 | INFO | train | epoch 010 | loss 2.399 | trans_loss 3.468 | nll_loss 1.615 | w2v_ctc_loss 0.663 | task_loss 0.476 | contrastive_loss 0.168 | total 4138.65 | n_correct 2514.91 | ppl 3.06 | accuracy 60.766 | wps 12970.3 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.342 | clip 0 | loss_scale 16 | train_wall 1320 | gb_free 17.4 | wall 13221
2023-07-11 18:16:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 18:16:29 | INFO | fairseq.trainer | begin training epoch 11
2023-07-11 18:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 18:17:37 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.373, trans_loss=3.448, nll_loss=1.59, w2v_ctc_loss=0.642, task_loss=0.441, contrastive_loss=0.177, total=4175.24, n_correct=2572.3, ppl=3.01, accuracy=61.608, wps=9449.1, ups=0.76, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.335, clip=0, loss_scale=16, train_wall=89, gb_free=16.9, wall=13290
2023-07-11 18:19:07 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.365, trans_loss=3.449, nll_loss=1.591, w2v_ctc_loss=0.643, task_loss=0.492, contrastive_loss=0.096, total=4087.78, n_correct=2509.75, ppl=3.01, accuracy=61.396, wps=13582.8, ups=1.11, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.34, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=13380
2023-07-11 18:20:37 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.363, trans_loss=3.446, nll_loss=1.589, w2v_ctc_loss=0.639, task_loss=0.49, contrastive_loss=0.091, total=4118.77, n_correct=2533.15, ppl=3.01, accuracy=61.503, wps=13689.7, ups=1.11, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.341, clip=0, loss_scale=32, train_wall=89, gb_free=12.7, wall=13470
tensor(0.2304, device='cuda:0')
tensor(0.1732, device='cuda:0')
2023-07-11 18:22:07 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.37, trans_loss=3.445, nll_loss=1.585, w2v_ctc_loss=0.639, task_loss=0.487, contrastive_loss=0.096, total=4097.83, n_correct=2522.02, ppl=3, accuracy=61.545, wps=13612.8, ups=1.12, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=13559
2023-07-11 18:23:38 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.392, trans_loss=3.459, nll_loss=1.599, w2v_ctc_loss=0.641, task_loss=0.499, contrastive_loss=0.255, total=4110.64, n_correct=2515.02, ppl=3.03, accuracy=61.183, wps=13497.6, ups=1.1, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=16.5, wall=13650
2023-07-11 18:25:09 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.396, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.652, task_loss=0.508, contrastive_loss=0.252, total=4071.69, n_correct=2492.62, ppl=3.04, accuracy=61.218, wps=13344.3, ups=1.1, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.25, clip=0, loss_scale=32, train_wall=91, gb_free=16.5, wall=13742
2023-07-11 18:26:39 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.392, trans_loss=3.452, nll_loss=1.594, w2v_ctc_loss=0.642, task_loss=0.469, contrastive_loss=0.332, total=4157.2, n_correct=2546.95, ppl=3.02, accuracy=61.266, wps=13784.8, ups=1.11, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=13831
2023-07-11 18:28:09 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.38, trans_loss=3.457, nll_loss=1.599, w2v_ctc_loss=0.651, task_loss=0.475, contrastive_loss=0.097, total=4174.91, n_correct=2559.48, ppl=3.03, accuracy=61.306, wps=13816.6, ups=1.11, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.247, clip=0, loss_scale=32, train_wall=90, gb_free=17.1, wall=13922
2023-07-11 18:29:39 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.374, trans_loss=3.456, nll_loss=1.601, w2v_ctc_loss=0.649, task_loss=0.5, contrastive_loss=0.081, total=4118.44, n_correct=2515.8, ppl=3.03, accuracy=61.086, wps=13729.9, ups=1.12, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=11.2, wall=14011
2023-07-11 18:31:08 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.375, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.648, task_loss=0.486, contrastive_loss=0.097, total=4140.92, n_correct=2539.07, ppl=3.03, accuracy=61.317, wps=13772.5, ups=1.11, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=15.8, wall=14101
2023-07-11 18:32:38 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.38, trans_loss=3.454, nll_loss=1.598, w2v_ctc_loss=0.65, task_loss=0.468, contrastive_loss=0.121, total=4136.99, n_correct=2542.77, ppl=3.03, accuracy=61.464, wps=13840.8, ups=1.12, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=17.7, wall=14190
2023-07-11 18:34:09 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.38, trans_loss=3.455, nll_loss=1.604, w2v_ctc_loss=0.652, task_loss=0.471, contrastive_loss=0.104, total=4185.65, n_correct=2559.93, ppl=3.04, accuracy=61.16, wps=13747.6, ups=1.1, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=14.3, wall=14281
2023-07-11 18:35:39 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.396, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.658, task_loss=0.457, contrastive_loss=0.193, total=4171.89, n_correct=2558.47, ppl=3.03, accuracy=61.326, wps=13789.3, ups=1.11, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.251, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=14372
2023-07-11 18:35:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2304, device='cuda:4')
tensor(0.1732, device='cuda:4')
tensor(0.2304, device='cuda:5')
tensor(0.1732, device='cuda:5')
tensor(0.2304, device='cuda:1')
tensor(0.1732, device='cuda:1')
tensor(0.2304, device='cuda:7')
tensor(0.1732, device='cuda:7')
tensor(0.2304, device='cuda:2')
tensor(0.1732, device='cuda:2')
tensor(0.2304, device='cuda:6')
tensor(0.1732, device='cuda:6')
tensor(0.2304, device='cuda:3')
tensor(0.1732, device='cuda:3')
2023-07-11 18:36:06 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.744 | trans_loss 5.641 | nll_loss 2.929 | w2v_ctc_loss 1.204 | task_loss 4.34 | contrastive_loss 0.251 | total 4003.4 | n_correct 2434 | ppl 7.62 | accuracy 60.798 | uer 17.466 | wer 19.153 | raw_wer 19.153 | bleu 19.1 | wps 2014.9 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.1
2023-07-11 18:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-11 18:36:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_11_16000.pt
2023-07-11 18:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_11_16000.pt
2023-07-11 18:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.1) (writing took 9.29670836403966 seconds)
2023-07-11 18:37:46 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.39, trans_loss=3.455, nll_loss=1.599, w2v_ctc_loss=0.64, task_loss=0.441, contrastive_loss=0.41, total=4190.34, n_correct=2567.63, ppl=3.03, accuracy=61.275, wps=9822.9, ups=0.79, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=17.1, wall=14499
2023-07-11 18:39:17 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.369, trans_loss=3.454, nll_loss=1.6, w2v_ctc_loss=0.643, task_loss=0.461, contrastive_loss=0.106, total=4158.39, n_correct=2552.25, ppl=3.03, accuracy=61.376, wps=13765.5, ups=1.11, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.245, clip=0, loss_scale=32, train_wall=90, gb_free=17.1, wall=14589
2023-07-11 18:39:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 18:39:49 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.724 | trans_loss 5.638 | nll_loss 2.928 | w2v_ctc_loss 1.137 | task_loss 4.311 | contrastive_loss 0.258 | total 4003.4 | n_correct 2429.8 | ppl 7.61 | accuracy 60.693 | uer 17.652 | wer 19.414 | raw_wer 19.414 | bleu 19.22 | wps 2035.4 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.22
2023-07-11 18:39:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-11 18:39:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 18:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 18:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.22) (writing took 8.445870677998755 seconds)
2023-07-11 18:39:57 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-11 18:39:57 | INFO | train | epoch 011 | loss 2.379 | trans_loss 3.453 | nll_loss 1.596 | w2v_ctc_loss 0.646 | task_loss 0.476 | contrastive_loss 0.164 | total 4138.65 | n_correct 2538.73 | ppl 3.02 | accuracy 61.342 | wps 12929.5 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.265 | clip 0 | loss_scale 32 | train_wall 1322 | gb_free 17.3 | wall 14630
2023-07-11 18:39:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 18:39:58 | INFO | fairseq.trainer | begin training epoch 12
2023-07-11 18:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 18:41:30 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.352, trans_loss=3.43, nll_loss=1.566, w2v_ctc_loss=0.629, task_loss=0.456, contrastive_loss=0.148, total=4146.82, n_correct=2580.53, ppl=2.96, accuracy=62.229, wps=9286.1, ups=0.75, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.244, clip=0, loss_scale=32, train_wall=89, gb_free=15.9, wall=14722
2023-07-11 18:43:01 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.357, trans_loss=3.433, nll_loss=1.57, w2v_ctc_loss=0.634, task_loss=0.493, contrastive_loss=0.085, total=4120.68, n_correct=2560.3, ppl=2.97, accuracy=62.133, wps=13611.5, ups=1.1, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.247, clip=0, loss_scale=32, train_wall=90, gb_free=15.8, wall=14813
2023-07-11 18:44:31 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.343, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.62, task_loss=0.449, contrastive_loss=0.125, total=4199.46, n_correct=2614.27, ppl=2.97, accuracy=62.253, wps=13800.2, ups=1.1, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=14904
2023-07-11 18:46:02 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.355, trans_loss=3.434, nll_loss=1.573, w2v_ctc_loss=0.629, task_loss=0.466, contrastive_loss=0.102, total=4151.14, n_correct=2580.97, ppl=2.98, accuracy=62.175, wps=13729.6, ups=1.11, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=14994
2023-07-11 18:47:32 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.372, trans_loss=3.448, nll_loss=1.588, w2v_ctc_loss=0.645, task_loss=0.478, contrastive_loss=0.113, total=4110.49, n_correct=2542.92, ppl=3.01, accuracy=61.864, wps=13605.3, ups=1.11, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=14.1, wall=15084
2023-07-11 18:49:03 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.371, trans_loss=3.435, nll_loss=1.577, w2v_ctc_loss=0.635, task_loss=0.454, contrastive_loss=0.199, total=4189.92, n_correct=2599.38, ppl=2.98, accuracy=62.039, wps=13776.5, ups=1.1, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.246, clip=0, loss_scale=32, train_wall=91, gb_free=15.1, wall=15175
2023-07-11 18:50:33 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.359, trans_loss=3.433, nll_loss=1.574, w2v_ctc_loss=0.621, task_loss=0.436, contrastive_loss=0.317, total=4206.3, n_correct=2614.39, ppl=2.98, accuracy=62.154, wps=13907.9, ups=1.11, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.246, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=15265
2023-07-11 18:52:03 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.357, trans_loss=3.441, nll_loss=1.579, w2v_ctc_loss=0.636, task_loss=0.488, contrastive_loss=0.1, total=4085.96, n_correct=2535.7, ppl=2.99, accuracy=62.059, wps=13473.1, ups=1.1, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.25, clip=0, loss_scale=64, train_wall=90, gb_free=16.6, wall=15356
2023-07-11 18:53:35 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.366, trans_loss=3.437, nll_loss=1.578, w2v_ctc_loss=0.631, task_loss=0.484, contrastive_loss=0.164, total=4169.74, n_correct=2589.14, ppl=2.99, accuracy=62.094, wps=13628.7, ups=1.09, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.244, clip=0, loss_scale=64, train_wall=91, gb_free=16.2, wall=15447
2023-07-11 18:55:04 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.372, trans_loss=3.444, nll_loss=1.585, w2v_ctc_loss=0.639, task_loss=0.484, contrastive_loss=0.181, total=4117.67, n_correct=2544.34, ppl=3, accuracy=61.791, wps=13720.6, ups=1.12, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.249, clip=0, loss_scale=64, train_wall=89, gb_free=17.7, wall=15537
2023-07-11 18:55:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 18:56:34 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.381, trans_loss=3.446, nll_loss=1.587, w2v_ctc_loss=0.649, task_loss=0.518, contrastive_loss=0.074, total=4014.56, n_correct=2484.71, ppl=3, accuracy=61.892, wps=13288.5, ups=1.11, wpb=11998.6, bsz=419.2, num_updates=17300, lr=0.000107521, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=15627
2023-07-11 18:58:05 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.378, trans_loss=3.448, nll_loss=1.594, w2v_ctc_loss=0.649, task_loss=0.464, contrastive_loss=0.197, total=4201.13, n_correct=2582.98, ppl=3.02, accuracy=61.483, wps=13873.2, ups=1.11, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=17.4, wall=15717
2023-07-11 18:59:35 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.367, trans_loss=3.447, nll_loss=1.592, w2v_ctc_loss=0.644, task_loss=0.532, contrastive_loss=0.081, total=4070.27, n_correct=2512.88, ppl=3.01, accuracy=61.737, wps=13490.5, ups=1.11, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.248, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=15808
2023-07-11 19:01:06 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.372, trans_loss=3.441, nll_loss=1.584, w2v_ctc_loss=0.631, task_loss=0.476, contrastive_loss=0.219, total=4139.63, n_correct=2559.31, ppl=3, accuracy=61.825, wps=13593.5, ups=1.1, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.248, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=15898
2023-07-11 19:02:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 19:02:44 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.716 | trans_loss 5.623 | nll_loss 2.91 | w2v_ctc_loss 1.142 | task_loss 4.326 | contrastive_loss 0.255 | total 4003.4 | n_correct 2444.8 | ppl 7.52 | accuracy 61.068 | uer 17.413 | wer 19.246 | raw_wer 19.246 | bleu 19.72 | wps 2027.4 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.72
2023-07-11 19:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-11 19:02:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 19:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 19:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.72) (writing took 8.39038396498654 seconds)
2023-07-11 19:02:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-11 19:02:53 | INFO | train | epoch 012 | loss 2.364 | trans_loss 3.44 | nll_loss 1.58 | w2v_ctc_loss 0.635 | task_loss 0.477 | contrastive_loss 0.149 | total 4136.49 | n_correct 2563.69 | ppl 2.99 | accuracy 61.977 | wps 13225.4 | ups 1.07 | wpb 12350.1 | bsz 457.4 | num_updates 17679 | lr 0.000106362 | gnorm 0.247 | clip 0 | loss_scale 32 | train_wall 1325 | gb_free 13.2 | wall 16005
2023-07-11 19:02:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 19:02:53 | INFO | fairseq.trainer | begin training epoch 13
2023-07-11 19:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 19:03:20 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.368, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.644, task_loss=0.496, contrastive_loss=0.092, total=4096.49, n_correct=2535.65, ppl=3, accuracy=61.898, wps=9126.8, ups=0.75, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=14.8, wall=16033
2023-07-11 19:04:51 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.337, trans_loss=3.419, nll_loss=1.554, w2v_ctc_loss=0.615, task_loss=0.478, contrastive_loss=0.106, total=4160.97, n_correct=2609, ppl=2.94, accuracy=62.702, wps=13705.7, ups=1.1, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.245, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=16123
2023-07-11 19:06:22 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.357, trans_loss=3.421, nll_loss=1.561, w2v_ctc_loss=0.615, task_loss=0.439, contrastive_loss=0.392, total=4212.08, n_correct=2637.32, ppl=2.95, accuracy=62.613, wps=13767.9, ups=1.1, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.243, clip=0, loss_scale=32, train_wall=91, gb_free=14.9, wall=16214
2023-07-11 19:07:51 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.339, trans_loss=3.424, nll_loss=1.558, w2v_ctc_loss=0.616, task_loss=0.497, contrastive_loss=0.088, total=4102.3, n_correct=2577.59, ppl=2.94, accuracy=62.833, wps=13652.8, ups=1.12, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.247, clip=0, loss_scale=32, train_wall=89, gb_free=17.4, wall=16304
2023-07-11 19:07:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 19:08:18 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.719 | trans_loss 5.629 | nll_loss 2.913 | w2v_ctc_loss 1.12 | task_loss 4.276 | contrastive_loss 0.255 | total 4003.4 | n_correct 2438.5 | ppl 7.53 | accuracy 60.911 | uer 17.251 | wer 19.19 | raw_wer 19.19 | bleu 19.47 | wps 1977.7 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.72
2023-07-11 19:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-11 19:08:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_13_18000.pt
2023-07-11 19:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_13_18000.pt
2023-07-11 19:08:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.47) (writing took 6.2924145860015415 seconds)
2023-07-11 19:09:54 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.35, trans_loss=3.428, nll_loss=1.565, w2v_ctc_loss=0.621, task_loss=0.448, contrastive_loss=0.151, total=4177.29, n_correct=2620.78, ppl=2.96, accuracy=62.739, wps=10180.5, ups=0.82, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.245, clip=0, loss_scale=32, train_wall=89, gb_free=17.6, wall=16426
2023-07-11 19:11:25 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.359, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.624, task_loss=0.46, contrastive_loss=0.199, total=4201.22, n_correct=2619.74, ppl=2.96, accuracy=62.357, wps=13719.2, ups=1.09, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.246, clip=0, loss_scale=32, train_wall=91, gb_free=13.2, wall=16518
2023-07-11 19:12:55 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.337, trans_loss=3.422, nll_loss=1.558, w2v_ctc_loss=0.616, task_loss=0.462, contrastive_loss=0.083, total=4161.98, n_correct=2612.51, ppl=2.94, accuracy=62.771, wps=13825.3, ups=1.11, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.242, clip=0, loss_scale=32, train_wall=89, gb_free=16, wall=16607
2023-07-11 19:14:26 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.362, trans_loss=3.429, nll_loss=1.567, w2v_ctc_loss=0.64, task_loss=0.525, contrastive_loss=0.082, total=4096.76, n_correct=2555.34, ppl=2.96, accuracy=62.375, wps=13481.3, ups=1.1, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=16.8, wall=16698
2023-07-11 19:15:57 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.351, trans_loss=3.428, nll_loss=1.566, w2v_ctc_loss=0.622, task_loss=0.482, contrastive_loss=0.143, total=4121.73, n_correct=2569.87, ppl=2.96, accuracy=62.349, wps=13553.9, ups=1.1, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.25, clip=0, loss_scale=32, train_wall=90, gb_free=15, wall=16789
2023-07-11 19:17:26 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.344, trans_loss=3.429, nll_loss=1.569, w2v_ctc_loss=0.621, task_loss=0.486, contrastive_loss=0.094, total=4107.01, n_correct=2563.86, ppl=2.97, accuracy=62.426, wps=13677, ups=1.12, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.247, clip=0, loss_scale=32, train_wall=89, gb_free=16.1, wall=16879
2023-07-11 19:18:56 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.363, trans_loss=3.427, nll_loss=1.569, w2v_ctc_loss=0.632, task_loss=0.501, contrastive_loss=0.162, total=4081.02, n_correct=2538.16, ppl=2.97, accuracy=62.194, wps=13627.9, ups=1.12, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.25, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=16968
2023-07-11 19:20:25 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.345, trans_loss=3.427, nll_loss=1.564, w2v_ctc_loss=0.619, task_loss=0.47, contrastive_loss=0.14, total=4105.62, n_correct=2570.48, ppl=2.96, accuracy=62.609, wps=13696.4, ups=1.12, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=17058
2023-07-11 19:21:55 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.358, trans_loss=3.436, nll_loss=1.575, w2v_ctc_loss=0.632, task_loss=0.506, contrastive_loss=0.086, total=4110.35, n_correct=2560.95, ppl=2.98, accuracy=62.305, wps=13654.7, ups=1.11, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.251, clip=0, loss_scale=32, train_wall=90, gb_free=15.1, wall=17148
2023-07-11 19:23:25 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.352, trans_loss=3.426, nll_loss=1.566, w2v_ctc_loss=0.621, task_loss=0.468, contrastive_loss=0.215, total=4112.2, n_correct=2577.25, ppl=2.96, accuracy=62.673, wps=13632.6, ups=1.11, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.25, clip=0, loss_scale=32, train_wall=90, gb_free=17.7, wall=17238
2023-07-11 19:24:56 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.36, trans_loss=3.436, nll_loss=1.575, w2v_ctc_loss=0.622, task_loss=0.468, contrastive_loss=0.231, total=4180.88, n_correct=2605.98, ppl=2.98, accuracy=62.331, wps=13810.7, ups=1.11, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.247, clip=0, loss_scale=32, train_wall=90, gb_free=15.5, wall=17328
2023-07-11 19:25:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 19:26:10 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.698 | trans_loss 5.611 | nll_loss 2.896 | w2v_ctc_loss 1.114 | task_loss 4.325 | contrastive_loss 0.247 | total 4003.4 | n_correct 2446 | ppl 7.44 | accuracy 61.098 | uer 17.015 | wer 18.795 | raw_wer 18.795 | bleu 19.6 | wps 2029.5 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.72
2023-07-11 19:26:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-11 19:26:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.6009.pt
2023-07-11 19:26:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.6009.pt
2023-07-11 19:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.6009.pt (epoch 13 @ 19153 updates, score 19.6) (writing took 5.455620841996279 seconds)
2023-07-11 19:26:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-11 19:26:16 | INFO | train | epoch 013 | loss 2.351 | trans_loss 3.427 | nll_loss 1.565 | w2v_ctc_loss 0.623 | task_loss 0.476 | contrastive_loss 0.155 | total 4138.65 | n_correct 2587.77 | ppl 2.96 | accuracy 62.527 | wps 12981.9 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.247 | clip 0 | loss_scale 32 | train_wall 1323 | gb_free 17.7 | wall 17408
2023-07-11 19:26:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 19:26:16 | INFO | fairseq.trainer | begin training epoch 14
2023-07-11 19:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 19:27:06 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.316, trans_loss=3.406, nll_loss=1.54, w2v_ctc_loss=0.606, task_loss=0.436, contrastive_loss=0.101, total=4176.2, n_correct=2641.65, ppl=2.91, accuracy=63.255, wps=9578.9, ups=0.77, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.241, clip=0, loss_scale=32, train_wall=89, gb_free=11.2, wall=17459
2023-07-11 19:28:36 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.32, trans_loss=3.408, nll_loss=1.538, w2v_ctc_loss=0.606, task_loss=0.484, contrastive_loss=0.079, total=4080.86, n_correct=2591.88, ppl=2.9, accuracy=63.513, wps=13586.6, ups=1.11, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.247, clip=0, loss_scale=64, train_wall=89, gb_free=17, wall=17548
2023-07-11 19:30:06 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.342, trans_loss=3.419, nll_loss=1.552, w2v_ctc_loss=0.606, task_loss=0.503, contrastive_loss=0.213, total=4106.97, n_correct=2591.75, ppl=2.93, accuracy=63.106, wps=13627.1, ups=1.11, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.248, clip=0, loss_scale=64, train_wall=89, gb_free=12.7, wall=17638
2023-07-11 19:31:35 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.317, trans_loss=3.401, nll_loss=1.539, w2v_ctc_loss=0.603, task_loss=0.435, contrastive_loss=0.124, total=4179.8, n_correct=2642.83, ppl=2.91, accuracy=63.229, wps=13912, ups=1.12, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.245, clip=0, loss_scale=64, train_wall=89, gb_free=17.4, wall=17728
2023-07-11 19:33:05 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.334, trans_loss=3.416, nll_loss=1.551, w2v_ctc_loss=0.61, task_loss=0.488, contrastive_loss=0.074, total=4120.38, n_correct=2596.96, ppl=2.93, accuracy=63.027, wps=13685.2, ups=1.11, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.248, clip=0, loss_scale=64, train_wall=89, gb_free=17.3, wall=17817
2023-07-11 19:34:36 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.343, trans_loss=3.422, nll_loss=1.558, w2v_ctc_loss=0.62, task_loss=0.505, contrastive_loss=0.117, total=4089.86, n_correct=2568.6, ppl=2.94, accuracy=62.804, wps=13504.6, ups=1.1, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.249, clip=0, loss_scale=64, train_wall=90, gb_free=12.4, wall=17908
2023-07-11 19:36:05 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.34, trans_loss=3.418, nll_loss=1.555, w2v_ctc_loss=0.609, task_loss=0.475, contrastive_loss=0.179, total=4158.94, n_correct=2618.17, ppl=2.94, accuracy=62.953, wps=13827.5, ups=1.11, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.248, clip=0, loss_scale=64, train_wall=89, gb_free=16.4, wall=17998
2023-07-11 19:37:35 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.322, trans_loss=3.411, nll_loss=1.545, w2v_ctc_loss=0.607, task_loss=0.464, contrastive_loss=0.088, total=4150.03, n_correct=2628.7, ppl=2.92, accuracy=63.342, wps=13801, ups=1.11, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.244, clip=0, loss_scale=64, train_wall=89, gb_free=15.7, wall=18088
2023-07-11 19:39:05 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.335, trans_loss=3.408, nll_loss=1.545, w2v_ctc_loss=0.603, task_loss=0.454, contrastive_loss=0.234, total=4162.8, n_correct=2627.13, ppl=2.92, accuracy=63.11, wps=13819.8, ups=1.11, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.248, clip=0, loss_scale=64, train_wall=89, gb_free=17.2, wall=18178
2023-07-11 19:39:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 19:39:30 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.696 | trans_loss 5.6 | nll_loss 2.88 | w2v_ctc_loss 1.138 | task_loss 4.339 | contrastive_loss 0.241 | total 4003.4 | n_correct 2459.6 | ppl 7.36 | accuracy 61.438 | uer 16.994 | wer 18.81 | raw_wer 18.81 | bleu 19.68 | wps 2060.6 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.72
2023-07-11 19:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-11 19:39:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_14_20000.pt
2023-07-11 19:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_14_20000.pt
2023-07-11 19:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.68) (writing took 6.47353205201216 seconds)
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-11 19:40:42 | INFO | train_inner | epoch 014:    947 / 1474 loss=1.708, trans_loss=5.359, nll_loss=2.703, w2v_ctc_loss=0.56, task_loss=1.403, contrastive_loss=0.138, total=4159.46, n_correct=2607.53, ppl=6.51, accuracy=62.689, wps=4401.6, ups=1.04, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=64, gb_free=15.6, wall=18274
2023-07-11 19:41:46 | INFO | train_inner | epoch 014:   1047 / 1474 loss=1.7, trans_loss=5.43, nll_loss=2.75, w2v_ctc_loss=0.555, task_loss=1.427, contrastive_loss=0.27, total=4155.93, n_correct=2607.92, ppl=6.73, accuracy=62.752, wps=6466.1, ups=1.56, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=18339
2023-07-11 19:42:50 | INFO | train_inner | epoch 014:   1147 / 1474 loss=1.71, trans_loss=5.436, nll_loss=2.759, w2v_ctc_loss=0.562, task_loss=1.34, contrastive_loss=0.718, total=4228.09, n_correct=2645.2, ppl=6.77, accuracy=62.563, wps=6579.8, ups=1.56, wpb=4228.1, bsz=163.2, num_updates=20300, lr=9.92583e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=17.7, wall=18403
2023-07-11 19:43:54 | INFO | train_inner | epoch 014:   1247 / 1474 loss=1.716, trans_loss=5.443, nll_loss=2.764, w2v_ctc_loss=0.572, task_loss=1.656, contrastive_loss=0.105, total=4027.71, n_correct=2515.69, ppl=6.79, accuracy=62.46, wps=6326.5, ups=1.57, wpb=4027.7, bsz=136.8, num_updates=20400, lr=9.90148e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=18467
2023-07-11 19:44:58 | INFO | train_inner | epoch 014:   1347 / 1474 loss=1.686, trans_loss=5.427, nll_loss=2.747, w2v_ctc_loss=0.551, task_loss=1.371, contrastive_loss=0.136, total=4198.71, n_correct=2634.16, ppl=6.71, accuracy=62.737, wps=6551.9, ups=1.56, wpb=4198.7, bsz=157.7, num_updates=20500, lr=9.8773e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=18531
2023-07-11 19:46:02 | INFO | train_inner | epoch 014:   1447 / 1474 loss=1.696, trans_loss=5.435, nll_loss=2.758, w2v_ctc_loss=0.556, task_loss=1.407, contrastive_loss=0.213, total=4140.5, n_correct=2593.42, ppl=6.77, accuracy=62.635, wps=6501.2, ups=1.57, wpb=4140.5, bsz=153.5, num_updates=20600, lr=9.85329e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=18594
2023-07-11 19:46:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
2023-07-11 19:46:46 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.718 | trans_loss 5.605 | nll_loss 2.89 | w2v_ctc_loss 1.177 | task_loss 4.288 | contrastive_loss 0.248 | total 4003.4 | n_correct 2448.6 | ppl 7.41 | accuracy 61.163 | uer 17.302 | wer 19.03 | raw_wer 19.03 | bleu 19.55 | wps 1933.8 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.72
2023-07-11 19:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-11 19:46:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.5505.pt
2023-07-11 19:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.5505.pt
2023-07-11 19:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.5505.pt (epoch 14 @ 20627 updates, score 19.55) (writing took 5.2673428999842145 seconds)
2023-07-11 19:46:51 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-11 19:46:51 | INFO | train | epoch 014 | loss 2.147 | trans_loss 3.813 | nll_loss 1.786 | w2v_ctc_loss 0.593 | task_loss 0.663 | contrastive_loss 0.161 | total 4138.65 | n_correct 2604.87 | ppl 3.45 | accuracy 62.94 | wps 10571.6 | ups 1.19 | wpb 8862.4 | bsz 329.2 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.318 | clip 0 | loss_scale 64 | train_wall 1157 | gb_free 16.6 | wall 18644
2023-07-11 19:46:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 19:46:52 | INFO | fairseq.trainer | begin training epoch 15
2023-07-11 19:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 19:47:46 | INFO | train_inner | epoch 015:     73 / 1474 loss=1.692, trans_loss=5.398, nll_loss=2.709, w2v_ctc_loss=0.546, task_loss=1.428, contrastive_loss=0.313, total=4083.93, n_correct=2581.28, ppl=6.54, accuracy=63.206, wps=3921.7, ups=0.96, wpb=4083.9, bsz=150, num_updates=20700, lr=9.82946e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=15.8, wall=18699
2023-07-11 19:48:50 | INFO | train_inner | epoch 015:    173 / 1474 loss=1.688, trans_loss=5.388, nll_loss=2.694, w2v_ctc_loss=0.554, task_loss=1.475, contrastive_loss=0.128, total=4122.67, n_correct=2610.16, ppl=6.47, accuracy=63.312, wps=6476, ups=1.57, wpb=4122.7, bsz=149.6, num_updates=20800, lr=9.80581e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=18762
2023-07-11 19:49:53 | INFO | train_inner | epoch 015:    273 / 1474 loss=1.674, trans_loss=5.383, nll_loss=2.688, w2v_ctc_loss=0.544, task_loss=1.375, contrastive_loss=0.113, total=4190.11, n_correct=2657.38, ppl=6.45, accuracy=63.42, wps=6592.1, ups=1.57, wpb=4190.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=18826
2023-07-11 19:50:57 | INFO | train_inner | epoch 015:    373 / 1474 loss=1.684, trans_loss=5.381, nll_loss=2.684, w2v_ctc_loss=0.546, task_loss=1.471, contrastive_loss=0.156, total=4150.33, n_correct=2637.79, ppl=6.43, accuracy=63.556, wps=6486.8, ups=1.56, wpb=4150.3, bsz=150.5, num_updates=21000, lr=9.759e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=15.7, wall=18890
2023-07-11 19:52:01 | INFO | train_inner | epoch 015:    473 / 1474 loss=1.692, trans_loss=5.396, nll_loss=2.705, w2v_ctc_loss=0.549, task_loss=1.46, contrastive_loss=0.345, total=4082.7, n_correct=2580.37, ppl=6.52, accuracy=63.203, wps=6397.8, ups=1.57, wpb=4082.7, bsz=149.2, num_updates=21100, lr=9.73585e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=18954
2023-07-11 19:53:05 | INFO | train_inner | epoch 015:    573 / 1474 loss=1.695, trans_loss=5.402, nll_loss=2.714, w2v_ctc_loss=0.562, task_loss=1.506, contrastive_loss=0.122, total=4130.96, n_correct=2607.18, ppl=6.56, accuracy=63.113, wps=6488.9, ups=1.57, wpb=4131, bsz=146.7, num_updates=21200, lr=9.71286e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=19017
2023-07-11 19:54:09 | INFO | train_inner | epoch 015:    673 / 1474 loss=1.683, trans_loss=5.392, nll_loss=2.701, w2v_ctc_loss=0.55, task_loss=1.418, contrastive_loss=0.265, total=4138.41, n_correct=2622.35, ppl=6.5, accuracy=63.366, wps=6457.7, ups=1.56, wpb=4138.4, bsz=154.7, num_updates=21300, lr=9.69003e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=17.1, wall=19081
2023-07-11 19:55:13 | INFO | train_inner | epoch 015:    773 / 1474 loss=1.69, trans_loss=5.406, nll_loss=2.72, w2v_ctc_loss=0.557, task_loss=1.434, contrastive_loss=0.164, total=4186.48, n_correct=2636.26, ppl=6.59, accuracy=62.971, wps=6515.6, ups=1.56, wpb=4186.5, bsz=153.9, num_updates=21400, lr=9.66736e-05, gnorm=0.414, clip=0, loss_scale=128, train_wall=64, gb_free=16.9, wall=19146
2023-07-11 19:56:16 | INFO | train_inner | epoch 015:    873 / 1474 loss=1.685, trans_loss=5.405, nll_loss=2.719, w2v_ctc_loss=0.554, task_loss=1.556, contrastive_loss=0.121, total=4054.09, n_correct=2556.54, ppl=6.58, accuracy=63.061, wps=6421, ups=1.58, wpb=4054.1, bsz=143.1, num_updates=21500, lr=9.64486e-05, gnorm=0.42, clip=0, loss_scale=128, train_wall=63, gb_free=16, wall=19209
2023-07-11 19:57:20 | INFO | train_inner | epoch 015:    973 / 1474 loss=1.689, trans_loss=5.396, nll_loss=2.706, w2v_ctc_loss=0.548, task_loss=1.423, contrastive_loss=0.291, total=4126.63, n_correct=2609.42, ppl=6.53, accuracy=63.234, wps=6493, ups=1.57, wpb=4126.6, bsz=151.5, num_updates=21600, lr=9.6225e-05, gnorm=0.415, clip=0, loss_scale=128, train_wall=63, gb_free=17, wall=19272
2023-07-11 19:58:24 | INFO | train_inner | epoch 015:   1073 / 1474 loss=1.691, trans_loss=5.405, nll_loss=2.719, w2v_ctc_loss=0.545, task_loss=1.327, contrastive_loss=0.601, total=4199.33, n_correct=2648.65, ppl=6.59, accuracy=63.073, wps=6520.2, ups=1.55, wpb=4199.3, bsz=163.6, num_updates=21700, lr=9.60031e-05, gnorm=0.414, clip=0, loss_scale=128, train_wall=64, gb_free=11.9, wall=19337
2023-07-11 19:59:28 | INFO | train_inner | epoch 015:   1173 / 1474 loss=1.669, trans_loss=5.387, nll_loss=2.699, w2v_ctc_loss=0.538, task_loss=1.301, contrastive_loss=0.216, total=4172.81, n_correct=2649.28, ppl=6.49, accuracy=63.489, wps=6564.4, ups=1.57, wpb=4172.8, bsz=163.2, num_updates=21800, lr=9.57826e-05, gnorm=0.404, clip=0, loss_scale=128, train_wall=63, gb_free=13.2, wall=19400
2023-07-11 20:00:31 | INFO | train_inner | epoch 015:   1273 / 1474 loss=1.685, trans_loss=5.398, nll_loss=2.711, w2v_ctc_loss=0.558, task_loss=1.447, contrastive_loss=0.127, total=4152.76, n_correct=2624.17, ppl=6.55, accuracy=63.191, wps=6538.9, ups=1.57, wpb=4152.8, bsz=152.3, num_updates=21900, lr=9.55637e-05, gnorm=0.413, clip=0, loss_scale=128, train_wall=63, gb_free=16.8, wall=19464
2023-07-11 20:01:35 | INFO | train_inner | epoch 015:   1373 / 1474 loss=1.693, trans_loss=5.396, nll_loss=2.707, w2v_ctc_loss=0.557, task_loss=1.472, contrastive_loss=0.101, total=4107.77, n_correct=2596.64, ppl=6.53, accuracy=63.213, wps=6483.3, ups=1.58, wpb=4107.8, bsz=147, num_updates=22000, lr=9.53463e-05, gnorm=0.417, clip=0, loss_scale=128, train_wall=63, gb_free=15.5, wall=19527
2023-07-11 20:01:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:02:03 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.703 | trans_loss 5.603 | nll_loss 2.883 | w2v_ctc_loss 1.125 | task_loss 4.298 | contrastive_loss 0.248 | total 4003.4 | n_correct 2456.7 | ppl 7.37 | accuracy 61.365 | uer 17.102 | wer 18.944 | raw_wer 18.944 | bleu 19.68 | wps 1916.6 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.72
2023-07-11 20:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-11 20:02:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_15_22000.pt
2023-07-11 20:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_15_22000.pt
2023-07-11 20:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.68) (writing took 6.336914867977612 seconds)
2023-07-11 20:03:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 20:03:14 | INFO | train_inner | epoch 015:   1474 / 1474 loss=1.678, trans_loss=5.396, nll_loss=2.709, w2v_ctc_loss=0.55, task_loss=1.405, contrastive_loss=0.162, total=4131.68, n_correct=2611.63, ppl=6.54, accuracy=63.21, wps=4138.9, ups=1, wpb=4131.7, bsz=154.8, num_updates=22100, lr=9.51303e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=65, gb_free=17.2, wall=19627
2023-07-11 20:03:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:03:41 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.704 | trans_loss 5.595 | nll_loss 2.878 | w2v_ctc_loss 1.162 | task_loss 4.302 | contrastive_loss 0.249 | total 4003.4 | n_correct 2463.6 | ppl 7.35 | accuracy 61.538 | uer 16.925 | wer 18.754 | raw_wer 18.754 | bleu 20.15 | wps 2104.1 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 20.15
2023-07-11 20:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-11 20:03:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 20:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 20:03:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 15 @ 22100 updates, score 20.15) (writing took 8.306494717020541 seconds)
2023-07-11 20:03:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-11 20:03:49 | INFO | train | epoch 015 | loss 1.685 | trans_loss 5.394 | nll_loss 2.704 | w2v_ctc_loss 0.55 | task_loss 1.429 | contrastive_loss 0.219 | total 4138.19 | n_correct 2617.64 | ppl 6.52 | accuracy 63.256 | wps 5987.8 | ups 1.45 | wpb 4138.2 | bsz 152.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.414 | clip 0 | loss_scale 64 | train_wall 933 | gb_free 17.2 | wall 19662
2023-07-11 20:03:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 20:03:50 | INFO | fairseq.trainer | begin training epoch 16
2023-07-11 20:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 20:05:01 | INFO | train_inner | epoch 016:    100 / 1474 loss=1.663, trans_loss=5.344, nll_loss=2.639, w2v_ctc_loss=0.537, task_loss=1.363, contrastive_loss=0.157, total=4126.22, n_correct=2643.68, ppl=6.23, accuracy=64.07, wps=3871.2, ups=0.94, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=63, gb_free=16.3, wall=19734
2023-07-11 20:06:05 | INFO | train_inner | epoch 016:    200 / 1474 loss=1.654, trans_loss=5.343, nll_loss=2.637, w2v_ctc_loss=0.529, task_loss=1.474, contrastive_loss=0.11, total=4100.6, n_correct=2627.46, ppl=6.22, accuracy=64.075, wps=6410.4, ups=1.56, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.404, clip=0, loss_scale=64, train_wall=63, gb_free=13, wall=19798
2023-07-11 20:07:09 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.686, trans_loss=5.374, nll_loss=2.679, w2v_ctc_loss=0.553, task_loss=1.412, contrastive_loss=0.257, total=4166.94, n_correct=2649.04, ppl=6.4, accuracy=63.573, wps=6514.5, ups=1.56, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=19862
2023-07-11 20:08:12 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.684, trans_loss=5.375, nll_loss=2.679, w2v_ctc_loss=0.551, task_loss=1.524, contrastive_loss=0.285, total=4073.3, n_correct=2589.22, ppl=6.4, accuracy=63.566, wps=6419.7, ups=1.58, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=19925
2023-07-11 20:09:17 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.671, trans_loss=5.365, nll_loss=2.668, w2v_ctc_loss=0.544, task_loss=1.37, contrastive_loss=0.177, total=4174.67, n_correct=2664.69, ppl=6.36, accuracy=63.83, wps=6510.5, ups=1.56, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=64, gb_free=16.2, wall=19989
2023-07-11 20:10:20 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.68, trans_loss=5.361, nll_loss=2.661, w2v_ctc_loss=0.543, task_loss=1.44, contrastive_loss=0.104, total=4124.65, n_correct=2631.6, ppl=6.33, accuracy=63.802, wps=6528.9, ups=1.58, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=20052
2023-07-11 20:11:23 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.679, trans_loss=5.372, nll_loss=2.676, w2v_ctc_loss=0.548, task_loss=1.466, contrastive_loss=0.11, total=4095.49, n_correct=2603.2, ppl=6.39, accuracy=63.563, wps=6423.5, ups=1.57, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=20116
2023-07-11 20:12:27 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.676, trans_loss=5.37, nll_loss=2.675, w2v_ctc_loss=0.54, task_loss=1.373, contrastive_loss=0.232, total=4174.94, n_correct=2653.79, ppl=6.39, accuracy=63.565, wps=6555.5, ups=1.57, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.408, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=20180
2023-07-11 20:13:31 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.668, trans_loss=5.362, nll_loss=2.664, w2v_ctc_loss=0.536, task_loss=1.383, contrastive_loss=0.216, total=4163.19, n_correct=2657.24, ppl=6.34, accuracy=63.827, wps=6564, ups=1.58, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=20243
2023-07-11 20:14:35 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.686, trans_loss=5.382, nll_loss=2.689, w2v_ctc_loss=0.554, task_loss=1.484, contrastive_loss=0.214, total=4103.45, n_correct=2602.72, ppl=6.45, accuracy=63.428, wps=6393.9, ups=1.56, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=15.1, wall=20307
2023-07-11 20:15:39 | INFO | train_inner | epoch 016:   1100 / 1474 loss=1.689, trans_loss=5.389, nll_loss=2.699, w2v_ctc_loss=0.556, task_loss=1.521, contrastive_loss=0.165, total=4119.27, n_correct=2609.7, ppl=6.5, accuracy=63.353, wps=6442.5, ups=1.56, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=20371
2023-07-11 20:16:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 20:16:43 | INFO | train_inner | epoch 016:   1201 / 1474 loss=1.674, trans_loss=5.376, nll_loss=2.683, w2v_ctc_loss=0.542, task_loss=1.491, contrastive_loss=0.125, total=4132.57, n_correct=2622.2, ppl=6.42, accuracy=63.452, wps=6407.2, ups=1.55, wpb=4132.6, bsz=149.4, num_updates=23300, lr=9.26482e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=64, gb_free=15.1, wall=20436
2023-07-11 20:17:47 | INFO | train_inner | epoch 016:   1301 / 1474 loss=1.683, trans_loss=5.388, nll_loss=2.699, w2v_ctc_loss=0.552, task_loss=1.385, contrastive_loss=0.319, total=4151.03, n_correct=2632.13, ppl=6.5, accuracy=63.409, wps=6486.7, ups=1.56, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=20500
2023-07-11 20:18:51 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.676, trans_loss=5.38, nll_loss=2.689, w2v_ctc_loss=0.549, task_loss=1.363, contrastive_loss=0.173, total=4201.47, n_correct=2669.39, ppl=6.45, accuracy=63.535, wps=6553.2, ups=1.56, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=64, gb_free=16.2, wall=20564
2023-07-11 20:19:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:20:07 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.697 | trans_loss 5.581 | nll_loss 2.861 | w2v_ctc_loss 1.165 | task_loss 4.333 | contrastive_loss 0.245 | total 4003.4 | n_correct 2472.6 | ppl 7.27 | accuracy 61.763 | uer 17.015 | wer 18.78 | raw_wer 18.78 | bleu 19.96 | wps 1759.6 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 20.15
2023-07-11 20:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-11 20:20:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.9604.pt
2023-07-11 20:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.9604.pt
2023-07-11 20:20:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.9604.pt (epoch 16 @ 23573 updates, score 19.96) (writing took 5.315621708985418 seconds)
2023-07-11 20:20:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-11 20:20:13 | INFO | train | epoch 016 | loss 1.677 | trans_loss 5.371 | nll_loss 2.675 | w2v_ctc_loss 0.546 | task_loss 1.43 | contrastive_loss 0.208 | total 4137.02 | n_correct 2632.57 | ppl 6.39 | accuracy 63.635 | wps 6196 | ups 1.5 | wpb 4137 | bsz 152.5 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.413 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 15.6 | wall 20646
2023-07-11 20:20:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 20:20:13 | INFO | fairseq.trainer | begin training epoch 17
2023-07-11 20:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 20:20:39 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.683, trans_loss=5.363, nll_loss=2.665, w2v_ctc_loss=0.545, task_loss=1.454, contrastive_loss=0.452, total=4145.04, n_correct=2641.7, ppl=6.34, accuracy=63.732, wps=3852, ups=0.93, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=64, gb_free=15.8, wall=20672
2023-07-11 20:21:43 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.672, trans_loss=5.334, nll_loss=2.627, w2v_ctc_loss=0.545, task_loss=1.469, contrastive_loss=0.121, total=4117.27, n_correct=2643.62, ppl=6.18, accuracy=64.208, wps=6456, ups=1.57, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.409, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=20735
2023-07-11 20:22:46 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.668, trans_loss=5.34, nll_loss=2.636, w2v_ctc_loss=0.532, task_loss=1.352, contrastive_loss=0.455, total=4159.6, n_correct=2666.08, ppl=6.22, accuracy=64.095, wps=6542.5, ups=1.57, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=20799
2023-07-11 20:23:50 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.669, trans_loss=5.341, nll_loss=2.637, w2v_ctc_loss=0.536, task_loss=1.422, contrastive_loss=0.462, total=4156.91, n_correct=2663.02, ppl=6.22, accuracy=64.062, wps=6550.6, ups=1.58, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=20862
2023-07-11 20:24:54 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.666, trans_loss=5.342, nll_loss=2.638, w2v_ctc_loss=0.543, task_loss=1.413, contrastive_loss=0.121, total=4146.43, n_correct=2663.92, ppl=6.23, accuracy=64.246, wps=6432.5, ups=1.55, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=20927
2023-07-11 20:24:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:25:22 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.589 | nll_loss 2.866 | w2v_ctc_loss 1.176 | task_loss 4.349 | contrastive_loss 0.25 | total 4003.4 | n_correct 2463.3 | ppl 7.29 | accuracy 61.53 | uer 17.302 | wer 19.026 | raw_wer 19.026 | bleu 19.74 | wps 1881 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.15
2023-07-11 20:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-11 20:25:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_17_24000.pt
2023-07-11 20:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_17_24000.pt
2023-07-11 20:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.74) (writing took 6.632995163963642 seconds)
2023-07-11 20:26:34 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.676, trans_loss=5.351, nll_loss=2.65, w2v_ctc_loss=0.547, task_loss=1.486, contrastive_loss=0.215, total=4182.1, n_correct=2671.8, ppl=6.28, accuracy=63.887, wps=4199.6, ups=1, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=21026
2023-07-11 20:27:38 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.668, trans_loss=5.348, nll_loss=2.646, w2v_ctc_loss=0.539, task_loss=1.437, contrastive_loss=0.111, total=4167.27, n_correct=2669.6, ppl=6.26, accuracy=64.061, wps=6536.3, ups=1.57, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.406, clip=0, loss_scale=32, train_wall=63, gb_free=11.3, wall=21090
2023-07-11 20:28:42 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.676, trans_loss=5.362, nll_loss=2.665, w2v_ctc_loss=0.551, task_loss=1.411, contrastive_loss=0.211, total=4166.12, n_correct=2657.24, ppl=6.34, accuracy=63.782, wps=6510.9, ups=1.56, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=64, gb_free=16.5, wall=21154
2023-07-11 20:29:45 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.68, trans_loss=5.354, nll_loss=2.654, w2v_ctc_loss=0.546, task_loss=1.442, contrastive_loss=0.136, total=4091.64, n_correct=2615.44, ppl=6.29, accuracy=63.922, wps=6482.5, ups=1.58, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=21217
2023-07-11 20:30:47 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.668, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=0.537, task_loss=1.402, contrastive_loss=0.133, total=4106.83, n_correct=2630.38, ppl=6.23, accuracy=64.049, wps=6540.3, ups=1.59, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=21280
2023-07-11 20:31:51 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.67, trans_loss=5.346, nll_loss=2.645, w2v_ctc_loss=0.542, task_loss=1.401, contrastive_loss=0.14, total=4115.49, n_correct=2634.76, ppl=6.25, accuracy=64.021, wps=6473.6, ups=1.57, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=21344
2023-07-11 20:32:54 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.666, trans_loss=5.347, nll_loss=2.646, w2v_ctc_loss=0.536, task_loss=1.486, contrastive_loss=0.114, total=4078.39, n_correct=2607.18, ppl=6.26, accuracy=63.927, wps=6470.6, ups=1.59, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=21407
2023-07-11 20:33:59 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.684, trans_loss=5.375, nll_loss=2.684, w2v_ctc_loss=0.541, task_loss=1.38, contrastive_loss=0.608, total=4173.49, n_correct=2652.4, ppl=6.42, accuracy=63.554, wps=6438.7, ups=1.54, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=21472
2023-07-11 20:35:03 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.666, trans_loss=5.356, nll_loss=2.659, w2v_ctc_loss=0.534, task_loss=1.419, contrastive_loss=0.279, total=4156.28, n_correct=2652.47, ppl=6.32, accuracy=63.818, wps=6453.8, ups=1.55, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=64, gb_free=17.9, wall=21536
2023-07-11 20:36:07 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.651, trans_loss=5.354, nll_loss=2.657, w2v_ctc_loss=0.533, task_loss=1.453, contrastive_loss=0.124, total=4112.95, n_correct=2627.38, ppl=6.31, accuracy=63.881, wps=6435.4, ups=1.56, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=21600
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-11 20:36:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
2023-07-11 20:37:05 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.702 | trans_loss 5.574 | nll_loss 2.853 | w2v_ctc_loss 1.172 | task_loss 4.309 | contrastive_loss 0.251 | total 4003.4 | n_correct 2473.2 | ppl 7.22 | accuracy 61.777 | uer 17.174 | wer 18.985 | raw_wer 18.985 | bleu 20.15 | wps 1882.7 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.15
2023-07-11 20:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-11 20:37:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 20:37:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 20:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 17 @ 25047 updates, score 20.15) (writing took 10.075528635992669 seconds)
2023-07-11 20:37:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-11 20:37:16 | INFO | train | epoch 017 | loss 1.67 | trans_loss 5.349 | nll_loss 2.648 | w2v_ctc_loss 0.54 | task_loss 1.428 | contrastive_loss 0.229 | total 4138.65 | n_correct 2647.71 | ppl 6.27 | accuracy 63.975 | wps 5965.2 | ups 1.44 | wpb 4138.6 | bsz 152.8 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.413 | clip 0 | loss_scale 32 | train_wall 935 | gb_free 16.6 | wall 21668
2023-07-11 20:37:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 20:37:16 | INFO | fairseq.trainer | begin training epoch 18
2023-07-11 20:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 20:37:58 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.668, trans_loss=5.337, nll_loss=2.632, w2v_ctc_loss=0.541, task_loss=1.455, contrastive_loss=0.143, total=4139.04, n_correct=2656.19, ppl=6.2, accuracy=64.174, wps=3731.2, ups=0.9, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=21711
2023-07-11 20:39:02 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.659, trans_loss=5.31, nll_loss=2.597, w2v_ctc_loss=0.521, task_loss=1.362, contrastive_loss=0.393, total=4154.85, n_correct=2684.28, ppl=6.05, accuracy=64.606, wps=6515.6, ups=1.57, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=21775
2023-07-11 20:40:06 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.653, trans_loss=5.308, nll_loss=2.595, w2v_ctc_loss=0.529, task_loss=1.385, contrastive_loss=0.125, total=4162.72, n_correct=2693.97, ppl=6.04, accuracy=64.717, wps=6472.4, ups=1.55, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=64, gb_free=16.4, wall=21839
2023-07-11 20:41:10 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.656, trans_loss=5.323, nll_loss=2.614, w2v_ctc_loss=0.53, task_loss=1.447, contrastive_loss=0.153, total=4161.22, n_correct=2676.64, ppl=6.12, accuracy=64.323, wps=6504.9, ups=1.56, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=63, gb_free=14.7, wall=21903
2023-07-11 20:42:14 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.672, trans_loss=5.333, nll_loss=2.626, w2v_ctc_loss=0.538, task_loss=1.52, contrastive_loss=0.338, total=4092.36, n_correct=2627.87, ppl=6.17, accuracy=64.214, wps=6389.9, ups=1.56, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=21967
2023-07-11 20:43:18 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.641, trans_loss=5.306, nll_loss=2.594, w2v_ctc_loss=0.523, task_loss=1.286, contrastive_loss=0.151, total=4206.45, n_correct=2716.82, ppl=6.04, accuracy=64.587, wps=6589, ups=1.57, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=22031
2023-07-11 20:44:22 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.669, trans_loss=5.341, nll_loss=2.638, w2v_ctc_loss=0.535, task_loss=1.475, contrastive_loss=0.293, total=4097.96, n_correct=2628.51, ppl=6.22, accuracy=64.142, wps=6460.9, ups=1.58, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=12.7, wall=22094
2023-07-11 20:45:25 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.665, trans_loss=5.337, nll_loss=2.632, w2v_ctc_loss=0.539, task_loss=1.369, contrastive_loss=0.468, total=4208.5, n_correct=2703.07, ppl=6.2, accuracy=64.229, wps=6602.9, ups=1.57, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.406, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=22158
2023-07-11 20:46:30 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.661, trans_loss=5.33, nll_loss=2.624, w2v_ctc_loss=0.533, task_loss=1.441, contrastive_loss=0.107, total=4166.07, n_correct=2676.35, ppl=6.17, accuracy=64.242, wps=6479.6, ups=1.56, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=16.5, wall=22222
2023-07-11 20:47:32 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.654, trans_loss=5.324, nll_loss=2.617, w2v_ctc_loss=0.53, task_loss=1.33, contrastive_loss=0.154, total=4141.27, n_correct=2666.3, ppl=6.14, accuracy=64.384, wps=6606.6, ups=1.6, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=62, gb_free=16.2, wall=22285
2023-07-11 20:47:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:47:58 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.694 | trans_loss 5.574 | nll_loss 2.848 | w2v_ctc_loss 1.17 | task_loss 4.327 | contrastive_loss 0.25 | total 4003.4 | n_correct 2475.4 | ppl 7.2 | accuracy 61.832 | uer 17.251 | wer 19.09 | raw_wer 19.09 | bleu 19.95 | wps 2037.8 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.15
2023-07-11 20:47:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-11 20:47:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_18_26000.pt
2023-07-11 20:48:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_18_26000.pt
2023-07-11 20:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.95) (writing took 6.5418811429990456 seconds)
2023-07-11 20:49:09 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.658, trans_loss=5.333, nll_loss=2.629, w2v_ctc_loss=0.53, task_loss=1.487, contrastive_loss=0.133, total=4134.55, n_correct=2656.2, ppl=6.19, accuracy=64.244, wps=4254, ups=1.03, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=22382
2023-07-11 20:50:14 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.662, trans_loss=5.325, nll_loss=2.619, w2v_ctc_loss=0.534, task_loss=1.363, contrastive_loss=0.345, total=4157.63, n_correct=2674.4, ppl=6.14, accuracy=64.325, wps=6481.3, ups=1.56, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=64, gb_free=17.2, wall=22446
2023-07-11 20:51:17 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.669, trans_loss=5.345, nll_loss=2.644, w2v_ctc_loss=0.539, task_loss=1.541, contrastive_loss=0.123, total=4085.66, n_correct=2612.95, ppl=6.25, accuracy=63.954, wps=6434.4, ups=1.57, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=17.6, wall=22510
2023-07-11 20:52:20 | INFO | train_inner | epoch 018:   1353 / 1474 loss=1.679, trans_loss=5.354, nll_loss=2.657, w2v_ctc_loss=0.553, task_loss=1.522, contrastive_loss=0.172, total=4065.6, n_correct=2599.21, ppl=6.31, accuracy=63.932, wps=6442.9, ups=1.58, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=13.5, wall=22573
2023-07-11 20:53:25 | INFO | train_inner | epoch 018:   1453 / 1474 loss=1.667, trans_loss=5.341, nll_loss=2.64, w2v_ctc_loss=0.539, task_loss=1.485, contrastive_loss=0.142, total=4122.48, n_correct=2641.37, ppl=6.23, accuracy=64.072, wps=6395.1, ups=1.55, wpb=4122.5, bsz=149.7, num_updates=26500, lr=8.68744e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=22637
2023-07-11 20:53:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 20:54:05 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.701 | trans_loss 5.574 | nll_loss 2.85 | w2v_ctc_loss 1.18 | task_loss 4.298 | contrastive_loss 0.257 | total 4003.4 | n_correct 2472 | ppl 7.21 | accuracy 61.748 | uer 17.007 | wer 18.94 | raw_wer 18.94 | bleu 19.71 | wps 1971.6 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 20.15
2023-07-11 20:54:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-07-11 20:54:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.7109.pt
2023-07-11 20:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.7109.pt
2023-07-11 20:54:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_19.7109.pt (epoch 18 @ 26521 updates, score 19.71) (writing took 5.267518118023872 seconds)
2023-07-11 20:54:11 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-11 20:54:11 | INFO | train | epoch 018 | loss 1.662 | trans_loss 5.329 | nll_loss 2.623 | w2v_ctc_loss 0.534 | task_loss 1.428 | contrastive_loss 0.228 | total 4138.65 | n_correct 2660.42 | ppl 6.16 | accuracy 64.282 | wps 6010.1 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 26521 | lr 8.684e-05 | gnorm 0.413 | clip 0 | loss_scale 64 | train_wall 934 | gb_free 16.1 | wall 22683
2023-07-11 20:54:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 20:54:11 | INFO | fairseq.trainer | begin training epoch 19
2023-07-11 20:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 20:55:09 | INFO | train_inner | epoch 019:     79 / 1474 loss=1.663, trans_loss=5.3, nll_loss=2.585, w2v_ctc_loss=0.526, task_loss=1.429, contrastive_loss=0.242, total=4101.48, n_correct=2654.16, ppl=6, accuracy=64.712, wps=3931.7, ups=0.96, wpb=4101.5, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=22742
2023-07-11 20:56:14 | INFO | train_inner | epoch 019:    179 / 1474 loss=1.647, trans_loss=5.295, nll_loss=2.579, w2v_ctc_loss=0.532, task_loss=1.331, contrastive_loss=0.223, total=4227.39, n_correct=2741.98, ppl=5.98, accuracy=64.862, wps=6526.8, ups=1.54, wpb=4227.4, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=22806
2023-07-11 20:57:18 | INFO | train_inner | epoch 019:    279 / 1474 loss=1.643, trans_loss=5.284, nll_loss=2.564, w2v_ctc_loss=0.522, task_loss=1.411, contrastive_loss=0.113, total=4186.65, n_correct=2725.67, ppl=5.91, accuracy=65.104, wps=6574.8, ups=1.57, wpb=4186.6, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=0.405, clip=0, loss_scale=64, train_wall=63, gb_free=14.1, wall=22870
2023-07-11 20:58:21 | INFO | train_inner | epoch 019:    379 / 1474 loss=1.65, trans_loss=5.299, nll_loss=2.584, w2v_ctc_loss=0.52, task_loss=1.413, contrastive_loss=0.33, total=4165.84, n_correct=2696.22, ppl=6, accuracy=64.722, wps=6536.9, ups=1.57, wpb=4165.8, bsz=155, num_updates=26900, lr=8.62261e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=22934
2023-07-11 20:59:25 | INFO | train_inner | epoch 019:    479 / 1474 loss=1.651, trans_loss=5.307, nll_loss=2.596, w2v_ctc_loss=0.53, task_loss=1.452, contrastive_loss=0.143, total=4122.98, n_correct=2663.86, ppl=6.04, accuracy=64.61, wps=6472.1, ups=1.57, wpb=4123, bsz=151.3, num_updates=27000, lr=8.60663e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=22998
2023-07-11 21:00:28 | INFO | train_inner | epoch 019:    579 / 1474 loss=1.649, trans_loss=5.304, nll_loss=2.591, w2v_ctc_loss=0.524, task_loss=1.41, contrastive_loss=0.274, total=4121.66, n_correct=2666.86, ppl=6.02, accuracy=64.704, wps=6521.3, ups=1.58, wpb=4121.7, bsz=152.2, num_updates=27100, lr=8.59074e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=23061
2023-07-11 21:01:32 | INFO | train_inner | epoch 019:    679 / 1474 loss=1.638, trans_loss=5.302, nll_loss=2.59, w2v_ctc_loss=0.517, task_loss=1.3, contrastive_loss=0.13, total=4205.65, n_correct=2721.41, ppl=6.02, accuracy=64.708, wps=6617, ups=1.57, wpb=4205.6, bsz=161.5, num_updates=27200, lr=8.57493e-05, gnorm=0.403, clip=0, loss_scale=64, train_wall=63, gb_free=16.3, wall=23124
2023-07-11 21:02:36 | INFO | train_inner | epoch 019:    779 / 1474 loss=1.655, trans_loss=5.306, nll_loss=2.594, w2v_ctc_loss=0.532, task_loss=1.476, contrastive_loss=0.134, total=4120.36, n_correct=2661.7, ppl=6.04, accuracy=64.599, wps=6451.7, ups=1.57, wpb=4120.4, bsz=149.3, num_updates=27300, lr=8.55921e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=14.1, wall=23188
2023-07-11 21:03:39 | INFO | train_inner | epoch 019:    879 / 1474 loss=1.659, trans_loss=5.321, nll_loss=2.613, w2v_ctc_loss=0.536, task_loss=1.423, contrastive_loss=0.132, total=4176.52, n_correct=2688.81, ppl=6.12, accuracy=64.379, wps=6563, ups=1.57, wpb=4176.5, bsz=154.9, num_updates=27400, lr=8.54358e-05, gnorm=0.413, clip=0, loss_scale=128, train_wall=63, gb_free=17.1, wall=23252
2023-07-11 21:04:43 | INFO | train_inner | epoch 019:    979 / 1474 loss=1.665, trans_loss=5.335, nll_loss=2.633, w2v_ctc_loss=0.53, task_loss=1.457, contrastive_loss=0.596, total=4079.93, n_correct=2619.9, ppl=6.2, accuracy=64.214, wps=6347.4, ups=1.56, wpb=4079.9, bsz=152.5, num_updates=27500, lr=8.52803e-05, gnorm=0.419, clip=0, loss_scale=128, train_wall=64, gb_free=16.7, wall=23316
2023-07-11 21:05:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 21:05:48 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.66, trans_loss=5.328, nll_loss=2.623, w2v_ctc_loss=0.533, task_loss=1.53, contrastive_loss=0.121, total=4034.29, n_correct=2591.22, ppl=6.16, accuracy=64.23, wps=6277.2, ups=1.56, wpb=4034.3, bsz=144.5, num_updates=27600, lr=8.51257e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=17.4, wall=23380
2023-07-11 21:06:52 | INFO | train_inner | epoch 019:   1180 / 1474 loss=1.676, trans_loss=5.334, nll_loss=2.631, w2v_ctc_loss=0.538, task_loss=1.446, contrastive_loss=0.367, total=4140.95, n_correct=2654.89, ppl=6.2, accuracy=64.113, wps=6406.5, ups=1.55, wpb=4140.9, bsz=154, num_updates=27700, lr=8.49719e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=13.1, wall=23445
2023-07-11 21:07:55 | INFO | train_inner | epoch 019:   1280 / 1474 loss=1.669, trans_loss=5.329, nll_loss=2.625, w2v_ctc_loss=0.531, task_loss=1.444, contrastive_loss=0.164, total=4135.79, n_correct=2656.73, ppl=6.17, accuracy=64.238, wps=6574.3, ups=1.59, wpb=4135.8, bsz=149.8, num_updates=27800, lr=8.48189e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=17.9, wall=23508
2023-07-11 21:08:59 | INFO | train_inner | epoch 019:   1380 / 1474 loss=1.656, trans_loss=5.315, nll_loss=2.607, w2v_ctc_loss=0.531, task_loss=1.46, contrastive_loss=0.135, total=4138.67, n_correct=2667.27, ppl=6.09, accuracy=64.448, wps=6471.6, ups=1.56, wpb=4138.7, bsz=150.8, num_updates=27900, lr=8.46668e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=23572
2023-07-11 21:09:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 21:10:26 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.695 | trans_loss 5.575 | nll_loss 2.857 | w2v_ctc_loss 1.195 | task_loss 4.354 | contrastive_loss 0.26 | total 4003.4 | n_correct 2471.8 | ppl 7.24 | accuracy 61.743 | uer 17.193 | wer 18.892 | raw_wer 18.892 | bleu 20 | wps 1946.7 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 20.15
2023-07-11 21:10:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-11 21:10:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.0006.pt
2023-07-11 21:10:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.0006.pt
2023-07-11 21:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.0006.pt (epoch 19 @ 27994 updates, score 20.0) (writing took 5.304680938017555 seconds)
2023-07-11 21:10:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-11 21:10:31 | INFO | train | epoch 019 | loss 1.656 | trans_loss 5.311 | nll_loss 2.601 | w2v_ctc_loss 0.529 | task_loss 1.429 | contrastive_loss 0.221 | total 4137.8 | n_correct 2671.05 | ppl 6.07 | accuracy 64.552 | wps 6214.5 | ups 1.5 | wpb 4137.8 | bsz 152.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.413 | clip 0 | loss_scale 64 | train_wall 933 | gb_free 17.5 | wall 23664
2023-07-11 21:10:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 21:10:32 | INFO | fairseq.trainer | begin training epoch 20
2023-07-11 21:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 21:10:44 | INFO | train_inner | epoch 020:      6 / 1474 loss=1.665, trans_loss=5.313, nll_loss=2.605, w2v_ctc_loss=0.531, task_loss=1.447, contrastive_loss=0.306, total=4117.61, n_correct=2655.81, ppl=6.08, accuracy=64.499, wps=3933.1, ups=0.96, wpb=4117.6, bsz=151.5, num_updates=28000, lr=8.45154e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=23677
2023-07-11 21:10:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 21:11:09 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.68 | trans_loss 5.569 | nll_loss 2.846 | w2v_ctc_loss 1.158 | task_loss 4.362 | contrastive_loss 0.252 | total 4003.4 | n_correct 2482.6 | ppl 7.19 | accuracy 62.012 | uer 16.948 | wer 18.705 | raw_wer 18.705 | bleu 20.35 | wps 2102.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.35
2023-07-11 21:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-11 21:11:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_20_28000.pt
2023-07-11 21:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_20_28000.pt
2023-07-11 21:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.35) (writing took 9.090474435011856 seconds)
2023-07-11 21:12:23 | INFO | train_inner | epoch 020:    106 / 1474 loss=1.636, trans_loss=5.271, nll_loss=2.548, w2v_ctc_loss=0.517, task_loss=1.379, contrastive_loss=0.149, total=4192.82, n_correct=2736.6, ppl=5.85, accuracy=65.269, wps=4241.1, ups=1.01, wpb=4192.8, bsz=156.4, num_updates=28100, lr=8.43649e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=64, gb_free=16.5, wall=23775
2023-07-11 21:13:28 | INFO | train_inner | epoch 020:    206 / 1474 loss=1.654, trans_loss=5.278, nll_loss=2.557, w2v_ctc_loss=0.522, task_loss=1.473, contrastive_loss=0.255, total=4155.9, n_correct=2708.4, ppl=5.88, accuracy=65.17, wps=6400.2, ups=1.54, wpb=4155.9, bsz=151.1, num_updates=28200, lr=8.42152e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=64, gb_free=12.2, wall=23840
2023-07-11 21:14:32 | INFO | train_inner | epoch 020:    306 / 1474 loss=1.627, trans_loss=5.269, nll_loss=2.546, w2v_ctc_loss=0.514, task_loss=1.288, contrastive_loss=0.13, total=4192.69, n_correct=2735.42, ppl=5.84, accuracy=65.243, wps=6569, ups=1.57, wpb=4192.7, bsz=163.8, num_updates=28300, lr=8.40663e-05, gnorm=0.406, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=23904
2023-07-11 21:15:36 | INFO | train_inner | epoch 020:    406 / 1474 loss=1.634, trans_loss=5.275, nll_loss=2.554, w2v_ctc_loss=0.513, task_loss=1.456, contrastive_loss=0.126, total=4116.96, n_correct=2685.1, ppl=5.87, accuracy=65.22, wps=6425.5, ups=1.56, wpb=4117, bsz=148.4, num_updates=28400, lr=8.39181e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=64, gb_free=13, wall=23968
2023-07-11 21:16:39 | INFO | train_inner | epoch 020:    506 / 1474 loss=1.66, trans_loss=5.303, nll_loss=2.59, w2v_ctc_loss=0.523, task_loss=1.474, contrastive_loss=0.306, total=4100.73, n_correct=2655.99, ppl=6.02, accuracy=64.769, wps=6450.1, ups=1.57, wpb=4100.7, bsz=149.2, num_updates=28500, lr=8.37708e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=24032
2023-07-11 21:17:43 | INFO | train_inner | epoch 020:    606 / 1474 loss=1.656, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=0.524, task_loss=1.479, contrastive_loss=0.308, total=4101.99, n_correct=2656.71, ppl=5.99, accuracy=64.766, wps=6453.5, ups=1.57, wpb=4102, bsz=149.2, num_updates=28600, lr=8.36242e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=63, gb_free=13.8, wall=24095
2023-07-11 21:18:46 | INFO | train_inner | epoch 020:    706 / 1474 loss=1.657, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=0.53, task_loss=1.443, contrastive_loss=0.11, total=4124.25, n_correct=2669.3, ppl=5.99, accuracy=64.722, wps=6514.7, ups=1.58, wpb=4124.2, bsz=148.6, num_updates=28700, lr=8.34784e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=24159
2023-07-11 21:19:50 | INFO | train_inner | epoch 020:    806 / 1474 loss=1.637, trans_loss=5.287, nll_loss=2.57, w2v_ctc_loss=0.522, task_loss=1.408, contrastive_loss=0.122, total=4153.23, n_correct=2697.19, ppl=5.94, accuracy=64.942, wps=6548.8, ups=1.58, wpb=4153.2, bsz=154.3, num_updates=28800, lr=8.33333e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=24222
2023-07-11 21:20:54 | INFO | train_inner | epoch 020:    906 / 1474 loss=1.672, trans_loss=5.313, nll_loss=2.604, w2v_ctc_loss=0.526, task_loss=1.369, contrastive_loss=0.714, total=4153.72, n_correct=2681.54, ppl=6.08, accuracy=64.558, wps=6420.5, ups=1.55, wpb=4153.7, bsz=160.3, num_updates=28900, lr=8.3189e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=16.3, wall=24287
2023-07-11 21:21:58 | INFO | train_inner | epoch 020:   1006 / 1474 loss=1.651, trans_loss=5.297, nll_loss=2.584, w2v_ctc_loss=0.52, task_loss=1.44, contrastive_loss=0.132, total=4156.05, n_correct=2694.56, ppl=5.99, accuracy=64.835, wps=6490.4, ups=1.56, wpb=4156.1, bsz=152.6, num_updates=29000, lr=8.30455e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=15.2, wall=24351
2023-07-11 21:23:02 | INFO | train_inner | epoch 020:   1106 / 1474 loss=1.657, trans_loss=5.304, nll_loss=2.594, w2v_ctc_loss=0.522, task_loss=1.346, contrastive_loss=0.402, total=4181.53, n_correct=2705.62, ppl=6.04, accuracy=64.704, wps=6583.8, ups=1.57, wpb=4181.5, bsz=160.1, num_updates=29100, lr=8.29027e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=24414
2023-07-11 21:24:06 | INFO | train_inner | epoch 020:   1206 / 1474 loss=1.647, trans_loss=5.3, nll_loss=2.587, w2v_ctc_loss=0.533, task_loss=1.581, contrastive_loss=0.101, total=4029.26, n_correct=2607.13, ppl=6.01, accuracy=64.705, wps=6304.1, ups=1.56, wpb=4029.3, bsz=141.2, num_updates=29200, lr=8.27606e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=24478
2023-07-11 21:25:10 | INFO | train_inner | epoch 020:   1306 / 1474 loss=1.649, trans_loss=5.307, nll_loss=2.597, w2v_ctc_loss=0.525, task_loss=1.485, contrastive_loss=0.125, total=4127.21, n_correct=2667.56, ppl=6.05, accuracy=64.633, wps=6464.9, ups=1.57, wpb=4127.2, bsz=150, num_updates=29300, lr=8.26192e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=15.1, wall=24542
2023-07-11 21:26:14 | INFO | train_inner | epoch 020:   1406 / 1474 loss=1.659, trans_loss=5.311, nll_loss=2.601, w2v_ctc_loss=0.532, task_loss=1.53, contrastive_loss=0.115, total=4110.89, n_correct=2654.38, ppl=6.07, accuracy=64.569, wps=6406.3, ups=1.56, wpb=4110.9, bsz=145.8, num_updates=29400, lr=8.24786e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=13.6, wall=24606
2023-07-11 21:26:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 21:27:23 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.664 | trans_loss 5.56 | nll_loss 2.836 | w2v_ctc_loss 1.111 | task_loss 4.345 | contrastive_loss 0.247 | total 4003.4 | n_correct 2484 | ppl 7.14 | accuracy 62.047 | uer 16.816 | wer 18.65 | raw_wer 18.65 | bleu 20.22 | wps 2027.9 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 20.35
2023-07-11 21:27:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-07-11 21:27:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2200.pt
2023-07-11 21:27:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2200.pt
2023-07-11 21:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2200.pt (epoch 20 @ 29468 updates, score 20.22) (writing took 5.237254170991946 seconds)
2023-07-11 21:27:28 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-11 21:27:28 | INFO | train | epoch 020 | loss 1.649 | trans_loss 5.294 | nll_loss 2.579 | w2v_ctc_loss 0.523 | task_loss 1.428 | contrastive_loss 0.223 | total 4138.65 | n_correct 2684.28 | ppl 5.98 | accuracy 64.859 | wps 5998.7 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.414 | clip 0 | loss_scale 64 | train_wall 935 | gb_free 16.8 | wall 24681
2023-07-11 21:27:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 21:27:29 | INFO | fairseq.trainer | begin training epoch 21
2023-07-11 21:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 21:27:57 | INFO | train_inner | epoch 021:     32 / 1474 loss=1.643, trans_loss=5.3, nll_loss=2.589, w2v_ctc_loss=0.52, task_loss=1.35, contrastive_loss=0.357, total=4166.35, n_correct=2699.75, ppl=6.01, accuracy=64.799, wps=4020.3, ups=0.96, wpb=4166.4, bsz=159.7, num_updates=29500, lr=8.23387e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=11.6, wall=24710
2023-07-11 21:29:02 | INFO | train_inner | epoch 021:    132 / 1474 loss=1.626, trans_loss=5.251, nll_loss=2.523, w2v_ctc_loss=0.505, task_loss=1.349, contrastive_loss=0.34, total=4181.45, n_correct=2741.99, ppl=5.75, accuracy=65.575, wps=6499.2, ups=1.55, wpb=4181.4, bsz=158.8, num_updates=29600, lr=8.21995e-05, gnorm=0.404, clip=0, loss_scale=128, train_wall=64, gb_free=15.3, wall=24774
2023-07-11 21:30:05 | INFO | train_inner | epoch 021:    232 / 1474 loss=1.63, trans_loss=5.261, nll_loss=2.536, w2v_ctc_loss=0.506, task_loss=1.352, contrastive_loss=0.254, total=4167.12, n_correct=2726.63, ppl=5.8, accuracy=65.432, wps=6594, ups=1.58, wpb=4167.1, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.409, clip=0, loss_scale=128, train_wall=63, gb_free=12.2, wall=24838
2023-07-11 21:31:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 21:31:10 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.635, trans_loss=5.266, nll_loss=2.542, w2v_ctc_loss=0.521, task_loss=1.479, contrastive_loss=0.117, total=4116.29, n_correct=2687.56, ppl=5.82, accuracy=65.291, wps=6291.1, ups=1.53, wpb=4116.3, bsz=149.5, num_updates=29800, lr=8.19232e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=65, gb_free=16.8, wall=24903
2023-07-11 21:32:14 | INFO | train_inner | epoch 021:    433 / 1474 loss=1.635, trans_loss=5.263, nll_loss=2.539, w2v_ctc_loss=0.511, task_loss=1.364, contrastive_loss=0.115, total=4195.53, n_correct=2746.07, ppl=5.81, accuracy=65.452, wps=6620.8, ups=1.58, wpb=4195.5, bsz=155.8, num_updates=29900, lr=8.17861e-05, gnorm=0.404, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=24966
2023-07-11 21:33:17 | INFO | train_inner | epoch 021:    533 / 1474 loss=1.633, trans_loss=5.267, nll_loss=2.544, w2v_ctc_loss=0.52, task_loss=1.473, contrastive_loss=0.107, total=4085.05, n_correct=2665.25, ppl=5.83, accuracy=65.244, wps=6426.6, ups=1.57, wpb=4085.1, bsz=148, num_updates=30000, lr=8.16497e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=25030
2023-07-11 21:33:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 21:33:43 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.572 | nll_loss 2.85 | w2v_ctc_loss 1.142 | task_loss 4.363 | contrastive_loss 0.248 | total 4003.4 | n_correct 2482.8 | ppl 7.21 | accuracy 62.017 | uer 16.744 | wer 18.519 | raw_wer 18.519 | bleu 20.19 | wps 2002.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.35
2023-07-11 21:33:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-11 21:33:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_21_30000.pt
2023-07-11 21:33:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_21_30000.pt
2023-07-11 21:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.19) (writing took 6.1839848139788955 seconds)
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-11 21:34:54 | INFO | train_inner | epoch 021:    633 / 1474 loss=1.648, trans_loss=5.274, nll_loss=2.554, w2v_ctc_loss=0.513, task_loss=1.409, contrastive_loss=0.447, total=4220.3, n_correct=2752.9, ppl=5.87, accuracy=65.23, wps=4364.2, ups=1.03, wpb=4220.3, bsz=157.9, num_updates=30100, lr=8.15139e-05, gnorm=0.408, clip=0, loss_scale=64, train_wall=63, gb_free=15.9, wall=25127
2023-07-11 21:35:59 | INFO | train_inner | epoch 021:    733 / 1474 loss=1.636, trans_loss=5.283, nll_loss=2.566, w2v_ctc_loss=0.512, task_loss=1.437, contrastive_loss=0.17, total=4148.18, n_correct=2696.76, ppl=5.92, accuracy=65.011, wps=6421.8, ups=1.55, wpb=4148.2, bsz=154.2, num_updates=30200, lr=8.13788e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=12.3, wall=25191
2023-07-11 21:37:03 | INFO | train_inner | epoch 021:    833 / 1474 loss=1.65, trans_loss=5.289, nll_loss=2.573, w2v_ctc_loss=0.522, task_loss=1.513, contrastive_loss=0.199, total=4062.56, n_correct=2637.55, ppl=5.95, accuracy=64.923, wps=6353.7, ups=1.56, wpb=4062.6, bsz=146.5, num_updates=30300, lr=8.12444e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=25255
2023-07-11 21:38:06 | INFO | train_inner | epoch 021:    933 / 1474 loss=1.651, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=0.521, task_loss=1.424, contrastive_loss=0.145, total=4103.66, n_correct=2666.9, ppl=5.89, accuracy=64.988, wps=6465.2, ups=1.58, wpb=4103.7, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=25319
2023-07-11 21:39:09 | INFO | train_inner | epoch 021:   1033 / 1474 loss=1.654, trans_loss=5.298, nll_loss=2.586, w2v_ctc_loss=0.527, task_loss=1.457, contrastive_loss=0.139, total=4100.54, n_correct=2657.33, ppl=6, accuracy=64.804, wps=6485, ups=1.58, wpb=4100.5, bsz=149.1, num_updates=30500, lr=8.09776e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=18, wall=25382
2023-07-11 21:40:14 | INFO | train_inner | epoch 021:   1133 / 1474 loss=1.652, trans_loss=5.285, nll_loss=2.568, w2v_ctc_loss=0.524, task_loss=1.535, contrastive_loss=0.146, total=4119.98, n_correct=2676.57, ppl=5.93, accuracy=64.966, wps=6404.9, ups=1.55, wpb=4120, bsz=147, num_updates=30600, lr=8.08452e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=18, wall=25446
2023-07-11 21:41:17 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.64, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=0.514, task_loss=1.359, contrastive_loss=0.247, total=4161.49, n_correct=2708.67, ppl=5.89, accuracy=65.089, wps=6552.7, ups=1.57, wpb=4161.5, bsz=156.5, num_updates=30700, lr=8.07134e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=25510
2023-07-11 21:42:21 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.641, trans_loss=5.28, nll_loss=2.563, w2v_ctc_loss=0.514, task_loss=1.382, contrastive_loss=0.168, total=4141.76, n_correct=2696.06, ppl=5.91, accuracy=65.095, wps=6477.5, ups=1.56, wpb=4141.8, bsz=155.8, num_updates=30800, lr=8.05823e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=63, gb_free=17.5, wall=25574
2023-07-11 21:43:26 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.661, trans_loss=5.299, nll_loss=2.588, w2v_ctc_loss=0.533, task_loss=1.506, contrastive_loss=0.266, total=4127.02, n_correct=2673.48, ppl=6.01, accuracy=64.78, wps=6404, ups=1.55, wpb=4127, bsz=151.1, num_updates=30900, lr=8.04518e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=25638
2023-07-11 21:43:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
2023-07-11 21:44:18 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.697 | trans_loss 5.563 | nll_loss 2.837 | w2v_ctc_loss 1.173 | task_loss 4.283 | contrastive_loss 0.249 | total 4003.4 | n_correct 2483.7 | ppl 7.15 | accuracy 62.04 | uer 16.808 | wer 18.683 | raw_wer 18.683 | bleu 20.44 | wps 1954.2 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.44
2023-07-11 21:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-07-11 21:44:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 21:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 21:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 21 @ 30941 updates, score 20.44) (writing took 8.379558999964502 seconds)
2023-07-11 21:44:27 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-11 21:44:27 | INFO | train | epoch 021 | loss 1.643 | trans_loss 5.277 | nll_loss 2.557 | w2v_ctc_loss 0.517 | task_loss 1.431 | contrastive_loss 0.214 | total 4137.8 | n_correct 2694.98 | ppl 5.89 | accuracy 65.131 | wps 5983.6 | ups 1.45 | wpb 4137.8 | bsz 152.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.412 | clip 0 | loss_scale 64 | train_wall 935 | gb_free 15.6 | wall 25700
2023-07-11 21:44:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 21:44:27 | INFO | fairseq.trainer | begin training epoch 22
2023-07-11 21:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 21:45:13 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.636, trans_loss=5.261, nll_loss=2.537, w2v_ctc_loss=0.517, task_loss=1.44, contrastive_loss=0.107, total=4140.16, n_correct=2705.83, ppl=5.81, accuracy=65.356, wps=3860.2, ups=0.93, wpb=4140.2, bsz=150.1, num_updates=31000, lr=8.03219e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=25745
2023-07-11 21:46:17 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.631, trans_loss=5.248, nll_loss=2.521, w2v_ctc_loss=0.509, task_loss=1.438, contrastive_loss=0.271, total=4115.86, n_correct=2697.07, ppl=5.74, accuracy=65.529, wps=6433.5, ups=1.56, wpb=4115.9, bsz=154.7, num_updates=31100, lr=8.01927e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=64, gb_free=17.5, wall=25809
2023-07-11 21:47:21 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.619, trans_loss=5.238, nll_loss=2.508, w2v_ctc_loss=0.499, task_loss=1.3, contrastive_loss=0.134, total=4247.73, n_correct=2793.64, ppl=5.69, accuracy=65.768, wps=6639.8, ups=1.56, wpb=4247.7, bsz=161.6, num_updates=31200, lr=8.00641e-05, gnorm=0.406, clip=0, loss_scale=64, train_wall=64, gb_free=14.2, wall=25873
2023-07-11 21:48:26 | INFO | train_inner | epoch 022:    359 / 1474 loss=1.642, trans_loss=5.26, nll_loss=2.535, w2v_ctc_loss=0.509, task_loss=1.41, contrastive_loss=0.477, total=4212.22, n_correct=2754.66, ppl=5.8, accuracy=65.397, wps=6469.7, ups=1.54, wpb=4212.2, bsz=159, num_updates=31300, lr=7.99361e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=65, gb_free=15.8, wall=25938
2023-07-11 21:49:30 | INFO | train_inner | epoch 022:    459 / 1474 loss=1.649, trans_loss=5.269, nll_loss=2.545, w2v_ctc_loss=0.518, task_loss=1.501, contrastive_loss=0.23, total=4131.12, n_correct=2696.26, ppl=5.84, accuracy=65.267, wps=6419.4, ups=1.55, wpb=4131.1, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=26003
2023-07-11 21:50:35 | INFO | train_inner | epoch 022:    559 / 1474 loss=1.634, trans_loss=5.257, nll_loss=2.532, w2v_ctc_loss=0.513, task_loss=1.443, contrastive_loss=0.128, total=4153.54, n_correct=2718.87, ppl=5.78, accuracy=65.459, wps=6449.3, ups=1.55, wpb=4153.5, bsz=153.6, num_updates=31500, lr=7.96819e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=15.2, wall=26067
2023-07-11 21:51:38 | INFO | train_inner | epoch 022:    659 / 1474 loss=1.627, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=0.498, task_loss=1.356, contrastive_loss=0.296, total=4143.91, n_correct=2718.56, ppl=5.74, accuracy=65.604, wps=6561.9, ups=1.58, wpb=4143.9, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=26130
2023-07-11 21:52:42 | INFO | train_inner | epoch 022:    759 / 1474 loss=1.639, trans_loss=5.259, nll_loss=2.533, w2v_ctc_loss=0.517, task_loss=1.466, contrastive_loss=0.135, total=4168.91, n_correct=2726.95, ppl=5.79, accuracy=65.412, wps=6513, ups=1.56, wpb=4168.9, bsz=151.8, num_updates=31700, lr=7.94301e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=64, gb_free=17.7, wall=26194
2023-07-11 21:53:46 | INFO | train_inner | epoch 022:    859 / 1474 loss=1.636, trans_loss=5.27, nll_loss=2.549, w2v_ctc_loss=0.515, task_loss=1.562, contrastive_loss=0.105, total=4079.59, n_correct=2658.83, ppl=5.85, accuracy=65.174, wps=6349.4, ups=1.56, wpb=4079.6, bsz=144.3, num_updates=31800, lr=7.93052e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=17.4, wall=26259
2023-07-11 21:54:50 | INFO | train_inner | epoch 022:    959 / 1474 loss=1.635, trans_loss=5.261, nll_loss=2.538, w2v_ctc_loss=0.511, task_loss=1.43, contrastive_loss=0.11, total=4129.75, n_correct=2699.18, ppl=5.81, accuracy=65.359, wps=6474.5, ups=1.57, wpb=4129.8, bsz=151.9, num_updates=31900, lr=7.91808e-05, gnorm=0.417, clip=0, loss_scale=128, train_wall=63, gb_free=17.9, wall=26322
2023-07-11 21:55:54 | INFO | train_inner | epoch 022:   1059 / 1474 loss=1.634, trans_loss=5.257, nll_loss=2.532, w2v_ctc_loss=0.504, task_loss=1.353, contrastive_loss=0.448, total=4155.56, n_correct=2722.18, ppl=5.79, accuracy=65.507, wps=6508.9, ups=1.57, wpb=4155.6, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.415, clip=0, loss_scale=128, train_wall=63, gb_free=17.2, wall=26386
2023-07-11 21:55:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 21:56:19 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.697 | trans_loss 5.571 | nll_loss 2.852 | w2v_ctc_loss 1.178 | task_loss 4.338 | contrastive_loss 0.252 | total 4003.4 | n_correct 2481.2 | ppl 7.22 | accuracy 61.977 | uer 16.887 | wer 18.687 | raw_wer 18.687 | bleu 20.07 | wps 2089.9 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.44
2023-07-11 21:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-11 21:56:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_22_32000.pt
2023-07-11 21:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_22_32000.pt
2023-07-11 21:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.07) (writing took 6.234673523984384 seconds)
2023-07-11 21:57:30 | INFO | train_inner | epoch 022:   1159 / 1474 loss=1.646, trans_loss=5.289, nll_loss=2.574, w2v_ctc_loss=0.519, task_loss=1.507, contrastive_loss=0.207, total=4089.92, n_correct=2656.7, ppl=5.96, accuracy=64.957, wps=4260.1, ups=1.04, wpb=4089.9, bsz=146.1, num_updates=32100, lr=7.89337e-05, gnorm=0.416, clip=0, loss_scale=128, train_wall=63, gb_free=16.4, wall=26482
2023-07-11 21:58:33 | INFO | train_inner | epoch 022:   1259 / 1474 loss=1.634, trans_loss=5.276, nll_loss=2.559, w2v_ctc_loss=0.513, task_loss=1.338, contrastive_loss=0.201, total=4179.82, n_correct=2721.93, ppl=5.89, accuracy=65.121, wps=6576.3, ups=1.57, wpb=4179.8, bsz=161.2, num_updates=32200, lr=7.8811e-05, gnorm=0.411, clip=0, loss_scale=128, train_wall=63, gb_free=16.6, wall=26546
2023-07-11 21:59:37 | INFO | train_inner | epoch 022:   1359 / 1474 loss=1.635, trans_loss=5.264, nll_loss=2.542, w2v_ctc_loss=0.507, task_loss=1.406, contrastive_loss=0.25, total=4076.98, n_correct=2663.14, ppl=5.82, accuracy=65.321, wps=6430.3, ups=1.58, wpb=4077, bsz=151.5, num_updates=32300, lr=7.86889e-05, gnorm=0.417, clip=0, loss_scale=128, train_wall=63, gb_free=11.2, wall=26609
2023-07-11 22:00:40 | INFO | train_inner | epoch 022:   1459 / 1474 loss=1.652, trans_loss=5.282, nll_loss=2.565, w2v_ctc_loss=0.523, task_loss=1.531, contrastive_loss=0.138, total=4070.93, n_correct=2644.4, ppl=5.92, accuracy=64.958, wps=6379.4, ups=1.57, wpb=4070.9, bsz=143.2, num_updates=32400, lr=7.85674e-05, gnorm=0.42, clip=0, loss_scale=128, train_wall=63, gb_free=16.9, wall=26673
2023-07-11 22:00:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 22:01:18 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.687 | trans_loss 5.561 | nll_loss 2.836 | w2v_ctc_loss 1.149 | task_loss 4.288 | contrastive_loss 0.251 | total 4003.4 | n_correct 2484.6 | ppl 7.14 | accuracy 62.062 | uer 16.956 | wer 18.769 | raw_wer 18.769 | bleu 20.23 | wps 1964.6 | wpb 4003.4 | bsz 141.8 | num_updates 32415 | best_bleu 20.44
2023-07-11 22:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32415 updates
2023-07-11 22:01:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2300.pt
2023-07-11 22:01:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2300.pt
2023-07-11 22:01:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2300.pt (epoch 22 @ 32415 updates, score 20.23) (writing took 5.335600672988221 seconds)
2023-07-11 22:01:23 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-11 22:01:23 | INFO | train | epoch 022 | loss 1.637 | trans_loss 5.262 | nll_loss 2.539 | w2v_ctc_loss 0.511 | task_loss 1.43 | contrastive_loss 0.22 | total 4138.65 | n_correct 2704.86 | ppl 5.81 | accuracy 65.356 | wps 6002.9 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 32415 | lr 7.85492e-05 | gnorm 0.415 | clip 0 | loss_scale 128 | train_wall 936 | gb_free 12.2 | wall 26716
2023-07-11 22:01:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 22:01:23 | INFO | fairseq.trainer | begin training epoch 23
2023-07-11 22:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 22:02:26 | INFO | train_inner | epoch 023:     85 / 1474 loss=1.631, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=0.511, task_loss=1.467, contrastive_loss=0.12, total=4094.01, n_correct=2694.46, ppl=5.67, accuracy=65.815, wps=3887.3, ups=0.95, wpb=4094, bsz=150.5, num_updates=32500, lr=7.84465e-05, gnorm=0.419, clip=0, loss_scale=128, train_wall=64, gb_free=16.6, wall=26778
2023-07-11 22:03:30 | INFO | train_inner | epoch 023:    185 / 1474 loss=1.631, trans_loss=5.236, nll_loss=2.504, w2v_ctc_loss=0.509, task_loss=1.501, contrastive_loss=0.117, total=4118.15, n_correct=2709.83, ppl=5.67, accuracy=65.802, wps=6434.7, ups=1.56, wpb=4118.1, bsz=148.1, num_updates=32600, lr=7.8326e-05, gnorm=0.418, clip=0, loss_scale=128, train_wall=64, gb_free=15.6, wall=26842
2023-07-11 22:03:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 22:04:35 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.629, trans_loss=5.242, nll_loss=2.512, w2v_ctc_loss=0.502, task_loss=1.478, contrastive_loss=0.248, total=4139.05, n_correct=2718.31, ppl=5.7, accuracy=65.675, wps=6387.4, ups=1.54, wpb=4139.1, bsz=150.2, num_updates=32700, lr=7.82062e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=64, gb_free=17.6, wall=26907
2023-07-11 22:05:38 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.629, trans_loss=5.234, nll_loss=2.501, w2v_ctc_loss=0.505, task_loss=1.464, contrastive_loss=0.104, total=4126.79, n_correct=2719.38, ppl=5.66, accuracy=65.896, wps=6474.4, ups=1.57, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=26971
2023-07-11 22:06:42 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.624, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.502, task_loss=1.395, contrastive_loss=0.215, total=4150.15, n_correct=2726.04, ppl=5.7, accuracy=65.685, wps=6553.3, ups=1.58, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=27034
2023-07-11 22:07:45 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.616, trans_loss=5.228, nll_loss=2.495, w2v_ctc_loss=0.499, task_loss=1.343, contrastive_loss=0.113, total=4174.6, n_correct=2752.44, ppl=5.64, accuracy=65.933, wps=6593.2, ups=1.58, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=27098
2023-07-11 22:08:49 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.633, trans_loss=5.236, nll_loss=2.505, w2v_ctc_loss=0.509, task_loss=1.441, contrastive_loss=0.191, total=4136.6, n_correct=2718.87, ppl=5.68, accuracy=65.727, wps=6469.7, ups=1.56, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=17.8, wall=27161
2023-07-11 22:09:52 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.642, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=0.517, task_loss=1.437, contrastive_loss=0.151, total=4147.22, n_correct=2716.44, ppl=5.78, accuracy=65.5, wps=6533.3, ups=1.58, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=27225
2023-07-11 22:10:56 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.629, trans_loss=5.242, nll_loss=2.514, w2v_ctc_loss=0.503, task_loss=1.297, contrastive_loss=0.313, total=4193.16, n_correct=2751.39, ppl=5.71, accuracy=65.616, wps=6610, ups=1.58, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=27288
2023-07-11 22:12:00 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.648, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=0.509, task_loss=1.422, contrastive_loss=0.62, total=4164.33, n_correct=2721.97, ppl=5.79, accuracy=65.364, wps=6511.8, ups=1.56, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=17.8, wall=27352
2023-07-11 22:13:04 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.64, trans_loss=5.258, nll_loss=2.534, w2v_ctc_loss=0.519, task_loss=1.533, contrastive_loss=0.13, total=4088.37, n_correct=2670.5, ppl=5.79, accuracy=65.319, wps=6377.1, ups=1.56, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=27416
2023-07-11 22:14:08 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.626, trans_loss=5.254, nll_loss=2.53, w2v_ctc_loss=0.507, task_loss=1.427, contrastive_loss=0.114, total=4162.3, n_correct=2724.27, ppl=5.78, accuracy=65.451, wps=6498.6, ups=1.56, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=27481
2023-07-11 22:15:12 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.624, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=0.503, task_loss=1.393, contrastive_loss=0.136, total=4131.74, n_correct=2711.09, ppl=5.74, accuracy=65.616, wps=6481, ups=1.57, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=27544
2023-07-11 22:16:16 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.64, trans_loss=5.275, nll_loss=2.557, w2v_ctc_loss=0.514, task_loss=1.441, contrastive_loss=0.247, total=4141.25, n_correct=2698.97, ppl=5.88, accuracy=65.173, wps=6459.9, ups=1.56, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=27608
2023-07-11 22:16:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 22:17:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 22:17:37 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.7 | trans_loss 5.562 | nll_loss 2.835 | w2v_ctc_loss 1.219 | task_loss 4.389 | contrastive_loss 0.243 | total 4003.4 | n_correct 2483.1 | ppl 7.14 | accuracy 62.025 | uer 16.911 | wer 18.638 | raw_wer 18.638 | bleu 20.26 | wps 2093.3 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.44
2023-07-11 22:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-11 22:17:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2608.pt
2023-07-11 22:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2608.pt
2023-07-11 22:17:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.2608.pt (epoch 23 @ 33887 updates, score 20.26) (writing took 5.650784700992517 seconds)
2023-07-11 22:17:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-11 22:17:43 | INFO | train | epoch 023 | loss 1.631 | trans_loss 5.247 | nll_loss 2.52 | w2v_ctc_loss 0.507 | task_loss 1.431 | contrastive_loss 0.218 | total 4138.21 | n_correct 2714.33 | ppl 5.74 | accuracy 65.592 | wps 6215.7 | ups 1.5 | wpb 4138.2 | bsz 152.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.414 | clip 0 | loss_scale 32 | train_wall 934 | gb_free 14.1 | wall 27696
2023-07-11 22:17:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 22:17:43 | INFO | fairseq.trainer | begin training epoch 24
2023-07-11 22:17:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 22:18:00 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.633, trans_loss=5.269, nll_loss=2.55, w2v_ctc_loss=0.501, task_loss=1.438, contrastive_loss=0.4, total=4092.9, n_correct=2672.53, ppl=5.86, accuracy=65.297, wps=3941.3, ups=0.96, wpb=4092.9, bsz=152.7, num_updates=33900, lr=7.68095e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=64, gb_free=13, wall=27712
2023-07-11 22:19:03 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.629, trans_loss=5.225, nll_loss=2.491, w2v_ctc_loss=0.497, task_loss=1.318, contrastive_loss=0.446, total=4171.44, n_correct=2752.86, ppl=5.62, accuracy=65.993, wps=6558.5, ups=1.57, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=27776
2023-07-11 22:19:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 22:19:28 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.68 | trans_loss 5.561 | nll_loss 2.829 | w2v_ctc_loss 1.168 | task_loss 4.391 | contrastive_loss 0.247 | total 4003.4 | n_correct 2486.2 | ppl 7.11 | accuracy 62.102 | uer 16.71 | wer 18.545 | raw_wer 18.545 | bleu 20.17 | wps 2171.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.44
2023-07-11 22:19:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-11 22:19:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_24_34000.pt
2023-07-11 22:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_24_34000.pt
2023-07-11 22:19:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.17) (writing took 6.405975687026512 seconds)
2023-07-11 22:20:40 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.619, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=0.486, task_loss=1.247, contrastive_loss=0.547, total=4251.29, n_correct=2804.15, ppl=5.63, accuracy=65.96, wps=4396.3, ups=1.03, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.408, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=27873
2023-07-11 22:21:44 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.613, trans_loss=5.219, nll_loss=2.483, w2v_ctc_loss=0.497, task_loss=1.401, contrastive_loss=0.107, total=4128.18, n_correct=2727.38, ppl=5.59, accuracy=66.067, wps=6454.7, ups=1.56, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=27936
2023-07-11 22:22:48 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.639, trans_loss=5.244, nll_loss=2.516, w2v_ctc_loss=0.51, task_loss=1.501, contrastive_loss=0.392, total=4158.92, n_correct=2732.14, ppl=5.72, accuracy=65.693, wps=6452.9, ups=1.55, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=28001
2023-07-11 22:23:52 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.625, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=0.504, task_loss=1.454, contrastive_loss=0.248, total=4144.91, n_correct=2725.04, ppl=5.67, accuracy=65.744, wps=6472.8, ups=1.56, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=64, gb_free=17.1, wall=28065
2023-07-11 22:24:56 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.615, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.496, task_loss=1.443, contrastive_loss=0.171, total=4165.3, n_correct=2744.58, ppl=5.63, accuracy=65.892, wps=6531.8, ups=1.57, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.409, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=28129
2023-07-11 22:26:00 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.633, trans_loss=5.242, nll_loss=2.513, w2v_ctc_loss=0.508, task_loss=1.477, contrastive_loss=0.194, total=4102.21, n_correct=2693.01, ppl=5.71, accuracy=65.648, wps=6415.7, ups=1.56, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=64, gb_free=17.1, wall=28193
2023-07-11 22:27:04 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.625, trans_loss=5.233, nll_loss=2.502, w2v_ctc_loss=0.499, task_loss=1.443, contrastive_loss=0.149, total=4110.6, n_correct=2706.31, ppl=5.67, accuracy=65.837, wps=6414.3, ups=1.56, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.409, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=28257
2023-07-11 22:28:08 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.639, trans_loss=5.246, nll_loss=2.517, w2v_ctc_loss=0.513, task_loss=1.578, contrastive_loss=0.101, total=4043.03, n_correct=2649.22, ppl=5.73, accuracy=65.526, wps=6386.3, ups=1.58, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=11.7, wall=28320
2023-07-11 22:29:12 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.624, trans_loss=5.245, nll_loss=2.518, w2v_ctc_loss=0.499, task_loss=1.477, contrastive_loss=0.109, total=4136.81, n_correct=2715.79, ppl=5.73, accuracy=65.649, wps=6441, ups=1.56, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=64, gb_free=17.1, wall=28384
2023-07-11 22:30:16 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.619, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.5, task_loss=1.391, contrastive_loss=0.194, total=4135.73, n_correct=2726.16, ppl=5.63, accuracy=65.917, wps=6475.9, ups=1.57, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=28448
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-11 22:31:20 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.633, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=0.503, task_loss=1.415, contrastive_loss=0.173, total=4148.3, n_correct=2722.86, ppl=5.72, accuracy=65.638, wps=6492.1, ups=1.57, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=28512
2023-07-11 22:32:24 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.637, trans_loss=5.25, nll_loss=2.524, w2v_ctc_loss=0.514, task_loss=1.517, contrastive_loss=0.119, total=4110.05, n_correct=2695.03, ppl=5.75, accuracy=65.572, wps=6416.3, ups=1.56, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=28576
2023-07-11 22:33:27 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.641, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=0.518, task_loss=1.49, contrastive_loss=0.116, total=4090.91, n_correct=2677.16, ppl=5.77, accuracy=65.442, wps=6469.8, ups=1.58, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=28639
2023-07-11 22:34:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
2023-07-11 22:34:31 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.567 | nll_loss 2.838 | w2v_ctc_loss 1.181 | task_loss 4.317 | contrastive_loss 0.251 | total 4003.4 | n_correct 2481.5 | ppl 7.15 | accuracy 61.985 | uer 16.832 | wer 18.724 | raw_wer 18.724 | bleu 20 | wps 2173.8 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.44
2023-07-11 22:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-11 22:34:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-11 22:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-11 22:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 24 @ 35361 updates, score 20.0) (writing took 4.370576318004169 seconds)
2023-07-11 22:34:35 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-11 22:34:35 | INFO | train | epoch 024 | loss 1.627 | trans_loss 5.236 | nll_loss 2.506 | w2v_ctc_loss 0.503 | task_loss 1.43 | contrastive_loss 0.219 | total 4138.65 | n_correct 2721.72 | ppl 5.68 | accuracy 65.763 | wps 6028.8 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.414 | clip 0 | loss_scale 32 | train_wall 936 | gb_free 16.3 | wall 28708
2023-07-11 22:34:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 22:34:35 | INFO | fairseq.trainer | begin training epoch 25
2023-07-11 22:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 22:35:08 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.609, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=0.494, task_loss=1.372, contrastive_loss=0.132, total=4166.95, n_correct=2753.97, ppl=5.6, accuracy=66.091, wps=4128.9, ups=0.99, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=28740
2023-07-11 22:36:12 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.597, trans_loss=5.204, nll_loss=2.465, w2v_ctc_loss=0.489, task_loss=1.408, contrastive_loss=0.126, total=4133.64, n_correct=2743.02, ppl=5.52, accuracy=66.358, wps=6462.3, ups=1.56, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=64, gb_free=16, wall=28804
2023-07-11 22:37:16 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.616, trans_loss=5.209, nll_loss=2.471, w2v_ctc_loss=0.499, task_loss=1.47, contrastive_loss=0.137, total=4114.53, n_correct=2724.62, ppl=5.54, accuracy=66.219, wps=6410.7, ups=1.56, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=28868
2023-07-11 22:38:21 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.631, trans_loss=5.216, nll_loss=2.478, w2v_ctc_loss=0.5, task_loss=1.511, contrastive_loss=0.193, total=4148.7, n_correct=2739.16, ppl=5.57, accuracy=66.025, wps=6391.3, ups=1.54, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=28933
2023-07-11 22:39:25 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.644, trans_loss=5.23, nll_loss=2.497, w2v_ctc_loss=0.512, task_loss=1.485, contrastive_loss=0.354, total=4167.03, n_correct=2746.61, ppl=5.65, accuracy=65.913, wps=6500.2, ups=1.56, wpb=4167, bsz=149.2, num_updates=35800, lr=7.47435e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=64, gb_free=12.7, wall=28998
2023-07-11 22:40:29 | INFO | train_inner | epoch 025:    539 / 1474 loss=1.626, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=0.505, task_loss=1.392, contrastive_loss=0.138, total=4156.93, n_correct=2740.86, ppl=5.64, accuracy=65.935, wps=6478.8, ups=1.56, wpb=4156.9, bsz=156.4, num_updates=35900, lr=7.46393e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=64, gb_free=17.2, wall=29062
2023-07-11 22:41:32 | INFO | train_inner | epoch 025:    639 / 1474 loss=1.621, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=0.498, task_loss=1.424, contrastive_loss=0.273, total=4153.23, n_correct=2746.57, ppl=5.58, accuracy=66.131, wps=6570.4, ups=1.58, wpb=4153.2, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=15.1, wall=29125
2023-07-11 22:41:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 22:41:58 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.151 | task_loss 4.314 | contrastive_loss 0.258 | total 4003.4 | n_correct 2488.7 | ppl 7.11 | accuracy 62.165 | uer 16.641 | wer 18.486 | raw_wer 18.486 | bleu 20.46 | wps 2123.5 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.46
2023-07-11 22:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-11 22:41:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_25_36000.pt
2023-07-11 22:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_25_36000.pt
2023-07-11 22:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.46) (writing took 9.005252268048935 seconds)
2023-07-11 22:43:11 | INFO | train_inner | epoch 025:    739 / 1474 loss=1.624, trans_loss=5.227, nll_loss=2.494, w2v_ctc_loss=0.503, task_loss=1.45, contrastive_loss=0.262, total=4123.21, n_correct=2719.52, ppl=5.63, accuracy=65.956, wps=4179, ups=1.01, wpb=4123.2, bsz=150.4, num_updates=36100, lr=7.44323e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=15, wall=29224
2023-07-11 22:44:15 | INFO | train_inner | epoch 025:    839 / 1474 loss=1.61, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=0.492, task_loss=1.31, contrastive_loss=0.155, total=4197.27, n_correct=2775.01, ppl=5.6, accuracy=66.115, wps=6558.5, ups=1.56, wpb=4197.3, bsz=164.1, num_updates=36200, lr=7.43294e-05, gnorm=0.408, clip=0, loss_scale=64, train_wall=64, gb_free=16.3, wall=29288
2023-07-11 22:45:19 | INFO | train_inner | epoch 025:    939 / 1474 loss=1.624, trans_loss=5.223, nll_loss=2.491, w2v_ctc_loss=0.499, task_loss=1.375, contrastive_loss=0.268, total=4137.23, n_correct=2730.84, ppl=5.62, accuracy=66.006, wps=6456.1, ups=1.56, wpb=4137.2, bsz=156.7, num_updates=36300, lr=7.4227e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=64, gb_free=16.8, wall=29352
2023-07-11 22:46:24 | INFO | train_inner | epoch 025:   1039 / 1474 loss=1.636, trans_loss=5.234, nll_loss=2.503, w2v_ctc_loss=0.493, task_loss=1.408, contrastive_loss=0.49, total=4183.45, n_correct=2751.74, ppl=5.67, accuracy=65.777, wps=6488.1, ups=1.55, wpb=4183.4, bsz=155.5, num_updates=36400, lr=7.41249e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=29416
2023-07-11 22:47:27 | INFO | train_inner | epoch 025:   1139 / 1474 loss=1.623, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.496, task_loss=1.536, contrastive_loss=0.105, total=4045.24, n_correct=2668.48, ppl=5.63, accuracy=65.966, wps=6340.7, ups=1.57, wpb=4045.2, bsz=143.5, num_updates=36500, lr=7.40233e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=29480
2023-07-11 22:48:30 | INFO | train_inner | epoch 025:   1239 / 1474 loss=1.629, trans_loss=5.232, nll_loss=2.501, w2v_ctc_loss=0.501, task_loss=1.466, contrastive_loss=0.113, total=4079.17, n_correct=2681.57, ppl=5.66, accuracy=65.738, wps=6517.7, ups=1.6, wpb=4079.2, bsz=146.2, num_updates=36600, lr=7.39221e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=29543
2023-07-11 22:49:34 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.623, trans_loss=5.224, nll_loss=2.492, w2v_ctc_loss=0.494, task_loss=1.382, contrastive_loss=0.315, total=4173.55, n_correct=2757.19, ppl=5.62, accuracy=66.063, wps=6498.8, ups=1.56, wpb=4173.6, bsz=156.3, num_updates=36700, lr=7.38213e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=29607
2023-07-11 22:50:39 | INFO | train_inner | epoch 025:   1439 / 1474 loss=1.628, trans_loss=5.249, nll_loss=2.524, w2v_ctc_loss=0.504, task_loss=1.491, contrastive_loss=0.211, total=4102.27, n_correct=2687.71, ppl=5.75, accuracy=65.518, wps=6371.6, ups=1.55, wpb=4102.3, bsz=149.9, num_updates=36800, lr=7.3721e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=16.2, wall=29671
2023-07-11 22:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 22:51:27 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.68 | trans_loss 5.551 | nll_loss 2.823 | w2v_ctc_loss 1.159 | task_loss 4.354 | contrastive_loss 0.256 | total 4003.4 | n_correct 2490.7 | ppl 7.08 | accuracy 62.215 | uer 16.614 | wer 18.676 | raw_wer 18.676 | bleu 20.61 | wps 2173.2 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.61
2023-07-11 22:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-07-11 22:51:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 22:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-11 22:51:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 25 @ 36835 updates, score 20.61) (writing took 8.763471132027917 seconds)
2023-07-11 22:51:36 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-11 22:51:36 | INFO | train | epoch 025 | loss 1.623 | trans_loss 5.224 | nll_loss 2.49 | w2v_ctc_loss 0.499 | task_loss 1.43 | contrastive_loss 0.222 | total 4138.65 | n_correct 2730.71 | ppl 5.62 | accuracy 65.981 | wps 5974 | ups 1.44 | wpb 4138.6 | bsz 152.8 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.415 | clip 0 | loss_scale 64 | train_wall 937 | gb_free 14.6 | wall 29729
2023-07-11 22:51:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 22:51:37 | INFO | fairseq.trainer | begin training epoch 26
2023-07-11 22:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 22:52:25 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.605, trans_loss=5.197, nll_loss=2.456, w2v_ctc_loss=0.486, task_loss=1.352, contrastive_loss=0.179, total=4178.19, n_correct=2773.58, ppl=5.49, accuracy=66.382, wps=3915.1, ups=0.94, wpb=4178.2, bsz=158.7, num_updates=36900, lr=7.3621e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=14.5, wall=29778
2023-07-11 22:53:30 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.61, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.474, task_loss=1.247, contrastive_loss=0.543, total=4269.55, n_correct=2845.28, ppl=5.46, accuracy=66.641, wps=6627.6, ups=1.55, wpb=4269.6, bsz=170.7, num_updates=37000, lr=7.35215e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=64, gb_free=15.6, wall=29842
2023-07-11 22:54:33 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.617, trans_loss=5.207, nll_loss=2.468, w2v_ctc_loss=0.498, task_loss=1.414, contrastive_loss=0.3, total=4128.39, n_correct=2734.41, ppl=5.53, accuracy=66.234, wps=6472.4, ups=1.57, wpb=4128.4, bsz=153.4, num_updates=37100, lr=7.34223e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=10.6, wall=29906
2023-07-11 22:55:37 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.61, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.489, task_loss=1.371, contrastive_loss=0.215, total=4166.22, n_correct=2762.99, ppl=5.5, accuracy=66.319, wps=6516.9, ups=1.56, wpb=4166.2, bsz=157.5, num_updates=37200, lr=7.33236e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=29970
2023-07-11 22:56:41 | INFO | train_inner | epoch 026:    465 / 1474 loss=1.614, trans_loss=5.191, nll_loss=2.448, w2v_ctc_loss=0.49, task_loss=1.356, contrastive_loss=0.305, total=4171.18, n_correct=2779.57, ppl=5.46, accuracy=66.637, wps=6563.2, ups=1.57, wpb=4171.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=30034
2023-07-11 22:57:45 | INFO | train_inner | epoch 026:    565 / 1474 loss=1.614, trans_loss=5.208, nll_loss=2.468, w2v_ctc_loss=0.502, task_loss=1.464, contrastive_loss=0.142, total=4139.82, n_correct=2742.6, ppl=5.53, accuracy=66.249, wps=6430.5, ups=1.55, wpb=4139.8, bsz=150, num_updates=37400, lr=7.31272e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=64, gb_free=15.3, wall=30098
2023-07-11 22:58:49 | INFO | train_inner | epoch 026:    665 / 1474 loss=1.616, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.487, task_loss=1.44, contrastive_loss=0.12, total=4146.72, n_correct=2751.91, ppl=5.5, accuracy=66.364, wps=6477.5, ups=1.56, wpb=4146.7, bsz=151.4, num_updates=37500, lr=7.30297e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=17.1, wall=30162
2023-07-11 22:59:53 | INFO | train_inner | epoch 026:    765 / 1474 loss=1.628, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=0.495, task_loss=1.46, contrastive_loss=0.343, total=4084.89, n_correct=2694.97, ppl=5.6, accuracy=65.974, wps=6428.5, ups=1.57, wpb=4084.9, bsz=148.6, num_updates=37600, lr=7.29325e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=30226
2023-07-11 23:00:57 | INFO | train_inner | epoch 026:    865 / 1474 loss=1.613, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.493, task_loss=1.404, contrastive_loss=0.147, total=4180.78, n_correct=2765.75, ppl=5.55, accuracy=66.154, wps=6575.2, ups=1.57, wpb=4180.8, bsz=154.8, num_updates=37700, lr=7.28357e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=30289
2023-07-11 23:02:01 | INFO | train_inner | epoch 026:    965 / 1474 loss=1.621, trans_loss=5.223, nll_loss=2.489, w2v_ctc_loss=0.491, task_loss=1.48, contrastive_loss=0.254, total=4147.79, n_correct=2736.03, ppl=5.61, accuracy=65.964, wps=6478.9, ups=1.56, wpb=4147.8, bsz=149.8, num_updates=37800, lr=7.27393e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=64, gb_free=12.9, wall=30353
2023-07-11 23:03:04 | INFO | train_inner | epoch 026:   1065 / 1474 loss=1.623, trans_loss=5.218, nll_loss=2.483, w2v_ctc_loss=0.499, task_loss=1.509, contrastive_loss=0.12, total=4118.07, n_correct=2722.73, ppl=5.59, accuracy=66.117, wps=6470.2, ups=1.57, wpb=4118.1, bsz=146.8, num_updates=37900, lr=7.26433e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=30417
2023-07-11 23:04:08 | INFO | train_inner | epoch 026:   1165 / 1474 loss=1.62, trans_loss=5.229, nll_loss=2.497, w2v_ctc_loss=0.499, task_loss=1.502, contrastive_loss=0.197, total=4108.48, n_correct=2706.58, ppl=5.64, accuracy=65.878, wps=6399, ups=1.56, wpb=4108.5, bsz=149, num_updates=38000, lr=7.25476e-05, gnorm=0.417, clip=0, loss_scale=128, train_wall=64, gb_free=16.8, wall=30481
2023-07-11 23:04:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 23:04:34 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.698 | trans_loss 5.564 | nll_loss 2.838 | w2v_ctc_loss 1.201 | task_loss 4.37 | contrastive_loss 0.254 | total 4003.4 | n_correct 2487.4 | ppl 7.15 | accuracy 62.132 | uer 16.826 | wer 18.672 | raw_wer 18.672 | bleu 19.9 | wps 2080.7 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.61
2023-07-11 23:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-11 23:04:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_26_38000.pt
2023-07-11 23:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_26_38000.pt
2023-07-11 23:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.9) (writing took 5.153042069985531 seconds)
2023-07-11 23:05:44 | INFO | train_inner | epoch 026:   1265 / 1474 loss=1.633, trans_loss=5.243, nll_loss=2.515, w2v_ctc_loss=0.509, task_loss=1.593, contrastive_loss=0.121, total=4005.94, n_correct=2628, ppl=5.72, accuracy=65.603, wps=4188.7, ups=1.05, wpb=4005.9, bsz=140.3, num_updates=38100, lr=7.24524e-05, gnorm=0.428, clip=0, loss_scale=128, train_wall=64, gb_free=16.6, wall=30577
2023-07-11 23:06:49 | INFO | train_inner | epoch 026:   1365 / 1474 loss=1.622, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=0.495, task_loss=1.445, contrastive_loss=0.137, total=4146.34, n_correct=2737.12, ppl=5.63, accuracy=66.013, wps=6371.1, ups=1.54, wpb=4146.3, bsz=153.8, num_updates=38200, lr=7.23575e-05, gnorm=0.421, clip=0, loss_scale=128, train_wall=65, gb_free=15.8, wall=30642
2023-07-11 23:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-11 23:07:54 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.607, trans_loss=5.218, nll_loss=2.484, w2v_ctc_loss=0.486, task_loss=1.362, contrastive_loss=0.139, total=4165.66, n_correct=2754.11, ppl=5.59, accuracy=66.115, wps=6446.5, ups=1.55, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=30706
2023-07-11 23:07:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 23:08:24 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.697 | trans_loss 5.553 | nll_loss 2.824 | w2v_ctc_loss 1.196 | task_loss 4.316 | contrastive_loss 0.256 | total 4003.4 | n_correct 2495.1 | ppl 7.08 | accuracy 62.325 | uer 16.773 | wer 18.623 | raw_wer 18.623 | bleu 20.35 | wps 2131.2 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.61
2023-07-11 23:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-11 23:08:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3501.pt
2023-07-11 23:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3501.pt
2023-07-11 23:08:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3501.pt (epoch 26 @ 38308 updates, score 20.35) (writing took 5.484126067021862 seconds)
2023-07-11 23:08:30 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-11 23:08:30 | INFO | train | epoch 026 | loss 1.617 | trans_loss 5.211 | nll_loss 2.474 | w2v_ctc_loss 0.493 | task_loss 1.431 | contrastive_loss 0.22 | total 4138.31 | n_correct 2739.25 | ppl 5.56 | accuracy 66.192 | wps 6013.3 | ups 1.45 | wpb 4138.3 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.416 | clip 0 | loss_scale 64 | train_wall 936 | gb_free 16.2 | wall 30743
2023-07-11 23:08:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 23:08:30 | INFO | fairseq.trainer | begin training epoch 27
2023-07-11 23:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 23:09:36 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.613, trans_loss=5.172, nll_loss=2.422, w2v_ctc_loss=0.486, task_loss=1.54, contrastive_loss=0.099, total=4054.57, n_correct=2710.67, ppl=5.36, accuracy=66.855, wps=3964.2, ups=0.98, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=30809
2023-07-11 23:10:40 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.597, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=0.485, task_loss=1.35, contrastive_loss=0.155, total=4195.2, n_correct=2798.74, ppl=5.38, accuracy=66.713, wps=6522.4, ups=1.55, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=30873
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15273
2023-07-12 13:40:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-12 13:40:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-12 13:40:25 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-12 13:40:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_window', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15273', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_window', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nopad=True, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-12 13:40:27 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-12 13:40:27 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-12 13:40:27 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-12 13:40:27 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-12 13:40:27 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-12 13:40:32 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-12 13:40:32 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-12 13:40:32 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-12 13:40:34 | INFO | root | load pretrained hubert
2023-07-12 13:40:38 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-12 13:40:40 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-12 13:40:43 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-12 13:40:43 | INFO | root | share the sematic adapter and textual encoder
2023-07-12 13:40:43 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-12 13:40:43 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-12 13:40:43 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-12 13:40:43 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-12 13:40:43 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-12 13:40:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-12 13:40:43 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-12 13:40:43 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-12 13:40:43 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-12 13:40:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-12 13:40:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-12 13:40:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-12 13:40:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-12 13:40:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-12 13:40:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-12 13:40:51 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-12 13:40:51 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-12 13:40:51 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 13:40:53 | INFO | fairseq.trainer | load the task parameters
tensor(0.0022, device='cuda:0')
tensor(0.0184, device='cuda:0')
2023-07-12 13:40:53 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 27 @ 38308 updates)
2023-07-12 13:40:53 | INFO | fairseq.trainer | loading train data for epoch 27
2023-07-12 13:40:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-12 13:40:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-12 13:40:53 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-12 13:40:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-12 13:41:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-12 13:41:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:6')
2023-07-12 13:42:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 13:42:10 | INFO | fairseq.trainer | begin training epoch 27
2023-07-12 13:42:10 | INFO | fairseq_cli.train | Start iterating over samples
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:1')
2023-07-12 13:43:18 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.609, trans_loss=5.169, nll_loss=2.417, w2v_ctc_loss=0.484, task_loss=1.507, contrastive_loss=0.099, total=4095.52, n_correct=2738.64, ppl=5.34, accuracy=66.869, wps=6451.6, ups=1.57, wpb=4095.5, bsz=144.3, num_updates=38400, lr=7.21688e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=148
2023-07-12 13:44:23 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.597, trans_loss=5.178, nll_loss=2.431, w2v_ctc_loss=0.482, task_loss=1.35, contrastive_loss=0.154, total=4195.2, n_correct=2799.47, ppl=5.39, accuracy=66.73, wps=6522.1, ups=1.55, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.411, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=212
2023-07-12 13:45:27 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.61, trans_loss=5.194, nll_loss=2.451, w2v_ctc_loss=0.492, task_loss=1.436, contrastive_loss=0.123, total=4162.23, n_correct=2769.69, ppl=5.47, accuracy=66.543, wps=6468.8, ups=1.55, wpb=4162.2, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=276
2023-07-12 13:46:31 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.625, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=0.491, task_loss=1.494, contrastive_loss=0.487, total=4079.05, n_correct=2707.23, ppl=5.52, accuracy=66.369, wps=6348.8, ups=1.56, wpb=4079.1, bsz=148.6, num_updates=38700, lr=7.18885e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=17.1, wall=341
2023-07-12 13:47:35 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.616, trans_loss=5.207, nll_loss=2.47, w2v_ctc_loss=0.489, task_loss=1.307, contrastive_loss=0.361, total=4243.25, n_correct=2813, ppl=5.54, accuracy=66.294, wps=6664.2, ups=1.57, wpb=4243.2, bsz=165.5, num_updates=38800, lr=7.17958e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=63, gb_free=15.9, wall=404
2023-07-12 13:48:38 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.61, trans_loss=5.194, nll_loss=2.452, w2v_ctc_loss=0.488, task_loss=1.395, contrastive_loss=0.239, total=4137.92, n_correct=2751.2, ppl=5.47, accuracy=66.488, wps=6560.9, ups=1.59, wpb=4137.9, bsz=156.7, num_updates=38900, lr=7.17035e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=467
2023-07-12 13:49:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-12 13:49:43 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.617, trans_loss=5.201, nll_loss=2.46, w2v_ctc_loss=0.492, task_loss=1.452, contrastive_loss=0.119, total=4151.77, n_correct=2753.96, ppl=5.5, accuracy=66.332, wps=6453.6, ups=1.55, wpb=4151.8, bsz=150, num_updates=39000, lr=7.16115e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=64, gb_free=16.5, wall=532
2023-07-12 13:50:46 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.61, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.491, task_loss=1.5, contrastive_loss=0.124, total=4103.81, n_correct=2724.86, ppl=5.5, accuracy=66.398, wps=6473.3, ups=1.58, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=595
2023-07-12 13:51:49 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.621, trans_loss=5.201, nll_loss=2.46, w2v_ctc_loss=0.487, task_loss=1.485, contrastive_loss=0.106, total=4101.56, n_correct=2720.66, ppl=5.5, accuracy=66.332, wps=6489.5, ups=1.58, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=658
2023-07-12 13:52:53 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.614, trans_loss=5.206, nll_loss=2.468, w2v_ctc_loss=0.486, task_loss=1.378, contrastive_loss=0.48, total=4199.56, n_correct=2782.21, ppl=5.53, accuracy=66.25, wps=6541.4, ups=1.56, wpb=4199.6, bsz=158.4, num_updates=39300, lr=7.13376e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=64, gb_free=12.1, wall=723
2023-07-12 13:53:57 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.61, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.488, task_loss=1.437, contrastive_loss=0.144, total=4150.97, n_correct=2752.72, ppl=5.5, accuracy=66.315, wps=6562, ups=1.58, wpb=4151, bsz=152.5, num_updates=39400, lr=7.1247e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=12.4, wall=786
2023-07-12 13:55:00 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.618, trans_loss=5.214, nll_loss=2.479, w2v_ctc_loss=0.5, task_loss=1.49, contrastive_loss=0.153, total=4103.06, n_correct=2712.26, ppl=5.57, accuracy=66.103, wps=6497.6, ups=1.58, wpb=4103.1, bsz=148.8, num_updates=39500, lr=7.11568e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=849
2023-07-12 13:56:03 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.615, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=0.49, task_loss=1.531, contrastive_loss=0.254, total=4062.52, n_correct=2684.35, ppl=5.58, accuracy=66.076, wps=6466.9, ups=1.59, wpb=4062.5, bsz=146.1, num_updates=39600, lr=7.10669e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=912
2023-07-12 13:57:05 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.616, trans_loss=5.21, nll_loss=2.474, w2v_ctc_loss=0.49, task_loss=1.351, contrastive_loss=0.221, total=4152, n_correct=2747.36, ppl=5.56, accuracy=66.17, wps=6598.7, ups=1.59, wpb=4152, bsz=156.2, num_updates=39700, lr=7.09773e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=975
2023-07-12 13:57:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-12 13:58:21 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.667 | trans_loss 5.547 | nll_loss 2.816 | w2v_ctc_loss 1.148 | task_loss 4.348 | contrastive_loss 0.253 | total 4003.4 | n_correct 2497.9 | ppl 7.04 | accuracy 62.394 | uer 16.569 | wer 18.396 | raw_wer 18.396 | bleu 20.32 | wps 2157 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.61
2023-07-12 13:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-12 13:58:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3202.pt
2023-07-12 13:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3202.pt
2023-07-12 13:58:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.3202.pt (epoch 27 @ 39781 updates, score 20.32) (writing took 5.384448594995774 seconds)
2023-07-12 13:58:27 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-12 13:58:27 | INFO | train | epoch 027 | loss 1.613 | trans_loss 5.2 | nll_loss 2.459 | w2v_ctc_loss 0.489 | task_loss 1.429 | contrastive_loss 0.217 | total 4137.89 | n_correct 2746.52 | ppl 5.5 | accuracy 66.375 | wps 6306.6 | ups 1.52 | wpb 4137.9 | bsz 152.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.416 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 17.9 | wall 1056
2023-07-12 13:58:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 13:58:27 | INFO | fairseq.trainer | begin training epoch 28
2023-07-12 13:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 13:58:46 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.607, trans_loss=5.194, nll_loss=2.452, w2v_ctc_loss=0.483, task_loss=1.381, contrastive_loss=0.126, total=4108.43, n_correct=2732.68, ppl=5.47, accuracy=66.514, wps=4100.8, ups=1, wpb=4108.4, bsz=152.6, num_updates=39800, lr=7.08881e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=1075
2023-07-12 13:59:49 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.607, trans_loss=5.168, nll_loss=2.418, w2v_ctc_loss=0.485, task_loss=1.49, contrastive_loss=0.116, total=4113.41, n_correct=2755.12, ppl=5.34, accuracy=66.979, wps=6509.8, ups=1.58, wpb=4113.4, bsz=147, num_updates=39900, lr=7.07992e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=1138
2023-07-12 14:00:52 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.6, trans_loss=5.171, nll_loss=2.423, w2v_ctc_loss=0.48, task_loss=1.35, contrastive_loss=0.131, total=4191.56, n_correct=2805.81, ppl=5.36, accuracy=66.94, wps=6630.1, ups=1.58, wpb=4191.6, bsz=157.6, num_updates=40000, lr=7.07107e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=15.4, wall=1201
2023-07-12 14:00:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 14:01:19 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.688 | trans_loss 5.566 | nll_loss 2.842 | w2v_ctc_loss 1.168 | task_loss 4.307 | contrastive_loss 0.256 | total 4003.4 | n_correct 2484.5 | ppl 7.17 | accuracy 62.06 | uer 16.84 | wer 18.747 | raw_wer 18.747 | bleu 20.45 | wps 1890.3 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.61
2023-07-12 14:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-12 14:01:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_28_40000.pt
2023-07-12 14:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_28_40000.pt
2023-07-12 14:01:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.45) (writing took 6.11030161997769 seconds)
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-12 14:02:29 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.623, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=0.479, task_loss=1.416, contrastive_loss=0.789, total=4145.32, n_correct=2756.63, ppl=5.46, accuracy=66.5, wps=4271.1, ups=1.03, wpb=4145.3, bsz=158.1, num_updates=40100, lr=7.06225e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=1298
2023-07-12 14:03:32 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.606, trans_loss=5.186, nll_loss=2.441, w2v_ctc_loss=0.489, task_loss=1.475, contrastive_loss=0.106, total=4092.14, n_correct=2729.22, ppl=5.43, accuracy=66.694, wps=6464.3, ups=1.58, wpb=4092.1, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=1362
2023-07-12 14:04:36 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.61, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=0.488, task_loss=1.483, contrastive_loss=0.129, total=4096.35, n_correct=2730.16, ppl=5.42, accuracy=66.649, wps=6399.5, ups=1.56, wpb=4096.4, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=64, gb_free=16.2, wall=1426
2023-07-12 14:05:40 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.607, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=0.485, task_loss=1.433, contrastive_loss=0.131, total=4178.12, n_correct=2780.17, ppl=5.44, accuracy=66.541, wps=6618.1, ups=1.58, wpb=4178.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=1489
2023-07-12 14:06:43 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.612, trans_loss=5.197, nll_loss=2.457, w2v_ctc_loss=0.484, task_loss=1.302, contrastive_loss=0.352, total=4185.82, n_correct=2779.91, ppl=5.49, accuracy=66.413, wps=6629.6, ups=1.58, wpb=4185.8, bsz=163.2, num_updates=40500, lr=7.02728e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=1552
2023-07-12 14:07:46 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.608, trans_loss=5.182, nll_loss=2.437, w2v_ctc_loss=0.484, task_loss=1.395, contrastive_loss=0.118, total=4096.2, n_correct=2733.15, ppl=5.42, accuracy=66.724, wps=6522.4, ups=1.59, wpb=4096.2, bsz=153.5, num_updates=40600, lr=7.01862e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=15.9, wall=1615
2023-07-12 14:08:49 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.605, trans_loss=5.197, nll_loss=2.456, w2v_ctc_loss=0.482, task_loss=1.476, contrastive_loss=0.238, total=4120.27, n_correct=2737.8, ppl=5.49, accuracy=66.447, wps=6453.1, ups=1.57, wpb=4120.3, bsz=150.4, num_updates=40700, lr=7.01e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=1679
2023-07-12 14:09:53 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.616, trans_loss=5.205, nll_loss=2.467, w2v_ctc_loss=0.49, task_loss=1.398, contrastive_loss=0.343, total=4177.86, n_correct=2769.22, ppl=5.53, accuracy=66.283, wps=6568.6, ups=1.57, wpb=4177.9, bsz=155.5, num_updates=40800, lr=7.0014e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=1742
2023-07-12 14:10:57 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.601, trans_loss=5.184, nll_loss=2.44, w2v_ctc_loss=0.484, task_loss=1.385, contrastive_loss=0.155, total=4210.86, n_correct=2803.71, ppl=5.43, accuracy=66.583, wps=6565, ups=1.56, wpb=4210.9, bsz=159.4, num_updates=40900, lr=6.99284e-05, gnorm=0.409, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=1806
2023-07-12 14:12:00 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.596, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.477, task_loss=1.409, contrastive_loss=0.128, total=4104.61, n_correct=2728.68, ppl=5.46, accuracy=66.478, wps=6525.8, ups=1.59, wpb=4104.6, bsz=152.8, num_updates=41000, lr=6.9843e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=1869
2023-07-12 14:13:04 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.622, trans_loss=5.205, nll_loss=2.467, w2v_ctc_loss=0.493, task_loss=1.56, contrastive_loss=0.159, total=4087.78, n_correct=2707.96, ppl=5.53, accuracy=66.245, wps=6436.6, ups=1.57, wpb=4087.8, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=1933
2023-07-12 14:14:07 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.617, trans_loss=5.206, nll_loss=2.468, w2v_ctc_loss=0.49, task_loss=1.5, contrastive_loss=0.202, total=4145.03, n_correct=2744.34, ppl=5.53, accuracy=66.208, wps=6558.6, ups=1.58, wpb=4145, bsz=148.8, num_updates=41200, lr=6.96733e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=1996
2023-07-12 14:14:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
2023-07-12 14:15:06 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.679 | trans_loss 5.551 | nll_loss 2.818 | w2v_ctc_loss 1.171 | task_loss 4.323 | contrastive_loss 0.248 | total 4003.4 | n_correct 2497.4 | ppl 7.05 | accuracy 62.382 | uer 16.441 | wer 18.251 | raw_wer 18.251 | bleu 20.57 | wps 2103.3 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.61
2023-07-12 14:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-07-12 14:15:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5702.pt
2023-07-12 14:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5702.pt
2023-07-12 14:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5702.pt (epoch 28 @ 41255 updates, score 20.57) (writing took 5.443433448963333 seconds)
2023-07-12 14:15:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-12 14:15:12 | INFO | train | epoch 028 | loss 1.609 | trans_loss 5.189 | nll_loss 2.446 | w2v_ctc_loss 0.485 | task_loss 1.427 | contrastive_loss 0.219 | total 4138.65 | n_correct 2754.9 | ppl 5.45 | accuracy 66.565 | wps 6069.7 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.417 | clip 0 | loss_scale 64 | train_wall 927 | gb_free 16.7 | wall 2061
2023-07-12 14:15:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 14:15:12 | INFO | fairseq.trainer | begin training epoch 29
2023-07-12 14:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 14:15:48 | INFO | train_inner | epoch 029:     45 / 1474 loss=1.595, trans_loss=5.165, nll_loss=2.416, w2v_ctc_loss=0.48, task_loss=1.375, contrastive_loss=0.138, total=4163.06, n_correct=2790.34, ppl=5.34, accuracy=67.026, wps=4116.2, ups=0.99, wpb=4163.1, bsz=157, num_updates=41300, lr=6.95889e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=62, gb_free=16.5, wall=2097
2023-07-12 14:16:51 | INFO | train_inner | epoch 029:    145 / 1474 loss=1.6, trans_loss=5.164, nll_loss=2.412, w2v_ctc_loss=0.476, task_loss=1.4, contrastive_loss=0.202, total=4116.29, n_correct=2758.57, ppl=5.32, accuracy=67.016, wps=6474.8, ups=1.57, wpb=4116.3, bsz=154.3, num_updates=41400, lr=6.95048e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=14.4, wall=2161
2023-07-12 14:17:56 | INFO | train_inner | epoch 029:    245 / 1474 loss=1.589, trans_loss=5.162, nll_loss=2.411, w2v_ctc_loss=0.469, task_loss=1.315, contrastive_loss=0.357, total=4197.24, n_correct=2813.84, ppl=5.32, accuracy=67.04, wps=6509, ups=1.55, wpb=4197.2, bsz=165, num_updates=41500, lr=6.9421e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=2225
2023-07-12 14:18:59 | INFO | train_inner | epoch 029:    345 / 1474 loss=1.614, trans_loss=5.183, nll_loss=2.437, w2v_ctc_loss=0.49, task_loss=1.529, contrastive_loss=0.12, total=4092.21, n_correct=2731.53, ppl=5.42, accuracy=66.75, wps=6500, ups=1.59, wpb=4092.2, bsz=145.3, num_updates=41600, lr=6.93375e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=15.9, wall=2288
2023-07-12 14:20:02 | INFO | train_inner | epoch 029:    445 / 1474 loss=1.592, trans_loss=5.156, nll_loss=2.401, w2v_ctc_loss=0.478, task_loss=1.384, contrastive_loss=0.109, total=4161.27, n_correct=2796.28, ppl=5.28, accuracy=67.198, wps=6607.5, ups=1.59, wpb=4161.3, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=2351
2023-07-12 14:21:06 | INFO | train_inner | epoch 029:    545 / 1474 loss=1.622, trans_loss=5.189, nll_loss=2.445, w2v_ctc_loss=0.489, task_loss=1.5, contrastive_loss=0.305, total=4159.68, n_correct=2768.22, ppl=5.44, accuracy=66.549, wps=6528.3, ups=1.57, wpb=4159.7, bsz=148.2, num_updates=41800, lr=6.91714e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=2415
2023-07-12 14:22:09 | INFO | train_inner | epoch 029:    645 / 1474 loss=1.602, trans_loss=5.175, nll_loss=2.429, w2v_ctc_loss=0.478, task_loss=1.344, contrastive_loss=0.437, total=4143.76, n_correct=2765.9, ppl=5.39, accuracy=66.749, wps=6590.1, ups=1.59, wpb=4143.8, bsz=159.4, num_updates=41900, lr=6.90889e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.5, wall=2478
2023-07-12 14:23:12 | INFO | train_inner | epoch 029:    745 / 1474 loss=1.598, trans_loss=5.173, nll_loss=2.426, w2v_ctc_loss=0.479, task_loss=1.324, contrastive_loss=0.275, total=4234.8, n_correct=2831.43, ppl=5.37, accuracy=66.861, wps=6635.3, ups=1.57, wpb=4234.8, bsz=164.1, num_updates=42000, lr=6.90066e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=2542
2023-07-12 14:23:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 14:23:38 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.558 | nll_loss 2.832 | w2v_ctc_loss 1.201 | task_loss 4.298 | contrastive_loss 0.252 | total 4003.4 | n_correct 2490.9 | ppl 7.12 | accuracy 62.22 | uer 16.84 | wer 18.791 | raw_wer 18.791 | bleu 19.99 | wps 2035.9 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.61
2023-07-12 14:23:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-12 14:23:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_29_42000.pt
2023-07-12 14:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_29_42000.pt
2023-07-12 14:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.99) (writing took 5.058665140008088 seconds)
2023-07-12 14:24:46 | INFO | train_inner | epoch 029:    845 / 1474 loss=1.612, trans_loss=5.185, nll_loss=2.44, w2v_ctc_loss=0.48, task_loss=1.575, contrastive_loss=0.107, total=4033.21, n_correct=2684.5, ppl=5.43, accuracy=66.56, wps=4302.1, ups=1.07, wpb=4033.2, bsz=140.8, num_updates=42100, lr=6.89246e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=2635
2023-07-12 14:25:48 | INFO | train_inner | epoch 029:    945 / 1474 loss=1.607, trans_loss=5.187, nll_loss=2.442, w2v_ctc_loss=0.483, task_loss=1.454, contrastive_loss=0.127, total=4085.97, n_correct=2721.99, ppl=5.44, accuracy=66.618, wps=6557.8, ups=1.6, wpb=4086, bsz=148.4, num_updates=42200, lr=6.88428e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.3, wall=2698
2023-07-12 14:26:51 | INFO | train_inner | epoch 029:   1045 / 1474 loss=1.605, trans_loss=5.182, nll_loss=2.436, w2v_ctc_loss=0.479, task_loss=1.431, contrastive_loss=0.275, total=4140.84, n_correct=2760.1, ppl=5.41, accuracy=66.656, wps=6626, ups=1.6, wpb=4140.8, bsz=153.4, num_updates=42300, lr=6.87614e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=2760
2023-07-12 14:27:53 | INFO | train_inner | epoch 029:   1145 / 1474 loss=1.607, trans_loss=5.19, nll_loss=2.447, w2v_ctc_loss=0.491, task_loss=1.557, contrastive_loss=0.1, total=4068.4, n_correct=2703.58, ppl=5.45, accuracy=66.453, wps=6530.3, ups=1.61, wpb=4068.4, bsz=142.1, num_updates=42400, lr=6.86803e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=62, gb_free=17.6, wall=2822
2023-07-12 14:28:56 | INFO | train_inner | epoch 029:   1245 / 1474 loss=1.608, trans_loss=5.192, nll_loss=2.451, w2v_ctc_loss=0.486, task_loss=1.465, contrastive_loss=0.113, total=4154.79, n_correct=2762.45, ppl=5.47, accuracy=66.488, wps=6575, ups=1.58, wpb=4154.8, bsz=149.8, num_updates=42500, lr=6.85994e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=2886
2023-07-12 14:30:00 | INFO | train_inner | epoch 029:   1345 / 1474 loss=1.603, trans_loss=5.179, nll_loss=2.433, w2v_ctc_loss=0.477, task_loss=1.399, contrastive_loss=0.243, total=4166.4, n_correct=2782.75, ppl=5.4, accuracy=66.79, wps=6555.2, ups=1.57, wpb=4166.4, bsz=155.8, num_updates=42600, lr=6.85189e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=2949
2023-07-12 14:31:04 | INFO | train_inner | epoch 029:   1445 / 1474 loss=1.615, trans_loss=5.187, nll_loss=2.445, w2v_ctc_loss=0.483, task_loss=1.396, contrastive_loss=0.299, total=4169.4, n_correct=2773.75, ppl=5.44, accuracy=66.526, wps=6542.2, ups=1.57, wpb=4169.4, bsz=156, num_updates=42700, lr=6.84386e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=3013
2023-07-12 14:31:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 14:31:48 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.68 | trans_loss 5.554 | nll_loss 2.824 | w2v_ctc_loss 1.163 | task_loss 4.341 | contrastive_loss 0.259 | total 4003.4 | n_correct 2492 | ppl 7.08 | accuracy 62.247 | uer 16.505 | wer 18.381 | raw_wer 18.381 | bleu 20.2 | wps 2127.3 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 20.61
2023-07-12 14:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-07-12 14:31:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 14:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 14:31:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 29 @ 42729 updates, score 20.2) (writing took 4.023062635969836 seconds)
2023-07-12 14:31:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-12 14:31:52 | INFO | train | epoch 029 | loss 1.604 | trans_loss 5.178 | nll_loss 2.431 | w2v_ctc_loss 0.481 | task_loss 1.427 | contrastive_loss 0.218 | total 4138.65 | n_correct 2762.74 | ppl 5.39 | accuracy 66.755 | wps 6098.2 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.417 | clip 0 | loss_scale 64 | train_wall 925 | gb_free 16.4 | wall 3061
2023-07-12 14:31:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 14:31:52 | INFO | fairseq.trainer | begin training epoch 30
2023-07-12 14:31:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 14:32:45 | INFO | train_inner | epoch 030:     71 / 1474 loss=1.592, trans_loss=5.158, nll_loss=2.405, w2v_ctc_loss=0.467, task_loss=1.357, contrastive_loss=0.33, total=4176.73, n_correct=2801.2, ppl=5.3, accuracy=67.067, wps=4113, ups=0.98, wpb=4176.7, bsz=159.5, num_updates=42800, lr=6.83586e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=3114
2023-07-12 14:33:48 | INFO | train_inner | epoch 030:    171 / 1474 loss=1.585, trans_loss=5.138, nll_loss=2.38, w2v_ctc_loss=0.471, task_loss=1.337, contrastive_loss=0.195, total=4202.84, n_correct=2837.38, ppl=5.2, accuracy=67.511, wps=6662.1, ups=1.59, wpb=4202.8, bsz=159.3, num_updates=42900, lr=6.82789e-05, gnorm=0.408, clip=0, loss_scale=64, train_wall=63, gb_free=13.1, wall=3178
2023-07-12 14:34:51 | INFO | train_inner | epoch 030:    271 / 1474 loss=1.601, trans_loss=5.159, nll_loss=2.406, w2v_ctc_loss=0.484, task_loss=1.465, contrastive_loss=0.107, total=4120.08, n_correct=2762.54, ppl=5.3, accuracy=67.051, wps=6585, ups=1.6, wpb=4120.1, bsz=148.2, num_updates=43000, lr=6.81994e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=3240
2023-07-12 14:35:54 | INFO | train_inner | epoch 030:    371 / 1474 loss=1.595, trans_loss=5.149, nll_loss=2.393, w2v_ctc_loss=0.472, task_loss=1.432, contrastive_loss=0.114, total=4175.82, n_correct=2811.4, ppl=5.25, accuracy=67.326, wps=6608.5, ups=1.58, wpb=4175.8, bsz=153.1, num_updates=43100, lr=6.81203e-05, gnorm=0.412, clip=0, loss_scale=128, train_wall=63, gb_free=15.8, wall=3303
2023-07-12 14:36:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-12 14:36:57 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.595, trans_loss=5.159, nll_loss=2.407, w2v_ctc_loss=0.479, task_loss=1.408, contrastive_loss=0.127, total=4109.37, n_correct=2754.1, ppl=5.3, accuracy=67.02, wps=6485.2, ups=1.58, wpb=4109.4, bsz=152.8, num_updates=43200, lr=6.80414e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=3367
2023-07-12 14:38:01 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.597, trans_loss=5.166, nll_loss=2.416, w2v_ctc_loss=0.475, task_loss=1.392, contrastive_loss=0.161, total=4168.65, n_correct=2791.56, ppl=5.34, accuracy=66.966, wps=6548.5, ups=1.57, wpb=4168.6, bsz=156.1, num_updates=43300, lr=6.79628e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=3430
2023-07-12 14:39:04 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.596, trans_loss=5.167, nll_loss=2.417, w2v_ctc_loss=0.479, task_loss=1.411, contrastive_loss=0.189, total=4183.65, n_correct=2796.15, ppl=5.34, accuracy=66.835, wps=6608.5, ups=1.58, wpb=4183.6, bsz=157.3, num_updates=43400, lr=6.78844e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=3494
2023-07-12 14:40:07 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.615, trans_loss=5.185, nll_loss=2.441, w2v_ctc_loss=0.487, task_loss=1.452, contrastive_loss=0.347, total=4106.9, n_correct=2735.07, ppl=5.43, accuracy=66.597, wps=6513.8, ups=1.59, wpb=4106.9, bsz=151.5, num_updates=43500, lr=6.78064e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=12.3, wall=3557
2023-07-12 14:41:10 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.605, trans_loss=5.173, nll_loss=2.424, w2v_ctc_loss=0.478, task_loss=1.491, contrastive_loss=0.115, total=4089.18, n_correct=2733.46, ppl=5.37, accuracy=66.846, wps=6543.9, ups=1.6, wpb=4089.2, bsz=145.7, num_updates=43600, lr=6.77285e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=3619
2023-07-12 14:42:13 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.603, trans_loss=5.179, nll_loss=2.432, w2v_ctc_loss=0.482, task_loss=1.446, contrastive_loss=0.154, total=4140.03, n_correct=2760.44, ppl=5.4, accuracy=66.677, wps=6565.6, ups=1.59, wpb=4140, bsz=152, num_updates=43700, lr=6.7651e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=14.1, wall=3682
2023-07-12 14:43:17 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.621, trans_loss=5.189, nll_loss=2.444, w2v_ctc_loss=0.482, task_loss=1.59, contrastive_loss=0.291, total=4101.12, n_correct=2725.59, ppl=5.44, accuracy=66.46, wps=6391.7, ups=1.56, wpb=4101.1, bsz=141.4, num_updates=43800, lr=6.75737e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=3746
2023-07-12 14:44:21 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.601, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=0.475, task_loss=1.371, contrastive_loss=0.255, total=4168.22, n_correct=2786.08, ppl=5.38, accuracy=66.841, wps=6530.6, ups=1.57, wpb=4168.2, bsz=157.3, num_updates=43900, lr=6.74967e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=3810
2023-07-12 14:45:24 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.617, trans_loss=5.187, nll_loss=2.443, w2v_ctc_loss=0.492, task_loss=1.599, contrastive_loss=0.12, total=4032.74, n_correct=2683.55, ppl=5.44, accuracy=66.544, wps=6413.1, ups=1.59, wpb=4032.7, bsz=140.9, num_updates=44000, lr=6.742e-05, gnorm=0.43, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=3873
2023-07-12 14:45:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 14:45:49 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.693 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 1.205 | task_loss 4.376 | contrastive_loss 0.255 | total 4003.4 | n_correct 2492.4 | ppl 7.11 | accuracy 62.257 | uer 16.879 | wer 18.72 | raw_wer 18.72 | bleu 20.42 | wps 2105.5 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.61
2023-07-12 14:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-12 14:45:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_30_44000.pt
2023-07-12 14:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_30_44000.pt
2023-07-12 14:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.42) (writing took 6.420050396991428 seconds)
2023-07-12 14:46:58 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.58, trans_loss=5.166, nll_loss=2.418, w2v_ctc_loss=0.468, task_loss=1.343, contrastive_loss=0.142, total=4166.96, n_correct=2790.82, ppl=5.35, accuracy=66.975, wps=4431.7, ups=1.06, wpb=4167, bsz=161.1, num_updates=44100, lr=6.73435e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=62, gb_free=16.4, wall=3967
2023-07-12 14:48:00 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.607, trans_loss=5.182, nll_loss=2.438, w2v_ctc_loss=0.474, task_loss=1.368, contrastive_loss=0.431, total=4125.17, n_correct=2749.45, ppl=5.42, accuracy=66.651, wps=6611.1, ups=1.6, wpb=4125.2, bsz=155, num_updates=44200, lr=6.72673e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=4030
2023-07-12 14:48:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 14:48:28 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.69 | trans_loss 5.562 | nll_loss 2.839 | w2v_ctc_loss 1.19 | task_loss 4.355 | contrastive_loss 0.259 | total 4003.4 | n_correct 2489 | ppl 7.16 | accuracy 62.172 | uer 16.986 | wer 18.814 | raw_wer 18.814 | bleu 20.01 | wps 1949.2 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.61
2023-07-12 14:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-12 14:48:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 14:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 14:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 30 @ 44202 updates, score 20.01) (writing took 4.035026222001761 seconds)
2023-07-12 14:48:32 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-12 14:48:32 | INFO | train | epoch 030 | loss 1.601 | trans_loss 5.169 | nll_loss 2.42 | w2v_ctc_loss 0.478 | task_loss 1.43 | contrastive_loss 0.208 | total 4137.17 | n_correct 2767.49 | ppl 5.35 | accuracy 66.893 | wps 6093 | ups 1.47 | wpb 4137.2 | bsz 152.6 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.417 | clip 0 | loss_scale 64 | train_wall 923 | gb_free 17.2 | wall 4061
2023-07-12 14:48:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 14:48:32 | INFO | fairseq.trainer | begin training epoch 31
2023-07-12 14:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 14:49:42 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.597, trans_loss=5.149, nll_loss=2.393, w2v_ctc_loss=0.476, task_loss=1.472, contrastive_loss=0.116, total=4081.34, n_correct=2744.03, ppl=5.25, accuracy=67.234, wps=4007.1, ups=0.98, wpb=4081.3, bsz=147.3, num_updates=44300, lr=6.71913e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=4131
2023-07-12 14:49:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-12 14:50:47 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.6, trans_loss=5.153, nll_loss=2.398, w2v_ctc_loss=0.479, task_loss=1.475, contrastive_loss=0.125, total=4129.26, n_correct=2771.45, ppl=5.27, accuracy=67.117, wps=6412.6, ups=1.55, wpb=4129.3, bsz=148.7, num_updates=44400, lr=6.71156e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=64, gb_free=16.9, wall=4196
2023-07-12 14:51:50 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.595, trans_loss=5.152, nll_loss=2.397, w2v_ctc_loss=0.473, task_loss=1.465, contrastive_loss=0.244, total=4149.21, n_correct=2788.75, ppl=5.27, accuracy=67.212, wps=6511.3, ups=1.57, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=4260
2023-07-12 14:52:53 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.601, trans_loss=5.157, nll_loss=2.403, w2v_ctc_loss=0.474, task_loss=1.558, contrastive_loss=0.119, total=4092.62, n_correct=2745.98, ppl=5.29, accuracy=67.096, wps=6534.3, ups=1.6, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=62, gb_free=17.3, wall=4322
2023-07-12 14:53:56 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.6, trans_loss=5.151, nll_loss=2.397, w2v_ctc_loss=0.482, task_loss=1.486, contrastive_loss=0.134, total=4111.85, n_correct=2761.9, ppl=5.27, accuracy=67.169, wps=6499, ups=1.58, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=11.5, wall=4385
2023-07-12 14:54:59 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.596, trans_loss=5.159, nll_loss=2.406, w2v_ctc_loss=0.475, task_loss=1.493, contrastive_loss=0.116, total=4083.44, n_correct=2738.44, ppl=5.3, accuracy=67.062, wps=6509.1, ups=1.59, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=4448
2023-07-12 14:56:02 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.585, trans_loss=5.146, nll_loss=2.39, w2v_ctc_loss=0.465, task_loss=1.363, contrastive_loss=0.117, total=4213.98, n_correct=2834.52, ppl=5.24, accuracy=67.265, wps=6683.8, ups=1.59, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=4511
2023-07-12 14:57:05 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.591, trans_loss=5.165, nll_loss=2.414, w2v_ctc_loss=0.469, task_loss=1.498, contrastive_loss=0.257, total=4097.37, n_correct=2741.31, ppl=5.33, accuracy=66.904, wps=6461, ups=1.58, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=63, gb_free=13.3, wall=4575
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-12 14:58:09 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.598, trans_loss=5.156, nll_loss=2.403, w2v_ctc_loss=0.476, task_loss=1.49, contrastive_loss=0.147, total=4096.72, n_correct=2747.17, ppl=5.29, accuracy=67.058, wps=6486, ups=1.58, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=4638
2023-07-12 14:59:11 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.603, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.476, task_loss=1.351, contrastive_loss=0.313, total=4187.84, n_correct=2805.16, ppl=5.35, accuracy=66.983, wps=6705.8, ups=1.6, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=62, gb_free=17.4, wall=4700
2023-07-12 15:00:14 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.593, trans_loss=5.161, nll_loss=2.411, w2v_ctc_loss=0.471, task_loss=1.402, contrastive_loss=0.21, total=4149.44, n_correct=2778.89, ppl=5.32, accuracy=66.97, wps=6605, ups=1.59, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=4763
2023-07-12 15:01:16 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.604, trans_loss=5.163, nll_loss=2.414, w2v_ctc_loss=0.472, task_loss=1.328, contrastive_loss=0.439, total=4189.76, n_correct=2808.61, ppl=5.33, accuracy=67.035, wps=6741.8, ups=1.61, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=62, gb_free=13.5, wall=4825
2023-07-12 15:02:19 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.588, trans_loss=5.159, nll_loss=2.409, w2v_ctc_loss=0.471, task_loss=1.28, contrastive_loss=0.128, total=4227.44, n_correct=2834.91, ppl=5.31, accuracy=67.06, wps=6723.8, ups=1.59, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=0.409, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=4888
2023-07-12 15:03:23 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.599, trans_loss=5.175, nll_loss=2.43, w2v_ctc_loss=0.472, task_loss=1.313, contrastive_loss=0.534, total=4186.05, n_correct=2796.11, ppl=5.39, accuracy=66.796, wps=6571.3, ups=1.57, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=4952
2023-07-12 15:04:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
2023-07-12 15:04:34 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.691 | trans_loss 5.557 | nll_loss 2.832 | w2v_ctc_loss 1.18 | task_loss 4.328 | contrastive_loss 0.258 | total 4003.4 | n_correct 2499.6 | ppl 7.12 | accuracy 62.437 | uer 16.518 | wer 18.601 | raw_wer 18.601 | bleu 20.54 | wps 2206.8 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.61
2023-07-12 15:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-12 15:04:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5401.pt
2023-07-12 15:04:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5401.pt
2023-07-12 15:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5401.pt (epoch 31 @ 45675 updates, score 20.54) (writing took 5.420030148990918 seconds)
2023-07-12 15:04:40 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-12 15:04:40 | INFO | train | epoch 031 | loss 1.597 | trans_loss 5.158 | nll_loss 2.406 | w2v_ctc_loss 0.474 | task_loss 1.428 | contrastive_loss 0.212 | total 4137.95 | n_correct 2775 | ppl 5.3 | accuracy 67.062 | wps 6298.7 | ups 1.52 | wpb 4137.9 | bsz 152.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.417 | clip 0 | loss_scale 32 | train_wall 923 | gb_free 12.5 | wall 5029
2023-07-12 15:04:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 15:04:40 | INFO | fairseq.trainer | begin training epoch 32
2023-07-12 15:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 15:05:04 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.598, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=0.476, task_loss=1.505, contrastive_loss=0.109, total=4042.6, n_correct=2714.07, ppl=5.29, accuracy=67.137, wps=4002.3, ups=0.99, wpb=4042.6, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=5053
2023-07-12 15:06:07 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.572, trans_loss=5.115, nll_loss=2.35, w2v_ctc_loss=0.456, task_loss=1.328, contrastive_loss=0.128, total=4227.68, n_correct=2865.76, ppl=5.1, accuracy=67.786, wps=6714.8, ups=1.59, wpb=4227.7, bsz=161.6, num_updates=45800, lr=6.60819e-05, gnorm=0.404, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=5116
2023-07-12 15:07:10 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.579, trans_loss=5.14, nll_loss=2.382, w2v_ctc_loss=0.467, task_loss=1.361, contrastive_loss=0.147, total=4157.32, n_correct=2801.96, ppl=5.21, accuracy=67.398, wps=6542.2, ups=1.57, wpb=4157.3, bsz=160.3, num_updates=45900, lr=6.60098e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=5179
2023-07-12 15:08:13 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.575, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=0.459, task_loss=1.35, contrastive_loss=0.138, total=4183.45, n_correct=2832, ppl=5.13, accuracy=67.695, wps=6705.3, ups=1.6, wpb=4183.4, bsz=157.2, num_updates=46000, lr=6.5938e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=5242
2023-07-12 15:08:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 15:08:38 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.701 | trans_loss 5.559 | nll_loss 2.833 | w2v_ctc_loss 1.215 | task_loss 4.314 | contrastive_loss 0.264 | total 4003.4 | n_correct 2494.4 | ppl 7.13 | accuracy 62.307 | uer 16.532 | wer 18.545 | raw_wer 18.545 | bleu 20.48 | wps 2062.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.61
2023-07-12 15:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-12 15:08:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_32_46000.pt
2023-07-12 15:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_32_46000.pt
2023-07-12 15:08:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.48) (writing took 6.265605203981977 seconds)
2023-07-12 15:09:48 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.587, trans_loss=5.136, nll_loss=2.376, w2v_ctc_loss=0.467, task_loss=1.416, contrastive_loss=0.131, total=4157.28, n_correct=2805.09, ppl=5.19, accuracy=67.474, wps=4364.6, ups=1.05, wpb=4157.3, bsz=152.9, num_updates=46100, lr=6.58665e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=15.1, wall=5337
2023-07-12 15:10:52 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.597, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=0.476, task_loss=1.382, contrastive_loss=0.297, total=4198.93, n_correct=2824.35, ppl=5.27, accuracy=67.264, wps=6554.4, ups=1.56, wpb=4198.9, bsz=158.8, num_updates=46200, lr=6.57952e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=5401
2023-07-12 15:11:55 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.598, trans_loss=5.159, nll_loss=2.407, w2v_ctc_loss=0.477, task_loss=1.472, contrastive_loss=0.146, total=4142.69, n_correct=2778.38, ppl=5.31, accuracy=67.067, wps=6538.7, ups=1.58, wpb=4142.7, bsz=150.8, num_updates=46300, lr=6.57241e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=5464
2023-07-12 15:12:59 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.598, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=0.48, task_loss=1.454, contrastive_loss=0.115, total=4154.59, n_correct=2789.65, ppl=5.28, accuracy=67.146, wps=6552.9, ups=1.58, wpb=4154.6, bsz=150.9, num_updates=46400, lr=6.56532e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=5528
2023-07-12 15:14:01 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.591, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=0.469, task_loss=1.475, contrastive_loss=0.108, total=4114.54, n_correct=2765.1, ppl=5.25, accuracy=67.203, wps=6628, ups=1.61, wpb=4114.5, bsz=147.4, num_updates=46500, lr=6.55826e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=17.3, wall=5590
2023-07-12 15:15:04 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.597, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=0.473, task_loss=1.478, contrastive_loss=0.107, total=4139.67, n_correct=2778.46, ppl=5.29, accuracy=67.118, wps=6569.1, ups=1.59, wpb=4139.7, bsz=149.2, num_updates=46600, lr=6.55122e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=5653
2023-07-12 15:16:06 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.596, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=0.468, task_loss=1.417, contrastive_loss=0.294, total=4119.15, n_correct=2763.01, ppl=5.29, accuracy=67.077, wps=6588.9, ups=1.6, wpb=4119.1, bsz=152.2, num_updates=46700, lr=6.5442e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=16.7, wall=5715
2023-07-12 15:17:10 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.615, trans_loss=5.173, nll_loss=2.423, w2v_ctc_loss=0.483, task_loss=1.682, contrastive_loss=0.183, total=4019.61, n_correct=2684.02, ppl=5.36, accuracy=66.773, wps=6322.9, ups=1.57, wpb=4019.6, bsz=135.7, num_updates=46800, lr=6.5372e-05, gnorm=0.432, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=5779
2023-07-12 15:18:13 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.61, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=0.475, task_loss=1.406, contrastive_loss=0.396, total=4149.28, n_correct=2769.1, ppl=5.38, accuracy=66.737, wps=6568, ups=1.58, wpb=4149.3, bsz=155.2, num_updates=46900, lr=6.53023e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=5842
2023-07-12 15:19:15 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.594, trans_loss=5.151, nll_loss=2.397, w2v_ctc_loss=0.47, task_loss=1.463, contrastive_loss=0.106, total=4079.22, n_correct=2739.99, ppl=5.27, accuracy=67.169, wps=6540.8, ups=1.6, wpb=4079.2, bsz=148.1, num_updates=47000, lr=6.52328e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=15.4, wall=5905
2023-07-12 15:20:18 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.608, trans_loss=5.169, nll_loss=2.421, w2v_ctc_loss=0.476, task_loss=1.431, contrastive_loss=0.571, total=4111.41, n_correct=2749.95, ppl=5.36, accuracy=66.886, wps=6595.8, ups=1.6, wpb=4111.4, bsz=153.1, num_updates=47100, lr=6.51635e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=62, gb_free=16.2, wall=5967
2023-07-12 15:20:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 15:21:14 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.696 | trans_loss 5.554 | nll_loss 2.828 | w2v_ctc_loss 1.211 | task_loss 4.332 | contrastive_loss 0.261 | total 4003.4 | n_correct 2498.1 | ppl 7.1 | accuracy 62.399 | uer 16.856 | wer 18.791 | raw_wer 18.791 | bleu 20.59 | wps 2116.6 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 20.61
2023-07-12 15:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-07-12 15:21:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5908.pt
2023-07-12 15:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5908.pt
2023-07-12 15:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5908.pt (epoch 32 @ 47149 updates, score 20.59) (writing took 5.493651554977987 seconds)
2023-07-12 15:21:20 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-12 15:21:20 | INFO | train | epoch 032 | loss 1.594 | trans_loss 5.15 | nll_loss 2.396 | w2v_ctc_loss 0.471 | task_loss 1.427 | contrastive_loss 0.215 | total 4138.65 | n_correct 2781.51 | ppl 5.26 | accuracy 67.208 | wps 6098.4 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.418 | clip 0 | loss_scale 64 | train_wall 921 | gb_free 16.8 | wall 6029
2023-07-12 15:21:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 15:21:20 | INFO | fairseq.trainer | begin training epoch 33
2023-07-12 15:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 15:22:01 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.582, trans_loss=5.147, nll_loss=2.393, w2v_ctc_loss=0.461, task_loss=1.334, contrastive_loss=0.314, total=4156.71, n_correct=2800.01, ppl=5.25, accuracy=67.361, wps=4035, ups=0.97, wpb=4156.7, bsz=161.2, num_updates=47200, lr=6.50945e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=62, gb_free=16.8, wall=6070
2023-07-12 15:23:04 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.581, trans_loss=5.12, nll_loss=2.356, w2v_ctc_loss=0.458, task_loss=1.545, contrastive_loss=0.092, total=4071.44, n_correct=2758.78, ppl=5.12, accuracy=67.759, wps=6481.8, ups=1.59, wpb=4071.4, bsz=142.1, num_updates=47300, lr=6.50256e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=62, gb_free=16.4, wall=6133
2023-07-12 15:24:08 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.576, trans_loss=5.129, nll_loss=2.37, w2v_ctc_loss=0.457, task_loss=1.226, contrastive_loss=0.448, total=4281.28, n_correct=2895.8, ppl=5.17, accuracy=67.639, wps=6688.6, ups=1.56, wpb=4281.3, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=6197
2023-07-12 15:25:10 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.596, trans_loss=5.136, nll_loss=2.378, w2v_ctc_loss=0.471, task_loss=1.469, contrastive_loss=0.145, total=4111.69, n_correct=2772.63, ppl=5.2, accuracy=67.433, wps=6544.4, ups=1.59, wpb=4111.7, bsz=149.2, num_updates=47500, lr=6.48886e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=6260
2023-07-12 15:26:12 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.572, trans_loss=5.113, nll_loss=2.348, w2v_ctc_loss=0.453, task_loss=1.34, contrastive_loss=0.109, total=4147.28, n_correct=2809.63, ppl=5.09, accuracy=67.746, wps=6706, ups=1.62, wpb=4147.3, bsz=156.7, num_updates=47600, lr=6.48204e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=6321
2023-07-12 15:27:15 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.603, trans_loss=5.146, nll_loss=2.389, w2v_ctc_loss=0.476, task_loss=1.49, contrastive_loss=0.149, total=4127.68, n_correct=2777.94, ppl=5.24, accuracy=67.3, wps=6558.1, ups=1.59, wpb=4127.7, bsz=146.3, num_updates=47700, lr=6.47524e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=62, gb_free=15.8, wall=6384
2023-07-12 15:28:18 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.592, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.466, task_loss=1.461, contrastive_loss=0.219, total=4164.1, n_correct=2797.71, ppl=5.26, accuracy=67.186, wps=6578, ups=1.58, wpb=4164.1, bsz=151.2, num_updates=47800, lr=6.46846e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=15.6, wall=6448
2023-07-12 15:29:21 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.605, trans_loss=5.16, nll_loss=2.408, w2v_ctc_loss=0.487, task_loss=1.554, contrastive_loss=0.109, total=4064.29, n_correct=2722.75, ppl=5.31, accuracy=66.992, wps=6463.9, ups=1.59, wpb=4064.3, bsz=142.9, num_updates=47900, lr=6.46171e-05, gnorm=0.431, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=6511
2023-07-12 15:30:24 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.583, trans_loss=5.135, nll_loss=2.377, w2v_ctc_loss=0.458, task_loss=1.354, contrastive_loss=0.246, total=4141.12, n_correct=2795.22, ppl=5.2, accuracy=67.499, wps=6602, ups=1.59, wpb=4141.1, bsz=159.3, num_updates=48000, lr=6.45497e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=6573
2023-07-12 15:30:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 15:30:49 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.692 | trans_loss 5.557 | nll_loss 2.827 | w2v_ctc_loss 1.203 | task_loss 4.345 | contrastive_loss 0.261 | total 4003.4 | n_correct 2496.5 | ppl 7.1 | accuracy 62.359 | uer 16.492 | wer 18.321 | raw_wer 18.321 | bleu 20.53 | wps 2107.1 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.61
2023-07-12 15:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-12 15:30:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_33_48000.pt
2023-07-12 15:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_33_48000.pt
2023-07-12 15:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.53) (writing took 6.809557740984019 seconds)
2023-07-12 15:31:59 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.592, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=0.474, task_loss=1.42, contrastive_loss=0.136, total=4147.76, n_correct=2792.29, ppl=5.25, accuracy=67.32, wps=4360.7, ups=1.05, wpb=4147.8, bsz=154.1, num_updates=48100, lr=6.44826e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=17.7, wall=6668
2023-07-12 15:33:02 | INFO | train_inner | epoch 033:   1051 / 1474 loss=1.596, trans_loss=5.144, nll_loss=2.388, w2v_ctc_loss=0.465, task_loss=1.427, contrastive_loss=0.342, total=4137.41, n_correct=2784.45, ppl=5.24, accuracy=67.299, wps=6540.5, ups=1.58, wpb=4137.4, bsz=154, num_updates=48200, lr=6.44157e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=6732
2023-07-12 15:34:06 | INFO | train_inner | epoch 033:   1151 / 1474 loss=1.601, trans_loss=5.158, nll_loss=2.407, w2v_ctc_loss=0.468, task_loss=1.425, contrastive_loss=0.321, total=4182.88, n_correct=2804.51, ppl=5.3, accuracy=67.047, wps=6636.5, ups=1.59, wpb=4182.9, bsz=154.3, num_updates=48300, lr=6.43489e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=6795
2023-07-12 15:35:09 | INFO | train_inner | epoch 033:   1251 / 1474 loss=1.595, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.47, task_loss=1.524, contrastive_loss=0.116, total=4102.27, n_correct=2757.59, ppl=5.25, accuracy=67.221, wps=6506.1, ups=1.59, wpb=4102.3, bsz=145.9, num_updates=48400, lr=6.42824e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=6858
2023-07-12 15:36:12 | INFO | train_inner | epoch 033:   1351 / 1474 loss=1.574, trans_loss=5.145, nll_loss=2.392, w2v_ctc_loss=0.466, task_loss=1.397, contrastive_loss=0.159, total=4131.08, n_correct=2780.85, ppl=5.25, accuracy=67.315, wps=6507.1, ups=1.58, wpb=4131.1, bsz=157, num_updates=48500, lr=6.42161e-05, gnorm=0.422, clip=0, loss_scale=128, train_wall=63, gb_free=17.4, wall=6921
2023-07-12 15:37:15 | INFO | train_inner | epoch 033:   1451 / 1474 loss=1.597, trans_loss=5.152, nll_loss=2.4, w2v_ctc_loss=0.467, task_loss=1.408, contrastive_loss=0.447, total=4135.49, n_correct=2778.92, ppl=5.28, accuracy=67.197, wps=6529.5, ups=1.58, wpb=4135.5, bsz=155.4, num_updates=48600, lr=6.415e-05, gnorm=0.423, clip=0, loss_scale=128, train_wall=63, gb_free=16.3, wall=6985
2023-07-12 15:37:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 15:37:58 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.687 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.161 | task_loss 4.313 | contrastive_loss 0.263 | total 4003.4 | n_correct 2492.3 | ppl 7.12 | accuracy 62.255 | uer 16.649 | wer 18.493 | raw_wer 18.493 | bleu 20.27 | wps 1809.2 | wpb 4003.4 | bsz 141.8 | num_updates 48623 | best_bleu 20.61
2023-07-12 15:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48623 updates
2023-07-12 15:37:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 15:38:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 15:38:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 33 @ 48623 updates, score 20.27) (writing took 4.246675703965593 seconds)
2023-07-12 15:38:02 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-12 15:38:02 | INFO | train | epoch 033 | loss 1.59 | trans_loss 5.142 | nll_loss 2.385 | w2v_ctc_loss 0.467 | task_loss 1.428 | contrastive_loss 0.216 | total 4138.65 | n_correct 2787.67 | ppl 5.22 | accuracy 67.357 | wps 6088.8 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 48623 | lr 6.41349e-05 | gnorm 0.421 | clip 0 | loss_scale 128 | train_wall 923 | gb_free 18 | wall 7031
2023-07-12 15:38:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 15:38:02 | INFO | fairseq.trainer | begin training epoch 34
2023-07-12 15:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 15:38:59 | INFO | train_inner | epoch 034:     77 / 1474 loss=1.58, trans_loss=5.118, nll_loss=2.353, w2v_ctc_loss=0.464, task_loss=1.411, contrastive_loss=0.121, total=4122.67, n_correct=2793.52, ppl=5.11, accuracy=67.76, wps=3987.7, ups=0.97, wpb=4122.7, bsz=150.7, num_updates=48700, lr=6.40841e-05, gnorm=0.415, clip=0, loss_scale=128, train_wall=63, gb_free=17.8, wall=7088
2023-07-12 15:40:02 | INFO | train_inner | epoch 034:    177 / 1474 loss=1.578, trans_loss=5.116, nll_loss=2.351, w2v_ctc_loss=0.464, task_loss=1.492, contrastive_loss=0.125, total=4074.94, n_correct=2762.49, ppl=5.1, accuracy=67.792, wps=6474.1, ups=1.59, wpb=4074.9, bsz=147.7, num_updates=48800, lr=6.40184e-05, gnorm=0.427, clip=0, loss_scale=128, train_wall=63, gb_free=17.2, wall=7151
2023-07-12 15:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-12 15:41:06 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.593, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.465, task_loss=1.381, contrastive_loss=0.336, total=4212.96, n_correct=2840.33, ppl=5.2, accuracy=67.419, wps=6574.7, ups=1.56, wpb=4213, bsz=159.4, num_updates=48900, lr=6.39529e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=64, gb_free=10.9, wall=7215
2023-07-12 15:42:09 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.58, trans_loss=5.119, nll_loss=2.357, w2v_ctc_loss=0.458, task_loss=1.349, contrastive_loss=0.318, total=4167, n_correct=2825.93, ppl=5.12, accuracy=67.817, wps=6622.4, ups=1.59, wpb=4167, bsz=159.5, num_updates=49000, lr=6.38877e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=62, gb_free=17.5, wall=7278
2023-07-12 15:43:12 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.591, trans_loss=5.131, nll_loss=2.37, w2v_ctc_loss=0.472, task_loss=1.558, contrastive_loss=0.11, total=4071.65, n_correct=2746.93, ppl=5.17, accuracy=67.465, wps=6396.4, ups=1.57, wpb=4071.7, bsz=142.4, num_updates=49100, lr=6.38226e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=12, wall=7342
2023-07-12 15:44:15 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.584, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.464, task_loss=1.454, contrastive_loss=0.116, total=4110.13, n_correct=2784.45, ppl=5.12, accuracy=67.746, wps=6572.6, ups=1.6, wpb=4110.1, bsz=149.5, num_updates=49200, lr=6.37577e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=7404
2023-07-12 15:45:18 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.579, trans_loss=5.119, nll_loss=2.356, w2v_ctc_loss=0.458, task_loss=1.452, contrastive_loss=0.106, total=4128.65, n_correct=2795.58, ppl=5.12, accuracy=67.712, wps=6525.8, ups=1.58, wpb=4128.6, bsz=150.4, num_updates=49300, lr=6.3693e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=18, wall=7467
2023-07-12 15:46:21 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.599, trans_loss=5.143, nll_loss=2.388, w2v_ctc_loss=0.461, task_loss=1.494, contrastive_loss=0.242, total=4075.69, n_correct=2742.31, ppl=5.23, accuracy=67.285, wps=6474.1, ups=1.59, wpb=4075.7, bsz=147.3, num_updates=49400, lr=6.36285e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=7530
2023-07-12 15:47:24 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.598, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.472, task_loss=1.506, contrastive_loss=0.158, total=4104.97, n_correct=2761.5, ppl=5.26, accuracy=67.272, wps=6498, ups=1.58, wpb=4105, bsz=148.2, num_updates=49500, lr=6.35642e-05, gnorm=0.431, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=7594
2023-07-12 15:48:28 | INFO | train_inner | epoch 034:    978 / 1474 loss=1.587, trans_loss=5.146, nll_loss=2.391, w2v_ctc_loss=0.471, task_loss=1.399, contrastive_loss=0.152, total=4168.94, n_correct=2804.28, ppl=5.25, accuracy=67.266, wps=6586, ups=1.58, wpb=4168.9, bsz=156.4, num_updates=49600, lr=6.35001e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=63, gb_free=15.2, wall=7657
2023-07-12 15:49:30 | INFO | train_inner | epoch 034:   1078 / 1474 loss=1.59, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.474, task_loss=1.381, contrastive_loss=0.116, total=4155.12, n_correct=2796.98, ppl=5.24, accuracy=67.314, wps=6630.3, ups=1.6, wpb=4155.1, bsz=154.6, num_updates=49700, lr=6.34361e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=7720
2023-07-12 15:50:33 | INFO | train_inner | epoch 034:   1178 / 1474 loss=1.586, trans_loss=5.138, nll_loss=2.381, w2v_ctc_loss=0.467, task_loss=1.478, contrastive_loss=0.142, total=4096.48, n_correct=2759.55, ppl=5.21, accuracy=67.364, wps=6510.2, ups=1.59, wpb=4096.5, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=7782
2023-07-12 15:51:36 | INFO | train_inner | epoch 034:   1278 / 1474 loss=1.585, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.465, task_loss=1.451, contrastive_loss=0.107, total=4149.03, n_correct=2795.95, ppl=5.2, accuracy=67.388, wps=6608.7, ups=1.59, wpb=4149, bsz=149.9, num_updates=49900, lr=6.33089e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=62, gb_free=16.6, wall=7845
2023-07-12 15:52:40 | INFO | train_inner | epoch 034:   1378 / 1474 loss=1.588, trans_loss=5.152, nll_loss=2.4, w2v_ctc_loss=0.471, task_loss=1.363, contrastive_loss=0.242, total=4200.34, n_correct=2819.24, ppl=5.28, accuracy=67.119, wps=6581.3, ups=1.57, wpb=4200.3, bsz=161, num_updates=50000, lr=6.32456e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=7909
2023-07-12 15:52:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 15:53:04 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.686 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.186 | task_loss 4.352 | contrastive_loss 0.262 | total 4003.4 | n_correct 2497.4 | ppl 7.1 | accuracy 62.382 | uer 16.274 | wer 18.113 | raw_wer 18.113 | bleu 20.56 | wps 2229.1 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.61
2023-07-12 15:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-12 15:53:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_34_50000.pt
2023-07-12 15:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_34_50000.pt
2023-07-12 15:53:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.56) (writing took 6.13951776799513 seconds)
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-12 15:54:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
2023-07-12 15:54:36 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.688 | trans_loss 5.555 | nll_loss 2.824 | w2v_ctc_loss 1.176 | task_loss 4.329 | contrastive_loss 0.258 | total 4003.4 | n_correct 2494.5 | ppl 7.08 | accuracy 62.31 | uer 16.298 | wer 18.083 | raw_wer 18.083 | bleu 20.56 | wps 2093.1 | wpb 4003.4 | bsz 141.8 | num_updates 50096 | best_bleu 20.61
2023-07-12 15:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50096 updates
2023-07-12 15:54:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt
2023-07-12 15:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt
2023-07-12 15:54:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt (epoch 34 @ 50096 updates, score 20.56) (writing took 7.114254307991359 seconds)
2023-07-12 15:54:43 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-12 15:54:43 | INFO | train | epoch 034 | loss 1.587 | trans_loss 5.134 | nll_loss 2.375 | w2v_ctc_loss 0.465 | task_loss 1.431 | contrastive_loss 0.199 | total 4137.27 | n_correct 2791.34 | ppl 5.19 | accuracy 67.468 | wps 6085.9 | ups 1.47 | wpb 4137.3 | bsz 152.6 | num_updates 50096 | lr 6.31849e-05 | gnorm 0.421 | clip 0 | loss_scale 64 | train_wall 924 | gb_free 17.5 | wall 8033
2023-07-12 15:54:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 15:54:44 | INFO | fairseq.trainer | begin training epoch 35
2023-07-12 15:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 15:54:54 | INFO | train_inner | epoch 035:      4 / 1474 loss=1.591, trans_loss=5.142, nll_loss=2.387, w2v_ctc_loss=0.458, task_loss=1.304, contrastive_loss=0.517, total=4211.77, n_correct=2833.57, ppl=5.23, accuracy=67.277, wps=3142.4, ups=0.75, wpb=4211.8, bsz=163.5, num_updates=50100, lr=6.31824e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=8043
2023-07-12 15:55:57 | INFO | train_inner | epoch 035:    104 / 1474 loss=1.575, trans_loss=5.107, nll_loss=2.34, w2v_ctc_loss=0.448, task_loss=1.383, contrastive_loss=0.397, total=4165.08, n_correct=2830.91, ppl=5.06, accuracy=67.968, wps=6598.9, ups=1.58, wpb=4165.1, bsz=156.3, num_updates=50200, lr=6.31194e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=8106
2023-07-12 15:57:00 | INFO | train_inner | epoch 035:    204 / 1474 loss=1.565, trans_loss=5.107, nll_loss=2.339, w2v_ctc_loss=0.453, task_loss=1.35, contrastive_loss=0.117, total=4176.66, n_correct=2836.38, ppl=5.06, accuracy=67.91, wps=6580.4, ups=1.58, wpb=4176.7, bsz=158.5, num_updates=50300, lr=6.30567e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=8170
2023-07-12 15:58:05 | INFO | train_inner | epoch 035:    304 / 1474 loss=1.585, trans_loss=5.113, nll_loss=2.346, w2v_ctc_loss=0.455, task_loss=1.489, contrastive_loss=0.451, total=4108.8, n_correct=2787.49, ppl=5.08, accuracy=67.842, wps=6372.5, ups=1.55, wpb=4108.8, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=8234
2023-07-12 15:59:08 | INFO | train_inner | epoch 035:    404 / 1474 loss=1.593, trans_loss=5.122, nll_loss=2.359, w2v_ctc_loss=0.471, task_loss=1.579, contrastive_loss=0.118, total=4069.25, n_correct=2750.55, ppl=5.13, accuracy=67.594, wps=6480.5, ups=1.59, wpb=4069.2, bsz=141.5, num_updates=50500, lr=6.29317e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=62, gb_free=17.4, wall=8297
2023-07-12 16:00:11 | INFO | train_inner | epoch 035:    504 / 1474 loss=1.582, trans_loss=5.12, nll_loss=2.356, w2v_ctc_loss=0.456, task_loss=1.447, contrastive_loss=0.264, total=4152.56, n_correct=2812.05, ppl=5.12, accuracy=67.718, wps=6603.6, ups=1.59, wpb=4152.6, bsz=152.5, num_updates=50600, lr=6.28695e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=62, gb_free=16.2, wall=8360
2023-07-12 16:01:13 | INFO | train_inner | epoch 035:    604 / 1474 loss=1.574, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.452, task_loss=1.431, contrastive_loss=0.284, total=4166.96, n_correct=2825.14, ppl=5.11, accuracy=67.799, wps=6669.2, ups=1.6, wpb=4167, bsz=153.9, num_updates=50700, lr=6.28074e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=62, gb_free=15.6, wall=8422
2023-07-12 16:02:16 | INFO | train_inner | epoch 035:    704 / 1474 loss=1.59, trans_loss=5.128, nll_loss=2.366, w2v_ctc_loss=0.472, task_loss=1.505, contrastive_loss=0.137, total=4076.62, n_correct=2758.98, ppl=5.16, accuracy=67.678, wps=6479, ups=1.59, wpb=4076.6, bsz=146.7, num_updates=50800, lr=6.27456e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=62, gb_free=15.2, wall=8485
2023-07-12 16:03:20 | INFO | train_inner | epoch 035:    804 / 1474 loss=1.579, trans_loss=5.125, nll_loss=2.363, w2v_ctc_loss=0.463, task_loss=1.402, contrastive_loss=0.156, total=4160.7, n_correct=2813.88, ppl=5.14, accuracy=67.63, wps=6552.2, ups=1.57, wpb=4160.7, bsz=156.3, num_updates=50900, lr=6.26839e-05, gnorm=0.422, clip=0, loss_scale=128, train_wall=63, gb_free=16.7, wall=8549
2023-07-12 16:04:24 | INFO | train_inner | epoch 035:    904 / 1474 loss=1.589, trans_loss=5.133, nll_loss=2.374, w2v_ctc_loss=0.472, task_loss=1.498, contrastive_loss=0.118, total=4094.05, n_correct=2762.79, ppl=5.18, accuracy=67.483, wps=6401.5, ups=1.56, wpb=4094.1, bsz=146.9, num_updates=51000, lr=6.26224e-05, gnorm=0.432, clip=0, loss_scale=128, train_wall=64, gb_free=17.6, wall=8613
2023-07-12 16:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-12 16:05:27 | INFO | train_inner | epoch 035:   1005 / 1474 loss=1.595, trans_loss=5.132, nll_loss=2.372, w2v_ctc_loss=0.469, task_loss=1.478, contrastive_loss=0.143, total=4123.24, n_correct=2782.11, ppl=5.18, accuracy=67.474, wps=6468.6, ups=1.57, wpb=4123.2, bsz=149.4, num_updates=51100, lr=6.25611e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=15, wall=8676
2023-07-12 16:06:30 | INFO | train_inner | epoch 035:   1105 / 1474 loss=1.584, trans_loss=5.131, nll_loss=2.373, w2v_ctc_loss=0.465, task_loss=1.363, contrastive_loss=0.133, total=4180.8, n_correct=2824.14, ppl=5.18, accuracy=67.55, wps=6682.5, ups=1.6, wpb=4180.8, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=8739
2023-07-12 16:07:33 | INFO | train_inner | epoch 035:   1205 / 1474 loss=1.588, trans_loss=5.129, nll_loss=2.37, w2v_ctc_loss=0.456, task_loss=1.317, contrastive_loss=0.24, total=4214.15, n_correct=2846.86, ppl=5.17, accuracy=67.555, wps=6702.3, ups=1.59, wpb=4214.1, bsz=160.4, num_updates=51300, lr=6.24391e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=8802
2023-07-12 16:08:36 | INFO | train_inner | epoch 035:   1305 / 1474 loss=1.579, trans_loss=5.128, nll_loss=2.37, w2v_ctc_loss=0.46, task_loss=1.375, contrastive_loss=0.142, total=4140.13, n_correct=2796.05, ppl=5.17, accuracy=67.535, wps=6561.8, ups=1.58, wpb=4140.1, bsz=156.5, num_updates=51400, lr=6.23783e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=8865
2023-07-12 16:09:39 | INFO | train_inner | epoch 035:   1405 / 1474 loss=1.591, trans_loss=5.141, nll_loss=2.383, w2v_ctc_loss=0.465, task_loss=1.557, contrastive_loss=0.114, total=4056.79, n_correct=2733.56, ppl=5.22, accuracy=67.382, wps=6449.8, ups=1.59, wpb=4056.8, bsz=143.1, num_updates=51500, lr=6.23177e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=8928
2023-07-12 16:10:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 16:10:48 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.692 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 1.207 | task_loss 4.352 | contrastive_loss 0.26 | total 4003.4 | n_correct 2501.5 | ppl 7.06 | accuracy 62.484 | uer 16.42 | wer 18.18 | raw_wer 18.18 | bleu 20.56 | wps 2127.2 | wpb 4003.4 | bsz 141.8 | num_updates 51569 | best_bleu 20.61
2023-07-12 16:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51569 updates
2023-07-12 16:10:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt
2023-07-12 16:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt
2023-07-12 16:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint.best_bleu_20.5603.pt (epoch 35 @ 51569 updates, score 20.56) (writing took 7.137022805982269 seconds)
2023-07-12 16:10:55 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-12 16:10:55 | INFO | train | epoch 035 | loss 1.583 | trans_loss 5.124 | nll_loss 2.362 | w2v_ctc_loss 0.46 | task_loss 1.43 | contrastive_loss 0.204 | total 4137.13 | n_correct 2799.1 | ppl 5.14 | accuracy 67.658 | wps 6272.9 | ups 1.52 | wpb 4137.1 | bsz 152.6 | num_updates 51569 | lr 6.2276e-05 | gnorm 0.42 | clip 0 | loss_scale 64 | train_wall 925 | gb_free 17.4 | wall 9004
2023-07-12 16:10:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 16:10:55 | INFO | fairseq.trainer | begin training epoch 36
2023-07-12 16:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 16:11:22 | INFO | train_inner | epoch 036:     31 / 1474 loss=1.583, trans_loss=5.115, nll_loss=2.352, w2v_ctc_loss=0.458, task_loss=1.386, contrastive_loss=0.204, total=4123.87, n_correct=2796.56, ppl=5.1, accuracy=67.814, wps=3990.3, ups=0.97, wpb=4123.9, bsz=154.3, num_updates=51600, lr=6.22573e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=17.5, wall=9031
2023-07-12 16:12:25 | INFO | train_inner | epoch 036:    131 / 1474 loss=1.57, trans_loss=5.098, nll_loss=2.327, w2v_ctc_loss=0.453, task_loss=1.488, contrastive_loss=0.135, total=4105.22, n_correct=2795.01, ppl=5.02, accuracy=68.084, wps=6495.3, ups=1.58, wpb=4105.2, bsz=149.6, num_updates=51700, lr=6.2197e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=15.8, wall=9094
2023-07-12 16:13:29 | INFO | train_inner | epoch 036:    231 / 1474 loss=1.579, trans_loss=5.105, nll_loss=2.338, w2v_ctc_loss=0.457, task_loss=1.455, contrastive_loss=0.164, total=4152.4, n_correct=2821.62, ppl=5.05, accuracy=67.952, wps=6523.5, ups=1.57, wpb=4152.4, bsz=151.5, num_updates=51800, lr=6.2137e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=9158
2023-07-12 16:14:31 | INFO | train_inner | epoch 036:    331 / 1474 loss=1.567, trans_loss=5.1, nll_loss=2.33, w2v_ctc_loss=0.445, task_loss=1.356, contrastive_loss=0.113, total=4161.71, n_correct=2835.39, ppl=5.03, accuracy=68.13, wps=6690.5, ups=1.61, wpb=4161.7, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=62, gb_free=13.9, wall=9220
2023-07-12 16:15:34 | INFO | train_inner | epoch 036:    431 / 1474 loss=1.566, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=0.44, task_loss=1.254, contrastive_loss=0.348, total=4234.57, n_correct=2886.2, ppl=5.02, accuracy=68.158, wps=6725.9, ups=1.59, wpb=4234.6, bsz=166.8, num_updates=52000, lr=6.20174e-05, gnorm=0.412, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=9283
2023-07-12 16:15:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 16:15:58 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.703 | trans_loss 5.565 | nll_loss 2.838 | w2v_ctc_loss 1.208 | task_loss 4.316 | contrastive_loss 0.257 | total 4003.4 | n_correct 2498.1 | ppl 7.15 | accuracy 62.399 | uer 16.455 | wer 18.389 | raw_wer 18.389 | bleu 20.28 | wps 2230.9 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.61
2023-07-12 16:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-12 16:15:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_36_52000.pt
2023-07-12 16:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_36_52000.pt
2023-07-12 16:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.28) (writing took 5.067128013994079 seconds)
2023-07-12 16:17:08 | INFO | train_inner | epoch 036:    531 / 1474 loss=1.588, trans_loss=5.124, nll_loss=2.362, w2v_ctc_loss=0.451, task_loss=1.438, contrastive_loss=0.637, total=4145.92, n_correct=2802.33, ppl=5.14, accuracy=67.592, wps=4420.8, ups=1.07, wpb=4145.9, bsz=155.5, num_updates=52100, lr=6.19578e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=9377
2023-07-12 16:18:12 | INFO | train_inner | epoch 036:    631 / 1474 loss=1.569, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.449, task_loss=1.38, contrastive_loss=0.273, total=4180.58, n_correct=2842.68, ppl=5.04, accuracy=67.997, wps=6564.1, ups=1.57, wpb=4180.6, bsz=158.3, num_updates=52200, lr=6.18984e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=9441
2023-07-12 16:19:15 | INFO | train_inner | epoch 036:    731 / 1474 loss=1.585, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.463, task_loss=1.368, contrastive_loss=0.144, total=4185.09, n_correct=2832.95, ppl=5.14, accuracy=67.691, wps=6636, ups=1.59, wpb=4185.1, bsz=158.6, num_updates=52300, lr=6.18392e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=9504
2023-07-12 16:20:18 | INFO | train_inner | epoch 036:    831 / 1474 loss=1.592, trans_loss=5.141, nll_loss=2.385, w2v_ctc_loss=0.457, task_loss=1.349, contrastive_loss=0.48, total=4167.92, n_correct=2808.34, ppl=5.22, accuracy=67.38, wps=6597.3, ups=1.58, wpb=4167.9, bsz=159.5, num_updates=52400, lr=6.17802e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=9567
2023-07-12 16:21:21 | INFO | train_inner | epoch 036:    931 / 1474 loss=1.578, trans_loss=5.111, nll_loss=2.345, w2v_ctc_loss=0.457, task_loss=1.431, contrastive_loss=0.126, total=4180.47, n_correct=2834.65, ppl=5.08, accuracy=67.807, wps=6592.5, ups=1.58, wpb=4180.5, bsz=153.8, num_updates=52500, lr=6.17213e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=13.1, wall=9630
2023-07-12 16:22:24 | INFO | train_inner | epoch 036:   1031 / 1474 loss=1.587, trans_loss=5.115, nll_loss=2.351, w2v_ctc_loss=0.459, task_loss=1.473, contrastive_loss=0.112, total=4175.32, n_correct=2831.59, ppl=5.1, accuracy=67.817, wps=6601.6, ups=1.58, wpb=4175.3, bsz=150.4, num_updates=52600, lr=6.16626e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=13.6, wall=9694
2023-07-12 16:23:28 | INFO | train_inner | epoch 036:   1131 / 1474 loss=1.576, trans_loss=5.116, nll_loss=2.351, w2v_ctc_loss=0.46, task_loss=1.421, contrastive_loss=0.144, total=4140.45, n_correct=2803.88, ppl=5.1, accuracy=67.719, wps=6534.4, ups=1.58, wpb=4140.4, bsz=154.1, num_updates=52700, lr=6.16041e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=9757
2023-07-12 16:24:31 | INFO | train_inner | epoch 036:   1231 / 1474 loss=1.587, trans_loss=5.122, nll_loss=2.358, w2v_ctc_loss=0.467, task_loss=1.586, contrastive_loss=0.107, total=4044.64, n_correct=2739.89, ppl=5.13, accuracy=67.741, wps=6378.2, ups=1.58, wpb=4044.6, bsz=139.5, num_updates=52800, lr=6.15457e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=13.7, wall=9820
2023-07-12 16:25:34 | INFO | train_inner | epoch 036:   1331 / 1474 loss=1.579, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.462, task_loss=1.43, contrastive_loss=0.132, total=4106.95, n_correct=2775.17, ppl=5.15, accuracy=67.573, wps=6584.5, ups=1.6, wpb=4106.9, bsz=152.7, num_updates=52900, lr=6.14875e-05, gnorm=0.432, clip=0, loss_scale=64, train_wall=62, gb_free=17.6, wall=9883
2023-07-12 16:26:37 | INFO | train_inner | epoch 036:   1431 / 1474 loss=1.602, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.467, task_loss=1.599, contrastive_loss=0.233, total=4043.37, n_correct=2723.86, ppl=5.2, accuracy=67.366, wps=6419.4, ups=1.59, wpb=4043.4, bsz=139.2, num_updates=53000, lr=6.14295e-05, gnorm=0.43, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=9946
2023-07-12 16:27:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 16:27:28 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.704 | trans_loss 5.554 | nll_loss 2.828 | w2v_ctc_loss 1.222 | task_loss 4.334 | contrastive_loss 0.273 | total 4003.4 | n_correct 2500.6 | ppl 7.1 | accuracy 62.462 | uer 16.484 | wer 18.254 | raw_wer 18.254 | bleu 20.38 | wps 2154.6 | wpb 4003.4 | bsz 141.8 | num_updates 53043 | best_bleu 20.61
2023-07-12 16:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53043 updates
2023-07-12 16:27:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 16:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 16:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 36 @ 53043 updates, score 20.38) (writing took 4.087252026016358 seconds)
2023-07-12 16:27:32 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-12 16:27:32 | INFO | train | epoch 036 | loss 1.58 | trans_loss 5.115 | nll_loss 2.351 | w2v_ctc_loss 0.456 | task_loss 1.427 | contrastive_loss 0.223 | total 4138.65 | n_correct 2805.59 | ppl 5.1 | accuracy 67.79 | wps 6117.5 | ups 1.48 | wpb 4138.6 | bsz 152.8 | num_updates 53043 | lr 6.14046e-05 | gnorm 0.42 | clip 0 | loss_scale 64 | train_wall 924 | gb_free 17 | wall 10001
2023-07-12 16:27:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 16:27:32 | INFO | fairseq.trainer | begin training epoch 37
2023-07-12 16:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 16:28:17 | INFO | train_inner | epoch 037:     57 / 1474 loss=1.575, trans_loss=5.102, nll_loss=2.335, w2v_ctc_loss=0.453, task_loss=1.425, contrastive_loss=0.143, total=4106.39, n_correct=2794.2, ppl=5.04, accuracy=68.045, wps=4099.7, ups=1, wpb=4106.4, bsz=150.6, num_updates=53100, lr=6.13716e-05, gnorm=0.422, clip=0, loss_scale=128, train_wall=62, gb_free=15.9, wall=10046
2023-07-12 16:29:21 | INFO | train_inner | epoch 037:    157 / 1474 loss=1.58, trans_loss=5.099, nll_loss=2.329, w2v_ctc_loss=0.453, task_loss=1.455, contrastive_loss=0.25, total=4113.11, n_correct=2799.91, ppl=5.02, accuracy=68.073, wps=6445.2, ups=1.57, wpb=4113.1, bsz=152.8, num_updates=53200, lr=6.13139e-05, gnorm=0.422, clip=0, loss_scale=128, train_wall=63, gb_free=16.9, wall=10110
2023-07-12 16:30:24 | INFO | train_inner | epoch 037:    257 / 1474 loss=1.557, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.44, task_loss=1.347, contrastive_loss=0.134, total=4185.25, n_correct=2859.95, ppl=4.97, accuracy=68.334, wps=6638.3, ups=1.59, wpb=4185.2, bsz=159, num_updates=53300, lr=6.12564e-05, gnorm=0.413, clip=0, loss_scale=128, train_wall=63, gb_free=17.4, wall=10173
2023-07-12 16:31:27 | INFO | train_inner | epoch 037:    357 / 1474 loss=1.581, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=0.458, task_loss=1.418, contrastive_loss=0.148, total=4178.25, n_correct=2846.5, ppl=5.02, accuracy=68.127, wps=6619.9, ups=1.58, wpb=4178.2, bsz=154.2, num_updates=53400, lr=6.1199e-05, gnorm=0.419, clip=0, loss_scale=128, train_wall=63, gb_free=16.5, wall=10236
2023-07-12 16:31:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-12 16:32:31 | INFO | train_inner | epoch 037:    458 / 1474 loss=1.592, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.453, task_loss=1.391, contrastive_loss=0.553, total=4170.96, n_correct=2825.57, ppl=5.12, accuracy=67.744, wps=6506.3, ups=1.56, wpb=4171, bsz=157, num_updates=53500, lr=6.11418e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=64, gb_free=13.6, wall=10300
2023-07-12 16:33:34 | INFO | train_inner | epoch 037:    558 / 1474 loss=1.568, trans_loss=5.103, nll_loss=2.335, w2v_ctc_loss=0.454, task_loss=1.479, contrastive_loss=0.128, total=4091.86, n_correct=2783.43, ppl=5.05, accuracy=68.024, wps=6488.7, ups=1.59, wpb=4091.9, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=10363
2023-07-12 16:34:37 | INFO | train_inner | epoch 037:    658 / 1474 loss=1.582, trans_loss=5.113, nll_loss=2.348, w2v_ctc_loss=0.463, task_loss=1.513, contrastive_loss=0.143, total=4096.37, n_correct=2776.23, ppl=5.09, accuracy=67.773, wps=6493.9, ups=1.59, wpb=4096.4, bsz=145.2, num_updates=53700, lr=6.10278e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=15.2, wall=10426
2023-07-12 16:35:40 | INFO | train_inner | epoch 037:    758 / 1474 loss=1.581, trans_loss=5.106, nll_loss=2.34, w2v_ctc_loss=0.455, task_loss=1.421, contrastive_loss=0.26, total=4124.05, n_correct=2799.71, ppl=5.06, accuracy=67.887, wps=6552.3, ups=1.59, wpb=4124.1, bsz=152.7, num_updates=53800, lr=6.09711e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=13.8, wall=10489
2023-07-12 16:36:43 | INFO | train_inner | epoch 037:    858 / 1474 loss=1.57, trans_loss=5.106, nll_loss=2.339, w2v_ctc_loss=0.45, task_loss=1.349, contrastive_loss=0.128, total=4161.41, n_correct=2829.02, ppl=5.06, accuracy=67.982, wps=6597.2, ups=1.59, wpb=4161.4, bsz=157.5, num_updates=53900, lr=6.09145e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=10552
2023-07-12 16:37:46 | INFO | train_inner | epoch 037:    958 / 1474 loss=1.586, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.466, task_loss=1.503, contrastive_loss=0.14, total=4108.96, n_correct=2784.33, ppl=5.12, accuracy=67.762, wps=6514, ups=1.59, wpb=4109, bsz=147.4, num_updates=54000, lr=6.08581e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=10615
2023-07-12 16:37:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 16:38:11 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.706 | trans_loss 5.564 | nll_loss 2.839 | w2v_ctc_loss 1.253 | task_loss 4.407 | contrastive_loss 0.267 | total 4003.4 | n_correct 2499 | ppl 7.15 | accuracy 62.422 | uer 16.558 | wer 18.43 | raw_wer 18.43 | bleu 20.35 | wps 2096.9 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.61
2023-07-12 16:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-12 16:38:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_37_54000.pt
2023-07-12 16:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_37_54000.pt
2023-07-12 16:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.35) (writing took 5.006065354042221 seconds)
2023-07-12 16:39:19 | INFO | train_inner | epoch 037:   1058 / 1474 loss=1.572, trans_loss=5.103, nll_loss=2.335, w2v_ctc_loss=0.445, task_loss=1.367, contrastive_loss=0.393, total=4140.79, n_correct=2819.76, ppl=5.05, accuracy=68.097, wps=4450.4, ups=1.07, wpb=4140.8, bsz=157.3, num_updates=54100, lr=6.08018e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=62, gb_free=15.3, wall=10708
2023-07-12 16:40:23 | INFO | train_inner | epoch 037:   1158 / 1474 loss=1.579, trans_loss=5.118, nll_loss=2.356, w2v_ctc_loss=0.448, task_loss=1.357, contrastive_loss=0.455, total=4188.76, n_correct=2838.55, ppl=5.12, accuracy=67.766, wps=6599.6, ups=1.58, wpb=4188.8, bsz=158.6, num_updates=54200, lr=6.07457e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=15.4, wall=10772
2023-07-12 16:41:26 | INFO | train_inner | epoch 037:   1258 / 1474 loss=1.576, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.456, task_loss=1.391, contrastive_loss=0.145, total=4170.22, n_correct=2824.17, ppl=5.12, accuracy=67.722, wps=6613.5, ups=1.59, wpb=4170.2, bsz=155.8, num_updates=54300, lr=6.06897e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=10835
2023-07-12 16:42:29 | INFO | train_inner | epoch 037:   1358 / 1474 loss=1.596, trans_loss=5.121, nll_loss=2.358, w2v_ctc_loss=0.472, task_loss=1.567, contrastive_loss=0.124, total=4071.07, n_correct=2754.05, ppl=5.13, accuracy=67.649, wps=6457.6, ups=1.59, wpb=4071.1, bsz=142.7, num_updates=54400, lr=6.06339e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=63, gb_free=10.4, wall=10898
2023-07-12 16:43:33 | INFO | train_inner | epoch 037:   1458 / 1474 loss=1.58, trans_loss=5.115, nll_loss=2.352, w2v_ctc_loss=0.453, task_loss=1.411, contrastive_loss=0.191, total=4160.94, n_correct=2820.01, ppl=5.1, accuracy=67.773, wps=6523.1, ups=1.57, wpb=4160.9, bsz=153.1, num_updates=54500, lr=6.05783e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=10962
2023-07-12 16:43:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 16:44:10 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.705 | trans_loss 5.561 | nll_loss 2.833 | w2v_ctc_loss 1.224 | task_loss 4.352 | contrastive_loss 0.271 | total 4003.4 | n_correct 2491.6 | ppl 7.12 | accuracy 62.237 | uer 16.585 | wer 18.534 | raw_wer 18.534 | bleu 19.97 | wps 2054.3 | wpb 4003.4 | bsz 141.8 | num_updates 54516 | best_bleu 20.61
2023-07-12 16:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54516 updates
2023-07-12 16:44:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 16:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 16:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 37 @ 54516 updates, score 19.97) (writing took 4.180793215986341 seconds)
2023-07-12 16:44:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-12 16:44:14 | INFO | train | epoch 037 | loss 1.579 | trans_loss 5.109 | nll_loss 2.342 | w2v_ctc_loss 0.455 | task_loss 1.429 | contrastive_loss 0.226 | total 4137.79 | n_correct 2810.3 | ppl 5.07 | accuracy 67.918 | wps 6085.3 | ups 1.47 | wpb 4137.8 | bsz 152.7 | num_updates 54516 | lr 6.05694e-05 | gnorm 0.421 | clip 0 | loss_scale 64 | train_wall 925 | gb_free 13.2 | wall 11003
2023-07-12 16:44:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 16:44:14 | INFO | fairseq.trainer | begin training epoch 38
2023-07-12 16:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 16:45:15 | INFO | train_inner | epoch 038:     84 / 1474 loss=1.578, trans_loss=5.087, nll_loss=2.313, w2v_ctc_loss=0.452, task_loss=1.492, contrastive_loss=0.121, total=4084.91, n_correct=2789.1, ppl=4.97, accuracy=68.278, wps=3984.2, ups=0.98, wpb=4084.9, bsz=146.6, num_updates=54600, lr=6.05228e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=16.3, wall=11064
2023-07-12 16:46:18 | INFO | train_inner | epoch 038:    184 / 1474 loss=1.565, trans_loss=5.086, nll_loss=2.312, w2v_ctc_loss=0.446, task_loss=1.508, contrastive_loss=0.128, total=4081.45, n_correct=2788.03, ppl=4.97, accuracy=68.31, wps=6505.8, ups=1.59, wpb=4081.5, bsz=146, num_updates=54700, lr=6.04674e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=11127
2023-07-12 16:47:21 | INFO | train_inner | epoch 038:    284 / 1474 loss=1.57, trans_loss=5.093, nll_loss=2.321, w2v_ctc_loss=0.447, task_loss=1.503, contrastive_loss=0.166, total=4059.24, n_correct=2765.39, ppl=5, accuracy=68.126, wps=6434.9, ups=1.59, wpb=4059.2, bsz=146.6, num_updates=54800, lr=6.04122e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=11190
2023-07-12 16:48:24 | INFO | train_inner | epoch 038:    384 / 1474 loss=1.565, trans_loss=5.091, nll_loss=2.318, w2v_ctc_loss=0.449, task_loss=1.409, contrastive_loss=0.173, total=4176.56, n_correct=2851.64, ppl=4.99, accuracy=68.277, wps=6639.5, ups=1.59, wpb=4176.6, bsz=154.6, num_updates=54900, lr=6.03572e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=62, gb_free=16.3, wall=11253
2023-07-12 16:49:27 | INFO | train_inner | epoch 038:    484 / 1474 loss=1.561, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.444, task_loss=1.376, contrastive_loss=0.167, total=4191.63, n_correct=2862.74, ppl=4.97, accuracy=68.297, wps=6668.4, ups=1.59, wpb=4191.6, bsz=156.4, num_updates=55000, lr=6.03023e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=15.9, wall=11316
tensor(0.0184, device='cuda:0')
tensor(0.0022, device='cuda:0')
2023-07-12 16:50:31 | INFO | train_inner | epoch 038:    584 / 1474 loss=1.588, trans_loss=5.117, nll_loss=2.354, w2v_ctc_loss=0.449, task_loss=1.418, contrastive_loss=0.498, total=4179.76, n_correct=2832.9, ppl=5.11, accuracy=67.777, wps=6457.9, ups=1.55, wpb=4179.8, bsz=154.8, num_updates=55100, lr=6.02475e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=64, gb_free=16.1, wall=11381
2023-07-12 16:51:35 | INFO | train_inner | epoch 038:    684 / 1474 loss=1.57, trans_loss=5.095, nll_loss=2.325, w2v_ctc_loss=0.443, task_loss=1.353, contrastive_loss=0.473, total=4173.72, n_correct=2843.43, ppl=5.01, accuracy=68.127, wps=6588.8, ups=1.58, wpb=4173.7, bsz=160.6, num_updates=55200, lr=6.01929e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=11444
2023-07-12 16:52:37 | INFO | train_inner | epoch 038:    784 / 1474 loss=1.576, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=0.447, task_loss=1.309, contrastive_loss=0.318, total=4183.15, n_correct=2856.81, ppl=4.98, accuracy=68.293, wps=6670.8, ups=1.59, wpb=4183.1, bsz=163.3, num_updates=55300, lr=6.01385e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=62, gb_free=17.8, wall=11507
2023-07-12 16:53:40 | INFO | train_inner | epoch 038:    884 / 1474 loss=1.561, trans_loss=5.09, nll_loss=2.32, w2v_ctc_loss=0.447, task_loss=1.367, contrastive_loss=0.138, total=4121.14, n_correct=2814.84, ppl=4.99, accuracy=68.302, wps=6577.5, ups=1.6, wpb=4121.1, bsz=155.6, num_updates=55400, lr=6.00842e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=16.8, wall=11569
2023-07-12 16:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-12 16:54:43 | INFO | train_inner | epoch 038:    985 / 1474 loss=1.579, trans_loss=5.113, nll_loss=2.348, w2v_ctc_loss=0.459, task_loss=1.455, contrastive_loss=0.132, total=4103.82, n_correct=2783.48, ppl=5.09, accuracy=67.827, wps=6511, ups=1.59, wpb=4103.8, bsz=148.6, num_updates=55500, lr=6.003e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=11632
2023-07-12 16:55:47 | INFO | train_inner | epoch 038:   1085 / 1474 loss=1.577, trans_loss=5.101, nll_loss=2.334, w2v_ctc_loss=0.454, task_loss=1.302, contrastive_loss=0.269, total=4248.59, n_correct=2891.13, ppl=5.04, accuracy=68.049, wps=6706.9, ups=1.58, wpb=4248.6, bsz=164.4, num_updates=55600, lr=5.9976e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=11696
2023-07-12 16:56:51 | INFO | train_inner | epoch 038:   1185 / 1474 loss=1.588, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=0.462, task_loss=1.565, contrastive_loss=0.146, total=4077.59, n_correct=2762.49, ppl=5.11, accuracy=67.748, wps=6340.1, ups=1.55, wpb=4077.6, bsz=143.7, num_updates=55700, lr=5.99222e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=64, gb_free=14.3, wall=11760
2023-07-12 16:57:54 | INFO | train_inner | epoch 038:   1285 / 1474 loss=1.595, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.46, task_loss=1.518, contrastive_loss=0.14, total=4146.3, n_correct=2804.64, ppl=5.14, accuracy=67.642, wps=6556.6, ups=1.58, wpb=4146.3, bsz=147.8, num_updates=55800, lr=5.98684e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=11823
2023-07-12 16:58:57 | INFO | train_inner | epoch 038:   1385 / 1474 loss=1.582, trans_loss=5.114, nll_loss=2.351, w2v_ctc_loss=0.457, task_loss=1.405, contrastive_loss=0.244, total=4156.39, n_correct=2820.35, ppl=5.1, accuracy=67.856, wps=6628.6, ups=1.59, wpb=4156.4, bsz=155.3, num_updates=55900, lr=5.98149e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=62, gb_free=16.6, wall=11886
2023-07-12 16:59:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0184, device='cuda:7')
tensor(0.0022, device='cuda:7')
tensor(0.0184, device='cuda:2')
tensor(0.0022, device='cuda:2')
tensor(0.0184, device='cuda:6')
tensor(0.0022, device='cuda:6')
tensor(0.0184, device='cuda:5')
tensor(0.0022, device='cuda:5')
tensor(0.0184, device='cuda:4')
tensor(0.0022, device='cuda:4')
tensor(0.0184, device='cuda:3')
tensor(0.0022, device='cuda:3')
tensor(0.0184, device='cuda:1')
tensor(0.0022, device='cuda:1')
2023-07-12 17:00:18 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.704 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.229 | task_loss 4.326 | contrastive_loss 0.27 | total 4003.4 | n_correct 2498.3 | ppl 7.12 | accuracy 62.404 | uer 16.683 | wer 18.497 | raw_wer 18.497 | bleu 20.35 | wps 2169.4 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 20.61
2023-07-12 17:00:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-12 17:00:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 17:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 17:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 38 @ 55989 updates, score 20.35) (writing took 4.19366725999862 seconds)
2023-07-12 17:00:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-12 17:00:22 | INFO | train | epoch 038 | loss 1.576 | trans_loss 5.101 | nll_loss 2.332 | w2v_ctc_loss 0.451 | task_loss 1.429 | contrastive_loss 0.229 | total 4137.77 | n_correct 2816.06 | ppl 5.04 | accuracy 68.057 | wps 6294.2 | ups 1.52 | wpb 4137.8 | bsz 152.7 | num_updates 55989 | lr 5.97673e-05 | gnorm 0.423 | clip 0 | loss_scale 64 | train_wall 924 | gb_free 16.8 | wall 11971
2023-07-12 17:00:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 17:00:22 | INFO | fairseq.trainer | begin training epoch 39
2023-07-12 17:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 17:00:37 | INFO | train_inner | epoch 039:     11 / 1474 loss=1.59, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.458, task_loss=1.53, contrastive_loss=0.263, total=4033.2, n_correct=2738.23, ppl=5.08, accuracy=67.892, wps=4012.2, ups=0.99, wpb=4033.2, bsz=142.9, num_updates=56000, lr=5.97614e-05, gnorm=0.43, clip=0, loss_scale=64, train_wall=62, gb_free=17.5, wall=11987
2023-07-12 17:00:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 17:01:02 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.686 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.186 | task_loss 4.371 | contrastive_loss 0.266 | total 4003.4 | n_correct 2496 | ppl 7.12 | accuracy 62.347 | uer 16.564 | wer 18.292 | raw_wer 18.292 | bleu 20.34 | wps 2139.9 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.61
2023-07-12 17:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-12 17:01:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_39_56000.pt
2023-07-12 17:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_39_56000.pt
2023-07-12 17:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.34) (writing took 5.144495630986057 seconds)
2023-07-12 17:02:10 | INFO | train_inner | epoch 039:    111 / 1474 loss=1.571, trans_loss=5.072, nll_loss=2.293, w2v_ctc_loss=0.448, task_loss=1.517, contrastive_loss=0.126, total=4057.77, n_correct=2778.21, ppl=4.9, accuracy=68.466, wps=4389.6, ups=1.08, wpb=4057.8, bsz=143.2, num_updates=56100, lr=5.97081e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=62, gb_free=17.5, wall=12079
2023-07-12 17:03:14 | INFO | train_inner | epoch 039:    211 / 1474 loss=1.578, trans_loss=5.081, nll_loss=2.305, w2v_ctc_loss=0.456, task_loss=1.449, contrastive_loss=0.129, total=4134.99, n_correct=2828.46, ppl=4.94, accuracy=68.403, wps=6423.2, ups=1.55, wpb=4135, bsz=150.2, num_updates=56200, lr=5.9655e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=64, gb_free=15.9, wall=12143
2023-07-12 17:04:17 | INFO | train_inner | epoch 039:    311 / 1474 loss=1.566, trans_loss=5.075, nll_loss=2.298, w2v_ctc_loss=0.445, task_loss=1.453, contrastive_loss=0.136, total=4135.88, n_correct=2833.52, ppl=4.92, accuracy=68.511, wps=6555.1, ups=1.58, wpb=4135.9, bsz=149.8, num_updates=56300, lr=5.9602e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=13.4, wall=12206
2023-07-12 17:05:21 | INFO | train_inner | epoch 039:    411 / 1474 loss=1.575, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=0.449, task_loss=1.415, contrastive_loss=0.439, total=4128.52, n_correct=2816.74, ppl=5.01, accuracy=68.226, wps=6494.6, ups=1.57, wpb=4128.5, bsz=156.1, num_updates=56400, lr=5.95491e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=13, wall=12270
2023-07-12 17:06:25 | INFO | train_inner | epoch 039:    511 / 1474 loss=1.572, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.445, task_loss=1.408, contrastive_loss=0.449, total=4143.39, n_correct=2827.13, ppl=5.01, accuracy=68.232, wps=6497.3, ups=1.57, wpb=4143.4, bsz=155.8, num_updates=56500, lr=5.94964e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=12334
2023-07-12 17:07:28 | INFO | train_inner | epoch 039:    611 / 1474 loss=1.576, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=0.449, task_loss=1.451, contrastive_loss=0.245, total=4131.41, n_correct=2814.9, ppl=5.02, accuracy=68.134, wps=6497.2, ups=1.57, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=12397
2023-07-12 17:08:30 | INFO | train_inner | epoch 039:    711 / 1474 loss=1.574, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.445, task_loss=1.385, contrastive_loss=0.232, total=4133.78, n_correct=2816.74, ppl=5.01, accuracy=68.14, wps=6642.2, ups=1.61, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=62, gb_free=16.2, wall=12460
2023-07-12 17:09:34 | INFO | train_inner | epoch 039:    811 / 1474 loss=1.571, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.455, task_loss=1.431, contrastive_loss=0.157, total=4178.43, n_correct=2845.63, ppl=5.02, accuracy=68.103, wps=6538.8, ups=1.56, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=12524
2023-07-12 17:10:37 | INFO | train_inner | epoch 039:    911 / 1474 loss=1.57, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.449, task_loss=1.475, contrastive_loss=0.164, total=4125.39, n_correct=2807.2, ppl=5.02, accuracy=68.047, wps=6544.7, ups=1.59, wpb=4125.4, bsz=149.5, num_updates=56900, lr=5.92869e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=12587
2023-07-12 17:11:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-12 17:11:42 | INFO | train_inner | epoch 039:   1012 / 1474 loss=1.572, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=0.45, task_loss=1.439, contrastive_loss=0.177, total=4176.11, n_correct=2841.8, ppl=5.04, accuracy=68.049, wps=6502.2, ups=1.56, wpb=4176.1, bsz=155.5, num_updates=57000, lr=5.92349e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=12651
2023-07-12 17:12:45 | INFO | train_inner | epoch 039:   1112 / 1474 loss=1.573, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=0.446, task_loss=1.341, contrastive_loss=0.334, total=4192.7, n_correct=2857.95, ppl=5.01, accuracy=68.165, wps=6663.9, ups=1.59, wpb=4192.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=62, gb_free=12.5, wall=12714
2023-07-12 17:13:47 | INFO | train_inner | epoch 039:   1212 / 1474 loss=1.572, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.447, task_loss=1.419, contrastive_loss=0.227, total=4126.68, n_correct=2805.63, ppl=5.04, accuracy=67.988, wps=6573, ups=1.59, wpb=4126.7, bsz=154.6, num_updates=57200, lr=5.91312e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=12776
2023-07-12 17:14:50 | INFO | train_inner | epoch 039:   1312 / 1474 loss=1.578, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.452, task_loss=1.363, contrastive_loss=0.192, total=4176.04, n_correct=2841.22, ppl=5.04, accuracy=68.036, wps=6644.8, ups=1.59, wpb=4176, bsz=157.7, num_updates=57300, lr=5.90796e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=62, gb_free=17.4, wall=12839
2023-07-12 17:15:53 | INFO | train_inner | epoch 039:   1412 / 1474 loss=1.584, trans_loss=5.105, nll_loss=2.337, w2v_ctc_loss=0.455, task_loss=1.569, contrastive_loss=0.126, total=4055.22, n_correct=2757.54, ppl=5.05, accuracy=68, wps=6437, ups=1.59, wpb=4055.2, bsz=139.2, num_updates=57400, lr=5.90281e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=63, gb_free=15.1, wall=12902
2023-07-12 17:16:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 17:16:56 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.69 | trans_loss 5.556 | nll_loss 2.826 | w2v_ctc_loss 1.186 | task_loss 4.341 | contrastive_loss 0.29 | total 4003.4 | n_correct 2503.3 | ppl 7.09 | accuracy 62.529 | uer 16.426 | wer 18.198 | raw_wer 18.198 | bleu 20.75 | wps 2400.1 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 20.75
2023-07-12 17:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-12 17:16:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-12 17:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt
2023-07-12 17:17:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_best.pt (epoch 39 @ 57462 updates, score 20.75) (writing took 8.299899089965038 seconds)
2023-07-12 17:17:04 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-12 17:17:04 | INFO | train | epoch 039 | loss 1.574 | trans_loss 5.094 | nll_loss 2.324 | w2v_ctc_loss 0.449 | task_loss 1.43 | contrastive_loss 0.224 | total 4137.05 | n_correct 2820.16 | ppl 5.01 | accuracy 68.168 | wps 6079.5 | ups 1.47 | wpb 4137 | bsz 152.6 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.425 | clip 0 | loss_scale 32 | train_wall 925 | gb_free 15.7 | wall 12974
2023-07-12 17:17:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 17:17:05 | INFO | fairseq.trainer | begin training epoch 40
2023-07-12 17:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 17:17:36 | INFO | train_inner | epoch 040:     38 / 1474 loss=1.576, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=0.446, task_loss=1.372, contrastive_loss=0.179, total=4169.65, n_correct=2840.69, ppl=5.02, accuracy=68.128, wps=4042.8, ups=0.97, wpb=4169.6, bsz=156, num_updates=57500, lr=5.89768e-05, gnorm=0.435, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=13005
2023-07-12 17:18:39 | INFO | train_inner | epoch 040:    138 / 1474 loss=1.57, trans_loss=5.063, nll_loss=2.282, w2v_ctc_loss=0.446, task_loss=1.423, contrastive_loss=0.159, total=4150.02, n_correct=2850.79, ppl=4.86, accuracy=68.693, wps=6644.6, ups=1.6, wpb=4150, bsz=152.6, num_updates=57600, lr=5.89256e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=62, gb_free=17.9, wall=13068
2023-07-12 17:19:41 | INFO | train_inner | epoch 040:    238 / 1474 loss=1.561, trans_loss=5.074, nll_loss=2.297, w2v_ctc_loss=0.448, task_loss=1.465, contrastive_loss=0.159, total=4101.15, n_correct=2811.7, ppl=4.91, accuracy=68.559, wps=6593.1, ups=1.61, wpb=4101.1, bsz=149.9, num_updates=57700, lr=5.88745e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=10.8, wall=13130
2023-07-12 17:20:43 | INFO | train_inner | epoch 040:    338 / 1474 loss=1.561, trans_loss=5.075, nll_loss=2.299, w2v_ctc_loss=0.441, task_loss=1.317, contrastive_loss=0.181, total=4161.74, n_correct=2853.62, ppl=4.92, accuracy=68.568, wps=6657.6, ups=1.6, wpb=4161.7, bsz=160.6, num_updates=57800, lr=5.88235e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=13193
2023-07-12 17:21:47 | INFO | train_inner | epoch 040:    438 / 1474 loss=1.574, trans_loss=5.086, nll_loss=2.314, w2v_ctc_loss=0.446, task_loss=1.422, contrastive_loss=0.33, total=4141.51, n_correct=2827.28, ppl=4.97, accuracy=68.267, wps=6555.7, ups=1.58, wpb=4141.5, bsz=155.3, num_updates=57900, lr=5.87727e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=13256
2023-07-12 17:22:50 | INFO | train_inner | epoch 040:    538 / 1474 loss=1.567, trans_loss=5.076, nll_loss=2.3, w2v_ctc_loss=0.436, task_loss=1.384, contrastive_loss=0.378, total=4167.53, n_correct=2854.14, ppl=4.93, accuracy=68.485, wps=6555, ups=1.57, wpb=4167.5, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=13319
2023-07-12 17:22:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 17:23:15 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.719 | trans_loss 5.561 | nll_loss 2.832 | w2v_ctc_loss 1.255 | task_loss 4.35 | contrastive_loss 0.285 | total 4003.4 | n_correct 2502.8 | ppl 7.12 | accuracy 62.517 | uer 16.638 | wer 18.411 | raw_wer 18.411 | bleu 20.35 | wps 2169.2 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.75
2023-07-12 17:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-12 17:23:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_40_58000.pt
2023-07-12 17:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_40_58000.pt
2023-07-12 17:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.35) (writing took 4.967021551041398 seconds)
2023-07-12 17:24:24 | INFO | train_inner | epoch 040:    638 / 1474 loss=1.574, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=0.45, task_loss=1.482, contrastive_loss=0.19, total=4118.6, n_correct=2809.45, ppl=4.98, accuracy=68.214, wps=4415.2, ups=1.07, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=12.7, wall=13413
2023-07-12 17:25:26 | INFO | train_inner | epoch 040:    738 / 1474 loss=1.563, trans_loss=5.079, nll_loss=2.304, w2v_ctc_loss=0.44, task_loss=1.384, contrastive_loss=0.144, total=4137.91, n_correct=2831.8, ppl=4.94, accuracy=68.436, wps=6622.8, ups=1.6, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=16.4, wall=13475
2023-07-12 17:26:29 | INFO | train_inner | epoch 040:    838 / 1474 loss=1.57, trans_loss=5.098, nll_loss=2.33, w2v_ctc_loss=0.44, task_loss=1.298, contrastive_loss=0.569, total=4214.92, n_correct=2870.31, ppl=5.03, accuracy=68.099, wps=6638.8, ups=1.58, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=13539
2023-07-12 17:27:32 | INFO | train_inner | epoch 040:    938 / 1474 loss=1.579, trans_loss=5.098, nll_loss=2.328, w2v_ctc_loss=0.455, task_loss=1.501, contrastive_loss=0.202, total=4092.24, n_correct=2784.03, ppl=5.02, accuracy=68.032, wps=6527.3, ups=1.6, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=62, gb_free=15.2, wall=13601
2023-07-12 17:28:36 | INFO | train_inner | epoch 040:   1038 / 1474 loss=1.593, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.457, task_loss=1.548, contrastive_loss=0.244, total=4119.93, n_correct=2795, ppl=5.09, accuracy=67.841, wps=6507.9, ups=1.58, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=13665
2023-07-12 17:29:39 | INFO | train_inner | epoch 040:   1138 / 1474 loss=1.573, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.447, task_loss=1.487, contrastive_loss=0.172, total=4124.74, n_correct=2809.39, ppl=5.01, accuracy=68.111, wps=6477.1, ups=1.57, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=13728
2023-07-12 17:30:42 | INFO | train_inner | epoch 040:   1238 / 1474 loss=1.574, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=0.444, task_loss=1.407, contrastive_loss=0.296, total=4198.52, n_correct=2864.46, ppl=4.99, accuracy=68.225, wps=6680.2, ups=1.59, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=13791
2023-07-12 17:31:45 | INFO | train_inner | epoch 040:   1338 / 1474 loss=1.577, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=0.444, task_loss=1.438, contrastive_loss=0.311, total=4124.38, n_correct=2810.16, ppl=5.02, accuracy=68.135, wps=6587.1, ups=1.6, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=13854
2023-07-12 17:32:47 | INFO | train_inner | epoch 040:   1438 / 1474 loss=1.582, trans_loss=5.095, nll_loss=2.324, w2v_ctc_loss=0.451, task_loss=1.431, contrastive_loss=0.236, total=4121.8, n_correct=2811.63, ppl=5.01, accuracy=68.214, wps=6561.1, ups=1.59, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=13917
2023-07-12 17:33:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 17:33:35 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.712 | trans_loss 5.565 | nll_loss 2.838 | w2v_ctc_loss 1.223 | task_loss 4.341 | contrastive_loss 0.287 | total 4003.4 | n_correct 2493.6 | ppl 7.15 | accuracy 62.287 | uer 16.728 | wer 18.538 | raw_wer 18.538 | bleu 20.04 | wps 2145.8 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.75
2023-07-12 17:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-12 17:33:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 17:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt
2023-07-12 17:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_last.pt (epoch 40 @ 58936 updates, score 20.04) (writing took 4.160683937021531 seconds)
2023-07-12 17:33:39 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-12 17:33:39 | INFO | train | epoch 040 | loss 1.573 | trans_loss 5.087 | nll_loss 2.315 | w2v_ctc_loss 0.446 | task_loss 1.427 | contrastive_loss 0.252 | total 4138.65 | n_correct 2826.07 | ppl 4.98 | accuracy 68.285 | wps 6134 | ups 1.48 | wpb 4138.6 | bsz 152.8 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.426 | clip 0 | loss_scale 32 | train_wall 921 | gb_free 16 | wall 13968
2023-07-12 17:33:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-12 17:33:39 | INFO | fairseq.trainer | begin training epoch 41
2023-07-12 17:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-12 17:34:28 | INFO | train_inner | epoch 041:     64 / 1474 loss=1.572, trans_loss=5.073, nll_loss=2.297, w2v_ctc_loss=0.441, task_loss=1.476, contrastive_loss=0.174, total=4088.95, n_correct=2803.32, ppl=4.91, accuracy=68.558, wps=4084.7, ups=1, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=14017
2023-07-12 17:35:30 | INFO | train_inner | epoch 041:    164 / 1474 loss=1.559, trans_loss=5.051, nll_loss=2.267, w2v_ctc_loss=0.432, task_loss=1.388, contrastive_loss=0.287, total=4141.51, n_correct=2855.56, ppl=4.81, accuracy=68.95, wps=6585.6, ups=1.59, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=62, gb_free=16, wall=14080
2023-07-12 17:36:33 | INFO | train_inner | epoch 041:    264 / 1474 loss=1.566, trans_loss=5.067, nll_loss=2.289, w2v_ctc_loss=0.435, task_loss=1.328, contrastive_loss=0.27, total=4181.72, n_correct=2869.5, ppl=4.89, accuracy=68.62, wps=6676, ups=1.6, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=62, gb_free=16.5, wall=14142
2023-07-12 17:37:36 | INFO | train_inner | epoch 041:    364 / 1474 loss=1.561, trans_loss=5.069, nll_loss=2.291, w2v_ctc_loss=0.443, task_loss=1.428, contrastive_loss=0.19, total=4147.02, n_correct=2842.76, ppl=4.89, accuracy=68.549, wps=6609.5, ups=1.59, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=62, gb_free=16.7, wall=14205
2023-07-12 17:38:38 | INFO | train_inner | epoch 041:    464 / 1474 loss=1.558, trans_loss=5.065, nll_loss=2.285, w2v_ctc_loss=0.436, task_loss=1.441, contrastive_loss=0.154, total=4144.36, n_correct=2846.96, ppl=4.87, accuracy=68.695, wps=6640.7, ups=1.6, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=62, gb_free=16.1, wall=14267
2023-07-12 17:39:41 | INFO | train_inner | epoch 041:    564 / 1474 loss=1.572, trans_loss=5.075, nll_loss=2.299, w2v_ctc_loss=0.449, task_loss=1.425, contrastive_loss=0.189, total=4145.19, n_correct=2839.32, ppl=4.92, accuracy=68.497, wps=6609.3, ups=1.59, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=14330
2023-07-12 17:40:43 | INFO | train_inner | epoch 041:    664 / 1474 loss=1.564, trans_loss=5.066, nll_loss=2.287, w2v_ctc_loss=0.439, task_loss=1.34, contrastive_loss=0.158, total=4189.74, n_correct=2878.42, ppl=4.88, accuracy=68.702, wps=6724.7, ups=1.61, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=62, gb_free=16.6, wall=14393
2023-07-12 17:41:46 | INFO | train_inner | epoch 041:    764 / 1474 loss=1.568, trans_loss=5.075, nll_loss=2.298, w2v_ctc_loss=0.439, task_loss=1.44, contrastive_loss=0.154, total=4150.75, n_correct=2842.64, ppl=4.92, accuracy=68.485, wps=6638.9, ups=1.6, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=62, gb_free=16.3, wall=14455
2023-07-12 17:42:49 | INFO | train_inner | epoch 041:    864 / 1474 loss=1.575, trans_loss=5.085, nll_loss=2.312, w2v_ctc_loss=0.449, task_loss=1.479, contrastive_loss=0.161, total=4108.1, n_correct=2806.92, ppl=4.97, accuracy=68.326, wps=6548.8, ups=1.59, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.433, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=14518
2023-07-12 17:43:52 | INFO | train_inner | epoch 041:    964 / 1474 loss=1.577, trans_loss=5.089, nll_loss=2.316, w2v_ctc_loss=0.448, task_loss=1.486, contrastive_loss=0.34, total=4122.2, n_correct=2815.63, ppl=4.98, accuracy=68.304, wps=6513, ups=1.58, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=15.2, wall=14581
2023-07-12 17:44:54 | INFO | train_inner | epoch 041:   1064 / 1474 loss=1.57, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=0.445, task_loss=1.423, contrastive_loss=0.169, total=4133.83, n_correct=2820.71, ppl=4.99, accuracy=68.235, wps=6636.6, ups=1.61, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.43, clip=0, loss_scale=64, train_wall=62, gb_free=12.8, wall=14643
2023-07-12 17:44:54 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-12 17:44:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-12 17:45:19 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.715 | trans_loss 5.557 | nll_loss 2.832 | w2v_ctc_loss 1.258 | task_loss 4.371 | contrastive_loss 0.293 | total 4003.4 | n_correct 2500.5 | ppl 7.12 | accuracy 62.459 | uer 16.55 | wer 18.325 | raw_wer 18.325 | bleu 20.48 | wps 2104.3 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.75
2023-07-12 17:45:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-12 17:45:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_41_60000.pt
2023-07-12 17:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_41_60000.pt
2023-07-12 17:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.48) (writing took 6.201385553984437 seconds)
2023-07-12 17:45:26 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-12 17:45:26 | INFO | train | epoch 041 | loss 1.567 | trans_loss 5.072 | nll_loss 2.295 | w2v_ctc_loss 0.442 | task_loss 1.42 | contrastive_loss 0.206 | total 4144.26 | n_correct 2840.74 | ppl 4.91 | accuracy 68.546 | wps 6237.5 | ups 1.51 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.426 | clip 0 | loss_scale 64 | train_wall 662 | gb_free 12.8 | wall 14675
2023-07-12 17:45:26 | INFO | fairseq_cli.train | done training in 14596.3 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 640 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
