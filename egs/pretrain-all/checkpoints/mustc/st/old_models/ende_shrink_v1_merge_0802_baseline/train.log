2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18984
2023-08-03 04:32:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-03 04:32:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-03 04:32:40 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-03 04:32:44 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18984', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-03 04:32:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-03 04:32:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-03 04:32:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-03 04:32:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-08-03 04:32:44 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-03 04:32:49 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-03 04:32:49 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-03 04:32:49 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-03 04:32:50 | INFO | root | load pretrained hubert
2023-08-03 04:32:52 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-03 04:32:53 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-03 04:32:55 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-03 04:32:55 | INFO | root | share the sematic adapter and textual encoder
2023-08-03 04:32:55 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-03 04:32:55 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-03 04:32:55 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-03 04:32:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-03 04:32:55 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-03 04:32:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-03 04:32:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-03 04:32:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-03 04:32:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-03 04:32:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-03 04:33:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-03 04:33:03 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-03 04:33:03 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-03 04:33:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-03 04:33:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-03 04:33:03 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-03 04:33:03 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-03 04:33:03 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 04:33:03 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 04:33:03 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-03 04:33:03 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-03 04:33:03 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-03 04:33:03 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-03 04:33:05 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-03 04:33:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-03 04:33:54 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-03 04:33:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 04:33:54 | INFO | fairseq.trainer | begin training epoch 1
2023-08-03 04:33:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 04:35:10 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.616, trans_loss=5.599, nll_loss=4.164, w2v_ctc_loss=23.048, task_loss=0, contrastive_loss=3.325, total=4207.04, n_correct=209.21, ppl=17.93, accuracy=4.973, wps=20308.5, ups=1.62, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.913, clip=0, loss_scale=128, train_wall=68, gb_free=19.5, wall=127
2023-08-03 04:36:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-03 04:36:12 | INFO | train_inner | epoch 001:    201 / 1474 loss=17.415, trans_loss=5.473, nll_loss=4.059, w2v_ctc_loss=19.847, task_loss=0, contrastive_loss=3.283, total=4121.36, n_correct=224.45, ppl=16.67, accuracy=5.446, wps=19772.4, ups=1.61, wpb=12305.5, bsz=461.4, num_updates=200, lr=8.096e-06, gnorm=3.718, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=189
2023-08-03 04:37:13 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.344, trans_loss=5.503, nll_loss=4.15, w2v_ctc_loss=8.993, task_loss=0, contrastive_loss=3.204, total=4079.62, n_correct=201.41, ppl=17.75, accuracy=4.937, wps=20156.8, ups=1.65, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.711, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=250
2023-08-03 04:38:14 | INFO | train_inner | epoch 001:    401 / 1474 loss=9.07, trans_loss=5.523, nll_loss=4.198, w2v_ctc_loss=6.983, task_loss=0, contrastive_loss=3.236, total=4174.14, n_correct=191.9, ppl=18.36, accuracy=4.597, wps=20452.5, ups=1.64, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.015, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=311
2023-08-03 04:39:14 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.63, trans_loss=5.497, nll_loss=4.18, w2v_ctc_loss=6.334, task_loss=0, contrastive_loss=3.231, total=4176.18, n_correct=185.58, ppl=18.13, accuracy=4.444, wps=20613.3, ups=1.65, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.448, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=371
2023-08-03 04:40:16 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.377, trans_loss=5.524, nll_loss=4.215, w2v_ctc_loss=5.959, task_loss=0, contrastive_loss=3.287, total=4147.79, n_correct=182.76, ppl=18.57, accuracy=4.406, wps=20009.6, ups=1.62, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.752, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=433
2023-08-03 04:41:17 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.202, trans_loss=5.521, nll_loss=4.216, w2v_ctc_loss=5.831, task_loss=0, contrastive_loss=3.037, total=4152.1, n_correct=196.69, ppl=18.59, accuracy=4.737, wps=20426.9, ups=1.65, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=494
2023-08-03 04:42:18 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.926, trans_loss=5.461, nll_loss=4.153, w2v_ctc_loss=5.602, task_loss=0, contrastive_loss=2.946, total=4123.83, n_correct=239.28, ppl=17.79, accuracy=5.802, wps=20292.4, ups=1.65, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.814, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=554
2023-08-03 04:43:18 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.65, trans_loss=5.424, nll_loss=4.118, w2v_ctc_loss=5.407, task_loss=0, contrastive_loss=2.705, total=4163.61, n_correct=265.15, ppl=17.37, accuracy=6.368, wps=20525, ups=1.65, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.328, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=615
2023-08-03 04:44:19 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.385, trans_loss=5.406, nll_loss=4.106, w2v_ctc_loss=5.19, task_loss=0, contrastive_loss=2.551, total=4135.34, n_correct=286.01, ppl=17.23, accuracy=6.916, wps=20243.3, ups=1.64, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.459, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=676
2023-08-03 04:45:20 | INFO | train_inner | epoch 001:   1101 / 1474 loss=7.108, trans_loss=5.396, nll_loss=4.097, w2v_ctc_loss=4.986, task_loss=0, contrastive_loss=2.329, total=4147.38, n_correct=310.24, ppl=17.11, accuracy=7.48, wps=20213, ups=1.63, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.702, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=737
2023-08-03 04:46:21 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.871, trans_loss=5.371, nll_loss=4.073, w2v_ctc_loss=4.812, task_loss=0, contrastive_loss=2.118, total=4139.9, n_correct=316.24, ppl=16.84, accuracy=7.639, wps=20425.5, ups=1.65, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.751, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=798
2023-08-03 04:47:21 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.655, trans_loss=5.371, nll_loss=4.075, w2v_ctc_loss=4.614, task_loss=0, contrastive_loss=1.939, total=4046.58, n_correct=321.21, ppl=16.86, accuracy=7.938, wps=19994.2, ups=1.65, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.84, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=858
2023-08-03 04:48:22 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.453, trans_loss=5.365, nll_loss=4.071, w2v_ctc_loss=4.413, task_loss=0, contrastive_loss=2.009, total=4133.18, n_correct=330.27, ppl=16.81, accuracy=7.991, wps=20478.8, ups=1.66, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.749, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=918
2023-08-03 04:49:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 04:49:44 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.961 | trans_loss 11.006 | nll_loss 10.009 | w2v_ctc_loss 5.794 | task_loss 0 | contrastive_loss 2.356 | total 4003.4 | n_correct 358.1 | ppl 1030.63 | accuracy 8.945 | uer 71.717 | wer 69.643 | raw_wer 69.643 | bleu 0.02 | wps 1177.9 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-03 04:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-03 04:49:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 04:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 04:49:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 5.732615176588297 seconds)
2023-08-03 04:49:50 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-03 04:49:50 | INFO | train | epoch 001 | loss 9.264 | trans_loss 5.455 | nll_loss 4.13 | w2v_ctc_loss 7.831 | task_loss 0 | contrastive_loss 2.76 | total 4138.36 | n_correct 251.395 | ppl 17.51 | accuracy 6.075 | wps 19324.2 | ups 1.56 | wpb 12355 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.833 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 19.2 | wall 1007
2023-08-03 04:49:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 04:49:51 | INFO | fairseq.trainer | begin training epoch 2
2023-08-03 04:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 04:50:15 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.266, trans_loss=5.356, nll_loss=4.055, w2v_ctc_loss=4.221, task_loss=0, contrastive_loss=1.857, total=4162.95, n_correct=334.92, ppl=16.62, accuracy=8.045, wps=10934.5, ups=0.88, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.698, clip=0, loss_scale=64, train_wall=61, gb_free=19.7, wall=1032
2023-08-03 04:51:16 | INFO | train_inner | epoch 002:    127 / 1474 loss=6.089, trans_loss=5.349, nll_loss=4.046, w2v_ctc_loss=4.098, task_loss=0, contrastive_loss=1.649, total=4155.98, n_correct=337.19, ppl=16.52, accuracy=8.113, wps=20523.9, ups=1.66, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.677, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1092
2023-08-03 04:52:16 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.93, trans_loss=5.327, nll_loss=4.023, w2v_ctc_loss=3.902, task_loss=0, contrastive_loss=1.679, total=4179.21, n_correct=347.95, ppl=16.25, accuracy=8.326, wps=20759.1, ups=1.66, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.489, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1152
2023-08-03 04:53:16 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.757, trans_loss=5.329, nll_loss=4.022, w2v_ctc_loss=3.8, task_loss=0, contrastive_loss=1.391, total=4146.1, n_correct=349.85, ppl=16.24, accuracy=8.438, wps=20469.2, ups=1.65, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.464, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1213
2023-08-03 04:54:17 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.606, trans_loss=5.321, nll_loss=4.016, w2v_ctc_loss=3.698, task_loss=0, contrastive_loss=1.208, total=4037.99, n_correct=342.66, ppl=16.18, accuracy=8.486, wps=19843.9, ups=1.64, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.434, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1274
2023-08-03 04:55:18 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.504, trans_loss=5.306, nll_loss=3.994, w2v_ctc_loss=3.54, task_loss=0, contrastive_loss=1.308, total=4176.97, n_correct=363.74, ppl=15.93, accuracy=8.708, wps=20588.5, ups=1.65, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.352, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1334
2023-08-03 04:55:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 04:55:57 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.296 | trans_loss 10.791 | nll_loss 9.732 | w2v_ctc_loss 4.674 | task_loss 0 | contrastive_loss 1.654 | total 4003.4 | n_correct 406.2 | ppl 850.21 | accuracy 10.146 | uer 61.296 | wer 59.159 | raw_wer 59.159 | bleu 0.05 | wps 1185.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-08-03 04:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-03 04:55:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_2_2000.pt
2023-08-03 04:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_2_2000.pt
2023-08-03 04:56:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 25.23467606306076 seconds)
2023-08-03 04:57:22 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.362, trans_loss=5.293, nll_loss=3.977, w2v_ctc_loss=3.431, task_loss=0, contrastive_loss=1.111, total=4126.49, n_correct=369.01, ppl=15.75, accuracy=8.942, wps=9900.4, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.199, clip=0, loss_scale=64, train_wall=59, gb_free=19.2, wall=1459
2023-08-03 04:58:22 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.294, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.347, task_loss=0, contrastive_loss=1.21, total=4149.06, n_correct=373.64, ppl=15.64, accuracy=9.005, wps=20618.2, ups=1.66, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.144, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1519
2023-08-03 04:59:23 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.205, trans_loss=5.271, nll_loss=3.955, w2v_ctc_loss=3.275, task_loss=0, contrastive_loss=1.159, total=4175.4, n_correct=383.99, ppl=15.5, accuracy=9.196, wps=20422.2, ups=1.64, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.065, clip=0, loss_scale=128, train_wall=61, gb_free=19.8, wall=1580
2023-08-03 05:00:24 | INFO | train_inner | epoch 002:    927 / 1474 loss=5.106, trans_loss=5.254, nll_loss=3.932, w2v_ctc_loss=3.178, task_loss=0, contrastive_loss=1.142, total=4104.2, n_correct=383.31, ppl=15.27, accuracy=9.339, wps=20137.6, ups=1.64, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.063, clip=0, loss_scale=128, train_wall=60, gb_free=19, wall=1641
2023-08-03 05:01:24 | INFO | train_inner | epoch 002:   1027 / 1474 loss=5.022, trans_loss=5.248, nll_loss=3.927, w2v_ctc_loss=3.106, task_loss=0, contrastive_loss=0.995, total=4102.5, n_correct=386.51, ppl=15.21, accuracy=9.421, wps=20288.9, ups=1.66, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.915, clip=0, loss_scale=128, train_wall=60, gb_free=19.3, wall=1701
2023-08-03 05:02:25 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.985, trans_loss=5.242, nll_loss=3.918, w2v_ctc_loss=3.019, task_loss=0, contrastive_loss=1.208, total=4187.61, n_correct=399.48, ppl=15.12, accuracy=9.54, wps=20667.3, ups=1.65, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.929, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1762
2023-08-03 05:03:26 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.921, trans_loss=5.227, nll_loss=3.9, w2v_ctc_loss=2.972, task_loss=0, contrastive_loss=1.128, total=4221.06, n_correct=418.47, ppl=14.93, accuracy=9.914, wps=20650.1, ups=1.64, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.838, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1823
2023-08-03 05:04:26 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.82, trans_loss=5.216, nll_loss=3.891, w2v_ctc_loss=2.934, task_loss=0, contrastive_loss=0.838, total=4157.86, n_correct=412.37, ppl=14.83, accuracy=9.918, wps=20583.1, ups=1.66, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.796, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1883
2023-08-03 05:05:27 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.78, trans_loss=5.223, nll_loss=3.899, w2v_ctc_loss=2.891, task_loss=0, contrastive_loss=0.925, total=4054.34, n_correct=400.96, ppl=14.92, accuracy=9.89, wps=19948, ups=1.65, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.76, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1944
2023-08-03 05:05:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 05:06:34 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.527 | trans_loss 10.313 | nll_loss 9.143 | w2v_ctc_loss 3.741 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 492.7 | ppl 565.24 | accuracy 12.307 | uer 52.056 | wer 50.628 | raw_wer 50.628 | bleu 0.13 | wps 1207.9 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-08-03 05:06:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-08-03 05:06:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:06:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 24.07229549996555 seconds)
2023-08-03 05:06:58 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-03 05:06:58 | INFO | train | epoch 002 | loss 5.312 | trans_loss 5.277 | nll_loss 3.961 | w2v_ctc_loss 3.369 | task_loss 0 | contrastive_loss 1.213 | total 4138.65 | n_correct 376.738 | ppl 15.57 | accuracy 9.103 | wps 17723.7 | ups 1.43 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.149 | clip 0 | loss_scale 128 | train_wall 885 | gb_free 19.3 | wall 2034
2023-08-03 05:06:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 05:06:58 | INFO | fairseq.trainer | begin training epoch 3
2023-08-03 05:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 05:07:38 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.705, trans_loss=5.195, nll_loss=3.864, w2v_ctc_loss=2.827, task_loss=0, contrastive_loss=0.828, total=4071.2, n_correct=420.83, ppl=14.56, accuracy=10.337, wps=9245.4, ups=0.76, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.75, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2075
2023-08-03 05:07:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-03 05:07:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 05:07:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 05:07:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-03 05:07:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-03 05:08:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-03 05:09:01 | INFO | train_inner | epoch 003:    159 / 1474 loss=3.909, trans_loss=4.362, nll_loss=2.774, w2v_ctc_loss=2.514, task_loss=0, contrastive_loss=0.778, total=4154.66, n_correct=1159.27, ppl=6.84, accuracy=27.903, wps=15024.2, ups=1.21, wpb=12403.7, bsz=462.5, num_updates=3100, lr=0.000124038, gnorm=2.302, clip=1, loss_scale=2, train_wall=82, gb_free=16.7, wall=2158
2023-08-03 05:10:21 | INFO | train_inner | epoch 003:    259 / 1474 loss=3.509, trans_loss=4.143, nll_loss=2.489, w2v_ctc_loss=2.282, task_loss=0, contrastive_loss=0.647, total=4155.72, n_correct=1415.93, ppl=5.61, accuracy=34.072, wps=15599.5, ups=1.26, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=1.713, clip=1, loss_scale=2, train_wall=79, gb_free=17.8, wall=2237
2023-08-03 05:11:40 | INFO | train_inner | epoch 003:    359 / 1474 loss=3.392, trans_loss=4.095, nll_loss=2.422, w2v_ctc_loss=2.184, task_loss=0, contrastive_loss=0.678, total=4154.07, n_correct=1493.33, ppl=5.36, accuracy=35.949, wps=15690.2, ups=1.27, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.584, clip=0, loss_scale=2, train_wall=78, gb_free=15.9, wall=2316
2023-08-03 05:12:59 | INFO | train_inner | epoch 003:    459 / 1474 loss=3.273, trans_loss=4.049, nll_loss=2.362, w2v_ctc_loss=2.102, task_loss=0, contrastive_loss=0.528, total=4212.17, n_correct=1591.31, ppl=5.14, accuracy=37.779, wps=15924.9, ups=1.27, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.517, clip=0, loss_scale=2, train_wall=78, gb_free=16, wall=2395
2023-08-03 05:14:17 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.193, trans_loss=4.028, nll_loss=2.337, w2v_ctc_loss=2.042, task_loss=0, contrastive_loss=0.509, total=4081.04, n_correct=1571.78, ppl=5.05, accuracy=38.514, wps=15529.5, ups=1.27, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.499, clip=0, loss_scale=2, train_wall=78, gb_free=16.7, wall=2474
2023-08-03 05:15:38 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.126, trans_loss=3.988, nll_loss=2.28, w2v_ctc_loss=1.962, task_loss=0, contrastive_loss=0.612, total=4231.09, n_correct=1696.67, ppl=4.86, accuracy=40.1, wps=15641.4, ups=1.24, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.241, clip=0, loss_scale=2, train_wall=80, gb_free=16.2, wall=2554
2023-08-03 05:16:56 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.043, trans_loss=3.96, nll_loss=2.247, w2v_ctc_loss=1.926, task_loss=0, contrastive_loss=0.373, total=4160.74, n_correct=1706.98, ppl=4.75, accuracy=41.026, wps=15860.7, ups=1.28, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.25, clip=0, loss_scale=2, train_wall=78, gb_free=17, wall=2633
2023-08-03 05:18:14 | INFO | train_inner | epoch 003:    859 / 1474 loss=2.995, trans_loss=3.948, nll_loss=2.23, w2v_ctc_loss=1.887, task_loss=0, contrastive_loss=0.344, total=4160.47, n_correct=1733.73, ppl=4.69, accuracy=41.671, wps=15839.9, ups=1.27, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.257, clip=0, loss_scale=2, train_wall=78, gb_free=16.6, wall=2711
2023-08-03 05:19:33 | INFO | train_inner | epoch 003:    959 / 1474 loss=2.972, trans_loss=3.93, nll_loss=2.205, w2v_ctc_loss=1.866, task_loss=0, contrastive_loss=0.377, total=4162.26, n_correct=1775.64, ppl=4.61, accuracy=42.66, wps=15726.8, ups=1.27, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.322, clip=0, loss_scale=2, train_wall=78, gb_free=17.9, wall=2790
2023-08-03 05:20:52 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.934, trans_loss=3.912, nll_loss=2.184, w2v_ctc_loss=1.851, task_loss=0, contrastive_loss=0.328, total=4062.67, n_correct=1750.81, ppl=4.54, accuracy=43.095, wps=15448.4, ups=1.27, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.255, clip=1, loss_scale=2, train_wall=78, gb_free=15.9, wall=2869
2023-08-03 05:20:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 05:21:19 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.278 | trans_loss 6.486 | nll_loss 4.063 | w2v_ctc_loss 2.221 | task_loss 0 | contrastive_loss 0.442 | total 4003.4 | n_correct 1929 | ppl 16.71 | accuracy 48.184 | uer 31.049 | wer 31.498 | raw_wer 31.498 | bleu 10.52 | wps 1633.2 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.52
2023-08-03 05:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-03 05:21:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_3_4000.pt
2023-08-03 05:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_3_4000.pt
2023-08-03 05:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.52) (writing took 48.11714785173535 seconds)
2023-08-03 05:23:25 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.881, trans_loss=3.902, nll_loss=2.168, w2v_ctc_loss=1.798, task_loss=0, contrastive_loss=0.307, total=4046.76, n_correct=1768.51, ppl=4.5, accuracy=43.702, wps=7884.8, ups=0.65, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.208, clip=0, loss_scale=2, train_wall=78, gb_free=16.5, wall=3022
2023-08-03 05:24:43 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.848, trans_loss=3.883, nll_loss=2.145, w2v_ctc_loss=1.777, task_loss=0, contrastive_loss=0.289, total=4064.26, n_correct=1803.18, ppl=4.42, accuracy=44.367, wps=15637.1, ups=1.29, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.181, clip=0, loss_scale=2, train_wall=77, gb_free=16.9, wall=3099
2023-08-03 05:26:02 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.84, trans_loss=3.869, nll_loss=2.128, w2v_ctc_loss=1.742, task_loss=0, contrastive_loss=0.406, total=4137.36, n_correct=1857.37, ppl=4.37, accuracy=44.893, wps=15581.8, ups=1.26, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.246, clip=0, loss_scale=2, train_wall=79, gb_free=16.5, wall=3179
2023-08-03 05:27:21 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.808, trans_loss=3.856, nll_loss=2.112, w2v_ctc_loss=1.721, task_loss=0, contrastive_loss=0.38, total=4207.75, n_correct=1916.05, ppl=4.32, accuracy=45.536, wps=15855.8, ups=1.26, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.165, clip=1, loss_scale=2, train_wall=79, gb_free=17.5, wall=3258
2023-08-03 05:27:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 05:27:54 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.141 | trans_loss 6.365 | nll_loss 3.895 | w2v_ctc_loss 2.063 | task_loss 0 | contrastive_loss 0.426 | total 4003.4 | n_correct 2008.9 | ppl 14.88 | accuracy 50.18 | uer 30.351 | wer 30.704 | raw_wer 30.704 | bleu 12 | wps 2426.2 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 12
2023-08-03 05:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-03 05:27:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:28:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 3 @ 4415 updates, score 12.0) (writing took 24.09549232572317 seconds)
2023-08-03 05:28:19 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-03 05:28:19 | INFO | train | epoch 003 | loss 3.178 | trans_loss 4.037 | nll_loss 2.347 | w2v_ctc_loss 2.004 | task_loss 0 | contrastive_loss 0.485 | total 4140.27 | n_correct 1617.03 | ppl 5.09 | accuracy 39.056 | wps 14167.6 | ups 1.15 | wpb 12360.6 | bsz 459.1 | num_updates 4415 | lr 0.000176612 | gnorm 1.382 | clip 0.3 | loss_scale 2 | train_wall 1144 | gb_free 16.6 | wall 3315
2023-08-03 05:28:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 05:28:19 | INFO | fairseq.trainer | begin training epoch 4
2023-08-03 05:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 05:29:33 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.727, trans_loss=3.825, nll_loss=2.067, w2v_ctc_loss=1.675, task_loss=0, contrastive_loss=0.231, total=4095.18, n_correct=1896.56, ppl=4.19, accuracy=46.312, wps=9308.6, ups=0.76, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.042, clip=0, loss_scale=2, train_wall=77, gb_free=13, wall=3389
2023-08-03 05:30:50 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.7, trans_loss=3.801, nll_loss=2.038, w2v_ctc_loss=1.643, task_loss=0, contrastive_loss=0.258, total=4178.83, n_correct=1972.69, ppl=4.11, accuracy=47.207, wps=16047, ups=1.29, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.986, clip=0, loss_scale=2, train_wall=77, gb_free=14.9, wall=3467
2023-08-03 05:32:10 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.715, trans_loss=3.803, nll_loss=2.042, w2v_ctc_loss=1.644, task_loss=0, contrastive_loss=0.385, total=4142.3, n_correct=1953.26, ppl=4.12, accuracy=47.154, wps=15618.3, ups=1.26, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.014, clip=0, loss_scale=2, train_wall=79, gb_free=13.6, wall=3546
2023-08-03 05:33:28 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.663, trans_loss=3.802, nll_loss=2.037, w2v_ctc_loss=1.613, task_loss=0, contrastive_loss=0.223, total=4124.92, n_correct=1958.45, ppl=4.1, accuracy=47.478, wps=15643.3, ups=1.27, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.952, clip=0, loss_scale=2, train_wall=78, gb_free=12.8, wall=3625
2023-08-03 05:34:48 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.69, trans_loss=3.78, nll_loss=2.012, w2v_ctc_loss=1.575, task_loss=0, contrastive_loss=0.616, total=4216.09, n_correct=2036.07, ppl=4.03, accuracy=48.293, wps=15794, ups=1.25, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=0.913, clip=0, loss_scale=2, train_wall=79, gb_free=17, wall=3705
2023-08-03 05:36:07 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.645, trans_loss=3.774, nll_loss=2.005, w2v_ctc_loss=1.588, task_loss=0, contrastive_loss=0.298, total=4231.12, n_correct=2061.83, ppl=4.01, accuracy=48.73, wps=15989.4, ups=1.27, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.907, clip=0, loss_scale=2, train_wall=79, gb_free=16.3, wall=3784
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:0')
2023-08-03 05:37:27 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.614, trans_loss=3.778, nll_loss=2.004, w2v_ctc_loss=1.553, task_loss=0, contrastive_loss=0.341, total=4176.95, n_correct=2037.89, ppl=4.01, accuracy=48.789, wps=15551.2, ups=1.25, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.607, clip=0, loss_scale=4, train_wall=80, gb_free=15.3, wall=3864
2023-08-03 05:38:46 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.592, trans_loss=3.767, nll_loss=1.995, w2v_ctc_loss=1.561, task_loss=0, contrastive_loss=0.209, total=4016.91, n_correct=1973.24, ppl=3.99, accuracy=49.123, wps=15162.8, ups=1.26, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.602, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=3943
2023-08-03 05:40:06 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.611, trans_loss=3.752, nll_loss=1.976, w2v_ctc_loss=1.554, task_loss=0, contrastive_loss=0.391, total=4183.4, n_correct=2070.92, ppl=3.94, accuracy=49.503, wps=15727.8, ups=1.26, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.594, clip=0, loss_scale=4, train_wall=79, gb_free=15.7, wall=4022
2023-08-03 05:41:25 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.565, trans_loss=3.741, nll_loss=1.964, w2v_ctc_loss=1.531, task_loss=0, contrastive_loss=0.256, total=4128.78, n_correct=2067.78, ppl=3.9, accuracy=50.082, wps=15616.4, ups=1.27, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.593, clip=0, loss_scale=4, train_wall=78, gb_free=16.2, wall=4101
2023-08-03 05:42:44 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.568, trans_loss=3.751, nll_loss=1.975, w2v_ctc_loss=1.54, task_loss=0, contrastive_loss=0.233, total=4080.2, n_correct=2038.69, ppl=3.93, accuracy=49.965, wps=15416.5, ups=1.27, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.597, clip=0, loss_scale=4, train_wall=78, gb_free=16.4, wall=4180
2023-08-03 05:44:02 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.571, trans_loss=3.735, nll_loss=1.958, w2v_ctc_loss=1.523, task_loss=0, contrastive_loss=0.346, total=4163.45, n_correct=2098.78, ppl=3.88, accuracy=50.41, wps=15846.3, ups=1.27, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.585, clip=0, loss_scale=4, train_wall=78, gb_free=15.4, wall=4259
2023-08-03 05:45:20 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.545, trans_loss=3.727, nll_loss=1.946, w2v_ctc_loss=1.509, task_loss=0, contrastive_loss=0.305, total=4152.41, n_correct=2109.1, ppl=3.85, accuracy=50.792, wps=15829.8, ups=1.28, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.597, clip=0, loss_scale=4, train_wall=78, gb_free=13.2, wall=4337
2023-08-03 05:46:38 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.511, trans_loss=3.725, nll_loss=1.943, w2v_ctc_loss=1.499, task_loss=0, contrastive_loss=0.181, total=4103.57, n_correct=2089.9, ppl=3.85, accuracy=50.929, wps=15820.6, ups=1.29, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.562, clip=0, loss_scale=4, train_wall=77, gb_free=16.9, wall=4415
2023-08-03 05:47:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.4562, device='cuda:3')
2023-08-03 05:48:11 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.752 | trans_loss 5.993 | nll_loss 3.397 | w2v_ctc_loss 1.694 | task_loss 0 | contrastive_loss 0.326 | total 4003.4 | n_correct 2210.4 | ppl 10.53 | accuracy 55.213 | uer 25.084 | wer 26.729 | raw_wer 26.729 | bleu 15.96 | wps 2209 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 15.96
2023-08-03 05:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-03 05:48:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:48:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 05:48:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 4 @ 5889 updates, score 15.96) (writing took 23.31226614676416 seconds)
2023-08-03 05:48:34 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-03 05:48:34 | INFO | train | epoch 004 | loss 2.614 | trans_loss 3.765 | nll_loss 1.993 | w2v_ctc_loss 1.565 | task_loss 0 | contrastive_loss 0.304 | total 4138.65 | n_correct 2031.15 | ppl 3.98 | accuracy 49.078 | wps 14981.1 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.739 | clip 0 | loss_scale 4 | train_wall 1154 | gb_free 15.1 | wall 4531
2023-08-03 05:48:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 05:48:35 | INFO | fairseq.trainer | begin training epoch 5
2023-08-03 05:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 05:48:51 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.49, trans_loss=3.713, nll_loss=1.927, w2v_ctc_loss=1.47, task_loss=0, contrastive_loss=0.201, total=4031.51, n_correct=2068.7, ppl=3.8, accuracy=51.313, wps=9070.7, ups=0.75, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.562, clip=0, loss_scale=4, train_wall=78, gb_free=14.5, wall=4547
2023-08-03 05:50:10 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.427, trans_loss=3.657, nll_loss=1.855, w2v_ctc_loss=1.398, task_loss=0, contrastive_loss=0.227, total=4256.63, n_correct=2255.65, ppl=3.62, accuracy=52.991, wps=16093.1, ups=1.27, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.54, clip=0, loss_scale=4, train_wall=78, gb_free=16.4, wall=4626
2023-08-03 05:50:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 05:50:34 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.75 | trans_loss 5.99 | nll_loss 3.387 | w2v_ctc_loss 1.689 | task_loss 0 | contrastive_loss 0.335 | total 4003.4 | n_correct 2215.9 | ppl 10.46 | accuracy 55.35 | uer 24.776 | wer 26.42 | raw_wer 26.42 | bleu 15.86 | wps 2073.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.96
2023-08-03 05:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-03 05:50:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_5_6000.pt
2023-08-03 05:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_5_6000.pt
2023-08-03 05:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.86) (writing took 22.820201199501753 seconds)
2023-08-03 05:52:14 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.459, trans_loss=3.668, nll_loss=1.866, w2v_ctc_loss=1.411, task_loss=0, contrastive_loss=0.424, total=4186.83, n_correct=2210.48, ppl=3.65, accuracy=52.796, wps=10050.3, ups=0.8, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.546, clip=0, loss_scale=4, train_wall=77, gb_free=16.2, wall=4751
2023-08-03 05:53:32 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.442, trans_loss=3.661, nll_loss=1.862, w2v_ctc_loss=1.426, task_loss=0, contrastive_loss=0.279, total=4094.07, n_correct=2158.41, ppl=3.64, accuracy=52.72, wps=15729.8, ups=1.28, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.557, clip=0, loss_scale=4, train_wall=77, gb_free=16.4, wall=4828
2023-08-03 05:54:50 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.437, trans_loss=3.656, nll_loss=1.856, w2v_ctc_loss=1.394, task_loss=0, contrastive_loss=0.362, total=4140.39, n_correct=2198.02, ppl=3.62, accuracy=53.087, wps=15738.8, ups=1.27, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.549, clip=0, loss_scale=4, train_wall=78, gb_free=16.3, wall=4907
2023-08-03 05:56:09 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.394, trans_loss=3.662, nll_loss=1.862, w2v_ctc_loss=1.393, task_loss=0, contrastive_loss=0.15, total=4026.21, n_correct=2130.74, ppl=3.64, accuracy=52.922, wps=15364.5, ups=1.28, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.542, clip=0, loss_scale=4, train_wall=78, gb_free=17.2, wall=4985
2023-08-03 05:57:27 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.419, trans_loss=3.67, nll_loss=1.869, w2v_ctc_loss=1.385, task_loss=0, contrastive_loss=0.325, total=4109.94, n_correct=2177, ppl=3.65, accuracy=52.969, wps=15569.3, ups=1.27, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.545, clip=0, loss_scale=4, train_wall=78, gb_free=15.6, wall=5064
2023-08-03 05:58:46 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.42, trans_loss=3.661, nll_loss=1.86, w2v_ctc_loss=1.385, task_loss=0, contrastive_loss=0.308, total=4176.83, n_correct=2223.71, ppl=3.63, accuracy=53.239, wps=15904.5, ups=1.28, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.544, clip=0, loss_scale=4, train_wall=78, gb_free=17.2, wall=5142
2023-08-03 06:00:05 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.401, trans_loss=3.663, nll_loss=1.862, w2v_ctc_loss=1.382, task_loss=0, contrastive_loss=0.23, total=4127.9, n_correct=2198.71, ppl=3.63, accuracy=53.265, wps=15642.4, ups=1.27, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.547, clip=0, loss_scale=4, train_wall=78, gb_free=16, wall=5221
2023-08-03 06:01:23 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.373, trans_loss=3.652, nll_loss=1.849, w2v_ctc_loss=1.363, task_loss=0, contrastive_loss=0.191, total=4101.19, n_correct=2199.68, ppl=3.6, accuracy=53.635, wps=15583.9, ups=1.27, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.529, clip=0, loss_scale=4, train_wall=78, gb_free=17.4, wall=5300
2023-08-03 06:02:41 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.386, trans_loss=3.653, nll_loss=1.851, w2v_ctc_loss=1.367, task_loss=0, contrastive_loss=0.271, total=4164.27, n_correct=2233.11, ppl=3.61, accuracy=53.625, wps=15947.3, ups=1.28, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.527, clip=0, loss_scale=4, train_wall=77, gb_free=15.2, wall=5378
2023-08-03 06:04:00 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.399, trans_loss=3.654, nll_loss=1.851, w2v_ctc_loss=1.376, task_loss=0, contrastive_loss=0.275, total=4168.94, n_correct=2242.39, ppl=3.61, accuracy=53.788, wps=15654.7, ups=1.26, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.535, clip=0, loss_scale=4, train_wall=79, gb_free=16.8, wall=5457
2023-08-03 06:05:20 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.361, trans_loss=3.649, nll_loss=1.845, w2v_ctc_loss=1.352, task_loss=0, contrastive_loss=0.179, total=4171.16, n_correct=2252.16, ppl=3.59, accuracy=53.994, wps=15722.7, ups=1.26, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.528, clip=0, loss_scale=4, train_wall=79, gb_free=16.1, wall=5536
2023-08-03 06:06:38 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.341, trans_loss=3.647, nll_loss=1.843, w2v_ctc_loss=1.336, task_loss=0, contrastive_loss=0.143, total=4126.97, n_correct=2231.72, ppl=3.59, accuracy=54.076, wps=15652.3, ups=1.27, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.518, clip=0, loss_scale=8, train_wall=78, gb_free=15.7, wall=5615
2023-08-03 06:07:57 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.354, trans_loss=3.647, nll_loss=1.846, w2v_ctc_loss=1.335, task_loss=0, contrastive_loss=0.211, total=4138.54, n_correct=2237.88, ppl=3.59, accuracy=54.074, wps=15810.3, ups=1.28, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.536, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=5693
2023-08-03 06:08:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 06:09:09 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.595 | trans_loss 5.854 | nll_loss 3.218 | w2v_ctc_loss 1.502 | task_loss 0 | contrastive_loss 0.317 | total 4003.4 | n_correct 2296.2 | ppl 9.3 | accuracy 57.356 | uer 22.156 | wer 23.661 | raw_wer 23.661 | bleu 16.95 | wps 2250.8 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 16.95
2023-08-03 06:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-03 06:09:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 5 @ 7363 updates, score 16.95) (writing took 25.3648043833673 seconds)
2023-08-03 06:09:34 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-03 06:09:34 | INFO | train | epoch 005 | loss 2.4 | trans_loss 3.656 | nll_loss 1.855 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.256 | total 4138.65 | n_correct 2210.03 | ppl 3.62 | accuracy 53.4 | wps 14457.3 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.539 | clip 0 | loss_scale 8 | train_wall 1150 | gb_free 16.5 | wall 5791
2023-08-03 06:09:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 06:09:34 | INFO | fairseq.trainer | begin training epoch 6
2023-08-03 06:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 06:10:12 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.338, trans_loss=3.622, nll_loss=1.811, w2v_ctc_loss=1.33, task_loss=0, contrastive_loss=0.207, total=4113.87, n_correct=2250.66, ppl=3.51, accuracy=54.709, wps=9088, ups=0.74, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.546, clip=0, loss_scale=8, train_wall=78, gb_free=18, wall=5828
2023-08-03 06:11:30 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.29, trans_loss=3.589, nll_loss=1.768, w2v_ctc_loss=1.275, task_loss=0, contrastive_loss=0.247, total=4161.2, n_correct=2308.28, ppl=3.41, accuracy=55.471, wps=15792.7, ups=1.27, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.515, clip=0, loss_scale=8, train_wall=78, gb_free=17.1, wall=5907
2023-08-03 06:12:49 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.303, trans_loss=3.602, nll_loss=1.786, w2v_ctc_loss=1.311, task_loss=0, contrastive_loss=0.156, total=4110.12, n_correct=2263.78, ppl=3.45, accuracy=55.078, wps=15584.6, ups=1.27, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.531, clip=0, loss_scale=8, train_wall=78, gb_free=17.3, wall=5986
2023-08-03 06:14:09 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.319, trans_loss=3.59, nll_loss=1.771, w2v_ctc_loss=1.262, task_loss=0, contrastive_loss=0.466, total=4170.52, n_correct=2316.22, ppl=3.41, accuracy=55.538, wps=15557.4, ups=1.25, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.538, clip=0, loss_scale=8, train_wall=80, gb_free=15.9, wall=6066
2023-08-03 06:15:27 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.273, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.266, task_loss=0, contrastive_loss=0.175, total=4154.89, n_correct=2315.17, ppl=3.42, accuracy=55.722, wps=15845.4, ups=1.28, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=16.6, wall=6144
2023-08-03 06:16:46 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.277, trans_loss=3.597, nll_loss=1.779, w2v_ctc_loss=1.277, task_loss=0, contrastive_loss=0.16, total=4174.46, n_correct=2325.66, ppl=3.43, accuracy=55.712, wps=15894.4, ups=1.28, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.514, clip=0, loss_scale=8, train_wall=78, gb_free=17.3, wall=6223
2023-08-03 06:18:04 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.277, trans_loss=3.598, nll_loss=1.781, w2v_ctc_loss=1.26, task_loss=0, contrastive_loss=0.219, total=4145.19, n_correct=2309.33, ppl=3.44, accuracy=55.711, wps=15830, ups=1.28, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.52, clip=0, loss_scale=8, train_wall=78, gb_free=16, wall=6301
2023-08-03 06:18:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 06:18:27 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.577 | trans_loss 5.814 | nll_loss 3.16 | w2v_ctc_loss 1.538 | task_loss 0 | contrastive_loss 0.316 | total 4003.4 | n_correct 2322.5 | ppl 8.94 | accuracy 58.013 | uer 21.883 | wer 23.765 | raw_wer 23.765 | bleu 17.43 | wps 2202.7 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.43
2023-08-03 06:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-03 06:18:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_6_8000.pt
2023-08-03 06:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_6_8000.pt
2023-08-03 06:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.43) (writing took 24.474909756332636 seconds)
2023-08-03 06:20:10 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.278, trans_loss=3.603, nll_loss=1.787, w2v_ctc_loss=1.277, task_loss=0, contrastive_loss=0.168, total=4151.01, n_correct=2309.09, ppl=3.45, accuracy=55.627, wps=9822.8, ups=0.79, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.506, clip=0, loss_scale=8, train_wall=78, gb_free=13.3, wall=6427
2023-08-03 06:21:29 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.271, trans_loss=3.61, nll_loss=1.796, w2v_ctc_loss=1.267, task_loss=0, contrastive_loss=0.15, total=4108.83, n_correct=2276.69, ppl=3.47, accuracy=55.41, wps=15614, ups=1.27, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.512, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=6505
2023-08-03 06:22:48 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.29, trans_loss=3.609, nll_loss=1.795, w2v_ctc_loss=1.271, task_loss=0, contrastive_loss=0.25, total=4076.46, n_correct=2258.15, ppl=3.47, accuracy=55.395, wps=15449.7, ups=1.27, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.513, clip=0, loss_scale=8, train_wall=78, gb_free=12.9, wall=6584
2023-08-03 06:24:06 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.28, trans_loss=3.593, nll_loss=1.776, w2v_ctc_loss=1.25, task_loss=0, contrastive_loss=0.325, total=4175.9, n_correct=2334.96, ppl=3.42, accuracy=55.915, wps=15788, ups=1.27, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.523, clip=0, loss_scale=8, train_wall=78, gb_free=14.4, wall=6663
2023-08-03 06:25:24 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.263, trans_loss=3.599, nll_loss=1.782, w2v_ctc_loss=1.262, task_loss=0, contrastive_loss=0.155, total=4077.2, n_correct=2270.8, ppl=3.44, accuracy=55.695, wps=15635.4, ups=1.28, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.513, clip=0, loss_scale=8, train_wall=77, gb_free=16.5, wall=6741
2023-08-03 06:26:44 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.3, trans_loss=3.591, nll_loss=1.775, w2v_ctc_loss=1.249, task_loss=0, contrastive_loss=0.476, total=4133.46, n_correct=2309.54, ppl=3.42, accuracy=55.874, wps=15532.8, ups=1.26, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.518, clip=0, loss_scale=8, train_wall=79, gb_free=12.7, wall=6820
2023-08-03 06:28:02 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.246, trans_loss=3.598, nll_loss=1.779, w2v_ctc_loss=1.245, task_loss=0, contrastive_loss=0.14, total=4127.77, n_correct=2314.05, ppl=3.43, accuracy=56.061, wps=15820.7, ups=1.28, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.506, clip=0, loss_scale=8, train_wall=77, gb_free=17.2, wall=6898
2023-08-03 06:29:21 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.242, trans_loss=3.59, nll_loss=1.772, w2v_ctc_loss=1.243, task_loss=0, contrastive_loss=0.145, total=4190.32, n_correct=2355.7, ppl=3.41, accuracy=56.218, wps=15837.9, ups=1.27, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.502, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=6977
2023-08-03 06:29:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 06:30:12 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.525 | trans_loss 5.776 | nll_loss 3.116 | w2v_ctc_loss 1.457 | task_loss 0 | contrastive_loss 0.308 | total 4003.4 | n_correct 2341.4 | ppl 8.67 | accuracy 58.485 | uer 20.872 | wer 22.617 | raw_wer 22.617 | bleu 17.88 | wps 2215.7 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 17.88
2023-08-03 06:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-03 06:30:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 6 @ 8837 updates, score 17.88) (writing took 24.355778506025672 seconds)
2023-08-03 06:30:37 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-03 06:30:37 | INFO | train | epoch 006 | loss 2.278 | trans_loss 3.597 | nll_loss 1.779 | w2v_ctc_loss 1.265 | task_loss 0 | contrastive_loss 0.23 | total 4138.65 | n_correct 2304.85 | ppl 3.43 | accuracy 55.691 | wps 14423.8 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.516 | clip 0 | loss_scale 8 | train_wall 1152 | gb_free 15.4 | wall 7053
2023-08-03 06:30:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 06:30:37 | INFO | fairseq.trainer | begin training epoch 7
2023-08-03 06:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 06:31:35 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.21, trans_loss=3.565, nll_loss=1.74, w2v_ctc_loss=1.211, task_loss=0, contrastive_loss=0.163, total=4110.43, n_correct=2337.17, ppl=3.34, accuracy=56.86, wps=9161, ups=0.75, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.501, clip=0, loss_scale=8, train_wall=78, gb_free=17.5, wall=7111
2023-08-03 06:32:52 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.207, trans_loss=3.555, nll_loss=1.725, w2v_ctc_loss=1.196, task_loss=0, contrastive_loss=0.235, total=4109.53, n_correct=2340.45, ppl=3.31, accuracy=56.952, wps=15770, ups=1.29, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.51, clip=0, loss_scale=8, train_wall=77, gb_free=13.9, wall=7189
2023-08-03 06:34:11 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.194, trans_loss=3.55, nll_loss=1.718, w2v_ctc_loss=1.202, task_loss=0, contrastive_loss=0.142, total=4133.29, n_correct=2368.63, ppl=3.29, accuracy=57.306, wps=15647.9, ups=1.27, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.514, clip=0, loss_scale=8, train_wall=78, gb_free=15.6, wall=7268
2023-08-03 06:35:30 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.23, trans_loss=3.559, nll_loss=1.73, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.405, total=4194.76, n_correct=2392.47, ppl=3.32, accuracy=57.035, wps=15812.3, ups=1.26, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.507, clip=0, loss_scale=16, train_wall=79, gb_free=13.3, wall=7347
2023-08-03 06:36:49 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.214, trans_loss=3.558, nll_loss=1.732, w2v_ctc_loss=1.188, task_loss=0, contrastive_loss=0.321, total=4153.22, n_correct=2366.51, ppl=3.32, accuracy=56.98, wps=15870.4, ups=1.28, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.503, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7425
2023-08-03 06:38:06 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.191, trans_loss=3.558, nll_loss=1.729, w2v_ctc_loss=1.192, task_loss=0, contrastive_loss=0.149, total=4168.14, n_correct=2387.65, ppl=3.31, accuracy=57.283, wps=15974.2, ups=1.28, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.504, clip=0, loss_scale=16, train_wall=77, gb_free=17, wall=7503
2023-08-03 06:39:25 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.18, trans_loss=3.556, nll_loss=1.726, w2v_ctc_loss=1.183, task_loss=0, contrastive_loss=0.135, total=4157.82, n_correct=2387.82, ppl=3.31, accuracy=57.43, wps=15713, ups=1.27, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.498, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=7582
2023-08-03 06:40:44 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.179, trans_loss=3.552, nll_loss=1.723, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.131, total=4122.1, n_correct=2359.97, ppl=3.3, accuracy=57.252, wps=15566, ups=1.26, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.507, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=7661
2023-08-03 06:42:03 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.186, trans_loss=3.56, nll_loss=1.733, w2v_ctc_loss=1.185, task_loss=0, contrastive_loss=0.155, total=4147.23, n_correct=2372.66, ppl=3.32, accuracy=57.211, wps=15737.7, ups=1.27, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.504, clip=0, loss_scale=16, train_wall=78, gb_free=17.6, wall=7740
2023-08-03 06:43:22 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.192, trans_loss=3.555, nll_loss=1.728, w2v_ctc_loss=1.172, task_loss=0, contrastive_loss=0.251, total=4140.14, n_correct=2372.99, ppl=3.31, accuracy=57.317, wps=15709.6, ups=1.27, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.508, clip=0, loss_scale=16, train_wall=78, gb_free=16.2, wall=7818
2023-08-03 06:44:40 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.18, trans_loss=3.566, nll_loss=1.742, w2v_ctc_loss=1.187, task_loss=0, contrastive_loss=0.116, total=4103.51, n_correct=2344.39, ppl=3.34, accuracy=57.131, wps=15609, ups=1.27, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7897
2023-08-03 06:45:59 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.218, trans_loss=3.553, nll_loss=1.728, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.389, total=4137.04, n_correct=2375.16, ppl=3.31, accuracy=57.412, wps=15688.8, ups=1.27, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.512, clip=0, loss_scale=16, train_wall=78, gb_free=16.2, wall=7976
2023-08-03 06:45:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 06:46:21 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.477 | trans_loss 5.724 | nll_loss 3.052 | w2v_ctc_loss 1.432 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2371.3 | ppl 8.29 | accuracy 59.232 | uer 19.579 | wer 21.17 | raw_wer 21.17 | bleu 18.06 | wps 2351.5 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.06
2023-08-03 06:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-03 06:46:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_7_10000.pt
2023-08-03 06:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_7_10000.pt
2023-08-03 06:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.06) (writing took 44.33640288747847 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 06:48:24 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.172, trans_loss=3.56, nll_loss=1.736, w2v_ctc_loss=1.172, task_loss=0, contrastive_loss=0.145, total=4129.52, n_correct=2363.1, ppl=3.33, accuracy=57.225, wps=8526.9, ups=0.69, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.423, clip=0, loss_scale=16, train_wall=77, gb_free=16.9, wall=8120
2023-08-03 06:49:42 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.185, trans_loss=3.552, nll_loss=1.725, w2v_ctc_loss=1.18, task_loss=0, contrastive_loss=0.183, total=4172.87, n_correct=2404.45, ppl=3.31, accuracy=57.621, wps=15895.5, ups=1.28, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.422, clip=0, loss_scale=16, train_wall=78, gb_free=17.3, wall=8199
2023-08-03 06:51:02 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.191, trans_loss=3.556, nll_loss=1.733, w2v_ctc_loss=1.178, task_loss=0, contrastive_loss=0.247, total=4109.42, n_correct=2349.78, ppl=3.32, accuracy=57.18, wps=15381.9, ups=1.25, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.429, clip=0, loss_scale=16, train_wall=79, gb_free=16.7, wall=8279
2023-08-03 06:51:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
2023-08-03 06:51:34 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.475 | trans_loss 5.719 | nll_loss 3.04 | w2v_ctc_loss 1.433 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2370.1 | ppl 8.22 | accuracy 59.202 | uer 19.953 | wer 21.606 | raw_wer 21.606 | bleu 18.39 | wps 2194.6 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.39
2023-08-03 06:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-03 06:51:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 06:51:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.39) (writing took 23.631213380023837 seconds)
2023-08-03 06:51:58 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-03 06:51:58 | INFO | train | epoch 007 | loss 2.194 | trans_loss 3.556 | nll_loss 1.729 | w2v_ctc_loss 1.185 | task_loss 0 | contrastive_loss 0.213 | total 4138.65 | n_correct 2368.81 | ppl 3.31 | accuracy 57.236 | wps 14217.7 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.49 | clip 0 | loss_scale 16 | train_wall 1151 | gb_free 13.5 | wall 8335
2023-08-03 06:51:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 06:51:58 | INFO | fairseq.trainer | begin training epoch 8
2023-08-03 06:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 06:53:15 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.138, trans_loss=3.533, nll_loss=1.694, w2v_ctc_loss=1.141, task_loss=0, contrastive_loss=0.142, total=4116.25, n_correct=2393.25, ppl=3.24, accuracy=58.142, wps=9190.5, ups=0.75, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.422, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=8412
2023-08-03 06:54:33 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.135, trans_loss=3.525, nll_loss=1.685, w2v_ctc_loss=1.135, task_loss=0, contrastive_loss=0.162, total=4037.23, n_correct=2353.4, ppl=3.22, accuracy=58.292, wps=15450, ups=1.28, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.433, clip=0, loss_scale=16, train_wall=77, gb_free=13.1, wall=8490
2023-08-03 06:55:52 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.139, trans_loss=3.519, nll_loss=1.68, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.163, total=4207.78, n_correct=2461.95, ppl=3.2, accuracy=58.509, wps=16002.3, ups=1.27, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.422, clip=0, loss_scale=16, train_wall=78, gb_free=13.4, wall=8569
2023-08-03 06:57:11 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.15, trans_loss=3.528, nll_loss=1.691, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.181, total=4127.24, n_correct=2398.5, ppl=3.23, accuracy=58.114, wps=15515, ups=1.26, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.425, clip=0, loss_scale=16, train_wall=79, gb_free=12.2, wall=8648
2023-08-03 06:58:30 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.183, trans_loss=3.522, nll_loss=1.686, w2v_ctc_loss=1.129, task_loss=0, contrastive_loss=0.444, total=4203.76, n_correct=2455.8, ppl=3.22, accuracy=58.419, wps=15858.1, ups=1.26, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.419, clip=0, loss_scale=16, train_wall=79, gb_free=14.8, wall=8727
2023-08-03 06:59:49 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.14, trans_loss=3.526, nll_loss=1.693, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.116, total=4062.5, n_correct=2358.6, ppl=3.23, accuracy=58.058, wps=15477, ups=1.27, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.425, clip=0, loss_scale=16, train_wall=78, gb_free=11.7, wall=8806
2023-08-03 07:01:08 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.131, trans_loss=3.521, nll_loss=1.683, w2v_ctc_loss=1.144, task_loss=0, contrastive_loss=0.127, total=4142.78, n_correct=2423.6, ppl=3.21, accuracy=58.502, wps=15675.9, ups=1.27, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.422, clip=0, loss_scale=16, train_wall=78, gb_free=16, wall=8884
2023-08-03 07:02:26 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.14, trans_loss=3.521, nll_loss=1.688, w2v_ctc_loss=1.138, task_loss=0, contrastive_loss=0.212, total=4118.9, n_correct=2401.35, ppl=3.22, accuracy=58.301, wps=15676.7, ups=1.27, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.425, clip=0, loss_scale=16, train_wall=78, gb_free=15.4, wall=8963
2023-08-03 07:03:45 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.137, trans_loss=3.524, nll_loss=1.69, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.225, total=4169.01, n_correct=2441.13, ppl=3.23, accuracy=58.554, wps=15885.3, ups=1.28, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.428, clip=0, loss_scale=16, train_wall=78, gb_free=16.3, wall=9041
2023-08-03 07:05:03 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.121, trans_loss=3.524, nll_loss=1.689, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.124, total=4154.69, n_correct=2434.69, ppl=3.22, accuracy=58.601, wps=15898.7, ups=1.28, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=17.9, wall=9119
2023-08-03 07:06:22 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.155, trans_loss=3.532, nll_loss=1.699, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.349, total=4199.1, n_correct=2442.11, ppl=3.25, accuracy=58.158, wps=15757.8, ups=1.26, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.419, clip=0, loss_scale=32, train_wall=79, gb_free=13, wall=9199
2023-08-03 07:07:40 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.127, trans_loss=3.525, nll_loss=1.693, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.134, total=4177.31, n_correct=2442.82, ppl=3.23, accuracy=58.478, wps=15988.5, ups=1.28, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=15.2, wall=9277
2023-08-03 07:08:58 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.135, trans_loss=3.529, nll_loss=1.698, w2v_ctc_loss=1.142, task_loss=0, contrastive_loss=0.157, total=4063.85, n_correct=2364.26, ppl=3.24, accuracy=58.178, wps=15670.2, ups=1.29, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.425, clip=0, loss_scale=32, train_wall=77, gb_free=17, wall=9354
2023-08-03 07:10:15 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.141, trans_loss=3.531, nll_loss=1.7, w2v_ctc_loss=1.131, task_loss=0, contrastive_loss=0.209, total=4141.5, n_correct=2418.26, ppl=3.25, accuracy=58.391, wps=15964.9, ups=1.29, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.423, clip=0, loss_scale=32, train_wall=77, gb_free=16.6, wall=9432
2023-08-03 07:11:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 07:11:44 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.437 | trans_loss 5.679 | nll_loss 2.991 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.278 | total 4003.4 | n_correct 2404.3 | ppl 7.95 | accuracy 60.056 | uer 19.008 | wer 20.76 | raw_wer 20.76 | bleu 18.61 | wps 2366 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.61
2023-08-03 07:11:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-03 07:11:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 07:11:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 07:12:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.61) (writing took 23.61890061944723 seconds)
2023-08-03 07:12:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-03 07:12:08 | INFO | train | epoch 008 | loss 2.141 | trans_loss 3.526 | nll_loss 1.691 | w2v_ctc_loss 1.136 | task_loss 0 | contrastive_loss 0.203 | total 4138.65 | n_correct 2415.11 | ppl 3.23 | accuracy 58.355 | wps 15054.7 | ups 1.22 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.424 | clip 0 | loss_scale 32 | train_wall 1149 | gb_free 17.1 | wall 9544
2023-08-03 07:12:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 07:12:08 | INFO | fairseq.trainer | begin training epoch 9
2023-08-03 07:12:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 07:12:27 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.138, trans_loss=3.522, nll_loss=1.686, w2v_ctc_loss=1.114, task_loss=0, contrastive_loss=0.336, total=4139.35, n_correct=2430.27, ppl=3.22, accuracy=58.711, wps=9342.9, ups=0.76, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=15.6, wall=9564
2023-08-03 07:13:46 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.085, trans_loss=3.487, nll_loss=1.641, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.154, total=4181.9, n_correct=2492.35, ppl=3.12, accuracy=59.599, wps=15922.9, ups=1.28, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=16.4, wall=9643
2023-08-03 07:15:05 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.078, trans_loss=3.493, nll_loss=1.648, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.111, total=4062.07, n_correct=2412.19, ppl=3.13, accuracy=59.383, wps=15410.5, ups=1.27, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=32, train_wall=78, gb_free=15.8, wall=9721
2023-08-03 07:15:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 07:15:27 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.435 | trans_loss 5.69 | nll_loss 2.997 | w2v_ctc_loss 1.372 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2396.3 | ppl 7.98 | accuracy 59.857 | uer 19.035 | wer 20.879 | raw_wer 20.879 | bleu 18.58 | wps 2147.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.61
2023-08-03 07:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-03 07:15:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_9_12000.pt
2023-08-03 07:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_9_12000.pt
2023-08-03 07:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.58) (writing took 20.034229204058647 seconds)
2023-08-03 07:17:05 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.076, trans_loss=3.481, nll_loss=1.636, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.161, total=4152.1, n_correct=2481.59, ppl=3.11, accuracy=59.767, wps=10294, ups=0.83, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.419, clip=0, loss_scale=32, train_wall=77, gb_free=16.5, wall=9842
2023-08-03 07:18:24 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.081, trans_loss=3.497, nll_loss=1.655, w2v_ctc_loss=1.087, task_loss=0, contrastive_loss=0.129, total=4203.78, n_correct=2493.4, ppl=3.15, accuracy=59.313, wps=15831.9, ups=1.26, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.42, clip=0, loss_scale=32, train_wall=79, gb_free=17.3, wall=9921
2023-08-03 07:19:43 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.108, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.179, total=4112.78, n_correct=2434.03, ppl=3.16, accuracy=59.182, wps=15652.5, ups=1.28, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.423, clip=0, loss_scale=32, train_wall=78, gb_free=16.3, wall=9999
2023-08-03 07:21:01 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.076, trans_loss=3.494, nll_loss=1.654, w2v_ctc_loss=1.081, task_loss=0, contrastive_loss=0.139, total=4131.32, n_correct=2453.05, ppl=3.15, accuracy=59.377, wps=15704, ups=1.27, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.423, clip=0, loss_scale=32, train_wall=78, gb_free=17.9, wall=10078
2023-08-03 07:22:20 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.109, trans_loss=3.506, nll_loss=1.668, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.223, total=4082.11, n_correct=2408.58, ppl=3.18, accuracy=59.003, wps=15614.8, ups=1.28, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.433, clip=0, loss_scale=32, train_wall=78, gb_free=17.2, wall=10156
2023-08-03 07:23:39 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.133, trans_loss=3.498, nll_loss=1.66, w2v_ctc_loss=1.098, task_loss=0, contrastive_loss=0.367, total=4221.08, n_correct=2500.96, ppl=3.16, accuracy=59.249, wps=15912.5, ups=1.26, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.435, clip=0, loss_scale=32, train_wall=79, gb_free=17.7, wall=10235
2023-08-03 07:24:58 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.112, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.093, task_loss=0, contrastive_loss=0.342, total=4142.34, n_correct=2452.12, ppl=3.16, accuracy=59.196, wps=15562.5, ups=1.26, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.425, clip=0, loss_scale=32, train_wall=79, gb_free=17.4, wall=10315
2023-08-03 07:26:17 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.092, trans_loss=3.513, nll_loss=1.674, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.125, total=4097.15, n_correct=2412.99, ppl=3.19, accuracy=58.894, wps=15573.6, ups=1.27, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.426, clip=0, loss_scale=32, train_wall=78, gb_free=16.9, wall=10393
2023-08-03 07:27:35 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.091, trans_loss=3.507, nll_loss=1.665, w2v_ctc_loss=1.092, task_loss=0, contrastive_loss=0.152, total=4182.29, n_correct=2484.2, ppl=3.17, accuracy=59.398, wps=15963.6, ups=1.28, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=10472
2023-08-03 07:28:54 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.098, trans_loss=3.509, nll_loss=1.671, w2v_ctc_loss=1.109, task_loss=0, contrastive_loss=0.133, total=4141.43, n_correct=2446.39, ppl=3.18, accuracy=59.071, wps=15558.6, ups=1.26, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.437, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=10551
2023-08-03 07:30:13 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.112, trans_loss=3.503, nll_loss=1.663, w2v_ctc_loss=1.086, task_loss=0, contrastive_loss=0.323, total=4203.91, n_correct=2499.1, ppl=3.17, accuracy=59.447, wps=15940, ups=1.27, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=10630
2023-08-03 07:31:31 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.088, trans_loss=3.515, nll_loss=1.677, w2v_ctc_loss=1.1, task_loss=0, contrastive_loss=0.107, total=4077.08, n_correct=2407.52, ppl=3.2, accuracy=59.05, wps=15508.4, ups=1.27, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.423, clip=0, loss_scale=32, train_wall=78, gb_free=17.5, wall=10708
2023-08-03 07:32:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 07:32:39 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.414 | trans_loss 5.66 | nll_loss 2.966 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2408.4 | ppl 7.82 | accuracy 60.159 | uer 18.615 | wer 20.409 | raw_wer 20.409 | bleu 18.83 | wps 2362.2 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.83
2023-08-03 07:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-03 07:32:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 07:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 07:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.83) (writing took 23.28977262787521 seconds)
2023-08-03 07:33:03 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-03 07:33:03 | INFO | train | epoch 009 | loss 2.096 | trans_loss 3.501 | nll_loss 1.66 | w2v_ctc_loss 1.095 | task_loss 0 | contrastive_loss 0.195 | total 4138.65 | n_correct 2453.82 | ppl 3.16 | accuracy 59.29 | wps 14507.1 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.425 | clip 0 | loss_scale 32 | train_wall 1152 | gb_free 12 | wall 10800
2023-08-03 07:33:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 07:33:03 | INFO | fairseq.trainer | begin training epoch 10
2023-08-03 07:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 07:33:43 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.085, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.209, total=4100.86, n_correct=2450.19, ppl=3.14, accuracy=59.748, wps=9275, ups=0.76, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.436, clip=0, loss_scale=64, train_wall=78, gb_free=16.6, wall=10840
2023-08-03 07:33:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 07:35:03 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.039, trans_loss=3.467, nll_loss=1.617, w2v_ctc_loss=1.047, task_loss=0, contrastive_loss=0.131, total=4240.32, n_correct=2557.51, ppl=3.07, accuracy=60.314, wps=15978, ups=1.26, wpb=12661.7, bsz=476.7, num_updates=13400, lr=0.000122169, gnorm=0.429, clip=0, loss_scale=32, train_wall=79, gb_free=12.1, wall=10919
2023-08-03 07:36:21 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.066, trans_loss=3.469, nll_loss=1.617, w2v_ctc_loss=1.058, task_loss=0, contrastive_loss=0.256, total=4122.82, n_correct=2487.59, ppl=3.07, accuracy=60.337, wps=15663.3, ups=1.27, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.433, clip=0, loss_scale=32, train_wall=78, gb_free=16.5, wall=10998
2023-08-03 07:37:40 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.046, trans_loss=3.468, nll_loss=1.622, w2v_ctc_loss=1.052, task_loss=0, contrastive_loss=0.164, total=4138.27, n_correct=2492.26, ppl=3.08, accuracy=60.225, wps=15770.5, ups=1.27, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=11076
2023-08-03 07:38:59 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.061, trans_loss=3.473, nll_loss=1.624, w2v_ctc_loss=1.036, task_loss=0, contrastive_loss=0.34, total=4196.37, n_correct=2528.44, ppl=3.08, accuracy=60.253, wps=15763.2, ups=1.26, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.416, clip=0, loss_scale=32, train_wall=79, gb_free=16.2, wall=11156
2023-08-03 07:40:18 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.061, trans_loss=3.487, nll_loss=1.638, w2v_ctc_loss=1.075, task_loss=0, contrastive_loss=0.12, total=4102.8, n_correct=2456.7, ppl=3.11, accuracy=59.879, wps=15605.9, ups=1.28, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.431, clip=0, loss_scale=32, train_wall=78, gb_free=17.2, wall=11234
2023-08-03 07:41:37 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.076, trans_loss=3.485, nll_loss=1.639, w2v_ctc_loss=1.066, task_loss=0, contrastive_loss=0.24, total=4176.56, n_correct=2506.28, ppl=3.11, accuracy=60.008, wps=15768.5, ups=1.27, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.428, clip=0, loss_scale=32, train_wall=79, gb_free=16.4, wall=11313
2023-08-03 07:42:54 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.066, trans_loss=3.484, nll_loss=1.638, w2v_ctc_loss=1.081, task_loss=0, contrastive_loss=0.117, total=4125.87, n_correct=2473.67, ppl=3.11, accuracy=59.955, wps=15837.5, ups=1.29, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.428, clip=0, loss_scale=32, train_wall=77, gb_free=14.8, wall=11391
2023-08-03 07:42:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 07:43:16 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.414 | trans_loss 5.658 | nll_loss 2.96 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.282 | total 4003.4 | n_correct 2416 | ppl 7.78 | accuracy 60.349 | uer 18.854 | wer 20.611 | raw_wer 20.611 | bleu 19.37 | wps 2398.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.37
2023-08-03 07:43:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-03 07:43:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_10_14000.pt
2023-08-03 07:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_10_14000.pt
2023-08-03 07:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.37) (writing took 44.01611090451479 seconds)
2023-08-03 07:45:19 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.045, trans_loss=3.479, nll_loss=1.634, w2v_ctc_loss=1.055, task_loss=0, contrastive_loss=0.121, total=4128.44, n_correct=2479.29, ppl=3.1, accuracy=60.054, wps=8504.1, ups=0.69, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.43, clip=0, loss_scale=32, train_wall=78, gb_free=14.9, wall=11536
2023-08-03 07:46:37 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.061, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1.062, task_loss=0, contrastive_loss=0.162, total=4160.94, n_correct=2498.01, ppl=3.1, accuracy=60.035, wps=15956.8, ups=1.29, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.428, clip=0, loss_scale=32, train_wall=77, gb_free=15.7, wall=11614
2023-08-03 07:47:56 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.056, trans_loss=3.485, nll_loss=1.64, w2v_ctc_loss=1.065, task_loss=0, contrastive_loss=0.132, total=4067.53, n_correct=2430.86, ppl=3.12, accuracy=59.763, wps=15459.2, ups=1.27, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.429, clip=0, loss_scale=32, train_wall=78, gb_free=17, wall=11692
2023-08-03 07:49:14 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.066, trans_loss=3.494, nll_loss=1.652, w2v_ctc_loss=1.081, task_loss=0, contrastive_loss=0.113, total=4044.03, n_correct=2405.88, ppl=3.14, accuracy=59.492, wps=15483.2, ups=1.28, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.437, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=11770
2023-08-03 07:50:32 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.055, trans_loss=3.481, nll_loss=1.641, w2v_ctc_loss=1.073, task_loss=0, contrastive_loss=0.107, total=4110.41, n_correct=2461.19, ppl=3.12, accuracy=59.877, wps=15733, ups=1.28, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.432, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=11848
2023-08-03 07:51:50 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.054, trans_loss=3.487, nll_loss=1.646, w2v_ctc_loss=1.066, task_loss=0, contrastive_loss=0.122, total=4121.38, n_correct=2471.45, ppl=3.13, accuracy=59.967, wps=15746.5, ups=1.28, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.425, clip=0, loss_scale=32, train_wall=78, gb_free=14.3, wall=11927
2023-08-03 07:53:09 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.094, trans_loss=3.492, nll_loss=1.649, w2v_ctc_loss=1.052, task_loss=0, contrastive_loss=0.376, total=4192.39, n_correct=2509.82, ppl=3.14, accuracy=59.866, wps=15740.8, ups=1.26, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.431, clip=0, loss_scale=32, train_wall=79, gb_free=17.2, wall=12006
2023-08-03 07:53:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 07:53:56 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.409 | trans_loss 5.642 | nll_loss 2.938 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2428.3 | ppl 7.66 | accuracy 60.656 | uer 18.18 | wer 19.835 | raw_wer 19.835 | bleu 19.13 | wps 2441.7 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.37
2023-08-03 07:53:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-03 07:53:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.1303.pt
2023-08-03 07:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.1303.pt
2023-08-03 07:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.1303.pt (epoch 10 @ 14732 updates, score 19.13) (writing took 18.675886444747448 seconds)
2023-08-03 07:54:15 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-03 07:54:15 | INFO | train | epoch 010 | loss 2.061 | trans_loss 3.48 | nll_loss 1.634 | w2v_ctc_loss 1.061 | task_loss 0 | contrastive_loss 0.19 | total 4138.51 | n_correct 2483.77 | ppl 3.1 | accuracy 60.016 | wps 14310.7 | ups 1.16 | wpb 12355.4 | bsz 458.4 | num_updates 14732 | lr 0.000116516 | gnorm 0.428 | clip 0 | loss_scale 32 | train_wall 1149 | gb_free 17.4 | wall 12071
2023-08-03 07:54:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 07:54:15 | INFO | fairseq.trainer | begin training epoch 11
2023-08-03 07:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 07:55:15 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.032, trans_loss=3.454, nll_loss=1.6, w2v_ctc_loss=1.034, task_loss=0, contrastive_loss=0.199, total=4175.24, n_correct=2540.62, ppl=3.03, accuracy=60.85, wps=9899, ups=0.79, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.418, clip=0, loss_scale=32, train_wall=77, gb_free=17, wall=12132
2023-08-03 07:56:34 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.02, trans_loss=3.455, nll_loss=1.604, w2v_ctc_loss=1.035, task_loss=0, contrastive_loss=0.117, total=4087.78, n_correct=2487.01, ppl=3.04, accuracy=60.84, wps=15567.1, ups=1.27, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.427, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=12210
2023-08-03 07:57:52 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.009, trans_loss=3.455, nll_loss=1.602, w2v_ctc_loss=1.024, task_loss=0, contrastive_loss=0.111, total=4118.77, n_correct=2503.71, ppl=3.04, accuracy=60.788, wps=15712.8, ups=1.28, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.417, clip=0, loss_scale=32, train_wall=78, gb_free=12.7, wall=12289
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 07:58:48 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.191, trans_loss=5.137, nll_loss=2.387, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.089, total=4097.83, n_correct=2485.46, ppl=5.23, accuracy=60.653, wps=14727, ups=1.79, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=12345
2023-08-03 07:59:44 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.209, trans_loss=5.175, nll_loss=2.413, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.207, total=4110.64, n_correct=2482.65, ppl=5.33, accuracy=60.396, wps=14666.8, ups=1.78, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=12401
2023-08-03 08:00:40 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.21, trans_loss=5.173, nll_loss=2.411, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.205, total=4071.69, n_correct=2458.26, ppl=5.32, accuracy=60.374, wps=14483.4, ups=1.78, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.589, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=12457
2023-08-03 08:01:36 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.216, trans_loss=5.175, nll_loss=2.414, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.262, total=4157.2, n_correct=2510.37, ppl=5.33, accuracy=60.386, wps=14862.6, ups=1.79, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=12513
2023-08-03 08:02:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 08:02:33 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.21, trans_loss=5.185, nll_loss=2.427, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.089, total=4174.98, n_correct=2522.84, ppl=5.38, accuracy=60.428, wps=14795.7, ups=1.77, wpb=8350, bsz=307.2, num_updates=15500, lr=0.000113592, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=12.7, wall=12569
2023-08-03 08:03:28 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.207, trans_loss=5.187, nll_loss=2.43, w2v_ctc_loss=0.792, task_loss=0, contrastive_loss=0.075, total=4120.01, n_correct=2479.6, ppl=5.39, accuracy=60.184, wps=14826.9, ups=1.8, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.571, clip=0, loss_scale=32, train_wall=55, gb_free=13.9, wall=12625
2023-08-03 08:04:24 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.206, trans_loss=5.183, nll_loss=2.426, w2v_ctc_loss=0.792, task_loss=0, contrastive_loss=0.09, total=4145.45, n_correct=2504.52, ppl=5.37, accuracy=60.416, wps=14858.5, ups=1.79, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.576, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=12681
2023-08-03 08:05:20 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.207, trans_loss=5.18, nll_loss=2.422, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.109, total=4141.18, n_correct=2504.12, ppl=5.36, accuracy=60.469, wps=14881.4, ups=1.8, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=12736
2023-08-03 08:06:16 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.207, trans_loss=5.186, nll_loss=2.429, w2v_ctc_loss=0.791, task_loss=0, contrastive_loss=0.095, total=4173.93, n_correct=2518.11, ppl=5.39, accuracy=60.329, wps=14950.5, ups=1.79, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=12792
2023-08-03 08:07:12 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.214, trans_loss=5.181, nll_loss=2.425, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.166, total=4174.26, n_correct=2521.86, ppl=5.37, accuracy=60.415, wps=14918.6, ups=1.79, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.583, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=12848
2023-08-03 08:07:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
2023-08-03 08:07:33 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.418 | trans_loss 5.642 | nll_loss 2.941 | w2v_ctc_loss 1.44 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2431.2 | ppl 7.68 | accuracy 60.728 | uer 18.371 | wer 20.1 | raw_wer 20.1 | bleu 18.61 | wps 2441.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.37
2023-08-03 08:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-03 08:07:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_11_16000.pt
2023-08-03 08:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_11_16000.pt
2023-08-03 08:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.61) (writing took 28.156838107854128 seconds)
2023-08-03 08:08:58 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.218, trans_loss=5.18, nll_loss=2.423, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.326, total=4191.56, n_correct=2533.12, ppl=5.36, accuracy=60.434, wps=7847.3, ups=0.94, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.578, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=12955
2023-08-03 08:09:54 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.207, trans_loss=5.188, nll_loss=2.433, w2v_ctc_loss=0.79, task_loss=0, contrastive_loss=0.098, total=4161.81, n_correct=2508.05, ppl=5.4, accuracy=60.263, wps=14936.5, ups=1.79, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=13011
2023-08-03 08:09:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 08:10:20 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.38 | trans_loss 5.628 | nll_loss 2.926 | w2v_ctc_loss 1.339 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2437.8 | ppl 7.6 | accuracy 60.893 | uer 18.265 | wer 20.078 | raw_wer 20.078 | bleu 19.03 | wps 2274.5 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.37
2023-08-03 08:10:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-03 08:10:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.0307.pt
2023-08-03 08:10:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.0307.pt
2023-08-03 08:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.0307.pt (epoch 11 @ 16205 updates, score 19.03) (writing took 13.066597986966372 seconds)
2023-08-03 08:10:33 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-03 08:10:33 | INFO | train | epoch 011 | loss 2.161 | trans_loss 4.748 | nll_loss 2.216 | w2v_ctc_loss 0.849 | task_loss 0 | contrastive_loss 0.142 | total 4138.9 | n_correct 2503.28 | ppl 4.65 | accuracy 60.482 | wps 13583 | ups 1.51 | wpb 9022 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.554 | clip 0 | loss_scale 32 | train_wall 876 | gb_free 17.5 | wall 13050
2023-08-03 08:10:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 08:10:33 | INFO | fairseq.trainer | begin training epoch 12
2023-08-03 08:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 08:11:34 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.179, trans_loss=5.124, nll_loss=2.348, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.13, total=4139.2, n_correct=2543.64, ppl=5.09, accuracy=61.452, wps=8309.6, ups=1, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=13110
2023-08-03 08:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 08:12:30 | INFO | train_inner | epoch 012:    196 / 1474 loss=2.181, trans_loss=5.135, nll_loss=2.362, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.081, total=4126.17, n_correct=2527.31, ppl=5.14, accuracy=61.251, wps=14732.9, ups=1.79, wpb=8252.3, bsz=297.4, num_updates=16400, lr=0.000110432, gnorm=0.597, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=13166
2023-08-03 08:13:26 | INFO | train_inner | epoch 012:    296 / 1474 loss=2.181, trans_loss=5.136, nll_loss=2.364, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.114, total=4208.07, n_correct=2575.78, ppl=5.15, accuracy=61.21, wps=15058.7, ups=1.79, wpb=8416.1, bsz=321.7, num_updates=16500, lr=0.000110096, gnorm=0.574, clip=0, loss_scale=16, train_wall=55, gb_free=12.8, wall=13222
2023-08-03 08:14:21 | INFO | train_inner | epoch 012:    396 / 1474 loss=2.189, trans_loss=5.15, nll_loss=2.382, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.097, total=4144.42, n_correct=2526.03, ppl=5.21, accuracy=60.95, wps=14871.8, ups=1.79, wpb=8288.8, bsz=305.3, num_updates=16600, lr=0.000109764, gnorm=0.599, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=13278
2023-08-03 08:15:17 | INFO | train_inner | epoch 012:    496 / 1474 loss=2.194, trans_loss=5.157, nll_loss=2.392, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.103, total=4095.26, n_correct=2497.68, ppl=5.25, accuracy=60.99, wps=14722.4, ups=1.8, wpb=8190.5, bsz=299.8, num_updates=16700, lr=0.000109435, gnorm=0.58, clip=0, loss_scale=16, train_wall=55, gb_free=17.9, wall=13334
2023-08-03 08:16:13 | INFO | train_inner | epoch 012:    596 / 1474 loss=2.19, trans_loss=5.145, nll_loss=2.377, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.17, total=4204.6, n_correct=2569.29, ppl=5.2, accuracy=61.107, wps=14899.5, ups=1.77, wpb=8409.2, bsz=319.2, num_updates=16800, lr=0.000109109, gnorm=0.581, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=13390
2023-08-03 08:17:09 | INFO | train_inner | epoch 012:    696 / 1474 loss=2.19, trans_loss=5.145, nll_loss=2.377, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.26, total=4197.19, n_correct=2569.78, ppl=5.19, accuracy=61.226, wps=15040.4, ups=1.79, wpb=8394.4, bsz=323.2, num_updates=16900, lr=0.000108786, gnorm=0.565, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=13446
2023-08-03 08:18:05 | INFO | train_inner | epoch 012:    796 / 1474 loss=2.185, trans_loss=5.148, nll_loss=2.381, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.092, total=4094.06, n_correct=2501.97, ppl=5.21, accuracy=61.112, wps=14700.6, ups=1.8, wpb=8188.1, bsz=298.2, num_updates=17000, lr=0.000108465, gnorm=0.589, clip=0, loss_scale=16, train_wall=55, gb_free=15.1, wall=13502
2023-08-03 08:19:01 | INFO | train_inner | epoch 012:    896 / 1474 loss=2.193, trans_loss=5.155, nll_loss=2.39, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.147, total=4163.5, n_correct=2538, ppl=5.24, accuracy=60.958, wps=14832, ups=1.78, wpb=8327, bsz=305.1, num_updates=17100, lr=0.000108148, gnorm=0.583, clip=0, loss_scale=16, train_wall=56, gb_free=13.3, wall=13558
2023-08-03 08:19:57 | INFO | train_inner | epoch 012:    996 / 1474 loss=2.196, trans_loss=5.163, nll_loss=2.401, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.153, total=4124.99, n_correct=2511.93, ppl=5.28, accuracy=60.895, wps=14757.9, ups=1.79, wpb=8250, bsz=302.7, num_updates=17200, lr=0.000107833, gnorm=0.587, clip=0, loss_scale=16, train_wall=55, gb_free=11.7, wall=13614
2023-08-03 08:20:53 | INFO | train_inner | epoch 012:   1096 / 1474 loss=2.205, trans_loss=5.169, nll_loss=2.407, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.197, total=4046.6, n_correct=2457.53, ppl=5.31, accuracy=60.731, wps=14521.4, ups=1.79, wpb=8093.2, bsz=289.8, num_updates=17300, lr=0.000107521, gnorm=0.592, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=13669
2023-08-03 08:21:49 | INFO | train_inner | epoch 012:   1196 / 1474 loss=2.212, trans_loss=5.179, nll_loss=2.424, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.17, total=4196.85, n_correct=2533.18, ppl=5.37, accuracy=60.359, wps=15044.1, ups=1.79, wpb=8393.7, bsz=319, num_updates=17400, lr=0.000107211, gnorm=0.594, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=13725
2023-08-03 08:22:44 | INFO | train_inner | epoch 012:   1296 / 1474 loss=2.2, trans_loss=5.169, nll_loss=2.408, w2v_ctc_loss=0.799, task_loss=0, contrastive_loss=0.078, total=4067.78, n_correct=2470.79, ppl=5.31, accuracy=60.741, wps=14565.3, ups=1.79, wpb=8135.6, bsz=285.5, num_updates=17500, lr=0.000106904, gnorm=0.593, clip=0, loss_scale=16, train_wall=55, gb_free=15.5, wall=13781
2023-08-03 08:23:40 | INFO | train_inner | epoch 012:   1396 / 1474 loss=2.196, trans_loss=5.17, nll_loss=2.411, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.185, total=4142.88, n_correct=2517, ppl=5.32, accuracy=60.755, wps=14815, ups=1.79, wpb=8285.8, bsz=306.2, num_updates=17600, lr=0.0001066, gnorm=0.582, clip=0, loss_scale=16, train_wall=55, gb_free=16, wall=13837
2023-08-03 08:24:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 08:24:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.404 | trans_loss 5.631 | nll_loss 2.926 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2434 | ppl 7.6 | accuracy 60.798 | uer 18.321 | wer 19.943 | raw_wer 19.943 | bleu 19.46 | wps 2221.6 | wpb 4003.4 | bsz 141.8 | num_updates 17678 | best_bleu 19.46
2023-08-03 08:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17678 updates
2023-08-03 08:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 08:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 08:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 12 @ 17678 updates, score 19.46) (writing took 22.805501401424408 seconds)
2023-08-03 08:25:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-03 08:25:10 | INFO | train | epoch 012 | loss 2.192 | trans_loss 5.154 | nll_loss 2.388 | w2v_ctc_loss 0.778 | task_loss 0 | contrastive_loss 0.139 | total 4138.6 | n_correct 2523.6 | ppl 5.24 | accuracy 60.977 | wps 13905.8 | ups 1.68 | wpb 8277.2 | bsz 305.7 | num_updates 17678 | lr 0.000106365 | gnorm 0.586 | clip 0 | loss_scale 16 | train_wall 816 | gb_free 13.3 | wall 13927
2023-08-03 08:25:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 08:25:10 | INFO | fairseq.trainer | begin training epoch 13
2023-08-03 08:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 08:25:30 | INFO | train_inner | epoch 013:     22 / 1474 loss=2.192, trans_loss=5.163, nll_loss=2.401, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.089, total=4097.08, n_correct=2495.36, ppl=5.28, accuracy=60.906, wps=7460.9, ups=0.91, wpb=8194.2, bsz=296.6, num_updates=17700, lr=0.000106299, gnorm=0.593, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=13947
2023-08-03 08:26:26 | INFO | train_inner | epoch 013:    122 / 1474 loss=2.17, trans_loss=5.12, nll_loss=2.343, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.101, total=4164.24, n_correct=2563.92, ppl=5.07, accuracy=61.57, wps=14831, ups=1.78, wpb=8328.5, bsz=301.9, num_updates=17800, lr=0.000106, gnorm=0.579, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=14003
2023-08-03 08:27:22 | INFO | train_inner | epoch 013:    222 / 1474 loss=2.189, trans_loss=5.127, nll_loss=2.355, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.32, total=4201.52, n_correct=2582.49, ppl=5.12, accuracy=61.466, wps=15003.7, ups=1.79, wpb=8403, bsz=328.5, num_updates=17900, lr=0.000105703, gnorm=0.59, clip=0, loss_scale=16, train_wall=56, gb_free=13.6, wall=14059
2023-08-03 08:28:18 | INFO | train_inner | epoch 013:    322 / 1474 loss=2.163, trans_loss=5.117, nll_loss=2.338, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.083, total=4102.53, n_correct=2533.42, ppl=5.06, accuracy=61.753, wps=14698.1, ups=1.79, wpb=8205.1, bsz=293.9, num_updates=18000, lr=0.000105409, gnorm=0.582, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=14115
2023-08-03 08:28:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 08:28:40 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.63 | nll_loss 2.924 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2441.3 | ppl 7.59 | accuracy 60.981 | uer 18.159 | wer 19.772 | raw_wer 19.772 | bleu 19.35 | wps 2343.5 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.46
2023-08-03 08:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-03 08:28:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_13_18000.pt
2023-08-03 08:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_13_18000.pt
2023-08-03 08:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.35) (writing took 29.90725728869438 seconds)
2023-08-03 08:30:07 | INFO | train_inner | epoch 013:    422 / 1474 loss=2.173, trans_loss=5.123, nll_loss=2.348, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.135, total=4190.45, n_correct=2591.32, ppl=5.09, accuracy=61.839, wps=7693.8, ups=0.92, wpb=8380.9, bsz=320.3, num_updates=18100, lr=0.000105118, gnorm=0.59, clip=0, loss_scale=16, train_wall=55, gb_free=16.1, wall=14224
2023-08-03 08:31:03 | INFO | train_inner | epoch 013:    522 / 1474 loss=2.183, trans_loss=5.134, nll_loss=2.364, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.172, total=4194.45, n_correct=2570.5, ppl=5.15, accuracy=61.283, wps=14907.9, ups=1.78, wpb=8388.9, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.587, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=14280
2023-08-03 08:31:59 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.168, trans_loss=5.128, nll_loss=2.356, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.08, total=4158.04, n_correct=2562.9, ppl=5.12, accuracy=61.637, wps=14947.7, ups=1.8, wpb=8316.1, bsz=306.7, num_updates=18300, lr=0.000104542, gnorm=0.581, clip=0, loss_scale=16, train_wall=55, gb_free=13.9, wall=14336
2023-08-03 08:32:55 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.184, trans_loss=5.142, nll_loss=2.372, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.078, total=4099.91, n_correct=2504.19, ppl=5.18, accuracy=61.079, wps=14724.7, ups=1.8, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=14391
2023-08-03 08:33:51 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.182, trans_loss=5.14, nll_loss=2.372, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.131, total=4122.78, n_correct=2526.12, ppl=5.17, accuracy=61.272, wps=14665.6, ups=1.78, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=14448
2023-08-03 08:34:47 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.177, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.091, total=4102.59, n_correct=2518.99, ppl=5.17, accuracy=61.4, wps=14691, ups=1.79, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=14504
2023-08-03 08:35:42 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.186, trans_loss=5.146, nll_loss=2.378, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.142, total=4087.8, n_correct=2499.84, ppl=5.2, accuracy=61.154, wps=14782.1, ups=1.81, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=14559
2023-08-03 08:36:38 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.175, trans_loss=5.135, nll_loss=2.366, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.123, total=4098.77, n_correct=2520.59, ppl=5.15, accuracy=61.496, wps=14812.6, ups=1.81, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=14.1, wall=14614
2023-08-03 08:37:33 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.183, trans_loss=5.15, nll_loss=2.384, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.082, total=4115.57, n_correct=2516.49, ppl=5.22, accuracy=61.146, wps=14744.5, ups=1.79, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=14670
2023-08-03 08:38:30 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.18, trans_loss=5.135, nll_loss=2.367, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.179, total=4111.02, n_correct=2529.34, ppl=5.16, accuracy=61.526, wps=14609.3, ups=1.78, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=18.1, wall=14726
2023-08-03 08:39:25 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.186, trans_loss=5.148, nll_loss=2.383, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.191, total=4179.06, n_correct=2556.55, ppl=5.22, accuracy=61.175, wps=14994.6, ups=1.79, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=14782
2023-08-03 08:39:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 08:40:17 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.394 | trans_loss 5.618 | nll_loss 2.908 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.287 | total 4003.4 | n_correct 2447.1 | ppl 7.51 | accuracy 61.126 | uer 18.199 | wer 19.82 | raw_wer 19.82 | bleu 19.48 | wps 2255.3 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.48
2023-08-03 08:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-03 08:40:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 08:40:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 08:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 13 @ 19152 updates, score 19.48) (writing took 23.60740095563233 seconds)
2023-08-03 08:40:41 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-03 08:40:41 | INFO | train | epoch 013 | loss 2.178 | trans_loss 5.134 | nll_loss 2.364 | w2v_ctc_loss 0.768 | task_loss 0 | contrastive_loss 0.137 | total 4138.65 | n_correct 2542.23 | ppl 5.15 | accuracy 61.427 | wps 13104.9 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.585 | clip 0 | loss_scale 32 | train_wall 816 | gb_free 17.9 | wall 14858
2023-08-03 08:40:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 08:40:41 | INFO | fairseq.trainer | begin training epoch 14
2023-08-03 08:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 08:41:15 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.158, trans_loss=5.104, nll_loss=2.326, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.098, total=4179.66, n_correct=2596.63, ppl=5.01, accuracy=62.125, wps=7620.5, ups=0.91, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=11.2, wall=14892
2023-08-03 08:42:10 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.151, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.078, total=4081.01, n_correct=2546.71, ppl=4.94, accuracy=62.404, wps=14763.7, ups=1.81, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=14947
2023-08-03 08:43:06 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.166, trans_loss=5.109, nll_loss=2.33, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.178, total=4109.83, n_correct=2545.84, ppl=5.03, accuracy=61.945, wps=14665.8, ups=1.78, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.58, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=15003
2023-08-03 08:44:02 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.157, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.118, total=4171.83, n_correct=2590.01, ppl=5, accuracy=62.083, wps=14955.2, ups=1.79, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.592, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=15059
2023-08-03 08:44:58 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.159, trans_loss=5.114, nll_loss=2.337, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.088, total=4142.75, n_correct=2564.89, ppl=5.05, accuracy=61.913, wps=14825.9, ups=1.79, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=15115
2023-08-03 08:45:54 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.172, trans_loss=5.119, nll_loss=2.343, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.095, total=4073.76, n_correct=2512.04, ppl=5.07, accuracy=61.664, wps=14591.6, ups=1.79, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.604, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=15171
2023-08-03 08:46:50 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.167, trans_loss=5.118, nll_loss=2.343, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.155, total=4158.79, n_correct=2569.61, ppl=5.07, accuracy=61.787, wps=14716, ups=1.77, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.579, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=15227
2023-08-03 08:47:46 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.155, trans_loss=5.106, nll_loss=2.327, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.086, total=4145.47, n_correct=2574.95, ppl=5.02, accuracy=62.115, wps=14842.9, ups=1.79, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.573, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=15283
2023-08-03 08:48:42 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.167, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.193, total=4171.1, n_correct=2587.32, ppl=5.04, accuracy=62.03, wps=14980.7, ups=1.8, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=15339
2023-08-03 08:48:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 08:49:04 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.392 | trans_loss 5.611 | nll_loss 2.899 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2451.2 | ppl 7.46 | accuracy 61.228 | uer 18.071 | wer 19.72 | raw_wer 19.72 | bleu 19.69 | wps 2279.1 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.69
2023-08-03 08:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-03 08:49:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_14_20000.pt
2023-08-03 08:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_14_20000.pt
2023-08-03 08:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.69) (writing took 25.698165457695723 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 08:50:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 08:50:28 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.167, trans_loss=5.12, nll_loss=2.347, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.129, total=4164.96, n_correct=2571.39, ppl=5.09, accuracy=61.739, wps=7896.9, ups=0.95, wpb=8329.9, bsz=308.8, num_updates=20100, lr=9.97509e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=15444
2023-08-03 08:51:24 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.166, trans_loss=5.125, nll_loss=2.352, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.11, total=4145.57, n_correct=2563.53, ppl=5.11, accuracy=61.838, wps=14644, ups=1.77, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=56, gb_free=17.7, wall=15501
2023-08-03 08:52:20 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.191, trans_loss=5.125, nll_loss=2.354, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.385, total=4219.9, n_correct=2600.38, ppl=5.11, accuracy=61.622, wps=14992.5, ups=1.78, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=15557
2023-08-03 08:53:16 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.174, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.066, total=4032.06, n_correct=2475.27, ppl=5.17, accuracy=61.39, wps=14527.4, ups=1.8, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=55, gb_free=17.9, wall=15613
2023-08-03 08:54:12 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.164, trans_loss=5.129, nll_loss=2.359, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.087, total=4205.07, n_correct=2596.13, ppl=5.13, accuracy=61.738, wps=15007.7, ups=1.78, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=15669
2023-08-03 08:55:08 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.172, trans_loss=5.136, nll_loss=2.368, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.125, total=4126.44, n_correct=2541.26, ppl=5.16, accuracy=61.585, wps=14824.2, ups=1.8, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=15724
2023-08-03 08:55:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
2023-08-03 08:55:44 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.373 | trans_loss 5.606 | nll_loss 2.898 | w2v_ctc_loss 1.372 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2452.5 | ppl 7.45 | accuracy 61.26 | uer 18.053 | wer 19.828 | raw_wer 19.828 | bleu 19.59 | wps 2303.7 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 19.69
2023-08-03 08:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-03 08:55:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.5905.pt
2023-08-03 08:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.5905.pt
2023-08-03 08:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.5905.pt (epoch 14 @ 20625 updates, score 19.59) (writing took 12.938282979652286 seconds)
2023-08-03 08:55:57 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-03 08:55:57 | INFO | train | epoch 014 | loss 2.166 | trans_loss 5.117 | nll_loss 2.342 | w2v_ctc_loss 0.759 | task_loss 0 | contrastive_loss 0.135 | total 4138.22 | n_correct 2559.57 | ppl 5.07 | accuracy 61.852 | wps 13303.3 | ups 1.61 | wpb 8276.4 | bsz 305.6 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.588 | clip 0 | loss_scale 16 | train_wall 817 | gb_free 16.6 | wall 15774
2023-08-03 08:55:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 08:55:58 | INFO | fairseq.trainer | begin training epoch 15
2023-08-03 08:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 08:56:47 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.159, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.172, total=4090.99, n_correct=2542.72, ppl=5, accuracy=62.154, wps=8249, ups=1.01, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=15824
2023-08-03 08:57:42 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.152, trans_loss=5.093, nll_loss=2.31, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.083, total=4115.56, n_correct=2562.73, ppl=4.96, accuracy=62.269, wps=14814.2, ups=1.8, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=15879
2023-08-03 08:58:38 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.143, trans_loss=5.091, nll_loss=2.307, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.073, total=4182.19, n_correct=2614.6, ppl=4.95, accuracy=62.517, wps=15032.5, ups=1.8, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=15935
2023-08-03 08:59:34 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.147, trans_loss=5.086, nll_loss=2.301, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.102, total=4172.52, n_correct=2599.67, ppl=4.93, accuracy=62.305, wps=14876.5, ups=1.78, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=15991
2023-08-03 09:00:30 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.154, trans_loss=5.098, nll_loss=2.316, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.187, total=4076.84, n_correct=2530.81, ppl=4.98, accuracy=62.078, wps=14659.9, ups=1.8, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=16046
2023-08-03 09:01:25 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.152, trans_loss=5.096, nll_loss=2.315, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.104, total=4156.05, n_correct=2584.44, ppl=4.98, accuracy=62.185, wps=14928.9, ups=1.8, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=55, gb_free=12.3, wall=16102
2023-08-03 09:02:22 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.159, trans_loss=5.097, nll_loss=2.315, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.15, total=4118.87, n_correct=2561.57, ppl=4.98, accuracy=62.191, wps=14688.1, ups=1.78, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=16158
2023-08-03 09:03:18 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.152, trans_loss=5.103, nll_loss=2.324, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.085, total=4176.64, n_correct=2596.3, ppl=5.01, accuracy=62.162, wps=14835.1, ups=1.78, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=56, gb_free=14.4, wall=16215
2023-08-03 09:04:13 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.158, trans_loss=5.111, nll_loss=2.335, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.079, total=4056.99, n_correct=2512.21, ppl=5.05, accuracy=61.923, wps=14617.7, ups=1.8, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=16270
2023-08-03 09:05:09 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.154, trans_loss=5.104, nll_loss=2.326, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.164, total=4134.44, n_correct=2572.52, ppl=5.01, accuracy=62.222, wps=14823.1, ups=1.79, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=55, gb_free=16.3, wall=16326
2023-08-03 09:06:06 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.175, trans_loss=5.112, nll_loss=2.337, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.325, total=4185.02, n_correct=2591.23, ppl=5.05, accuracy=61.917, wps=14847.7, ups=1.77, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=56, gb_free=17, wall=16382
2023-08-03 09:07:02 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.145, trans_loss=5.097, nll_loss=2.32, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.129, total=4187.68, n_correct=2620.75, ppl=4.99, accuracy=62.582, wps=14918.4, ups=1.78, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=16438
2023-08-03 09:07:57 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.16, trans_loss=5.111, nll_loss=2.335, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.083, total=4141.6, n_correct=2567.87, ppl=5.05, accuracy=62.002, wps=14858.6, ups=1.79, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=55, gb_free=13.9, wall=16494
2023-08-03 09:08:53 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.149, trans_loss=5.109, nll_loss=2.332, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.067, total=4099.6, n_correct=2547.98, ppl=5.04, accuracy=62.152, wps=14661, ups=1.79, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=55, gb_free=14.8, wall=16550
2023-08-03 09:08:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:09:16 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.603 | nll_loss 2.886 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2457.6 | ppl 7.39 | accuracy 61.388 | uer 17.567 | wer 19.183 | raw_wer 19.183 | bleu 19.5 | wps 2167.2 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.69
2023-08-03 09:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-03 09:09:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_15_22000.pt
2023-08-03 09:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_15_22000.pt
2023-08-03 09:09:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.5) (writing took 40.27636295557022 seconds)
2023-08-03 09:10:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:11:15 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.381 | trans_loss 5.599 | nll_loss 2.885 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2454.4 | ppl 7.39 | accuracy 61.308 | uer 17.933 | wer 19.649 | raw_wer 19.649 | bleu 19.67 | wps 2416.1 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.69
2023-08-03 09:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-03 09:11:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.6700.pt
2023-08-03 09:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.6700.pt
2023-08-03 09:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.6700.pt (epoch 15 @ 22099 updates, score 19.67) (writing took 13.502699872478843 seconds)
2023-08-03 09:11:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-03 09:11:29 | INFO | train | epoch 015 | loss 2.154 | trans_loss 5.101 | nll_loss 2.321 | w2v_ctc_loss 0.749 | task_loss 0 | contrastive_loss 0.133 | total 4138.65 | n_correct 2574.23 | ppl 5 | accuracy 62.2 | wps 13098.4 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.585 | clip 0 | loss_scale 16 | train_wall 817 | gb_free 17.1 | wall 16706
2023-08-03 09:11:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 09:11:29 | INFO | fairseq.trainer | begin training epoch 16
2023-08-03 09:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 09:11:37 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.163, trans_loss=5.113, nll_loss=2.34, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.162, total=4149.9, n_correct=2573.42, ppl=5.06, accuracy=62.012, wps=5076.5, ups=0.61, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=56, gb_free=17.8, wall=16714
2023-08-03 09:12:32 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.136, trans_loss=5.07, nll_loss=2.281, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.103, total=4118.73, n_correct=2587.14, ppl=4.86, accuracy=62.814, wps=14823.9, ups=1.8, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=16769
2023-08-03 09:13:28 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.129, trans_loss=5.068, nll_loss=2.278, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.075, total=4106.45, n_correct=2583.65, ppl=4.85, accuracy=62.917, wps=14756.8, ups=1.8, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=16825
2023-08-03 09:14:24 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.145, trans_loss=5.079, nll_loss=2.293, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.15, total=4169.65, n_correct=2614.72, ppl=4.9, accuracy=62.708, wps=14819.5, ups=1.78, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=11.4, wall=16881
2023-08-03 09:15:20 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.146, trans_loss=5.081, nll_loss=2.294, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.163, total=4063.79, n_correct=2540.94, ppl=4.9, accuracy=62.526, wps=14522.2, ups=1.79, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=55, gb_free=13.2, wall=16937
2023-08-03 09:16:17 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.138, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.11, total=4179.53, n_correct=2627.3, ppl=4.89, accuracy=62.861, wps=14840.7, ups=1.78, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=16993
2023-08-03 09:17:12 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.136, trans_loss=5.082, nll_loss=2.297, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.069, total=4121.37, n_correct=2580.8, ppl=4.91, accuracy=62.62, wps=14837.2, ups=1.8, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=17049
2023-08-03 09:18:08 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.14, trans_loss=5.087, nll_loss=2.303, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.071, total=4099.17, n_correct=2563.97, ppl=4.94, accuracy=62.549, wps=14747.6, ups=1.8, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=17104
2023-08-03 09:19:04 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.142, trans_loss=5.087, nll_loss=2.305, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.135, total=4184.53, n_correct=2615.3, ppl=4.94, accuracy=62.499, wps=15012.7, ups=1.79, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=13.9, wall=17160
2023-08-03 09:20:00 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.141, trans_loss=5.085, nll_loss=2.303, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.126, total=4151.84, n_correct=2601.76, ppl=4.94, accuracy=62.665, wps=14821.9, ups=1.78, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=17216
2023-08-03 09:20:55 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.152, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.125, total=4112.79, n_correct=2559.52, ppl=4.98, accuracy=62.233, wps=14780.6, ups=1.8, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=15.3, wall=17272
2023-08-03 09:21:52 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.153, trans_loss=5.104, nll_loss=2.326, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.101, total=4111.6, n_correct=2553.89, ppl=5.01, accuracy=62.114, wps=14614, ups=1.78, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=17328
2023-08-03 09:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 09:22:49 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.138, trans_loss=5.093, nll_loss=2.313, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.08, total=4137.51, n_correct=2584.44, ppl=4.97, accuracy=62.464, wps=14382, ups=1.74, wpb=8275, bsz=299.7, num_updates=23300, lr=9.26482e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=57, gb_free=15.9, wall=17386
2023-08-03 09:23:46 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.153, trans_loss=5.096, nll_loss=2.317, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.173, total=4149.14, n_correct=2592.17, ppl=4.98, accuracy=62.475, wps=14697, ups=1.77, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=56, gb_free=11.9, wall=17442
2023-08-03 09:24:42 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.15, trans_loss=5.099, nll_loss=2.322, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.107, total=4200.01, n_correct=2617.55, ppl=5, accuracy=62.322, wps=14996.6, ups=1.79, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=55, gb_free=17.2, wall=17498
2023-08-03 09:25:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:25:46 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.595 | nll_loss 2.88 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2461.2 | ppl 7.36 | accuracy 61.478 | uer 17.819 | wer 19.406 | raw_wer 19.406 | bleu 20.03 | wps 2109.6 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 20.03
2023-08-03 09:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-08-03 09:25:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 16 @ 23572 updates, score 20.03) (writing took 23.408246966078877 seconds)
2023-08-03 09:26:10 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-03 09:26:10 | INFO | train | epoch 016 | loss 2.143 | trans_loss 5.086 | nll_loss 2.303 | w2v_ctc_loss 0.741 | task_loss 0 | contrastive_loss 0.123 | total 4137.02 | n_correct 2587.43 | ppl 4.94 | accuracy 62.543 | wps 13837.7 | ups 1.67 | wpb 8274 | bsz 305.1 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.587 | clip 0 | loss_scale 16 | train_wall 818 | gb_free 15.8 | wall 17586
2023-08-03 09:26:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 09:26:10 | INFO | fairseq.trainer | begin training epoch 17
2023-08-03 09:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 09:26:34 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.145, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.243, total=4141.79, n_correct=2592.59, ppl=4.91, accuracy=62.596, wps=7370.4, ups=0.89, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=17611
2023-08-03 09:27:30 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.126, trans_loss=5.055, nll_loss=2.262, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.075, total=4110.88, n_correct=2594.21, ppl=4.8, accuracy=63.106, wps=14627.8, ups=1.78, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=17667
2023-08-03 09:28:27 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.136, trans_loss=5.057, nll_loss=2.265, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.245, total=4171.95, n_correct=2630.06, ppl=4.81, accuracy=63.042, wps=14758, ups=1.77, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=17723
2023-08-03 09:29:24 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.137, trans_loss=5.067, nll_loss=2.277, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.243, total=4157.94, n_correct=2613.97, ppl=4.85, accuracy=62.867, wps=14642.7, ups=1.76, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=56, gb_free=14.9, wall=17780
2023-08-03 09:30:20 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.125, trans_loss=5.065, nll_loss=2.276, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.074, total=4141.8, n_correct=2613.81, ppl=4.84, accuracy=63.108, wps=14615.3, ups=1.76, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=17837
2023-08-03 09:30:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:30:42 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.595 | nll_loss 2.878 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2459.5 | ppl 7.35 | accuracy 61.435 | uer 17.655 | wer 19.172 | raw_wer 19.172 | bleu 19.66 | wps 2406.8 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.03
2023-08-03 09:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-03 09:30:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_17_24000.pt
2023-08-03 09:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_17_24000.pt
2023-08-03 09:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.66) (writing took 20.733450651168823 seconds)
2023-08-03 09:32:01 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.133, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.122, total=4180.09, n_correct=2628.29, ppl=4.86, accuracy=62.876, wps=8312.7, ups=0.99, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=17937
2023-08-03 09:32:57 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.128, trans_loss=5.073, nll_loss=2.286, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.069, total=4166.6, n_correct=2621.51, ppl=4.88, accuracy=62.917, wps=14803.5, ups=1.78, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=56, gb_free=16, wall=17994
2023-08-03 09:33:54 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.142, trans_loss=5.079, nll_loss=2.294, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.123, total=4168.97, n_correct=2612.74, ppl=4.91, accuracy=62.671, wps=14737.3, ups=1.77, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=18050
2023-08-03 09:34:50 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.132, trans_loss=5.078, nll_loss=2.291, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.083, total=4097.38, n_correct=2571.67, ppl=4.89, accuracy=62.764, wps=14443.5, ups=1.76, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=56, gb_free=11.2, wall=18107
2023-08-03 09:35:46 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.128, trans_loss=5.075, nll_loss=2.29, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.08, total=4105.01, n_correct=2576.61, ppl=4.89, accuracy=62.767, wps=14638.3, ups=1.78, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=18163
2023-08-03 09:36:43 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.132, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.085, total=4105.88, n_correct=2581.27, ppl=4.89, accuracy=62.868, wps=14625.2, ups=1.78, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=18219
2023-08-03 09:37:39 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.128, trans_loss=5.075, nll_loss=2.29, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.075, total=4095.58, n_correct=2575.46, ppl=4.89, accuracy=62.884, wps=14631.8, ups=1.79, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=18275
2023-08-03 09:38:36 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.153, trans_loss=5.086, nll_loss=2.304, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.321, total=4162.14, n_correct=2602.25, ppl=4.94, accuracy=62.522, wps=14508.7, ups=1.74, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=57, gb_free=16.3, wall=18333
2023-08-03 09:39:33 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.138, trans_loss=5.085, nll_loss=2.303, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.156, total=4149.03, n_correct=2597.42, ppl=4.94, accuracy=62.603, wps=14640.7, ups=1.76, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=18389
2023-08-03 09:40:29 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.131, trans_loss=5.083, nll_loss=2.3, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.074, total=4117.13, n_correct=2583.31, ppl=4.93, accuracy=62.745, wps=14575.9, ups=1.77, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=56, gb_free=17.8, wall=18446
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 09:40:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
2023-08-03 09:41:18 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.59 | nll_loss 2.878 | w2v_ctc_loss 1.375 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2463.7 | ppl 7.35 | accuracy 61.54 | uer 17.631 | wer 19.246 | raw_wer 19.246 | bleu 20.04 | wps 2235.3 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.04
2023-08-03 09:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-03 09:41:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 17 @ 25046 updates, score 20.04) (writing took 22.30526159889996 seconds)
2023-08-03 09:41:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-03 09:41:41 | INFO | train | epoch 017 | loss 2.133 | trans_loss 5.073 | nll_loss 2.286 | w2v_ctc_loss 0.73 | task_loss 0 | contrastive_loss 0.129 | total 4138.65 | n_correct 2600.73 | ppl 4.88 | accuracy 62.84 | wps 13097.6 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.587 | clip 0 | loss_scale 16 | train_wall 826 | gb_free 16.6 | wall 18518
2023-08-03 09:41:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 09:41:42 | INFO | fairseq.trainer | begin training epoch 18
2023-08-03 09:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 09:42:21 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.129, trans_loss=5.067, nll_loss=2.279, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.085, total=4138.21, n_correct=2605.42, ppl=4.85, accuracy=62.96, wps=7423.6, ups=0.9, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=57, gb_free=18, wall=18557
2023-08-03 09:43:17 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.121, trans_loss=5.042, nll_loss=2.246, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.21, total=4158.88, n_correct=2636.86, ppl=4.74, accuracy=63.403, wps=14661.4, ups=1.76, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=18614
2023-08-03 09:44:14 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.11, trans_loss=5.04, nll_loss=2.244, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.076, total=4164.11, n_correct=2648.88, ppl=4.74, accuracy=63.612, wps=14607.9, ups=1.75, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=18671
2023-08-03 09:45:11 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.119, trans_loss=5.051, nll_loss=2.257, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.091, total=4163.13, n_correct=2633.18, ppl=4.78, accuracy=63.25, wps=14687.5, ups=1.76, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=18728
2023-08-03 09:46:09 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.128, trans_loss=5.059, nll_loss=2.267, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.18, total=4087.83, n_correct=2578.13, ppl=4.81, accuracy=63.068, wps=14209.1, ups=1.74, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=18785
2023-08-03 09:47:05 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.111, trans_loss=5.042, nll_loss=2.248, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.092, total=4204.41, n_correct=2672.61, ppl=4.75, accuracy=63.567, wps=14822.3, ups=1.76, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=18842
2023-08-03 09:48:03 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.131, trans_loss=5.068, nll_loss=2.28, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.159, total=4096.81, n_correct=2581.16, ppl=4.86, accuracy=63.004, wps=14292.1, ups=1.74, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=18899
2023-08-03 09:49:00 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.139, trans_loss=5.065, nll_loss=2.277, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.253, total=4208.29, n_correct=2650.28, ppl=4.85, accuracy=62.978, wps=14722.7, ups=1.75, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=57, gb_free=18.1, wall=18957
2023-08-03 09:49:57 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.12, trans_loss=5.064, nll_loss=2.275, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.065, total=4166.81, n_correct=2629.99, ppl=4.84, accuracy=63.118, wps=14590.6, ups=1.75, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=19014
2023-08-03 09:50:54 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.115, trans_loss=5.055, nll_loss=2.265, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.092, total=4142.65, n_correct=2625.51, ppl=4.81, accuracy=63.378, wps=14590.7, ups=1.76, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=19070
2023-08-03 09:50:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:51:17 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.381 | trans_loss 5.602 | nll_loss 2.887 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2459.7 | ppl 7.4 | accuracy 61.44 | uer 17.747 | wer 19.399 | raw_wer 19.399 | bleu 20.06 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.06
2023-08-03 09:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-03 09:51:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_18_26000.pt
2023-08-03 09:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_18_26000.pt
2023-08-03 09:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.06) (writing took 43.57743442803621 seconds)
2023-08-03 09:53:00 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.12, trans_loss=5.065, nll_loss=2.277, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.079, total=4137.77, n_correct=2612.23, ppl=4.85, accuracy=63.131, wps=6568.7, ups=0.79, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.616, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=19196
2023-08-03 09:53:57 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.126, trans_loss=5.054, nll_loss=2.263, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.185, total=4153.69, n_correct=2628.03, ppl=4.8, accuracy=63.27, wps=14605.6, ups=1.76, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=19253
2023-08-03 09:54:54 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.122, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.07, total=4087.62, n_correct=2571.28, ppl=4.88, accuracy=62.904, wps=14308.8, ups=1.75, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=19310
2023-08-03 09:55:51 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.136, trans_loss=5.081, nll_loss=2.297, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.097, total=4070.69, n_correct=2555.29, ppl=4.92, accuracy=62.773, wps=14296.5, ups=1.76, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=19367
2023-08-03 09:56:48 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.127, trans_loss=5.074, nll_loss=2.289, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.083, total=4113.2, n_correct=2584.69, ppl=4.89, accuracy=62.839, wps=14417.3, ups=1.75, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=19424
2023-08-03 09:56:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 09:57:22 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.585 | nll_loss 2.87 | w2v_ctc_loss 1.433 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2461.3 | ppl 7.31 | accuracy 61.48 | uer 17.463 | wer 19.138 | raw_wer 19.138 | bleu 20.07 | wps 2311.3 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.07
2023-08-03 09:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-03 09:57:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 09:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 18 @ 26520 updates, score 20.07) (writing took 23.364679235965014 seconds)
2023-08-03 09:57:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-03 09:57:46 | INFO | train | epoch 018 | loss 2.123 | trans_loss 5.059 | nll_loss 2.269 | w2v_ctc_loss 0.72 | task_loss 0 | contrastive_loss 0.127 | total 4138.65 | n_correct 2614.22 | ppl 4.82 | accuracy 63.166 | wps 12652.5 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.589 | clip 0 | loss_scale 32 | train_wall 833 | gb_free 16.2 | wall 19482
2023-08-03 09:57:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 09:57:46 | INFO | fairseq.trainer | begin training epoch 19
2023-08-03 09:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 09:58:39 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.112, trans_loss=5.035, nll_loss=2.237, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.13, total=4102.06, n_correct=2604.75, ppl=4.71, accuracy=63.499, wps=7379.7, ups=0.9, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=19536
2023-08-03 09:59:36 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.112, trans_loss=5.027, nll_loss=2.228, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.129, total=4227.7, n_correct=2697.44, ppl=4.68, accuracy=63.804, wps=14723.4, ups=1.74, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=19593
2023-08-03 10:00:33 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.104, trans_loss=5.031, nll_loss=2.232, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.067, total=4187.34, n_correct=2674.33, ppl=4.7, accuracy=63.867, wps=14742, ups=1.76, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=19650
2023-08-03 10:01:30 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.113, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.178, total=4170.52, n_correct=2653.65, ppl=4.72, accuracy=63.629, wps=14622.4, ups=1.75, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=19707
2023-08-03 10:02:27 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.112, trans_loss=5.044, nll_loss=2.249, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.085, total=4113.89, n_correct=2614.29, ppl=4.75, accuracy=63.548, wps=14583.3, ups=1.77, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=19763
2023-08-03 10:03:24 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.111, trans_loss=5.04, nll_loss=2.244, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.148, total=4128.58, n_correct=2628.72, ppl=4.74, accuracy=63.671, wps=14516, ups=1.76, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=19820
2023-08-03 10:04:21 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.1, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.074, total=4201.56, n_correct=2676.84, ppl=4.74, accuracy=63.711, wps=14761.5, ups=1.76, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=18.1, wall=19877
2023-08-03 10:05:18 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.111, trans_loss=5.044, nll_loss=2.248, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.081, total=4124.03, n_correct=2618.91, ppl=4.75, accuracy=63.504, wps=14383.9, ups=1.74, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=19935
2023-08-03 10:05:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 10:06:15 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.117, trans_loss=5.056, nll_loss=2.265, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.074, total=4163.69, n_correct=2633.28, ppl=4.81, accuracy=63.244, wps=14483.3, ups=1.74, wpb=8327.4, bsz=306.4, num_updates=27400, lr=8.54358e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=19992
2023-08-03 10:07:13 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.134, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.306, total=4101.29, n_correct=2587.2, ppl=4.84, accuracy=63.083, wps=14160, ups=1.73, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=20050
2023-08-03 10:08:11 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.121, trans_loss=5.066, nll_loss=2.278, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.114, total=4036.97, n_correct=2548.89, ppl=4.85, accuracy=63.139, wps=14112.4, ups=1.75, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=57, gb_free=15.1, wall=20107
2023-08-03 10:09:08 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.133, trans_loss=5.066, nll_loss=2.279, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.197, total=4137.49, n_correct=2607.23, ppl=4.85, accuracy=63.015, wps=14354.8, ups=1.73, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=20165
2023-08-03 10:10:05 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.116, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.095, total=4141.89, n_correct=2619.02, ppl=4.84, accuracy=63.232, wps=14708.4, ups=1.78, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=20221
2023-08-03 10:11:02 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.115, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.08, total=4133.26, n_correct=2616.08, ppl=4.82, accuracy=63.293, wps=14497.8, ups=1.75, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=20278
2023-08-03 10:11:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 10:12:17 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.58 | nll_loss 2.861 | w2v_ctc_loss 1.385 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2468.8 | ppl 7.27 | accuracy 61.668 | uer 17.304 | wer 19 | raw_wer 19 | bleu 20.03 | wps 2417.7 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.07
2023-08-03 10:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-03 10:12:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0306.pt
2023-08-03 10:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0306.pt
2023-08-03 10:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0306.pt (epoch 19 @ 27993 updates, score 20.03) (writing took 22.690245520323515 seconds)
2023-08-03 10:12:40 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-03 10:12:40 | INFO | train | epoch 019 | loss 2.115 | trans_loss 5.048 | nll_loss 2.255 | w2v_ctc_loss 0.714 | task_loss 0 | contrastive_loss 0.125 | total 4138.38 | n_correct 2625.69 | ppl 4.77 | accuracy 63.447 | wps 13631 | ups 1.65 | wpb 8276.8 | bsz 305.6 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.59 | clip 0 | loss_scale 32 | train_wall 833 | gb_free 17.7 | wall 20377
2023-08-03 10:12:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 10:12:40 | INFO | fairseq.trainer | begin training epoch 20
2023-08-03 10:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 10:12:53 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.116, trans_loss=5.053, nll_loss=2.262, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.162, total=4119.08, n_correct=2611.93, ppl=4.8, accuracy=63.411, wps=7419.3, ups=0.9, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=20389
2023-08-03 10:12:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 10:13:15 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.578 | nll_loss 2.856 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2474 | ppl 7.24 | accuracy 61.797 | uer 17.217 | wer 18.974 | raw_wer 18.974 | bleu 19.85 | wps 2362.8 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.07
2023-08-03 10:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-03 10:13:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_20_28000.pt
2023-08-03 10:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_20_28000.pt
2023-08-03 10:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.85) (writing took 34.317494263872504 seconds)
2023-08-03 10:14:51 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.093, trans_loss=5.014, nll_loss=2.21, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.089, total=4195.03, n_correct=2689.43, ppl=4.63, accuracy=64.11, wps=7098.6, ups=0.85, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=20507
2023-08-03 10:15:48 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.101, trans_loss=5.023, nll_loss=2.222, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.139, total=4154.14, n_correct=2654.86, ppl=4.66, accuracy=63.909, wps=14601.3, ups=1.76, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=20564
2023-08-03 10:15:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 10:16:45 | INFO | train_inner | epoch 020:    308 / 1474 loss=2.097, trans_loss=5.019, nll_loss=2.218, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.079, total=4184.36, n_correct=2684.2, ppl=4.65, accuracy=64.148, wps=14561.5, ups=1.74, wpb=8368.7, bsz=325.4, num_updates=28300, lr=8.40663e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=20622
2023-08-03 10:17:42 | INFO | train_inner | epoch 020:    408 / 1474 loss=2.093, trans_loss=5.022, nll_loss=2.22, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.074, total=4114.19, n_correct=2635.25, ppl=4.66, accuracy=64.053, wps=14481.4, ups=1.76, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=20679
2023-08-03 10:18:39 | INFO | train_inner | epoch 020:    508 / 1474 loss=2.107, trans_loss=5.037, nll_loss=2.24, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.163, total=4108.2, n_correct=2618.41, ppl=4.73, accuracy=63.736, wps=14356.8, ups=1.75, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=20736
2023-08-03 10:19:36 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.114, trans_loss=5.039, nll_loss=2.243, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.168, total=4092.44, n_correct=2601.4, ppl=4.73, accuracy=63.566, wps=14514.3, ups=1.77, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=56, gb_free=17.9, wall=20792
2023-08-03 10:20:32 | INFO | train_inner | epoch 020:    708 / 1474 loss=2.104, trans_loss=5.038, nll_loss=2.24, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.067, total=4137.06, n_correct=2634.98, ppl=4.73, accuracy=63.692, wps=14609.7, ups=1.77, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=20849
2023-08-03 10:21:30 | INFO | train_inner | epoch 020:    808 / 1474 loss=2.104, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.073, total=4146.78, n_correct=2645.24, ppl=4.73, accuracy=63.79, wps=14470.1, ups=1.74, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=57, gb_free=15.6, wall=20906
2023-08-03 10:22:28 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.133, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.367, total=4161, n_correct=2638.44, ppl=4.77, accuracy=63.409, wps=14368.2, ups=1.73, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=20964
2023-08-03 10:23:25 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.103, trans_loss=5.041, nll_loss=2.246, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.077, total=4168.14, n_correct=2653.35, ppl=4.74, accuracy=63.658, wps=14575.4, ups=1.75, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=21021
2023-08-03 10:24:22 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.118, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.218, total=4166.49, n_correct=2648.57, ppl=4.77, accuracy=63.568, wps=14591.3, ups=1.75, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=57, gb_free=15.1, wall=21078
2023-08-03 10:25:19 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.109, trans_loss=5.043, nll_loss=2.249, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.065, total=4029.18, n_correct=2560.66, ppl=4.75, accuracy=63.553, wps=14077.9, ups=1.75, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=57, gb_free=12.4, wall=21136
2023-08-03 10:26:17 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.105, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.071, total=4123.21, n_correct=2620.78, ppl=4.77, accuracy=63.562, wps=14288.2, ups=1.73, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=21193
2023-08-03 10:27:14 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.106, trans_loss=5.048, nll_loss=2.256, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.069, total=4116.28, n_correct=2611.88, ppl=4.78, accuracy=63.452, wps=14499.6, ups=1.76, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=17.8, wall=21250
2023-08-03 10:27:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 10:28:13 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.575 | nll_loss 2.854 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2465.3 | ppl 7.23 | accuracy 61.58 | uer 17.248 | wer 19.075 | raw_wer 19.075 | bleu 19.5 | wps 2390.3 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.07
2023-08-03 10:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-03 10:28:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 10:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 10:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt (epoch 20 @ 29466 updates, score 19.5) (writing took 13.239260852336884 seconds)
2023-08-03 10:28:26 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-03 10:28:26 | INFO | train | epoch 020 | loss 2.106 | trans_loss 5.036 | nll_loss 2.24 | w2v_ctc_loss 0.706 | task_loss 0 | contrastive_loss 0.124 | total 4138.37 | n_correct 2637.27 | ppl 4.72 | accuracy 63.727 | wps 12888.4 | ups 1.56 | wpb 8276.7 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.593 | clip 0 | loss_scale 16 | train_wall 833 | gb_free 16.4 | wall 21323
2023-08-03 10:28:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 10:28:26 | INFO | fairseq.trainer | begin training epoch 21
2023-08-03 10:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 10:28:54 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.113, trans_loss=5.039, nll_loss=2.245, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.193, total=4152.26, n_correct=2643.63, ppl=4.74, accuracy=63.667, wps=8267.1, ups=1, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.595, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=21351
2023-08-03 10:29:51 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.098, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.186, total=4195.08, n_correct=2692.74, ppl=4.61, accuracy=64.188, wps=14663.5, ups=1.75, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.641, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=21408
2023-08-03 10:30:49 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.086, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.136, total=4155.31, n_correct=2673.32, ppl=4.62, accuracy=64.335, wps=14513.8, ups=1.75, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=57, gb_free=17, wall=21465
2023-08-03 10:31:47 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.097, trans_loss=5.015, nll_loss=2.212, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.142, total=4151.51, n_correct=2660.43, ppl=4.63, accuracy=64.083, wps=14249.7, ups=1.72, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=58, gb_free=15.8, wall=21523
2023-08-03 10:32:46 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.085, trans_loss=5.015, nll_loss=2.21, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.063, total=4180.85, n_correct=2685.5, ppl=4.63, accuracy=64.233, wps=14035.6, ups=1.68, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=59, gb_free=16.1, wall=21583
2023-08-03 10:33:45 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.088, trans_loss=5.013, nll_loss=2.209, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.062, total=4083.98, n_correct=2621.35, ppl=4.62, accuracy=64.186, wps=13897.8, ups=1.7, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.608, clip=0, loss_scale=16, train_wall=58, gb_free=13.5, wall=21642
2023-08-03 10:33:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 10:34:10 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.592 | nll_loss 2.875 | w2v_ctc_loss 1.325 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2467.5 | ppl 7.33 | accuracy 61.635 | uer 17.299 | wer 18.881 | raw_wer 18.881 | bleu 19.79 | wps 2073.9 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.07
2023-08-03 10:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-03 10:34:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_21_30000.pt
2023-08-03 10:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_21_30000.pt
2023-08-03 10:34:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.79) (writing took 38.457544688135386 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 10:35:50 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.103, trans_loss=5.024, nll_loss=2.224, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.236, total=4215.41, n_correct=2696.02, ppl=4.67, accuracy=63.956, wps=6763.1, ups=0.8, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=60, gb_free=11.9, wall=21766
2023-08-03 10:36:49 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.1, trans_loss=5.032, nll_loss=2.235, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.098, total=4152.97, n_correct=2653.67, ppl=4.71, accuracy=63.898, wps=14090.1, ups=1.7, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=58, gb_free=16.6, wall=21825
2023-08-03 10:37:46 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.101, trans_loss=5.035, nll_loss=2.238, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.108, total=4066.93, n_correct=2599.19, ppl=4.72, accuracy=63.91, wps=14262.1, ups=1.75, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=21882
2023-08-03 10:38:43 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.095, trans_loss=5.027, nll_loss=2.228, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.083, total=4103.34, n_correct=2618.73, ppl=4.68, accuracy=63.819, wps=14317, ups=1.74, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=57, gb_free=14.4, wall=21940
2023-08-03 10:39:40 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.101, trans_loss=5.042, nll_loss=2.247, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.079, total=4099.86, n_correct=2612.36, ppl=4.75, accuracy=63.718, wps=14433.7, ups=1.76, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.613, clip=0, loss_scale=32, train_wall=56, gb_free=12, wall=21997
2023-08-03 10:40:37 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.101, trans_loss=5.035, nll_loss=2.238, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.083, total=4120.75, n_correct=2629.75, ppl=4.72, accuracy=63.817, wps=14491.5, ups=1.76, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=22053
2023-08-03 10:41:34 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.101, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.136, total=4154.73, n_correct=2651.78, ppl=4.71, accuracy=63.826, wps=14570.3, ups=1.75, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=22110
2023-08-03 10:42:31 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.101, trans_loss=5.035, nll_loss=2.241, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.096, total=4147.17, n_correct=2645.16, ppl=4.73, accuracy=63.782, wps=14420.1, ups=1.74, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=22168
2023-08-03 10:43:28 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.117, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.147, total=4133.93, n_correct=2623.73, ppl=4.76, accuracy=63.468, wps=14481.7, ups=1.75, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=22225
2023-08-03 10:43:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
2023-08-03 10:44:15 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.593 | nll_loss 2.878 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2467.7 | ppl 7.35 | accuracy 61.64 | uer 17.517 | wer 19.459 | raw_wer 19.459 | bleu 19.53 | wps 2077.4 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.07
2023-08-03 10:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-03 10:44:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 10:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 10:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt (epoch 21 @ 30940 updates, score 19.53) (writing took 12.594027139246464 seconds)
2023-08-03 10:44:27 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-03 10:44:27 | INFO | train | epoch 021 | loss 2.099 | trans_loss 5.027 | nll_loss 2.227 | w2v_ctc_loss 0.697 | task_loss 0 | contrastive_loss 0.123 | total 4138.65 | n_correct 2646.18 | ppl 4.68 | accuracy 63.938 | wps 12689.6 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.599 | clip 0 | loss_scale 32 | train_wall 844 | gb_free 15.7 | wall 22284
2023-08-03 10:44:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 10:44:28 | INFO | fairseq.trainer | begin training epoch 22
2023-08-03 10:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 10:45:10 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.087, trans_loss=5.012, nll_loss=2.209, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.061, total=4128.84, n_correct=2655.22, ppl=4.62, accuracy=64.309, wps=8124.5, ups=0.98, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=56, gb_free=14.6, wall=22327
2023-08-03 10:46:07 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.09, trans_loss=5.002, nll_loss=2.195, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.149, total=4123.35, n_correct=2652.64, ppl=4.58, accuracy=64.332, wps=14543.3, ups=1.76, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=22383
2023-08-03 10:47:05 | INFO | train_inner | epoch 022:    260 / 1474 loss=2.076, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.088, total=4267.16, n_correct=2758.75, ppl=4.56, accuracy=64.651, wps=14763.5, ups=1.73, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=22441
2023-08-03 10:47:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 10:48:03 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.096, trans_loss=5.011, nll_loss=2.206, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.186, total=4163.56, n_correct=2672.81, ppl=4.62, accuracy=64.195, wps=14350.1, ups=1.72, wpb=8327.1, bsz=304, num_updates=31300, lr=7.99361e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=58, gb_free=15.5, wall=22499
2023-08-03 10:49:00 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.094, trans_loss=5.017, nll_loss=2.213, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.129, total=4132.96, n_correct=2651.4, ppl=4.64, accuracy=64.153, wps=14449.3, ups=1.75, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=22557
2023-08-03 10:49:58 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.086, trans_loss=5.008, nll_loss=2.204, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.076, total=4158.17, n_correct=2676.27, ppl=4.61, accuracy=64.362, wps=14369.3, ups=1.73, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=57, gb_free=16.9, wall=22614
2023-08-03 10:50:59 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.083, trans_loss=5.005, nll_loss=2.2, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.156, total=4139.66, n_correct=2667.36, ppl=4.6, accuracy=64.434, wps=13516.5, ups=1.63, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=22676
2023-08-03 10:51:59 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.087, trans_loss=5.013, nll_loss=2.209, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.077, total=4167.89, n_correct=2677.62, ppl=4.62, accuracy=64.244, wps=13865.2, ups=1.66, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=60, gb_free=13.3, wall=22736
2023-08-03 10:53:00 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.094, trans_loss=5.026, nll_loss=2.227, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.063, total=4075.79, n_correct=2605.32, ppl=4.68, accuracy=63.922, wps=13410.3, ups=1.65, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.649, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=22797
2023-08-03 10:53:57 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.085, trans_loss=5.018, nll_loss=2.216, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.064, total=4134.72, n_correct=2654.19, ppl=4.65, accuracy=64.193, wps=14440.7, ups=1.75, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.615, clip=0, loss_scale=16, train_wall=57, gb_free=14.7, wall=22854
2023-08-03 10:54:55 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.096, trans_loss=5.017, nll_loss=2.216, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.233, total=4160.57, n_correct=2670.93, ppl=4.64, accuracy=64.196, wps=14359.5, ups=1.73, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.595, clip=0, loss_scale=16, train_wall=57, gb_free=17.5, wall=22912
2023-08-03 10:54:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 10:55:19 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.586 | nll_loss 2.866 | w2v_ctc_loss 1.395 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2467 | ppl 7.29 | accuracy 61.623 | uer 17.474 | wer 19.086 | raw_wer 19.086 | bleu 19.87 | wps 2122.8 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.07
2023-08-03 10:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-03 10:55:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_22_32000.pt
2023-08-03 10:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_22_32000.pt
2023-08-03 10:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.87) (writing took 35.70667119696736 seconds)
2023-08-03 10:56:54 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.104, trans_loss=5.039, nll_loss=2.244, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.115, total=4099.59, n_correct=2612.59, ppl=4.74, accuracy=63.728, wps=6930.2, ups=0.85, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=56, gb_free=15.4, wall=23030
2023-08-03 10:57:50 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.099, trans_loss=5.031, nll_loss=2.236, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.114, total=4182.05, n_correct=2674.53, ppl=4.71, accuracy=63.953, wps=14682, ups=1.76, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.633, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=23087
2023-08-03 10:58:47 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.09, trans_loss=5.022, nll_loss=2.223, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.132, total=4062.31, n_correct=2605.17, ppl=4.67, accuracy=64.13, wps=14374.8, ups=1.77, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=15.4, wall=23144
2023-08-03 10:59:44 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.101, trans_loss=5.04, nll_loss=2.245, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.08, total=4081.88, n_correct=2600.59, ppl=4.74, accuracy=63.711, wps=14212.3, ups=1.74, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=57, gb_free=17.5, wall=23201
2023-08-03 10:59:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:00:16 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.576 | nll_loss 2.853 | w2v_ctc_loss 1.358 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2476.6 | ppl 7.22 | accuracy 61.862 | uer 17.325 | wer 19.049 | raw_wer 19.049 | bleu 19.96 | wps 2079.3 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.07
2023-08-03 11:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-03 11:00:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9608.pt
2023-08-03 11:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9608.pt
2023-08-03 11:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9608.pt (epoch 22 @ 32413 updates, score 19.96) (writing took 13.835666321218014 seconds)
2023-08-03 11:00:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-03 11:00:31 | INFO | train | epoch 022 | loss 2.091 | trans_loss 5.017 | nll_loss 2.215 | w2v_ctc_loss 0.692 | task_loss 0 | contrastive_loss 0.117 | total 4137.49 | n_correct 2655.38 | ppl 4.64 | accuracy 64.179 | wps 12654.7 | ups 1.53 | wpb 8275 | bsz 305.2 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.603 | clip 0 | loss_scale 16 | train_wall 846 | gb_free 12.2 | wall 23247
2023-08-03 11:00:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 11:00:31 | INFO | fairseq.trainer | begin training epoch 23
2023-08-03 11:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 11:01:32 | INFO | train_inner | epoch 023:     87 / 1474 loss=2.077, trans_loss=4.993, nll_loss=2.183, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.071, total=4096.09, n_correct=2648.51, ppl=4.54, accuracy=64.659, wps=7650.6, ups=0.93, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.609, clip=0, loss_scale=16, train_wall=59, gb_free=16.6, wall=23308
2023-08-03 11:02:29 | INFO | train_inner | epoch 023:    187 / 1474 loss=2.073, trans_loss=4.99, nll_loss=2.179, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.067, total=4107.77, n_correct=2655.08, ppl=4.53, accuracy=64.636, wps=14401.1, ups=1.75, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=23365
2023-08-03 11:03:26 | INFO | train_inner | epoch 023:    287 / 1474 loss=2.08, trans_loss=4.998, nll_loss=2.191, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.147, total=4153.12, n_correct=2678.77, ppl=4.57, accuracy=64.5, wps=14473, ups=1.74, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=57, gb_free=17.2, wall=23423
2023-08-03 11:04:23 | INFO | train_inner | epoch 023:    387 / 1474 loss=2.077, trans_loss=5, nll_loss=2.192, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.058, total=4116.7, n_correct=2658.39, ppl=4.57, accuracy=64.576, wps=14482, ups=1.76, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.64, clip=0, loss_scale=16, train_wall=56, gb_free=15.7, wall=23480
2023-08-03 11:05:20 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.086, trans_loss=5.004, nll_loss=2.198, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.12, total=4157.6, n_correct=2676.99, ppl=4.59, accuracy=64.388, wps=14645.5, ups=1.76, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=23536
2023-08-03 11:06:16 | INFO | train_inner | epoch 023:    587 / 1474 loss=2.071, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.064, total=4173.42, n_correct=2701.28, ppl=4.54, accuracy=64.726, wps=14718.7, ups=1.76, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=56, gb_free=13.1, wall=23593
2023-08-03 11:07:13 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.079, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.106, total=4137.82, n_correct=2670.65, ppl=4.57, accuracy=64.542, wps=14529.2, ups=1.76, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=56, gb_free=17.5, wall=23650
2023-08-03 11:08:11 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.086, trans_loss=5.012, nll_loss=2.208, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.086, total=4150.99, n_correct=2670.37, ppl=4.62, accuracy=64.331, wps=14500.2, ups=1.75, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=57, gb_free=16.5, wall=23707
2023-08-03 11:09:07 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.087, trans_loss=5.005, nll_loss=2.201, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.168, total=4181.99, n_correct=2697.31, ppl=4.6, accuracy=64.498, wps=14724.8, ups=1.76, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.595, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=23764
2023-08-03 11:10:05 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.094, trans_loss=5.009, nll_loss=2.205, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.316, total=4168.73, n_correct=2682.49, ppl=4.61, accuracy=64.348, wps=14502.6, ups=1.74, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=57, gb_free=11.5, wall=23822
2023-08-03 11:10:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 11:11:03 | INFO | train_inner | epoch 023:   1088 / 1474 loss=2.089, trans_loss=5.018, nll_loss=2.217, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.071, total=4079.38, n_correct=2616.8, ppl=4.65, accuracy=64.147, wps=14067.4, ups=1.72, wpb=8158.8, bsz=288.6, num_updates=33500, lr=7.72667e-05, gnorm=0.607, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=23880
2023-08-03 11:12:00 | INFO | train_inner | epoch 023:   1188 / 1474 loss=2.083, trans_loss=5.016, nll_loss=2.214, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.063, total=4164.9, n_correct=2676.17, ppl=4.64, accuracy=64.255, wps=14503.6, ups=1.74, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=57, gb_free=14.1, wall=23937
2023-08-03 11:12:57 | INFO | train_inner | epoch 023:   1288 / 1474 loss=2.079, trans_loss=5.013, nll_loss=2.212, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.077, total=4136.96, n_correct=2663.34, ppl=4.63, accuracy=64.379, wps=14561.7, ups=1.76, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=23994
2023-08-03 11:13:54 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.095, trans_loss=5.031, nll_loss=2.234, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.134, total=4142.84, n_correct=2651.42, ppl=4.71, accuracy=64, wps=14541.6, ups=1.76, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=24051
2023-08-03 11:14:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:15:06 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.578 | nll_loss 2.859 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2471.1 | ppl 7.25 | accuracy 61.725 | uer 17.073 | wer 18.661 | raw_wer 18.661 | bleu 19.98 | wps 2297.4 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 20.07
2023-08-03 11:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-03 11:15:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9803.pt
2023-08-03 11:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9803.pt
2023-08-03 11:15:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_19.9803.pt (epoch 23 @ 33886 updates, score 19.98) (writing took 16.977290669456124 seconds)
2023-08-03 11:15:24 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-03 11:15:24 | INFO | train | epoch 023 | loss 2.084 | trans_loss 5.007 | nll_loss 2.203 | w2v_ctc_loss 0.683 | task_loss 0 | contrastive_loss 0.119 | total 4138.16 | n_correct 2664.93 | ppl 4.6 | accuracy 64.399 | wps 13654.2 | ups 1.65 | wpb 8276.3 | bsz 305.6 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.601 | clip 0 | loss_scale 16 | train_wall 836 | gb_free 14.1 | wall 24140
2023-08-03 11:15:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 11:15:24 | INFO | fairseq.trainer | begin training epoch 24
2023-08-03 11:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 11:15:40 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.1, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.213, total=4084.21, n_correct=2615.19, ppl=4.68, accuracy=64.032, wps=7735.5, ups=0.95, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=57, gb_free=15.7, wall=24156
2023-08-03 11:16:37 | INFO | train_inner | epoch 024:    114 / 1474 loss=2.079, trans_loss=4.98, nll_loss=2.167, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.23, total=4168.61, n_correct=2705.05, ppl=4.49, accuracy=64.891, wps=14641.5, ups=1.76, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=56, gb_free=12, wall=24213
2023-08-03 11:16:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:17:01 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.358 | trans_loss 5.584 | nll_loss 2.862 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2468.9 | ppl 7.27 | accuracy 61.67 | uer 17.113 | wer 18.855 | raw_wer 18.855 | bleu 20.06 | wps 2048.7 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.07
2023-08-03 11:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-03 11:17:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_24_34000.pt
2023-08-03 11:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_24_34000.pt
2023-08-03 11:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.06) (writing took 24.144408321008086 seconds)
2023-08-03 11:18:23 | INFO | train_inner | epoch 024:    214 / 1474 loss=2.079, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.29, total=4252.53, n_correct=2760.3, ppl=4.49, accuracy=64.91, wps=7984.6, ups=0.94, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=24320
2023-08-03 11:19:20 | INFO | train_inner | epoch 024:    314 / 1474 loss=2.068, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.061, total=4138.44, n_correct=2684.84, ppl=4.52, accuracy=64.876, wps=14503.7, ups=1.75, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=57, gb_free=15.8, wall=24377
2023-08-03 11:20:19 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.089, trans_loss=4.994, nll_loss=2.185, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.21, total=4153.83, n_correct=2682.13, ppl=4.55, accuracy=64.57, wps=14249.5, ups=1.72, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=58, gb_free=16.4, wall=24435
2023-08-03 11:21:16 | INFO | train_inner | epoch 024:    514 / 1474 loss=2.075, trans_loss=4.991, nll_loss=2.182, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.13, total=4141.88, n_correct=2679.31, ppl=4.54, accuracy=64.688, wps=14480.6, ups=1.75, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=57, gb_free=15.5, wall=24492
2023-08-03 11:22:13 | INFO | train_inner | epoch 024:    614 / 1474 loss=2.07, trans_loss=4.992, nll_loss=2.184, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.097, total=4162.06, n_correct=2694.26, ppl=4.54, accuracy=64.734, wps=14560, ups=1.75, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=24550
2023-08-03 11:23:10 | INFO | train_inner | epoch 024:    714 / 1474 loss=2.077, trans_loss=5.003, nll_loss=2.197, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.104, total=4097.35, n_correct=2645.84, ppl=4.59, accuracy=64.574, wps=14401.9, ups=1.76, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=24607
2023-08-03 11:24:08 | INFO | train_inner | epoch 024:    814 / 1474 loss=2.079, trans_loss=5.007, nll_loss=2.204, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.086, total=4124.25, n_correct=2660.79, ppl=4.61, accuracy=64.516, wps=14116.2, ups=1.71, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.623, clip=0, loss_scale=16, train_wall=58, gb_free=16.2, wall=24665
2023-08-03 11:25:05 | INFO | train_inner | epoch 024:    914 / 1474 loss=2.08, trans_loss=5.011, nll_loss=2.206, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.054, total=4041.44, n_correct=2597.27, ppl=4.61, accuracy=64.266, wps=14225.7, ups=1.76, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=24722
2023-08-03 11:26:02 | INFO | train_inner | epoch 024:   1014 / 1474 loss=2.074, trans_loss=5.005, nll_loss=2.2, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.06, total=4128.8, n_correct=2664.56, ppl=4.6, accuracy=64.536, wps=14471.4, ups=1.75, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=57, gb_free=15.4, wall=24779
2023-08-03 11:26:59 | INFO | train_inner | epoch 024:   1114 / 1474 loss=2.078, trans_loss=4.996, nll_loss=2.189, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.106, total=4130.49, n_correct=2669.49, ppl=4.56, accuracy=64.629, wps=14444.7, ups=1.75, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=57, gb_free=16.3, wall=24836
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 11:27:57 | INFO | train_inner | epoch 024:   1214 / 1474 loss=2.079, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.097, total=4157.47, n_correct=2681.09, ppl=4.6, accuracy=64.488, wps=14411.1, ups=1.73, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.648, clip=0, loss_scale=16, train_wall=57, gb_free=13.2, wall=24894
2023-08-03 11:28:54 | INFO | train_inner | epoch 024:   1314 / 1474 loss=2.085, trans_loss=5.015, nll_loss=2.213, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.065, total=4107.23, n_correct=2637.05, ppl=4.64, accuracy=64.205, wps=14387.7, ups=1.75, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.627, clip=0, loss_scale=16, train_wall=57, gb_free=17.8, wall=24951
2023-08-03 11:29:51 | INFO | train_inner | epoch 024:   1414 / 1474 loss=2.086, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.064, total=4094.39, n_correct=2630.92, ppl=4.65, accuracy=64.257, wps=14389.7, ups=1.76, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.615, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=25008
2023-08-03 11:30:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
2023-08-03 11:30:48 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.574 | nll_loss 2.849 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2479.4 | ppl 7.21 | accuracy 61.932 | uer 16.829 | wer 18.612 | raw_wer 18.612 | bleu 20.03 | wps 2221.1 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.07
2023-08-03 11:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-03 11:30:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0309.pt
2023-08-03 11:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0309.pt
2023-08-03 11:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.0309.pt (epoch 24 @ 35360 updates, score 20.03) (writing took 13.643821047618985 seconds)
2023-08-03 11:31:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-03 11:31:02 | INFO | train | epoch 024 | loss 2.078 | trans_loss 4.999 | nll_loss 2.192 | w2v_ctc_loss 0.678 | task_loss 0 | contrastive_loss 0.118 | total 4138.65 | n_correct 2673.24 | ppl 4.57 | accuracy 64.592 | wps 12993.8 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.606 | clip 0 | loss_scale 16 | train_wall 837 | gb_free 16.4 | wall 25079
2023-08-03 11:31:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 11:31:03 | INFO | fairseq.trainer | begin training epoch 25
2023-08-03 11:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 11:31:34 | INFO | train_inner | epoch 025:     40 / 1474 loss=2.067, trans_loss=4.989, nll_loss=2.181, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.072, total=4165.57, n_correct=2705.29, ppl=4.53, accuracy=64.944, wps=8094.9, ups=0.97, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=57, gb_free=13.6, wall=25111
2023-08-03 11:32:31 | INFO | train_inner | epoch 025:    140 / 1474 loss=2.057, trans_loss=4.969, nll_loss=2.153, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.071, total=4135.43, n_correct=2698.28, ppl=4.45, accuracy=65.248, wps=14493.5, ups=1.75, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=57, gb_free=18, wall=25168
2023-08-03 11:33:28 | INFO | train_inner | epoch 025:    240 / 1474 loss=2.062, trans_loss=4.976, nll_loss=2.162, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.075, total=4116.13, n_correct=2676.92, ppl=4.48, accuracy=65.035, wps=14400.4, ups=1.75, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=25225
2023-08-03 11:34:26 | INFO | train_inner | epoch 025:    340 / 1474 loss=2.068, trans_loss=4.982, nll_loss=2.168, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.101, total=4141.49, n_correct=2682.32, ppl=4.49, accuracy=64.767, wps=14463.9, ups=1.75, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=25282
2023-08-03 11:35:23 | INFO | train_inner | epoch 025:    440 / 1474 loss=2.081, trans_loss=4.985, nll_loss=2.173, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.179, total=4167.4, n_correct=2700.06, ppl=4.51, accuracy=64.79, wps=14604.8, ups=1.75, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=25339
2023-08-03 11:36:20 | INFO | train_inner | epoch 025:    540 / 1474 loss=2.073, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.075, total=4160.61, n_correct=2695.06, ppl=4.55, accuracy=64.776, wps=14585.1, ups=1.75, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=25396
2023-08-03 11:37:17 | INFO | train_inner | epoch 025:    640 / 1474 loss=2.073, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.142, total=4153.68, n_correct=2695.7, ppl=4.51, accuracy=64.899, wps=14603.4, ups=1.76, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=25453
2023-08-03 11:37:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:37:43 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.584 | nll_loss 2.86 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2471.2 | ppl 7.26 | accuracy 61.728 | uer 17.193 | wer 18.952 | raw_wer 18.952 | bleu 20.04 | wps 1872.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.07
2023-08-03 11:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-03 11:37:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_25_36000.pt
2023-08-03 11:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_25_36000.pt
2023-08-03 11:38:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.04) (writing took 32.267277143895626 seconds)
2023-08-03 11:39:15 | INFO | train_inner | epoch 025:    740 / 1474 loss=2.075, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.138, total=4128.34, n_correct=2674.08, ppl=4.52, accuracy=64.774, wps=6948.6, ups=0.84, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=25572
2023-08-03 11:40:12 | INFO | train_inner | epoch 025:    840 / 1474 loss=2.069, trans_loss=4.991, nll_loss=2.183, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.085, total=4182.4, n_correct=2714.51, ppl=4.54, accuracy=64.903, wps=14734.6, ups=1.76, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=25629
2023-08-03 11:41:10 | INFO | train_inner | epoch 025:    940 / 1474 loss=2.077, trans_loss=4.994, nll_loss=2.188, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.142, total=4155.21, n_correct=2692.36, ppl=4.56, accuracy=64.795, wps=14434.7, ups=1.74, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=57, gb_free=14.5, wall=25686
2023-08-03 11:42:06 | INFO | train_inner | epoch 025:   1040 / 1474 loss=2.082, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.252, total=4177.7, n_correct=2697.35, ppl=4.59, accuracy=64.565, wps=14764.6, ups=1.77, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=25743
2023-08-03 11:43:03 | INFO | train_inner | epoch 025:   1140 / 1474 loss=2.065, trans_loss=4.996, nll_loss=2.188, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.054, total=4039.24, n_correct=2615.95, ppl=4.56, accuracy=64.763, wps=14289.7, ups=1.77, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.611, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=25800
2023-08-03 11:43:59 | INFO | train_inner | epoch 025:   1240 / 1474 loss=2.069, trans_loss=5, nll_loss=2.193, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.064, total=4090.59, n_correct=2644.41, ppl=4.57, accuracy=64.646, wps=14465.9, ups=1.77, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=25856
2023-08-03 11:44:57 | INFO | train_inner | epoch 025:   1340 / 1474 loss=2.078, trans_loss=4.997, nll_loss=2.191, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.158, total=4164.34, n_correct=2692.28, ppl=4.57, accuracy=64.651, wps=14458, ups=1.74, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=25914
2023-08-03 11:45:54 | INFO | train_inner | epoch 025:   1440 / 1474 loss=2.083, trans_loss=5.014, nll_loss=2.212, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.112, total=4099.11, n_correct=2635.13, ppl=4.63, accuracy=64.285, wps=14326.2, ups=1.75, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.624, clip=0, loss_scale=32, train_wall=57, gb_free=12.8, wall=25971
2023-08-03 11:46:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:46:38 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.574 | nll_loss 2.855 | w2v_ctc_loss 1.362 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2474.7 | ppl 7.24 | accuracy 61.815 | uer 17.063 | wer 18.851 | raw_wer 18.851 | bleu 20.08 | wps 2005.6 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.08
2023-08-03 11:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-03 11:46:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 11:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 11:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 25 @ 36834 updates, score 20.08) (writing took 22.940633695572615 seconds)
2023-08-03 11:47:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-03 11:47:02 | INFO | train | epoch 025 | loss 2.072 | trans_loss 4.991 | nll_loss 2.182 | w2v_ctc_loss 0.673 | task_loss 0 | contrastive_loss 0.117 | total 4138.65 | n_correct 2681.02 | ppl 4.54 | accuracy 64.78 | wps 12715.8 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.604 | clip 0 | loss_scale 32 | train_wall 834 | gb_free 14.7 | wall 26039
2023-08-03 11:47:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 11:47:02 | INFO | fairseq.trainer | begin training epoch 26
2023-08-03 11:47:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 11:47:48 | INFO | train_inner | epoch 026:     66 / 1474 loss=2.059, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.097, total=4180.21, n_correct=2724.81, ppl=4.45, accuracy=65.184, wps=7332, ups=0.88, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=26085
2023-08-03 11:48:46 | INFO | train_inner | epoch 026:    166 / 1474 loss=2.068, trans_loss=4.966, nll_loss=2.151, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.283, total=4270.78, n_correct=2788.4, ppl=4.44, accuracy=65.29, wps=14744.6, ups=1.73, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=26143
2023-08-03 11:49:43 | INFO | train_inner | epoch 026:    266 / 1474 loss=2.066, trans_loss=4.968, nll_loss=2.153, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.155, total=4125.04, n_correct=2688.72, ppl=4.45, accuracy=65.18, wps=14498.3, ups=1.76, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=26200
2023-08-03 11:50:40 | INFO | train_inner | epoch 026:    366 / 1474 loss=2.063, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.115, total=4165.74, n_correct=2713.82, ppl=4.46, accuracy=65.146, wps=14661.7, ups=1.76, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=26257
2023-08-03 11:51:37 | INFO | train_inner | epoch 026:    466 / 1474 loss=2.064, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.158, total=4170.23, n_correct=2720.65, ppl=4.44, accuracy=65.24, wps=14671, ups=1.76, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=26314
2023-08-03 11:52:34 | INFO | train_inner | epoch 026:    566 / 1474 loss=2.068, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.08, total=4155.02, n_correct=2699.41, ppl=4.5, accuracy=64.967, wps=14466.1, ups=1.74, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.619, clip=0, loss_scale=32, train_wall=57, gb_free=18.1, wall=26371
2023-08-03 11:53:32 | INFO | train_inner | epoch 026:    666 / 1474 loss=2.059, trans_loss=4.979, nll_loss=2.167, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.062, total=4136.96, n_correct=2688.54, ppl=4.49, accuracy=64.988, wps=14456, ups=1.75, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=26428
2023-08-03 11:54:28 | INFO | train_inner | epoch 026:    766 / 1474 loss=2.074, trans_loss=4.987, nll_loss=2.176, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.176, total=4086.28, n_correct=2647.47, ppl=4.52, accuracy=64.789, wps=14408.9, ups=1.76, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.619, clip=0, loss_scale=64, train_wall=56, gb_free=15.4, wall=26485
2023-08-03 11:55:25 | INFO | train_inner | epoch 026:    866 / 1474 loss=2.067, trans_loss=4.985, nll_loss=2.174, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.079, total=4183.26, n_correct=2711.71, ppl=4.51, accuracy=64.823, wps=14725.6, ups=1.76, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=17.6, wall=26542
2023-08-03 11:55:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 11:56:23 | INFO | train_inner | epoch 026:    967 / 1474 loss=2.069, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.131, total=4130.84, n_correct=2674.14, ppl=4.55, accuracy=64.736, wps=14172.2, ups=1.72, wpb=8261.7, bsz=296.5, num_updates=37800, lr=7.27393e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=58, gb_free=15.9, wall=26600
2023-08-03 11:57:21 | INFO | train_inner | epoch 026:   1067 / 1474 loss=2.061, trans_loss=4.988, nll_loss=2.178, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.061, total=4113.69, n_correct=2672.85, ppl=4.52, accuracy=64.975, wps=14391.5, ups=1.75, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=26657
2023-08-03 11:58:18 | INFO | train_inner | epoch 026:   1167 / 1474 loss=2.07, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.101, total=4116.78, n_correct=2664.93, ppl=4.55, accuracy=64.733, wps=14456.7, ups=1.76, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=26714
2023-08-03 11:58:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 11:58:43 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 1.41 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2478.8 | ppl 7.24 | accuracy 61.917 | uer 17.065 | wer 18.78 | raw_wer 18.78 | bleu 20.09 | wps 1947.7 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.09
2023-08-03 11:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-03 11:58:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_26_38000.pt
2023-08-03 11:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_26_38000.pt
2023-08-03 11:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.09) (writing took 23.982713541015983 seconds)
2023-08-03 12:00:05 | INFO | train_inner | epoch 026:   1267 / 1474 loss=2.074, trans_loss=5.004, nll_loss=2.198, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.065, total=4001.06, n_correct=2581.22, ppl=4.59, accuracy=64.513, wps=7461.4, ups=0.93, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.612, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=26821
2023-08-03 12:01:02 | INFO | train_inner | epoch 026:   1367 / 1474 loss=2.065, trans_loss=4.996, nll_loss=2.189, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.081, total=4157.69, n_correct=2698.88, ppl=4.56, accuracy=64.913, wps=14439, ups=1.74, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=26879
2023-08-03 12:01:59 | INFO | train_inner | epoch 026:   1467 / 1474 loss=2.062, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.073, total=4158.47, n_correct=2703.61, ppl=4.54, accuracy=65.015, wps=14681.4, ups=1.77, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=26936
2023-08-03 12:02:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 12:02:27 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.58 | nll_loss 2.857 | w2v_ctc_loss 1.355 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2480.6 | ppl 7.24 | accuracy 61.962 | uer 17.105 | wer 18.836 | raw_wer 18.836 | bleu 20.16 | wps 2117.6 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.16
2023-08-03 12:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-03 12:02:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 12:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 12:02:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 26 @ 38307 updates, score 20.16) (writing took 24.594097500666976 seconds)
2023-08-03 12:02:52 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-03 12:02:52 | INFO | train | epoch 026 | loss 2.065 | trans_loss 4.982 | nll_loss 2.171 | w2v_ctc_loss 0.666 | task_loss 0 | contrastive_loss 0.116 | total 4138.05 | n_correct 2689.01 | ppl 4.5 | accuracy 64.983 | wps 12832.7 | ups 1.55 | wpb 8276.1 | bsz 305.5 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.603 | clip 0 | loss_scale 32 | train_wall 834 | gb_free 16.2 | wall 26989
2023-08-03 12:02:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 12:02:52 | INFO | fairseq.trainer | begin training epoch 27
2023-08-03 12:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 12:03:53 | INFO | train_inner | epoch 027:     93 / 1474 loss=2.042, trans_loss=4.948, nll_loss=2.124, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.05, total=4067.62, n_correct=2668.2, ppl=4.36, accuracy=65.596, wps=7128.3, ups=0.88, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=27050
2023-08-03 12:04:50 | INFO | train_inner | epoch 027:    193 / 1474 loss=2.049, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.083, total=4185.52, n_correct=2744.59, ppl=4.39, accuracy=65.573, wps=14790.4, ups=1.77, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=27106
2023-08-03 12:05:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 12:05:48 | INFO | train_inner | epoch 027:    294 / 1474 loss=2.053, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.064, total=4169.35, n_correct=2727.79, ppl=4.42, accuracy=65.425, wps=14405.5, ups=1.73, wpb=8338.7, bsz=307.6, num_updates=38600, lr=7.19816e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=27164
2023-08-03 12:06:45 | INFO | train_inner | epoch 027:    394 / 1474 loss=2.066, trans_loss=4.969, nll_loss=2.153, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.246, total=4078.73, n_correct=2660.95, ppl=4.45, accuracy=65.24, wps=14288.4, ups=1.75, wpb=8157.5, bsz=297.5, num_updates=38700, lr=7.18885e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=27221
2023-08-03 12:07:42 | INFO | train_inner | epoch 027:    494 / 1474 loss=2.066, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.186, total=4245.37, n_correct=2767.52, ppl=4.48, accuracy=65.189, wps=14950.9, ups=1.76, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=56, gb_free=17.1, wall=27278
2023-08-03 12:08:38 | INFO | train_inner | epoch 027:    594 / 1474 loss=2.064, trans_loss=4.974, nll_loss=2.161, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.125, total=4134.93, n_correct=2693, ppl=4.47, accuracy=65.128, wps=14653.7, ups=1.77, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=56, gb_free=17.9, wall=27335
2023-08-03 12:09:35 | INFO | train_inner | epoch 027:    694 / 1474 loss=2.063, trans_loss=4.978, nll_loss=2.166, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.102, total=4162.17, n_correct=2709.02, ppl=4.49, accuracy=65.087, wps=14553.5, ups=1.75, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.615, clip=0, loss_scale=16, train_wall=57, gb_free=15.9, wall=27392
2023-08-03 12:10:31 | INFO | train_inner | epoch 027:    794 / 1474 loss=2.06, trans_loss=4.978, nll_loss=2.165, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.066, total=4107.17, n_correct=2672.53, ppl=4.48, accuracy=65.07, wps=14601.3, ups=1.78, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.614, clip=0, loss_scale=16, train_wall=56, gb_free=12.1, wall=27448
2023-08-03 12:11:28 | INFO | train_inner | epoch 027:    894 / 1474 loss=2.053, trans_loss=4.983, nll_loss=2.171, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.053, total=4101.4, n_correct=2671.72, ppl=4.5, accuracy=65.142, wps=14600.9, ups=1.78, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=27504
2023-08-03 12:12:24 | INFO | train_inner | epoch 027:    994 / 1474 loss=2.067, trans_loss=4.977, nll_loss=2.165, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.245, total=4195.5, n_correct=2734.21, ppl=4.48, accuracy=65.17, wps=14755.5, ups=1.76, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=56, gb_free=17, wall=27561
2023-08-03 12:13:22 | INFO | train_inner | epoch 027:   1094 / 1474 loss=2.052, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.076, total=4147.99, n_correct=2703.42, ppl=4.48, accuracy=65.174, wps=14480.7, ups=1.75, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=57, gb_free=16.5, wall=27618
2023-08-03 12:14:18 | INFO | train_inner | epoch 027:   1194 / 1474 loss=2.067, trans_loss=4.987, nll_loss=2.177, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.08, total=4104.84, n_correct=2665.12, ppl=4.52, accuracy=64.926, wps=14552, ups=1.77, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.619, clip=0, loss_scale=16, train_wall=56, gb_free=12.8, wall=27675
2023-08-03 12:15:14 | INFO | train_inner | epoch 027:   1294 / 1474 loss=2.073, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.131, total=4062.86, n_correct=2626.54, ppl=4.55, accuracy=64.648, wps=14485.8, ups=1.78, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.618, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=27731
2023-08-03 12:16:11 | INFO | train_inner | epoch 027:   1394 / 1474 loss=2.061, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.116, total=4157.6, n_correct=2703.24, ppl=4.51, accuracy=65.019, wps=14747.3, ups=1.77, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=56, gb_free=17.9, wall=27787
2023-08-03 12:16:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 12:17:20 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.576 | nll_loss 2.851 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2477.9 | ppl 7.21 | accuracy 61.895 | uer 16.763 | wer 18.389 | raw_wer 18.389 | bleu 20.35 | wps 2112.5 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.35
2023-08-03 12:17:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-03 12:17:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 12:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt
2023-08-03 12:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_best.pt (epoch 27 @ 39780 updates, score 20.35) (writing took 28.797930726781487 seconds)
2023-08-03 12:17:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-03 12:17:49 | INFO | train | epoch 027 | loss 2.059 | trans_loss 4.974 | nll_loss 2.161 | w2v_ctc_loss 0.66 | task_loss 0 | contrastive_loss 0.114 | total 4138.71 | n_correct 2697.57 | ppl 4.47 | accuracy 65.179 | wps 13593.3 | ups 1.64 | wpb 8277.4 | bsz 305.8 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.602 | clip 0 | loss_scale 16 | train_wall 828 | gb_free 18.1 | wall 27886
2023-08-03 12:17:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 12:17:49 | INFO | fairseq.trainer | begin training epoch 28
2023-08-03 12:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 12:18:09 | INFO | train_inner | epoch 028:     20 / 1474 loss=2.05, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.063, total=4107.3, n_correct=2683.5, ppl=4.47, accuracy=65.335, wps=6950.3, ups=0.85, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=27906
2023-08-03 12:19:05 | INFO | train_inner | epoch 028:    120 / 1474 loss=2.04, trans_loss=4.945, nll_loss=2.121, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.058, total=4112.44, n_correct=2707.47, ppl=4.35, accuracy=65.836, wps=14589.6, ups=1.77, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=56, gb_free=14.2, wall=27962
2023-08-03 12:20:02 | INFO | train_inner | epoch 028:    220 / 1474 loss=2.041, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.07, total=4193.3, n_correct=2757.34, ppl=4.38, accuracy=65.756, wps=14850.5, ups=1.77, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=28018
2023-08-03 12:20:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 12:20:25 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.584 | nll_loss 2.861 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2474.5 | ppl 7.26 | accuracy 61.81 | uer 17.007 | wer 18.653 | raw_wer 18.653 | bleu 20.13 | wps 2226.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.35
2023-08-03 12:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-03 12:20:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_28_40000.pt
2023-08-03 12:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_28_40000.pt
2023-08-03 12:20:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.13) (writing took 28.112003315240145 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 12:21:52 | INFO | train_inner | epoch 028:    320 / 1474 loss=2.072, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.401, total=4138.69, n_correct=2701.16, ppl=4.43, accuracy=65.266, wps=7539, ups=0.91, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=57, gb_free=13.8, wall=28128
2023-08-03 12:22:48 | INFO | train_inner | epoch 028:    420 / 1474 loss=2.047, trans_loss=4.958, nll_loss=2.139, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.054, total=4089.84, n_correct=2681.33, ppl=4.4, accuracy=65.561, wps=14529.3, ups=1.78, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=28184
2023-08-03 12:23:44 | INFO | train_inner | epoch 028:    520 / 1474 loss=2.047, trans_loss=4.961, nll_loss=2.143, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.067, total=4098.92, n_correct=2680.96, ppl=4.42, accuracy=65.406, wps=14565.2, ups=1.78, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=28241
2023-08-03 12:24:40 | INFO | train_inner | epoch 028:    620 / 1474 loss=2.052, trans_loss=4.972, nll_loss=2.157, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.068, total=4180.1, n_correct=2725.39, ppl=4.46, accuracy=65.199, wps=14896.4, ups=1.78, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=28297
2023-08-03 12:25:37 | INFO | train_inner | epoch 028:    720 / 1474 loss=2.059, trans_loss=4.968, nll_loss=2.155, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.183, total=4191.62, n_correct=2739.59, ppl=4.45, accuracy=65.359, wps=14850.5, ups=1.77, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=56, gb_free=17.3, wall=28353
2023-08-03 12:26:33 | INFO | train_inner | epoch 028:    820 / 1474 loss=2.046, trans_loss=4.965, nll_loss=2.149, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.058, total=4088.91, n_correct=2681.37, ppl=4.43, accuracy=65.577, wps=14529.9, ups=1.78, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.619, clip=0, loss_scale=16, train_wall=56, gb_free=17.3, wall=28410
2023-08-03 12:27:30 | INFO | train_inner | epoch 028:    920 / 1474 loss=2.061, trans_loss=4.977, nll_loss=2.165, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.125, total=4117.01, n_correct=2679.2, ppl=4.48, accuracy=65.076, wps=14563.3, ups=1.77, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.614, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=28466
2023-08-03 12:28:26 | INFO | train_inner | epoch 028:   1020 / 1474 loss=2.068, trans_loss=4.978, nll_loss=2.165, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.178, total=4182.85, n_correct=2720.59, ppl=4.49, accuracy=65.042, wps=14846.6, ups=1.77, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.611, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=28523
2023-08-03 12:29:22 | INFO | train_inner | epoch 028:   1120 / 1474 loss=2.05, trans_loss=4.965, nll_loss=2.151, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.084, total=4220.16, n_correct=2758.3, ppl=4.44, accuracy=65.36, wps=14963.7, ups=1.77, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=28579
2023-08-03 12:30:19 | INFO | train_inner | epoch 028:   1220 / 1474 loss=2.052, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.068, total=4092.46, n_correct=2668.06, ppl=4.48, accuracy=65.195, wps=14534.4, ups=1.78, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.61, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=28635
2023-08-03 12:31:15 | INFO | train_inner | epoch 028:   1320 / 1474 loss=2.061, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.082, total=4084.55, n_correct=2656.48, ppl=4.5, accuracy=65.037, wps=14452.4, ups=1.77, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.61, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=28692
2023-08-03 12:32:12 | INFO | train_inner | epoch 028:   1420 / 1474 loss=2.056, trans_loss=4.976, nll_loss=2.162, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.103, total=4154.09, n_correct=2706.16, ppl=4.48, accuracy=65.144, wps=14713.9, ups=1.77, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=28748
2023-08-03 12:32:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
2023-08-03 12:33:05 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 1.361 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2480.4 | ppl 7.23 | accuracy 61.957 | uer 16.922 | wer 18.631 | raw_wer 18.631 | bleu 20.24 | wps 2148.9 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.35
2023-08-03 12:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-03 12:33:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.2409.pt
2023-08-03 12:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.2409.pt
2023-08-03 12:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.2409.pt (epoch 28 @ 41254 updates, score 20.24) (writing took 17.15874651260674 seconds)
2023-08-03 12:33:23 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-03 12:33:23 | INFO | train | epoch 028 | loss 2.054 | trans_loss 4.967 | nll_loss 2.151 | w2v_ctc_loss 0.655 | task_loss 0 | contrastive_loss 0.113 | total 4138.65 | n_correct 2704.65 | ppl 4.44 | accuracy 65.351 | wps 13064.2 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.606 | clip 0 | loss_scale 32 | train_wall 825 | gb_free 16.7 | wall 28820
2023-08-03 12:33:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 12:33:23 | INFO | fairseq.trainer | begin training epoch 29
2023-08-03 12:33:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 12:33:57 | INFO | train_inner | epoch 029:     46 / 1474 loss=2.047, trans_loss=4.954, nll_loss=2.135, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.081, total=4169.12, n_correct=2736.87, ppl=4.39, accuracy=65.646, wps=7900.5, ups=0.95, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.615, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=28854
2023-08-03 12:34:54 | INFO | train_inner | epoch 029:    146 / 1474 loss=2.046, trans_loss=4.95, nll_loss=2.129, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.098, total=4105.72, n_correct=2694.78, ppl=4.37, accuracy=65.635, wps=14572.6, ups=1.77, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.631, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=28910
2023-08-03 12:35:50 | INFO | train_inner | epoch 029:    246 / 1474 loss=2.044, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.182, total=4199.67, n_correct=2766.96, ppl=4.34, accuracy=65.885, wps=14873.7, ups=1.77, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=28967
2023-08-03 12:36:46 | INFO | train_inner | epoch 029:    346 / 1474 loss=2.05, trans_loss=4.962, nll_loss=2.144, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.063, total=4095.17, n_correct=2680.28, ppl=4.42, accuracy=65.45, wps=14526.6, ups=1.77, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=29023
2023-08-03 12:37:43 | INFO | train_inner | epoch 029:    446 / 1474 loss=2.033, trans_loss=4.939, nll_loss=2.114, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.055, total=4157.44, n_correct=2740.02, ppl=4.33, accuracy=65.906, wps=14695.8, ups=1.77, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=29080
2023-08-03 12:38:40 | INFO | train_inner | epoch 029:    546 / 1474 loss=2.056, trans_loss=4.965, nll_loss=2.148, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.155, total=4150.87, n_correct=2711.85, ppl=4.43, accuracy=65.332, wps=14616.6, ups=1.76, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.627, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=29136
2023-08-03 12:39:36 | INFO | train_inner | epoch 029:    646 / 1474 loss=2.05, trans_loss=4.951, nll_loss=2.131, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.221, total=4143.02, n_correct=2720.61, ppl=4.38, accuracy=65.667, wps=14795, ups=1.79, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=29192
2023-08-03 12:40:32 | INFO | train_inner | epoch 029:    746 / 1474 loss=2.048, trans_loss=4.953, nll_loss=2.134, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.142, total=4249.79, n_correct=2786.91, ppl=4.39, accuracy=65.578, wps=15002.2, ups=1.77, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.632, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=29249
2023-08-03 12:40:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 12:40:55 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.568 | nll_loss 2.841 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2484.7 | ppl 7.17 | accuracy 62.065 | uer 16.771 | wer 18.478 | raw_wer 18.478 | bleu 20.24 | wps 2326.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.35
2023-08-03 12:40:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-03 12:40:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_29_42000.pt
2023-08-03 12:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_29_42000.pt
2023-08-03 12:41:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.24) (writing took 21.052793312817812 seconds)
2023-08-03 12:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 12:42:14 | INFO | train_inner | epoch 029:    847 / 1474 loss=2.051, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.054, total=4025.01, n_correct=2621.9, ppl=4.47, accuracy=65.14, wps=7920.1, ups=0.98, wpb=8050, bsz=281.4, num_updates=42100, lr=6.89246e-05, gnorm=0.626, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=29351
2023-08-03 12:43:10 | INFO | train_inner | epoch 029:    947 / 1474 loss=2.052, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.067, total=4086.72, n_correct=2669.43, ppl=4.46, accuracy=65.32, wps=14623.5, ups=1.79, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.614, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=29407
2023-08-03 12:44:06 | INFO | train_inner | epoch 029:   1047 / 1474 loss=2.047, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.143, total=4139.4, n_correct=2711.71, ppl=4.41, accuracy=65.51, wps=14787.9, ups=1.79, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=29463
2023-08-03 12:45:02 | INFO | train_inner | epoch 029:   1147 / 1474 loss=2.05, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.05, total=4072.33, n_correct=2656.88, ppl=4.48, accuracy=65.242, wps=14529.3, ups=1.78, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=29519
2023-08-03 12:45:58 | INFO | train_inner | epoch 029:   1247 / 1474 loss=2.051, trans_loss=4.973, nll_loss=2.16, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.06, total=4160.52, n_correct=2717.59, ppl=4.47, accuracy=65.319, wps=14740.3, ups=1.77, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.607, clip=0, loss_scale=16, train_wall=56, gb_free=16, wall=29575
2023-08-03 12:46:55 | INFO | train_inner | epoch 029:   1347 / 1474 loss=2.053, trans_loss=4.967, nll_loss=2.152, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.127, total=4168.02, n_correct=2726.08, ppl=4.44, accuracy=65.405, wps=14727.1, ups=1.77, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=29632
2023-08-03 12:47:51 | INFO | train_inner | epoch 029:   1447 / 1474 loss=2.054, trans_loss=4.965, nll_loss=2.151, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.153, total=4166.06, n_correct=2722.51, ppl=4.44, accuracy=65.35, wps=14891.5, ups=1.79, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=55, gb_free=17.1, wall=29688
2023-08-03 12:48:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 12:48:30 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.574 | nll_loss 2.849 | w2v_ctc_loss 1.39 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2484.3 | ppl 7.21 | accuracy 62.055 | uer 16.858 | wer 18.683 | raw_wer 18.683 | bleu 20.16 | wps 2153.9 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.35
2023-08-03 12:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-03 12:48:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1602.pt
2023-08-03 12:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1602.pt
2023-08-03 12:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1602.pt (epoch 29 @ 42727 updates, score 20.16) (writing took 16.631033739075065 seconds)
2023-08-03 12:48:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-03 12:48:47 | INFO | train | epoch 029 | loss 2.048 | trans_loss 4.96 | nll_loss 2.142 | w2v_ctc_loss 0.649 | task_loss 0 | contrastive_loss 0.112 | total 4138.89 | n_correct 2710.75 | ppl 4.41 | accuracy 65.495 | wps 13200.8 | ups 1.59 | wpb 8277.8 | bsz 305.8 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.61 | clip 0 | loss_scale 16 | train_wall 824 | gb_free 16.3 | wall 29743
2023-08-03 12:48:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 12:48:47 | INFO | fairseq.trainer | begin training epoch 30
2023-08-03 12:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 12:49:36 | INFO | train_inner | epoch 030:     73 / 1474 loss=2.042, trans_loss=4.943, nll_loss=2.12, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.172, total=4175.11, n_correct=2746.23, ppl=4.35, accuracy=65.776, wps=7952, ups=0.95, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=29793
2023-08-03 12:50:32 | INFO | train_inner | epoch 030:    173 / 1474 loss=2.036, trans_loss=4.927, nll_loss=2.1, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.105, total=4202.64, n_correct=2779.03, ppl=4.29, accuracy=66.126, wps=14923.2, ups=1.78, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.627, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=29849
2023-08-03 12:51:29 | INFO | train_inner | epoch 030:    273 / 1474 loss=2.037, trans_loss=4.942, nll_loss=2.117, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.054, total=4120.21, n_correct=2715.14, ppl=4.34, accuracy=65.898, wps=14646.7, ups=1.78, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=29905
2023-08-03 12:52:25 | INFO | train_inner | epoch 030:    373 / 1474 loss=2.03, trans_loss=4.935, nll_loss=2.11, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.06, total=4178.23, n_correct=2763.37, ppl=4.32, accuracy=66.137, wps=14701, ups=1.76, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=56, gb_free=10.7, wall=29962
2023-08-03 12:53:21 | INFO | train_inner | epoch 030:    473 / 1474 loss=2.039, trans_loss=4.944, nll_loss=2.122, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.124, total=4124.47, n_correct=2715.75, ppl=4.35, accuracy=65.845, wps=14821, ups=1.8, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=55, gb_free=17.8, wall=30018
2023-08-03 12:54:17 | INFO | train_inner | epoch 030:    573 / 1474 loss=2.04, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.086, total=4168.41, n_correct=2739.11, ppl=4.38, accuracy=65.711, wps=14795.6, ups=1.77, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=56, gb_free=17.5, wall=30074
2023-08-03 12:55:14 | INFO | train_inner | epoch 030:    673 / 1474 loss=2.047, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.103, total=4187.95, n_correct=2745.3, ppl=4.39, accuracy=65.552, wps=14773.9, ups=1.76, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=30131
2023-08-03 12:56:10 | INFO | train_inner | epoch 030:    773 / 1474 loss=2.061, trans_loss=4.965, nll_loss=2.15, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.18, total=4105.32, n_correct=2682.8, ppl=4.44, accuracy=65.349, wps=14623, ups=1.78, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.615, clip=0, loss_scale=16, train_wall=56, gb_free=13.5, wall=30187
2023-08-03 12:57:06 | INFO | train_inner | epoch 030:    873 / 1474 loss=2.042, trans_loss=4.957, nll_loss=2.137, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.069, total=4102.11, n_correct=2691.93, ppl=4.4, accuracy=65.623, wps=14613.7, ups=1.78, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=56, gb_free=17.7, wall=30243
2023-08-03 12:58:02 | INFO | train_inner | epoch 030:    973 / 1474 loss=2.048, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.074, total=4129.98, n_correct=2699.21, ppl=4.43, accuracy=65.356, wps=14819.5, ups=1.79, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=30299
2023-08-03 12:58:59 | INFO | train_inner | epoch 030:   1073 / 1474 loss=2.056, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.145, total=4101.17, n_correct=2672.78, ppl=4.46, accuracy=65.171, wps=14448.4, ups=1.76, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=56, gb_free=15.9, wall=30356
2023-08-03 12:59:56 | INFO | train_inner | epoch 030:   1173 / 1474 loss=2.041, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.133, total=4168.36, n_correct=2737.18, ppl=4.4, accuracy=65.666, wps=14690.4, ups=1.76, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=30412
2023-08-03 13:00:52 | INFO | train_inner | epoch 030:   1273 / 1474 loss=2.049, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.064, total=4036.17, n_correct=2639.09, ppl=4.44, accuracy=65.386, wps=14361, ups=1.78, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.617, clip=0, loss_scale=16, train_wall=56, gb_free=16.1, wall=30469
2023-08-03 13:00:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:01:16 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.334 | trans_loss 5.568 | nll_loss 2.841 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2486.1 | ppl 7.17 | accuracy 62.1 | uer 16.917 | wer 18.609 | raw_wer 18.609 | bleu 20.34 | wps 2146.5 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.35
2023-08-03 13:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-03 13:01:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_30_44000.pt
2023-08-03 13:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_30_44000.pt
2023-08-03 13:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.34) (writing took 19.15977069362998 seconds)
2023-08-03 13:02:32 | INFO | train_inner | epoch 030:   1373 / 1474 loss=2.041, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.077, total=4165.07, n_correct=2736.23, ppl=4.41, accuracy=65.695, wps=8324.2, ups=1, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.618, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=30569
2023-08-03 13:03:28 | INFO | train_inner | epoch 030:   1473 / 1474 loss=2.049, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.217, total=4141.76, n_correct=2712.22, ppl=4.43, accuracy=65.485, wps=14789.2, ups=1.79, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.613, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=30625
2023-08-03 13:03:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:03:51 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.575 | nll_loss 2.85 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2480.2 | ppl 7.21 | accuracy 61.952 | uer 16.999 | wer 18.799 | raw_wer 18.799 | bleu 20.02 | wps 2256.6 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.35
2023-08-03 13:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-03 13:03:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt (epoch 30 @ 44201 updates, score 20.02) (writing took 12.284710628911853 seconds)
2023-08-03 13:04:04 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-03 13:04:04 | INFO | train | epoch 030 | loss 2.044 | trans_loss 4.953 | nll_loss 2.133 | w2v_ctc_loss 0.645 | task_loss 0 | contrastive_loss 0.112 | total 4138.65 | n_correct 2717.33 | ppl 4.39 | accuracy 65.657 | wps 13304.9 | ups 1.61 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.609 | clip 0 | loss_scale 32 | train_wall 823 | gb_free 17.4 | wall 30660
2023-08-03 13:04:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 13:04:04 | INFO | fairseq.trainer | begin training epoch 31
2023-08-03 13:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 13:05:07 | INFO | train_inner | epoch 031:     99 / 1474 loss=2.034, trans_loss=4.936, nll_loss=2.109, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.056, total=4054.44, n_correct=2674.01, ppl=4.31, accuracy=65.953, wps=8214.5, ups=1.01, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=30723
2023-08-03 13:06:03 | INFO | train_inner | epoch 031:    199 / 1474 loss=2.036, trans_loss=4.939, nll_loss=2.114, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.089, total=4147.4, n_correct=2736.96, ppl=4.33, accuracy=65.992, wps=14626.3, ups=1.76, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.613, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=30780
2023-08-03 13:07:00 | INFO | train_inner | epoch 031:    299 / 1474 loss=2.036, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.124, total=4149.21, n_correct=2740.53, ppl=4.31, accuracy=66.049, wps=14626.2, ups=1.76, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.625, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=30837
2023-08-03 13:07:56 | INFO | train_inner | epoch 031:    399 / 1474 loss=2.035, trans_loss=4.946, nll_loss=2.123, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.06, total=4092.62, n_correct=2692.08, ppl=4.36, accuracy=65.779, wps=14597.2, ups=1.78, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.613, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=30893
2023-08-03 13:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 13:08:53 | INFO | train_inner | epoch 031:    500 / 1474 loss=2.037, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.071, total=4115.24, n_correct=2708.43, ppl=4.34, accuracy=65.815, wps=14482.7, ups=1.76, wpb=8230.5, bsz=301.3, num_updates=44700, lr=6.689e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=30950
2023-08-03 13:09:49 | INFO | train_inner | epoch 031:    600 / 1474 loss=2.032, trans_loss=4.943, nll_loss=2.12, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.06, total=4075.9, n_correct=2686.01, ppl=4.35, accuracy=65.9, wps=14512.2, ups=1.78, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.627, clip=0, loss_scale=16, train_wall=56, gb_free=12.5, wall=31006
2023-08-03 13:10:45 | INFO | train_inner | epoch 031:    700 / 1474 loss=2.029, trans_loss=4.939, nll_loss=2.115, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.061, total=4208.99, n_correct=2776.69, ppl=4.33, accuracy=65.97, wps=15060.9, ups=1.79, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=55, gb_free=18.1, wall=31062
2023-08-03 13:11:42 | INFO | train_inner | epoch 031:    800 / 1474 loss=2.044, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.133, total=4104.19, n_correct=2694.42, ppl=4.39, accuracy=65.65, wps=14485.3, ups=1.76, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=31119
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:0')
2023-08-03 13:12:38 | INFO | train_inner | epoch 031:    900 / 1474 loss=2.038, trans_loss=4.946, nll_loss=2.125, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.076, total=4099.13, n_correct=2694.82, ppl=4.36, accuracy=65.741, wps=14603.2, ups=1.78, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=56, gb_free=15.5, wall=31175
2023-08-03 13:13:34 | INFO | train_inner | epoch 031:   1000 / 1474 loss=2.045, trans_loss=4.954, nll_loss=2.137, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.159, total=4186.81, n_correct=2750.41, ppl=4.4, accuracy=65.692, wps=14932.2, ups=1.78, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=56, gb_free=13.8, wall=31231
2023-08-03 13:14:30 | INFO | train_inner | epoch 031:   1100 / 1474 loss=2.04, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.11, total=4149.25, n_correct=2729.95, ppl=4.38, accuracy=65.794, wps=14822.6, ups=1.79, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=31287
2023-08-03 13:15:26 | INFO | train_inner | epoch 031:   1200 / 1474 loss=2.048, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.222, total=4187.45, n_correct=2750.8, ppl=4.4, accuracy=65.692, wps=14924.7, ups=1.78, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=56, gb_free=17.3, wall=31343
2023-08-03 13:16:22 | INFO | train_inner | epoch 031:   1300 / 1474 loss=2.039, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.068, total=4227.39, n_correct=2783.79, ppl=4.4, accuracy=65.851, wps=15060.4, ups=1.78, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=31399
2023-08-03 13:17:19 | INFO | train_inner | epoch 031:   1400 / 1474 loss=2.058, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.275, total=4191.1, n_correct=2746.82, ppl=4.41, accuracy=65.539, wps=14754.4, ups=1.76, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.636, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=31456
2023-08-03 13:18:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2389, device='cuda:1')
2023-08-03 13:18:23 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.353 | trans_loss 5.57 | nll_loss 2.843 | w2v_ctc_loss 1.399 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2490.5 | ppl 7.18 | accuracy 62.21 | uer 16.895 | wer 18.743 | raw_wer 18.743 | bleu 20.19 | wps 2223.8 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.35
2023-08-03 13:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-03 13:18:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1909.pt
2023-08-03 13:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1909.pt
2023-08-03 13:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint.best_bleu_20.1909.pt (epoch 31 @ 45674 updates, score 20.19) (writing took 13.088381184265018 seconds)
2023-08-03 13:18:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-03 13:18:37 | INFO | train | epoch 031 | loss 2.04 | trans_loss 4.947 | nll_loss 2.126 | w2v_ctc_loss 0.641 | task_loss 0 | contrastive_loss 0.111 | total 4138.45 | n_correct 2723.13 | ppl 4.36 | accuracy 65.801 | wps 13962.9 | ups 1.69 | wpb 8276.9 | bsz 305.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.612 | clip 0 | loss_scale 16 | train_wall 822 | gb_free 12.6 | wall 31533
2023-08-03 13:18:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 13:18:37 | INFO | fairseq.trainer | begin training epoch 32
2023-08-03 13:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 13:19:00 | INFO | train_inner | epoch 032:     26 / 1474 loss=2.037, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.055, total=4040.88, n_correct=2656.68, ppl=4.37, accuracy=65.745, wps=8040.7, ups=0.99, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.616, clip=0, loss_scale=16, train_wall=55, gb_free=15.9, wall=31556
2023-08-03 13:19:56 | INFO | train_inner | epoch 032:    126 / 1474 loss=2.013, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.067, total=4222.14, n_correct=2811.82, ppl=4.22, accuracy=66.597, wps=14930.2, ups=1.77, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=31613
2023-08-03 13:20:53 | INFO | train_inner | epoch 032:    226 / 1474 loss=2.027, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.079, total=4159.77, n_correct=2751.23, ppl=4.29, accuracy=66.139, wps=14793.2, ups=1.78, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=31669
2023-08-03 13:21:49 | INFO | train_inner | epoch 032:    326 / 1474 loss=2.016, trans_loss=4.917, nll_loss=2.087, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.071, total=4179.65, n_correct=2776.07, ppl=4.25, accuracy=66.419, wps=14919, ups=1.78, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.609, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=31725
2023-08-03 13:21:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:22:12 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.579 | nll_loss 2.853 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2484.6 | ppl 7.23 | accuracy 62.062 | uer 16.917 | wer 18.75 | raw_wer 18.75 | bleu 20.36 | wps 2232 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.36
2023-08-03 13:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-03 13:22:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_32_46000.pt
2023-08-03 13:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_32_46000.pt
2023-08-03 13:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.36) (writing took 34.443417958915234 seconds)
2023-08-03 13:23:43 | INFO | train_inner | epoch 032:    426 / 1474 loss=2.025, trans_loss=4.928, nll_loss=2.101, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.068, total=4172.34, n_correct=2765.68, ppl=4.29, accuracy=66.286, wps=7260, ups=0.87, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.616, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=31840
2023-08-03 13:24:40 | INFO | train_inner | epoch 032:    526 / 1474 loss=2.038, trans_loss=4.937, nll_loss=2.114, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.152, total=4191.15, n_correct=2770.8, ppl=4.33, accuracy=66.111, wps=14724.1, ups=1.76, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=56, gb_free=15.4, wall=31897
2023-08-03 13:25:37 | INFO | train_inner | epoch 032:    626 / 1474 loss=2.033, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.075, total=4138.05, n_correct=2728, ppl=4.34, accuracy=65.925, wps=14676.6, ups=1.77, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.614, clip=0, loss_scale=16, train_wall=56, gb_free=13.8, wall=31953
2023-08-03 13:26:33 | INFO | train_inner | epoch 032:    726 / 1474 loss=2.033, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.057, total=4156.23, n_correct=2743.62, ppl=4.34, accuracy=66.012, wps=14680.8, ups=1.77, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=32010
2023-08-03 13:27:29 | INFO | train_inner | epoch 032:    826 / 1474 loss=2.026, trans_loss=4.94, nll_loss=2.115, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.054, total=4112.3, n_correct=2717.77, ppl=4.33, accuracy=66.089, wps=14675.9, ups=1.78, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=32066
2023-08-03 13:28:26 | INFO | train_inner | epoch 032:    926 / 1474 loss=2.028, trans_loss=4.943, nll_loss=2.12, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.053, total=4139.37, n_correct=2726.14, ppl=4.35, accuracy=65.859, wps=14744.2, ups=1.78, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=56, gb_free=13.3, wall=32122
2023-08-03 13:29:21 | INFO | train_inner | epoch 032:   1026 / 1474 loss=2.044, trans_loss=4.954, nll_loss=2.134, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.147, total=4121.85, n_correct=2705.19, ppl=4.39, accuracy=65.63, wps=14780.1, ups=1.79, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.631, clip=0, loss_scale=16, train_wall=55, gb_free=17.1, wall=32178
2023-08-03 13:30:18 | INFO | train_inner | epoch 032:   1126 / 1474 loss=2.042, trans_loss=4.958, nll_loss=2.138, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.09, total=4015.59, n_correct=2630.59, ppl=4.4, accuracy=65.509, wps=14298.6, ups=1.78, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.622, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=32234
2023-08-03 13:31:14 | INFO | train_inner | epoch 032:   1226 / 1474 loss=2.052, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.201, total=4153.44, n_correct=2721.34, ppl=4.42, accuracy=65.52, wps=14711.7, ups=1.77, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.632, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=32291
2023-08-03 13:32:11 | INFO | train_inner | epoch 032:   1326 / 1474 loss=2.038, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.053, total=4075.86, n_correct=2676.33, ppl=4.39, accuracy=65.663, wps=14417.2, ups=1.77, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.621, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=32347
2023-08-03 13:33:07 | INFO | train_inner | epoch 032:   1426 / 1474 loss=2.056, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.287, total=4116.4, n_correct=2699.23, ppl=4.4, accuracy=65.573, wps=14724.5, ups=1.79, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=32403
2023-08-03 13:33:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:33:58 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.366 | trans_loss 5.574 | nll_loss 2.85 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2479.7 | ppl 7.21 | accuracy 61.94 | uer 17.052 | wer 18.735 | raw_wer 18.735 | bleu 19.93 | wps 2000.7 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.36
2023-08-03 13:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-03 13:33:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt (epoch 32 @ 47148 updates, score 19.93) (writing took 12.481463031843305 seconds)
2023-08-03 13:34:11 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-03 13:34:11 | INFO | train | epoch 032 | loss 2.034 | trans_loss 4.94 | nll_loss 2.117 | w2v_ctc_loss 0.635 | task_loss 0 | contrastive_loss 0.109 | total 4138.65 | n_correct 2729.78 | ppl 4.34 | accuracy 65.958 | wps 13062 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.61 | clip 0 | loss_scale 32 | train_wall 823 | gb_free 16.7 | wall 32468
2023-08-03 13:34:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 13:34:11 | INFO | fairseq.trainer | begin training epoch 33
2023-08-03 13:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 13:34:48 | INFO | train_inner | epoch 033:     52 / 1474 loss=2.036, trans_loss=4.936, nll_loss=2.113, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.161, total=4149.21, n_correct=2740.25, ppl=4.33, accuracy=66.043, wps=8209.2, ups=0.99, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.611, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=32504
2023-08-03 13:35:43 | INFO | train_inner | epoch 033:    152 / 1474 loss=2.014, trans_loss=4.918, nll_loss=2.086, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.044, total=4073.9, n_correct=2706.86, ppl=4.25, accuracy=66.444, wps=14593.9, ups=1.79, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=32560
2023-08-03 13:36:40 | INFO | train_inner | epoch 033:    252 / 1474 loss=2.034, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.23, total=4280.14, n_correct=2843.79, ppl=4.25, accuracy=66.442, wps=15182.9, ups=1.77, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.617, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=32616
2023-08-03 13:37:36 | INFO | train_inner | epoch 033:    352 / 1474 loss=2.026, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.078, total=4120.27, n_correct=2728.41, ppl=4.29, accuracy=66.219, wps=14742.4, ups=1.79, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.615, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=32672
2023-08-03 13:38:32 | INFO | train_inner | epoch 033:    452 / 1474 loss=2.014, trans_loss=4.915, nll_loss=2.083, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.052, total=4141.22, n_correct=2755.69, ppl=4.24, accuracy=66.543, wps=14833.6, ups=1.79, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=32728
2023-08-03 13:39:28 | INFO | train_inner | epoch 033:    552 / 1474 loss=2.032, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.077, total=4133.59, n_correct=2725.33, ppl=4.32, accuracy=65.931, wps=14678.8, ups=1.78, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.619, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=32785
2023-08-03 13:40:24 | INFO | train_inner | epoch 033:    652 / 1474 loss=2.034, trans_loss=4.947, nll_loss=2.125, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.108, total=4157.63, n_correct=2737.41, ppl=4.36, accuracy=65.841, wps=14869.3, ups=1.79, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=32840
2023-08-03 13:41:20 | INFO | train_inner | epoch 033:    752 / 1474 loss=2.037, trans_loss=4.944, nll_loss=2.12, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.054, total=4070.75, n_correct=2679.33, ppl=4.35, accuracy=65.819, wps=14515.8, ups=1.78, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.616, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=32897
2023-08-03 13:42:16 | INFO | train_inner | epoch 033:    852 / 1474 loss=2.021, trans_loss=4.928, nll_loss=2.102, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.126, total=4130.24, n_correct=2740.3, ppl=4.29, accuracy=66.347, wps=14804.1, ups=1.79, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.629, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=32952
2023-08-03 13:42:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:42:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.578 | nll_loss 2.852 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2485.1 | ppl 7.22 | accuracy 62.075 | uer 16.805 | wer 18.564 | raw_wer 18.564 | bleu 20.21 | wps 1848.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.36
2023-08-03 13:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-03 13:42:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_33_48000.pt
2023-08-03 13:42:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_33_48000.pt
2023-08-03 13:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.21) (writing took 20.795733954757452 seconds)
2023-08-03 13:44:00 | INFO | train_inner | epoch 033:    952 / 1474 loss=2.033, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.068, total=4151.18, n_correct=2738.86, ppl=4.34, accuracy=65.978, wps=7995.1, ups=0.96, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.61, clip=0, loss_scale=32, train_wall=56, gb_free=11.9, wall=33056
2023-08-03 13:44:56 | INFO | train_inner | epoch 033:   1052 / 1474 loss=2.037, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.173, total=4140.1, n_correct=2731.54, ppl=4.33, accuracy=65.978, wps=14743.7, ups=1.78, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=56, gb_free=12.3, wall=33112
2023-08-03 13:45:52 | INFO | train_inner | epoch 033:   1152 / 1474 loss=2.037, trans_loss=4.945, nll_loss=2.124, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.161, total=4182.67, n_correct=2756.22, ppl=4.36, accuracy=65.896, wps=14782.5, ups=1.77, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.621, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=33169
2023-08-03 13:46:48 | INFO | train_inner | epoch 033:   1252 / 1474 loss=2.031, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.059, total=4110.02, n_correct=2710.05, ppl=4.34, accuracy=65.938, wps=14669.9, ups=1.78, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.625, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=33225
2023-08-03 13:47:45 | INFO | train_inner | epoch 033:   1352 / 1474 loss=2.032, trans_loss=4.944, nll_loss=2.123, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.082, total=4128.82, n_correct=2724.94, ppl=4.36, accuracy=65.998, wps=14626.9, ups=1.77, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.617, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=33281
2023-08-03 13:48:41 | INFO | train_inner | epoch 033:   1452 / 1474 loss=2.039, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.223, total=4123.47, n_correct=2721.27, ppl=4.35, accuracy=65.995, wps=14606.5, ups=1.77, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.614, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=33338
2023-08-03 13:48:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 13:49:17 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.352 | trans_loss 5.577 | nll_loss 2.851 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2481.2 | ppl 7.22 | accuracy 61.977 | uer 16.776 | wer 18.411 | raw_wer 18.411 | bleu 19.84 | wps 2102.9 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.36
2023-08-03 13:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-03 13:49:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt
2023-08-03 13:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_last.pt (epoch 33 @ 48622 updates, score 19.84) (writing took 12.921147564426064 seconds)
2023-08-03 13:49:30 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-03 13:49:30 | INFO | train | epoch 033 | loss 2.03 | trans_loss 4.934 | nll_loss 2.109 | w2v_ctc_loss 0.631 | task_loss 0 | contrastive_loss 0.109 | total 4138.65 | n_correct 2735.8 | ppl 4.31 | accuracy 66.104 | wps 13279.3 | ups 1.6 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.615 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 18.1 | wall 33386
2023-08-03 13:49:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 13:49:30 | INFO | fairseq.trainer | begin training epoch 34
2023-08-03 13:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 13:50:21 | INFO | train_inner | epoch 034:     78 / 1474 loss=2.015, trans_loss=4.914, nll_loss=2.083, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.061, total=4128.94, n_correct=2748.65, ppl=4.24, accuracy=66.57, wps=8264.7, ups=1, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=33438
2023-08-03 13:51:17 | INFO | train_inner | epoch 034:    178 / 1474 loss=2.013, trans_loss=4.908, nll_loss=2.075, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.062, total=4071.22, n_correct=2711.77, ppl=4.21, accuracy=66.608, wps=14509.2, ups=1.78, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.614, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=33494
2023-08-03 13:52:14 | INFO | train_inner | epoch 034:    278 / 1474 loss=2.039, trans_loss=4.928, nll_loss=2.102, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.276, total=4237.89, n_correct=2803.11, ppl=4.29, accuracy=66.144, wps=14897.4, ups=1.76, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=56, gb_free=11.1, wall=33551
2023-08-03 13:52:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 13:53:11 | INFO | train_inner | epoch 034:    379 / 1474 loss=2.019, trans_loss=4.911, nll_loss=2.08, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.163, total=4153.56, n_correct=2765.67, ppl=4.23, accuracy=66.586, wps=14663.3, ups=1.77, wpb=8307.1, bsz=315.7, num_updates=49000, lr=6.38877e-05, gnorm=0.609, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=33608
2023-08-03 13:54:07 | INFO | train_inner | epoch 034:    479 / 1474 loss=2.025, trans_loss=4.929, nll_loss=2.101, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.054, total=4070.55, n_correct=2694.65, ppl=4.29, accuracy=66.199, wps=14595.2, ups=1.79, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.616, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=33663
2023-08-03 13:55:03 | INFO | train_inner | epoch 034:    579 / 1474 loss=2.018, trans_loss=4.918, nll_loss=2.088, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.058, total=4119.38, n_correct=2737.71, ppl=4.25, accuracy=66.459, wps=14746.5, ups=1.79, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.644, clip=0, loss_scale=32, train_wall=55, gb_free=13.6, wall=33719
2023-08-03 13:55:59 | INFO | train_inner | epoch 034:    679 / 1474 loss=2.018, trans_loss=4.923, nll_loss=2.096, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.051, total=4124.83, n_correct=2736.74, ppl=4.27, accuracy=66.348, wps=14611.9, ups=1.77, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.628, clip=0, loss_scale=32, train_wall=56, gb_free=14.7, wall=33776
2023-08-03 13:56:55 | INFO | train_inner | epoch 034:    779 / 1474 loss=2.029, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.123, total=4082.07, n_correct=2697.25, ppl=4.34, accuracy=66.076, wps=14537.8, ups=1.78, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=33832
2023-08-03 13:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-03 13:57:52 | INFO | train_inner | epoch 034:    880 / 1474 loss=2.027, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.083, total=4093.11, n_correct=2706.52, ppl=4.32, accuracy=66.124, wps=14418.4, ups=1.76, wpb=8186.2, bsz=295.1, num_updates=49500, lr=6.35642e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=56, gb_free=15.1, wall=33889
2023-08-03 13:58:48 | INFO | train_inner | epoch 034:    980 / 1474 loss=2.03, trans_loss=4.935, nll_loss=2.112, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.078, total=4175.9, n_correct=2761.72, ppl=4.32, accuracy=66.135, wps=14946.1, ups=1.79, wpb=8351.8, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.619, clip=0, loss_scale=16, train_wall=55, gb_free=14.2, wall=33944
2023-08-03 13:59:44 | INFO | train_inner | epoch 034:   1080 / 1474 loss=2.028, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.058, total=4152.17, n_correct=2744.89, ppl=4.33, accuracy=66.107, wps=14835.9, ups=1.79, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.626, clip=0, loss_scale=16, train_wall=56, gb_free=14.9, wall=34000
2023-08-03 14:00:40 | INFO | train_inner | epoch 034:   1180 / 1474 loss=2.024, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.071, total=4101.68, n_correct=2714.31, ppl=4.32, accuracy=66.176, wps=14612.9, ups=1.78, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=34057
2023-08-03 14:01:36 | INFO | train_inner | epoch 034:   1280 / 1474 loss=2.022, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.054, total=4146.01, n_correct=2743.79, ppl=4.3, accuracy=66.179, wps=14778.8, ups=1.78, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=56, gb_free=17.6, wall=34113
2023-08-03 14:02:32 | INFO | train_inner | epoch 034:   1380 / 1474 loss=2.038, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.122, total=4197.99, n_correct=2767.87, ppl=4.34, accuracy=65.933, wps=14885.1, ups=1.77, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=56, gb_free=17.5, wall=34169
2023-08-03 14:02:32 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-03 14:02:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 14:02:57 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.577 | nll_loss 2.851 | w2v_ctc_loss 1.403 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2482.9 | ppl 7.21 | accuracy 62.02 | uer 16.749 | wer 18.62 | raw_wer 18.62 | bleu 20 | wps 2039.1 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.36
2023-08-03 14:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-03 14:02:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_34_50000.pt
2023-08-03 14:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_34_50000.pt
2023-08-03 14:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0802_baseline/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.0) (writing took 14.151445645838976 seconds)
2023-08-03 14:03:12 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-03 14:03:12 | INFO | train | epoch 034 | loss 2.025 | trans_loss 4.928 | nll_loss 2.101 | w2v_ctc_loss 0.628 | task_loss 0 | contrastive_loss 0.096 | total 4132.55 | n_correct 2738.37 | ppl 4.29 | accuracy 66.263 | wps 13858.7 | ups 1.68 | wpb 8265.1 | bsz 304.1 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.614 | clip 0 | loss_scale 16 | train_wall 768 | gb_free 17.5 | wall 34208
2023-08-03 14:03:12 | INFO | fairseq_cli.train | done training in 34157.5 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
