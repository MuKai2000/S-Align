2023-08-10 01:00:33 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-10 01:00:34 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18059
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-10 01:00:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-10 01:00:35 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-10 01:00:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18059', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-10 01:00:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-10 01:00:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-10 01:00:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-10 01:00:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-10 01:00:39 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-10 01:00:44 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-10 01:00:44 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-10 01:00:44 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-10 01:00:45 | INFO | root | load pretrained hubert
2023-08-10 01:00:48 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-10 01:00:50 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-10 01:00:51 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-10 01:00:51 | INFO | root | share the sematic adapter and textual encoder
2023-08-10 01:00:51 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-10 01:00:51 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-10 01:00:51 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-10 01:00:51 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-10 01:00:51 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-10 01:00:51 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-10 01:00:51 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-10 01:00:51 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 01:00:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 01:00:51 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 01:00:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-10 01:00:57 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-10 01:00:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-10 01:00:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 01:00:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-10 01:00:57 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-10 01:00:57 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-10 01:00:57 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_last.pt
2023-08-10 01:00:57 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_last.pt
2023-08-10 01:00:57 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-10 01:00:57 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-10 01:00:57 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 01:00:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 01:00:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 01:01:01 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 01:01:50 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-10 01:01:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 01:01:50 | INFO | fairseq.trainer | begin training epoch 1
2023-08-10 01:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 01:03:08 | INFO | train_inner | epoch 001:    100 / 1474 loss=20.948, trans_loss=5.598, nll_loss=4.162, w2v_ctc_loss=22.489, task_loss=2.624, contrastive_loss=3.325, total=4207.04, n_correct=209.47, ppl=17.9, accuracy=4.979, wps=19403.1, ups=1.54, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.962, clip=0, loss_scale=128, train_wall=69, gb_free=19.5, wall=130
2023-08-10 01:04:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 01:04:13 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.856, trans_loss=5.472, nll_loss=4.057, w2v_ctc_loss=19.512, task_loss=2.555, contrastive_loss=3.285, total=4123.37, n_correct=223.95, ppl=16.65, accuracy=5.431, wps=18892.3, ups=1.53, wpb=12310.5, bsz=462.6, num_updates=200, lr=8.096e-06, gnorm=3.523, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=196
2023-08-10 01:05:17 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.839, trans_loss=5.494, nll_loss=4.138, w2v_ctc_loss=8.812, task_loss=2.555, contrastive_loss=3.202, total=4079.62, n_correct=203.25, ppl=17.6, accuracy=4.982, wps=18989, ups=1.56, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.65, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=260
2023-08-10 01:06:21 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.581, trans_loss=5.513, nll_loss=4.185, w2v_ctc_loss=6.809, task_loss=2.241, contrastive_loss=3.233, total=4174.14, n_correct=196.67, ppl=18.19, accuracy=4.712, wps=19439, ups=1.56, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.949, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=324
2023-08-10 01:07:25 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.14, trans_loss=5.494, nll_loss=4.176, w2v_ctc_loss=6.182, task_loss=2.049, contrastive_loss=3.219, total=4176.18, n_correct=191.49, ppl=18.07, accuracy=4.585, wps=19428.9, ups=1.56, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.465, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=388
2023-08-10 01:08:30 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.843, trans_loss=5.517, nll_loss=4.203, w2v_ctc_loss=5.829, task_loss=1.911, contrastive_loss=3.258, total=4147.79, n_correct=196.21, ppl=18.41, accuracy=4.73, wps=19024.9, ups=1.54, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=65, gb_free=18.9, wall=453
2023-08-10 01:09:34 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.581, trans_loss=5.5, nll_loss=4.192, w2v_ctc_loss=5.732, task_loss=1.987, contrastive_loss=2.987, total=4152.1, n_correct=214.8, ppl=18.28, accuracy=5.173, wps=19527.5, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=1.069, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=517
2023-08-10 01:10:38 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.272, trans_loss=5.445, nll_loss=4.136, w2v_ctc_loss=5.575, task_loss=1.921, contrastive_loss=2.9, total=4123.83, n_correct=252.67, ppl=17.59, accuracy=6.127, wps=19305.1, ups=1.57, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=1.554, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=580
2023-08-10 01:11:41 | INFO | train_inner | epoch 001:    901 / 1474 loss=8.996, trans_loss=5.422, nll_loss=4.118, w2v_ctc_loss=5.485, task_loss=1.952, contrastive_loss=2.687, total=4163.61, n_correct=269.55, ppl=17.36, accuracy=6.474, wps=19685.9, ups=1.58, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=2.429, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=644
2023-08-10 01:12:46 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.711, trans_loss=5.399, nll_loss=4.097, w2v_ctc_loss=5.347, task_loss=1.964, contrastive_loss=2.565, total=4135.34, n_correct=291.38, ppl=17.11, accuracy=7.046, wps=19008.4, ups=1.54, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=2.617, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=709
2023-08-10 01:13:49 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.396, trans_loss=5.391, nll_loss=4.089, w2v_ctc_loss=5.21, task_loss=1.98, contrastive_loss=2.375, total=4147.38, n_correct=309.13, ppl=17.01, accuracy=7.454, wps=19567.4, ups=1.58, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=3.091, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=772
2023-08-10 01:14:53 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.124, trans_loss=5.372, nll_loss=4.074, w2v_ctc_loss=5.095, task_loss=2.064, contrastive_loss=2.183, total=4139.9, n_correct=317.77, ppl=16.84, accuracy=7.676, wps=19410.6, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=3.072, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=835
2023-08-10 01:15:56 | INFO | train_inner | epoch 001:   1301 / 1474 loss=7.841, trans_loss=5.37, nll_loss=4.074, w2v_ctc_loss=4.928, task_loss=1.985, contrastive_loss=2.003, total=4046.58, n_correct=316.67, ppl=16.84, accuracy=7.826, wps=19244.3, ups=1.59, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=3.118, clip=0, loss_scale=64, train_wall=62, gb_free=19.7, wall=898
2023-08-10 01:17:00 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.573, trans_loss=5.362, nll_loss=4.07, w2v_ctc_loss=4.734, task_loss=1.962, contrastive_loss=2.068, total=4133.18, n_correct=325.51, ppl=16.79, accuracy=7.876, wps=19048.9, ups=1.54, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=2.831, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=963
2023-08-10 01:17:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 01:18:27 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.37 | trans_loss 10.979 | nll_loss 9.983 | w2v_ctc_loss 6.263 | task_loss 11.319 | contrastive_loss 2.484 | total 4003.4 | n_correct 377.2 | ppl 1012.25 | accuracy 9.422 | uer 79.24 | wer 78.714 | raw_wer 78.714 | bleu 0.02 | wps 1140.4 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-10 01:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-10 01:18:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 01:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 01:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 5.7118234392255545 seconds)
2023-08-10 01:18:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-10 01:18:33 | INFO | train | epoch 001 | loss 10.608 | trans_loss 5.449 | nll_loss 4.124 | w2v_ctc_loss 7.827 | task_loss 2.114 | contrastive_loss 2.768 | total 4138.5 | n_correct 255.196 | ppl 17.43 | accuracy 6.166 | wps 18382 | ups 1.49 | wpb 12355.3 | bsz 458.5 | num_updates 1473 | lr 5.89905e-05 | gnorm 2.471 | clip 0 | loss_scale 64 | train_wall 941 | gb_free 19.2 | wall 1056
2023-08-10 01:18:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 01:18:33 | INFO | fairseq.trainer | begin training epoch 2
2023-08-10 01:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 01:18:59 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.327, trans_loss=5.361, nll_loss=4.064, w2v_ctc_loss=4.536, task_loss=1.869, contrastive_loss=1.916, total=4162.95, n_correct=331.8, ppl=16.73, accuracy=7.97, wps=10478.9, ups=0.84, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=2.974, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1082
2023-08-10 01:20:02 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.07, trans_loss=5.362, nll_loss=4.064, w2v_ctc_loss=4.411, task_loss=1.994, contrastive_loss=1.707, total=4155.98, n_correct=331.31, ppl=16.73, accuracy=7.972, wps=19514.4, ups=1.57, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=3.096, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1145
2023-08-10 01:21:06 | INFO | train_inner | epoch 002:    227 / 1474 loss=6.869, trans_loss=5.345, nll_loss=4.048, w2v_ctc_loss=4.194, task_loss=1.73, contrastive_loss=1.729, total=4179.21, n_correct=335.76, ppl=16.54, accuracy=8.034, wps=19735.1, ups=1.58, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=2.769, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1208
2023-08-10 01:22:10 | INFO | train_inner | epoch 002:    327 / 1474 loss=6.583, trans_loss=5.347, nll_loss=4.046, w2v_ctc_loss=4.084, task_loss=1.987, contrastive_loss=1.431, total=4146.1, n_correct=339.1, ppl=16.52, accuracy=8.179, wps=19247.9, ups=1.56, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=2.492, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1273
2023-08-10 01:23:13 | INFO | train_inner | epoch 002:    427 / 1474 loss=6.344, trans_loss=5.343, nll_loss=4.045, w2v_ctc_loss=3.965, task_loss=2.184, contrastive_loss=1.24, total=4037.99, n_correct=329.55, ppl=16.51, accuracy=8.161, wps=19222.9, ups=1.59, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=2.567, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1335
2023-08-10 01:24:16 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.208, trans_loss=5.331, nll_loss=4.026, w2v_ctc_loss=3.771, task_loss=1.899, contrastive_loss=1.326, total=4176.97, n_correct=349.42, ppl=16.29, accuracy=8.365, wps=19728.9, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=2.291, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1399
2023-08-10 01:24:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 01:24:55 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.511 | trans_loss 10.868 | nll_loss 9.827 | w2v_ctc_loss 4.987 | task_loss 11.318 | contrastive_loss 1.672 | total 4003.4 | n_correct 396 | ppl 908.08 | accuracy 9.892 | uer 66.772 | wer 64.315 | raw_wer 64.315 | bleu 0.04 | wps 1172 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-08-10 01:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-10 01:24:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_2_2000.pt
2023-08-10 01:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_2_2000.pt
2023-08-10 01:25:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 47.50868122279644 seconds)
2023-08-10 01:26:47 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.993, trans_loss=5.325, nll_loss=4.018, w2v_ctc_loss=3.64, task_loss=1.963, contrastive_loss=1.12, total=4126.49, n_correct=354, ppl=16.2, accuracy=8.579, wps=8148.2, ups=0.66, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=2.074, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1550
2023-08-10 01:27:51 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.886, trans_loss=5.306, nll_loss=3.998, w2v_ctc_loss=3.522, task_loss=1.924, contrastive_loss=1.216, total=4149.06, n_correct=363.48, ppl=15.98, accuracy=8.761, wps=19484, ups=1.57, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.897, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1613
2023-08-10 01:28:54 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.739, trans_loss=5.292, nll_loss=3.981, w2v_ctc_loss=3.43, task_loss=1.976, contrastive_loss=1.154, total=4175.4, n_correct=370.91, ppl=15.79, accuracy=8.883, wps=19756.5, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.713, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1676
2023-08-10 01:29:57 | INFO | train_inner | epoch 002:    927 / 1474 loss=5.604, trans_loss=5.279, nll_loss=3.964, w2v_ctc_loss=3.314, task_loss=2.016, contrastive_loss=1.132, total=4104.2, n_correct=366.52, ppl=15.61, accuracy=8.93, wps=19459.3, ups=1.59, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.702, clip=0, loss_scale=128, train_wall=62, gb_free=19, wall=1739
2023-08-10 01:31:00 | INFO | train_inner | epoch 002:   1027 / 1474 loss=5.469, trans_loss=5.274, nll_loss=3.96, w2v_ctc_loss=3.221, task_loss=1.957, contrastive_loss=0.982, total=4102.5, n_correct=372.6, ppl=15.56, accuracy=9.082, wps=19451.8, ups=1.59, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=1.444, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1802
2023-08-10 01:31:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 01:32:05 | INFO | train_inner | epoch 002:   1128 / 1474 loss=5.394, trans_loss=5.263, nll_loss=3.944, w2v_ctc_loss=3.129, task_loss=1.828, contrastive_loss=1.052, total=4166.43, n_correct=386.66, ppl=15.4, accuracy=9.28, wps=19177.1, ups=1.54, wpb=12432.5, bsz=474.9, num_updates=2600, lr=0.000104048, gnorm=1.465, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=1867
2023-08-10 01:33:08 | INFO | train_inner | epoch 002:   1228 / 1474 loss=5.33, trans_loss=5.247, nll_loss=3.925, w2v_ctc_loss=3.054, task_loss=1.796, contrastive_loss=1.103, total=4219.96, n_correct=405.13, ppl=15.19, accuracy=9.6, wps=19801.1, ups=1.57, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=1.279, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1931
2023-08-10 01:34:11 | INFO | train_inner | epoch 002:   1328 / 1474 loss=5.159, trans_loss=5.227, nll_loss=3.903, w2v_ctc_loss=3.003, task_loss=1.875, contrastive_loss=0.814, total=4163.26, n_correct=406.36, ppl=14.96, accuracy=9.761, wps=19773.7, ups=1.59, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=1.195, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1994
2023-08-10 01:35:14 | INFO | train_inner | epoch 002:   1428 / 1474 loss=5.094, trans_loss=5.236, nll_loss=3.914, w2v_ctc_loss=2.952, task_loss=2.126, contrastive_loss=0.895, total=4049.42, n_correct=394.44, ppl=15.07, accuracy=9.741, wps=19125.2, ups=1.58, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=1.137, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=2057
2023-08-10 01:35:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 01:36:24 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.448 | trans_loss 10.305 | nll_loss 9.126 | w2v_ctc_loss 3.793 | task_loss 11.319 | contrastive_loss 0.969 | total 4003.4 | n_correct 498 | ppl 558.87 | accuracy 12.439 | uer 54.806 | wer 53.152 | raw_wer 53.152 | bleu 0.11 | wps 1154.6 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.11
2023-08-10 01:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-10 01:36:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 01:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 01:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.11) (writing took 24.54106741771102 seconds)
2023-08-10 01:36:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-10 01:36:49 | INFO | train | epoch 002 | loss 5.908 | trans_loss 5.297 | nll_loss 3.987 | w2v_ctc_loss 3.547 | task_loss 1.941 | contrastive_loss 1.21 | total 4137.19 | n_correct 365.271 | ppl 15.86 | accuracy 8.829 | wps 16603 | ups 1.34 | wpb 12351.4 | bsz 457.7 | num_updates 2946 | lr 0.000117881 | gnorm 1.931 | clip 0 | loss_scale 64 | train_wall 928 | gb_free 19.3 | wall 2152
2023-08-10 01:36:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 01:36:49 | INFO | fairseq.trainer | begin training epoch 3
2023-08-10 01:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 01:37:33 | INFO | train_inner | epoch 003:     54 / 1474 loss=4.982, trans_loss=5.206, nll_loss=3.876, w2v_ctc_loss=2.88, task_loss=1.994, contrastive_loss=0.791, total=4067, n_correct=415.07, ppl=14.69, accuracy=10.206, wps=8776.7, ups=0.72, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=1.094, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=2195
2023-08-10 01:37:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 01:37:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 01:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-10 01:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-10 01:39:08 | INFO | train_inner | epoch 003:    158 / 1474 loss=4.153, trans_loss=4.413, nll_loss=2.837, w2v_ctc_loss=2.546, task_loss=1.359, contrastive_loss=0.702, total=4144.24, n_correct=1125.18, ppl=7.14, accuracy=27.15, wps=13039.5, ups=1.05, wpb=12374.7, bsz=457.6, num_updates=3100, lr=0.000124038, gnorm=2.57, clip=1, loss_scale=4, train_wall=94, gb_free=16.6, wall=2290
2023-08-10 01:40:40 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.657, trans_loss=4.166, nll_loss=2.517, w2v_ctc_loss=2.28, task_loss=1.366, contrastive_loss=0.587, total=4161.13, n_correct=1417.43, ppl=5.72, accuracy=34.064, wps=13386.6, ups=1.08, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.761, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2383
2023-08-10 01:42:13 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.509, trans_loss=4.107, nll_loss=2.436, w2v_ctc_loss=2.165, task_loss=1.367, contrastive_loss=0.619, total=4150.02, n_correct=1503.75, ppl=5.41, accuracy=36.235, wps=13368.3, ups=1.08, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.59, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2476
2023-08-10 01:43:46 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.335, trans_loss=4.054, nll_loss=2.367, w2v_ctc_loss=2.058, task_loss=1.325, contrastive_loss=0.464, total=4209.57, n_correct=1609.15, ppl=5.16, accuracy=38.226, wps=13573, ups=1.08, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.396, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=2568
2023-08-10 01:45:17 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.218, trans_loss=4.024, nll_loss=2.329, w2v_ctc_loss=1.977, task_loss=1.454, contrastive_loss=0.444, total=4088.48, n_correct=1605.07, ppl=5.02, accuracy=39.258, wps=13309.5, ups=1.09, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.372, clip=0, loss_scale=4, train_wall=91, gb_free=17.6, wall=2660
2023-08-10 01:46:51 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.179, trans_loss=3.993, nll_loss=2.283, w2v_ctc_loss=1.906, task_loss=1.308, contrastive_loss=0.553, total=4221.58, n_correct=1716.35, ppl=4.87, accuracy=40.657, wps=13439.9, ups=1.07, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.362, clip=0, loss_scale=4, train_wall=93, gb_free=16.4, wall=2754
2023-08-10 01:48:22 | INFO | train_inner | epoch 003:    758 / 1474 loss=3.076, trans_loss=3.962, nll_loss=2.248, w2v_ctc_loss=1.884, task_loss=1.307, contrastive_loss=0.329, total=4167.41, n_correct=1732.86, ppl=4.75, accuracy=41.581, wps=13639.7, ups=1.1, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.421, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2845
2023-08-10 01:49:55 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.992, trans_loss=3.946, nll_loss=2.224, w2v_ctc_loss=1.823, task_loss=1.381, contrastive_loss=0.288, total=4165.53, n_correct=1769.11, ppl=4.67, accuracy=42.47, wps=13428.1, ups=1.08, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.19, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=2938
2023-08-10 01:51:28 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.971, trans_loss=3.925, nll_loss=2.196, w2v_ctc_loss=1.799, task_loss=1.325, contrastive_loss=0.32, total=4162.3, n_correct=1811.77, ppl=4.58, accuracy=43.528, wps=13404.3, ups=1.08, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.229, clip=0, loss_scale=4, train_wall=92, gb_free=16.8, wall=3030
2023-08-10 01:52:59 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.922, trans_loss=3.906, nll_loss=2.172, w2v_ctc_loss=1.783, task_loss=1.452, contrastive_loss=0.278, total=4069.95, n_correct=1787.44, ppl=4.51, accuracy=43.918, wps=13292.1, ups=1.09, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.162, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3122
2023-08-10 01:52:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 01:53:26 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.097 | trans_loss 6.411 | nll_loss 3.955 | w2v_ctc_loss 2.153 | task_loss 6.473 | contrastive_loss 0.385 | total 4003.4 | n_correct 1956.9 | ppl 15.5 | accuracy 48.881 | uer 30.929 | wer 31.52 | raw_wer 31.52 | bleu 11.14 | wps 1804.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.14
2023-08-10 01:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-10 01:53:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_3_4000.pt
2023-08-10 01:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_3_4000.pt
2023-08-10 01:54:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.14) (writing took 43.838216127827764 seconds)
2023-08-10 01:55:41 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.866, trans_loss=3.895, nll_loss=2.156, w2v_ctc_loss=1.734, task_loss=1.481, contrastive_loss=0.258, total=4038.49, n_correct=1798.45, ppl=4.46, accuracy=44.533, wps=7426.3, ups=0.62, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.098, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3284
2023-08-10 01:57:13 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.815, trans_loss=3.873, nll_loss=2.129, w2v_ctc_loss=1.699, task_loss=1.447, contrastive_loss=0.24, total=4064.31, n_correct=1846.04, ppl=4.38, accuracy=45.421, wps=13283.5, ups=1.09, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.06, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=3375
2023-08-10 01:58:45 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.816, trans_loss=3.854, nll_loss=2.105, w2v_ctc_loss=1.661, task_loss=1.382, contrastive_loss=0.351, total=4134.58, n_correct=1907.03, ppl=4.3, accuracy=46.124, wps=13358.3, ups=1.08, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1.103, clip=0, loss_scale=4, train_wall=92, gb_free=17.7, wall=3468
2023-08-10 02:00:18 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.783, trans_loss=3.843, nll_loss=2.091, w2v_ctc_loss=1.639, task_loss=1.303, contrastive_loss=0.328, total=4209.94, n_correct=1965.18, ppl=4.26, accuracy=46.68, wps=13487.5, ups=1.07, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=1.046, clip=0, loss_scale=4, train_wall=93, gb_free=17, wall=3561
2023-08-10 02:00:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 02:00:57 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.964 | trans_loss 6.286 | nll_loss 3.791 | w2v_ctc_loss 1.996 | task_loss 6.267 | contrastive_loss 0.387 | total 4003.4 | n_correct 2046.2 | ppl 13.84 | accuracy 51.112 | uer 29.915 | wer 30.282 | raw_wer 30.282 | bleu 12.67 | wps 1990.6 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.67
2023-08-10 02:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-10 02:00:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:01:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.67) (writing took 24.833613768219948 seconds)
2023-08-10 02:01:22 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-10 02:01:22 | INFO | train | epoch 003 | loss 3.227 | trans_loss 4.04 | nll_loss 2.348 | w2v_ctc_loss 1.957 | task_loss 1.396 | contrastive_loss 0.428 | total 4139.74 | n_correct 1640.99 | ppl 5.09 | accuracy 39.64 | wps 12334.6 | ups 1 | wpb 12359.1 | bsz 458.8 | num_updates 4416 | lr 0.000176652 | gnorm 1.368 | clip 0.1 | loss_scale 4 | train_wall 1337 | gb_free 16.4 | wall 3625
2023-08-10 02:01:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 02:01:22 | INFO | fairseq.trainer | begin training epoch 4
2023-08-10 02:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 02:02:47 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.675, trans_loss=3.813, nll_loss=2.049, w2v_ctc_loss=1.591, task_loss=1.417, contrastive_loss=0.188, total=4099.41, n_correct=1953.13, ppl=4.14, accuracy=47.644, wps=8234.3, ups=0.67, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.99, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3710
2023-08-10 02:04:18 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.66, trans_loss=3.792, nll_loss=2.023, w2v_ctc_loss=1.57, task_loss=1.312, contrastive_loss=0.211, total=4175.15, n_correct=2021.24, ppl=4.06, accuracy=48.411, wps=13671, ups=1.1, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.981, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=3801
2023-08-10 02:05:51 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.684, trans_loss=3.795, nll_loss=2.028, w2v_ctc_loss=1.564, task_loss=1.377, contrastive_loss=0.335, total=4145.23, n_correct=2003.24, ppl=4.08, accuracy=48.326, wps=13355.3, ups=1.08, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.956, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=3894
2023-08-10 02:07:23 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.624, trans_loss=3.794, nll_loss=2.023, w2v_ctc_loss=1.546, task_loss=1.433, contrastive_loss=0.182, total=4127.66, n_correct=2005.73, ppl=4.07, accuracy=48.592, wps=13389.5, ups=1.09, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.943, clip=0, loss_scale=4, train_wall=91, gb_free=17.4, wall=3986
2023-08-10 02:08:55 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.708, trans_loss=3.773, nll_loss=1.999, w2v_ctc_loss=1.508, task_loss=1.247, contrastive_loss=0.576, total=4218.78, n_correct=2080.62, ppl=4, accuracy=49.318, wps=13669.5, ups=1.09, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.964, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=4078
2023-08-10 02:10:28 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.62, trans_loss=3.767, nll_loss=1.992, w2v_ctc_loss=1.527, task_loss=1.297, contrastive_loss=0.253, total=4217.52, n_correct=2095.49, ppl=3.98, accuracy=49.685, wps=13551.5, ups=1.08, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.944, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=4171
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:0')
2023-08-10 02:12:02 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.586, trans_loss=3.769, nll_loss=1.989, w2v_ctc_loss=1.486, task_loss=1.411, contrastive_loss=0.3, total=4176.39, n_correct=2089.62, ppl=3.97, accuracy=50.034, wps=13302, ups=1.07, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.571, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=4264
2023-08-10 02:13:33 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.553, trans_loss=3.761, nll_loss=1.985, w2v_ctc_loss=1.501, task_loss=1.515, contrastive_loss=0.172, total=4026.63, n_correct=2018.74, ppl=3.96, accuracy=50.135, wps=13085, ups=1.09, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.581, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=4356
2023-08-10 02:14:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-10 02:15:07 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.548, trans_loss=3.745, nll_loss=1.964, w2v_ctc_loss=1.494, task_loss=1.408, contrastive_loss=0.185, total=4157.57, n_correct=2101.2, ppl=3.9, accuracy=50.539, wps=13316.7, ups=1.07, wpb=12416, bsz=454, num_updates=5300, lr=0.000194257, gnorm=0.571, clip=0, loss_scale=4, train_wall=93, gb_free=15.4, wall=4449
2023-08-10 02:16:39 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.535, trans_loss=3.735, nll_loss=1.953, w2v_ctc_loss=1.468, task_loss=1.403, contrastive_loss=0.217, total=4128.78, n_correct=2107.27, ppl=3.87, accuracy=51.039, wps=13328.8, ups=1.08, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.559, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=4542
2023-08-10 02:18:11 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.531, trans_loss=3.742, nll_loss=1.96, w2v_ctc_loss=1.475, task_loss=1.479, contrastive_loss=0.194, total=4080.2, n_correct=2079.67, ppl=3.89, accuracy=50.97, wps=13231, ups=1.09, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.56, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=4634
2023-08-10 02:19:43 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.56, trans_loss=3.731, nll_loss=1.95, w2v_ctc_loss=1.466, task_loss=1.288, contrastive_loss=0.306, total=4163.45, n_correct=2134.97, ppl=3.86, accuracy=51.279, wps=13490.1, ups=1.08, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.587, clip=0, loss_scale=4, train_wall=92, gb_free=15.1, wall=4726
2023-08-10 02:21:15 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.521, trans_loss=3.721, nll_loss=1.935, w2v_ctc_loss=1.446, task_loss=1.32, contrastive_loss=0.265, total=4152.41, n_correct=2153.56, ppl=3.83, accuracy=51.863, wps=13484.5, ups=1.09, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.564, clip=0, loss_scale=4, train_wall=91, gb_free=12.7, wall=4818
2023-08-10 02:22:45 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.469, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=1.438, task_loss=1.418, contrastive_loss=0.149, total=4103.57, n_correct=2133.28, ppl=3.81, accuracy=51.986, wps=13608.8, ups=1.11, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.536, clip=0, loss_scale=4, train_wall=90, gb_free=16.7, wall=4908
2023-08-10 02:24:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4377, device='cuda:5')
2023-08-10 02:24:31 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.585 | trans_loss 5.94 | nll_loss 3.324 | w2v_ctc_loss 1.626 | task_loss 6.638 | contrastive_loss 0.29 | total 4003.4 | n_correct 2244.8 | ppl 10.02 | accuracy 56.072 | uer 24.681 | wer 26.256 | raw_wer 26.256 | bleu 16 | wps 2080.9 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16
2023-08-10 02:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-10 02:24:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.0) (writing took 26.223035383969545 seconds)
2023-08-10 02:24:57 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-10 02:24:57 | INFO | train | epoch 004 | loss 2.583 | trans_loss 3.757 | nll_loss 1.98 | w2v_ctc_loss 1.499 | task_loss 1.38 | contrastive_loss 0.252 | total 4137.18 | n_correct 2074.46 | ppl 3.94 | accuracy 50.142 | wps 12854.6 | ups 1.04 | wpb 12351.5 | bsz 457.8 | num_updates 5889 | lr 0.000184287 | gnorm 0.722 | clip 0 | loss_scale 4 | train_wall 1349 | gb_free 14.8 | wall 5040
2023-08-10 02:24:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 02:24:58 | INFO | fairseq.trainer | begin training epoch 5
2023-08-10 02:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 02:25:16 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.453, trans_loss=3.707, nll_loss=1.917, w2v_ctc_loss=1.413, task_loss=1.446, contrastive_loss=0.165, total=4031.51, n_correct=2107.54, ppl=3.78, accuracy=52.277, wps=8005.9, ups=0.67, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.541, clip=0, loss_scale=4, train_wall=91, gb_free=14.2, wall=5059
2023-08-10 02:26:48 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.388, trans_loss=3.654, nll_loss=1.848, w2v_ctc_loss=1.339, task_loss=1.238, contrastive_loss=0.183, total=4256.63, n_correct=2297.18, ppl=3.6, accuracy=53.967, wps=13728.9, ups=1.08, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.524, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=5151
2023-08-10 02:26:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 02:27:13 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.567 | trans_loss 5.924 | nll_loss 3.297 | w2v_ctc_loss 1.601 | task_loss 6.627 | contrastive_loss 0.293 | total 4003.4 | n_correct 2252.4 | ppl 9.83 | accuracy 56.262 | uer 23.93 | wer 25.514 | raw_wer 25.514 | bleu 16.15 | wps 2019.5 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.15
2023-08-10 02:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-10 02:27:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_5_6000.pt
2023-08-10 02:27:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_5_6000.pt
2023-08-10 02:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.15) (writing took 29.296228874474764 seconds)
2023-08-10 02:29:14 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.442, trans_loss=3.664, nll_loss=1.859, w2v_ctc_loss=1.351, task_loss=1.286, contrastive_loss=0.38, total=4186.83, n_correct=2253.4, ppl=3.63, accuracy=53.821, wps=8592.4, ups=0.69, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.526, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=5297
2023-08-10 02:30:46 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.413, trans_loss=3.659, nll_loss=1.858, w2v_ctc_loss=1.368, task_loss=1.414, contrastive_loss=0.241, total=4094.07, n_correct=2192.35, ppl=3.62, accuracy=53.549, wps=13307.2, ups=1.09, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.527, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=5388
2023-08-10 02:32:18 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.42, trans_loss=3.653, nll_loss=1.849, w2v_ctc_loss=1.335, task_loss=1.352, contrastive_loss=0.325, total=4140.39, n_correct=2234.91, ppl=3.6, accuracy=53.978, wps=13406.8, ups=1.08, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.533, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=5481
2023-08-10 02:33:49 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.356, trans_loss=3.662, nll_loss=1.859, w2v_ctc_loss=1.343, task_loss=1.539, contrastive_loss=0.123, total=4026.21, n_correct=2165.77, ppl=3.63, accuracy=53.792, wps=13188, ups=1.1, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.516, clip=0, loss_scale=4, train_wall=91, gb_free=17, wall=5572
2023-08-10 02:35:22 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.399, trans_loss=3.667, nll_loss=1.863, w2v_ctc_loss=1.33, task_loss=1.429, contrastive_loss=0.293, total=4109.94, n_correct=2211.71, ppl=3.64, accuracy=53.814, wps=13277.4, ups=1.08, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.537, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=5664
2023-08-10 02:36:54 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.404, trans_loss=3.658, nll_loss=1.855, w2v_ctc_loss=1.331, task_loss=1.3, contrastive_loss=0.272, total=4176.83, n_correct=2260.05, ppl=3.62, accuracy=54.109, wps=13443.7, ups=1.08, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.534, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=5757
2023-08-10 02:38:27 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.368, trans_loss=3.66, nll_loss=1.855, w2v_ctc_loss=1.326, task_loss=1.428, contrastive_loss=0.197, total=4127.9, n_correct=2236.52, ppl=3.62, accuracy=54.181, wps=13361.6, ups=1.08, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.526, clip=0, loss_scale=4, train_wall=92, gb_free=15.6, wall=5849
2023-08-10 02:39:58 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.34, trans_loss=3.649, nll_loss=1.843, w2v_ctc_loss=1.314, task_loss=1.417, contrastive_loss=0.159, total=4101.19, n_correct=2235.14, ppl=3.59, accuracy=54.5, wps=13334.8, ups=1.09, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.518, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=5941
2023-08-10 02:41:30 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.36, trans_loss=3.651, nll_loss=1.846, w2v_ctc_loss=1.313, task_loss=1.363, contrastive_loss=0.239, total=4164.27, n_correct=2268.68, ppl=3.59, accuracy=54.48, wps=13590.2, ups=1.09, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.516, clip=0, loss_scale=4, train_wall=91, gb_free=14.9, wall=6033
2023-08-10 02:43:02 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.381, trans_loss=3.653, nll_loss=1.847, w2v_ctc_loss=1.326, task_loss=1.376, contrastive_loss=0.244, total=4168.94, n_correct=2276.76, ppl=3.6, accuracy=54.612, wps=13438.9, ups=1.08, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.527, clip=0, loss_scale=4, train_wall=92, gb_free=16.5, wall=6125
2023-08-10 02:44:35 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.325, trans_loss=3.649, nll_loss=1.843, w2v_ctc_loss=1.299, task_loss=1.401, contrastive_loss=0.147, total=4171.16, n_correct=2283, ppl=3.59, accuracy=54.733, wps=13461.5, ups=1.08, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.521, clip=0, loss_scale=4, train_wall=92, gb_free=15.8, wall=6218
2023-08-10 02:46:08 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.302, trans_loss=3.646, nll_loss=1.84, w2v_ctc_loss=1.287, task_loss=1.409, contrastive_loss=0.116, total=4126.97, n_correct=2259.72, ppl=3.58, accuracy=54.755, wps=13289.6, ups=1.08, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.507, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=6310
2023-08-10 02:47:39 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.318, trans_loss=3.644, nll_loss=1.84, w2v_ctc_loss=1.28, task_loss=1.391, contrastive_loss=0.175, total=4138.54, n_correct=2271.95, ppl=3.58, accuracy=54.897, wps=13484, ups=1.09, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.501, clip=0, loss_scale=4, train_wall=91, gb_free=16.7, wall=6402
2023-08-10 02:48:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 02:49:01 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.481 | trans_loss 5.854 | nll_loss 3.217 | w2v_ctc_loss 1.466 | task_loss 6.689 | contrastive_loss 0.294 | total 4003.4 | n_correct 2296.3 | ppl 9.3 | accuracy 57.359 | uer 22.873 | wer 24.753 | raw_wer 24.753 | bleu 16.82 | wps 2178.3 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 16.82
2023-08-10 02:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-10 02:49:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 02:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 5 @ 7363 updates, score 16.82) (writing took 27.5920849442482 seconds)
2023-08-10 02:49:29 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-10 02:49:29 | INFO | train | epoch 005 | loss 2.371 | trans_loss 3.654 | nll_loss 1.85 | w2v_ctc_loss 1.324 | task_loss 1.381 | contrastive_loss 0.221 | total 4138.65 | n_correct 2245.28 | ppl 3.6 | accuracy 54.251 | wps 12377.2 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.523 | clip 0 | loss_scale 8 | train_wall 1350 | gb_free 16.1 | wall 6511
2023-08-10 02:49:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 02:49:29 | INFO | fairseq.trainer | begin training epoch 6
2023-08-10 02:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 02:50:12 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.304, trans_loss=3.622, nll_loss=1.808, w2v_ctc_loss=1.278, task_loss=1.423, contrastive_loss=0.173, total=4113.87, n_correct=2280.78, ppl=3.5, accuracy=55.441, wps=8063.6, ups=0.66, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.515, clip=0, loss_scale=8, train_wall=92, gb_free=17.8, wall=6554
2023-08-10 02:51:44 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.265, trans_loss=3.591, nll_loss=1.769, w2v_ctc_loss=1.228, task_loss=1.367, contrastive_loss=0.219, total=4161.2, n_correct=2340.35, ppl=3.41, accuracy=56.242, wps=13483.8, ups=1.08, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.501, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=6646
2023-08-10 02:53:16 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.261, trans_loss=3.602, nll_loss=1.784, w2v_ctc_loss=1.26, task_loss=1.483, contrastive_loss=0.124, total=4110.12, n_correct=2298.24, ppl=3.44, accuracy=55.917, wps=13330.7, ups=1.09, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.49, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=6739
2023-08-10 02:54:50 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.322, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.212, task_loss=1.298, contrastive_loss=0.428, total=4170.52, n_correct=2352.1, ppl=3.41, accuracy=56.398, wps=13245.9, ups=1.06, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.514, clip=0, loss_scale=8, train_wall=94, gb_free=15.6, wall=6833
2023-08-10 02:56:22 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.236, trans_loss=3.593, nll_loss=1.772, w2v_ctc_loss=1.22, task_loss=1.328, contrastive_loss=0.139, total=4154.89, n_correct=2345.32, ppl=3.42, accuracy=56.447, wps=13489.6, ups=1.09, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.498, clip=0, loss_scale=8, train_wall=91, gb_free=16.3, wall=6924
2023-08-10 02:57:54 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.238, trans_loss=3.597, nll_loss=1.778, w2v_ctc_loss=1.231, task_loss=1.373, contrastive_loss=0.129, total=4174.46, n_correct=2358.94, ppl=3.43, accuracy=56.509, wps=13545.4, ups=1.09, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.506, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=7016
2023-08-10 02:59:26 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.247, trans_loss=3.6, nll_loss=1.781, w2v_ctc_loss=1.215, task_loss=1.314, contrastive_loss=0.184, total=4145.19, n_correct=2338.97, ppl=3.44, accuracy=56.426, wps=13458.9, ups=1.09, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.513, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=7108
2023-08-10 02:59:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 02:59:50 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.428 | trans_loss 5.782 | nll_loss 3.117 | w2v_ctc_loss 1.482 | task_loss 6.74 | contrastive_loss 0.272 | total 4003.4 | n_correct 2335.3 | ppl 8.67 | accuracy 58.333 | uer 22.143 | wer 23.892 | raw_wer 23.892 | bleu 17.84 | wps 2091.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.84
2023-08-10 02:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-10 02:59:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_6_8000.pt
2023-08-10 02:59:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_6_8000.pt
2023-08-10 03:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.84) (writing took 47.92922258377075 seconds)
2023-08-10 03:02:11 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.244, trans_loss=3.603, nll_loss=1.786, w2v_ctc_loss=1.231, task_loss=1.413, contrastive_loss=0.138, total=4151.01, n_correct=2342.1, ppl=3.45, accuracy=56.422, wps=7516.7, ups=0.61, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.492, clip=0, loss_scale=8, train_wall=92, gb_free=12.9, wall=7273
2023-08-10 03:03:42 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.235, trans_loss=3.611, nll_loss=1.796, w2v_ctc_loss=1.224, task_loss=1.465, contrastive_loss=0.122, total=4108.83, n_correct=2306.26, ppl=3.47, accuracy=56.129, wps=13410.5, ups=1.09, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.494, clip=0, loss_scale=8, train_wall=91, gb_free=17.1, wall=7365
2023-08-10 03:05:15 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.269, trans_loss=3.61, nll_loss=1.795, w2v_ctc_loss=1.228, task_loss=1.45, contrastive_loss=0.218, total=4076.46, n_correct=2291.08, ppl=3.47, accuracy=56.203, wps=13151.5, ups=1.08, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.505, clip=0, loss_scale=8, train_wall=92, gb_free=12.5, wall=7457
2023-08-10 03:06:46 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.267, trans_loss=3.594, nll_loss=1.775, w2v_ctc_loss=1.206, task_loss=1.296, contrastive_loss=0.289, total=4175.9, n_correct=2366.3, ppl=3.42, accuracy=56.666, wps=13579.2, ups=1.09, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.51, clip=0, loss_scale=8, train_wall=91, gb_free=14.1, wall=7549
2023-08-10 03:08:18 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.229, trans_loss=3.6, nll_loss=1.783, w2v_ctc_loss=1.22, task_loss=1.519, contrastive_loss=0.127, total=4077.2, n_correct=2301.37, ppl=3.44, accuracy=56.445, wps=13266.4, ups=1.09, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.501, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=7641
2023-08-10 03:09:51 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.304, trans_loss=3.593, nll_loss=1.777, w2v_ctc_loss=1.204, task_loss=1.357, contrastive_loss=0.437, total=4133.46, n_correct=2338.94, ppl=3.43, accuracy=56.586, wps=13247.7, ups=1.07, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.514, clip=0, loss_scale=8, train_wall=93, gb_free=12.2, wall=7734
2023-08-10 03:11:23 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.209, trans_loss=3.6, nll_loss=1.781, w2v_ctc_loss=1.202, task_loss=1.372, contrastive_loss=0.112, total=4127.77, n_correct=2341.79, ppl=3.44, accuracy=56.733, wps=13499.3, ups=1.1, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.498, clip=0, loss_scale=8, train_wall=91, gb_free=17, wall=7825
2023-08-10 03:12:55 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.205, trans_loss=3.59, nll_loss=1.771, w2v_ctc_loss=1.201, task_loss=1.39, contrastive_loss=0.116, total=4190.32, n_correct=2387.87, ppl=3.41, accuracy=56.985, wps=13529.9, ups=1.08, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.487, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=7918
2023-08-10 03:13:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 03:13:52 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.37 | trans_loss 5.739 | nll_loss 3.065 | w2v_ctc_loss 1.397 | task_loss 6.786 | contrastive_loss 0.262 | total 4003.4 | n_correct 2360.9 | ppl 8.37 | accuracy 58.972 | uer 20.407 | wer 22.24 | raw_wer 22.24 | bleu 18.11 | wps 2126 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 18.11
2023-08-10 03:13:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-10 03:13:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 03:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 03:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 6 @ 8837 updates, score 18.11) (writing took 28.378130627796054 seconds)
2023-08-10 03:14:21 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-10 03:14:21 | INFO | train | epoch 006 | loss 2.251 | trans_loss 3.598 | nll_loss 1.779 | w2v_ctc_loss 1.219 | task_loss 1.384 | contrastive_loss 0.198 | total 4138.65 | n_correct 2336.39 | ppl 3.43 | accuracy 56.453 | wps 12205.7 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.501 | clip 0 | loss_scale 8 | train_wall 1352 | gb_free 14.9 | wall 8004
2023-08-10 03:14:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 03:14:21 | INFO | fairseq.trainer | begin training epoch 7
2023-08-10 03:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 03:15:28 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.173, trans_loss=3.568, nll_loss=1.743, w2v_ctc_loss=1.168, task_loss=1.354, contrastive_loss=0.13, total=4110.43, n_correct=2363.01, ppl=3.35, accuracy=57.488, wps=8045.4, ups=0.66, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.487, clip=0, loss_scale=8, train_wall=91, gb_free=17.3, wall=8070
2023-08-10 03:16:59 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.183, trans_loss=3.558, nll_loss=1.729, w2v_ctc_loss=1.158, task_loss=1.408, contrastive_loss=0.204, total=4109.53, n_correct=2375.72, ppl=3.31, accuracy=57.81, wps=13391.3, ups=1.09, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.495, clip=0, loss_scale=8, train_wall=91, gb_free=13.5, wall=8162
2023-08-10 03:18:32 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.157, trans_loss=3.553, nll_loss=1.72, w2v_ctc_loss=1.16, task_loss=1.379, contrastive_loss=0.113, total=4133.29, n_correct=2402.58, ppl=3.3, accuracy=58.128, wps=13356.1, ups=1.08, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.49, clip=0, loss_scale=8, train_wall=92, gb_free=15.1, wall=8254
2023-08-10 03:20:04 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.223, trans_loss=3.562, nll_loss=1.733, w2v_ctc_loss=1.149, task_loss=1.344, contrastive_loss=0.372, total=4194.76, n_correct=2423.47, ppl=3.32, accuracy=57.774, wps=13534.3, ups=1.08, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.489, clip=0, loss_scale=8, train_wall=92, gb_free=12.9, wall=8347
2023-08-10 03:21:35 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.203, trans_loss=3.561, nll_loss=1.734, w2v_ctc_loss=1.148, task_loss=1.37, contrastive_loss=0.298, total=4153.22, n_correct=2398.21, ppl=3.33, accuracy=57.743, wps=13569.2, ups=1.09, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.492, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=8438
2023-08-10 03:23:07 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.153, trans_loss=3.561, nll_loss=1.731, w2v_ctc_loss=1.149, task_loss=1.355, contrastive_loss=0.118, total=4168.14, n_correct=2416.65, ppl=3.32, accuracy=57.979, wps=13560.6, ups=1.09, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.486, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=8530
2023-08-10 03:24:40 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.143, trans_loss=3.558, nll_loss=1.728, w2v_ctc_loss=1.143, task_loss=1.374, contrastive_loss=0.108, total=4157.82, n_correct=2416.36, ppl=3.31, accuracy=58.116, wps=13419.5, ups=1.08, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.481, clip=0, loss_scale=16, train_wall=92, gb_free=15.5, wall=8622
2023-08-10 03:26:12 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.144, trans_loss=3.556, nll_loss=1.727, w2v_ctc_loss=1.146, task_loss=1.448, contrastive_loss=0.105, total=4122.1, n_correct=2388.52, ppl=3.31, accuracy=57.944, wps=13300.8, ups=1.08, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.483, clip=0, loss_scale=16, train_wall=92, gb_free=15.6, wall=8715
2023-08-10 03:27:45 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.15, trans_loss=3.564, nll_loss=1.737, w2v_ctc_loss=1.145, task_loss=1.395, contrastive_loss=0.123, total=4147.23, n_correct=2398.01, ppl=3.33, accuracy=57.822, wps=13330.4, ups=1.08, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.48, clip=0, loss_scale=16, train_wall=92, gb_free=17.5, wall=8808
2023-08-10 03:29:17 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.169, trans_loss=3.557, nll_loss=1.73, w2v_ctc_loss=1.131, task_loss=1.318, contrastive_loss=0.214, total=4140.14, n_correct=2407.21, ppl=3.32, accuracy=58.143, wps=13442.2, ups=1.09, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.489, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=8900
2023-08-10 03:30:49 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.142, trans_loss=3.569, nll_loss=1.744, w2v_ctc_loss=1.15, task_loss=1.45, contrastive_loss=0.092, total=4103.51, n_correct=2373.79, ppl=3.35, accuracy=57.848, wps=13325.4, ups=1.09, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.485, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=8992
2023-08-10 03:32:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-10 03:32:22 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.194, trans_loss=3.554, nll_loss=1.729, w2v_ctc_loss=1.134, task_loss=1.389, contrastive_loss=0.294, total=4115.79, n_correct=2392.71, ppl=3.31, accuracy=58.135, wps=13163.2, ups=1.07, wpb=12298, bsz=460.5, num_updates=10000, lr=0.000141421, gnorm=0.495, clip=0, loss_scale=8, train_wall=93, gb_free=16.6, wall=9085
2023-08-10 03:32:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 03:32:45 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.327 | trans_loss 5.693 | nll_loss 3.008 | w2v_ctc_loss 1.362 | task_loss 6.879 | contrastive_loss 0.256 | total 4003.4 | n_correct 2394 | ppl 8.05 | accuracy 59.799 | uer 19.717 | wer 21.569 | raw_wer 21.569 | bleu 18.59 | wps 2222.4 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.59
2023-08-10 03:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-10 03:32:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_7_10000.pt
2023-08-10 03:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_7_10000.pt
2023-08-10 03:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.59) (writing took 44.353137996047735 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 03:35:02 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.137, trans_loss=3.563, nll_loss=1.739, w2v_ctc_loss=1.132, task_loss=1.412, contrastive_loss=0.117, total=4129.16, n_correct=2390.82, ppl=3.34, accuracy=57.901, wps=7734.9, ups=0.63, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.405, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=9244
2023-08-10 03:36:33 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.158, trans_loss=3.555, nll_loss=1.729, w2v_ctc_loss=1.144, task_loss=1.292, contrastive_loss=0.15, total=4177.71, n_correct=2432.72, ppl=3.31, accuracy=58.231, wps=13650.9, ups=1.09, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.412, clip=0, loss_scale=8, train_wall=91, gb_free=16.6, wall=9336
2023-08-10 03:38:07 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.171, trans_loss=3.561, nll_loss=1.738, w2v_ctc_loss=1.139, task_loss=1.489, contrastive_loss=0.219, total=4107.01, n_correct=2378.17, ppl=3.34, accuracy=57.905, wps=13010.9, ups=1.06, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.406, clip=0, loss_scale=8, train_wall=94, gb_free=13, wall=9430
2023-08-10 03:38:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
2023-08-10 03:38:42 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.325 | trans_loss 5.684 | nll_loss 2.997 | w2v_ctc_loss 1.381 | task_loss 6.865 | contrastive_loss 0.254 | total 4003.4 | n_correct 2390.8 | ppl 7.99 | accuracy 59.719 | uer 20.245 | wer 22.221 | raw_wer 22.221 | bleu 18.26 | wps 1914.3 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 18.59
2023-08-10 03:38:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-10 03:38:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.2603.pt
2023-08-10 03:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.2603.pt
2023-08-10 03:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.2603.pt (epoch 7 @ 10310 updates, score 18.26) (writing took 18.806182460859418 seconds)
2023-08-10 03:39:01 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-10 03:39:01 | INFO | train | epoch 007 | loss 2.166 | trans_loss 3.559 | nll_loss 1.731 | w2v_ctc_loss 1.145 | task_loss 1.387 | contrastive_loss 0.179 | total 4137.22 | n_correct 2397.84 | ppl 3.32 | accuracy 57.958 | wps 12293.1 | ups 1 | wpb 12351.6 | bsz 457.8 | num_updates 10310 | lr 0.000139279 | gnorm 0.471 | clip 0 | loss_scale 8 | train_wall 1352 | gb_free 13.1 | wall 9484
2023-08-10 03:39:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 03:39:01 | INFO | fairseq.trainer | begin training epoch 8
2023-08-10 03:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 03:40:32 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.102, trans_loss=3.537, nll_loss=1.7, w2v_ctc_loss=1.105, task_loss=1.477, contrastive_loss=0.111, total=4106.01, n_correct=2413.92, ppl=3.25, accuracy=58.79, wps=8484.3, ups=0.69, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.403, clip=0, loss_scale=8, train_wall=91, gb_free=17.1, wall=9574
2023-08-10 03:42:04 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.103, trans_loss=3.528, nll_loss=1.687, w2v_ctc_loss=1.1, task_loss=1.495, contrastive_loss=0.131, total=4043.12, n_correct=2388.14, ppl=3.22, accuracy=59.067, wps=13132.2, ups=1.09, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.406, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=9666
2023-08-10 03:43:36 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.101, trans_loss=3.523, nll_loss=1.685, w2v_ctc_loss=1.1, task_loss=1.298, contrastive_loss=0.127, total=4207.9, n_correct=2484.96, ppl=3.22, accuracy=59.055, wps=13581.5, ups=1.08, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.401, clip=0, loss_scale=8, train_wall=92, gb_free=13.9, wall=9759
2023-08-10 03:45:08 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.122, trans_loss=3.533, nll_loss=1.697, w2v_ctc_loss=1.116, task_loss=1.455, contrastive_loss=0.154, total=4134.6, n_correct=2431.62, ppl=3.24, accuracy=58.811, wps=13373.3, ups=1.08, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.403, clip=0, loss_scale=8, train_wall=92, gb_free=17.3, wall=9851
2023-08-10 03:46:41 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.19, trans_loss=3.528, nll_loss=1.693, w2v_ctc_loss=1.091, task_loss=1.25, contrastive_loss=0.407, total=4196.6, n_correct=2480.1, ppl=3.23, accuracy=59.098, wps=13469.8, ups=1.08, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.405, clip=0, loss_scale=8, train_wall=92, gb_free=12.6, wall=9944
2023-08-10 03:48:14 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.102, trans_loss=3.53, nll_loss=1.698, w2v_ctc_loss=1.117, task_loss=1.504, contrastive_loss=0.089, total=4065.55, n_correct=2389.33, ppl=3.25, accuracy=58.77, wps=13184.7, ups=1.08, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.406, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=10036
2023-08-10 03:49:46 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.095, trans_loss=3.526, nll_loss=1.689, w2v_ctc_loss=1.11, task_loss=1.432, contrastive_loss=0.1, total=4135.41, n_correct=2447.06, ppl=3.22, accuracy=59.173, wps=13373.3, ups=1.08, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.402, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=10129
2023-08-10 03:51:17 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.115, trans_loss=3.526, nll_loss=1.694, w2v_ctc_loss=1.101, task_loss=1.404, contrastive_loss=0.185, total=4128.86, n_correct=2438.92, ppl=3.23, accuracy=59.07, wps=13467.1, ups=1.09, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.403, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=10220
2023-08-10 03:52:50 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.113, trans_loss=3.527, nll_loss=1.694, w2v_ctc_loss=1.089, task_loss=1.336, contrastive_loss=0.191, total=4166.92, n_correct=2465.92, ppl=3.24, accuracy=59.178, wps=13399.6, ups=1.08, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.402, clip=0, loss_scale=8, train_wall=92, gb_free=14.3, wall=10313
2023-08-10 03:54:21 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.083, trans_loss=3.53, nll_loss=1.696, w2v_ctc_loss=1.091, task_loss=1.331, contrastive_loss=0.097, total=4150.39, n_correct=2455.56, ppl=3.24, accuracy=59.165, wps=13606.4, ups=1.1, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.4, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=10404
2023-08-10 03:55:54 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.141, trans_loss=3.533, nll_loss=1.7, w2v_ctc_loss=1.088, task_loss=1.369, contrastive_loss=0.32, total=4197.39, n_correct=2471.53, ppl=3.25, accuracy=58.883, wps=13512.3, ups=1.08, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.399, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=10497
2023-08-10 03:57:26 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.091, trans_loss=3.527, nll_loss=1.695, w2v_ctc_loss=1.094, task_loss=1.308, contrastive_loss=0.105, total=4180.55, n_correct=2472.88, ppl=3.24, accuracy=59.152, wps=13594.4, ups=1.09, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.401, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=10589
2023-08-10 03:58:57 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.102, trans_loss=3.533, nll_loss=1.702, w2v_ctc_loss=1.105, task_loss=1.446, contrastive_loss=0.127, total=4062.6, n_correct=2389.49, ppl=3.25, accuracy=58.817, wps=13356.7, ups=1.1, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.406, clip=0, loss_scale=8, train_wall=90, gb_free=12.9, wall=10680
2023-08-10 04:00:28 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.117, trans_loss=3.533, nll_loss=1.702, w2v_ctc_loss=1.09, task_loss=1.346, contrastive_loss=0.192, total=4159.11, n_correct=2458.9, ppl=3.25, accuracy=59.121, wps=13620.9, ups=1.1, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.404, clip=0, loss_scale=8, train_wall=91, gb_free=13.2, wall=10771
2023-08-10 04:01:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 04:02:08 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.296 | trans_loss 5.658 | nll_loss 2.958 | w2v_ctc_loss 1.346 | task_loss 6.876 | contrastive_loss 0.251 | total 4003.4 | n_correct 2411.6 | ppl 7.77 | accuracy 60.239 | uer 19.006 | wer 20.92 | raw_wer 20.92 | bleu 18.69 | wps 2227.8 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 18.69
2023-08-10 04:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-10 04:02:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 04:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 04:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 18.69) (writing took 25.298574421554804 seconds)
2023-08-10 04:02:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-10 04:02:34 | INFO | train | epoch 008 | loss 2.113 | trans_loss 3.53 | nll_loss 1.695 | w2v_ctc_loss 1.099 | task_loss 1.384 | contrastive_loss 0.173 | total 4138.65 | n_correct 2442.61 | ppl 3.24 | accuracy 59.02 | wps 12886.5 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.403 | clip 0 | loss_scale 8 | train_wall 1348 | gb_free 16.8 | wall 10897
2023-08-10 04:02:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 04:02:35 | INFO | fairseq.trainer | begin training epoch 9
2023-08-10 04:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 04:02:57 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.122, trans_loss=3.527, nll_loss=1.692, w2v_ctc_loss=1.078, task_loss=1.356, contrastive_loss=0.291, total=4121.25, n_correct=2440.99, ppl=3.23, accuracy=59.229, wps=8232.6, ups=0.67, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.412, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=10920
2023-08-10 04:04:29 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.052, trans_loss=3.492, nll_loss=1.648, w2v_ctc_loss=1.054, task_loss=1.305, contrastive_loss=0.124, total=4191.82, n_correct=2527.35, ppl=3.13, accuracy=60.292, wps=13640, ups=1.09, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.4, clip=0, loss_scale=8, train_wall=91, gb_free=15.9, wall=11012
2023-08-10 04:06:01 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.038, trans_loss=3.497, nll_loss=1.653, w2v_ctc_loss=1.055, task_loss=1.495, contrastive_loss=0.082, total=4061.27, n_correct=2438.31, ppl=3.14, accuracy=60.038, wps=13195.9, ups=1.09, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.402, clip=0, loss_scale=8, train_wall=91, gb_free=17.5, wall=11104
2023-08-10 04:06:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 04:06:24 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.282 | trans_loss 5.657 | nll_loss 2.958 | w2v_ctc_loss 1.301 | task_loss 6.855 | contrastive_loss 0.253 | total 4003.4 | n_correct 2410.7 | ppl 7.77 | accuracy 60.216 | uer 18.748 | wer 20.711 | raw_wer 20.711 | bleu 18.8 | wps 2183 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.8
2023-08-10 04:06:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-10 04:06:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_9_12000.pt
2023-08-10 04:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_9_12000.pt
2023-08-10 04:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.8) (writing took 45.45821852050722 seconds)
2023-08-10 04:08:42 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.043, trans_loss=3.487, nll_loss=1.644, w2v_ctc_loss=1.042, task_loss=1.311, contrastive_loss=0.131, total=4146.43, n_correct=2507.97, ppl=3.12, accuracy=60.485, wps=7707.6, ups=0.62, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.399, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=11265
2023-08-10 04:10:14 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.044, trans_loss=3.503, nll_loss=1.661, w2v_ctc_loss=1.052, task_loss=1.364, contrastive_loss=0.098, total=4194.84, n_correct=2509.33, ppl=3.16, accuracy=59.819, wps=13578.4, ups=1.08, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=11357
2023-08-10 04:11:45 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.081, trans_loss=3.509, nll_loss=1.668, w2v_ctc_loss=1.078, task_loss=1.458, contrastive_loss=0.151, total=4124.3, n_correct=2466.84, ppl=3.18, accuracy=59.812, wps=13539.4, ups=1.1, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.404, clip=0, loss_scale=16, train_wall=90, gb_free=11.3, wall=11448
2023-08-10 04:13:17 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.041, trans_loss=3.498, nll_loss=1.659, w2v_ctc_loss=1.049, task_loss=1.421, contrastive_loss=0.11, total=4120.96, n_correct=2472.02, ppl=3.16, accuracy=59.987, wps=13364.1, ups=1.09, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.401, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=11540
2023-08-10 04:14:49 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.085, trans_loss=3.51, nll_loss=1.672, w2v_ctc_loss=1.07, task_loss=1.41, contrastive_loss=0.192, total=4088.53, n_correct=2441.9, ppl=3.19, accuracy=59.726, wps=13365.6, ups=1.09, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.407, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=11631
2023-08-10 04:16:22 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.135, trans_loss=3.503, nll_loss=1.666, w2v_ctc_loss=1.063, task_loss=1.255, contrastive_loss=0.336, total=4220.43, n_correct=2525.06, ppl=3.17, accuracy=59.829, wps=13537.6, ups=1.07, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.416, clip=0, loss_scale=16, train_wall=92, gb_free=14.3, wall=11724
2023-08-10 04:17:55 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.105, trans_loss=3.509, nll_loss=1.669, w2v_ctc_loss=1.063, task_loss=1.434, contrastive_loss=0.319, total=4146.05, n_correct=2479.94, ppl=3.18, accuracy=59.815, wps=13278.5, ups=1.07, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.407, clip=0, loss_scale=16, train_wall=92, gb_free=17.7, wall=11818
2023-08-10 04:19:27 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.059, trans_loss=3.518, nll_loss=1.681, w2v_ctc_loss=1.069, task_loss=1.548, contrastive_loss=0.099, total=4101.48, n_correct=2442.12, ppl=3.21, accuracy=59.542, wps=13304.9, ups=1.09, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.412, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=11910
2023-08-10 04:20:58 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.06, trans_loss=3.513, nll_loss=1.673, w2v_ctc_loss=1.06, task_loss=1.304, contrastive_loss=0.12, total=4179.09, n_correct=2506.2, ppl=3.19, accuracy=59.97, wps=13629.7, ups=1.09, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.407, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=12001
2023-08-10 04:22:31 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.06, trans_loss=3.511, nll_loss=1.674, w2v_ctc_loss=1.073, task_loss=1.47, contrastive_loss=0.104, total=4140.66, n_correct=2476.37, ppl=3.19, accuracy=59.806, wps=13349.8, ups=1.08, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.403, clip=0, loss_scale=16, train_wall=92, gb_free=17, wall=12094
2023-08-10 04:24:02 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.107, trans_loss=3.507, nll_loss=1.668, w2v_ctc_loss=1.053, task_loss=1.263, contrastive_loss=0.301, total=4204.43, n_correct=2524.93, ppl=3.18, accuracy=60.054, wps=13744.4, ups=1.1, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.415, clip=0, loss_scale=16, train_wall=91, gb_free=17.6, wall=12185
2023-08-10 04:25:34 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.056, trans_loss=3.521, nll_loss=1.686, w2v_ctc_loss=1.071, task_loss=1.5, contrastive_loss=0.084, total=4069.19, n_correct=2426.71, ppl=3.22, accuracy=59.636, wps=13294.2, ups=1.09, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.415, clip=0, loss_scale=16, train_wall=91, gb_free=16.5, wall=12276
2023-08-10 04:26:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 04:26:49 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.631 | nll_loss 2.927 | w2v_ctc_loss 1.324 | task_loss 6.901 | contrastive_loss 0.241 | total 4003.4 | n_correct 2425.3 | ppl 7.61 | accuracy 60.581 | uer 18.501 | wer 20.249 | raw_wer 20.249 | bleu 18.81 | wps 2238.2 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.81
2023-08-10 04:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-10 04:26:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 04:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 04:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 18.81) (writing took 24.694089083001018 seconds)
2023-08-10 04:27:14 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-10 04:27:14 | INFO | train | epoch 009 | loss 2.07 | trans_loss 3.506 | nll_loss 1.666 | w2v_ctc_loss 1.061 | task_loss 1.388 | contrastive_loss 0.167 | total 4138.65 | n_correct 2479.82 | ppl 3.17 | accuracy 59.919 | wps 12306.6 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.406 | clip 0 | loss_scale 16 | train_wall 1346 | gb_free 11.4 | wall 12377
2023-08-10 04:27:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 04:27:14 | INFO | fairseq.trainer | begin training epoch 10
2023-08-10 04:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 04:28:01 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.056, trans_loss=3.498, nll_loss=1.656, w2v_ctc_loss=1.039, task_loss=1.32, contrastive_loss=0.179, total=4100.8, n_correct=2473.53, ppl=3.15, accuracy=60.318, wps=8309, ups=0.68, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.407, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=12424
2023-08-10 04:29:33 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.002, trans_loss=3.471, nll_loss=1.622, w2v_ctc_loss=1.014, task_loss=1.309, contrastive_loss=0.103, total=4247.35, n_correct=2589.68, ppl=3.08, accuracy=60.972, wps=13840.8, ups=1.09, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.4, clip=0, loss_scale=16, train_wall=91, gb_free=11.4, wall=12515
2023-08-10 04:31:04 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.046, trans_loss=3.475, nll_loss=1.626, w2v_ctc_loss=1.027, task_loss=1.367, contrastive_loss=0.226, total=4122.82, n_correct=2507.85, ppl=3.09, accuracy=60.829, wps=13413.5, ups=1.09, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.413, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=12607
2023-08-10 04:32:36 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.018, trans_loss=3.475, nll_loss=1.63, w2v_ctc_loss=1.021, task_loss=1.405, contrastive_loss=0.138, total=4138.27, n_correct=2514.87, ppl=3.1, accuracy=60.771, wps=13419, ups=1.08, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.408, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=12699
2023-08-10 04:34:09 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.055, trans_loss=3.48, nll_loss=1.633, w2v_ctc_loss=1.008, task_loss=1.333, contrastive_loss=0.309, total=4196.37, n_correct=2547.39, ppl=3.1, accuracy=60.705, wps=13471.8, ups=1.08, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.402, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=12792
2023-08-10 04:35:41 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.027, trans_loss=3.495, nll_loss=1.648, w2v_ctc_loss=1.044, task_loss=1.484, contrastive_loss=0.092, total=4102.8, n_correct=2476.47, ppl=3.13, accuracy=60.36, wps=13343.2, ups=1.09, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=17, wall=12884
2023-08-10 04:37:13 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.053, trans_loss=3.49, nll_loss=1.645, w2v_ctc_loss=1.031, task_loss=1.319, contrastive_loss=0.203, total=4176.56, n_correct=2531.57, ppl=3.13, accuracy=60.614, wps=13568.1, ups=1.09, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.404, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=12976
2023-08-10 04:38:44 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.03, trans_loss=3.49, nll_loss=1.646, w2v_ctc_loss=1.047, task_loss=1.39, contrastive_loss=0.091, total=4125.87, n_correct=2493.32, ppl=3.13, accuracy=60.431, wps=13472.4, ups=1.09, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=14.2, wall=13067
2023-08-10 04:38:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 04:39:08 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.275 | trans_loss 5.628 | nll_loss 2.918 | w2v_ctc_loss 1.347 | task_loss 6.893 | contrastive_loss 0.25 | total 4003.4 | n_correct 2432.1 | ppl 7.56 | accuracy 60.751 | uer 18.942 | wer 20.726 | raw_wer 20.726 | bleu 19.34 | wps 2205.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.34
2023-08-10 04:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-10 04:39:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_10_14000.pt
2023-08-10 04:39:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_10_14000.pt
2023-08-10 04:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.34) (writing took 43.10218219272792 seconds)
2023-08-10 04:41:23 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.008, trans_loss=3.485, nll_loss=1.64, w2v_ctc_loss=1.02, task_loss=1.373, contrastive_loss=0.093, total=4128.44, n_correct=2505.67, ppl=3.12, accuracy=60.693, wps=7770.6, ups=0.63, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.394, clip=0, loss_scale=32, train_wall=91, gb_free=14.7, wall=13226
2023-08-10 04:42:54 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.03, trans_loss=3.487, nll_loss=1.641, w2v_ctc_loss=1.031, task_loss=1.332, contrastive_loss=0.128, total=4160.94, n_correct=2525.55, ppl=3.12, accuracy=60.697, wps=13618.8, ups=1.1, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.408, clip=0, loss_scale=32, train_wall=91, gb_free=15.3, wall=13317
2023-08-10 04:44:27 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.021, trans_loss=3.491, nll_loss=1.648, w2v_ctc_loss=1.032, task_loss=1.501, contrastive_loss=0.103, total=4067.53, n_correct=2454.41, ppl=3.13, accuracy=60.342, wps=13154.5, ups=1.08, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.406, clip=0, loss_scale=32, train_wall=92, gb_free=16.8, wall=13409
2023-08-10 04:45:57 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.028, trans_loss=3.498, nll_loss=1.657, w2v_ctc_loss=1.047, task_loss=1.548, contrastive_loss=0.089, total=4044.03, n_correct=2433.13, ppl=3.15, accuracy=60.166, wps=13313.2, ups=1.1, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.403, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=13500
2023-08-10 04:47:29 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.018, trans_loss=3.487, nll_loss=1.648, w2v_ctc_loss=1.04, task_loss=1.423, contrastive_loss=0.084, total=4110.41, n_correct=2486.1, ppl=3.13, accuracy=60.483, wps=13434.7, ups=1.09, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.399, clip=0, loss_scale=32, train_wall=91, gb_free=16.4, wall=13591
2023-08-10 04:49:00 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.016, trans_loss=3.493, nll_loss=1.653, w2v_ctc_loss=1.032, task_loss=1.419, contrastive_loss=0.094, total=4121.38, n_correct=2493.74, ppl=3.14, accuracy=60.507, wps=13443.1, ups=1.09, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.4, clip=0, loss_scale=32, train_wall=91, gb_free=13.8, wall=13683
2023-08-10 04:49:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 04:50:33 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.047, trans_loss=3.496, nll_loss=1.653, w2v_ctc_loss=1.02, task_loss=1.334, contrastive_loss=0.197, total=4177.73, n_correct=2528.71, ppl=3.15, accuracy=60.528, wps=13438, ups=1.08, wpb=12461.7, bsz=472.7, num_updates=14700, lr=0.000116642, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=13776
2023-08-10 04:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 04:51:24 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.267 | trans_loss 5.618 | nll_loss 2.908 | w2v_ctc_loss 1.346 | task_loss 6.885 | contrastive_loss 0.248 | total 4003.4 | n_correct 2434.5 | ppl 7.5 | accuracy 60.811 | uer 18.265 | wer 19.824 | raw_wer 19.824 | bleu 18.76 | wps 2279.4 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 19.34
2023-08-10 04:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-10 04:51:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.7601.pt
2023-08-10 04:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.7601.pt
2023-08-10 04:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_18.7601.pt (epoch 10 @ 14731 updates, score 18.76) (writing took 15.263734055683017 seconds)
2023-08-10 04:51:40 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-10 04:51:40 | INFO | train | epoch 010 | loss 2.03 | trans_loss 3.486 | nll_loss 1.642 | w2v_ctc_loss 1.028 | task_loss 1.39 | contrastive_loss 0.15 | total 4137.35 | n_correct 2506.82 | ppl 3.12 | accuracy 60.59 | wps 12415 | ups 1.01 | wpb 12351.9 | bsz 457.7 | num_updates 14731 | lr 0.00011652 | gnorm 0.405 | clip 0 | loss_scale 16 | train_wall 1343 | gb_free 17.2 | wall 13842
2023-08-10 04:51:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 04:51:40 | INFO | fairseq.trainer | begin training epoch 11
2023-08-10 04:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 04:52:50 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.003, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=1.002, task_loss=1.293, contrastive_loss=0.17, total=4166, n_correct=2557.37, ppl=3.06, accuracy=61.387, wps=9092.6, ups=0.73, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.396, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=13912
2023-08-10 04:54:22 | INFO | train_inner | epoch 011:    169 / 1474 loss=1.984, trans_loss=3.462, nll_loss=1.612, w2v_ctc_loss=1.003, task_loss=1.421, contrastive_loss=0.094, total=4100.74, n_correct=2516.27, ppl=3.06, accuracy=61.361, wps=13288.5, ups=1.08, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.399, clip=0, loss_scale=16, train_wall=91, gb_free=14.3, wall=14005
2023-08-10 04:55:53 | INFO | train_inner | epoch 011:    269 / 1474 loss=1.971, trans_loss=3.461, nll_loss=1.61, w2v_ctc_loss=0.995, task_loss=1.429, contrastive_loss=0.08, total=4115.58, n_correct=2530.58, ppl=3.05, accuracy=61.488, wps=13473.7, ups=1.1, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.397, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=14096
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 04:57:02 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.11, trans_loss=5.151, nll_loss=2.402, w2v_ctc_loss=0.746, task_loss=2.133, contrastive_loss=0.067, total=4094.16, n_correct=2507.84, ppl=5.29, accuracy=61.254, wps=12010.4, ups=1.46, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=12.6, wall=14164
2023-08-10 04:58:11 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.137, trans_loss=5.185, nll_loss=2.427, w2v_ctc_loss=0.749, task_loss=2.148, contrastive_loss=0.189, total=4112.8, n_correct=2506.49, ppl=5.38, accuracy=60.944, wps=11923.7, ups=1.45, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=14233
2023-08-10 04:59:20 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.135, trans_loss=5.184, nll_loss=2.425, w2v_ctc_loss=0.755, task_loss=2.24, contrastive_loss=0.183, total=4071.06, n_correct=2483.87, ppl=5.37, accuracy=61.013, wps=11840.7, ups=1.45, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=14302
2023-08-10 05:00:28 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.14, trans_loss=5.181, nll_loss=2.422, w2v_ctc_loss=0.748, task_loss=2.046, contrastive_loss=0.245, total=4156.4, n_correct=2538.91, ppl=5.36, accuracy=61.084, wps=12138.8, ups=1.46, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=14371
2023-08-10 05:01:37 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.123, trans_loss=5.19, nll_loss=2.435, w2v_ctc_loss=0.759, task_loss=2.107, contrastive_loss=0.067, total=4169.17, n_correct=2545.71, ppl=5.41, accuracy=61.06, wps=12041.3, ups=1.44, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=12, wall=14440
2023-08-10 05:02:46 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.122, trans_loss=5.192, nll_loss=2.437, w2v_ctc_loss=0.756, task_loss=2.174, contrastive_loss=0.058, total=4120.01, n_correct=2508.91, ppl=5.41, accuracy=60.896, wps=11985.5, ups=1.45, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=14509
2023-08-10 05:03:55 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.121, trans_loss=5.19, nll_loss=2.435, w2v_ctc_loss=0.757, task_loss=2.107, contrastive_loss=0.07, total=4145.45, n_correct=2528.46, ppl=5.41, accuracy=60.994, wps=12006, ups=1.45, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=14578
2023-08-10 05:05:03 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.123, trans_loss=5.188, nll_loss=2.433, w2v_ctc_loss=0.759, task_loss=2.033, contrastive_loss=0.086, total=4141.18, n_correct=2529.53, ppl=5.4, accuracy=61.082, wps=12141.2, ups=1.47, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=14646
2023-08-10 05:06:12 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.126, trans_loss=5.196, nll_loss=2.443, w2v_ctc_loss=0.762, task_loss=2.082, contrastive_loss=0.073, total=4173.93, n_correct=2543.9, ppl=5.44, accuracy=60.947, wps=12130.8, ups=1.45, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=14715
2023-08-10 05:07:22 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.132, trans_loss=5.188, nll_loss=2.434, w2v_ctc_loss=0.76, task_loss=1.993, contrastive_loss=0.14, total=4174.26, n_correct=2547.33, ppl=5.4, accuracy=61.025, wps=11971.4, ups=1.43, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.545, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=14785
2023-08-10 05:07:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
2023-08-10 05:07:45 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.263 | trans_loss 5.611 | nll_loss 2.9 | w2v_ctc_loss 1.353 | task_loss 6.894 | contrastive_loss 0.245 | total 4003.4 | n_correct 2442.8 | ppl 7.46 | accuracy 61.018 | uer 18.212 | wer 20.074 | raw_wer 20.074 | bleu 19.18 | wps 2304.5 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.34
2023-08-10 05:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-10 05:07:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_11_16000.pt
2023-08-10 05:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_11_16000.pt
2023-08-10 05:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.18) (writing took 40.12241539359093 seconds)
2023-08-10 05:09:35 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.147, trans_loss=5.189, nll_loss=2.436, w2v_ctc_loss=0.745, task_loss=1.917, contrastive_loss=0.301, total=4191.56, n_correct=2552.73, ppl=5.41, accuracy=60.902, wps=6307, ups=0.75, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=14917
2023-08-10 05:10:43 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.118, trans_loss=5.192, nll_loss=2.44, w2v_ctc_loss=0.751, task_loss=1.997, contrastive_loss=0.077, total=4161.81, n_correct=2536.86, ppl=5.42, accuracy=60.956, wps=12153.9, ups=1.46, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=14986
2023-08-10 05:10:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 05:11:10 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.604 | nll_loss 2.895 | w2v_ctc_loss 1.285 | task_loss 6.915 | contrastive_loss 0.247 | total 4003.4 | n_correct 2440.9 | ppl 7.44 | accuracy 60.971 | uer 18.071 | wer 19.858 | raw_wer 19.858 | bleu 19.52 | wps 2103.3 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.52
2023-08-10 05:11:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-10 05:11:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 05:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 05:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 11 @ 16205 updates, score 19.52) (writing took 24.44444253668189 seconds)
2023-08-10 05:11:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-10 05:11:36 | INFO | train | epoch 011 | loss 2.091 | trans_loss 4.755 | nll_loss 2.225 | w2v_ctc_loss 0.815 | task_loss 1.905 | contrastive_loss 0.12 | total 4138.65 | n_correct 2528.6 | ppl 4.68 | accuracy 61.097 | wps 11123.2 | ups 1.23 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.51 | clip 0 | loss_scale 16 | train_wall 1066 | gb_free 17.1 | wall 15038
2023-08-10 05:11:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 05:11:36 | INFO | fairseq.trainer | begin training epoch 12
2023-08-10 05:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 05:12:50 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.097, trans_loss=5.135, nll_loss=2.363, w2v_ctc_loss=0.736, task_loss=2.007, contrastive_loss=0.109, total=4139.2, n_correct=2565.5, ppl=5.15, accuracy=61.981, wps=6519.4, ups=0.79, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=15113
2023-08-10 05:13:58 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.099, trans_loss=5.146, nll_loss=2.377, w2v_ctc_loss=0.744, task_loss=2.143, contrastive_loss=0.061, total=4126.87, n_correct=2550.38, ppl=5.19, accuracy=61.799, wps=12132.6, ups=1.47, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.533, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=15181
2023-08-10 05:15:07 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.092, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.727, task_loss=1.95, contrastive_loss=0.088, total=4203.54, n_correct=2604.15, ppl=5.17, accuracy=61.951, wps=12181.7, ups=1.45, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=15250
2023-08-10 05:16:17 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.098, trans_loss=5.151, nll_loss=2.384, w2v_ctc_loss=0.737, task_loss=2.035, contrastive_loss=0.075, total=4149.28, n_correct=2559.88, ppl=5.22, accuracy=61.695, wps=11966.4, ups=1.44, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=15319
2023-08-10 05:17:25 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.112, trans_loss=5.169, nll_loss=2.408, w2v_ctc_loss=0.749, task_loss=2.109, contrastive_loss=0.082, total=4106.46, n_correct=2522.16, ppl=5.31, accuracy=61.419, wps=12047.4, ups=1.47, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=15388
2023-08-10 05:18:34 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.108, trans_loss=5.155, nll_loss=2.39, w2v_ctc_loss=0.738, task_loss=1.985, contrastive_loss=0.144, total=4190.91, n_correct=2586.74, ppl=5.24, accuracy=61.723, wps=12096.1, ups=1.44, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=15457
2023-08-10 05:19:43 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.111, trans_loss=5.152, nll_loss=2.388, w2v_ctc_loss=0.726, task_loss=1.911, contrastive_loss=0.234, total=4203.66, n_correct=2600.55, ppl=5.23, accuracy=61.864, wps=12141.7, ups=1.44, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=15526
2023-08-10 05:20:51 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.102, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.743, task_loss=2.103, contrastive_loss=0.073, total=4095.72, n_correct=2523.43, ppl=5.24, accuracy=61.611, wps=12034.1, ups=1.47, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15594
2023-08-10 05:22:00 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.113, trans_loss=5.162, nll_loss=2.4, w2v_ctc_loss=0.743, task_loss=2.132, contrastive_loss=0.121, total=4162.82, n_correct=2559.86, ppl=5.28, accuracy=61.493, wps=12108.4, ups=1.45, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=15663
2023-08-10 05:23:09 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.114, trans_loss=5.171, nll_loss=2.411, w2v_ctc_loss=0.743, task_loss=2.114, contrastive_loss=0.133, total=4117.63, n_correct=2527.27, ppl=5.32, accuracy=61.377, wps=11953.5, ups=1.45, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=15732
2023-08-10 05:24:17 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.128, trans_loss=5.176, nll_loss=2.418, w2v_ctc_loss=0.75, task_loss=2.186, contrastive_loss=0.176, total=4046.48, n_correct=2481.16, ppl=5.35, accuracy=61.317, wps=11902.8, ups=1.47, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.537, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=15800
2023-08-10 05:25:26 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.126, trans_loss=5.182, nll_loss=2.428, w2v_ctc_loss=0.756, task_loss=2.029, contrastive_loss=0.141, total=4201.13, n_correct=2570.4, ppl=5.38, accuracy=61.184, wps=12188.6, ups=1.45, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15869
2023-08-10 05:26:35 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.114, trans_loss=5.174, nll_loss=2.416, w2v_ctc_loss=0.757, task_loss=2.309, contrastive_loss=0.059, total=4070.27, n_correct=2494.7, ppl=5.34, accuracy=61.291, wps=11751, ups=1.44, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=15938
2023-08-10 05:27:44 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.121, trans_loss=5.178, nll_loss=2.422, w2v_ctc_loss=0.742, task_loss=2.096, contrastive_loss=0.164, total=4139.63, n_correct=2536.25, ppl=5.36, accuracy=61.268, wps=12108, ups=1.46, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=16006
2023-08-10 05:28:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 05:29:01 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.249 | trans_loss 5.59 | nll_loss 2.879 | w2v_ctc_loss 1.353 | task_loss 6.904 | contrastive_loss 0.244 | total 4003.4 | n_correct 2455.5 | ppl 7.36 | accuracy 61.335 | uer 18.236 | wer 20.003 | raw_wer 20.003 | bleu 19.45 | wps 2238.9 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.52
2023-08-10 05:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-10 05:29:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4502.pt
2023-08-10 05:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4502.pt
2023-08-10 05:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4502.pt (epoch 12 @ 17679 updates, score 19.45) (writing took 14.304661536589265 seconds)
2023-08-10 05:29:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-10 05:29:15 | INFO | train | epoch 012 | loss 2.11 | trans_loss 5.161 | nll_loss 2.399 | w2v_ctc_loss 0.743 | task_loss 2.079 | contrastive_loss 0.116 | total 4138.65 | n_correct 2547.73 | ppl 5.27 | accuracy 61.559 | wps 11511 | ups 1.39 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 1003 | gb_free 12.7 | wall 16098
2023-08-10 05:29:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 05:29:16 | INFO | fairseq.trainer | begin training epoch 13
2023-08-10 05:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 05:29:38 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.113, trans_loss=5.175, nll_loss=2.418, w2v_ctc_loss=0.757, task_loss=2.159, contrastive_loss=0.066, total=4096.49, n_correct=2513.66, ppl=5.34, accuracy=61.361, wps=7187.3, ups=0.88, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=14.4, wall=16120
2023-08-10 05:30:49 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.085, trans_loss=5.127, nll_loss=2.353, w2v_ctc_loss=0.727, task_loss=2.077, contrastive_loss=0.079, total=4160.97, n_correct=2591.33, ppl=5.11, accuracy=62.277, wps=12044.8, ups=1.45, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=16192
2023-08-10 05:31:58 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.114, trans_loss=5.135, nll_loss=2.366, w2v_ctc_loss=0.727, task_loss=1.915, contrastive_loss=0.293, total=4212.08, n_correct=2614.27, ppl=5.15, accuracy=62.066, wps=12149.4, ups=1.44, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=16261
2023-08-10 05:33:07 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.084, trans_loss=5.127, nll_loss=2.354, w2v_ctc_loss=0.726, task_loss=2.158, contrastive_loss=0.063, total=4102.3, n_correct=2554.47, ppl=5.11, accuracy=62.269, wps=11978.7, ups=1.46, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=16330
2023-08-10 05:33:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 05:33:30 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.249 | trans_loss 5.599 | nll_loss 2.881 | w2v_ctc_loss 1.331 | task_loss 6.916 | contrastive_loss 0.245 | total 4003.4 | n_correct 2455.3 | ppl 7.37 | accuracy 61.33 | uer 18.093 | wer 19.988 | raw_wer 19.988 | bleu 19.52 | wps 2304.8 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.52
2023-08-10 05:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-10 05:33:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_13_18000.pt
2023-08-10 05:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_13_18000.pt
2023-08-10 05:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.52) (writing took 48.24535701982677 seconds)
2023-08-10 05:35:27 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.088, trans_loss=5.131, nll_loss=2.361, w2v_ctc_loss=0.726, task_loss=1.95, contrastive_loss=0.11, total=4177.29, n_correct=2602.44, ppl=5.14, accuracy=62.3, wps=5965.9, ups=0.71, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=16470
2023-08-10 05:36:36 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.099, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.734, task_loss=2.019, contrastive_loss=0.147, total=4201.22, n_correct=2604.16, ppl=5.18, accuracy=61.986, wps=12223.1, ups=1.45, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=12.8, wall=16538
2023-08-10 05:37:44 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.082, trans_loss=5.136, nll_loss=2.367, w2v_ctc_loss=0.726, task_loss=2.016, contrastive_loss=0.061, total=4161.98, n_correct=2589.26, ppl=5.16, accuracy=62.212, wps=12121.6, ups=1.46, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=16607
2023-08-10 05:38:54 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.1, trans_loss=5.148, nll_loss=2.381, w2v_ctc_loss=0.749, task_loss=2.308, contrastive_loss=0.06, total=4096.76, n_correct=2529.96, ppl=5.21, accuracy=61.755, wps=11861.4, ups=1.45, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=16676
2023-08-10 05:40:03 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.099, trans_loss=5.148, nll_loss=2.383, w2v_ctc_loss=0.732, task_loss=2.097, contrastive_loss=0.105, total=4121.73, n_correct=2552.39, ppl=5.22, accuracy=61.925, wps=11911.8, ups=1.44, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=16745
2023-08-10 05:41:12 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.089, trans_loss=5.145, nll_loss=2.378, w2v_ctc_loss=0.731, task_loss=2.124, contrastive_loss=0.068, total=4107.01, n_correct=2551.41, ppl=5.2, accuracy=62.123, wps=11900.1, ups=1.45, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=16814
2023-08-10 05:42:20 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.107, trans_loss=5.153, nll_loss=2.389, w2v_ctc_loss=0.744, task_loss=2.193, contrastive_loss=0.117, total=4081.02, n_correct=2519.1, ppl=5.24, accuracy=61.727, wps=11966.8, ups=1.47, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=16883
2023-08-10 05:43:28 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.09, trans_loss=5.14, nll_loss=2.373, w2v_ctc_loss=0.725, task_loss=2.048, contrastive_loss=0.102, total=4105.62, n_correct=2550.98, ppl=5.18, accuracy=62.134, wps=12050.3, ups=1.47, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.529, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=16951
2023-08-10 05:44:37 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.097, trans_loss=5.155, nll_loss=2.393, w2v_ctc_loss=0.741, task_loss=2.215, contrastive_loss=0.062, total=4110.35, n_correct=2542.64, ppl=5.25, accuracy=61.859, wps=11871.4, ups=1.44, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=14.8, wall=17020
2023-08-10 05:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 05:45:47 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.091, trans_loss=5.144, nll_loss=2.378, w2v_ctc_loss=0.739, task_loss=2.118, contrastive_loss=0.065, total=4094.47, n_correct=2546.12, ppl=5.2, accuracy=62.184, wps=11787, ups=1.44, wpb=8188.9, bsz=300.2, num_updates=19000, lr=0.000102598, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=17.9, wall=17090
2023-08-10 05:46:55 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.108, trans_loss=5.155, nll_loss=2.394, w2v_ctc_loss=0.73, task_loss=2.04, contrastive_loss=0.17, total=4179.06, n_correct=2581.07, ppl=5.26, accuracy=61.762, wps=12215.5, ups=1.46, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=17158
2023-08-10 05:47:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 05:47:54 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.247 | trans_loss 5.594 | nll_loss 2.878 | w2v_ctc_loss 1.341 | task_loss 6.892 | contrastive_loss 0.242 | total 4003.4 | n_correct 2459.5 | ppl 7.35 | accuracy 61.435 | uer 18.17 | wer 20.025 | raw_wer 20.025 | bleu 19.51 | wps 2253.7 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.52
2023-08-10 05:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-10 05:47:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.5108.pt
2023-08-10 05:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.5108.pt
2023-08-10 05:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.5108.pt (epoch 13 @ 19152 updates, score 19.51) (writing took 18.87277887389064 seconds)
2023-08-10 05:48:13 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-10 05:48:13 | INFO | train | epoch 013 | loss 2.095 | trans_loss 5.141 | nll_loss 2.374 | w2v_ctc_loss 0.733 | task_loss 2.082 | contrastive_loss 0.108 | total 4137.55 | n_correct 2567.16 | ppl 5.18 | accuracy 62.046 | wps 10712.3 | ups 1.29 | wpb 8275.1 | bsz 305.2 | num_updates 19152 | lr 0.00010219 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 17.6 | wall 17236
2023-08-10 05:48:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 05:48:14 | INFO | fairseq.trainer | begin training epoch 14
2023-08-10 05:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 05:48:55 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.073, trans_loss=5.112, nll_loss=2.338, w2v_ctc_loss=0.725, task_loss=1.912, contrastive_loss=0.074, total=4179.66, n_correct=2618.5, ppl=5.05, accuracy=62.649, wps=6971.9, ups=0.83, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=10.2, wall=17278
2023-08-10 05:50:03 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.065, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.719, task_loss=2.079, contrastive_loss=0.057, total=4081.01, n_correct=2569.55, ppl=4.98, accuracy=62.964, wps=12075.1, ups=1.48, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=17345
2023-08-10 05:51:11 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.087, trans_loss=5.118, nll_loss=2.342, w2v_ctc_loss=0.723, task_loss=2.17, contrastive_loss=0.158, total=4109.83, n_correct=2574.05, ppl=5.07, accuracy=62.632, wps=12039.1, ups=1.46, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=17414
2023-08-10 05:52:20 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.071, trans_loss=5.11, nll_loss=2.335, w2v_ctc_loss=0.714, task_loss=1.941, contrastive_loss=0.091, total=4171.83, n_correct=2617.4, ppl=5.04, accuracy=62.74, wps=12096.8, ups=1.45, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=17483
2023-08-10 05:53:28 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.072, trans_loss=5.119, nll_loss=2.345, w2v_ctc_loss=0.716, task_loss=2.078, contrastive_loss=0.067, total=4142.75, n_correct=2593.11, ppl=5.08, accuracy=62.594, wps=12121.5, ups=1.46, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=17551
2023-08-10 05:54:38 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.09, trans_loss=5.128, nll_loss=2.355, w2v_ctc_loss=0.742, task_loss=2.235, contrastive_loss=0.075, total=4073.76, n_correct=2535.28, ppl=5.12, accuracy=62.234, wps=11780.2, ups=1.45, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=17620
2023-08-10 05:55:47 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.087, trans_loss=5.126, nll_loss=2.355, w2v_ctc_loss=0.724, task_loss=2.079, contrastive_loss=0.13, total=4158.79, n_correct=2593.02, ppl=5.12, accuracy=62.35, wps=12008, ups=1.44, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=17690
2023-08-10 05:56:55 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.074, trans_loss=5.117, nll_loss=2.342, w2v_ctc_loss=0.725, task_loss=2.025, contrastive_loss=0.065, total=4145.47, n_correct=2599.31, ppl=5.07, accuracy=62.702, wps=12158.9, ups=1.47, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=17758
2023-08-10 05:58:04 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.089, trans_loss=5.117, nll_loss=2.345, w2v_ctc_loss=0.719, task_loss=1.977, contrastive_loss=0.175, total=4171.1, n_correct=2610.42, ppl=5.08, accuracy=62.583, wps=12137.5, ups=1.45, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=17826
2023-08-10 05:58:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 05:58:26 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.253 | trans_loss 5.586 | nll_loss 2.869 | w2v_ctc_loss 1.378 | task_loss 6.919 | contrastive_loss 0.243 | total 4003.4 | n_correct 2461.1 | ppl 7.31 | accuracy 61.475 | uer 18.063 | wer 19.906 | raw_wer 19.906 | bleu 19.71 | wps 2318.9 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.71
2023-08-10 05:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-10 05:58:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_14_20000.pt
2023-08-10 05:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_14_20000.pt
2023-08-10 05:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.71) (writing took 25.648162668570876 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 06:00:02 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.082, trans_loss=5.125, nll_loss=2.353, w2v_ctc_loss=0.72, task_loss=2.081, contrastive_loss=0.112, total=4167.75, n_correct=2603.63, ppl=5.11, accuracy=62.471, wps=7029.2, ups=0.84, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=17945
2023-08-10 06:01:11 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.086, trans_loss=5.134, nll_loss=2.367, w2v_ctc_loss=0.725, task_loss=2.118, contrastive_loss=0.088, total=4143.92, n_correct=2580.42, ppl=5.16, accuracy=62.27, wps=12022.8, ups=1.45, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=18014
2023-08-10 06:02:20 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.12, trans_loss=5.131, nll_loss=2.363, w2v_ctc_loss=0.731, task_loss=1.944, contrastive_loss=0.357, total=4228.69, n_correct=2631.42, ppl=5.15, accuracy=62.228, wps=12234.8, ups=1.45, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=18083
2023-08-10 06:03:30 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.094, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.741, task_loss=2.443, contrastive_loss=0.05, total=4021.19, n_correct=2493.47, ppl=5.22, accuracy=62.008, wps=11632.7, ups=1.45, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=18152
2023-08-10 06:04:38 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.077, trans_loss=5.134, nll_loss=2.367, w2v_ctc_loss=0.718, task_loss=1.956, contrastive_loss=0.065, total=4213.9, n_correct=2625.7, ppl=5.16, accuracy=62.31, wps=12343.9, ups=1.46, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=18221
2023-08-10 06:05:47 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.089, trans_loss=5.142, nll_loss=2.377, w2v_ctc_loss=0.724, task_loss=2.071, contrastive_loss=0.103, total=4130.28, n_correct=2569.06, ppl=5.2, accuracy=62.201, wps=11984, ups=1.45, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=18289
2023-08-10 06:06:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
2023-08-10 06:06:27 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.223 | trans_loss 5.576 | nll_loss 2.857 | w2v_ctc_loss 1.298 | task_loss 6.903 | contrastive_loss 0.248 | total 4003.4 | n_correct 2463.3 | ppl 7.25 | accuracy 61.53 | uer 17.739 | wer 19.574 | raw_wer 19.574 | bleu 19.48 | wps 2322.7 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.71
2023-08-10 06:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-10 06:06:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4804.pt
2023-08-10 06:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4804.pt
2023-08-10 06:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.4804.pt (epoch 14 @ 20626 updates, score 19.48) (writing took 21.381863610818982 seconds)
2023-08-10 06:06:49 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-10 06:06:49 | INFO | train | epoch 014 | loss 2.084 | trans_loss 5.124 | nll_loss 2.353 | w2v_ctc_loss 0.724 | task_loss 2.078 | contrastive_loss 0.113 | total 4138.65 | n_correct 2584.98 | ppl 5.11 | accuracy 62.46 | wps 10935.9 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 16.3 | wall 18352
2023-08-10 06:06:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 06:06:49 | INFO | fairseq.trainer | begin training epoch 15
2023-08-10 06:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 06:07:48 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.078, trans_loss=5.11, nll_loss=2.334, w2v_ctc_loss=0.713, task_loss=2.085, contrastive_loss=0.153, total=4083.88, n_correct=2563.06, ppl=5.04, accuracy=62.76, wps=6755.5, ups=0.83, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=18410
2023-08-10 06:08:56 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.065, trans_loss=5.099, nll_loss=2.319, w2v_ctc_loss=0.718, task_loss=2.163, contrastive_loss=0.061, total=4115.73, n_correct=2592.27, ppl=4.99, accuracy=62.984, wps=12063.4, ups=1.47, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=18479
2023-08-10 06:10:04 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.056, trans_loss=5.099, nll_loss=2.32, w2v_ctc_loss=0.706, task_loss=1.999, contrastive_loss=0.054, total=4193.15, n_correct=2649.07, ppl=4.99, accuracy=63.176, wps=12237.4, ups=1.46, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=18547
2023-08-10 06:11:13 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.061, trans_loss=5.093, nll_loss=2.312, w2v_ctc_loss=0.709, task_loss=2.094, contrastive_loss=0.076, total=4167.66, n_correct=2625.87, ppl=4.97, accuracy=63.006, wps=12115.3, ups=1.45, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=18616
2023-08-10 06:12:22 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.076, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.701, task_loss=2.175, contrastive_loss=0.168, total=4074.53, n_correct=2558.64, ppl=5.01, accuracy=62.796, wps=11901.2, ups=1.46, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=15.7, wall=18684
2023-08-10 06:13:30 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.064, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.717, task_loss=2.156, contrastive_loss=0.061, total=4140.59, n_correct=2603.27, ppl=5.01, accuracy=62.872, wps=12091.6, ups=1.46, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=68, gb_free=12, wall=18753
2023-08-10 06:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 06:14:40 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.069, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.713, task_loss=2.141, contrastive_loss=0.101, total=4122.71, n_correct=2598.16, ppl=5, accuracy=63.021, wps=11837.5, ups=1.44, wpb=8245.4, bsz=302, num_updates=21300, lr=9.69003e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=18823
2023-08-10 06:15:49 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.067, trans_loss=5.112, nll_loss=2.337, w2v_ctc_loss=0.717, task_loss=2.097, contrastive_loss=0.063, total=4176.64, n_correct=2621.5, ppl=5.05, accuracy=62.766, wps=12141.6, ups=1.45, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=18891
2023-08-10 06:16:57 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.07, trans_loss=5.115, nll_loss=2.341, w2v_ctc_loss=0.717, task_loss=2.246, contrastive_loss=0.058, total=4056.99, n_correct=2543.47, ppl=5.07, accuracy=62.694, wps=11882.3, ups=1.46, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=18960
2023-08-10 06:18:06 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.073, trans_loss=5.111, nll_loss=2.336, w2v_ctc_loss=0.708, task_loss=2.063, contrastive_loss=0.142, total=4134.44, n_correct=2595.37, ppl=5.05, accuracy=62.774, wps=12030.3, ups=1.45, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=19028
2023-08-10 06:19:16 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.098, trans_loss=5.116, nll_loss=2.345, w2v_ctc_loss=0.716, task_loss=1.955, contrastive_loss=0.299, total=4185.02, n_correct=2622.8, ppl=5.08, accuracy=62.671, wps=11998.5, ups=1.43, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=19098
2023-08-10 06:20:24 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.06, trans_loss=5.106, nll_loss=2.333, w2v_ctc_loss=0.699, task_loss=1.859, contrastive_loss=0.105, total=4187.68, n_correct=2639.06, ppl=5.04, accuracy=63.02, wps=12258.7, ups=1.46, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=19166
2023-08-10 06:21:33 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.075, trans_loss=5.118, nll_loss=2.347, w2v_ctc_loss=0.729, task_loss=2.148, contrastive_loss=0.061, total=4141.6, n_correct=2592.22, ppl=5.09, accuracy=62.59, wps=12036.4, ups=1.45, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=13.2, wall=19235
2023-08-10 06:22:41 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.067, trans_loss=5.116, nll_loss=2.343, w2v_ctc_loss=0.714, task_loss=2.156, contrastive_loss=0.05, total=4099.6, n_correct=2571.56, ppl=5.07, accuracy=62.727, wps=12000.8, ups=1.46, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=14.2, wall=19304
2023-08-10 06:22:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 06:23:05 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.573 | nll_loss 2.848 | w2v_ctc_loss 1.281 | task_loss 6.909 | contrastive_loss 0.238 | total 4003.4 | n_correct 2475.3 | ppl 7.2 | accuracy 61.83 | uer 17.692 | wer 19.585 | raw_wer 19.585 | bleu 19.91 | wps 2061.4 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.91
2023-08-10 06:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-10 06:23:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_15_22000.pt
2023-08-10 06:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_15_22000.pt
2023-08-10 06:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.91) (writing took 47.54799850843847 seconds)
2023-08-10 06:25:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 06:25:26 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.572 | nll_loss 2.85 | w2v_ctc_loss 1.324 | task_loss 6.899 | contrastive_loss 0.245 | total 4003.4 | n_correct 2469.9 | ppl 7.21 | accuracy 61.695 | uer 17.631 | wer 19.38 | raw_wer 19.38 | bleu 19.64 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.91
2023-08-10 06:25:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-10 06:25:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6405.pt
2023-08-10 06:25:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6405.pt
2023-08-10 06:25:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6405.pt (epoch 15 @ 22099 updates, score 19.64) (writing took 18.9683010391891 seconds)
2023-08-10 06:25:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-10 06:25:45 | INFO | train | epoch 015 | loss 2.07 | trans_loss 5.107 | nll_loss 2.331 | w2v_ctc_loss 0.712 | task_loss 2.082 | contrastive_loss 0.108 | total 4138.01 | n_correct 2600.96 | ppl 5.03 | accuracy 62.855 | wps 10731.4 | ups 1.3 | wpb 8276 | bsz 305.4 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 16.9 | wall 19488
2023-08-10 06:25:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 06:25:45 | INFO | fairseq.trainer | begin training epoch 16
2023-08-10 06:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 06:25:54 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.077, trans_loss=5.118, nll_loss=2.348, w2v_ctc_loss=0.712, task_loss=1.994, contrastive_loss=0.134, total=4149.9, n_correct=2603.76, ppl=5.09, accuracy=62.743, wps=4306.4, ups=0.52, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=19496
2023-08-10 06:27:02 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.048, trans_loss=5.076, nll_loss=2.291, w2v_ctc_loss=0.701, task_loss=1.996, contrastive_loss=0.077, total=4118.73, n_correct=2614.58, ppl=4.89, accuracy=63.48, wps=12131.9, ups=1.47, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=19564
2023-08-10 06:28:10 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.045, trans_loss=5.076, nll_loss=2.29, w2v_ctc_loss=0.694, task_loss=2.136, contrastive_loss=0.056, total=4106.45, n_correct=2608.65, ppl=4.89, accuracy=63.526, wps=11936.8, ups=1.45, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=19633
2023-08-10 06:29:20 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.062, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.707, task_loss=2.051, contrastive_loss=0.127, total=4169.65, n_correct=2642.07, ppl=4.93, accuracy=63.364, wps=12054.3, ups=1.45, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=10.6, wall=19702
2023-08-10 06:30:28 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.066, trans_loss=5.087, nll_loss=2.305, w2v_ctc_loss=0.708, task_loss=2.238, contrastive_loss=0.141, total=4063.79, n_correct=2569.36, ppl=4.94, accuracy=63.226, wps=11969.3, ups=1.47, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=19770
2023-08-10 06:31:37 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.051, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.701, task_loss=1.989, contrastive_loss=0.084, total=4179.53, n_correct=2653.35, ppl=4.93, accuracy=63.484, wps=12051.9, ups=1.44, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.8, wall=19840
2023-08-10 06:32:45 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.059, trans_loss=5.095, nll_loss=2.316, w2v_ctc_loss=0.711, task_loss=2.094, contrastive_loss=0.051, total=4121.37, n_correct=2597.88, ppl=4.98, accuracy=63.034, wps=12081.5, ups=1.47, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=19908
2023-08-10 06:33:53 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.057, trans_loss=5.096, nll_loss=2.317, w2v_ctc_loss=0.71, task_loss=2.127, contrastive_loss=0.053, total=4099.17, n_correct=2589.71, ppl=4.98, accuracy=63.176, wps=12101.6, ups=1.48, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=19976
2023-08-10 06:35:01 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.058, trans_loss=5.093, nll_loss=2.314, w2v_ctc_loss=0.695, task_loss=1.988, contrastive_loss=0.112, total=4184.53, n_correct=2643.59, ppl=4.97, accuracy=63.175, wps=12213.7, ups=1.46, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=20044
2023-08-10 06:36:10 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.06, trans_loss=5.094, nll_loss=2.316, w2v_ctc_loss=0.702, task_loss=2.039, contrastive_loss=0.104, total=4151.84, n_correct=2625.4, ppl=4.98, accuracy=63.235, wps=12038.1, ups=1.45, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=20113
2023-08-10 06:37:20 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.072, trans_loss=5.107, nll_loss=2.331, w2v_ctc_loss=0.719, task_loss=2.154, contrastive_loss=0.104, total=4112.79, n_correct=2587.36, ppl=5.03, accuracy=62.91, wps=11884.8, ups=1.44, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=20182
2023-08-10 06:38:29 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.068, trans_loss=5.109, nll_loss=2.335, w2v_ctc_loss=0.715, task_loss=2.212, contrastive_loss=0.078, total=4111.6, n_correct=2584.71, ppl=5.05, accuracy=62.864, wps=11926, ups=1.45, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=20251
2023-08-10 06:39:38 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.07, trans_loss=5.103, nll_loss=2.328, w2v_ctc_loss=0.694, task_loss=2.118, contrastive_loss=0.172, total=4157.51, n_correct=2618.55, ppl=5.02, accuracy=62.984, wps=12012.1, ups=1.44, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=14.8, wall=20320
2023-08-10 06:40:47 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.071, trans_loss=5.103, nll_loss=2.328, w2v_ctc_loss=0.71, task_loss=2.019, contrastive_loss=0.153, total=4151.03, n_correct=2617.22, ppl=5.02, accuracy=63.05, wps=11937.6, ups=1.44, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=20390
2023-08-10 06:41:57 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.06, trans_loss=5.104, nll_loss=2.329, w2v_ctc_loss=0.707, task_loss=1.985, contrastive_loss=0.081, total=4201.47, n_correct=2649.42, ppl=5.03, accuracy=63.059, wps=12141, ups=1.44, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=20459
2023-08-10 06:42:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 06:42:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 06:43:09 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.566 | nll_loss 2.842 | w2v_ctc_loss 1.298 | task_loss 6.907 | contrastive_loss 0.242 | total 4003.4 | n_correct 2475.6 | ppl 7.17 | accuracy 61.837 | uer 17.519 | wer 19.433 | raw_wer 19.433 | bleu 20.32 | wps 2288.9 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 20.32
2023-08-10 06:43:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-08-10 06:43:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 06:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 06:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 16 @ 23572 updates, score 20.32) (writing took 26.072361953556538 seconds)
2023-08-10 06:43:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-10 06:43:36 | INFO | train | epoch 016 | loss 2.06 | trans_loss 5.094 | nll_loss 2.315 | w2v_ctc_loss 0.705 | task_loss 2.085 | contrastive_loss 0.097 | total 4136.64 | n_correct 2613.49 | ppl 4.98 | accuracy 63.179 | wps 11381.5 | ups 1.38 | wpb 8273.3 | bsz 304.9 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 15.4 | wall 20558
2023-08-10 06:43:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 06:43:36 | INFO | fairseq.trainer | begin training epoch 17
2023-08-10 06:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 06:44:04 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.048, trans_loss=5.086, nll_loss=2.304, w2v_ctc_loss=0.697, task_loss=2.216, contrastive_loss=0.049, total=4112.89, n_correct=2605.15, ppl=4.94, accuracy=63.341, wps=6469.9, ups=0.79, wpb=8225.8, bsz=290.5, num_updates=23600, lr=9.20575e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=20586
2023-08-10 06:45:12 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.039, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.696, task_loss=2.155, contrastive_loss=0.055, total=4110.88, n_correct=2624.78, ppl=4.83, accuracy=63.85, wps=11986.2, ups=1.46, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=20655
2023-08-10 06:46:21 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.059, trans_loss=5.065, nll_loss=2.278, w2v_ctc_loss=0.687, task_loss=1.953, contrastive_loss=0.216, total=4171.95, n_correct=2657.82, ppl=4.85, accuracy=63.707, wps=12194, ups=1.46, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=20723
2023-08-10 06:47:30 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.059, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.689, task_loss=2.073, contrastive_loss=0.226, total=4157.94, n_correct=2641.42, ppl=4.87, accuracy=63.527, wps=12045.8, ups=1.45, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=14.3, wall=20792
2023-08-10 06:48:39 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.038, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.694, task_loss=2.075, contrastive_loss=0.054, total=4141.8, n_correct=2640.21, ppl=4.87, accuracy=63.745, wps=11977.3, ups=1.45, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=20862
2023-08-10 06:48:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 06:49:05 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.222 | trans_loss 5.57 | nll_loss 2.846 | w2v_ctc_loss 1.315 | task_loss 6.906 | contrastive_loss 0.24 | total 4003.4 | n_correct 2470.8 | ppl 7.19 | accuracy 61.718 | uer 17.623 | wer 19.462 | raw_wer 19.462 | bleu 19.78 | wps 1924.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.32
2023-08-10 06:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-10 06:49:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_17_24000.pt
2023-08-10 06:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_17_24000.pt
2023-08-10 06:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.78) (writing took 23.470795430243015 seconds)
2023-08-10 06:50:38 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.049, trans_loss=5.076, nll_loss=2.293, w2v_ctc_loss=0.695, task_loss=2.167, contrastive_loss=0.099, total=4180.09, n_correct=2653.39, ppl=4.9, accuracy=63.477, wps=7016.4, ups=0.84, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=20981
2023-08-10 06:51:47 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.041, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.693, task_loss=2.091, contrastive_loss=0.05, total=4166.6, n_correct=2651.67, ppl=4.92, accuracy=63.641, wps=12073.2, ups=1.45, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=21050
2023-08-10 06:52:56 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.061, trans_loss=5.087, nll_loss=2.306, w2v_ctc_loss=0.714, task_loss=2.058, contrastive_loss=0.096, total=4168.97, n_correct=2638.27, ppl=4.95, accuracy=63.283, wps=12190.5, ups=1.46, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=21118
2023-08-10 06:54:04 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.048, trans_loss=5.085, nll_loss=2.302, w2v_ctc_loss=0.699, task_loss=2.101, contrastive_loss=0.062, total=4097.38, n_correct=2602.3, ppl=4.93, accuracy=63.511, wps=12045.5, ups=1.47, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=10.3, wall=21186
2023-08-10 06:55:12 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.045, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.695, task_loss=2.063, contrastive_loss=0.061, total=4105.01, n_correct=2606.28, ppl=4.93, accuracy=63.49, wps=12045.3, ups=1.47, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=21254
2023-08-10 06:56:20 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.046, trans_loss=5.083, nll_loss=2.301, w2v_ctc_loss=0.699, task_loss=2.085, contrastive_loss=0.063, total=4105.88, n_correct=2608.33, ppl=4.93, accuracy=63.527, wps=12053.7, ups=1.47, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=21323
2023-08-10 06:57:28 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.043, trans_loss=5.083, nll_loss=2.302, w2v_ctc_loss=0.691, task_loss=2.12, contrastive_loss=0.056, total=4095.58, n_correct=2604.3, ppl=4.93, accuracy=63.588, wps=12022.9, ups=1.47, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=21391
2023-08-10 06:58:37 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.081, trans_loss=5.096, nll_loss=2.32, w2v_ctc_loss=0.693, task_loss=2.04, contrastive_loss=0.291, total=4162.14, n_correct=2625.8, ppl=4.99, accuracy=63.088, wps=12007.3, ups=1.44, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=21460
2023-08-10 06:59:46 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.057, trans_loss=5.094, nll_loss=2.317, w2v_ctc_loss=0.688, task_loss=2.075, contrastive_loss=0.133, total=4149.03, n_correct=2623.49, ppl=4.98, accuracy=63.231, wps=12091.4, ups=1.46, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=21529
2023-08-10 07:00:54 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.045, trans_loss=5.09, nll_loss=2.311, w2v_ctc_loss=0.693, task_loss=2.095, contrastive_loss=0.055, total=4117.13, n_correct=2609.45, ppl=4.96, accuracy=63.38, wps=12014.9, ups=1.46, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=21597
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 07:01:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
2023-08-10 07:01:53 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.567 | nll_loss 2.845 | w2v_ctc_loss 1.293 | task_loss 6.959 | contrastive_loss 0.24 | total 4003.4 | n_correct 2471.6 | ppl 7.18 | accuracy 61.738 | uer 17.363 | wer 19.049 | raw_wer 19.049 | bleu 19.85 | wps 1772.5 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.32
2023-08-10 07:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-10 07:01:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.8503.pt
2023-08-10 07:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.8503.pt
2023-08-10 07:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.8503.pt (epoch 17 @ 25046 updates, score 19.85) (writing took 19.04331941716373 seconds)
2023-08-10 07:02:13 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-10 07:02:13 | INFO | train | epoch 017 | loss 2.05 | trans_loss 5.08 | nll_loss 2.298 | w2v_ctc_loss 0.695 | task_loss 2.083 | contrastive_loss 0.107 | total 4138.65 | n_correct 2628.29 | ppl 4.92 | accuracy 63.506 | wps 10925.5 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 16.3 | wall 21675
2023-08-10 07:02:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 07:02:13 | INFO | fairseq.trainer | begin training epoch 18
2023-08-10 07:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 07:02:58 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.04, trans_loss=5.072, nll_loss=2.287, w2v_ctc_loss=0.695, task_loss=2.114, contrastive_loss=0.063, total=4138.21, n_correct=2635.46, ppl=4.88, accuracy=63.686, wps=6721.6, ups=0.81, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=21720
2023-08-10 07:04:06 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.04, trans_loss=5.048, nll_loss=2.256, w2v_ctc_loss=0.67, task_loss=1.982, contrastive_loss=0.183, total=4158.88, n_correct=2666.97, ppl=4.78, accuracy=64.127, wps=12187.9, ups=1.47, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=21789
2023-08-10 07:05:14 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.026, trans_loss=5.05, nll_loss=2.259, w2v_ctc_loss=0.683, task_loss=2.025, contrastive_loss=0.056, total=4164.11, n_correct=2674.58, ppl=4.79, accuracy=64.229, wps=12135.8, ups=1.46, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=21857
2023-08-10 07:06:23 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.029, trans_loss=5.055, nll_loss=2.264, w2v_ctc_loss=0.679, task_loss=2.119, contrastive_loss=0.068, total=4163.13, n_correct=2665.99, ppl=4.8, accuracy=64.038, wps=12069.8, ups=1.45, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21926
2023-08-10 07:07:32 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.05, trans_loss=5.067, nll_loss=2.28, w2v_ctc_loss=0.686, task_loss=2.225, contrastive_loss=0.159, total=4087.83, n_correct=2606.55, ppl=4.86, accuracy=63.764, wps=11851.4, ups=1.45, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21995
2023-08-10 07:08:41 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.02, trans_loss=5.049, nll_loss=2.258, w2v_ctc_loss=0.671, task_loss=1.876, contrastive_loss=0.068, total=4204.41, n_correct=2696.96, ppl=4.78, accuracy=64.146, wps=12268.5, ups=1.46, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=22064
2023-08-10 07:09:50 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.054, trans_loss=5.078, nll_loss=2.295, w2v_ctc_loss=0.697, task_loss=2.144, contrastive_loss=0.138, total=4096.81, n_correct=2602.39, ppl=4.91, accuracy=63.522, wps=11908.7, ups=1.45, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=22132
2023-08-10 07:10:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 07:10:59 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.057, trans_loss=5.071, nll_loss=2.287, w2v_ctc_loss=0.693, task_loss=2.003, contrastive_loss=0.221, total=4196.88, n_correct=2671.35, ppl=4.88, accuracy=63.651, wps=12057.3, ups=1.44, wpb=8393.8, bsz=319.3, num_updates=25800, lr=8.80451e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=22202
2023-08-10 07:12:08 | INFO | train_inner | epoch 018:    855 / 1474 loss=2.037, trans_loss=5.072, nll_loss=2.287, w2v_ctc_loss=0.687, task_loss=2.088, contrastive_loss=0.054, total=4177.43, n_correct=2659.75, ppl=4.88, accuracy=63.67, wps=12151.6, ups=1.45, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=22271
2023-08-10 07:13:17 | INFO | train_inner | epoch 018:    955 / 1474 loss=2.025, trans_loss=5.059, nll_loss=2.272, w2v_ctc_loss=0.672, task_loss=1.937, contrastive_loss=0.062, total=4138.23, n_correct=2648.46, ppl=4.83, accuracy=64, wps=12097.2, ups=1.46, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=22339
2023-08-10 07:13:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 07:13:40 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.562 | nll_loss 2.839 | w2v_ctc_loss 1.343 | task_loss 6.932 | contrastive_loss 0.24 | total 4003.4 | n_correct 2475.9 | ppl 7.15 | accuracy 61.845 | uer 17.524 | wer 19.44 | raw_wer 19.44 | bleu 19.89 | wps 2224.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.32
2023-08-10 07:13:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-10 07:13:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_18_26000.pt
2023-08-10 07:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_18_26000.pt
2023-08-10 07:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.89) (writing took 21.75785251893103 seconds)
2023-08-10 07:15:12 | INFO | train_inner | epoch 018:   1055 / 1474 loss=2.037, trans_loss=5.074, nll_loss=2.291, w2v_ctc_loss=0.683, task_loss=2.19, contrastive_loss=0.057, total=4133.59, n_correct=2632.65, ppl=4.89, accuracy=63.689, wps=7196.5, ups=0.87, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=22454
2023-08-10 07:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 07:16:20 | INFO | train_inner | epoch 018:   1156 / 1474 loss=2.046, trans_loss=5.062, nll_loss=2.276, w2v_ctc_loss=0.685, task_loss=1.955, contrastive_loss=0.162, total=4159.12, n_correct=2658.95, ppl=4.84, accuracy=63.931, wps=12058.4, ups=1.45, wpb=8318.2, bsz=316.6, num_updates=26200, lr=8.73704e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=13.6, wall=22523
2023-08-10 07:17:29 | INFO | train_inner | epoch 018:   1256 / 1474 loss=2.039, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.684, task_loss=2.231, contrastive_loss=0.052, total=4093.35, n_correct=2601.71, ppl=4.92, accuracy=63.559, wps=11931.6, ups=1.46, wpb=8186.7, bsz=288, num_updates=26300, lr=8.72041e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=22592
2023-08-10 07:18:38 | INFO | train_inner | epoch 018:   1356 / 1474 loss=2.056, trans_loss=5.091, nll_loss=2.312, w2v_ctc_loss=0.707, task_loss=2.251, contrastive_loss=0.074, total=4056.71, n_correct=2570.23, ppl=4.97, accuracy=63.357, wps=11850.6, ups=1.46, wpb=8113.4, bsz=289.2, num_updates=26400, lr=8.70388e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=22660
2023-08-10 07:19:46 | INFO | train_inner | epoch 018:   1456 / 1474 loss=2.045, trans_loss=5.083, nll_loss=2.302, w2v_ctc_loss=0.697, task_loss=2.179, contrastive_loss=0.061, total=4125.39, n_correct=2618.99, ppl=4.93, accuracy=63.485, wps=12099.8, ups=1.47, wpb=8250.8, bsz=299, num_updates=26500, lr=8.68744e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=22728
2023-08-10 07:19:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 07:20:23 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.247 | trans_loss 5.567 | nll_loss 2.844 | w2v_ctc_loss 1.394 | task_loss 6.944 | contrastive_loss 0.253 | total 4003.4 | n_correct 2480.6 | ppl 7.18 | accuracy 61.962 | uer 17.801 | wer 19.764 | raw_wer 19.764 | bleu 19.66 | wps 1942.5 | wpb 4003.4 | bsz 141.8 | num_updates 26518 | best_bleu 20.32
2023-08-10 07:20:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26518 updates
2023-08-10 07:20:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6601.pt
2023-08-10 07:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6601.pt
2023-08-10 07:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.6601.pt (epoch 18 @ 26518 updates, score 19.66) (writing took 19.700364783406258 seconds)
2023-08-10 07:20:43 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-10 07:20:43 | INFO | train | epoch 018 | loss 2.04 | trans_loss 5.067 | nll_loss 2.281 | w2v_ctc_loss 0.685 | task_loss 2.082 | contrastive_loss 0.104 | total 4138.38 | n_correct 2640.44 | ppl 4.86 | accuracy 63.804 | wps 10971.6 | ups 1.33 | wpb 8276.8 | bsz 305.5 | num_updates 26518 | lr 8.6845e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 1003 | gb_free 15.9 | wall 22786
2023-08-10 07:20:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 07:20:43 | INFO | fairseq.trainer | begin training epoch 19
2023-08-10 07:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 07:21:47 | INFO | train_inner | epoch 019:     82 / 1474 loss=2.031, trans_loss=5.044, nll_loss=2.251, w2v_ctc_loss=0.677, task_loss=2.078, contrastive_loss=0.112, total=4098.8, n_correct=2632.01, ppl=4.76, accuracy=64.214, wps=6760.3, ups=0.82, wpb=8197.6, bsz=296.6, num_updates=26600, lr=8.6711e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=22850
2023-08-10 07:22:56 | INFO | train_inner | epoch 019:    182 / 1474 loss=2.028, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.686, task_loss=1.941, contrastive_loss=0.099, total=4227.47, n_correct=2724.89, ppl=4.73, accuracy=64.457, wps=12212.5, ups=1.44, wpb=8454.9, bsz=325, num_updates=26700, lr=8.65485e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=22919
2023-08-10 07:24:04 | INFO | train_inner | epoch 019:    282 / 1474 loss=2.016, trans_loss=5.036, nll_loss=2.241, w2v_ctc_loss=0.676, task_loss=2.038, contrastive_loss=0.048, total=4188.96, n_correct=2700.93, ppl=4.73, accuracy=64.477, wps=12292.3, ups=1.47, wpb=8377.9, bsz=308.1, num_updates=26800, lr=8.63868e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=22987
2023-08-10 07:25:13 | INFO | train_inner | epoch 019:    382 / 1474 loss=2.033, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.671, task_loss=2.061, contrastive_loss=0.152, total=4168.76, n_correct=2679.24, ppl=4.75, accuracy=64.269, wps=12151.5, ups=1.46, wpb=8337.5, bsz=310.6, num_updates=26900, lr=8.62261e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=23056
2023-08-10 07:26:21 | INFO | train_inner | epoch 019:    482 / 1474 loss=2.031, trans_loss=5.054, nll_loss=2.265, w2v_ctc_loss=0.69, task_loss=2.152, contrastive_loss=0.06, total=4107.91, n_correct=2631.17, ppl=4.81, accuracy=64.051, wps=12031.6, ups=1.46, wpb=8215.8, bsz=299.6, num_updates=27000, lr=8.60663e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=23124
2023-08-10 07:27:30 | INFO | train_inner | epoch 019:    582 / 1474 loss=2.029, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.671, task_loss=2.037, contrastive_loss=0.127, total=4133.95, n_correct=2656.66, ppl=4.78, accuracy=64.264, wps=12106.3, ups=1.46, wpb=8267.9, bsz=306.3, num_updates=27100, lr=8.59074e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=23192
2023-08-10 07:28:38 | INFO | train_inner | epoch 019:    682 / 1474 loss=2.015, trans_loss=5.052, nll_loss=2.262, w2v_ctc_loss=0.664, task_loss=1.889, contrastive_loss=0.054, total=4199.37, n_correct=2699.88, ppl=4.8, accuracy=64.293, wps=12215.5, ups=1.45, wpb=8398.7, bsz=321.7, num_updates=27200, lr=8.57493e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=23261
2023-08-10 07:29:47 | INFO | train_inner | epoch 019:    782 / 1474 loss=2.027, trans_loss=5.052, nll_loss=2.262, w2v_ctc_loss=0.682, task_loss=2.101, contrastive_loss=0.064, total=4142.94, n_correct=2658.11, ppl=4.8, accuracy=64.16, wps=12059.4, ups=1.46, wpb=8285.9, bsz=305.4, num_updates=27300, lr=8.55921e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=23330
2023-08-10 07:30:56 | INFO | train_inner | epoch 019:    882 / 1474 loss=2.03, trans_loss=5.063, nll_loss=2.276, w2v_ctc_loss=0.683, task_loss=2.123, contrastive_loss=0.05, total=4153.23, n_correct=2654.14, ppl=4.84, accuracy=63.905, wps=12137.2, ups=1.46, wpb=8306.5, bsz=303.4, num_updates=27400, lr=8.54358e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=23398
2023-08-10 07:32:06 | INFO | train_inner | epoch 019:    982 / 1474 loss=2.059, trans_loss=5.072, nll_loss=2.289, w2v_ctc_loss=0.676, task_loss=2.083, contrastive_loss=0.283, total=4102.27, n_correct=2617.95, ppl=4.89, accuracy=63.817, wps=11719.5, ups=1.43, wpb=8204.5, bsz=308.7, num_updates=27500, lr=8.52803e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=23468
2023-08-10 07:33:14 | INFO | train_inner | epoch 019:   1082 / 1474 loss=2.039, trans_loss=5.074, nll_loss=2.291, w2v_ctc_loss=0.68, task_loss=2.222, contrastive_loss=0.093, total=4036.79, n_correct=2572.99, ppl=4.89, accuracy=63.739, wps=11842.3, ups=1.47, wpb=8073.6, bsz=291.6, num_updates=27600, lr=8.51257e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=23536
2023-08-10 07:34:23 | INFO | train_inner | epoch 019:   1182 / 1474 loss=2.053, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.686, task_loss=2.139, contrastive_loss=0.176, total=4129.82, n_correct=2628.19, ppl=4.88, accuracy=63.639, wps=11979.9, ups=1.45, wpb=8259.6, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=23605
2023-08-10 07:35:31 | INFO | train_inner | epoch 019:   1282 / 1474 loss=2.033, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.676, task_loss=2.09, contrastive_loss=0.072, total=4147.96, n_correct=2645.73, ppl=4.88, accuracy=63.784, wps=12132.6, ups=1.46, wpb=8295.9, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=23674
2023-08-10 07:36:39 | INFO | train_inner | epoch 019:   1382 / 1474 loss=2.03, trans_loss=5.064, nll_loss=2.279, w2v_ctc_loss=0.679, task_loss=2.128, contrastive_loss=0.06, total=4125.32, n_correct=2639.28, ppl=4.85, accuracy=63.978, wps=12070.7, ups=1.46, wpb=8250.6, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=23742
2023-08-10 07:37:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 07:38:06 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.558 | nll_loss 2.832 | w2v_ctc_loss 1.352 | task_loss 6.984 | contrastive_loss 0.252 | total 4003.4 | n_correct 2479.2 | ppl 7.12 | accuracy 61.927 | uer 17.477 | wer 19.336 | raw_wer 19.336 | bleu 19.96 | wps 2255.7 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 20.32
2023-08-10 07:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-08-10 07:38:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.9604.pt
2023-08-10 07:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.9604.pt
2023-08-10 07:38:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.9604.pt (epoch 19 @ 27992 updates, score 19.96) (writing took 14.777519593015313 seconds)
2023-08-10 07:38:21 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-10 07:38:21 | INFO | train | epoch 019 | loss 2.032 | trans_loss 5.056 | nll_loss 2.267 | w2v_ctc_loss 0.678 | task_loss 2.08 | contrastive_loss 0.103 | total 4138.65 | n_correct 2652.28 | ppl 4.81 | accuracy 64.086 | wps 11533.3 | ups 1.39 | wpb 8277.3 | bsz 305.7 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.534 | clip 0 | loss_scale 16 | train_wall 1003 | gb_free 17.3 | wall 23844
2023-08-10 07:38:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 07:38:21 | INFO | fairseq.trainer | begin training epoch 20
2023-08-10 07:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 07:38:35 | INFO | train_inner | epoch 020:      8 / 1474 loss=2.035, trans_loss=5.057, nll_loss=2.269, w2v_ctc_loss=0.673, task_loss=2.086, contrastive_loss=0.144, total=4124.63, n_correct=2646.57, ppl=4.82, accuracy=64.165, wps=7164.3, ups=0.87, wpb=8249.3, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=23857
2023-08-10 07:38:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 07:38:59 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.562 | nll_loss 2.835 | w2v_ctc_loss 1.34 | task_loss 6.975 | contrastive_loss 0.249 | total 4003.4 | n_correct 2480.7 | ppl 7.13 | accuracy 61.965 | uer 17.469 | wer 19.421 | raw_wer 19.421 | bleu 20.25 | wps 2077.5 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.32
2023-08-10 07:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-10 07:38:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_20_28000.pt
2023-08-10 07:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_20_28000.pt
2023-08-10 07:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.25) (writing took 15.493899190798402 seconds)
2023-08-10 07:40:25 | INFO | train_inner | epoch 020:    108 / 1474 loss=2.005, trans_loss=5.021, nll_loss=2.222, w2v_ctc_loss=0.659, task_loss=2.006, contrastive_loss=0.064, total=4199.19, n_correct=2724.85, ppl=4.66, accuracy=64.89, wps=7640.9, ups=0.91, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=23967
2023-08-10 07:41:33 | INFO | train_inner | epoch 020:    208 / 1474 loss=2.021, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.67, task_loss=2.165, contrastive_loss=0.119, total=4148.29, n_correct=2679.15, ppl=4.71, accuracy=64.584, wps=12033.3, ups=1.45, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=24036
2023-08-10 07:42:42 | INFO | train_inner | epoch 020:    308 / 1474 loss=2.007, trans_loss=5.027, nll_loss=2.23, w2v_ctc_loss=0.666, task_loss=1.883, contrastive_loss=0.056, total=4191.34, n_correct=2710.95, ppl=4.69, accuracy=64.68, wps=12218.6, ups=1.46, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=24105
2023-08-10 07:43:51 | INFO | train_inner | epoch 020:    408 / 1474 loss=2.012, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.665, task_loss=2.111, contrastive_loss=0.055, total=4114.19, n_correct=2655.43, ppl=4.71, accuracy=64.543, wps=11976.8, ups=1.46, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=24173
2023-08-10 07:44:59 | INFO | train_inner | epoch 020:    508 / 1474 loss=2.024, trans_loss=5.044, nll_loss=2.251, w2v_ctc_loss=0.66, task_loss=2.133, contrastive_loss=0.143, total=4108.2, n_correct=2645.83, ppl=4.76, accuracy=64.404, wps=11977.7, ups=1.46, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=24242
2023-08-10 07:46:07 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.034, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.672, task_loss=2.19, contrastive_loss=0.145, total=4092.44, n_correct=2629.3, ppl=4.77, accuracy=64.248, wps=12038.3, ups=1.47, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=24310
2023-08-10 07:46:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 07:47:16 | INFO | train_inner | epoch 020:    709 / 1474 loss=2.022, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.681, task_loss=2.084, contrastive_loss=0.049, total=4137.46, n_correct=2658.14, ppl=4.78, accuracy=64.246, wps=11993.7, ups=1.45, wpb=8274.9, bsz=301.3, num_updates=28700, lr=8.34784e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=24379
2023-08-10 07:48:25 | INFO | train_inner | epoch 020:    809 / 1474 loss=2.018, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.674, task_loss=2.068, contrastive_loss=0.053, total=4145.82, n_correct=2669.49, ppl=4.77, accuracy=64.39, wps=12126.2, ups=1.46, wpb=8291.6, bsz=306.6, num_updates=28800, lr=8.33333e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=12.4, wall=24447
2023-08-10 07:49:34 | INFO | train_inner | epoch 020:    909 / 1474 loss=2.062, trans_loss=5.054, nll_loss=2.266, w2v_ctc_loss=0.673, task_loss=1.964, contrastive_loss=0.343, total=4161.77, n_correct=2666.57, ppl=4.81, accuracy=64.073, wps=12037.7, ups=1.45, wpb=8323.5, bsz=324.4, num_updates=28900, lr=8.3189e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=24517
2023-08-10 07:50:43 | INFO | train_inner | epoch 020:   1009 / 1474 loss=2.017, trans_loss=5.047, nll_loss=2.256, w2v_ctc_loss=0.666, task_loss=2.071, contrastive_loss=0.057, total=4167.85, n_correct=2680.99, ppl=4.78, accuracy=64.325, wps=12014.1, ups=1.44, wpb=8335.7, bsz=306.3, num_updates=29000, lr=8.30455e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=24586
2023-08-10 07:51:52 | INFO | train_inner | epoch 020:   1109 / 1474 loss=2.04, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.67, task_loss=2.003, contrastive_loss=0.19, total=4169.06, n_correct=2674.62, ppl=4.81, accuracy=64.154, wps=12134.3, ups=1.46, wpb=8338.1, bsz=315.8, num_updates=29100, lr=8.29027e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=24655
2023-08-10 07:53:01 | INFO | train_inner | epoch 020:   1209 / 1474 loss=2.026, trans_loss=5.053, nll_loss=2.263, w2v_ctc_loss=0.682, task_loss=2.315, contrastive_loss=0.047, total=4023.64, n_correct=2578.07, ppl=4.8, accuracy=64.073, wps=11709.5, ups=1.46, wpb=8047.3, bsz=282.8, num_updates=29200, lr=8.27606e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=24723
2023-08-10 07:54:10 | INFO | train_inner | epoch 020:   1309 / 1474 loss=2.023, trans_loss=5.057, nll_loss=2.27, w2v_ctc_loss=0.673, task_loss=2.168, contrastive_loss=0.052, total=4128.46, n_correct=2647.55, ppl=4.82, accuracy=64.129, wps=11924.9, ups=1.44, wpb=8256.9, bsz=299.2, num_updates=29300, lr=8.26192e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=24793
2023-08-10 07:55:19 | INFO | train_inner | epoch 020:   1409 / 1474 loss=2.027, trans_loss=5.058, nll_loss=2.271, w2v_ctc_loss=0.678, task_loss=2.183, contrastive_loss=0.05, total=4120.53, n_correct=2638.21, ppl=4.83, accuracy=64.026, wps=12026.9, ups=1.46, wpb=8241.1, bsz=294.2, num_updates=29400, lr=8.24786e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=24861
2023-08-10 07:56:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 07:56:26 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 1.323 | task_loss 6.929 | contrastive_loss 0.242 | total 4003.4 | n_correct 2479.2 | ppl 7.11 | accuracy 61.927 | uer 17.278 | wer 19.142 | raw_wer 19.142 | bleu 19.72 | wps 2197 | wpb 4003.4 | bsz 141.8 | num_updates 29465 | best_bleu 20.32
2023-08-10 07:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29465 updates
2023-08-10 07:56:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7207.pt
2023-08-10 07:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7207.pt
2023-08-10 07:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7207.pt (epoch 20 @ 29465 updates, score 19.72) (writing took 20.424846820533276 seconds)
2023-08-10 07:56:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-10 07:56:47 | INFO | train | epoch 020 | loss 2.024 | trans_loss 5.045 | nll_loss 2.253 | w2v_ctc_loss 0.67 | task_loss 2.08 | contrastive_loss 0.102 | total 4138.73 | n_correct 2662.67 | ppl 4.77 | accuracy 64.335 | wps 11025.5 | ups 1.33 | wpb 8277.5 | bsz 305.7 | num_updates 29465 | lr 8.23876e-05 | gnorm 0.538 | clip 0 | loss_scale 16 | train_wall 1004 | gb_free 16.1 | wall 24949
2023-08-10 07:56:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 07:56:47 | INFO | fairseq.trainer | begin training epoch 21
2023-08-10 07:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 07:57:19 | INFO | train_inner | epoch 021:     35 / 1474 loss=2.031, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.662, task_loss=1.989, contrastive_loss=0.169, total=4145.63, n_correct=2664.03, ppl=4.79, accuracy=64.261, wps=6887.8, ups=0.83, wpb=8291.3, bsz=315.4, num_updates=29500, lr=8.23387e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=24982
2023-08-10 07:58:28 | INFO | train_inner | epoch 021:    135 / 1474 loss=2.016, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.66, task_loss=1.948, contrastive_loss=0.16, total=4194.57, n_correct=2723.7, ppl=4.64, accuracy=64.934, wps=12190.5, ups=1.45, wpb=8389.1, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=25050
2023-08-10 07:59:36 | INFO | train_inner | epoch 021:    235 / 1474 loss=2.004, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.65, task_loss=1.995, contrastive_loss=0.116, total=4152.42, n_correct=2698.32, ppl=4.65, accuracy=64.982, wps=12218.4, ups=1.47, wpb=8304.8, bsz=312, num_updates=29700, lr=8.2061e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=67, gb_free=17.4, wall=25118
2023-08-10 08:00:45 | INFO | train_inner | epoch 021:    335 / 1474 loss=2.019, trans_loss=5.027, nll_loss=2.229, w2v_ctc_loss=0.669, task_loss=2.067, contrastive_loss=0.119, total=4157.2, n_correct=2684.61, ppl=4.69, accuracy=64.577, wps=12072.3, ups=1.45, wpb=8314.4, bsz=311.1, num_updates=29800, lr=8.19232e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=25187
2023-08-10 08:01:53 | INFO | train_inner | epoch 021:    435 / 1474 loss=1.998, trans_loss=5.022, nll_loss=2.222, w2v_ctc_loss=0.652, task_loss=1.999, contrastive_loss=0.044, total=4181.07, n_correct=2715.71, ppl=4.67, accuracy=64.953, wps=12276.5, ups=1.47, wpb=8362.1, bsz=308.2, num_updates=29900, lr=8.17861e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=25255
2023-08-10 08:03:01 | INFO | train_inner | epoch 021:    535 / 1474 loss=2.002, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.663, task_loss=2.158, contrastive_loss=0.044, total=4089.72, n_correct=2656.22, ppl=4.66, accuracy=64.949, wps=11979.4, ups=1.46, wpb=8179.4, bsz=295.7, num_updates=30000, lr=8.16497e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=14.4, wall=25324
2023-08-10 08:03:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 08:03:26 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.559 | nll_loss 2.83 | w2v_ctc_loss 1.326 | task_loss 6.931 | contrastive_loss 0.237 | total 4003.4 | n_correct 2481.6 | ppl 7.11 | accuracy 61.987 | uer 17.185 | wer 19.078 | raw_wer 19.078 | bleu 19.78 | wps 1948 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.32
2023-08-10 08:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-10 08:03:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_21_30000.pt
2023-08-10 08:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_21_30000.pt
2023-08-10 08:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.78) (writing took 33.55138571374118 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 08:05:10 | INFO | train_inner | epoch 021:    635 / 1474 loss=2.026, trans_loss=5.03, nll_loss=2.235, w2v_ctc_loss=0.659, task_loss=2.06, contrastive_loss=0.215, total=4210.28, n_correct=2725.41, ppl=4.71, accuracy=64.732, wps=6514.9, ups=0.77, wpb=8420.6, bsz=315.7, num_updates=30100, lr=8.15139e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=25453
2023-08-10 08:06:19 | INFO | train_inner | epoch 021:    735 / 1474 loss=2.014, trans_loss=5.041, nll_loss=2.248, w2v_ctc_loss=0.66, task_loss=2.091, contrastive_loss=0.074, total=4149.01, n_correct=2675.54, ppl=4.75, accuracy=64.486, wps=12015.4, ups=1.45, wpb=8298, bsz=307.4, num_updates=30200, lr=8.13788e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=25522
2023-08-10 08:07:28 | INFO | train_inner | epoch 021:    835 / 1474 loss=2.021, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.667, task_loss=2.186, contrastive_loss=0.088, total=4075.99, n_correct=2625.18, ppl=4.77, accuracy=64.406, wps=11883.6, ups=1.46, wpb=8152, bsz=295.7, num_updates=30300, lr=8.12444e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=25591
2023-08-10 08:08:36 | INFO | train_inner | epoch 021:    935 / 1474 loss=2.009, trans_loss=5.033, nll_loss=2.238, w2v_ctc_loss=0.662, task_loss=2.095, contrastive_loss=0.061, total=4091.88, n_correct=2642.31, ppl=4.72, accuracy=64.574, wps=11953.2, ups=1.46, wpb=8183.8, bsz=300, num_updates=30400, lr=8.11107e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=25659
2023-08-10 08:09:45 | INFO | train_inner | epoch 021:   1035 / 1474 loss=2.017, trans_loss=5.049, nll_loss=2.26, w2v_ctc_loss=0.665, task_loss=2.117, contrastive_loss=0.058, total=4107.66, n_correct=2641.77, ppl=4.79, accuracy=64.313, wps=12016.9, ups=1.46, wpb=8215.3, bsz=299.5, num_updates=30500, lr=8.09776e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=25727
2023-08-10 08:10:53 | INFO | train_inner | epoch 021:   1135 / 1474 loss=2.017, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.669, task_loss=2.228, contrastive_loss=0.063, total=4118.94, n_correct=2654.02, ppl=4.75, accuracy=64.435, wps=12062.7, ups=1.46, wpb=8237.9, bsz=294.9, num_updates=30600, lr=8.08452e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=25796
2023-08-10 08:12:01 | INFO | train_inner | epoch 021:   1235 / 1474 loss=2.021, trans_loss=5.043, nll_loss=2.252, w2v_ctc_loss=0.665, task_loss=1.998, contrastive_loss=0.111, total=4151.84, n_correct=2677.67, ppl=4.76, accuracy=64.494, wps=12191.7, ups=1.47, wpb=8303.7, bsz=309.1, num_updates=30700, lr=8.07134e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=25864
2023-08-10 08:13:10 | INFO | train_inner | epoch 021:   1335 / 1474 loss=2.012, trans_loss=5.04, nll_loss=2.248, w2v_ctc_loss=0.661, task_loss=2.015, contrastive_loss=0.072, total=4145.91, n_correct=2679.17, ppl=4.75, accuracy=64.622, wps=12046.8, ups=1.45, wpb=8291.8, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=25933
2023-08-10 08:14:19 | INFO | train_inner | epoch 021:   1435 / 1474 loss=2.035, trans_loss=5.052, nll_loss=2.263, w2v_ctc_loss=0.684, task_loss=2.178, contrastive_loss=0.121, total=4136.27, n_correct=2654.3, ppl=4.8, accuracy=64.171, wps=11971.5, ups=1.45, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=26002
2023-08-10 08:14:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
2023-08-10 08:15:10 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.553 | nll_loss 2.826 | w2v_ctc_loss 1.321 | task_loss 6.93 | contrastive_loss 0.244 | total 4003.4 | n_correct 2486.5 | ppl 7.09 | accuracy 62.11 | uer 17.304 | wer 19.242 | raw_wer 19.242 | bleu 19.75 | wps 2109.4 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 20.32
2023-08-10 08:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-10 08:15:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7507.pt
2023-08-10 08:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7507.pt
2023-08-10 08:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_19.7507.pt (epoch 21 @ 30939 updates, score 19.75) (writing took 17.990900710225105 seconds)
2023-08-10 08:15:28 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-10 08:15:28 | INFO | train | epoch 021 | loss 2.016 | trans_loss 5.034 | nll_loss 2.239 | w2v_ctc_loss 0.663 | task_loss 2.082 | contrastive_loss 0.101 | total 4138.65 | n_correct 2674.19 | ppl 4.72 | accuracy 64.615 | wps 10877.3 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.536 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 15.4 | wall 26071
2023-08-10 08:15:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 08:15:29 | INFO | fairseq.trainer | begin training epoch 22
2023-08-10 08:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 08:16:18 | INFO | train_inner | epoch 022:     61 / 1474 loss=2, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.658, task_loss=2.086, contrastive_loss=0.045, total=4133.81, n_correct=2687.62, ppl=4.66, accuracy=65.016, wps=6955, ups=0.84, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=26121
2023-08-10 08:17:27 | INFO | train_inner | epoch 022:    161 / 1474 loss=2.01, trans_loss=5.012, nll_loss=2.21, w2v_ctc_loss=0.661, task_loss=2.128, contrastive_loss=0.123, total=4116.11, n_correct=2672.03, ppl=4.63, accuracy=64.916, wps=11930.5, ups=1.45, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=26190
2023-08-10 08:18:36 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.99, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.645, task_loss=1.82, contrastive_loss=0.066, total=4272.11, n_correct=2789.49, ppl=4.6, accuracy=65.295, wps=12410.3, ups=1.45, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=26258
2023-08-10 08:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 08:19:46 | INFO | train_inner | epoch 022:    362 / 1474 loss=2.018, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.659, task_loss=2.158, contrastive_loss=0.162, total=4159.07, n_correct=2696.75, ppl=4.66, accuracy=64.84, wps=11811.9, ups=1.42, wpb=8318.1, bsz=302.5, num_updates=31300, lr=7.99361e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=70, gb_free=17.7, wall=26329
2023-08-10 08:20:55 | INFO | train_inner | epoch 022:    462 / 1474 loss=2.013, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.658, task_loss=2.151, contrastive_loss=0.106, total=4143.46, n_correct=2685.09, ppl=4.69, accuracy=64.803, wps=12000.1, ups=1.45, wpb=8286.9, bsz=300.6, num_updates=31400, lr=7.98087e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=26398
2023-08-10 08:22:05 | INFO | train_inner | epoch 022:    562 / 1474 loss=2, trans_loss=5.018, nll_loss=2.219, w2v_ctc_loss=0.654, task_loss=2.105, contrastive_loss=0.051, total=4143.14, n_correct=2690.71, ppl=4.65, accuracy=64.944, wps=11967.3, ups=1.44, wpb=8286.3, bsz=304.4, num_updates=31500, lr=7.96819e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=26467
2023-08-10 08:23:12 | INFO | train_inner | epoch 022:    662 / 1474 loss=2.003, trans_loss=5.014, nll_loss=2.214, w2v_ctc_loss=0.644, task_loss=1.978, contrastive_loss=0.138, total=4146.54, n_correct=2693.85, ppl=4.64, accuracy=64.966, wps=12209.9, ups=1.47, wpb=8293.1, bsz=311.9, num_updates=31600, lr=7.95557e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=67, gb_free=13.2, wall=26535
2023-08-10 08:24:22 | INFO | train_inner | epoch 022:    762 / 1474 loss=2.005, trans_loss=5.023, nll_loss=2.225, w2v_ctc_loss=0.661, task_loss=2.135, contrastive_loss=0.056, total=4170.82, n_correct=2704.93, ppl=4.68, accuracy=64.854, wps=12041.2, ups=1.44, wpb=8341.6, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=26604
2023-08-10 08:25:31 | INFO | train_inner | epoch 022:    862 / 1474 loss=2.008, trans_loss=5.033, nll_loss=2.237, w2v_ctc_loss=0.662, task_loss=2.232, contrastive_loss=0.045, total=4077.65, n_correct=2631.72, ppl=4.72, accuracy=64.54, wps=11832.2, ups=1.45, wpb=8155.3, bsz=290.5, num_updates=31800, lr=7.93052e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=26673
2023-08-10 08:26:39 | INFO | train_inner | epoch 022:    962 / 1474 loss=2.002, trans_loss=5.027, nll_loss=2.231, w2v_ctc_loss=0.655, task_loss=2.09, contrastive_loss=0.053, total=4136.66, n_correct=2681.89, ppl=4.69, accuracy=64.832, wps=12075.4, ups=1.46, wpb=8273.3, bsz=304.7, num_updates=31900, lr=7.91808e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=26742
2023-08-10 08:27:48 | INFO | train_inner | epoch 022:   1062 / 1474 loss=2.017, trans_loss=5.024, nll_loss=2.228, w2v_ctc_loss=0.647, task_loss=1.995, contrastive_loss=0.214, total=4152.13, n_correct=2692.5, ppl=4.68, accuracy=64.846, wps=12122.5, ups=1.46, wpb=8304.3, bsz=313.8, num_updates=32000, lr=7.90569e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=26810
2023-08-10 08:27:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 08:28:12 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.554 | nll_loss 2.826 | w2v_ctc_loss 1.339 | task_loss 6.955 | contrastive_loss 0.237 | total 4003.4 | n_correct 2486 | ppl 7.09 | accuracy 62.097 | uer 17.333 | wer 19.287 | raw_wer 19.287 | bleu 19.86 | wps 2016.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.32
2023-08-10 08:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-10 08:28:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_22_32000.pt
2023-08-10 08:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_22_32000.pt
2023-08-10 08:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.86) (writing took 37.99293510615826 seconds)
2023-08-10 08:29:59 | INFO | train_inner | epoch 022:   1162 / 1474 loss=2.021, trans_loss=5.045, nll_loss=2.255, w2v_ctc_loss=0.667, task_loss=2.159, contrastive_loss=0.097, total=4102.27, n_correct=2643.58, ppl=4.77, accuracy=64.442, wps=6236.8, ups=0.76, wpb=8204.5, bsz=296.1, num_updates=32100, lr=7.89337e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=26942
2023-08-10 08:31:08 | INFO | train_inner | epoch 022:   1262 / 1474 loss=2.013, trans_loss=5.038, nll_loss=2.247, w2v_ctc_loss=0.661, task_loss=1.928, contrastive_loss=0.086, total=4179.1, n_correct=2695.89, ppl=4.75, accuracy=64.509, wps=12173.2, ups=1.46, wpb=8358.2, bsz=321.7, num_updates=32200, lr=7.8811e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=27011
2023-08-10 08:32:16 | INFO | train_inner | epoch 022:   1362 / 1474 loss=2.009, trans_loss=5.028, nll_loss=2.233, w2v_ctc_loss=0.652, task_loss=2.074, contrastive_loss=0.115, total=4061.14, n_correct=2626.79, ppl=4.7, accuracy=64.681, wps=11918, ups=1.47, wpb=8122.3, bsz=299.1, num_updates=32300, lr=7.86889e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=27079
2023-08-10 08:33:24 | INFO | train_inner | epoch 022:   1462 / 1474 loss=2.018, trans_loss=5.048, nll_loss=2.258, w2v_ctc_loss=0.669, task_loss=2.228, contrastive_loss=0.06, total=4083.08, n_correct=2629.11, ppl=4.78, accuracy=64.39, wps=11955.1, ups=1.46, wpb=8166.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=27147
2023-08-10 08:33:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 08:33:56 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.547 | nll_loss 2.816 | w2v_ctc_loss 1.306 | task_loss 6.932 | contrastive_loss 0.242 | total 4003.4 | n_correct 2491.4 | ppl 7.04 | accuracy 62.232 | uer 17.309 | wer 19.205 | raw_wer 19.205 | bleu 20.03 | wps 2247.4 | wpb 4003.4 | bsz 141.8 | num_updates 32412 | best_bleu 20.32
2023-08-10 08:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-08-10 08:33:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt
2023-08-10 08:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt
2023-08-10 08:34:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt (epoch 22 @ 32412 updates, score 20.03) (writing took 34.672755068168044 seconds)
2023-08-10 08:34:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-10 08:34:31 | INFO | train | epoch 022 | loss 2.009 | trans_loss 5.025 | nll_loss 2.228 | w2v_ctc_loss 0.657 | task_loss 2.082 | contrastive_loss 0.096 | total 4137.49 | n_correct 2680.93 | ppl 4.68 | accuracy 64.796 | wps 10671.3 | ups 1.29 | wpb 8275 | bsz 305.2 | num_updates 32412 | lr 7.85529e-05 | gnorm 0.538 | clip 0 | loss_scale 16 | train_wall 1003 | gb_free 11.6 | wall 27213
2023-08-10 08:34:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 08:34:31 | INFO | fairseq.trainer | begin training epoch 23
2023-08-10 08:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 08:35:39 | INFO | train_inner | epoch 023:     88 / 1474 loss=1.991, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.655, task_loss=2.12, contrastive_loss=0.05, total=4093.3, n_correct=2674.1, ppl=4.58, accuracy=65.329, wps=6089.5, ups=0.74, wpb=8186.6, bsz=301.3, num_updates=32500, lr=7.84465e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=27282
2023-08-10 08:36:47 | INFO | train_inner | epoch 023:    188 / 1474 loss=1.991, trans_loss=4.998, nll_loss=2.192, w2v_ctc_loss=0.649, task_loss=2.211, contrastive_loss=0.049, total=4116.26, n_correct=2690.16, ppl=4.57, accuracy=65.354, wps=12007.1, ups=1.46, wpb=8232.5, bsz=294.4, num_updates=32600, lr=7.8326e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=27350
2023-08-10 08:37:57 | INFO | train_inner | epoch 023:    288 / 1474 loss=1.999, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.641, task_loss=2.091, contrastive_loss=0.123, total=4148.03, n_correct=2704.09, ppl=4.6, accuracy=65.19, wps=11923.8, ups=1.44, wpb=8296.1, bsz=305.7, num_updates=32700, lr=7.82062e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=27420
2023-08-10 08:39:05 | INFO | train_inner | epoch 023:    388 / 1474 loss=1.99, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.646, task_loss=2.163, contrastive_loss=0.042, total=4115.99, n_correct=2683.92, ppl=4.6, accuracy=65.207, wps=12081, ups=1.47, wpb=8232, bsz=294.1, num_updates=32800, lr=7.80869e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=27488
2023-08-10 08:40:14 | INFO | train_inner | epoch 023:    488 / 1474 loss=1.998, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.646, task_loss=2.046, contrastive_loss=0.097, total=4156.5, n_correct=2708.72, ppl=4.61, accuracy=65.168, wps=12085.1, ups=1.45, wpb=8313, bsz=312.2, num_updates=32900, lr=7.79681e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27557
2023-08-10 08:41:22 | INFO | train_inner | epoch 023:    588 / 1474 loss=1.985, trans_loss=5.003, nll_loss=2.2, w2v_ctc_loss=0.644, task_loss=1.961, contrastive_loss=0.045, total=4174.84, n_correct=2731.03, ppl=4.59, accuracy=65.416, wps=12205.3, ups=1.46, wpb=8349.7, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=27625
2023-08-10 08:42:30 | INFO | train_inner | epoch 023:    688 / 1474 loss=1.998, trans_loss=5.01, nll_loss=2.209, w2v_ctc_loss=0.648, task_loss=2.097, contrastive_loss=0.085, total=4139.68, n_correct=2694.3, ppl=4.62, accuracy=65.085, wps=12178.3, ups=1.47, wpb=8279.4, bsz=302.2, num_updates=33100, lr=7.77322e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=27693
2023-08-10 08:43:39 | INFO | train_inner | epoch 023:    788 / 1474 loss=2, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.655, task_loss=2.096, contrastive_loss=0.064, total=4147.97, n_correct=2697.46, ppl=4.65, accuracy=65.031, wps=12085.2, ups=1.46, wpb=8295.9, bsz=305.8, num_updates=33200, lr=7.76151e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=27762
2023-08-10 08:44:48 | INFO | train_inner | epoch 023:    888 / 1474 loss=2.003, trans_loss=5.011, nll_loss=2.211, w2v_ctc_loss=0.647, task_loss=1.903, contrastive_loss=0.142, total=4182.69, n_correct=2723.13, ppl=4.63, accuracy=65.105, wps=12191.1, ups=1.46, wpb=8365.4, bsz=325, num_updates=33300, lr=7.74984e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=27830
2023-08-10 08:45:57 | INFO | train_inner | epoch 023:    988 / 1474 loss=2.024, trans_loss=5.017, nll_loss=2.218, w2v_ctc_loss=0.644, task_loss=2.074, contrastive_loss=0.3, total=4165.01, n_correct=2704.75, ppl=4.65, accuracy=64.94, wps=11981.8, ups=1.44, wpb=8330, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=27900
2023-08-10 08:47:06 | INFO | train_inner | epoch 023:   1088 / 1474 loss=2.004, trans_loss=5.023, nll_loss=2.226, w2v_ctc_loss=0.661, task_loss=2.208, contrastive_loss=0.052, total=4092.37, n_correct=2656.56, ppl=4.68, accuracy=64.915, wps=11875.3, ups=1.45, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=27969
2023-08-10 08:48:15 | INFO | train_inner | epoch 023:   1188 / 1474 loss=1.999, trans_loss=5.026, nll_loss=2.23, w2v_ctc_loss=0.657, task_loss=2.072, contrastive_loss=0.046, total=4164.9, n_correct=2699.45, ppl=4.69, accuracy=64.814, wps=12046.7, ups=1.45, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=13.6, wall=28038
2023-08-10 08:49:24 | INFO | train_inner | epoch 023:   1288 / 1474 loss=1.995, trans_loss=5.022, nll_loss=2.225, w2v_ctc_loss=0.647, task_loss=2.021, contrastive_loss=0.057, total=4136.96, n_correct=2688.96, ppl=4.67, accuracy=64.998, wps=12068.7, ups=1.46, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28106
2023-08-10 08:50:33 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.015, trans_loss=5.041, nll_loss=2.251, w2v_ctc_loss=0.652, task_loss=2.1, contrastive_loss=0.111, total=4142.84, n_correct=2673.96, ppl=4.76, accuracy=64.544, wps=12024.1, ups=1.45, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=28175
2023-08-10 08:51:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 08:51:56 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.547 | nll_loss 2.817 | w2v_ctc_loss 1.314 | task_loss 6.943 | contrastive_loss 0.242 | total 4003.4 | n_correct 2490 | ppl 7.05 | accuracy 62.197 | uer 17.028 | wer 18.937 | raw_wer 18.937 | bleu 20.03 | wps 2146.4 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 20.32
2023-08-10 08:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-10 08:51:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt
2023-08-10 08:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt
2023-08-10 08:52:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.0303.pt (epoch 23 @ 33886 updates, score 20.03) (writing took 22.856820981949568 seconds)
2023-08-10 08:52:19 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-10 08:52:19 | INFO | train | epoch 023 | loss 2.001 | trans_loss 5.015 | nll_loss 2.215 | w2v_ctc_loss 0.649 | task_loss 2.082 | contrastive_loss 0.098 | total 4138.65 | n_correct 2692.52 | ppl 4.64 | accuracy 65.058 | wps 11420 | ups 1.38 | wpb 8277.3 | bsz 305.7 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.54 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 13.6 | wall 28282
2023-08-10 08:52:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 08:52:19 | INFO | fairseq.trainer | begin training epoch 24
2023-08-10 08:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 08:52:37 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.021, trans_loss=5.031, nll_loss=2.238, w2v_ctc_loss=0.648, task_loss=2.106, contrastive_loss=0.186, total=4084.21, n_correct=2645.22, ppl=4.72, accuracy=64.767, wps=6595.3, ups=0.81, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=28299
2023-08-10 08:53:45 | INFO | train_inner | epoch 024:    114 / 1474 loss=2, trans_loss=4.989, nll_loss=2.181, w2v_ctc_loss=0.636, task_loss=1.916, contrastive_loss=0.208, total=4168.61, n_correct=2732.91, ppl=4.53, accuracy=65.559, wps=12099.9, ups=1.45, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=11.2, wall=28368
2023-08-10 08:53:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 08:54:08 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.55 | nll_loss 2.818 | w2v_ctc_loss 1.299 | task_loss 6.953 | contrastive_loss 0.237 | total 4003.4 | n_correct 2493.3 | ppl 7.05 | accuracy 62.28 | uer 16.938 | wer 18.761 | raw_wer 18.761 | bleu 20.06 | wps 2298.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.32
2023-08-10 08:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-10 08:54:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_24_34000.pt
2023-08-10 08:54:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_24_34000.pt
2023-08-10 08:54:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.06) (writing took 34.79451542161405 seconds)
2023-08-10 08:55:53 | INFO | train_inner | epoch 024:    214 / 1474 loss=2.002, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.627, task_loss=1.81, contrastive_loss=0.262, total=4252.53, n_correct=2789.99, ppl=4.54, accuracy=65.608, wps=6662.9, ups=0.78, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=28496
2023-08-10 08:57:02 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.983, trans_loss=4.997, nll_loss=2.191, w2v_ctc_loss=0.643, task_loss=2.022, contrastive_loss=0.043, total=4138.44, n_correct=2710.98, ppl=4.57, accuracy=65.507, wps=12058.2, ups=1.46, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=28564
2023-08-10 08:58:11 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.015, trans_loss=5.003, nll_loss=2.199, w2v_ctc_loss=0.653, task_loss=2.205, contrastive_loss=0.183, total=4153.83, n_correct=2706.62, ppl=4.59, accuracy=65.16, wps=12028.7, ups=1.45, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28633
2023-08-10 08:59:20 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.996, trans_loss=5.001, nll_loss=2.196, w2v_ctc_loss=0.647, task_loss=2.123, contrastive_loss=0.112, total=4141.88, n_correct=2703.52, ppl=4.58, accuracy=65.273, wps=12050, ups=1.45, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=28702
2023-08-10 09:00:29 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.987, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.636, task_loss=2.093, contrastive_loss=0.072, total=4162.06, n_correct=2720.46, ppl=4.58, accuracy=65.363, wps=12057.1, ups=1.45, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=28771
2023-08-10 09:01:38 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.998, trans_loss=5.013, nll_loss=2.212, w2v_ctc_loss=0.645, task_loss=2.155, contrastive_loss=0.087, total=4097.35, n_correct=2670.07, ppl=4.63, accuracy=65.166, wps=11878.1, ups=1.45, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=28840
2023-08-10 09:02:46 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.993, trans_loss=5.015, nll_loss=2.216, w2v_ctc_loss=0.645, task_loss=2.081, contrastive_loss=0.062, total=4124.25, n_correct=2690.11, ppl=4.65, accuracy=65.227, wps=12019, ups=1.46, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=28909
2023-08-10 09:03:55 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.998, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.655, task_loss=2.313, contrastive_loss=0.039, total=4041.44, n_correct=2625.29, ppl=4.65, accuracy=64.959, wps=11818.5, ups=1.46, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28977
2023-08-10 09:05:03 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.99, trans_loss=5.013, nll_loss=2.213, w2v_ctc_loss=0.643, task_loss=2.172, contrastive_loss=0.044, total=4128.8, n_correct=2691.99, ppl=4.64, accuracy=65.2, wps=12062.1, ups=1.46, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=29046
2023-08-10 09:06:11 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.993, trans_loss=5.002, nll_loss=2.2, w2v_ctc_loss=0.649, task_loss=2.003, contrastive_loss=0.083, total=4130.49, n_correct=2700.33, ppl=4.59, accuracy=65.376, wps=12103, ups=1.47, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=29114
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 09:07:20 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.993, trans_loss=5.013, nll_loss=2.214, w2v_ctc_loss=0.643, task_loss=2.052, contrastive_loss=0.072, total=4157.47, n_correct=2707.95, ppl=4.64, accuracy=65.135, wps=12064.2, ups=1.45, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=29183
2023-08-10 09:08:29 | INFO | train_inner | epoch 024:   1314 / 1474 loss=2, trans_loss=5.023, nll_loss=2.226, w2v_ctc_loss=0.657, task_loss=2.205, contrastive_loss=0.047, total=4107.23, n_correct=2667.5, ppl=4.68, accuracy=64.946, wps=11920.6, ups=1.45, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=29252
2023-08-10 09:09:38 | INFO | train_inner | epoch 024:   1414 / 1474 loss=2, trans_loss=5.026, nll_loss=2.23, w2v_ctc_loss=0.655, task_loss=2.174, contrastive_loss=0.047, total=4094.39, n_correct=2655.9, ppl=4.69, accuracy=64.867, wps=11985.6, ups=1.46, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=29320
2023-08-10 09:10:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
2023-08-10 09:10:41 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.548 | nll_loss 2.815 | w2v_ctc_loss 1.33 | task_loss 6.945 | contrastive_loss 0.246 | total 4003.4 | n_correct 2492.8 | ppl 7.04 | accuracy 62.267 | uer 17.299 | wer 19.201 | raw_wer 19.201 | bleu 20.32 | wps 2335.2 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.32
2023-08-10 09:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-10 09:10:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 09:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 09:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 24 @ 35360 updates, score 20.32) (writing took 25.531291410326958 seconds)
2023-08-10 09:11:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-10 09:11:07 | INFO | train | epoch 024 | loss 1.996 | trans_loss 5.007 | nll_loss 2.205 | w2v_ctc_loss 0.645 | task_loss 2.081 | contrastive_loss 0.097 | total 4138.65 | n_correct 2700.4 | ppl 4.61 | accuracy 65.248 | wps 10814.4 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.539 | clip 0 | loss_scale 64 | train_wall 1004 | gb_free 16 | wall 29410
2023-08-10 09:11:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 09:11:08 | INFO | fairseq.trainer | begin training epoch 25
2023-08-10 09:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 09:11:42 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.981, trans_loss=4.997, nll_loss=2.194, w2v_ctc_loss=0.637, task_loss=2.009, contrastive_loss=0.052, total=4165.57, n_correct=2731.57, ppl=4.58, accuracy=65.575, wps=6682.9, ups=0.8, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=13, wall=29445
2023-08-10 09:12:50 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.969, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.628, task_loss=2.019, contrastive_loss=0.051, total=4135.43, n_correct=2728.65, ppl=4.48, accuracy=65.982, wps=12113.6, ups=1.46, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=68, gb_free=17.7, wall=29513
2023-08-10 09:13:59 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.979, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.639, task_loss=2.129, contrastive_loss=0.054, total=4116.13, n_correct=2702.93, ppl=4.52, accuracy=65.667, wps=11950.9, ups=1.45, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=29582
2023-08-10 09:15:09 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.986, trans_loss=4.989, nll_loss=2.18, w2v_ctc_loss=0.635, task_loss=2.22, contrastive_loss=0.084, total=4141.49, n_correct=2713.31, ppl=4.53, accuracy=65.515, wps=11959, ups=1.44, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=69, gb_free=15.1, wall=29651
2023-08-10 09:15:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 09:16:18 | INFO | train_inner | epoch 025:    441 / 1474 loss=2.005, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.652, task_loss=2.175, contrastive_loss=0.16, total=4165.67, n_correct=2728.45, ppl=4.55, accuracy=65.498, wps=12010, ups=1.44, wpb=8331.3, bsz=297.6, num_updates=35800, lr=7.47435e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=29721
2023-08-10 09:17:27 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.983, trans_loss=5, nll_loss=2.197, w2v_ctc_loss=0.637, task_loss=2.016, contrastive_loss=0.054, total=4154.79, n_correct=2719.39, ppl=4.58, accuracy=65.452, wps=12082.2, ups=1.45, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=29789
2023-08-10 09:18:35 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.99, trans_loss=4.991, nll_loss=2.185, w2v_ctc_loss=0.641, task_loss=2.059, contrastive_loss=0.121, total=4156.33, n_correct=2723.42, ppl=4.55, accuracy=65.525, wps=12116.6, ups=1.46, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=29858
2023-08-10 09:18:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 09:18:59 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.223 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.354 | task_loss 6.909 | contrastive_loss 0.248 | total 4003.4 | n_correct 2487.3 | ppl 7.09 | accuracy 62.13 | uer 17.482 | wer 19.354 | raw_wer 19.354 | bleu 19.95 | wps 2213.8 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.32
2023-08-10 09:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-10 09:18:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_25_36000.pt
2023-08-10 09:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_25_36000.pt
2023-08-10 09:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.95) (writing took 35.6947908885777 seconds)
2023-08-10 09:20:44 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.992, trans_loss=4.996, nll_loss=2.191, w2v_ctc_loss=0.637, task_loss=2.095, contrastive_loss=0.114, total=4133.94, n_correct=2707.23, ppl=4.57, accuracy=65.488, wps=6438.9, ups=0.78, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=29986
2023-08-10 09:21:52 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.982, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.638, task_loss=1.933, contrastive_loss=0.061, total=4174.24, n_correct=2738.17, ppl=4.58, accuracy=65.597, wps=12238.3, ups=1.47, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=30055
2023-08-10 09:23:01 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.993, trans_loss=5.004, nll_loss=2.203, w2v_ctc_loss=0.64, task_loss=1.982, contrastive_loss=0.118, total=4154.13, n_correct=2713.57, ppl=4.6, accuracy=65.322, wps=12051.1, ups=1.45, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=10.6, wall=30124
2023-08-10 09:24:10 | INFO | train_inner | epoch 025:   1041 / 1474 loss=2.009, trans_loss=5.012, nll_loss=2.213, w2v_ctc_loss=0.636, task_loss=2.067, contrastive_loss=0.23, total=4178.3, n_correct=2722, ppl=4.64, accuracy=65.146, wps=12149.9, ups=1.45, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=30192
2023-08-10 09:25:18 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.983, trans_loss=5.005, nll_loss=2.202, w2v_ctc_loss=0.634, task_loss=2.229, contrastive_loss=0.039, total=4042.33, n_correct=2643.42, ppl=4.6, accuracy=65.393, wps=11850.6, ups=1.47, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=30261
2023-08-10 09:26:26 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.988, trans_loss=5.011, nll_loss=2.211, w2v_ctc_loss=0.639, task_loss=2.117, contrastive_loss=0.046, total=4087.78, n_correct=2663.74, ppl=4.63, accuracy=65.163, wps=12016.6, ups=1.47, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=30329
2023-08-10 09:27:35 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.996, trans_loss=5.005, nll_loss=2.203, w2v_ctc_loss=0.638, task_loss=2.035, contrastive_loss=0.139, total=4166.64, n_correct=2722.17, ppl=4.61, accuracy=65.332, wps=12138.5, ups=1.46, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=30397
2023-08-10 09:28:44 | INFO | train_inner | epoch 025:   1441 / 1474 loss=2.004, trans_loss=5.023, nll_loss=2.227, w2v_ctc_loss=0.645, task_loss=2.124, contrastive_loss=0.105, total=4114.64, n_correct=2669.08, ppl=4.68, accuracy=64.868, wps=11906.7, ups=1.45, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=30466
2023-08-10 09:29:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 09:29:29 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.542 | nll_loss 2.81 | w2v_ctc_loss 1.335 | task_loss 6.916 | contrastive_loss 0.249 | total 4003.4 | n_correct 2495.1 | ppl 7.01 | accuracy 62.325 | uer 17.023 | wer 19.034 | raw_wer 19.034 | bleu 20.13 | wps 2283.4 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.32
2023-08-10 09:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-10 09:29:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.1302.pt
2023-08-10 09:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.1302.pt
2023-08-10 09:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.1302.pt (epoch 25 @ 36833 updates, score 20.13) (writing took 18.503916814923286 seconds)
2023-08-10 09:29:48 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-10 09:29:48 | INFO | train | epoch 025 | loss 1.989 | trans_loss 4.999 | nll_loss 2.195 | w2v_ctc_loss 0.639 | task_loss 2.079 | contrastive_loss 0.096 | total 4138.35 | n_correct 2708.07 | ppl 4.58 | accuracy 65.438 | wps 10875.5 | ups 1.31 | wpb 8276.7 | bsz 305.6 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.54 | clip 0 | loss_scale 32 | train_wall 1002 | gb_free 14.2 | wall 30531
2023-08-10 09:29:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 09:29:49 | INFO | fairseq.trainer | begin training epoch 26
2023-08-10 09:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 09:30:42 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.97, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.625, task_loss=1.972, contrastive_loss=0.07, total=4172.16, n_correct=2754.81, ppl=4.47, accuracy=66.028, wps=7061.7, ups=0.85, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=30585
2023-08-10 09:31:51 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.986, trans_loss=4.972, nll_loss=2.161, w2v_ctc_loss=0.615, task_loss=1.835, contrastive_loss=0.245, total=4265.22, n_correct=2818.37, ppl=4.47, accuracy=66.078, wps=12296.7, ups=1.44, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=30654
2023-08-10 09:33:00 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.985, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.635, task_loss=2.063, contrastive_loss=0.133, total=4123.94, n_correct=2712.49, ppl=4.49, accuracy=65.774, wps=11966.1, ups=1.45, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=30723
2023-08-10 09:34:09 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.978, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.631, task_loss=1.984, contrastive_loss=0.09, total=4168.11, n_correct=2740.99, ppl=4.51, accuracy=65.761, wps=12190.6, ups=1.46, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=30791
2023-08-10 09:35:17 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.981, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.63, task_loss=1.995, contrastive_loss=0.137, total=4167.53, n_correct=2750.38, ppl=4.47, accuracy=65.995, wps=12170.8, ups=1.46, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=14, wall=30860
2023-08-10 09:36:26 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.981, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.642, task_loss=2.093, contrastive_loss=0.058, total=4158.48, n_correct=2732.79, ppl=4.53, accuracy=65.716, wps=12092.2, ups=1.45, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=30929
2023-08-10 09:37:35 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.974, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.627, task_loss=2.13, contrastive_loss=0.044, total=4129.11, n_correct=2713.15, ppl=4.53, accuracy=65.708, wps=11908.3, ups=1.44, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=13.8, wall=30998
2023-08-10 09:38:44 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.993, trans_loss=4.993, nll_loss=2.188, w2v_ctc_loss=0.63, task_loss=2.094, contrastive_loss=0.157, total=4096.84, n_correct=2684.64, ppl=4.56, accuracy=65.53, wps=12007.2, ups=1.47, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=31066
2023-08-10 09:39:52 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.982, trans_loss=4.992, nll_loss=2.186, w2v_ctc_loss=0.638, task_loss=2.077, contrastive_loss=0.059, total=4176.27, n_correct=2736.02, ppl=4.55, accuracy=65.513, wps=12174.5, ups=1.46, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=31135
2023-08-10 09:41:01 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.986, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.624, task_loss=2.147, contrastive_loss=0.111, total=4141.01, n_correct=2710.59, ppl=4.58, accuracy=65.457, wps=12003.9, ups=1.45, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=68, gb_free=15.4, wall=31204
2023-08-10 09:41:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 09:42:10 | INFO | train_inner | epoch 026:   1068 / 1474 loss=1.979, trans_loss=4.997, nll_loss=2.192, w2v_ctc_loss=0.634, task_loss=2.186, contrastive_loss=0.043, total=4119.22, n_correct=2705.7, ppl=4.57, accuracy=65.685, wps=11919.8, ups=1.45, wpb=8238.4, bsz=293.5, num_updates=37900, lr=7.26433e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=31273
2023-08-10 09:43:19 | INFO | train_inner | epoch 026:   1168 / 1474 loss=1.989, trans_loss=5.003, nll_loss=2.201, w2v_ctc_loss=0.637, task_loss=2.171, contrastive_loss=0.084, total=4112.79, n_correct=2686.02, ppl=4.6, accuracy=65.309, wps=11984.6, ups=1.46, wpb=8225.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31342
2023-08-10 09:43:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 09:43:41 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.548 | nll_loss 2.817 | w2v_ctc_loss 1.377 | task_loss 6.955 | contrastive_loss 0.242 | total 4003.4 | n_correct 2490.2 | ppl 7.05 | accuracy 62.202 | uer 17.24 | wer 19.056 | raw_wer 19.056 | bleu 20.27 | wps 2245.3 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.32
2023-08-10 09:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-10 09:43:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_26_38000.pt
2023-08-10 09:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_26_38000.pt
2023-08-10 09:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.27) (writing took 34.09487383440137 seconds)
2023-08-10 09:45:25 | INFO | train_inner | epoch 026:   1268 / 1474 loss=1.995, trans_loss=5.016, nll_loss=2.217, w2v_ctc_loss=0.649, task_loss=2.315, contrastive_loss=0.046, total=4005.82, n_correct=2603.86, ppl=4.65, accuracy=65.002, wps=6360.9, ups=0.79, wpb=8011.6, bsz=280.5, num_updates=38100, lr=7.24524e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31468
2023-08-10 09:46:34 | INFO | train_inner | epoch 026:   1368 / 1474 loss=1.981, trans_loss=5.005, nll_loss=2.203, w2v_ctc_loss=0.627, task_loss=2.08, contrastive_loss=0.057, total=4158.84, n_correct=2721.81, ppl=4.6, accuracy=65.446, wps=11981.3, ups=1.44, wpb=8317.7, bsz=311.2, num_updates=38200, lr=7.23575e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=69, gb_free=13.5, wall=31537
2023-08-10 09:47:42 | INFO | train_inner | epoch 026:   1468 / 1474 loss=1.975, trans_loss=4.997, nll_loss=2.195, w2v_ctc_loss=0.626, task_loss=1.993, contrastive_loss=0.053, total=4151.66, n_correct=2725.74, ppl=4.58, accuracy=65.654, wps=12214.9, ups=1.47, wpb=8303.3, bsz=315.5, num_updates=38300, lr=7.22629e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=31605
2023-08-10 09:47:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 09:48:09 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 1.297 | task_loss 6.936 | contrastive_loss 0.241 | total 4003.4 | n_correct 2485.4 | ppl 7.06 | accuracy 62.082 | uer 17.06 | wer 18.866 | raw_wer 18.866 | bleu 20.22 | wps 2314.9 | wpb 4003.4 | bsz 141.8 | num_updates 38306 | best_bleu 20.32
2023-08-10 09:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38306 updates
2023-08-10 09:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2206.pt
2023-08-10 09:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2206.pt
2023-08-10 09:48:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2206.pt (epoch 26 @ 38306 updates, score 20.22) (writing took 14.438098691403866 seconds)
2023-08-10 09:48:24 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-10 09:48:24 | INFO | train | epoch 026 | loss 1.982 | trans_loss 4.99 | nll_loss 2.183 | w2v_ctc_loss 0.631 | task_loss 2.08 | contrastive_loss 0.095 | total 4138.97 | n_correct 2717.11 | ppl 4.54 | accuracy 65.647 | wps 10933.2 | ups 1.32 | wpb 8277.9 | bsz 305.7 | num_updates 38306 | lr 7.22573e-05 | gnorm 0.543 | clip 0 | loss_scale 32 | train_wall 1003 | gb_free 15.9 | wall 31646
2023-08-10 09:48:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 09:48:24 | INFO | fairseq.trainer | begin training epoch 27
2023-08-10 09:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 09:49:35 | INFO | train_inner | epoch 027:     94 / 1474 loss=1.957, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.615, task_loss=2.218, contrastive_loss=0.035, total=4072.63, n_correct=2703.57, ppl=4.4, accuracy=66.384, wps=7200.4, ups=0.88, wpb=8145.3, bsz=284.2, num_updates=38400, lr=7.21688e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=31718
2023-08-10 09:50:44 | INFO | train_inner | epoch 027:    194 / 1474 loss=1.959, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.62, task_loss=1.993, contrastive_loss=0.06, total=4179.66, n_correct=2770.93, ppl=4.42, accuracy=66.296, wps=12117.7, ups=1.45, wpb=8359.3, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=31787
2023-08-10 09:51:53 | INFO | train_inner | epoch 027:    294 / 1474 loss=1.966, trans_loss=4.971, nll_loss=2.159, w2v_ctc_loss=0.625, task_loss=2.067, contrastive_loss=0.045, total=4173.27, n_correct=2757.87, ppl=4.46, accuracy=66.084, wps=12115.9, ups=1.45, wpb=8346.5, bsz=307, num_updates=38600, lr=7.19816e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31856
2023-08-10 09:53:03 | INFO | train_inner | epoch 027:    394 / 1474 loss=1.997, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.628, task_loss=2.168, contrastive_loss=0.229, total=4078.73, n_correct=2686.8, ppl=4.5, accuracy=65.873, wps=11671.4, ups=1.43, wpb=8157.5, bsz=297.5, num_updates=38700, lr=7.18885e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31926
2023-08-10 09:54:12 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.984, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.624, task_loss=1.906, contrastive_loss=0.16, total=4245.37, n_correct=2795.56, ppl=4.51, accuracy=65.85, wps=12277.5, ups=1.45, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31995
2023-08-10 09:55:21 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.98, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.632, task_loss=2.037, contrastive_loss=0.102, total=4134.93, n_correct=2724.18, ppl=4.51, accuracy=65.882, wps=12032.1, ups=1.45, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=32064
2023-08-10 09:56:30 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.979, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.628, task_loss=2.073, contrastive_loss=0.079, total=4162.17, n_correct=2734.26, ppl=4.53, accuracy=65.693, wps=12076.6, ups=1.45, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=32133
2023-08-10 09:57:38 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.976, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.634, task_loss=2.186, contrastive_loss=0.045, total=4107.17, n_correct=2702.6, ppl=4.52, accuracy=65.802, wps=12053.2, ups=1.47, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=11.4, wall=32201
2023-08-10 09:58:46 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.972, trans_loss=4.991, nll_loss=2.184, w2v_ctc_loss=0.623, task_loss=2.161, contrastive_loss=0.039, total=4101.4, n_correct=2697.6, ppl=4.54, accuracy=65.773, wps=12079.1, ups=1.47, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=32269
2023-08-10 09:59:55 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.992, trans_loss=4.985, nll_loss=2.179, w2v_ctc_loss=0.623, task_loss=2.01, contrastive_loss=0.22, total=4195.5, n_correct=2760.98, ppl=4.53, accuracy=65.808, wps=12148.2, ups=1.45, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=32338
2023-08-10 10:01:04 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.972, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.625, task_loss=2.09, contrastive_loss=0.056, total=4147.99, n_correct=2727.79, ppl=4.53, accuracy=65.762, wps=12037.6, ups=1.45, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=32407
2023-08-10 10:02:13 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.982, trans_loss=4.994, nll_loss=2.19, w2v_ctc_loss=0.636, task_loss=2.166, contrastive_loss=0.057, total=4104.84, n_correct=2690.32, ppl=4.56, accuracy=65.54, wps=11976.6, ups=1.46, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=12.1, wall=32475
2023-08-10 10:03:21 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.989, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.631, task_loss=2.204, contrastive_loss=0.11, total=4062.86, n_correct=2658.92, ppl=4.58, accuracy=65.445, wps=11853.1, ups=1.46, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=32544
2023-08-10 10:04:29 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.979, trans_loss=4.993, nll_loss=2.188, w2v_ctc_loss=0.625, task_loss=1.954, contrastive_loss=0.095, total=4157.6, n_correct=2730.68, ppl=4.56, accuracy=65.679, wps=12296.1, ups=1.48, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=32612
2023-08-10 10:05:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 10:05:46 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.543 | nll_loss 2.813 | w2v_ctc_loss 1.299 | task_loss 6.906 | contrastive_loss 0.233 | total 4003.4 | n_correct 2495.6 | ppl 7.03 | accuracy 62.337 | uer 17.227 | wer 19.03 | raw_wer 19.03 | bleu 20.4 | wps 2282 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.4
2023-08-10 10:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-10 10:05:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 10:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 10:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 27 @ 39780 updates, score 20.4) (writing took 24.193998577073216 seconds)
2023-08-10 10:06:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-10 10:06:11 | INFO | train | epoch 027 | loss 1.977 | trans_loss 4.982 | nll_loss 2.174 | w2v_ctc_loss 0.626 | task_loss 2.077 | contrastive_loss 0.094 | total 4138.65 | n_correct 2725.33 | ppl 4.51 | accuracy 65.851 | wps 11434.4 | ups 1.38 | wpb 8277.3 | bsz 305.7 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 1003 | gb_free 17.8 | wall 32713
2023-08-10 10:06:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 10:06:11 | INFO | fairseq.trainer | begin training epoch 28
2023-08-10 10:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 10:06:32 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.965, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.617, task_loss=2.018, contrastive_loss=0.046, total=4107.3, n_correct=2708.24, ppl=4.51, accuracy=65.937, wps=6671.4, ups=0.81, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=32735
2023-08-10 10:07:40 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.959, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.62, task_loss=2.175, contrastive_loss=0.041, total=4112.44, n_correct=2731.95, ppl=4.39, accuracy=66.431, wps=12024.3, ups=1.46, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=13.7, wall=32803
2023-08-10 10:08:49 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.954, trans_loss=4.96, nll_loss=2.145, w2v_ctc_loss=0.611, task_loss=1.973, contrastive_loss=0.05, total=4193.3, n_correct=2784.32, ppl=4.42, accuracy=66.399, wps=12294.3, ups=1.47, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=67, gb_free=16.9, wall=32871
2023-08-10 10:08:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 10:09:12 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 1.345 | task_loss 6.954 | contrastive_loss 0.236 | total 4003.4 | n_correct 2492.3 | ppl 7.09 | accuracy 62.255 | uer 17.248 | wer 19.019 | raw_wer 19.019 | bleu 20.49 | wps 2246.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.49
2023-08-10 10:09:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-10 10:09:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_28_40000.pt
2023-08-10 10:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_28_40000.pt
2023-08-10 10:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.49) (writing took 26.61264499090612 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 10:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 10:10:49 | INFO | train_inner | epoch 028:    321 / 1474 loss=1.99, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.615, task_loss=2.141, contrastive_loss=0.277, total=4114.66, n_correct=2713.54, ppl=4.46, accuracy=65.948, wps=6809.7, ups=0.83, wpb=8229.3, bsz=306, num_updates=40100, lr=7.06225e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=32992
2023-08-10 10:11:58 | INFO | train_inner | epoch 028:    421 / 1474 loss=1.965, trans_loss=4.969, nll_loss=2.155, w2v_ctc_loss=0.626, task_loss=2.15, contrastive_loss=0.038, total=4096.12, n_correct=2708.87, ppl=4.46, accuracy=66.133, wps=11966.3, ups=1.46, wpb=8192.2, bsz=296.6, num_updates=40200, lr=7.05346e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=33061
2023-08-10 10:13:06 | INFO | train_inner | epoch 028:    521 / 1474 loss=1.964, trans_loss=4.969, nll_loss=2.157, w2v_ctc_loss=0.618, task_loss=2.14, contrastive_loss=0.055, total=4109.15, n_correct=2718.38, ppl=4.46, accuracy=66.154, wps=12118.6, ups=1.47, wpb=8218.3, bsz=298.6, num_updates=40300, lr=7.0447e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=33128
2023-08-10 10:14:14 | INFO | train_inner | epoch 028:    621 / 1474 loss=1.967, trans_loss=4.98, nll_loss=2.17, w2v_ctc_loss=0.625, task_loss=2.108, contrastive_loss=0.044, total=4178.56, n_correct=2757.66, ppl=4.5, accuracy=65.995, wps=12256, ups=1.47, wpb=8357.1, bsz=304.4, num_updates=40400, lr=7.03598e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=33197
2023-08-10 10:15:23 | INFO | train_inner | epoch 028:    721 / 1474 loss=1.978, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.618, task_loss=1.892, contrastive_loss=0.156, total=4184.74, n_correct=2763.66, ppl=4.5, accuracy=66.041, wps=12165.2, ups=1.45, wpb=8369.5, bsz=327.2, num_updates=40500, lr=7.02728e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33265
2023-08-10 10:16:31 | INFO | train_inner | epoch 028:    821 / 1474 loss=1.96, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.615, task_loss=2.047, contrastive_loss=0.04, total=4087.21, n_correct=2702.85, ppl=4.48, accuracy=66.129, wps=12050.3, ups=1.47, wpb=8174.4, bsz=304.8, num_updates=40600, lr=7.01862e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=33333
2023-08-10 10:17:40 | INFO | train_inner | epoch 028:    921 / 1474 loss=1.979, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.626, task_loss=2.164, contrastive_loss=0.101, total=4119.18, n_correct=2707.95, ppl=4.52, accuracy=65.74, wps=11939.7, ups=1.45, wpb=8238.4, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=33402
2023-08-10 10:18:48 | INFO | train_inner | epoch 028:   1021 / 1474 loss=1.988, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.629, task_loss=2.036, contrastive_loss=0.152, total=4174.98, n_correct=2748.17, ppl=4.52, accuracy=65.825, wps=12148.3, ups=1.45, wpb=8350, bsz=310.9, num_updates=40800, lr=7.0014e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=33471
2023-08-10 10:19:57 | INFO | train_inner | epoch 028:   1121 / 1474 loss=1.962, trans_loss=4.971, nll_loss=2.161, w2v_ctc_loss=0.617, task_loss=1.994, contrastive_loss=0.059, total=4222.19, n_correct=2790.91, ppl=4.47, accuracy=66.101, wps=12312.8, ups=1.46, wpb=8444.4, bsz=321.5, num_updates=40900, lr=6.99284e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=33540
2023-08-10 10:21:05 | INFO | train_inner | epoch 028:   1221 / 1474 loss=1.965, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.616, task_loss=2.051, contrastive_loss=0.048, total=4104.72, n_correct=2706.68, ppl=4.51, accuracy=65.941, wps=12055.9, ups=1.47, wpb=8209.4, bsz=305.5, num_updates=41000, lr=6.9843e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=33608
2023-08-10 10:22:14 | INFO | train_inner | epoch 028:   1321 / 1474 loss=1.98, trans_loss=4.99, nll_loss=2.184, w2v_ctc_loss=0.631, task_loss=2.307, contrastive_loss=0.062, total=4074.43, n_correct=2679.39, ppl=4.54, accuracy=65.761, wps=11875.1, ups=1.46, wpb=8148.9, bsz=282.9, num_updates=41100, lr=6.9758e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=33676
2023-08-10 10:23:22 | INFO | train_inner | epoch 028:   1421 / 1474 loss=1.975, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.619, task_loss=2.154, contrastive_loss=0.085, total=4156.52, n_correct=2735.54, ppl=4.52, accuracy=65.813, wps=12094.9, ups=1.45, wpb=8313, bsz=300.8, num_updates=41200, lr=6.96733e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=33745
2023-08-10 10:23:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
2023-08-10 10:24:22 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.546 | nll_loss 2.815 | w2v_ctc_loss 1.29 | task_loss 6.915 | contrastive_loss 0.237 | total 4003.4 | n_correct 2494.1 | ppl 7.04 | accuracy 62.3 | uer 16.879 | wer 18.717 | raw_wer 18.717 | bleu 20.34 | wps 2120.8 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 20.49
2023-08-10 10:24:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-08-10 10:24:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3401.pt
2023-08-10 10:24:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3401.pt
2023-08-10 10:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3401.pt (epoch 28 @ 41253 updates, score 20.34) (writing took 14.1771250218153 seconds)
2023-08-10 10:24:37 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-10 10:24:37 | INFO | train | epoch 028 | loss 1.97 | trans_loss 4.975 | nll_loss 2.164 | w2v_ctc_loss 0.621 | task_loss 2.086 | contrastive_loss 0.085 | total 4137.55 | n_correct 2732.22 | ppl 4.48 | accuracy 66.035 | wps 11018.4 | ups 1.33 | wpb 8275.1 | bsz 305.2 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 16.3 | wall 33820
2023-08-10 10:24:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 10:24:37 | INFO | fairseq.trainer | begin training epoch 29
2023-08-10 10:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 10:25:17 | INFO | train_inner | epoch 029:     47 / 1474 loss=1.961, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.623, task_loss=2.01, contrastive_loss=0.059, total=4169.02, n_correct=2765.9, ppl=4.43, accuracy=66.344, wps=7292.6, ups=0.87, wpb=8338, bsz=315.1, num_updates=41300, lr=6.95889e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=33859
2023-08-10 10:26:26 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.966, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.624, task_loss=2.076, contrastive_loss=0.076, total=4110.03, n_correct=2723.64, ppl=4.42, accuracy=66.268, wps=11920.4, ups=1.45, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=33928
2023-08-10 10:27:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 10:27:34 | INFO | train_inner | epoch 029:    248 / 1474 loss=1.948, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.606, task_loss=1.952, contrastive_loss=0.054, total=4167.92, n_correct=2774.08, ppl=4.38, accuracy=66.558, wps=12114.1, ups=1.45, wpb=8335.8, bsz=320.9, num_updates=41500, lr=6.9421e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=33997
2023-08-10 10:28:43 | INFO | train_inner | epoch 029:    348 / 1474 loss=1.969, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.63, task_loss=2.245, contrastive_loss=0.045, total=4095.08, n_correct=2707.39, ppl=4.47, accuracy=66.113, wps=12009.4, ups=1.47, wpb=8190.2, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=34065
2023-08-10 10:29:51 | INFO | train_inner | epoch 029:    448 / 1474 loss=1.945, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.603, task_loss=2.006, contrastive_loss=0.038, total=4155.97, n_correct=2771.58, ppl=4.37, accuracy=66.689, wps=12107.9, ups=1.46, wpb=8311.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=34134
2023-08-10 10:31:00 | INFO | train_inner | epoch 029:    548 / 1474 loss=1.979, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.618, task_loss=2.212, contrastive_loss=0.13, total=4159.23, n_correct=2745.41, ppl=4.47, accuracy=66.008, wps=12143.6, ups=1.46, wpb=8318.5, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=34203
2023-08-10 10:32:09 | INFO | train_inner | epoch 029:    648 / 1474 loss=1.973, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.612, task_loss=1.963, contrastive_loss=0.202, total=4139.5, n_correct=2745.82, ppl=4.42, accuracy=66.332, wps=12048.6, ups=1.46, wpb=8279, bsz=318.8, num_updates=41900, lr=6.90889e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=34271
2023-08-10 10:33:18 | INFO | train_inner | epoch 029:    748 / 1474 loss=1.965, trans_loss=4.962, nll_loss=2.148, w2v_ctc_loss=0.613, task_loss=1.931, contrastive_loss=0.118, total=4241.03, n_correct=2813.47, ppl=4.43, accuracy=66.339, wps=12208.8, ups=1.44, wpb=8482.1, bsz=328.7, num_updates=42000, lr=6.90066e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=34341
2023-08-10 10:33:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 10:33:40 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.545 | nll_loss 2.813 | w2v_ctc_loss 1.364 | task_loss 6.937 | contrastive_loss 0.234 | total 4003.4 | n_correct 2492.9 | ppl 7.03 | accuracy 62.27 | uer 17.097 | wer 18.87 | raw_wer 18.87 | bleu 20.23 | wps 2310.8 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.49
2023-08-10 10:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-10 10:33:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_29_42000.pt
2023-08-10 10:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_29_42000.pt
2023-08-10 10:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.23) (writing took 21.451018108054996 seconds)
2023-08-10 10:35:11 | INFO | train_inner | epoch 029:    848 / 1474 loss=1.967, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.618, task_loss=2.291, contrastive_loss=0.039, total=4031.53, n_correct=2657.06, ppl=4.51, accuracy=65.907, wps=7165.1, ups=0.89, wpb=8063.1, bsz=282.9, num_updates=42100, lr=6.89246e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=34453
2023-08-10 10:36:19 | INFO | train_inner | epoch 029:    948 / 1474 loss=1.969, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.624, task_loss=2.167, contrastive_loss=0.047, total=4082.22, n_correct=2691.49, ppl=4.51, accuracy=65.932, wps=12017.4, ups=1.47, wpb=8164.4, bsz=293.3, num_updates=42200, lr=6.88428e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=34521
2023-08-10 10:37:27 | INFO | train_inner | epoch 029:   1048 / 1474 loss=1.967, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.612, task_loss=2.063, contrastive_loss=0.12, total=4134.44, n_correct=2737.11, ppl=4.46, accuracy=66.203, wps=12061, ups=1.46, wpb=8268.9, bsz=307.7, num_updates=42300, lr=6.87614e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=34590
2023-08-10 10:38:36 | INFO | train_inner | epoch 029:   1148 / 1474 loss=1.97, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.626, task_loss=2.271, contrastive_loss=0.036, total=4080.4, n_correct=2687.29, ppl=4.52, accuracy=65.858, wps=11915.4, ups=1.46, wpb=8160.8, bsz=285.2, num_updates=42400, lr=6.86803e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=68, gb_free=12, wall=34658
2023-08-10 10:39:44 | INFO | train_inner | epoch 029:   1248 / 1474 loss=1.965, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.618, task_loss=2.103, contrastive_loss=0.04, total=4158.63, n_correct=2741.31, ppl=4.51, accuracy=65.919, wps=12145.8, ups=1.46, wpb=8317.3, bsz=301.6, num_updates=42500, lr=6.85994e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=34727
2023-08-10 10:40:53 | INFO | train_inner | epoch 029:   1348 / 1474 loss=1.967, trans_loss=4.972, nll_loss=2.162, w2v_ctc_loss=0.609, task_loss=2.064, contrastive_loss=0.103, total=4159.66, n_correct=2750.19, ppl=4.47, accuracy=66.116, wps=12056.5, ups=1.45, wpb=8319.3, bsz=308.6, num_updates=42600, lr=6.85189e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=34796
2023-08-10 10:42:01 | INFO | train_inner | epoch 029:   1448 / 1474 loss=1.974, trans_loss=4.974, nll_loss=2.166, w2v_ctc_loss=0.619, task_loss=2.024, contrastive_loss=0.133, total=4169.01, n_correct=2751.15, ppl=4.49, accuracy=65.99, wps=12312, ups=1.48, wpb=8338, bsz=314.2, num_updates=42700, lr=6.84386e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=34863
2023-08-10 10:42:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 10:42:43 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.22 | trans_loss 5.547 | nll_loss 2.815 | w2v_ctc_loss 1.362 | task_loss 6.927 | contrastive_loss 0.242 | total 4003.4 | n_correct 2491.4 | ppl 7.04 | accuracy 62.232 | uer 16.885 | wer 18.829 | raw_wer 18.829 | bleu 20.26 | wps 2082.4 | wpb 4003.4 | bsz 141.8 | num_updates 42726 | best_bleu 20.49
2023-08-10 10:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42726 updates
2023-08-10 10:42:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2603.pt
2023-08-10 10:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2603.pt
2023-08-10 10:42:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.2603.pt (epoch 29 @ 42726 updates, score 20.26) (writing took 14.25750551559031 seconds)
2023-08-10 10:42:57 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-10 10:42:57 | INFO | train | epoch 029 | loss 1.965 | trans_loss 4.968 | nll_loss 2.156 | w2v_ctc_loss 0.616 | task_loss 2.087 | contrastive_loss 0.084 | total 4136.74 | n_correct 2737.77 | ppl 4.46 | accuracy 66.182 | wps 11075 | ups 1.34 | wpb 8273.5 | bsz 305.1 | num_updates 42726 | lr 6.84178e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 15.9 | wall 34920
2023-08-10 10:42:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 10:42:58 | INFO | fairseq.trainer | begin training epoch 30
2023-08-10 10:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 10:43:56 | INFO | train_inner | epoch 030:     74 / 1474 loss=1.961, trans_loss=4.952, nll_loss=2.134, w2v_ctc_loss=0.601, task_loss=1.996, contrastive_loss=0.15, total=4172.13, n_correct=2777.94, ppl=4.39, accuracy=66.583, wps=7238.4, ups=0.87, wpb=8344.3, bsz=317.1, num_updates=42800, lr=6.83586e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=34979
2023-08-10 10:45:05 | INFO | train_inner | epoch 030:    174 / 1474 loss=1.948, trans_loss=4.933, nll_loss=2.111, w2v_ctc_loss=0.609, task_loss=1.934, contrastive_loss=0.079, total=4211.56, n_correct=2818.1, ppl=4.32, accuracy=66.913, wps=12225.4, ups=1.45, wpb=8423.1, bsz=320.5, num_updates=42900, lr=6.82789e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=35048
2023-08-10 10:46:13 | INFO | train_inner | epoch 030:    274 / 1474 loss=1.954, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.618, task_loss=2.166, contrastive_loss=0.036, total=4115.07, n_correct=2735.78, ppl=4.38, accuracy=66.482, wps=12145.5, ups=1.48, wpb=8230.1, bsz=293.2, num_updates=43000, lr=6.81994e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=67, gb_free=15.6, wall=35115
2023-08-10 10:47:21 | INFO | train_inner | epoch 030:    374 / 1474 loss=1.942, trans_loss=4.942, nll_loss=2.121, w2v_ctc_loss=0.602, task_loss=2.059, contrastive_loss=0.04, total=4184.54, n_correct=2796.18, ppl=4.35, accuracy=66.822, wps=12177.8, ups=1.46, wpb=8369.1, bsz=309.3, num_updates=43100, lr=6.81203e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=35184
2023-08-10 10:48:29 | INFO | train_inner | epoch 030:    474 / 1474 loss=1.954, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.6, task_loss=2.012, contrastive_loss=0.101, total=4121.08, n_correct=2741.87, ppl=4.38, accuracy=66.533, wps=12126.1, ups=1.47, wpb=8242.2, bsz=311.1, num_updates=43200, lr=6.80414e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=67, gb_free=14.7, wall=35252
2023-08-10 10:49:38 | INFO | train_inner | epoch 030:    574 / 1474 loss=1.957, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.611, task_loss=2.023, contrastive_loss=0.064, total=4162.58, n_correct=2764.36, ppl=4.43, accuracy=66.41, wps=12166.1, ups=1.46, wpb=8325.2, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=35321
2023-08-10 10:50:47 | INFO | train_inner | epoch 030:    674 / 1474 loss=1.963, trans_loss=4.96, nll_loss=2.146, w2v_ctc_loss=0.621, task_loss=2.051, contrastive_loss=0.075, total=4192, n_correct=2774.47, ppl=4.43, accuracy=66.185, wps=12131.7, ups=1.45, wpb=8384, bsz=315.3, num_updates=43400, lr=6.78844e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=35390
2023-08-10 10:51:55 | INFO | train_inner | epoch 030:    774 / 1474 loss=1.979, trans_loss=4.97, nll_loss=2.158, w2v_ctc_loss=0.622, task_loss=2.127, contrastive_loss=0.157, total=4103.26, n_correct=2711.28, ppl=4.46, accuracy=66.076, wps=12033, ups=1.47, wpb=8206.5, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=35458
2023-08-10 10:53:04 | INFO | train_inner | epoch 030:    874 / 1474 loss=1.963, trans_loss=4.969, nll_loss=2.157, w2v_ctc_loss=0.617, task_loss=2.129, contrastive_loss=0.053, total=4111.51, n_correct=2720.56, ppl=4.46, accuracy=66.169, wps=11991.7, ups=1.46, wpb=8223, bsz=297.8, num_updates=43600, lr=6.77285e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=35526
2023-08-10 10:54:12 | INFO | train_inner | epoch 030:    974 / 1474 loss=1.966, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.62, task_loss=2.151, contrastive_loss=0.051, total=4125.95, n_correct=2724.59, ppl=4.48, accuracy=66.035, wps=12056.5, ups=1.46, wpb=8251.9, bsz=298.7, num_updates=43700, lr=6.7651e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=35595
2023-08-10 10:55:22 | INFO | train_inner | epoch 030:   1074 / 1474 loss=1.978, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.616, task_loss=2.323, contrastive_loss=0.134, total=4096.17, n_correct=2698.9, ppl=4.49, accuracy=65.888, wps=11808.9, ups=1.44, wpb=8192.3, bsz=281.5, num_updates=43800, lr=6.75737e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=35664
2023-08-10 10:56:30 | INFO | train_inner | epoch 030:   1174 / 1474 loss=1.959, trans_loss=4.964, nll_loss=2.152, w2v_ctc_loss=0.6, task_loss=1.987, contrastive_loss=0.11, total=4168.92, n_correct=2767.36, ppl=4.44, accuracy=66.381, wps=12167.9, ups=1.46, wpb=8337.8, bsz=314.8, num_updates=43900, lr=6.74967e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=35733
2023-08-10 10:57:39 | INFO | train_inner | epoch 030:   1274 / 1474 loss=1.966, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.621, task_loss=2.307, contrastive_loss=0.044, total=4038.68, n_correct=2665.81, ppl=4.48, accuracy=66.007, wps=11715, ups=1.45, wpb=8077.4, bsz=284.1, num_updates=44000, lr=6.742e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=35802
2023-08-10 10:57:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 10:58:03 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.54 | nll_loss 2.807 | w2v_ctc_loss 1.31 | task_loss 6.921 | contrastive_loss 0.235 | total 4003.4 | n_correct 2500.3 | ppl 7 | accuracy 62.454 | uer 16.84 | wer 18.556 | raw_wer 18.556 | bleu 20.22 | wps 2158.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.49
2023-08-10 10:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-10 10:58:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_30_44000.pt
2023-08-10 10:58:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_30_44000.pt
2023-08-10 10:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.22) (writing took 19.969580560922623 seconds)
2023-08-10 10:59:31 | INFO | train_inner | epoch 030:   1374 / 1474 loss=1.953, trans_loss=4.965, nll_loss=2.154, w2v_ctc_loss=0.607, task_loss=1.956, contrastive_loss=0.054, total=4167.64, n_correct=2766.15, ppl=4.45, accuracy=66.372, wps=7439.6, ups=0.89, wpb=8335.3, bsz=321.9, num_updates=44100, lr=6.73435e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=35914
2023-08-10 11:00:39 | INFO | train_inner | epoch 030:   1474 / 1474 loss=1.971, trans_loss=4.971, nll_loss=2.161, w2v_ctc_loss=0.6, task_loss=1.956, contrastive_loss=0.202, total=4117.91, n_correct=2728.59, ppl=4.47, accuracy=66.262, wps=12159.2, ups=1.48, wpb=8235.8, bsz=312.2, num_updates=44200, lr=6.72673e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=35982
2023-08-10 11:00:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 11:01:02 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.548 | nll_loss 2.815 | w2v_ctc_loss 1.335 | task_loss 6.908 | contrastive_loss 0.238 | total 4003.4 | n_correct 2497.3 | ppl 7.04 | accuracy 62.379 | uer 17.06 | wer 18.881 | raw_wer 18.881 | bleu 20.45 | wps 2266.8 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 20.49
2023-08-10 11:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-08-10 11:01:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4502.pt
2023-08-10 11:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4502.pt
2023-08-10 11:01:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4502.pt (epoch 30 @ 44200 updates, score 20.45) (writing took 19.175892386585474 seconds)
2023-08-10 11:01:21 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-10 11:01:21 | INFO | train | epoch 030 | loss 1.961 | trans_loss 4.961 | nll_loss 2.146 | w2v_ctc_loss 0.611 | task_loss 2.079 | contrastive_loss 0.091 | total 4138.65 | n_correct 2745.75 | ppl 4.43 | accuracy 66.344 | wps 11053.2 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.542 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 17 | wall 36024
2023-08-10 11:01:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 11:01:22 | INFO | fairseq.trainer | begin training epoch 31
2023-08-10 11:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 11:02:38 | INFO | train_inner | epoch 031:    100 / 1474 loss=1.949, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.611, task_loss=2.2, contrastive_loss=0.047, total=4085.38, n_correct=2727.42, ppl=4.35, accuracy=66.76, wps=6884.8, ups=0.84, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=36100
2023-08-10 11:03:46 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.947, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.604, task_loss=2.157, contrastive_loss=0.057, total=4139.51, n_correct=2765.87, ppl=4.36, accuracy=66.816, wps=12150.3, ups=1.47, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=36168
2023-08-10 11:04:54 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.956, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.606, task_loss=2.131, contrastive_loss=0.104, total=4148.01, n_correct=2764.74, ppl=4.36, accuracy=66.652, wps=12099.2, ups=1.46, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=13.1, wall=36237
2023-08-10 11:06:03 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.951, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.605, task_loss=2.267, contrastive_loss=0.043, total=4095.42, n_correct=2725.67, ppl=4.4, accuracy=66.554, wps=11879.6, ups=1.45, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=36306
2023-08-10 11:07:12 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.951, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.613, task_loss=2.164, contrastive_loss=0.05, total=4115.61, n_correct=2739.71, ppl=4.37, accuracy=66.569, wps=12002.2, ups=1.46, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=36374
2023-08-10 11:08:20 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.951, trans_loss=4.952, nll_loss=2.134, w2v_ctc_loss=0.608, task_loss=2.19, contrastive_loss=0.041, total=4075.9, n_correct=2709.26, ppl=4.39, accuracy=66.47, wps=11883.9, ups=1.46, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=36443
2023-08-10 11:09:29 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.944, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.6, task_loss=1.987, contrastive_loss=0.043, total=4208.99, n_correct=2807.53, ppl=4.38, accuracy=66.703, wps=12289.2, ups=1.46, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=36512
2023-08-10 11:10:37 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.964, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.607, task_loss=2.162, contrastive_loss=0.11, total=4104.19, n_correct=2722.15, ppl=4.43, accuracy=66.326, wps=11970.2, ups=1.46, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=36580
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:0')
2023-08-10 11:11:46 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.953, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.608, task_loss=2.19, contrastive_loss=0.056, total=4099.13, n_correct=2723.06, ppl=4.4, accuracy=66.43, wps=11956.3, ups=1.46, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=36649
2023-08-10 11:12:55 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.962, trans_loss=4.963, nll_loss=2.15, w2v_ctc_loss=0.602, task_loss=1.942, contrastive_loss=0.138, total=4186.81, n_correct=2779.47, ppl=4.44, accuracy=66.386, wps=12156.6, ups=1.45, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=36718
2023-08-10 11:14:03 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.955, trans_loss=4.956, nll_loss=2.141, w2v_ctc_loss=0.604, task_loss=2.03, contrastive_loss=0.085, total=4149.25, n_correct=2757.39, ppl=4.41, accuracy=66.455, wps=12152.4, ups=1.46, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=36786
2023-08-10 11:15:12 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.967, trans_loss=4.959, nll_loss=2.146, w2v_ctc_loss=0.601, task_loss=1.965, contrastive_loss=0.202, total=4187.45, n_correct=2782.2, ppl=4.43, accuracy=66.441, wps=12195, ups=1.46, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=36855
2023-08-10 11:16:21 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.953, trans_loss=4.965, nll_loss=2.153, w2v_ctc_loss=0.61, task_loss=1.865, contrastive_loss=0.048, total=4227.39, n_correct=2808.85, ppl=4.45, accuracy=66.444, wps=12281.5, ups=1.45, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=36923
2023-08-10 11:17:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 11:17:31 | INFO | train_inner | epoch 031:   1401 / 1474 loss=1.964, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.607, task_loss=1.944, contrastive_loss=0.148, total=4164.79, n_correct=2765.5, ppl=4.43, accuracy=66.402, wps=11913.7, ups=1.43, wpb=8329.6, bsz=319.3, num_updates=45600, lr=6.62266e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=36993
2023-08-10 11:18:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2248, device='cuda:3')
2023-08-10 11:18:44 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.545 | nll_loss 2.813 | w2v_ctc_loss 1.326 | task_loss 6.981 | contrastive_loss 0.241 | total 4003.4 | n_correct 2500.3 | ppl 7.03 | accuracy 62.454 | uer 17.057 | wer 18.933 | raw_wer 18.933 | bleu 20.63 | wps 2169.5 | wpb 4003.4 | bsz 141.8 | num_updates 45673 | best_bleu 20.63
2023-08-10 11:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-08-10 11:18:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 11:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt
2023-08-10 11:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_best.pt (epoch 31 @ 45673 updates, score 20.63) (writing took 25.169538227841258 seconds)
2023-08-10 11:19:09 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-10 11:19:09 | INFO | train | epoch 031 | loss 1.955 | trans_loss 4.955 | nll_loss 2.138 | w2v_ctc_loss 0.607 | task_loss 2.085 | contrastive_loss 0.083 | total 4136.77 | n_correct 2751.59 | ppl 4.4 | accuracy 66.515 | wps 11408.6 | ups 1.38 | wpb 8273.5 | bsz 305.1 | num_updates 45673 | lr 6.61737e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 1002 | gb_free 11.9 | wall 37092
2023-08-10 11:19:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 11:19:10 | INFO | fairseq.trainer | begin training epoch 32
2023-08-10 11:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 11:19:36 | INFO | train_inner | epoch 032:     27 / 1474 loss=1.953, trans_loss=4.957, nll_loss=2.142, w2v_ctc_loss=0.613, task_loss=2.182, contrastive_loss=0.039, total=4051.41, n_correct=2693.54, ppl=4.41, accuracy=66.484, wps=6466.6, ups=0.8, wpb=8102.8, bsz=291.6, num_updates=45700, lr=6.61541e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=37119
2023-08-10 11:20:45 | INFO | train_inner | epoch 032:    127 / 1474 loss=1.929, trans_loss=4.921, nll_loss=2.095, w2v_ctc_loss=0.588, task_loss=1.947, contrastive_loss=0.048, total=4208.32, n_correct=2828.88, ppl=4.27, accuracy=67.221, wps=12275.9, ups=1.46, wpb=8416.6, bsz=319.1, num_updates=45800, lr=6.60819e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=11.5, wall=37187
2023-08-10 11:21:53 | INFO | train_inner | epoch 032:    227 / 1474 loss=1.94, trans_loss=4.937, nll_loss=2.116, w2v_ctc_loss=0.6, task_loss=1.991, contrastive_loss=0.055, total=4157.86, n_correct=2781.79, ppl=4.33, accuracy=66.904, wps=12119.5, ups=1.46, wpb=8315.7, bsz=320.3, num_updates=45900, lr=6.60098e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=14.3, wall=37256
2023-08-10 11:23:02 | INFO | train_inner | epoch 032:    327 / 1474 loss=1.936, trans_loss=4.929, nll_loss=2.105, w2v_ctc_loss=0.594, task_loss=1.976, contrastive_loss=0.051, total=4179.17, n_correct=2800.67, ppl=4.3, accuracy=67.015, wps=12190.4, ups=1.46, wpb=8358.3, bsz=313.4, num_updates=46000, lr=6.5938e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=37324
2023-08-10 11:23:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 11:23:26 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.551 | nll_loss 2.819 | w2v_ctc_loss 1.348 | task_loss 6.966 | contrastive_loss 0.239 | total 4003.4 | n_correct 2500.4 | ppl 7.06 | accuracy 62.457 | uer 16.93 | wer 18.978 | raw_wer 18.978 | bleu 20.42 | wps 2113.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.63
2023-08-10 11:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-10 11:23:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_32_46000.pt
2023-08-10 11:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_32_46000.pt
2023-08-10 11:24:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.42) (writing took 37.28114661574364 seconds)
2023-08-10 11:25:16 | INFO | train_inner | epoch 032:    427 / 1474 loss=1.941, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.602, task_loss=2.015, contrastive_loss=0.049, total=4179.5, n_correct=2799.1, ppl=4.33, accuracy=66.972, wps=6239.9, ups=0.75, wpb=8359, bsz=312.2, num_updates=46100, lr=6.58665e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=37458
2023-08-10 11:26:25 | INFO | train_inner | epoch 032:    527 / 1474 loss=1.959, trans_loss=4.948, nll_loss=2.13, w2v_ctc_loss=0.606, task_loss=2.041, contrastive_loss=0.125, total=4188.83, n_correct=2791.72, ppl=4.38, accuracy=66.647, wps=12146.4, ups=1.45, wpb=8377.7, bsz=313.9, num_updates=46200, lr=6.57952e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=37527
2023-08-10 11:27:34 | INFO | train_inner | epoch 032:    627 / 1474 loss=1.951, trans_loss=4.952, nll_loss=2.135, w2v_ctc_loss=0.607, task_loss=2.183, contrastive_loss=0.054, total=4133.19, n_correct=2750.99, ppl=4.39, accuracy=66.559, wps=11911.9, ups=1.44, wpb=8266.4, bsz=298.7, num_updates=46300, lr=6.57241e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=37597
2023-08-10 11:28:43 | INFO | train_inner | epoch 032:    727 / 1474 loss=1.947, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.609, task_loss=2.099, contrastive_loss=0.04, total=4162.1, n_correct=2776.25, ppl=4.38, accuracy=66.703, wps=12031.8, ups=1.45, wpb=8324.2, bsz=304.3, num_updates=46400, lr=6.56532e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=37666
2023-08-10 11:29:51 | INFO | train_inner | epoch 032:    827 / 1474 loss=1.945, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.599, task_loss=2.168, contrastive_loss=0.037, total=4107.86, n_correct=2736.68, ppl=4.38, accuracy=66.621, wps=12077.7, ups=1.47, wpb=8215.7, bsz=292.6, num_updates=46500, lr=6.55826e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=37734
2023-08-10 11:31:00 | INFO | train_inner | epoch 032:    927 / 1474 loss=1.943, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.596, task_loss=2.129, contrastive_loss=0.037, total=4146.9, n_correct=2765.51, ppl=4.38, accuracy=66.689, wps=12018.7, ups=1.45, wpb=8293.8, bsz=300.4, num_updates=46600, lr=6.55122e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=37803
2023-08-10 11:32:09 | INFO | train_inner | epoch 032:   1027 / 1474 loss=1.963, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.608, task_loss=2.067, contrastive_loss=0.131, total=4112.45, n_correct=2733.32, ppl=4.43, accuracy=66.465, wps=11946.1, ups=1.45, wpb=8224.9, bsz=304.3, num_updates=46700, lr=6.5442e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=37872
2023-08-10 11:33:18 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.959, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.604, task_loss=2.475, contrastive_loss=0.073, total=4015.2, n_correct=2667.27, ppl=4.42, accuracy=66.429, wps=11614.8, ups=1.45, wpb=8030.4, bsz=269.7, num_updates=46800, lr=6.5372e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=14.2, wall=37941
2023-08-10 11:34:27 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.975, trans_loss=4.968, nll_loss=2.157, w2v_ctc_loss=0.606, task_loss=2.036, contrastive_loss=0.178, total=4158.99, n_correct=2753.98, ppl=4.46, accuracy=66.218, wps=12044.6, ups=1.45, wpb=8318, bsz=312.1, num_updates=46900, lr=6.53023e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=38010
2023-08-10 11:35:36 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.951, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.607, task_loss=2.124, contrastive_loss=0.038, total=4079.56, n_correct=2709.47, ppl=4.42, accuracy=66.416, wps=11925.7, ups=1.46, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=38079
2023-08-10 11:36:45 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.985, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.616, task_loss=2.111, contrastive_loss=0.273, total=4107.37, n_correct=2718.15, ppl=4.45, accuracy=66.177, wps=11949.4, ups=1.45, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=38147
2023-08-10 11:37:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 11:37:40 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.219 | trans_loss 5.545 | nll_loss 2.813 | w2v_ctc_loss 1.364 | task_loss 6.994 | contrastive_loss 0.242 | total 4003.4 | n_correct 2499.4 | ppl 7.03 | accuracy 62.432 | uer 17.089 | wer 18.925 | raw_wer 18.925 | bleu 20.44 | wps 2117.3 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 20.63
2023-08-10 11:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-08-10 11:37:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4404.pt
2023-08-10 11:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4404.pt
2023-08-10 11:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.4404.pt (epoch 32 @ 47147 updates, score 20.44) (writing took 14.606653736904263 seconds)
2023-08-10 11:37:56 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-10 11:37:56 | INFO | train | epoch 032 | loss 1.952 | trans_loss 4.948 | nll_loss 2.13 | w2v_ctc_loss 0.602 | task_loss 2.082 | contrastive_loss 0.09 | total 4138.65 | n_correct 2758.64 | ppl 4.38 | accuracy 66.656 | wps 10833.3 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.55 | clip 0 | loss_scale 32 | train_wall 1005 | gb_free 16.4 | wall 38218
2023-08-10 11:37:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 11:37:56 | INFO | fairseq.trainer | begin training epoch 33
2023-08-10 11:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 11:38:40 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.952, trans_loss=4.94, nll_loss=2.121, w2v_ctc_loss=0.592, task_loss=1.977, contrastive_loss=0.139, total=4146.91, n_correct=2771.99, ppl=4.35, accuracy=66.845, wps=7180.3, ups=0.87, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=38263
2023-08-10 11:39:49 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.93, trans_loss=4.924, nll_loss=2.097, w2v_ctc_loss=0.584, task_loss=2.224, contrastive_loss=0.03, total=4073.36, n_correct=2735.07, ppl=4.28, accuracy=67.145, wps=11835.4, ups=1.45, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=38332
2023-08-10 11:40:58 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.955, trans_loss=4.926, nll_loss=2.104, w2v_ctc_loss=0.591, task_loss=1.767, contrastive_loss=0.195, total=4283.64, n_correct=2875.28, ppl=4.3, accuracy=67.122, wps=12446.1, ups=1.45, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=38400
2023-08-10 11:42:06 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.944, trans_loss=4.939, nll_loss=2.119, w2v_ctc_loss=0.603, task_loss=2.111, contrastive_loss=0.055, total=4131.27, n_correct=2760.88, ppl=4.34, accuracy=66.829, wps=12034.6, ups=1.46, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=38469
2023-08-10 11:43:15 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.925, trans_loss=4.922, nll_loss=2.096, w2v_ctc_loss=0.584, task_loss=1.982, contrastive_loss=0.037, total=4135.1, n_correct=2782.35, ppl=4.28, accuracy=67.286, wps=12140.8, ups=1.47, wpb=8270.2, bsz=309.7, num_updates=47600, lr=6.48204e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=38537
2023-08-10 11:44:23 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.949, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.604, task_loss=2.162, contrastive_loss=0.056, total=4132.78, n_correct=2755.27, ppl=4.36, accuracy=66.669, wps=12010.6, ups=1.45, wpb=8265.6, bsz=294.2, num_updates=47700, lr=6.47524e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=68, gb_free=17.7, wall=38606
2023-08-10 11:45:33 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.951, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.597, task_loss=2.136, contrastive_loss=0.088, total=4156.26, n_correct=2766.99, ppl=4.39, accuracy=66.574, wps=12022.9, ups=1.45, wpb=8312.5, bsz=300.7, num_updates=47800, lr=6.46846e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=38675
2023-08-10 11:46:41 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.951, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.613, task_loss=2.25, contrastive_loss=0.038, total=4074.99, n_correct=2712.56, ppl=4.38, accuracy=66.566, wps=11838.7, ups=1.45, wpb=8150, bsz=288.2, num_updates=47900, lr=6.46171e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=38744
2023-08-10 11:47:49 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.938, trans_loss=4.937, nll_loss=2.117, w2v_ctc_loss=0.583, task_loss=1.994, contrastive_loss=0.107, total=4127.6, n_correct=2766.6, ppl=4.34, accuracy=67.027, wps=12118.5, ups=1.47, wpb=8255.2, bsz=315.3, num_updates=48000, lr=6.45497e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=38812
2023-08-10 11:47:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 11:48:12 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.222 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 1.372 | task_loss 6.962 | contrastive_loss 0.234 | total 4003.4 | n_correct 2499.8 | ppl 7.05 | accuracy 62.442 | uer 16.71 | wer 18.564 | raw_wer 18.564 | bleu 20.27 | wps 2256.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.63
2023-08-10 11:48:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-10 11:48:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_33_48000.pt
2023-08-10 11:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_33_48000.pt
2023-08-10 11:48:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.27) (writing took 14.297013817355037 seconds)
2023-08-10 11:49:36 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.945, trans_loss=4.944, nll_loss=2.126, w2v_ctc_loss=0.606, task_loss=2.056, contrastive_loss=0.048, total=4157.37, n_correct=2775.58, ppl=4.36, accuracy=66.763, wps=7800.7, ups=0.94, wpb=8314.7, bsz=310.1, num_updates=48100, lr=6.44826e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=38919
2023-08-10 11:50:46 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.96, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.6, task_loss=2.11, contrastive_loss=0.152, total=4134.8, n_correct=2754.31, ppl=4.38, accuracy=66.613, wps=11896.9, ups=1.44, wpb=8269.6, bsz=306, num_updates=48200, lr=6.44157e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=38988
2023-08-10 11:51:55 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.956, trans_loss=4.953, nll_loss=2.137, w2v_ctc_loss=0.595, task_loss=2.078, contrastive_loss=0.139, total=4181.58, n_correct=2783.61, ppl=4.4, accuracy=66.568, wps=12133.6, ups=1.45, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=68, gb_free=15, wall=39057
2023-08-10 11:53:03 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.945, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.602, task_loss=2.174, contrastive_loss=0.042, total=4115.76, n_correct=2750.36, ppl=4.37, accuracy=66.825, wps=11947.8, ups=1.45, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=39126
2023-08-10 11:54:12 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.945, trans_loss=4.949, nll_loss=2.133, w2v_ctc_loss=0.6, task_loss=2.041, contrastive_loss=0.058, total=4120.69, n_correct=2752.73, ppl=4.39, accuracy=66.803, wps=11952.7, ups=1.45, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=39195
2023-08-10 11:55:21 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.963, trans_loss=4.95, nll_loss=2.135, w2v_ctc_loss=0.596, task_loss=2.072, contrastive_loss=0.207, total=4125.28, n_correct=2745.43, ppl=4.39, accuracy=66.551, wps=12039.7, ups=1.46, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=39264
2023-08-10 11:55:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 11:55:58 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.545 | nll_loss 2.813 | w2v_ctc_loss 1.349 | task_loss 6.941 | contrastive_loss 0.241 | total 4003.4 | n_correct 2503.7 | ppl 7.03 | accuracy 62.539 | uer 17.01 | wer 18.922 | raw_wer 18.922 | bleu 20.3 | wps 2219.8 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.63
2023-08-10 11:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-10 11:55:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3001.pt
2023-08-10 11:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3001.pt
2023-08-10 11:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint.best_bleu_20.3001.pt (epoch 33 @ 48621 updates, score 20.3) (writing took 17.62818504869938 seconds)
2023-08-10 11:56:16 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-10 11:56:16 | INFO | train | epoch 033 | loss 1.946 | trans_loss 4.942 | nll_loss 2.122 | w2v_ctc_loss 0.597 | task_loss 2.079 | contrastive_loss 0.089 | total 4138.65 | n_correct 2765.43 | ppl 4.35 | accuracy 66.82 | wps 11086.1 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.547 | clip 0 | loss_scale 64 | train_wall 1006 | gb_free 17.8 | wall 39319
2023-08-10 11:56:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 11:56:16 | INFO | fairseq.trainer | begin training epoch 34
2023-08-10 11:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 11:57:19 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.932, trans_loss=4.923, nll_loss=2.097, w2v_ctc_loss=0.594, task_loss=2.048, contrastive_loss=0.042, total=4131.47, n_correct=2777.54, ppl=4.28, accuracy=67.229, wps=7020.6, ups=0.85, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=39381
2023-08-10 11:58:27 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.931, trans_loss=4.92, nll_loss=2.093, w2v_ctc_loss=0.592, task_loss=2.173, contrastive_loss=0.044, total=4065.88, n_correct=2733.13, ppl=4.27, accuracy=67.221, wps=11854.5, ups=1.46, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=39450
2023-08-10 11:58:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 11:58:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 11:59:38 | INFO | train_inner | epoch 034:    281 / 1474 loss=1.934, trans_loss=4.931, nll_loss=2.107, w2v_ctc_loss=0.588, task_loss=2.011, contrastive_loss=0.059, total=4211.92, n_correct=2824.05, ppl=4.31, accuracy=67.049, wps=11984.4, ups=1.42, wpb=8423.8, bsz=316.7, num_updates=48900, lr=6.39529e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=39520
2023-08-10 12:00:46 | INFO | train_inner | epoch 034:    381 / 1474 loss=1.941, trans_loss=4.921, nll_loss=2.095, w2v_ctc_loss=0.587, task_loss=1.986, contrastive_loss=0.141, total=4151.69, n_correct=2791.95, ppl=4.27, accuracy=67.249, wps=12070, ups=1.45, wpb=8303.4, bsz=316.4, num_updates=49000, lr=6.38877e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=39589
2023-08-10 12:01:55 | INFO | train_inner | epoch 034:    481 / 1474 loss=1.942, trans_loss=4.936, nll_loss=2.113, w2v_ctc_loss=0.605, task_loss=2.266, contrastive_loss=0.037, total=4078.14, n_correct=2731.41, ppl=4.33, accuracy=66.977, wps=11903.3, ups=1.46, wpb=8156.3, bsz=284.7, num_updates=49100, lr=6.38226e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=39658
2023-08-10 12:03:03 | INFO | train_inner | epoch 034:    581 / 1474 loss=1.931, trans_loss=4.924, nll_loss=2.099, w2v_ctc_loss=0.589, task_loss=2.079, contrastive_loss=0.039, total=4130.95, n_correct=2777.29, ppl=4.28, accuracy=67.231, wps=12099.3, ups=1.46, wpb=8261.9, bsz=302, num_updates=49200, lr=6.37577e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=39726
2023-08-10 12:04:12 | INFO | train_inner | epoch 034:    681 / 1474 loss=1.933, trans_loss=4.93, nll_loss=2.107, w2v_ctc_loss=0.592, task_loss=2.136, contrastive_loss=0.035, total=4110.04, n_correct=2757.04, ppl=4.31, accuracy=67.081, wps=11984.3, ups=1.46, wpb=8220.1, bsz=296.9, num_updates=49300, lr=6.3693e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=39794
2023-08-10 12:05:20 | INFO | train_inner | epoch 034:    781 / 1474 loss=1.951, trans_loss=4.952, nll_loss=2.135, w2v_ctc_loss=0.592, task_loss=2.166, contrastive_loss=0.102, total=4079.01, n_correct=2719.4, ppl=4.39, accuracy=66.668, wps=11963.3, ups=1.47, wpb=8158, bsz=295.7, num_updates=49400, lr=6.36285e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=39863
2023-08-10 12:06:28 | INFO | train_inner | epoch 034:    881 / 1474 loss=1.946, trans_loss=4.944, nll_loss=2.126, w2v_ctc_loss=0.6, task_loss=2.199, contrastive_loss=0.06, total=4092.48, n_correct=2733.2, ppl=4.36, accuracy=66.786, wps=11980.7, ups=1.46, wpb=8185, bsz=295.5, num_updates=49500, lr=6.35642e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=39931
2023-08-10 12:07:37 | INFO | train_inner | epoch 034:    981 / 1474 loss=1.943, trans_loss=4.941, nll_loss=2.122, w2v_ctc_loss=0.602, task_loss=2.024, contrastive_loss=0.056, total=4185.89, n_correct=2797.66, ppl=4.35, accuracy=66.835, wps=12157.1, ups=1.45, wpb=8371.8, bsz=315, num_updates=49600, lr=6.35001e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=40000
2023-08-10 12:08:45 | INFO | train_inner | epoch 034:   1081 / 1474 loss=1.941, trans_loss=4.945, nll_loss=2.127, w2v_ctc_loss=0.6, task_loss=2.031, contrastive_loss=0.04, total=4142.31, n_correct=2769.63, ppl=4.37, accuracy=66.862, wps=12211.1, ups=1.47, wpb=8284.6, bsz=306.1, num_updates=49700, lr=6.34361e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=67, gb_free=17.9, wall=40068
2023-08-10 12:09:53 | INFO | train_inner | epoch 034:   1181 / 1474 loss=1.943, trans_loss=4.946, nll_loss=2.128, w2v_ctc_loss=0.598, task_loss=2.143, contrastive_loss=0.052, total=4101.07, n_correct=2739.31, ppl=4.37, accuracy=66.795, wps=12012.4, ups=1.46, wpb=8202.1, bsz=297.9, num_updates=49800, lr=6.33724e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=40136
2023-08-10 12:11:02 | INFO | train_inner | epoch 034:   1281 / 1474 loss=1.939, trans_loss=4.941, nll_loss=2.122, w2v_ctc_loss=0.596, task_loss=2.093, contrastive_loss=0.038, total=4150.75, n_correct=2772.66, ppl=4.35, accuracy=66.799, wps=12114.2, ups=1.46, wpb=8301.5, bsz=301.4, num_updates=49900, lr=6.33089e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=40204
2023-08-10 12:12:11 | INFO | train_inner | epoch 034:   1381 / 1474 loss=1.955, trans_loss=4.949, nll_loss=2.133, w2v_ctc_loss=0.606, task_loss=2.006, contrastive_loss=0.099, total=4194.17, n_correct=2792.16, ppl=4.39, accuracy=66.572, wps=12190.6, ups=1.45, wpb=8388.3, bsz=320.1, num_updates=50000, lr=6.32456e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=40273
2023-08-10 12:12:11 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-10 12:12:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 12:12:35 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.547 | nll_loss 2.814 | w2v_ctc_loss 1.347 | task_loss 6.93 | contrastive_loss 0.241 | total 4003.4 | n_correct 2500 | ppl 7.03 | accuracy 62.447 | uer 16.757 | wer 18.765 | raw_wer 18.765 | bleu 20.37 | wps 2009.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.63
2023-08-10 12:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-10 12:12:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_34_50000.pt
2023-08-10 12:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_34_50000.pt
2023-08-10 12:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup_alpha2.0_mt0.5_scale1.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.37) (writing took 16.73512674868107 seconds)
2023-08-10 12:12:54 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-10 12:12:54 | INFO | train | epoch 034 | loss 1.94 | trans_loss 4.936 | nll_loss 2.114 | w2v_ctc_loss 0.596 | task_loss 2.097 | contrastive_loss 0.061 | total 4130.36 | n_correct 2765.47 | ppl 4.33 | accuracy 66.955 | wps 11412.5 | ups 1.38 | wpb 8260.7 | bsz 303.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 938 | gb_free 15.7 | wall 40317
2023-08-10 12:12:54 | INFO | fairseq_cli.train | done training in 40264.6 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
