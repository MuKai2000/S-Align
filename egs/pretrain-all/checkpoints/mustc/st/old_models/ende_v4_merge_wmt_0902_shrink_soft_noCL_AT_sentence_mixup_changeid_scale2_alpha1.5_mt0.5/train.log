2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17559
2023-09-03 03:01:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-03 03:01:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-03 03:01:51 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 03:01:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-03 03:01:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17559', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-03 03:01:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-03 03:01:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-03 03:01:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-03 03:01:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-03 03:01:54 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 03:01:59 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-03 03:01:59 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-03 03:01:59 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-03 03:02:00 | INFO | root | load pretrained hubert
2023-09-03 03:02:08 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 03:02:12 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 03:02:18 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 03:02:18 | INFO | root | share the sematic adapter and textual encoder
2023-09-03 03:02:18 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-03 03:02:18 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-03 03:02:18 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-03 03:02:18 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-03 03:02:18 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-03 03:02:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-03 03:02:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 03:02:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 03:02:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 03:02:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 03:02:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-03 03:02:34 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-03 03:02:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-03 03:02:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 03:02:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 03:02:34 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-03 03:02:34 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-03 03:02:34 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 03:02:34 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 03:02:34 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-03 03:02:34 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 03:02:34 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 03:02:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 03:02:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 03:02:38 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 03:03:18 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-03 03:03:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 03:03:18 | INFO | fairseq.trainer | begin training epoch 1
2023-09-03 03:03:18 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 03:03:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 03:04:29 | INFO | train_inner | epoch 001:    101 / 1474 loss=17.384, trans_loss=5.872, nll_loss=4.681, w2v_ctc_loss=22.309, task_loss=2.746, task_loss_gen=2.791, contrastive_loss=0, total=4212.33, n_correct=124.65, ppl=25.64, accuracy=2.959, wps=21365.5, ups=1.7, wpb=12566.1, bsz=472.9, num_updates=100, lr=4.098e-06, gnorm=2.695, clip=0, loss_scale=64, train_wall=63, gb_free=18.8, wall=115
2023-09-03 03:04:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-03 03:05:28 | INFO | train_inner | epoch 001:    202 / 1474 loss=13.471, trans_loss=5.85, nll_loss=4.681, w2v_ctc_loss=16.303, task_loss=2.247, task_loss_gen=2.855, contrastive_loss=0, total=4127.88, n_correct=127.63, ppl=25.65, accuracy=3.092, wps=20874.3, ups=1.69, wpb=12326, bsz=463, num_updates=200, lr=8.096e-06, gnorm=7.325, clip=15, loss_scale=32, train_wall=58, gb_free=18.7, wall=174
2023-09-03 03:06:28 | INFO | train_inner | epoch 001:    302 / 1474 loss=7.225, trans_loss=5.785, nll_loss=4.64, w2v_ctc_loss=6.746, task_loss=1.666, task_loss_gen=3.559, contrastive_loss=0, total=4077.62, n_correct=133.77, ppl=24.93, accuracy=3.281, wps=20345.2, ups=1.67, wpb=12179.5, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=1.408, clip=0, loss_scale=32, train_wall=59, gb_free=19.3, wall=233
2023-09-03 03:07:26 | INFO | train_inner | epoch 001:    402 / 1474 loss=6.701, trans_loss=5.721, nll_loss=4.585, w2v_ctc_loss=6.01, task_loss=0.827, task_loss_gen=4.506, contrastive_loss=0, total=4177.45, n_correct=119.54, ppl=24, accuracy=2.862, wps=21457.3, ups=1.72, wpb=12474.2, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=57, gb_free=18.7, wall=292
2023-09-03 03:08:24 | INFO | train_inner | epoch 001:    502 / 1474 loss=6.525, trans_loss=5.766, nll_loss=4.65, w2v_ctc_loss=5.688, task_loss=0.315, task_loss_gen=6.157, contrastive_loss=0, total=4202.06, n_correct=98.43, ppl=25.1, accuracy=2.342, wps=21477.6, ups=1.71, wpb=12556.3, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=58, gb_free=14.6, wall=350
2023-09-03 03:09:22 | INFO | train_inner | epoch 001:    602 / 1474 loss=6.467, trans_loss=5.898, nll_loss=4.81, w2v_ctc_loss=5.461, task_loss=0.095, task_loss_gen=8.902, contrastive_loss=0, total=4124.52, n_correct=78.12, ppl=28.05, accuracy=1.894, wps=21260.9, ups=1.73, wpb=12301.1, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=57, gb_free=18.8, wall=408
2023-09-03 03:10:20 | INFO | train_inner | epoch 001:    702 / 1474 loss=6.284, trans_loss=5.96, nll_loss=4.889, w2v_ctc_loss=5.11, task_loss=0.027, task_loss_gen=12.105, contrastive_loss=0, total=4147.01, n_correct=49.04, ppl=29.63, accuracy=1.183, wps=21415.2, ups=1.73, wpb=12381.3, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.456, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=466
2023-09-03 03:11:18 | INFO | train_inner | epoch 001:    802 / 1474 loss=6.013, trans_loss=5.992, nll_loss=4.925, w2v_ctc_loss=4.662, task_loss=0.008, task_loss_gen=14.321, contrastive_loss=0, total=4121.11, n_correct=46.34, ppl=30.39, accuracy=1.124, wps=21228.5, ups=1.73, wpb=12298.3, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.764, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=524
2023-09-03 03:12:17 | INFO | train_inner | epoch 001:    902 / 1474 loss=5.841, trans_loss=6.033, nll_loss=4.973, w2v_ctc_loss=4.352, task_loss=0.003, task_loss_gen=16.773, contrastive_loss=0, total=4167.98, n_correct=67.8, ppl=31.41, accuracy=1.627, wps=21117.3, ups=1.7, wpb=12446.6, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.796, clip=0, loss_scale=32, train_wall=58, gb_free=19, wall=583
2023-09-03 03:13:15 | INFO | train_inner | epoch 001:   1002 / 1474 loss=5.702, trans_loss=6.069, nll_loss=5.014, w2v_ctc_loss=4.096, task_loss=0.001, task_loss_gen=18.728, contrastive_loss=0, total=4136.38, n_correct=115.8, ppl=32.32, accuracy=2.8, wps=21117.9, ups=1.71, wpb=12354.6, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=0.994, clip=0, loss_scale=32, train_wall=58, gb_free=19.2, wall=641
2023-09-03 03:14:14 | INFO | train_inner | epoch 001:   1102 / 1474 loss=5.539, trans_loss=5.998, nll_loss=4.941, w2v_ctc_loss=3.923, task_loss=0.878, task_loss_gen=7.155, contrastive_loss=0, total=4148.31, n_correct=106.68, ppl=30.72, accuracy=2.572, wps=21228.1, ups=1.72, wpb=12371.7, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=0.999, clip=0, loss_scale=32, train_wall=58, gb_free=18.6, wall=699
2023-09-03 03:14:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 03:15:12 | INFO | train_inner | epoch 001:   1203 / 1474 loss=5.784, trans_loss=6.471, nll_loss=5.528, w2v_ctc_loss=3.796, task_loss=2.038, task_loss_gen=3.473, contrastive_loss=0, total=4116.39, n_correct=6.03, ppl=46.13, accuracy=0.146, wps=20950, ups=1.7, wpb=12295.1, bsz=430, num_updates=1200, lr=4.8076e-05, gnorm=1.059, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=758
2023-09-03 03:16:10 | INFO | train_inner | epoch 001:   1303 / 1474 loss=5.569, trans_loss=6.301, nll_loss=5.321, w2v_ctc_loss=3.649, task_loss=2.151, task_loss_gen=3.047, contrastive_loss=0, total=4055.88, n_correct=4.94, ppl=39.97, accuracy=0.122, wps=21079.1, ups=1.74, wpb=12109.1, bsz=443.9, num_updates=1300, lr=5.2074e-05, gnorm=1.061, clip=0, loss_scale=16, train_wall=57, gb_free=19.2, wall=816
2023-09-03 03:17:09 | INFO | train_inner | epoch 001:   1403 / 1474 loss=5.353, trans_loss=6.105, nll_loss=5.081, w2v_ctc_loss=3.524, task_loss=2.368, task_loss_gen=3.132, contrastive_loss=0, total=4127.47, n_correct=13.35, ppl=33.84, accuracy=0.323, wps=20938, ups=1.7, wpb=12332.8, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.076, clip=0, loss_scale=16, train_wall=58, gb_free=19.1, wall=874
2023-09-03 03:17:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-03 03:18:36 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.335 | trans_loss 13.303 | nll_loss 12.999 | w2v_ctc_loss 4.472 | task_loss 11.367 | task_loss_gen 15.635 | contrastive_loss 0 | total 4003.4 | n_correct 4.1 | ppl 8188.78 | accuracy 0.102 | uer 60.075 | wer 58.723 | raw_wer 58.723 | bleu 0 | wps 1040.4 | wpb 4003.4 | bsz 141.8 | num_updates 1471
2023-09-03 03:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1471 updates
2023-09-03 03:18:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:18:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1471 updates, score 0.0) (writing took 4.8184719429700635 seconds)
2023-09-03 03:18:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-03 03:18:41 | INFO | train | epoch 001 | loss 7.329 | trans_loss 5.992 | nll_loss 4.914 | w2v_ctc_loss 6.688 | task_loss 1.154 | task_loss_gen 7.478 | contrastive_loss 0 | total 4138.13 | n_correct 74.5343 | ppl 30.16 | accuracy 1.801 | wps 19940.9 | ups 1.61 | wpb 12354.2 | bsz 458.2 | num_updates 1471 | lr 5.89106e-05 | gnorm 1.425 | clip 1 | loss_scale 16 | train_wall 855 | gb_free 18.9 | wall 967
2023-09-03 03:18:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 03:18:42 | INFO | fairseq.trainer | begin training epoch 2
2023-09-03 03:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 03:19:05 | INFO | train_inner | epoch 002:     29 / 1474 loss=5.253, trans_loss=6.063, nll_loss=5.023, w2v_ctc_loss=3.413, task_loss=2.395, task_loss_gen=3.004, contrastive_loss=0, total=4165.52, n_correct=11.77, ppl=32.52, accuracy=0.283, wps=10673, ups=0.86, wpb=12425.3, bsz=471.4, num_updates=1500, lr=6.007e-05, gnorm=1.325, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=991
2023-09-03 03:20:03 | INFO | train_inner | epoch 002:    129 / 1474 loss=5.284, trans_loss=6.175, nll_loss=5.177, w2v_ctc_loss=3.34, task_loss=1.905, task_loss_gen=3.35, contrastive_loss=0, total=4149.27, n_correct=7.02, ppl=36.17, accuracy=0.169, wps=21241.2, ups=1.72, wpb=12375.1, bsz=451.7, num_updates=1600, lr=6.4068e-05, gnorm=1.065, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1049
2023-09-03 03:21:01 | INFO | train_inner | epoch 002:    229 / 1474 loss=5.196, trans_loss=6.162, nll_loss=5.167, w2v_ctc_loss=3.223, task_loss=1.426, task_loss_gen=2.99, contrastive_loss=0, total=4199.2, n_correct=3.27, ppl=35.92, accuracy=0.078, wps=21900.4, ups=1.75, wpb=12541.6, bsz=494.4, num_updates=1700, lr=6.8066e-05, gnorm=1.101, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1106
2023-09-03 03:21:58 | INFO | train_inner | epoch 002:    329 / 1474 loss=5.112, trans_loss=6.064, nll_loss=5.046, w2v_ctc_loss=3.186, task_loss=1.432, task_loss_gen=3.634, contrastive_loss=0, total=4130.92, n_correct=10.8, ppl=33.05, accuracy=0.261, wps=21357.8, ups=1.73, wpb=12331.6, bsz=442.3, num_updates=1800, lr=7.2064e-05, gnorm=1.111, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1164
2023-09-03 03:22:56 | INFO | train_inner | epoch 002:    429 / 1474 loss=5.068, trans_loss=6.047, nll_loss=5.024, w2v_ctc_loss=3.137, task_loss=1.353, task_loss_gen=4.232, contrastive_loss=0, total=4036.18, n_correct=8.91, ppl=32.54, accuracy=0.221, wps=20817.9, ups=1.73, wpb=12064.4, bsz=416.3, num_updates=1900, lr=7.6062e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=57, gb_free=18.9, wall=1222
2023-09-03 03:23:55 | INFO | train_inner | epoch 002:    529 / 1474 loss=5.057, trans_loss=6.135, nll_loss=5.131, w2v_ctc_loss=3.032, task_loss=1.063, task_loss_gen=3.736, contrastive_loss=0, total=4185.63, n_correct=16.33, ppl=35.05, accuracy=0.39, wps=21292.8, ups=1.71, wpb=12487.7, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=0.969, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1281
2023-09-03 03:23:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 03:24:42 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.408 | trans_loss 13.662 | nll_loss 13.48 | w2v_ctc_loss 3.904 | task_loss 7.826 | task_loss_gen 16.995 | contrastive_loss 0 | total 4003.4 | n_correct 1.1 | ppl 11427.3 | accuracy 0.027 | uer 54.347 | wer 53.604 | raw_wer 53.604 | bleu 0 | wps 1041.2 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-09-03 03:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-03 03:24:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-03 03:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-03 03:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.296577025030274 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.2285, -1.6084, -0.0614,  0.5562, -0.4624], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0173, -0.0262, -0.0447,  ..., -0.0127, -0.0039,  0.0017],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0105, -0.0266,  0.0520,  ..., -0.0116, -0.0118, -0.0005]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.2285, -1.6084, -0.0614,  0.5562, -0.4624], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-03 03:25:51 | INFO | train_inner | epoch 002:    629 / 1474 loss=4.981, trans_loss=6.083, nll_loss=5.066, w2v_ctc_loss=2.968, task_loss=1.031, task_loss_gen=4.07, contrastive_loss=0, total=4116.05, n_correct=17.55, ppl=33.5, accuracy=0.426, wps=10563.2, ups=0.86, wpb=12285, bsz=443.4, num_updates=2100, lr=8.4058e-05, gnorm=1.03, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1397
2023-09-03 03:26:48 | INFO | train_inner | epoch 002:    729 / 1474 loss=5.005, trans_loss=6.159, nll_loss=5.157, w2v_ctc_loss=2.93, task_loss=0.811, task_loss_gen=4.262, contrastive_loss=0, total=4152.4, n_correct=44.04, ppl=35.69, accuracy=1.061, wps=21677.4, ups=1.75, wpb=12393.8, bsz=463.6, num_updates=2200, lr=8.8056e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=56, gb_free=18.8, wall=1454
2023-09-03 03:27:46 | INFO | train_inner | epoch 002:    829 / 1474 loss=4.923, trans_loss=6.071, nll_loss=5.06, w2v_ctc_loss=2.894, task_loss=0.735, task_loss_gen=4.573, contrastive_loss=0, total=4168.87, n_correct=12.45, ppl=33.36, accuracy=0.299, wps=21705.9, ups=1.74, wpb=12453.5, bsz=461.2, num_updates=2300, lr=9.2054e-05, gnorm=0.842, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1512
2023-09-03 03:28:43 | INFO | train_inner | epoch 002:    929 / 1474 loss=4.926, trans_loss=6.135, nll_loss=5.132, w2v_ctc_loss=2.831, task_loss=0.543, task_loss_gen=5.248, contrastive_loss=0, total=4104.79, n_correct=35.42, ppl=35.07, accuracy=0.863, wps=21321.7, ups=1.74, wpb=12254.8, bsz=445.6, num_updates=2400, lr=9.6052e-05, gnorm=0.854, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1569
2023-09-03 03:29:42 | INFO | train_inner | epoch 002:   1029 / 1474 loss=4.895, trans_loss=6.125, nll_loss=5.124, w2v_ctc_loss=2.791, task_loss=0.377, task_loss_gen=5.604, contrastive_loss=0, total=4100.85, n_correct=9.18, ppl=34.88, accuracy=0.224, wps=20937.1, ups=1.71, wpb=12245.2, bsz=455.2, num_updates=2500, lr=0.00010005, gnorm=0.795, clip=0, loss_scale=16, train_wall=58, gb_free=19.2, wall=1628
2023-09-03 03:30:40 | INFO | train_inner | epoch 002:   1129 / 1474 loss=4.825, trans_loss=6.093, nll_loss=5.082, w2v_ctc_loss=2.726, task_loss=0.257, task_loss_gen=5.642, contrastive_loss=0, total=4195.47, n_correct=5.57, ppl=33.87, accuracy=0.133, wps=21574.6, ups=1.72, wpb=12522.7, bsz=489.6, num_updates=2600, lr=0.000104048, gnorm=0.741, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1686
2023-09-03 03:31:38 | INFO | train_inner | epoch 002:   1229 / 1474 loss=4.85, trans_loss=6.149, nll_loss=5.154, w2v_ctc_loss=2.706, task_loss=0.205, task_loss_gen=6.051, contrastive_loss=0, total=4220.45, n_correct=11.43, ppl=35.61, accuracy=0.271, wps=21726.8, ups=1.73, wpb=12591.7, bsz=492, num_updates=2700, lr=0.000108046, gnorm=0.68, clip=0, loss_scale=16, train_wall=57, gb_free=19.6, wall=1744
2023-09-03 03:32:36 | INFO | train_inner | epoch 002:   1329 / 1474 loss=4.812, trans_loss=6.108, nll_loss=5.088, w2v_ctc_loss=2.681, task_loss=0.12, task_loss_gen=7.5, contrastive_loss=0, total=4159.97, n_correct=17.9, ppl=34.02, accuracy=0.43, wps=21560.4, ups=1.73, wpb=12433.6, bsz=462.1, num_updates=2800, lr=0.000112044, gnorm=0.643, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1801
2023-09-03 03:33:33 | INFO | train_inner | epoch 002:   1429 / 1474 loss=4.855, trans_loss=6.194, nll_loss=5.211, w2v_ctc_loss=2.66, task_loss=0.11, task_loss_gen=8.785, contrastive_loss=0, total=4050.6, n_correct=4, ppl=37.04, accuracy=0.099, wps=21023, ups=1.74, wpb=12095, bsz=438.3, num_updates=2900, lr=0.000116042, gnorm=0.74, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1859
2023-09-03 03:33:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.6875, -0.5444, -0.0189,  0.0665, -0.1411], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 6.0425e-03,  7.8659e-03,  9.1934e-03,  ...,  3.2902e-04,
         -1.9970e-03, -4.7646e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 7.5302e-03,  1.2314e-02,  1.0216e-02,  ..., -1.1311e-03,
         -8.5473e-05, -1.0929e-03]], device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.6875, -0.5444, -0.0189,  0.0665, -0.1411], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.6206, -0.4492, -0.0190,  0.0729, -0.1476], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.9569e-03,  4.0970e-03, -3.8683e-05,  ..., -2.8419e-03,
          4.2868e-04,  2.0142e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.0605e-03, -1.5335e-03, -4.8904e-03,  ..., -1.1740e-03,
         -3.2020e-04,  2.5320e-04]], device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.6206, -0.4492, -0.0190,  0.0729, -0.1476], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.9482, -1.3789, -0.0590,  0.4365, -0.4060], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0024, -0.0115,  0.0194,  ..., -0.0147,  0.0002,  0.0116],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0438, -0.1189, -0.0878,  ...,  0.0016, -0.0067,  0.0043]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.9482, -1.3789, -0.0590,  0.4365, -0.4060], device='cuda:4',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.9883, -0.6914, -0.0324,  0.1602, -0.2102], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 9.1124e-04,  1.3962e-02,  9.0561e-03,  ..., -3.1796e-03,
         -3.1300e-03, -5.6982e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.7519e-03, -2.1927e-02, -2.4231e-02,  ..., -5.9929e-03,
         -6.2790e-03, -2.0599e-03]], device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.9883, -0.6914, -0.0324,  0.1602, -0.2102], device='cuda:2',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.5801, -1.0723, -0.0433,  0.3413, -0.3394], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0136,  0.0123, -0.0041,  ..., -0.0068,  0.0033,  0.0055],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0206,  0.0486,  0.1506,  ..., -0.0024, -0.0092,  0.0143]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.5801, -1.0723, -0.0433,  0.3413, -0.3394], device='cuda:5',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.9980, -1.9160, -0.0807,  0.7441, -0.6826], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0268, -0.0073, -0.0418,  ..., -0.0179, -0.0006,  0.0025],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0101, -0.0590, -0.0090,  ..., -0.0130,  0.0029,  0.0011]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.9980, -1.9160, -0.0807,  0.7441, -0.6826], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.7363, -0.5879, -0.0289,  0.0973, -0.1763], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0020, -0.0071, -0.0097,  ..., -0.0018, -0.0016, -0.0018],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0042, -0.0170, -0.0176,  ...,  0.0025, -0.0022, -0.0023]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.7363, -0.5879, -0.0289,  0.0973, -0.1763], device='cuda:3',
       dtype=torch.float16)
--------------------
2023-09-03 03:34:46 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.486 | trans_loss 14.005 | nll_loss 13.935 | w2v_ctc_loss 3.392 | task_loss 0.6 | task_loss_gen 39.838 | contrastive_loss 0 | total 4003.4 | n_correct 0.1 | ppl 15661.5 | accuracy 0.002 | uer 48.515 | wer 47.317 | raw_wer 47.317 | bleu 0 | wps 1038.8 | wpb 4003.4 | bsz 141.8 | num_updates 2945 | best_bleu 0
2023-09-03 03:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2945 updates
2023-09-03 03:34:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2945 updates, score 0.0) (writing took 13.385857682034839 seconds)
2023-09-03 03:34:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-03 03:34:59 | INFO | train | epoch 002 | loss 4.982 | trans_loss 6.117 | nll_loss 5.11 | w2v_ctc_loss 2.936 | task_loss 0.815 | task_loss_gen 5.048 | contrastive_loss 0 | total 4138.65 | n_correct 14.5963 | ppl 34.54 | accuracy 0.353 | wps 18621.1 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 2945 | lr 0.000117841 | gnorm 0.891 | clip 0 | loss_scale 16 | train_wall 841 | gb_free 19 | wall 1945
2023-09-03 03:35:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 03:35:00 | INFO | fairseq.trainer | begin training epoch 3
2023-09-03 03:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 03:35:39 | INFO | train_inner | epoch 003:     55 / 1474 loss=4.754, trans_loss=6.085, nll_loss=5.069, w2v_ctc_loss=2.611, task_loss=0.066, task_loss_gen=9.32, contrastive_loss=0, total=4066.57, n_correct=4.9, ppl=33.56, accuracy=0.12, wps=9627.9, ups=0.79, wpb=12139.2, bsz=441.1, num_updates=3000, lr=0.00012004, gnorm=0.664, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1985
2023-09-03 03:35:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 03:36:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-03 03:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-03 03:36:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-03 03:36:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-03 03:37:08 | INFO | train_inner | epoch 003:    160 / 1474 loss=3.845, trans_loss=4.931, nll_loss=3.577, w2v_ctc_loss=2.433, task_loss=1.275, task_loss_gen=5.39, contrastive_loss=0, total=4138.69, n_correct=555.36, ppl=11.93, accuracy=13.419, wps=13941, ups=1.13, wpb=12359, bsz=456.2, num_updates=3100, lr=0.000124038, gnorm=4.906, clip=9, loss_scale=0.5, train_wall=88, gb_free=16.8, wall=2074
2023-09-03 03:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-03 03:38:35 | INFO | train_inner | epoch 003:    261 / 1474 loss=3.453, trans_loss=4.431, nll_loss=2.906, w2v_ctc_loss=2.421, task_loss=1.126, task_loss_gen=3.34, contrastive_loss=0, total=4160.41, n_correct=1081.81, ppl=7.5, accuracy=26.002, wps=14270.9, ups=1.15, wpb=12429.2, bsz=468.1, num_updates=3200, lr=0.000128036, gnorm=8.054, clip=19, loss_scale=0.25, train_wall=86, gb_free=13.2, wall=2161
2023-09-03 03:38:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-03 03:40:01 | INFO | train_inner | epoch 003:    362 / 1474 loss=3.406, trans_loss=4.535, nll_loss=3.031, w2v_ctc_loss=2.363, task_loss=1.078, task_loss_gen=2.882, contrastive_loss=0, total=4174.19, n_correct=1103.63, ppl=8.18, accuracy=26.439, wps=14469.8, ups=1.16, wpb=12457.3, bsz=475, num_updates=3300, lr=0.000132034, gnorm=8.699, clip=19, loss_scale=0.125, train_wall=85, gb_free=16.2, wall=2247
2023-09-03 03:41:26 | INFO | train_inner | epoch 003:    462 / 1474 loss=3.409, trans_loss=4.631, nll_loss=3.146, w2v_ctc_loss=2.352, task_loss=1.081, task_loss_gen=2.913, contrastive_loss=0, total=4187.52, n_correct=1102.72, ppl=8.85, accuracy=26.333, wps=14684.2, ups=1.17, wpb=12498.8, bsz=463.6, num_updates=3400, lr=0.000136032, gnorm=12.389, clip=20, loss_scale=0.125, train_wall=84, gb_free=13.9, wall=2332
2023-09-03 03:42:51 | INFO | train_inner | epoch 003:    562 / 1474 loss=3.375, trans_loss=4.556, nll_loss=3.059, w2v_ctc_loss=2.359, task_loss=1.41, task_loss_gen=2.874, contrastive_loss=0, total=4083.21, n_correct=1128.78, ppl=8.33, accuracy=27.644, wps=14301.8, ups=1.17, wpb=12199, bsz=437.9, num_updates=3500, lr=0.00014003, gnorm=11.258, clip=30, loss_scale=0.125, train_wall=85, gb_free=15.5, wall=2417
2023-09-03 03:44:18 | INFO | train_inner | epoch 003:    662 / 1474 loss=3.306, trans_loss=4.602, nll_loss=3.113, w2v_ctc_loss=2.242, task_loss=1.318, task_loss_gen=2.428, contrastive_loss=0, total=4232.39, n_correct=1175.44, ppl=8.65, accuracy=27.772, wps=14534.8, ups=1.15, wpb=12618.9, bsz=487.6, num_updates=3600, lr=0.000144028, gnorm=9.092, clip=27, loss_scale=0.125, train_wall=86, gb_free=16.1, wall=2504
2023-09-03 03:45:43 | INFO | train_inner | epoch 003:    762 / 1474 loss=3.292, trans_loss=4.536, nll_loss=3.034, w2v_ctc_loss=2.275, task_loss=1.339, task_loss_gen=2.462, contrastive_loss=0, total=4155.31, n_correct=1193.55, ppl=8.19, accuracy=28.723, wps=14620.8, ups=1.18, wpb=12412.9, bsz=465.8, num_updates=3700, lr=0.000148026, gnorm=9.365, clip=24, loss_scale=0.125, train_wall=84, gb_free=16.1, wall=2589
2023-09-03 03:47:09 | INFO | train_inner | epoch 003:    862 / 1474 loss=3.262, trans_loss=4.493, nll_loss=2.982, w2v_ctc_loss=2.238, task_loss=1.336, task_loss_gen=2.527, contrastive_loss=0, total=4170.95, n_correct=1212.17, ppl=7.9, accuracy=29.062, wps=14593.6, ups=1.17, wpb=12453.7, bsz=458.1, num_updates=3800, lr=0.000152024, gnorm=9.277, clip=24, loss_scale=0.125, train_wall=85, gb_free=17.1, wall=2674
2023-09-03 03:48:34 | INFO | train_inner | epoch 003:    962 / 1474 loss=3.181, trans_loss=4.551, nll_loss=3.049, w2v_ctc_loss=2.164, task_loss=1.493, task_loss_gen=2.422, contrastive_loss=0, total=4174.19, n_correct=1258.99, ppl=8.27, accuracy=30.161, wps=14611.2, ups=1.17, wpb=12449.2, bsz=475.7, num_updates=3900, lr=0.000156022, gnorm=9.17, clip=32, loss_scale=0.125, train_wall=85, gb_free=13.4, wall=2760
2023-09-03 03:49:59 | INFO | train_inner | epoch 003:   1062 / 1474 loss=3.345, trans_loss=4.557, nll_loss=3.065, w2v_ctc_loss=2.302, task_loss=1.745, task_loss_gen=2.73, contrastive_loss=0, total=4049.41, n_correct=1125.98, ppl=8.37, accuracy=27.806, wps=14202.1, ups=1.17, wpb=12096, bsz=436.3, num_updates=4000, lr=0.00016002, gnorm=11.911, clip=50, loss_scale=0.125, train_wall=85, gb_free=16.1, wall=2845
2023-09-03 03:49:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 03:50:34 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.974 | trans_loss 7.662 | nll_loss 5.66 | w2v_ctc_loss 2.646 | task_loss 6.413 | task_loss_gen 9.428 | contrastive_loss 0 | total 4003.4 | n_correct 1251.1 | ppl 50.56 | accuracy 31.251 | uer 38.545 | wer 37.888 | raw_wer 37.888 | bleu 0.11 | wps 1453.2 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 0.11
2023-09-03 03:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-09-03 03:50:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-03 03:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-03 03:50:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.11) (writing took 14.600833375006914 seconds)
2023-09-03 03:52:14 | INFO | train_inner | epoch 003:   1162 / 1474 loss=3.252, trans_loss=4.507, nll_loss=2.998, w2v_ctc_loss=2.204, task_loss=1.704, task_loss_gen=2.658, contrastive_loss=0, total=4044.1, n_correct=1165.09, ppl=7.99, accuracy=28.81, wps=8955.6, ups=0.74, wpb=12070.2, bsz=433.6, num_updates=4100, lr=0.000164018, gnorm=10.623, clip=45, loss_scale=0.125, train_wall=84, gb_free=15.2, wall=2980
2023-09-03 03:53:38 | INFO | train_inner | epoch 003:   1262 / 1474 loss=3.133, trans_loss=4.405, nll_loss=2.87, w2v_ctc_loss=2.117, task_loss=1.742, task_loss_gen=2.551, contrastive_loss=0, total=4065.1, n_correct=1248.46, ppl=7.31, accuracy=30.712, wps=14353.8, ups=1.18, wpb=12140.5, bsz=432.3, num_updates=4200, lr=0.000168016, gnorm=9.317, clip=42, loss_scale=0.125, train_wall=84, gb_free=16.9, wall=3064
2023-09-03 03:55:04 | INFO | train_inner | epoch 003:   1362 / 1474 loss=3.106, trans_loss=4.387, nll_loss=2.843, w2v_ctc_loss=2.073, task_loss=1.491, task_loss_gen=2.43, contrastive_loss=0, total=4132.35, n_correct=1277.07, ppl=7.17, accuracy=30.904, wps=14445.5, ups=1.17, wpb=12335.6, bsz=462.1, num_updates=4300, lr=0.000172014, gnorm=8.762, clip=32, loss_scale=0.125, train_wall=85, gb_free=17.3, wall=3150
2023-09-03 03:56:29 | INFO | train_inner | epoch 003:   1462 / 1474 loss=3.093, trans_loss=4.382, nll_loss=2.839, w2v_ctc_loss=2.076, task_loss=1.727, task_loss_gen=2.299, contrastive_loss=0, total=4206.88, n_correct=1319.99, ppl=7.16, accuracy=31.377, wps=14752.1, ups=1.17, wpb=12566, bsz=476, num_updates=4400, lr=0.000176012, gnorm=9.808, clip=37, loss_scale=0.125, train_wall=84, gb_free=14.7, wall=3235
2023-09-03 03:56:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 03:57:18 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 6.022 | trans_loss 7.757 | nll_loss 5.811 | w2v_ctc_loss 2.595 | task_loss 14.827 | task_loss_gen 9.634 | contrastive_loss 0 | total 4003.4 | n_correct 1222.4 | ppl 56.16 | accuracy 30.534 | uer 38.34 | wer 38.008 | raw_wer 38.008 | bleu 0.15 | wps 1275.4 | wpb 4003.4 | bsz 141.8 | num_updates 4412 | best_bleu 0.15
2023-09-03 03:57:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4412 updates
2023-09-03 03:57:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 03:57:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4412 updates, score 0.15) (writing took 14.38170142902527 seconds)
2023-09-03 03:57:32 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-03 03:57:32 | INFO | train | epoch 003 | loss 3.371 | trans_loss 4.594 | nll_loss 3.113 | w2v_ctc_loss 2.27 | task_loss 1.366 | task_loss_gen 3.092 | contrastive_loss 0 | total 4138.71 | n_correct 1096.75 | ppl 8.65 | accuracy 26.5 | wps 13399.7 | ups 1.08 | wpb 12356.1 | bsz 458.6 | num_updates 4412 | lr 0.000176492 | gnorm 9.249 | clip 28.4 | loss_scale 0.125 | train_wall 1233 | gb_free 16 | wall 3298
2023-09-03 03:57:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 03:57:32 | INFO | fairseq.trainer | begin training epoch 4
2023-09-03 03:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 03:58:54 | INFO | train_inner | epoch 004:     88 / 1474 loss=3.141, trans_loss=4.354, nll_loss=2.803, w2v_ctc_loss=2.136, task_loss=1.867, task_loss_gen=2.523, contrastive_loss=0, total=4082.27, n_correct=1275.52, ppl=6.98, accuracy=31.245, wps=8418.2, ups=0.69, wpb=12182.1, bsz=434.2, num_updates=4500, lr=0.00018001, gnorm=11.297, clip=42, loss_scale=0.125, train_wall=84, gb_free=17.5, wall=3379
2023-09-03 04:00:19 | INFO | train_inner | epoch 004:    188 / 1474 loss=3.138, trans_loss=4.325, nll_loss=2.769, w2v_ctc_loss=2.124, task_loss=1.635, task_loss_gen=2.269, contrastive_loss=0, total=4184.92, n_correct=1294.56, ppl=6.82, accuracy=30.934, wps=14616.8, ups=1.17, wpb=12496.9, bsz=470.3, num_updates=4600, lr=0.000184008, gnorm=9.872, clip=34, loss_scale=0.125, train_wall=85, gb_free=12.8, wall=3465
2023-09-03 04:01:44 | INFO | train_inner | epoch 004:    288 / 1474 loss=3.119, trans_loss=4.349, nll_loss=2.802, w2v_ctc_loss=2.089, task_loss=1.68, task_loss_gen=2.366, contrastive_loss=0, total=4150, n_correct=1274, ppl=6.97, accuracy=30.699, wps=14617.3, ups=1.18, wpb=12397.9, bsz=465.2, num_updates=4700, lr=0.000188006, gnorm=8.602, clip=28, loss_scale=0.125, train_wall=84, gb_free=16.6, wall=3550
2023-09-03 04:03:08 | INFO | train_inner | epoch 004:    388 / 1474 loss=3.064, trans_loss=4.335, nll_loss=2.777, w2v_ctc_loss=2.034, task_loss=1.74, task_loss_gen=2.476, contrastive_loss=0, total=4114.32, n_correct=1300.12, ppl=6.85, accuracy=31.6, wps=14543.2, ups=1.18, wpb=12277.1, bsz=440, num_updates=4800, lr=0.000192004, gnorm=9.51, clip=24, loss_scale=0.125, train_wall=84, gb_free=11.6, wall=3634
2023-09-03 04:04:33 | INFO | train_inner | epoch 004:    488 / 1474 loss=3.062, trans_loss=4.301, nll_loss=2.736, w2v_ctc_loss=2.051, task_loss=1.718, task_loss_gen=2.147, contrastive_loss=0, total=4239.74, n_correct=1356.81, ppl=6.66, accuracy=32.002, wps=14872.1, ups=1.18, wpb=12652.2, bsz=506.4, num_updates=4900, lr=0.000196002, gnorm=9.779, clip=40, loss_scale=0.125, train_wall=84, gb_free=16.6, wall=3719
2023-09-03 04:05:58 | INFO | train_inner | epoch 004:    588 / 1474 loss=3.092, trans_loss=4.269, nll_loss=2.696, w2v_ctc_loss=2.091, task_loss=1.655, task_loss_gen=2.264, contrastive_loss=0, total=4219.26, n_correct=1347.47, ppl=6.48, accuracy=31.936, wps=14843.8, ups=1.18, wpb=12596.5, bsz=483.8, num_updates=5000, lr=0.0002, gnorm=9.141, clip=31, loss_scale=0.125, train_wall=84, gb_free=15.9, wall=3804
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:0')
2023-09-03 04:07:26 | INFO | train_inner | epoch 004:    688 / 1474 loss=3.191, trans_loss=4.287, nll_loss=2.717, w2v_ctc_loss=2.225, task_loss=1.772, task_loss_gen=2.458, contrastive_loss=0, total=4171.93, n_correct=1324.18, ppl=6.58, accuracy=31.74, wps=14217.1, ups=1.14, wpb=12436.9, bsz=453.3, num_updates=5100, lr=0.00019803, gnorm=9.958, clip=27, loss_scale=0.125, train_wall=87, gb_free=15.3, wall=3892
2023-09-03 04:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2023-09-03 04:08:52 | INFO | train_inner | epoch 004:    789 / 1474 loss=3.345, trans_loss=4.278, nll_loss=2.711, w2v_ctc_loss=2.485, task_loss=1.871, task_loss_gen=3.008, contrastive_loss=0, total=4033.77, n_correct=1292.37, ppl=6.55, accuracy=32.039, wps=14050.3, ups=1.17, wpb=12045.1, bsz=424.3, num_updates=5200, lr=0.000196116, gnorm=20.417, clip=46, loss_scale=0.0625, train_wall=85, gb_free=14.3, wall=3977
2023-09-03 04:10:17 | INFO | train_inner | epoch 004:    889 / 1474 loss=3.461, trans_loss=4.379, nll_loss=2.836, w2v_ctc_loss=2.635, task_loss=1.814, task_loss_gen=2.487, contrastive_loss=0, total=4176.45, n_correct=1314.87, ppl=7.14, accuracy=31.483, wps=14622.1, ups=1.17, wpb=12471.1, bsz=464.3, num_updates=5300, lr=0.000194257, gnorm=26.835, clip=82, loss_scale=0.0625, train_wall=85, gb_free=15.9, wall=4063
2023-09-03 04:11:42 | INFO | train_inner | epoch 004:    989 / 1474 loss=3.46, trans_loss=4.343, nll_loss=2.791, w2v_ctc_loss=2.645, task_loss=1.88, task_loss_gen=2.515, contrastive_loss=0, total=4128.13, n_correct=1308.89, ppl=6.92, accuracy=31.707, wps=14402.9, ups=1.17, wpb=12330.8, bsz=455.9, num_updates=5400, lr=0.00019245, gnorm=27.53, clip=77, loss_scale=0.0625, train_wall=85, gb_free=16.3, wall=4148
2023-09-03 04:13:08 | INFO | train_inner | epoch 004:   1089 / 1474 loss=3.337, trans_loss=4.289, nll_loss=2.722, w2v_ctc_loss=2.469, task_loss=1.872, task_loss_gen=2.52, contrastive_loss=0, total=4075.19, n_correct=1307.82, ppl=6.6, accuracy=32.092, wps=14276.6, ups=1.17, wpb=12164.7, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=15.134, clip=72, loss_scale=0.0625, train_wall=85, gb_free=14.9, wall=4233
2023-09-03 04:14:33 | INFO | train_inner | epoch 004:   1189 / 1474 loss=3.248, trans_loss=4.28, nll_loss=2.712, w2v_ctc_loss=2.34, task_loss=1.673, task_loss_gen=2.173, contrastive_loss=0, total=4170.09, n_correct=1342.21, ppl=6.55, accuracy=32.187, wps=14576.2, ups=1.17, wpb=12453, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=13.831, clip=72, loss_scale=0.0625, train_wall=85, gb_free=14.2, wall=4319
2023-09-03 04:15:58 | INFO | train_inner | epoch 004:   1289 / 1474 loss=3.235, trans_loss=4.303, nll_loss=2.743, w2v_ctc_loss=2.323, task_loss=1.678, task_loss_gen=2.298, contrastive_loss=0, total=4141.07, n_correct=1338.99, ppl=6.69, accuracy=32.334, wps=14618.1, ups=1.18, wpb=12367.3, bsz=468.9, num_updates=5700, lr=0.000187317, gnorm=15.463, clip=72, loss_scale=0.0625, train_wall=84, gb_free=14.1, wall=4403
2023-09-03 04:17:22 | INFO | train_inner | epoch 004:   1389 / 1474 loss=3.399, trans_loss=4.288, nll_loss=2.725, w2v_ctc_loss=2.536, task_loss=1.873, task_loss_gen=2.46, contrastive_loss=0, total=4098.08, n_correct=1286.44, ppl=6.61, accuracy=31.391, wps=14591, ups=1.19, wpb=12241.1, bsz=435.7, num_updates=5800, lr=0.000185695, gnorm=19.383, clip=73, loss_scale=0.0625, train_wall=83, gb_free=16, wall=4487
2023-09-03 04:18:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.6133, device='cuda:3')
2023-09-03 04:19:02 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 6.199 | trans_loss 7.898 | nll_loss 6.019 | w2v_ctc_loss 2.865 | task_loss 20.886 | task_loss_gen 12.029 | contrastive_loss 0 | total 4003.4 | n_correct 1091 | ppl 64.83 | accuracy 27.252 | uer 40.029 | wer 40.021 | raw_wer 40.021 | bleu 0.07 | wps 1961.6 | wpb 4003.4 | bsz 141.8 | num_updates 5885 | best_bleu 0.15
2023-09-03 04:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5885 updates
2023-09-03 04:19:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0701.pt
2023-09-03 04:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0701.pt
2023-09-03 04:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0701.pt (epoch 4 @ 5885 updates, score 0.07) (writing took 6.431297107017599 seconds)
2023-09-03 04:19:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-03 04:19:08 | INFO | train | epoch 004 | loss 3.244 | trans_loss 4.31 | nll_loss 2.749 | w2v_ctc_loss 2.313 | task_loss 1.765 | task_loss_gen 2.425 | contrastive_loss 0 | total 4138.87 | n_correct 1310.56 | ppl 6.72 | accuracy 31.665 | wps 14040.6 | ups 1.14 | wpb 12356.4 | bsz 458.6 | num_updates 5885 | lr 0.000184349 | gnorm 15.653 | clip 53.4 | loss_scale 0.0625 | train_wall 1243 | gb_free 14.5 | wall 4594
2023-09-03 04:19:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 04:19:09 | INFO | fairseq.trainer | begin training epoch 5
2023-09-03 04:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 04:19:29 | INFO | train_inner | epoch 005:     15 / 1474 loss=3.38, trans_loss=4.275, nll_loss=2.705, w2v_ctc_loss=2.515, task_loss=1.811, task_loss_gen=2.507, contrastive_loss=0, total=4068.63, n_correct=1276.27, ppl=6.52, accuracy=31.369, wps=9552.1, ups=0.79, wpb=12144.6, bsz=450.3, num_updates=5900, lr=0.000184115, gnorm=30.419, clip=86, loss_scale=0.0625, train_wall=83, gb_free=10.2, wall=4615
2023-09-03 04:20:53 | INFO | train_inner | epoch 005:    115 / 1474 loss=3.305, trans_loss=4.224, nll_loss=2.644, w2v_ctc_loss=2.442, task_loss=1.554, task_loss_gen=2.147, contrastive_loss=0, total=4235.83, n_correct=1384, ppl=6.25, accuracy=32.674, wps=14983.3, ups=1.18, wpb=12652.3, bsz=492.7, num_updates=6000, lr=0.000182574, gnorm=15.254, clip=68, loss_scale=0.0625, train_wall=84, gb_free=16.5, wall=4699
2023-09-03 04:20:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 04:21:32 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.928 | trans_loss 7.453 | nll_loss 5.407 | w2v_ctc_loss 2.964 | task_loss 16.091 | task_loss_gen 10.277 | contrastive_loss 0 | total 4003.4 | n_correct 1331.8 | ppl 42.42 | accuracy 33.267 | uer 40.785 | wer 40.96 | raw_wer 40.96 | bleu 0.12 | wps 1246 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 0.15
2023-09-03 04:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-09-03 04:21:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-03 04:21:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-03 04:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 0.12) (writing took 9.081103213946335 seconds)
2023-09-03 04:23:05 | INFO | train_inner | epoch 005:    215 / 1474 loss=3.321, trans_loss=4.246, nll_loss=2.669, w2v_ctc_loss=2.447, task_loss=1.536, task_loss_gen=2.281, contrastive_loss=0, total=4181.72, n_correct=1351.55, ppl=6.36, accuracy=32.32, wps=9451.3, ups=0.76, wpb=12476.3, bsz=482.6, num_updates=6100, lr=0.000181071, gnorm=15.641, clip=59, loss_scale=0.0625, train_wall=83, gb_free=16.1, wall=4831
2023-09-03 04:24:29 | INFO | train_inner | epoch 005:    315 / 1474 loss=3.355, trans_loss=4.224, nll_loss=2.647, w2v_ctc_loss=2.513, task_loss=1.693, task_loss_gen=2.407, contrastive_loss=0, total=4093.94, n_correct=1329.07, ppl=6.26, accuracy=32.464, wps=14555.4, ups=1.19, wpb=12240.6, bsz=447.1, num_updates=6200, lr=0.000179605, gnorm=13.744, clip=49, loss_scale=0.0625, train_wall=83, gb_free=15.7, wall=4915
2023-09-03 04:25:54 | INFO | train_inner | epoch 005:    415 / 1474 loss=3.217, trans_loss=4.192, nll_loss=2.604, w2v_ctc_loss=2.326, task_loss=1.617, task_loss_gen=2.294, contrastive_loss=0, total=4141.47, n_correct=1373.7, ppl=6.08, accuracy=33.169, wps=14550.7, ups=1.18, wpb=12376, bsz=466.7, num_updates=6300, lr=0.000178174, gnorm=9.079, clip=31, loss_scale=0.0625, train_wall=84, gb_free=15.4, wall=5000
2023-09-03 04:27:18 | INFO | train_inner | epoch 005:    515 / 1474 loss=3.327, trans_loss=4.234, nll_loss=2.657, w2v_ctc_loss=2.464, task_loss=1.974, task_loss_gen=2.654, contrastive_loss=0, total=4035.24, n_correct=1306.28, ppl=6.31, accuracy=32.372, wps=14364.6, ups=1.19, wpb=12054, bsz=428.9, num_updates=6400, lr=0.000176777, gnorm=25.58, clip=75, loss_scale=0.0625, train_wall=83, gb_free=16.3, wall=5084
2023-09-03 04:28:43 | INFO | train_inner | epoch 005:    615 / 1474 loss=3.33, trans_loss=4.238, nll_loss=2.657, w2v_ctc_loss=2.469, task_loss=1.847, task_loss_gen=2.396, contrastive_loss=0, total=4124.7, n_correct=1342.17, ppl=6.31, accuracy=32.54, wps=14535.8, ups=1.18, wpb=12303.6, bsz=445.9, num_updates=6500, lr=0.000175412, gnorm=15.301, clip=53, loss_scale=0.0625, train_wall=84, gb_free=16.8, wall=5169
2023-09-03 04:30:08 | INFO | train_inner | epoch 005:    715 / 1474 loss=3.297, trans_loss=4.209, nll_loss=2.624, w2v_ctc_loss=2.437, task_loss=1.819, task_loss_gen=2.27, contrastive_loss=0, total=4142.64, n_correct=1365.44, ppl=6.17, accuracy=32.961, wps=14562.5, ups=1.18, wpb=12365, bsz=472.2, num_updates=6600, lr=0.000174078, gnorm=18.859, clip=65, loss_scale=0.0625, train_wall=84, gb_free=16.6, wall=5254
2023-09-03 04:31:34 | INFO | train_inner | epoch 005:    815 / 1474 loss=3.268, trans_loss=4.185, nll_loss=2.593, w2v_ctc_loss=2.405, task_loss=1.749, task_loss_gen=2.419, contrastive_loss=0, total=4131.47, n_correct=1378.62, ppl=6.03, accuracy=33.369, wps=14397.5, ups=1.17, wpb=12335.6, bsz=455.4, num_updates=6700, lr=0.000172774, gnorm=23.912, clip=41, loss_scale=0.0625, train_wall=85, gb_free=17.3, wall=5339
2023-09-03 04:32:58 | INFO | train_inner | epoch 005:    915 / 1474 loss=3.241, trans_loss=4.183, nll_loss=2.592, w2v_ctc_loss=2.359, task_loss=1.855, task_loss_gen=2.373, contrastive_loss=0, total=4109.79, n_correct=1363.81, ppl=6.03, accuracy=33.184, wps=14532.9, ups=1.18, wpb=12270.6, bsz=446, num_updates=6800, lr=0.000171499, gnorm=16.01, clip=43, loss_scale=0.0625, train_wall=84, gb_free=16.3, wall=5424
2023-09-03 04:34:22 | INFO | train_inner | epoch 005:   1015 / 1474 loss=3.276, trans_loss=4.199, nll_loss=2.612, w2v_ctc_loss=2.403, task_loss=1.912, task_loss_gen=2.279, contrastive_loss=0, total=4169.45, n_correct=1370.7, ppl=6.11, accuracy=32.875, wps=14811, ups=1.19, wpb=12445, bsz=463.3, num_updates=6900, lr=0.000170251, gnorm=17.353, clip=67, loss_scale=0.0625, train_wall=83, gb_free=12.1, wall=5508
2023-09-03 04:35:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
2023-09-03 04:35:49 | INFO | train_inner | epoch 005:   1116 / 1474 loss=3.262, trans_loss=4.177, nll_loss=2.582, w2v_ctc_loss=2.398, task_loss=1.833, task_loss_gen=2.287, contrastive_loss=0, total=4172.5, n_correct=1390.02, ppl=5.99, accuracy=33.314, wps=14357.7, ups=1.15, wpb=12447.2, bsz=465.5, num_updates=7000, lr=0.000169031, gnorm=13.336, clip=40, loss_scale=0.0312, train_wall=86, gb_free=16.1, wall=5594
2023-09-03 04:37:14 | INFO | train_inner | epoch 005:   1216 / 1474 loss=3.48, trans_loss=4.206, nll_loss=2.619, w2v_ctc_loss=2.705, task_loss=1.719, task_loss_gen=2.365, contrastive_loss=0, total=4158.38, n_correct=1354.6, ppl=6.14, accuracy=32.575, wps=14577.8, ups=1.18, wpb=12402.6, bsz=453.3, num_updates=7100, lr=0.000167836, gnorm=31.097, clip=77, loss_scale=0.0312, train_wall=84, gb_free=15.5, wall=5680
2023-09-03 04:38:40 | INFO | train_inner | epoch 005:   1316 / 1474 loss=3.389, trans_loss=4.202, nll_loss=2.615, w2v_ctc_loss=2.566, task_loss=1.764, task_loss_gen=2.331, contrastive_loss=0, total=4133.01, n_correct=1350.74, ppl=6.13, accuracy=32.682, wps=14364.3, ups=1.16, wpb=12337.1, bsz=445.7, num_updates=7200, lr=0.000166667, gnorm=19.41, clip=72, loss_scale=0.0312, train_wall=85, gb_free=14.7, wall=5765
2023-09-03 04:40:04 | INFO | train_inner | epoch 005:   1416 / 1474 loss=3.355, trans_loss=4.187, nll_loss=2.599, w2v_ctc_loss=2.529, task_loss=1.871, task_loss_gen=2.284, contrastive_loss=0, total=4133.51, n_correct=1365.97, ppl=6.06, accuracy=33.046, wps=14680.8, ups=1.19, wpb=12344.9, bsz=457.2, num_updates=7300, lr=0.000165521, gnorm=27.659, clip=72, loss_scale=0.0312, train_wall=83, gb_free=15.4, wall=5850
2023-09-03 04:40:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 04:41:27 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.784 | trans_loss 7.366 | nll_loss 5.297 | w2v_ctc_loss 2.681 | task_loss 6.807 | task_loss_gen 8.683 | contrastive_loss 0 | total 4003.4 | n_correct 1363.4 | ppl 39.31 | accuracy 34.056 | uer 40.148 | wer 40.565 | raw_wer 40.565 | bleu 0.2 | wps 1532.2 | wpb 4003.4 | bsz 141.8 | num_updates 7358 | best_bleu 0.2
2023-09-03 04:41:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7358 updates
2023-09-03 04:41:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 04:41:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 04:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7358 updates, score 0.2) (writing took 12.250596302968916 seconds)
2023-09-03 04:41:40 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-03 04:41:40 | INFO | train | epoch 005 | loss 3.314 | trans_loss 4.206 | nll_loss 2.621 | w2v_ctc_loss 2.459 | task_loss 1.766 | task_loss_gen 2.339 | contrastive_loss 0 | total 4138.65 | n_correct 1359.21 | ppl 6.15 | accuracy 32.842 | wps 13469 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 7358 | lr 0.000164868 | gnorm 18.845 | clip 58.6 | loss_scale 0.0312 | train_wall 1238 | gb_free 15.9 | wall 5945
2023-09-03 04:41:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 04:41:40 | INFO | fairseq.trainer | begin training epoch 6
2023-09-03 04:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 04:42:22 | INFO | train_inner | epoch 006:     42 / 1474 loss=3.285, trans_loss=4.162, nll_loss=2.564, w2v_ctc_loss=2.437, task_loss=1.851, task_loss_gen=2.356, contrastive_loss=0, total=4117.69, n_correct=1375.98, ppl=5.91, accuracy=33.416, wps=8867.4, ups=0.72, wpb=12286.9, bsz=446.6, num_updates=7400, lr=0.000164399, gnorm=16.681, clip=67, loss_scale=0.0312, train_wall=84, gb_free=16.4, wall=5988
2023-09-03 04:43:47 | INFO | train_inner | epoch 006:    142 / 1474 loss=3.262, trans_loss=4.14, nll_loss=2.538, w2v_ctc_loss=2.414, task_loss=1.691, task_loss_gen=2.483, contrastive_loss=0, total=4162.89, n_correct=1406.47, ppl=5.81, accuracy=33.786, wps=14654.9, ups=1.18, wpb=12435.5, bsz=456.6, num_updates=7500, lr=0.000163299, gnorm=25.047, clip=60, loss_scale=0.0312, train_wall=84, gb_free=9.9, wall=6073
2023-09-03 04:45:12 | INFO | train_inner | epoch 006:    242 / 1474 loss=3.473, trans_loss=4.146, nll_loss=2.546, w2v_ctc_loss=2.741, task_loss=1.838, task_loss_gen=2.444, contrastive_loss=0, total=4127, n_correct=1392.54, ppl=5.84, accuracy=33.742, wps=14562, ups=1.18, wpb=12325.9, bsz=451, num_updates=7600, lr=0.000162221, gnorm=42.653, clip=68, loss_scale=0.0312, train_wall=84, gb_free=16.6, wall=6158
2023-09-03 04:46:39 | INFO | train_inner | epoch 006:    342 / 1474 loss=3.365, trans_loss=4.142, nll_loss=2.54, w2v_ctc_loss=2.574, task_loss=1.744, task_loss_gen=2.249, contrastive_loss=0, total=4151.56, n_correct=1397.31, ppl=5.81, accuracy=33.657, wps=14283, ups=1.15, wpb=12396.9, bsz=479.6, num_updates=7700, lr=0.000161165, gnorm=35.068, clip=71, loss_scale=0.0312, train_wall=86, gb_free=16.2, wall=6244
2023-09-03 04:48:03 | INFO | train_inner | epoch 006:    442 / 1474 loss=3.448, trans_loss=4.159, nll_loss=2.562, w2v_ctc_loss=2.681, task_loss=1.741, task_loss_gen=2.188, contrastive_loss=0, total=4163.13, n_correct=1390.22, ppl=5.91, accuracy=33.394, wps=14787.8, ups=1.19, wpb=12431, bsz=469.5, num_updates=7800, lr=0.000160128, gnorm=19.071, clip=68, loss_scale=0.0312, train_wall=83, gb_free=16.5, wall=6328
2023-09-03 04:49:27 | INFO | train_inner | epoch 006:    542 / 1474 loss=3.438, trans_loss=4.155, nll_loss=2.556, w2v_ctc_loss=2.669, task_loss=1.818, task_loss_gen=2.281, contrastive_loss=0, total=4157.56, n_correct=1402.45, ppl=5.88, accuracy=33.733, wps=14745.4, ups=1.19, wpb=12410.3, bsz=453.4, num_updates=7900, lr=0.000159111, gnorm=30.459, clip=73, loss_scale=0.0312, train_wall=84, gb_free=12.2, wall=6413
2023-09-03 04:50:51 | INFO | train_inner | epoch 006:    642 / 1474 loss=3.375, trans_loss=4.166, nll_loss=2.572, w2v_ctc_loss=2.568, task_loss=1.744, task_loss_gen=2.115, contrastive_loss=0, total=4156.54, n_correct=1388.7, ppl=5.94, accuracy=33.41, wps=14737, ups=1.19, wpb=12409.1, bsz=473.4, num_updates=8000, lr=0.000158114, gnorm=23.11, clip=77, loss_scale=0.0312, train_wall=83, gb_free=12.9, wall=6497
2023-09-03 04:50:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 04:51:21 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.791 | trans_loss 7.328 | nll_loss 5.246 | w2v_ctc_loss 2.789 | task_loss 6.644 | task_loss_gen 8.528 | contrastive_loss 0 | total 4003.4 | n_correct 1382.5 | ppl 37.94 | accuracy 34.533 | uer 42.067 | wer 41.986 | raw_wer 41.986 | bleu 0.22 | wps 1909.7 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 0.22
2023-09-03 04:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-09-03 04:51:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-03 04:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-03 04:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 0.22) (writing took 12.695136455993634 seconds)
2023-09-03 04:52:58 | INFO | train_inner | epoch 006:    742 / 1474 loss=3.345, trans_loss=4.161, nll_loss=2.563, w2v_ctc_loss=2.53, task_loss=1.899, task_loss_gen=2.292, contrastive_loss=0, total=4144.04, n_correct=1390.21, ppl=5.91, accuracy=33.547, wps=9721.8, ups=0.79, wpb=12371, bsz=455.4, num_updates=8100, lr=0.000157135, gnorm=20.012, clip=73, loss_scale=0.0312, train_wall=84, gb_free=15.9, wall=6624
2023-09-03 04:54:24 | INFO | train_inner | epoch 006:    842 / 1474 loss=3.301, trans_loss=4.181, nll_loss=2.59, w2v_ctc_loss=2.44, task_loss=1.906, task_loss_gen=2.345, contrastive_loss=0, total=4128.68, n_correct=1366.87, ppl=6.02, accuracy=33.107, wps=14395.1, ups=1.17, wpb=12323.5, bsz=444.8, num_updates=8200, lr=0.000156174, gnorm=14.428, clip=53, loss_scale=0.0312, train_wall=85, gb_free=16.9, wall=6710
2023-09-03 04:55:49 | INFO | train_inner | epoch 006:    942 / 1474 loss=3.292, trans_loss=4.173, nll_loss=2.58, w2v_ctc_loss=2.427, task_loss=1.92, task_loss_gen=2.446, contrastive_loss=0, total=4056.99, n_correct=1347.29, ppl=5.98, accuracy=33.209, wps=14304.2, ups=1.18, wpb=12112.2, bsz=434.5, num_updates=8300, lr=0.00015523, gnorm=16.2, clip=59, loss_scale=0.0312, train_wall=84, gb_free=16.9, wall=6794
2023-09-03 04:57:13 | INFO | train_inner | epoch 006:   1042 / 1474 loss=3.331, trans_loss=4.167, nll_loss=2.571, w2v_ctc_loss=2.488, task_loss=1.717, task_loss_gen=2.083, contrastive_loss=0, total=4190.44, n_correct=1389.7, ppl=5.94, accuracy=33.164, wps=14872.8, ups=1.19, wpb=12505, bsz=481.7, num_updates=8400, lr=0.000154303, gnorm=13.923, clip=55, loss_scale=0.0312, train_wall=83, gb_free=12.3, wall=6878
2023-09-03 04:58:37 | INFO | train_inner | epoch 006:   1142 / 1474 loss=3.338, trans_loss=4.158, nll_loss=2.561, w2v_ctc_loss=2.501, task_loss=1.83, task_loss_gen=2.465, contrastive_loss=0, total=4067.19, n_correct=1352.34, ppl=5.9, accuracy=33.25, wps=14387, ups=1.19, wpb=12142.6, bsz=434.8, num_updates=8500, lr=0.000153393, gnorm=14.752, clip=48, loss_scale=0.0312, train_wall=84, gb_free=16.5, wall=6963
2023-09-03 05:00:02 | INFO | train_inner | epoch 006:   1242 / 1474 loss=3.264, trans_loss=4.137, nll_loss=2.536, w2v_ctc_loss=2.411, task_loss=1.685, task_loss_gen=2.283, contrastive_loss=0, total=4130.01, n_correct=1397.41, ppl=5.8, accuracy=33.836, wps=14527.7, ups=1.18, wpb=12336.7, bsz=462.5, num_updates=8600, lr=0.000152499, gnorm=13.234, clip=40, loss_scale=0.0312, train_wall=84, gb_free=16.2, wall=7048
2023-09-03 05:01:26 | INFO | train_inner | epoch 006:   1342 / 1474 loss=3.375, trans_loss=4.149, nll_loss=2.547, w2v_ctc_loss=2.574, task_loss=1.607, task_loss_gen=2.248, contrastive_loss=0, total=4130.33, n_correct=1390.35, ppl=5.84, accuracy=33.662, wps=14613.1, ups=1.19, wpb=12323.4, bsz=456.7, num_updates=8700, lr=0.00015162, gnorm=20.429, clip=50, loss_scale=0.0312, train_wall=84, gb_free=17.2, wall=7132
2023-09-03 05:02:52 | INFO | train_inner | epoch 006:   1442 / 1474 loss=3.406, trans_loss=4.132, nll_loss=2.528, w2v_ctc_loss=2.636, task_loss=2.147, task_loss_gen=2.39, contrastive_loss=0, total=4200.52, n_correct=1430.51, ppl=5.77, accuracy=34.056, wps=14682.5, ups=1.17, wpb=12538.8, bsz=465.2, num_updates=8800, lr=0.000150756, gnorm=28.643, clip=77, loss_scale=0.0312, train_wall=85, gb_free=15.7, wall=7218
2023-09-03 05:03:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 05:04:01 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.909 | trans_loss 7.355 | nll_loss 5.284 | w2v_ctc_loss 3.12 | task_loss 12.449 | task_loss_gen 9.5 | contrastive_loss 0 | total 4003.4 | n_correct 1347.9 | ppl 38.95 | accuracy 33.669 | uer 45.353 | wer 45.483 | raw_wer 45.483 | bleu 0.06 | wps 1120.4 | wpb 4003.4 | bsz 141.8 | num_updates 8832 | best_bleu 0.22
2023-09-03 05:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8832 updates
2023-09-03 05:04:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0603.pt
2023-09-03 05:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0603.pt
2023-09-03 05:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.0603.pt (epoch 6 @ 8832 updates, score 0.06) (writing took 7.097640444000717 seconds)
2023-09-03 05:04:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-03 05:04:08 | INFO | train | epoch 006 | loss 3.359 | trans_loss 4.154 | nll_loss 2.556 | w2v_ctc_loss 2.549 | task_loss 1.802 | task_loss_gen 2.305 | contrastive_loss 0 | total 4138.65 | n_correct 1388.21 | ppl 5.88 | accuracy 33.543 | wps 13508.9 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 8832 | lr 0.000150482 | gnorm 22.639 | clip 63.3 | loss_scale 0.0312 | train_wall 1238 | gb_free 14.8 | wall 7294
2023-09-03 05:04:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 05:04:08 | INFO | fairseq.trainer | begin training epoch 7
2023-09-03 05:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 05:05:13 | INFO | train_inner | epoch 007:     68 / 1474 loss=3.413, trans_loss=4.137, nll_loss=2.534, w2v_ctc_loss=2.653, task_loss=1.788, task_loss_gen=2.301, contrastive_loss=0, total=4091.75, n_correct=1397.28, ppl=5.79, accuracy=34.149, wps=8622.4, ups=0.71, wpb=12213.6, bsz=456.9, num_updates=8900, lr=0.000149906, gnorm=24.21, clip=83, loss_scale=0.0312, train_wall=84, gb_free=17.1, wall=7359
2023-09-03 05:06:37 | INFO | train_inner | epoch 007:    168 / 1474 loss=3.354, trans_loss=4.207, nll_loss=2.621, w2v_ctc_loss=2.483, task_loss=1.993, task_loss_gen=2.22, contrastive_loss=0, total=4133.39, n_correct=1312.94, ppl=6.15, accuracy=31.764, wps=14698.8, ups=1.19, wpb=12340.1, bsz=466.9, num_updates=9000, lr=0.000149071, gnorm=27.446, clip=88, loss_scale=0.0312, train_wall=83, gb_free=11.6, wall=7443
2023-09-03 05:08:02 | INFO | train_inner | epoch 007:    268 / 1474 loss=3.249, trans_loss=4.128, nll_loss=2.52, w2v_ctc_loss=2.406, task_loss=1.887, task_loss_gen=2.292, contrastive_loss=0, total=4123.72, n_correct=1416.45, ppl=5.74, accuracy=34.349, wps=14528.9, ups=1.18, wpb=12308.1, bsz=447.9, num_updates=9100, lr=0.00014825, gnorm=9.171, clip=25, loss_scale=0.0625, train_wall=84, gb_free=12.6, wall=7528
2023-09-03 05:09:27 | INFO | train_inner | epoch 007:    368 / 1474 loss=3.149, trans_loss=4.116, nll_loss=2.505, w2v_ctc_loss=2.257, task_loss=1.878, task_loss_gen=2.173, contrastive_loss=0, total=4179.78, n_correct=1443.82, ppl=5.68, accuracy=34.543, wps=14609.1, ups=1.17, wpb=12474.1, bsz=473.8, num_updates=9200, lr=0.000147442, gnorm=6.868, clip=12, loss_scale=0.0625, train_wall=85, gb_free=15.9, wall=7613
2023-09-03 05:10:52 | INFO | train_inner | epoch 007:    468 / 1474 loss=3.176, trans_loss=4.116, nll_loss=2.507, w2v_ctc_loss=2.293, task_loss=1.754, task_loss_gen=2.196, contrastive_loss=0, total=4165.95, n_correct=1430.06, ppl=5.69, accuracy=34.327, wps=14738.3, ups=1.18, wpb=12439.7, bsz=465, num_updates=9300, lr=0.000146647, gnorm=7.328, clip=14, loss_scale=0.0625, train_wall=84, gb_free=16.3, wall=7698
2023-09-03 05:12:16 | INFO | train_inner | epoch 007:    568 / 1474 loss=3.156, trans_loss=4.116, nll_loss=2.506, w2v_ctc_loss=2.259, task_loss=1.734, task_loss_gen=2.212, contrastive_loss=0, total=4163.63, n_correct=1431.68, ppl=5.68, accuracy=34.385, wps=14772.2, ups=1.19, wpb=12422.2, bsz=459, num_updates=9400, lr=0.000145865, gnorm=7.02, clip=14, loss_scale=0.0625, train_wall=83, gb_free=17.4, wall=7782
2023-09-03 05:13:41 | INFO | train_inner | epoch 007:    668 / 1474 loss=3.215, trans_loss=4.124, nll_loss=2.517, w2v_ctc_loss=2.341, task_loss=1.772, task_loss_gen=2.295, contrastive_loss=0, total=4177.64, n_correct=1426.21, ppl=5.72, accuracy=34.139, wps=14694.1, ups=1.18, wpb=12467.9, bsz=461.8, num_updates=9500, lr=0.000145095, gnorm=17.693, clip=64, loss_scale=0.0625, train_wall=84, gb_free=13.7, wall=7867
2023-09-03 05:15:06 | INFO | train_inner | epoch 007:    768 / 1474 loss=3.182, trans_loss=4.105, nll_loss=2.493, w2v_ctc_loss=2.303, task_loss=1.865, task_loss_gen=2.358, contrastive_loss=0, total=4107.56, n_correct=1413.56, ppl=5.63, accuracy=34.414, wps=14433.7, ups=1.18, wpb=12265.3, bsz=443.6, num_updates=9600, lr=0.000144338, gnorm=9.982, clip=15, loss_scale=0.0625, train_wall=84, gb_free=12.4, wall=7952
2023-09-03 05:16:31 | INFO | train_inner | epoch 007:    868 / 1474 loss=3.142, trans_loss=4.115, nll_loss=2.504, w2v_ctc_loss=2.24, task_loss=1.783, task_loss_gen=2.29, contrastive_loss=0, total=4139.64, n_correct=1422.78, ppl=5.67, accuracy=34.37, wps=14475, ups=1.17, wpb=12349.4, bsz=458.1, num_updates=9700, lr=0.000143592, gnorm=7.992, clip=16, loss_scale=0.0625, train_wall=85, gb_free=15.9, wall=8037
2023-09-03 05:17:57 | INFO | train_inner | epoch 007:    968 / 1474 loss=3.142, trans_loss=4.098, nll_loss=2.486, w2v_ctc_loss=2.25, task_loss=1.67, task_loss_gen=2.219, contrastive_loss=0, total=4142.26, n_correct=1437.07, ppl=5.6, accuracy=34.693, wps=14474.7, ups=1.17, wpb=12370.1, bsz=473.2, num_updates=9800, lr=0.000142857, gnorm=8.723, clip=20, loss_scale=0.0625, train_wall=85, gb_free=16.2, wall=8122
2023-09-03 05:19:21 | INFO | train_inner | epoch 007:   1068 / 1474 loss=3.13, trans_loss=4.123, nll_loss=2.516, w2v_ctc_loss=2.221, task_loss=2.068, task_loss_gen=2.403, contrastive_loss=0, total=4109.77, n_correct=1414.18, ppl=5.72, accuracy=34.41, wps=14495.3, ups=1.18, wpb=12269.3, bsz=438.4, num_updates=9900, lr=0.000142134, gnorm=12.977, clip=55, loss_scale=0.0625, train_wall=84, gb_free=15.8, wall=8207
2023-09-03 05:20:46 | INFO | train_inner | epoch 007:   1168 / 1474 loss=3.054, trans_loss=4.117, nll_loss=2.51, w2v_ctc_loss=2.12, task_loss=1.965, task_loss_gen=2.201, contrastive_loss=0, total=4125.49, n_correct=1432.45, ppl=5.7, accuracy=34.722, wps=14533.3, ups=1.18, wpb=12325.5, bsz=467.3, num_updates=10000, lr=0.000141421, gnorm=7.867, clip=16, loss_scale=0.0625, train_wall=84, gb_free=15.5, wall=8292
2023-09-03 05:20:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 05:21:17 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.744 | trans_loss 7.386 | nll_loss 5.319 | w2v_ctc_loss 2.503 | task_loss 10.932 | task_loss_gen 9.193 | contrastive_loss 0 | total 4003.4 | n_correct 1357.1 | ppl 39.92 | accuracy 33.899 | uer 36.52 | wer 37.187 | raw_wer 37.187 | bleu 0.25 | wps 1823.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 0.25
2023-09-03 05:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-09-03 05:21:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-03 05:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-03 05:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 0.25) (writing took 13.644721981021576 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:0')
2023-09-03 05:22:54 | INFO | train_inner | epoch 007:   1268 / 1474 loss=3.151, trans_loss=4.114, nll_loss=2.505, w2v_ctc_loss=2.256, task_loss=2.136, task_loss_gen=2.318, contrastive_loss=0, total=4127.75, n_correct=1418.84, ppl=5.68, accuracy=34.373, wps=9602.2, ups=0.78, wpb=12328.2, bsz=451.1, num_updates=10100, lr=0.00014072, gnorm=15.099, clip=47, loss_scale=0.0625, train_wall=83, gb_free=15.6, wall=8420
2023-09-03 05:24:19 | INFO | train_inner | epoch 007:   1368 / 1474 loss=3.091, trans_loss=4.103, nll_loss=2.49, w2v_ctc_loss=2.172, task_loss=1.94, task_loss_gen=2.113, contrastive_loss=0, total=4180.86, n_correct=1451.96, ppl=5.62, accuracy=34.729, wps=14795.9, ups=1.19, wpb=12481.5, bsz=476.8, num_updates=10200, lr=0.000140028, gnorm=9.623, clip=37, loss_scale=0.0625, train_wall=84, gb_free=16.3, wall=8505
2023-09-03 05:25:45 | INFO | train_inner | epoch 007:   1468 / 1474 loss=3.073, trans_loss=4.098, nll_loss=2.487, w2v_ctc_loss=2.142, task_loss=1.932, task_loss_gen=2.342, contrastive_loss=0, total=4121.26, n_correct=1432.14, ppl=5.6, accuracy=34.75, wps=14285.5, ups=1.16, wpb=12314.3, bsz=448.8, num_updates=10300, lr=0.000139347, gnorm=7.391, clip=13, loss_scale=0.0625, train_wall=85, gb_free=16.6, wall=8591
2023-09-03 05:25:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:1')
2023-09-03 05:26:24 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.674 | trans_loss 7.292 | nll_loss 5.2 | w2v_ctc_loss 2.482 | task_loss 7.943 | task_loss_gen 8.813 | contrastive_loss 0 | total 4003.4 | n_correct 1411.3 | ppl 36.76 | accuracy 35.253 | uer 36.379 | wer 37.09 | raw_wer 37.09 | bleu 0.13 | wps 1536.9 | wpb 4003.4 | bsz 141.8 | num_updates 10306 | best_bleu 0.25
2023-09-03 05:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10306 updates
2023-09-03 05:26:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1308.pt
2023-09-03 05:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1308.pt
2023-09-03 05:26:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1308.pt (epoch 7 @ 10306 updates, score 0.13) (writing took 8.748679662996437 seconds)
2023-09-03 05:26:33 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-03 05:26:33 | INFO | train | epoch 007 | loss 3.171 | trans_loss 4.121 | nll_loss 2.513 | w2v_ctc_loss 2.282 | task_loss 1.887 | task_loss_gen 2.261 | contrastive_loss 0 | total 4138.65 | n_correct 1418.81 | ppl 5.71 | accuracy 34.282 | wps 13543.8 | ups 1.1 | wpb 12355.8 | bsz 458.5 | num_updates 10306 | lr 0.000139306 | gnorm 11.449 | clip 33.2 | loss_scale 0.0625 | train_wall 1240 | gb_free 12.8 | wall 8638
2023-09-03 05:26:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 05:26:33 | INFO | fairseq.trainer | begin training epoch 8
2023-09-03 05:26:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 05:27:59 | INFO | train_inner | epoch 008:     94 / 1474 loss=3.079, trans_loss=4.098, nll_loss=2.48, w2v_ctc_loss=2.153, task_loss=2.025, task_loss_gen=2.386, contrastive_loss=0, total=4105.83, n_correct=1431.56, ppl=5.58, accuracy=34.867, wps=9113.5, ups=0.74, wpb=12240.4, bsz=439.6, num_updates=10400, lr=0.000138675, gnorm=10.306, clip=28, loss_scale=0.0625, train_wall=83, gb_free=17.6, wall=8725
2023-09-03 05:29:24 | INFO | train_inner | epoch 008:    194 / 1474 loss=3.099, trans_loss=4.099, nll_loss=2.481, w2v_ctc_loss=2.178, task_loss=2.049, task_loss_gen=2.43, contrastive_loss=0, total=4020.77, n_correct=1394.01, ppl=5.58, accuracy=34.67, wps=14224.2, ups=1.19, wpb=11991.3, bsz=425.1, num_updates=10500, lr=0.000138013, gnorm=6.941, clip=17, loss_scale=0.0625, train_wall=84, gb_free=16.6, wall=8809
2023-09-03 05:30:48 | INFO | train_inner | epoch 008:    294 / 1474 loss=3.131, trans_loss=4.08, nll_loss=2.461, w2v_ctc_loss=2.245, task_loss=1.634, task_loss_gen=2.112, contrastive_loss=0, total=4215.76, n_correct=1478.94, ppl=5.51, accuracy=35.081, wps=14905.5, ups=1.18, wpb=12584.1, bsz=488.4, num_updates=10600, lr=0.000137361, gnorm=10.321, clip=34, loss_scale=0.0625, train_wall=84, gb_free=15.9, wall=8894
2023-09-03 05:32:14 | INFO | train_inner | epoch 008:    394 / 1474 loss=3.086, trans_loss=4.092, nll_loss=2.474, w2v_ctc_loss=2.169, task_loss=1.916, task_loss_gen=2.327, contrastive_loss=0, total=4139.28, n_correct=1445.78, ppl=5.56, accuracy=34.928, wps=14384.9, ups=1.16, wpb=12347.9, bsz=448.2, num_updates=10700, lr=0.000136717, gnorm=6.945, clip=12, loss_scale=0.0625, train_wall=85, gb_free=16.9, wall=8980
2023-09-03 05:33:40 | INFO | train_inner | epoch 008:    494 / 1474 loss=3.08, trans_loss=4.084, nll_loss=2.467, w2v_ctc_loss=2.164, task_loss=1.686, task_loss_gen=2.052, contrastive_loss=0, total=4191.9, n_correct=1469.28, ppl=5.53, accuracy=35.05, wps=14559.3, ups=1.16, wpb=12516.4, bsz=497.9, num_updates=10800, lr=0.000136083, gnorm=8.323, clip=26, loss_scale=0.0625, train_wall=85, gb_free=16.7, wall=9066
2023-09-03 05:35:04 | INFO | train_inner | epoch 008:    594 / 1474 loss=3.129, trans_loss=4.085, nll_loss=2.471, w2v_ctc_loss=2.23, task_loss=1.931, task_loss_gen=2.391, contrastive_loss=0, total=4075.21, n_correct=1413.84, ppl=5.55, accuracy=34.694, wps=14446.1, ups=1.19, wpb=12181.8, bsz=434.6, num_updates=10900, lr=0.000135457, gnorm=6.293, clip=12, loss_scale=0.0625, train_wall=84, gb_free=17.5, wall=9150
2023-09-03 05:36:29 | INFO | train_inner | epoch 008:    694 / 1474 loss=3.149, trans_loss=4.083, nll_loss=2.465, w2v_ctc_loss=2.264, task_loss=1.757, task_loss_gen=2.339, contrastive_loss=0, total=4138.17, n_correct=1444.86, ppl=5.52, accuracy=34.915, wps=14584.5, ups=1.18, wpb=12352.9, bsz=446.3, num_updates=11000, lr=0.00013484, gnorm=11.725, clip=18, loss_scale=0.0625, train_wall=84, gb_free=15.5, wall=9235
2023-09-03 05:37:53 | INFO | train_inner | epoch 008:    794 / 1474 loss=3.112, trans_loss=4.074, nll_loss=2.458, w2v_ctc_loss=2.215, task_loss=1.889, task_loss_gen=2.282, contrastive_loss=0, total=4120.58, n_correct=1444.69, ppl=5.49, accuracy=35.06, wps=14582.7, ups=1.18, wpb=12316.7, bsz=450.3, num_updates=11100, lr=0.000134231, gnorm=14.953, clip=29, loss_scale=0.125, train_wall=84, gb_free=12.9, wall=9319
2023-09-03 05:39:18 | INFO | train_inner | epoch 008:    894 / 1474 loss=3.041, trans_loss=4.084, nll_loss=2.466, w2v_ctc_loss=2.105, task_loss=1.803, task_loss_gen=2.149, contrastive_loss=0, total=4172.66, n_correct=1466.2, ppl=5.53, accuracy=35.138, wps=14661.4, ups=1.18, wpb=12458.1, bsz=473.6, num_updates=11200, lr=0.000133631, gnorm=6.122, clip=16, loss_scale=0.125, train_wall=84, gb_free=16.6, wall=9404
2023-09-03 05:40:43 | INFO | train_inner | epoch 008:    994 / 1474 loss=3.015, trans_loss=4.081, nll_loss=2.464, w2v_ctc_loss=2.061, task_loss=1.805, task_loss_gen=2.163, contrastive_loss=0, total=4163.42, n_correct=1452.09, ppl=5.52, accuracy=34.877, wps=14725.4, ups=1.18, wpb=12433.5, bsz=467.1, num_updates=11300, lr=0.000133038, gnorm=5.748, clip=14, loss_scale=0.125, train_wall=84, gb_free=16.6, wall=9489
2023-09-03 05:42:09 | INFO | train_inner | epoch 008:   1094 / 1474 loss=3.037, trans_loss=4.074, nll_loss=2.453, w2v_ctc_loss=2.1, task_loss=1.782, task_loss_gen=2.309, contrastive_loss=0, total=4175.4, n_correct=1471.16, ppl=5.48, accuracy=35.234, wps=14537.9, ups=1.17, wpb=12461.7, bsz=458.2, num_updates=11400, lr=0.000132453, gnorm=5.157, clip=9, loss_scale=0.125, train_wall=85, gb_free=17.2, wall=9574
2023-09-03 05:43:33 | INFO | train_inner | epoch 008:   1194 / 1474 loss=3.065, trans_loss=4.07, nll_loss=2.451, w2v_ctc_loss=2.146, task_loss=1.62, task_loss_gen=2.161, contrastive_loss=0, total=4174.4, n_correct=1467.29, ppl=5.47, accuracy=35.15, wps=14829.3, ups=1.19, wpb=12468.1, bsz=471.6, num_updates=11500, lr=0.000131876, gnorm=3.887, clip=11, loss_scale=0.125, train_wall=83, gb_free=15.3, wall=9658
2023-09-03 05:44:57 | INFO | train_inner | epoch 008:   1294 / 1474 loss=3.029, trans_loss=4.069, nll_loss=2.449, w2v_ctc_loss=2.089, task_loss=1.807, task_loss_gen=2.304, contrastive_loss=0, total=4081.78, n_correct=1433.26, ppl=5.46, accuracy=35.114, wps=14445.2, ups=1.18, wpb=12192.8, bsz=442.3, num_updates=11600, lr=0.000131306, gnorm=4.392, clip=9, loss_scale=0.125, train_wall=84, gb_free=15.5, wall=9743
2023-09-03 05:46:21 | INFO | train_inner | epoch 008:   1394 / 1474 loss=3.043, trans_loss=4.081, nll_loss=2.465, w2v_ctc_loss=2.107, task_loss=1.813, task_loss_gen=2.279, contrastive_loss=0, total=4153.08, n_correct=1458.61, ppl=5.52, accuracy=35.121, wps=14791.2, ups=1.19, wpb=12401.3, bsz=467.2, num_updates=11700, lr=0.000130744, gnorm=7.993, clip=25, loss_scale=0.125, train_wall=83, gb_free=15.2, wall=9827
2023-09-03 05:47:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 05:48:00 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 5.68 | trans_loss 7.282 | nll_loss 5.186 | w2v_ctc_loss 2.522 | task_loss 8.513 | task_loss_gen 8.981 | contrastive_loss 0 | total 4003.4 | n_correct 1417.8 | ppl 36.41 | accuracy 35.415 | uer 36.498 | wer 37.072 | raw_wer 37.072 | bleu 0.16 | wps 1777.5 | wpb 4003.4 | bsz 141.8 | num_updates 11780 | best_bleu 0.25
2023-09-03 05:48:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11780 updates
2023-09-03 05:48:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1608.pt
2023-09-03 05:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1608.pt
2023-09-03 05:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1608.pt (epoch 8 @ 11780 updates, score 0.16) (writing took 7.8857935320120305 seconds)
2023-09-03 05:48:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-03 05:48:08 | INFO | train | epoch 008 | loss 3.075 | trans_loss 4.082 | nll_loss 2.464 | w2v_ctc_loss 2.155 | task_loss 1.817 | task_loss_gen 2.254 | contrastive_loss 0 | total 4138.65 | n_correct 1449.07 | ppl 5.52 | accuracy 35.013 | wps 14058.5 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 11780 | lr 0.000130299 | gnorm 7.573 | clip 18.1 | loss_scale 0.125 | train_wall 1237 | gb_free 16.6 | wall 9934
2023-09-03 05:48:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 05:48:08 | INFO | fairseq.trainer | begin training epoch 9
2023-09-03 05:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 05:48:34 | INFO | train_inner | epoch 009:     20 / 1474 loss=3.019, trans_loss=4.068, nll_loss=2.445, w2v_ctc_loss=2.079, task_loss=1.841, task_loss_gen=2.225, contrastive_loss=0, total=4111.18, n_correct=1452.85, ppl=5.44, accuracy=35.339, wps=9247.2, ups=0.75, wpb=12270.5, bsz=462.1, num_updates=11800, lr=0.000130189, gnorm=4.408, clip=11, loss_scale=0.125, train_wall=84, gb_free=16.2, wall=9959
2023-09-03 05:49:58 | INFO | train_inner | epoch 009:    120 / 1474 loss=3.044, trans_loss=4.059, nll_loss=2.435, w2v_ctc_loss=2.121, task_loss=1.613, task_loss_gen=2.153, contrastive_loss=0, total=4190.48, n_correct=1484.7, ppl=5.41, accuracy=35.43, wps=14814.6, ups=1.18, wpb=12512.7, bsz=483.8, num_updates=11900, lr=0.000129641, gnorm=5.873, clip=15, loss_scale=0.125, train_wall=84, gb_free=15.6, wall=10044
2023-09-03 05:51:23 | INFO | train_inner | epoch 009:    220 / 1474 loss=3.013, trans_loss=4.06, nll_loss=2.436, w2v_ctc_loss=2.065, task_loss=1.99, task_loss_gen=2.45, contrastive_loss=0, total=4065.17, n_correct=1441.01, ppl=5.41, accuracy=35.448, wps=14292.7, ups=1.18, wpb=12137.5, bsz=427.1, num_updates=12000, lr=0.000129099, gnorm=4.827, clip=7, loss_scale=0.125, train_wall=84, gb_free=15.6, wall=10129
2023-09-03 05:51:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 05:51:55 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.646 | trans_loss 7.281 | nll_loss 5.184 | w2v_ctc_loss 2.414 | task_loss 11.346 | task_loss_gen 9.234 | contrastive_loss 0 | total 4003.4 | n_correct 1414.6 | ppl 36.35 | accuracy 35.335 | uer 35.572 | wer 36.46 | raw_wer 36.46 | bleu 0.15 | wps 1673.5 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 0.25
2023-09-03 05:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-09-03 05:51:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-03 05:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-03 05:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 0.15) (writing took 8.463555715978146 seconds)
2023-09-03 05:53:28 | INFO | train_inner | epoch 009:    320 / 1474 loss=3.006, trans_loss=4.05, nll_loss=2.425, w2v_ctc_loss=2.067, task_loss=1.564, task_loss_gen=2.095, contrastive_loss=0, total=4172.96, n_correct=1485.95, ppl=5.37, accuracy=35.609, wps=9965.6, ups=0.8, wpb=12467.1, bsz=486.5, num_updates=12100, lr=0.000128565, gnorm=7.937, clip=9, loss_scale=0.125, train_wall=83, gb_free=10.4, wall=10254
2023-09-03 05:54:53 | INFO | train_inner | epoch 009:    420 / 1474 loss=3.05, trans_loss=4.061, nll_loss=2.437, w2v_ctc_loss=2.129, task_loss=1.649, task_loss_gen=2.287, contrastive_loss=0, total=4182.58, n_correct=1478.67, ppl=5.42, accuracy=35.353, wps=14620.9, ups=1.17, wpb=12488.5, bsz=461.4, num_updates=12200, lr=0.000128037, gnorm=5.56, clip=13, loss_scale=0.125, train_wall=85, gb_free=17.4, wall=10339
2023-09-03 05:56:18 | INFO | train_inner | epoch 009:    520 / 1474 loss=3.066, trans_loss=4.065, nll_loss=2.442, w2v_ctc_loss=2.145, task_loss=1.84, task_loss_gen=2.469, contrastive_loss=0, total=4112.02, n_correct=1453.11, ppl=5.44, accuracy=35.338, wps=14458.8, ups=1.18, wpb=12275, bsz=437.1, num_updates=12300, lr=0.000127515, gnorm=8.235, clip=26, loss_scale=0.125, train_wall=84, gb_free=17.4, wall=10424
2023-09-03 05:57:43 | INFO | train_inner | epoch 009:    620 / 1474 loss=3.05, trans_loss=4.054, nll_loss=2.431, w2v_ctc_loss=2.135, task_loss=1.888, task_loss_gen=2.274, contrastive_loss=0, total=4140.3, n_correct=1467.47, ppl=5.39, accuracy=35.444, wps=14572.9, ups=1.18, wpb=12373, bsz=462, num_updates=12400, lr=0.000127, gnorm=5.593, clip=13, loss_scale=0.125, train_wall=84, gb_free=15.3, wall=10509
2023-09-03 05:59:07 | INFO | train_inner | epoch 009:    720 / 1474 loss=3.06, trans_loss=4.066, nll_loss=2.446, w2v_ctc_loss=2.138, task_loss=1.881, task_loss_gen=2.439, contrastive_loss=0, total=4074.09, n_correct=1431.14, ppl=5.45, accuracy=35.128, wps=14503.4, ups=1.19, wpb=12175.5, bsz=442.4, num_updates=12500, lr=0.000126491, gnorm=7.974, clip=30, loss_scale=0.125, train_wall=83, gb_free=16.3, wall=10593
2023-09-03 06:00:32 | INFO | train_inner | epoch 009:    820 / 1474 loss=3.024, trans_loss=4.051, nll_loss=2.427, w2v_ctc_loss=2.097, task_loss=1.694, task_loss_gen=2.057, contrastive_loss=0, total=4200.53, n_correct=1494.82, ppl=5.38, accuracy=35.586, wps=14846.8, ups=1.18, wpb=12551.2, bsz=495.6, num_updates=12600, lr=0.000125988, gnorm=4.677, clip=6, loss_scale=0.125, train_wall=84, gb_free=11.7, wall=10678
2023-09-03 06:01:57 | INFO | train_inner | epoch 009:    920 / 1474 loss=3.092, trans_loss=4.068, nll_loss=2.443, w2v_ctc_loss=2.183, task_loss=1.711, task_loss_gen=2.402, contrastive_loss=0, total=4168.08, n_correct=1469.27, ppl=5.44, accuracy=35.251, wps=14524.5, ups=1.17, wpb=12433.4, bsz=454.9, num_updates=12700, lr=0.000125491, gnorm=6.9, clip=21, loss_scale=0.125, train_wall=85, gb_free=16.7, wall=10763
2023-09-03 06:03:22 | INFO | train_inner | epoch 009:   1020 / 1474 loss=3.088, trans_loss=4.068, nll_loss=2.445, w2v_ctc_loss=2.175, task_loss=1.928, task_loss_gen=2.561, contrastive_loss=0, total=4098.18, n_correct=1445.31, ppl=5.45, accuracy=35.267, wps=14397.2, ups=1.18, wpb=12233.3, bsz=424.7, num_updates=12800, lr=0.000125, gnorm=6.9, clip=18, loss_scale=0.125, train_wall=84, gb_free=16.4, wall=10848
2023-09-03 06:04:47 | INFO | train_inner | epoch 009:   1120 / 1474 loss=3.057, trans_loss=4.067, nll_loss=2.44, w2v_ctc_loss=2.135, task_loss=1.715, task_loss_gen=2.168, contrastive_loss=0, total=4164.24, n_correct=1471.2, ppl=5.43, accuracy=35.329, wps=14686, ups=1.18, wpb=12412.9, bsz=468.7, num_updates=12900, lr=0.000124515, gnorm=4.539, clip=10, loss_scale=0.125, train_wall=84, gb_free=14.2, wall=10933
2023-09-03 06:06:12 | INFO | train_inner | epoch 009:   1220 / 1474 loss=3.035, trans_loss=4.059, nll_loss=2.435, w2v_ctc_loss=2.104, task_loss=1.695, task_loss_gen=2.387, contrastive_loss=0, total=4152.13, n_correct=1471.79, ppl=5.41, accuracy=35.447, wps=14510.6, ups=1.17, wpb=12395.5, bsz=451.3, num_updates=13000, lr=0.000124035, gnorm=3.938, clip=5, loss_scale=0.125, train_wall=85, gb_free=17.3, wall=11018
2023-09-03 06:07:36 | INFO | train_inner | epoch 009:   1320 / 1474 loss=2.982, trans_loss=4.057, nll_loss=2.431, w2v_ctc_loss=2.024, task_loss=1.747, task_loss_gen=2.094, contrastive_loss=0, total=4199.35, n_correct=1485.63, ppl=5.39, accuracy=35.378, wps=14906, ups=1.19, wpb=12531.8, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=8.562, clip=33, loss_scale=0.125, train_wall=83, gb_free=16.2, wall=11102
2023-09-03 06:09:01 | INFO | train_inner | epoch 009:   1420 / 1474 loss=3.065, trans_loss=4.064, nll_loss=2.44, w2v_ctc_loss=2.147, task_loss=1.885, task_loss_gen=2.386, contrastive_loss=0, total=4073.83, n_correct=1439.15, ppl=5.43, accuracy=35.327, wps=14420.2, ups=1.19, wpb=12155.9, bsz=431.5, num_updates=13200, lr=0.000123091, gnorm=6.047, clip=12, loss_scale=0.25, train_wall=84, gb_free=12.5, wall=11187
2023-09-03 06:09:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 06:10:18 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.614 | trans_loss 7.263 | nll_loss 5.163 | w2v_ctc_loss 2.347 | task_loss 10.004 | task_loss_gen 9.025 | contrastive_loss 0 | total 4003.4 | n_correct 1425.2 | ppl 35.83 | accuracy 35.6 | uer 34.603 | wer 35.495 | raw_wer 35.495 | bleu 0.14 | wps 1654.8 | wpb 4003.4 | bsz 141.8 | num_updates 13254 | best_bleu 0.25
2023-09-03 06:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13254 updates
2023-09-03 06:10:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1404.pt
2023-09-03 06:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1404.pt
2023-09-03 06:10:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1404.pt (epoch 9 @ 13254 updates, score 0.14) (writing took 7.598351448017638 seconds)
2023-09-03 06:10:26 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-03 06:10:26 | INFO | train | epoch 009 | loss 3.042 | trans_loss 4.06 | nll_loss 2.436 | w2v_ctc_loss 2.114 | task_loss 1.77 | task_loss_gen 2.289 | contrastive_loss 0 | total 4138.65 | n_correct 1464.83 | ppl 5.41 | accuracy 35.394 | wps 13613.5 | ups 1.1 | wpb 12355.8 | bsz 458.5 | num_updates 13254 | lr 0.00012284 | gnorm 6.068 | clip 14.9 | loss_scale 0.25 | train_wall 1238 | gb_free 11.1 | wall 11272
2023-09-03 06:10:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 06:10:26 | INFO | fairseq.trainer | begin training epoch 10
2023-09-03 06:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 06:11:12 | INFO | train_inner | epoch 010:     46 / 1474 loss=2.946, trans_loss=4.042, nll_loss=2.413, w2v_ctc_loss=1.985, task_loss=1.65, task_loss_gen=2.1, contrastive_loss=0, total=4122.64, n_correct=1481.44, ppl=5.33, accuracy=35.934, wps=9345.2, ups=0.76, wpb=12305.9, bsz=477, num_updates=13300, lr=0.000122628, gnorm=1.844, clip=1, loss_scale=0.25, train_wall=83, gb_free=15.6, wall=11318
2023-09-03 06:12:38 | INFO | train_inner | epoch 010:    146 / 1474 loss=2.948, trans_loss=4.036, nll_loss=2.407, w2v_ctc_loss=1.987, task_loss=1.611, task_loss_gen=2.167, contrastive_loss=0, total=4236.72, n_correct=1522.66, ppl=5.3, accuracy=35.94, wps=14815.1, ups=1.17, wpb=12652.8, bsz=475.1, num_updates=13400, lr=0.000122169, gnorm=2.575, clip=2, loss_scale=0.25, train_wall=85, gb_free=16.4, wall=11404
2023-09-03 06:14:02 | INFO | train_inner | epoch 010:    246 / 1474 loss=2.927, trans_loss=4.035, nll_loss=2.402, w2v_ctc_loss=1.952, task_loss=1.988, task_loss_gen=2.226, contrastive_loss=0, total=4127.77, n_correct=1482.08, ppl=5.28, accuracy=35.905, wps=14647.6, ups=1.19, wpb=12319.2, bsz=461.1, num_updates=13500, lr=0.000121716, gnorm=4.387, clip=13, loss_scale=0.25, train_wall=83, gb_free=14.6, wall=11488
2023-09-03 06:15:26 | INFO | train_inner | epoch 010:    346 / 1474 loss=2.888, trans_loss=4.035, nll_loss=2.408, w2v_ctc_loss=1.891, task_loss=1.872, task_loss_gen=2.239, contrastive_loss=0, total=4129.43, n_correct=1478.95, ppl=5.31, accuracy=35.815, wps=14623.3, ups=1.18, wpb=12340.9, bsz=453.1, num_updates=13600, lr=0.000121268, gnorm=2.302, clip=1, loss_scale=0.25, train_wall=84, gb_free=15.9, wall=11572
2023-09-03 06:16:52 | INFO | train_inner | epoch 010:    446 / 1474 loss=2.876, trans_loss=4.033, nll_loss=2.403, w2v_ctc_loss=1.877, task_loss=1.792, task_loss_gen=2.194, contrastive_loss=0, total=4185.96, n_correct=1508.59, ppl=5.29, accuracy=36.039, wps=14667.6, ups=1.17, wpb=12499.4, bsz=478.6, num_updates=13700, lr=0.000120824, gnorm=2.272, clip=3, loss_scale=0.25, train_wall=85, gb_free=16.3, wall=11657
2023-09-03 06:18:17 | INFO | train_inner | epoch 010:    546 / 1474 loss=2.923, trans_loss=4.044, nll_loss=2.411, w2v_ctc_loss=1.94, task_loss=1.756, task_loss_gen=2.508, contrastive_loss=0, total=4092.73, n_correct=1469.03, ppl=5.32, accuracy=35.894, wps=14338.4, ups=1.18, wpb=12202.1, bsz=433.1, num_updates=13800, lr=0.000120386, gnorm=2.618, clip=2, loss_scale=0.25, train_wall=84, gb_free=16.4, wall=11742
2023-09-03 06:19:42 | INFO | train_inner | epoch 010:    646 / 1474 loss=2.887, trans_loss=4.039, nll_loss=2.407, w2v_ctc_loss=1.894, task_loss=1.466, task_loss_gen=2.138, contrastive_loss=0, total=4209.71, n_correct=1515.08, ppl=5.31, accuracy=35.99, wps=14754.8, ups=1.17, wpb=12562, bsz=489, num_updates=13900, lr=0.000119952, gnorm=1.898, clip=3, loss_scale=0.25, train_wall=84, gb_free=13.6, wall=11828
2023-09-03 06:21:06 | INFO | train_inner | epoch 010:    746 / 1474 loss=2.92, trans_loss=4.04, nll_loss=2.41, w2v_ctc_loss=1.936, task_loss=1.601, task_loss_gen=2.407, contrastive_loss=0, total=4100.84, n_correct=1469.63, ppl=5.32, accuracy=35.837, wps=14525.7, ups=1.19, wpb=12244.9, bsz=445, num_updates=14000, lr=0.000119523, gnorm=2.264, clip=1, loss_scale=0.25, train_wall=84, gb_free=16.7, wall=11912
2023-09-03 06:21:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 06:21:39 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 5.583 | trans_loss 7.268 | nll_loss 5.166 | w2v_ctc_loss 2.232 | task_loss 26.761 | task_loss_gen 14.439 | contrastive_loss 0 | total 4003.4 | n_correct 1429.2 | ppl 35.89 | accuracy 35.7 | uer 32.96 | wer 34.242 | raw_wer 34.242 | bleu 0.15 | wps 1642.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 0.25
2023-09-03 06:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-09-03 06:21:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-03 06:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-03 06:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 0.15) (writing took 8.199255693005398 seconds)
2023-09-03 06:23:12 | INFO | train_inner | epoch 010:    846 / 1474 loss=2.868, trans_loss=4.044, nll_loss=2.416, w2v_ctc_loss=1.858, task_loss=1.831, task_loss_gen=2.263, contrastive_loss=0, total=4138.46, n_correct=1482, ppl=5.34, accuracy=35.81, wps=9805.6, ups=0.79, wpb=12354.3, bsz=456.5, num_updates=14100, lr=0.000119098, gnorm=3.166, clip=2, loss_scale=0.25, train_wall=84, gb_free=17, wall=12038
2023-09-03 06:24:36 | INFO | train_inner | epoch 010:    946 / 1474 loss=2.873, trans_loss=4.043, nll_loss=2.412, w2v_ctc_loss=1.868, task_loss=1.807, task_loss_gen=2.132, contrastive_loss=0, total=4159.81, n_correct=1497.28, ppl=5.32, accuracy=35.994, wps=14852.4, ups=1.2, wpb=12407.1, bsz=472.6, num_updates=14200, lr=0.000118678, gnorm=3.126, clip=3, loss_scale=0.25, train_wall=83, gb_free=16, wall=12121
2023-09-03 06:26:01 | INFO | train_inner | epoch 010:   1046 / 1474 loss=2.891, trans_loss=4.04, nll_loss=2.411, w2v_ctc_loss=1.887, task_loss=2.263, task_loss_gen=2.444, contrastive_loss=0, total=4064.74, n_correct=1452.37, ppl=5.32, accuracy=35.731, wps=14280.2, ups=1.18, wpb=12137.8, bsz=432.1, num_updates=14300, lr=0.000118262, gnorm=2.906, clip=2, loss_scale=0.25, train_wall=84, gb_free=16, wall=12206
2023-09-03 06:27:25 | INFO | train_inner | epoch 010:   1146 / 1474 loss=2.902, trans_loss=4.048, nll_loss=2.42, w2v_ctc_loss=1.906, task_loss=2.096, task_loss_gen=2.49, contrastive_loss=0, total=4032.56, n_correct=1435.01, ppl=5.35, accuracy=35.586, wps=14346.4, ups=1.19, wpb=12038.7, bsz=419.7, num_updates=14400, lr=0.000117851, gnorm=3.311, clip=6, loss_scale=0.25, train_wall=83, gb_free=12.8, wall=12290
2023-09-03 06:28:49 | INFO | train_inner | epoch 010:   1246 / 1474 loss=2.882, trans_loss=4.031, nll_loss=2.404, w2v_ctc_loss=1.884, task_loss=2.003, task_loss_gen=2.371, contrastive_loss=0, total=4108.65, n_correct=1472.03, ppl=5.29, accuracy=35.828, wps=14540.6, ups=1.18, wpb=12288.9, bsz=445.7, num_updates=14500, lr=0.000117444, gnorm=2.971, clip=4, loss_scale=0.25, train_wall=84, gb_free=15.4, wall=12375
2023-09-03 06:30:14 | INFO | train_inner | epoch 010:   1346 / 1474 loss=2.91, trans_loss=4.038, nll_loss=2.409, w2v_ctc_loss=1.924, task_loss=1.719, task_loss_gen=2.295, contrastive_loss=0, total=4147.4, n_correct=1491.31, ppl=5.31, accuracy=35.958, wps=14651.4, ups=1.18, wpb=12385, bsz=456.3, num_updates=14600, lr=0.000117041, gnorm=4.283, clip=7, loss_scale=0.25, train_wall=84, gb_free=15.1, wall=12459
2023-09-03 06:31:39 | INFO | train_inner | epoch 010:   1446 / 1474 loss=2.88, trans_loss=4.036, nll_loss=2.403, w2v_ctc_loss=1.884, task_loss=1.47, task_loss_gen=2.205, contrastive_loss=0, total=4189.02, n_correct=1513.89, ppl=5.29, accuracy=36.139, wps=14645.9, ups=1.17, wpb=12494.2, bsz=483.2, num_updates=14700, lr=0.000116642, gnorm=4.455, clip=8, loss_scale=0.25, train_wall=85, gb_free=15, wall=12545
2023-09-03 06:32:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 06:32:34 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 5.558 | trans_loss 7.255 | nll_loss 5.15 | w2v_ctc_loss 2.18 | task_loss 9.263 | task_loss_gen 9.125 | contrastive_loss 0 | total 4003.4 | n_correct 1430.1 | ppl 35.51 | accuracy 35.722 | uer 32.464 | wer 33.94 | raw_wer 33.94 | bleu 0.14 | wps 1746 | wpb 4003.4 | bsz 141.8 | num_updates 14728 | best_bleu 0.25
2023-09-03 06:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14728 updates
2023-09-03 06:32:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1403.pt
2023-09-03 06:32:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1403.pt
2023-09-03 06:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1403.pt (epoch 10 @ 14728 updates, score 0.14) (writing took 7.516714047989808 seconds)
2023-09-03 06:32:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-03 06:32:41 | INFO | train | epoch 010 | loss 2.898 | trans_loss 4.038 | nll_loss 2.408 | w2v_ctc_loss 1.907 | task_loss 1.786 | task_loss_gen 2.28 | contrastive_loss 0 | total 4138.65 | n_correct 1485.89 | ppl 5.31 | accuracy 35.903 | wps 13637 | ups 1.1 | wpb 12355.8 | bsz 458.5 | num_updates 14728 | lr 0.000116531 | gnorm 2.988 | clip 3.9 | loss_scale 0.25 | train_wall 1237 | gb_free 16.9 | wall 12607
2023-09-03 06:32:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 06:32:42 | INFO | fairseq.trainer | begin training epoch 11
2023-09-03 06:32:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 06:33:49 | INFO | train_inner | epoch 011:     72 / 1474 loss=2.849, trans_loss=4.022, nll_loss=2.388, w2v_ctc_loss=1.841, task_loss=1.544, task_loss_gen=2.198, contrastive_loss=0, total=4151.84, n_correct=1504.76, ppl=5.23, accuracy=36.243, wps=9558.7, ups=0.77, wpb=12396.2, bsz=472.4, num_updates=14800, lr=0.000116248, gnorm=1.668, clip=1, loss_scale=0.25, train_wall=82, gb_free=17.2, wall=12674
2023-09-03 06:35:13 | INFO | train_inner | epoch 011:    172 / 1474 loss=2.873, trans_loss=4.026, nll_loss=2.394, w2v_ctc_loss=1.874, task_loss=2.005, task_loss_gen=2.334, contrastive_loss=0, total=4112.36, n_correct=1483.85, ppl=5.26, accuracy=36.083, wps=14479.2, ups=1.18, wpb=12285.1, bsz=453.4, num_updates=14900, lr=0.000115857, gnorm=4.398, clip=7, loss_scale=0.25, train_wall=84, gb_free=16.2, wall=12759
2023-09-03 06:36:38 | INFO | train_inner | epoch 011:    272 / 1474 loss=2.861, trans_loss=4.024, nll_loss=2.39, w2v_ctc_loss=1.857, task_loss=1.895, task_loss_gen=2.336, contrastive_loss=0, total=4108.86, n_correct=1487.85, ppl=5.24, accuracy=36.211, wps=14587.2, ups=1.19, wpb=12272.6, bsz=441, num_updates=15000, lr=0.00011547, gnorm=3.109, clip=7, loss_scale=0.25, train_wall=84, gb_free=15.9, wall=12843
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:0')
2023-09-03 06:37:39 | INFO | train_inner | epoch 011:    372 / 1474 loss=2.883, trans_loss=5.982, nll_loss=3.555, w2v_ctc_loss=1.467, task_loss=2.735, task_loss_gen=3.526, contrastive_loss=0, total=4099.47, n_correct=1473.25, ppl=11.76, accuracy=35.938, wps=13477.5, ups=1.64, wpb=8238.3, bsz=296.2, num_updates=15100, lr=0.000115087, gnorm=7.111, clip=8, loss_scale=0.25, train_wall=60, gb_free=16.7, wall=12905
2023-09-03 06:38:41 | INFO | train_inner | epoch 011:    472 / 1474 loss=2.885, trans_loss=6.004, nll_loss=3.563, w2v_ctc_loss=1.492, task_loss=2.715, task_loss_gen=3.544, contrastive_loss=0, total=4112.57, n_correct=1493.06, ppl=11.82, accuracy=36.305, wps=13233.1, ups=1.61, wpb=8225.1, bsz=302.7, num_updates=15200, lr=0.000114708, gnorm=3.042, clip=5, loss_scale=0.5, train_wall=61, gb_free=11.6, wall=12967
2023-09-03 06:39:42 | INFO | train_inner | epoch 011:    572 / 1474 loss=2.876, trans_loss=6.004, nll_loss=3.563, w2v_ctc_loss=1.456, task_loss=2.699, task_loss_gen=3.665, contrastive_loss=0, total=4068.45, n_correct=1473.69, ppl=11.82, accuracy=36.222, wps=13302.4, ups=1.63, wpb=8136.9, bsz=292.8, num_updates=15300, lr=0.000114332, gnorm=2.421, clip=3, loss_scale=0.5, train_wall=60, gb_free=17.6, wall=13028
2023-09-03 06:40:44 | INFO | train_inner | epoch 011:    672 / 1474 loss=2.881, trans_loss=6, nll_loss=3.558, w2v_ctc_loss=1.481, task_loss=2.414, task_loss_gen=3.413, contrastive_loss=0, total=4161.97, n_correct=1510.74, ppl=11.78, accuracy=36.299, wps=13483.6, ups=1.62, wpb=8323.9, bsz=311.9, num_updates=15400, lr=0.000113961, gnorm=3.964, clip=5, loss_scale=0.5, train_wall=61, gb_free=17.4, wall=13090
2023-09-03 06:41:45 | INFO | train_inner | epoch 011:    772 / 1474 loss=2.896, trans_loss=6.013, nll_loss=3.576, w2v_ctc_loss=1.513, task_loss=2.628, task_loss_gen=3.521, contrastive_loss=0, total=4155.4, n_correct=1503.99, ppl=11.92, accuracy=36.194, wps=13540.8, ups=1.63, wpb=8310.8, bsz=301.7, num_updates=15500, lr=0.000113592, gnorm=3.018, clip=9, loss_scale=0.5, train_wall=61, gb_free=16.4, wall=13151
2023-09-03 06:42:46 | INFO | train_inner | epoch 011:    872 / 1474 loss=2.898, trans_loss=6.019, nll_loss=3.583, w2v_ctc_loss=1.496, task_loss=2.93, task_loss_gen=3.653, contrastive_loss=0, total=4128.59, n_correct=1476.79, ppl=11.99, accuracy=35.77, wps=13526, ups=1.64, wpb=8257.2, bsz=295.2, num_updates=15600, lr=0.000113228, gnorm=3.81, clip=4, loss_scale=0.5, train_wall=60, gb_free=14.8, wall=13212
2023-09-03 06:43:47 | INFO | train_inner | epoch 011:    972 / 1474 loss=2.875, trans_loss=6.005, nll_loss=3.565, w2v_ctc_loss=1.459, task_loss=2.758, task_loss_gen=3.414, contrastive_loss=0, total=4151.98, n_correct=1503.02, ppl=11.83, accuracy=36.2, wps=13618.5, ups=1.64, wpb=8304, bsz=305, num_updates=15700, lr=0.000112867, gnorm=1.784, clip=1, loss_scale=0.5, train_wall=60, gb_free=14.7, wall=13273
2023-09-03 06:44:48 | INFO | train_inner | epoch 011:   1072 / 1474 loss=2.879, trans_loss=5.999, nll_loss=3.557, w2v_ctc_loss=1.48, task_loss=2.29, task_loss_gen=3.444, contrastive_loss=0, total=4152.41, n_correct=1507.51, ppl=11.77, accuracy=36.304, wps=13590.5, ups=1.64, wpb=8304.8, bsz=311, num_updates=15800, lr=0.000112509, gnorm=2.054, clip=4, loss_scale=0.5, train_wall=60, gb_free=15.7, wall=13334
2023-09-03 06:45:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-03 06:45:50 | INFO | train_inner | epoch 011:   1173 / 1474 loss=2.874, trans_loss=6.008, nll_loss=3.57, w2v_ctc_loss=1.453, task_loss=2.634, task_loss_gen=3.464, contrastive_loss=0, total=4170.61, n_correct=1507.99, ppl=11.87, accuracy=36.158, wps=13417.8, ups=1.61, wpb=8341.2, bsz=309.9, num_updates=15900, lr=0.000112154, gnorm=2.742, clip=3, loss_scale=0.25, train_wall=62, gb_free=14.4, wall=13396
2023-09-03 06:46:53 | INFO | train_inner | epoch 011:   1273 / 1474 loss=2.897, trans_loss=6.008, nll_loss=3.57, w2v_ctc_loss=1.531, task_loss=2.61, task_loss_gen=3.333, contrastive_loss=0, total=4164.89, n_correct=1503.36, ppl=11.87, accuracy=36.096, wps=13367.5, ups=1.6, wpb=8329.8, bsz=311.8, num_updates=16000, lr=0.000111803, gnorm=3.982, clip=8, loss_scale=0.25, train_wall=62, gb_free=16, wall=13459
2023-09-03 06:46:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:5')
2023-09-03 06:47:24 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.591 | trans_loss 7.266 | nll_loss 5.158 | w2v_ctc_loss 2.263 | task_loss 13.224 | task_loss_gen 9.776 | contrastive_loss 0 | total 4003.4 | n_correct 1424.1 | ppl 35.7 | accuracy 35.572 | uer 33.839 | wer 35.096 | raw_wer 35.096 | bleu 0.15 | wps 1802.1 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 0.25
2023-09-03 06:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-09-03 06:47:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-03 06:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-03 06:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 0.15) (writing took 9.063102565996815 seconds)
2023-09-03 06:48:35 | INFO | train_inner | epoch 011:   1373 / 1474 loss=2.878, trans_loss=6.002, nll_loss=3.561, w2v_ctc_loss=1.489, task_loss=2.958, task_loss_gen=3.147, contrastive_loss=0, total=4180.06, n_correct=1515.89, ppl=11.81, accuracy=36.265, wps=8187.1, ups=0.98, wpb=8360.1, bsz=322.9, num_updates=16100, lr=0.000111456, gnorm=4.464, clip=5, loss_scale=0.25, train_wall=61, gb_free=15.6, wall=13561
2023-09-03 06:49:36 | INFO | train_inner | epoch 011:   1473 / 1474 loss=2.901, trans_loss=6.007, nll_loss=3.569, w2v_ctc_loss=1.552, task_loss=2.606, task_loss_gen=3.294, contrastive_loss=0, total=4166.03, n_correct=1508.7, ppl=11.87, accuracy=36.214, wps=13718.3, ups=1.65, wpb=8332.1, bsz=315.3, num_updates=16200, lr=0.000111111, gnorm=6.469, clip=17, loss_scale=0.25, train_wall=60, gb_free=16, wall=13621
2023-09-03 06:49:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 06:50:08 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.608 | trans_loss 7.25 | nll_loss 5.142 | w2v_ctc_loss 2.355 | task_loss 12.644 | task_loss_gen 9.598 | contrastive_loss 0 | total 4003.4 | n_correct 1433.8 | ppl 35.31 | accuracy 35.815 | uer 34.449 | wer 35.808 | raw_wer 35.808 | bleu 0.17 | wps 1747.2 | wpb 4003.4 | bsz 141.8 | num_updates 16201 | best_bleu 0.25
2023-09-03 06:50:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16201 updates
2023-09-03 06:50:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1700.pt
2023-09-03 06:50:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1700.pt
2023-09-03 06:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1700.pt (epoch 11 @ 16201 updates, score 0.17) (writing took 8.37371181504568 seconds)
2023-09-03 06:50:16 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-03 06:50:16 | INFO | train | epoch 011 | loss 2.879 | trans_loss 5.505 | nll_loss 3.269 | w2v_ctc_loss 1.581 | task_loss 2.452 | task_loss_gen 3.153 | contrastive_loss 0 | total 4138.57 | n_correct 1496.93 | ppl 9.64 | accuracy 36.17 | wps 12612.7 | ups 1.4 | wpb 9032.1 | bsz 333.8 | num_updates 16201 | lr 0.000111108 | gnorm 3.643 | clip 5.9 | loss_scale 0.25 | train_wall 956 | gb_free 16.9 | wall 13662
2023-09-03 06:50:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 06:50:16 | INFO | fairseq.trainer | begin training epoch 12
2023-09-03 06:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 06:51:24 | INFO | train_inner | epoch 012:     99 / 1474 loss=2.883, trans_loss=5.98, nll_loss=3.533, w2v_ctc_loss=1.52, task_loss=2.749, task_loss_gen=3.191, contrastive_loss=0, total=4148.71, n_correct=1516.71, ppl=11.58, accuracy=36.559, wps=7687.9, ups=0.93, wpb=8297.4, bsz=315.5, num_updates=16300, lr=0.00011077, gnorm=4.823, clip=7, loss_scale=0.25, train_wall=60, gb_free=16.3, wall=13729
2023-09-03 06:52:25 | INFO | train_inner | epoch 012:    199 / 1474 loss=2.911, trans_loss=5.988, nll_loss=3.543, w2v_ctc_loss=1.585, task_loss=2.66, task_loss_gen=3.455, contrastive_loss=0, total=4140.57, n_correct=1505.05, ppl=11.66, accuracy=36.349, wps=13426.6, ups=1.62, wpb=8281.1, bsz=300.4, num_updates=16400, lr=0.000110432, gnorm=5.146, clip=14, loss_scale=0.25, train_wall=61, gb_free=17.2, wall=13791
2023-09-03 06:53:27 | INFO | train_inner | epoch 012:    299 / 1474 loss=2.905, trans_loss=5.985, nll_loss=3.54, w2v_ctc_loss=1.587, task_loss=2.591, task_loss_gen=3.316, contrastive_loss=0, total=4199.51, n_correct=1531.81, ppl=11.63, accuracy=36.476, wps=13671.9, ups=1.63, wpb=8399, bsz=318.6, num_updates=16500, lr=0.000110096, gnorm=7.006, clip=13, loss_scale=0.25, train_wall=61, gb_free=16.6, wall=13853
2023-09-03 06:54:28 | INFO | train_inner | epoch 012:    399 / 1474 loss=2.926, trans_loss=5.998, nll_loss=3.555, w2v_ctc_loss=1.623, task_loss=2.328, task_loss_gen=3.606, contrastive_loss=0, total=4135.31, n_correct=1501.41, ppl=11.75, accuracy=36.307, wps=13449, ups=1.63, wpb=8270.6, bsz=301.3, num_updates=16600, lr=0.000109764, gnorm=5.182, clip=13, loss_scale=0.25, train_wall=61, gb_free=16.9, wall=13914
2023-09-03 06:55:29 | INFO | train_inner | epoch 012:    499 / 1474 loss=2.921, trans_loss=5.999, nll_loss=3.558, w2v_ctc_loss=1.609, task_loss=2.48, task_loss_gen=3.545, contrastive_loss=0, total=4087.67, n_correct=1485.68, ppl=11.78, accuracy=36.345, wps=13427.3, ups=1.64, wpb=8175.3, bsz=299.4, num_updates=16700, lr=0.000109435, gnorm=6.097, clip=9, loss_scale=0.25, train_wall=60, gb_free=14.5, wall=13975
2023-09-03 06:56:31 | INFO | train_inner | epoch 012:    599 / 1474 loss=2.913, trans_loss=5.996, nll_loss=3.553, w2v_ctc_loss=1.608, task_loss=2.383, task_loss_gen=3.229, contrastive_loss=0, total=4218.35, n_correct=1538.02, ppl=11.74, accuracy=36.46, wps=13563.3, ups=1.61, wpb=8436.7, bsz=321.4, num_updates=16800, lr=0.000109109, gnorm=4.8, clip=9, loss_scale=0.25, train_wall=62, gb_free=15.9, wall=14037
2023-09-03 06:57:33 | INFO | train_inner | epoch 012:    699 / 1474 loss=2.898, trans_loss=5.983, nll_loss=3.537, w2v_ctc_loss=1.58, task_loss=2.757, task_loss_gen=3.196, contrastive_loss=0, total=4191.35, n_correct=1534.17, ppl=11.6, accuracy=36.603, wps=13678.7, ups=1.63, wpb=8382.7, bsz=322.4, num_updates=16900, lr=0.000108786, gnorm=5.598, clip=19, loss_scale=0.25, train_wall=61, gb_free=16.2, wall=14098
2023-09-03 06:58:34 | INFO | train_inner | epoch 012:    799 / 1474 loss=2.911, trans_loss=5.988, nll_loss=3.543, w2v_ctc_loss=1.587, task_loss=2.975, task_loss_gen=3.39, contrastive_loss=0, total=4083.28, n_correct=1483.99, ppl=11.65, accuracy=36.343, wps=13266.9, ups=1.62, wpb=8166.6, bsz=296.7, num_updates=17000, lr=0.000108465, gnorm=3.829, clip=6, loss_scale=0.25, train_wall=61, gb_free=16.9, wall=14160
2023-09-03 06:59:36 | INFO | train_inner | epoch 012:    899 / 1474 loss=2.911, trans_loss=5.989, nll_loss=3.544, w2v_ctc_loss=1.595, task_loss=2.748, task_loss_gen=3.447, contrastive_loss=0, total=4175.19, n_correct=1519.32, ppl=11.67, accuracy=36.389, wps=13525.9, ups=1.62, wpb=8350.4, bsz=305.8, num_updates=17100, lr=0.000108148, gnorm=4.281, clip=10, loss_scale=0.25, train_wall=61, gb_free=16.9, wall=14222
2023-09-03 07:00:37 | INFO | train_inner | epoch 012:    999 / 1474 loss=2.953, trans_loss=5.997, nll_loss=3.555, w2v_ctc_loss=1.718, task_loss=3.237, task_loss_gen=3.603, contrastive_loss=0, total=4117.25, n_correct=1489.07, ppl=11.75, accuracy=36.167, wps=13443.4, ups=1.63, wpb=8234.5, bsz=302.4, num_updates=17200, lr=0.000107833, gnorm=7.67, clip=25, loss_scale=0.25, train_wall=60, gb_free=16.2, wall=14283
2023-09-03 07:01:39 | INFO | train_inner | epoch 012:   1099 / 1474 loss=2.94, trans_loss=5.995, nll_loss=3.551, w2v_ctc_loss=1.671, task_loss=2.758, task_loss_gen=3.512, contrastive_loss=0, total=4063.87, n_correct=1477.94, ppl=11.72, accuracy=36.368, wps=13244.2, ups=1.63, wpb=8127.7, bsz=291.1, num_updates=17300, lr=0.000107521, gnorm=3.846, clip=8, loss_scale=0.25, train_wall=61, gb_free=13, wall=14344
2023-09-03 07:02:40 | INFO | train_inner | epoch 012:   1199 / 1474 loss=2.918, trans_loss=6.002, nll_loss=3.562, w2v_ctc_loss=1.613, task_loss=2.437, task_loss_gen=3.387, contrastive_loss=0, total=4185.74, n_correct=1519.58, ppl=11.81, accuracy=36.304, wps=13657, ups=1.63, wpb=8371.5, bsz=318.1, num_updates=17400, lr=0.000107211, gnorm=6.102, clip=8, loss_scale=0.25, train_wall=61, gb_free=16.4, wall=14406
2023-09-03 07:03:42 | INFO | train_inner | epoch 012:   1299 / 1474 loss=2.941, trans_loss=5.999, nll_loss=3.557, w2v_ctc_loss=1.667, task_loss=2.854, task_loss_gen=3.826, contrastive_loss=0, total=4072.36, n_correct=1474.71, ppl=11.77, accuracy=36.213, wps=13177.8, ups=1.62, wpb=8144.7, bsz=285.7, num_updates=17500, lr=0.000106904, gnorm=4.773, clip=9, loss_scale=0.25, train_wall=61, gb_free=16.1, wall=14467
2023-09-03 07:04:44 | INFO | train_inner | epoch 012:   1399 / 1474 loss=2.926, trans_loss=6.002, nll_loss=3.561, w2v_ctc_loss=1.64, task_loss=2.824, task_loss_gen=3.427, contrastive_loss=0, total=4138.49, n_correct=1499.4, ppl=11.81, accuracy=36.231, wps=13342.4, ups=1.61, wpb=8277, bsz=305.6, num_updates=17600, lr=0.0001066, gnorm=6.375, clip=12, loss_scale=0.25, train_wall=61, gb_free=14.1, wall=14529
2023-09-03 07:05:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:06:04 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 5.653 | trans_loss 7.247 | nll_loss 5.138 | w2v_ctc_loss 2.512 | task_loss 9.584 | task_loss_gen 9.142 | contrastive_loss 0 | total 4003.4 | n_correct 1431.7 | ppl 35.22 | accuracy 35.762 | uer 37.714 | wer 38.761 | raw_wer 38.761 | bleu 0.13 | wps 1490.9 | wpb 4003.4 | bsz 141.8 | num_updates 17675 | best_bleu 0.25
2023-09-03 07:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17675 updates
2023-09-03 07:06:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 07:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 07:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt (epoch 12 @ 17675 updates, score 0.13) (writing took 5.957744694955181 seconds)
2023-09-03 07:06:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-03 07:06:10 | INFO | train | epoch 012 | loss 2.92 | trans_loss 5.994 | nll_loss 3.55 | w2v_ctc_loss 1.618 | task_loss 2.694 | task_loss_gen 3.438 | contrastive_loss 0 | total 4138.65 | n_correct 1504.49 | ppl 11.72 | accuracy 36.352 | wps 12793.6 | ups 1.55 | wpb 8277.3 | bsz 305.7 | num_updates 17675 | lr 0.000106374 | gnorm 5.498 | clip 11.9 | loss_scale 0.25 | train_wall 895 | gb_free 12.5 | wall 14616
2023-09-03 07:06:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 07:06:10 | INFO | fairseq.trainer | begin training epoch 13
2023-09-03 07:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 07:06:32 | INFO | train_inner | epoch 013:     25 / 1474 loss=2.946, trans_loss=6.004, nll_loss=3.564, w2v_ctc_loss=1.691, task_loss=2.685, task_loss_gen=3.529, contrastive_loss=0, total=4094.69, n_correct=1481.9, ppl=11.83, accuracy=36.191, wps=7528.9, ups=0.92, wpb=8189.4, bsz=297.7, num_updates=17700, lr=0.000106299, gnorm=7.792, clip=18, loss_scale=0.25, train_wall=60, gb_free=17, wall=14638
2023-09-03 07:07:34 | INFO | train_inner | epoch 013:    125 / 1474 loss=2.94, trans_loss=5.984, nll_loss=3.537, w2v_ctc_loss=1.689, task_loss=2.907, task_loss_gen=3.433, contrastive_loss=0, total=4174.39, n_correct=1524.13, ppl=11.61, accuracy=36.511, wps=13566.9, ups=1.63, wpb=8348.8, bsz=303.7, num_updates=17800, lr=0.000106, gnorm=6.309, clip=16, loss_scale=0.25, train_wall=61, gb_free=16.1, wall=14700
2023-09-03 07:08:36 | INFO | train_inner | epoch 013:    225 / 1474 loss=2.918, trans_loss=5.974, nll_loss=3.525, w2v_ctc_loss=1.658, task_loss=2.417, task_loss_gen=3.25, contrastive_loss=0, total=4188.05, n_correct=1532.14, ppl=11.51, accuracy=36.584, wps=13607.9, ups=1.62, wpb=8376.1, bsz=326.2, num_updates=17900, lr=0.000105703, gnorm=5.341, clip=10, loss_scale=0.25, train_wall=61, gb_free=15.4, wall=14761
2023-09-03 07:09:37 | INFO | train_inner | epoch 013:    325 / 1474 loss=2.918, trans_loss=5.974, nll_loss=3.524, w2v_ctc_loss=1.622, task_loss=2.812, task_loss_gen=3.573, contrastive_loss=0, total=4099.96, n_correct=1499.36, ppl=11.5, accuracy=36.57, wps=13313.8, ups=1.62, wpb=8199.9, bsz=292.3, num_updates=18000, lr=0.000105409, gnorm=3.634, clip=5, loss_scale=0.5, train_wall=61, gb_free=16.8, wall=14823
2023-09-03 07:09:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:10:09 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 5.61 | trans_loss 7.251 | nll_loss 5.142 | w2v_ctc_loss 2.361 | task_loss 7.81 | task_loss_gen 9.217 | contrastive_loss 0 | total 4003.4 | n_correct 1432.3 | ppl 35.32 | accuracy 35.777 | uer 35.686 | wer 36.889 | raw_wer 36.889 | bleu 0.19 | wps 1744.7 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 0.25
2023-09-03 07:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-09-03 07:10:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-03 07:10:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-03 07:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 0.19) (writing took 7.844527242006734 seconds)
2023-09-03 07:10:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-03 07:11:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-03 07:11:20 | INFO | train_inner | epoch 013:    427 / 1474 loss=2.888, trans_loss=5.967, nll_loss=3.516, w2v_ctc_loss=1.561, task_loss=2.244, task_loss_gen=3.283, contrastive_loss=0, total=4199.49, n_correct=1544.33, ppl=11.44, accuracy=36.774, wps=8176.6, ups=0.97, wpb=8399, bsz=321.7, num_updates=18100, lr=0.000105118, gnorm=3.715, clip=8, loss_scale=0.125, train_wall=62, gb_free=16.6, wall=14926
2023-09-03 07:12:21 | INFO | train_inner | epoch 013:    527 / 1474 loss=2.912, trans_loss=5.979, nll_loss=3.531, w2v_ctc_loss=1.63, task_loss=2.622, task_loss_gen=3.327, contrastive_loss=0, total=4193.29, n_correct=1535.48, ppl=11.56, accuracy=36.618, wps=13696.5, ups=1.63, wpb=8386.6, bsz=320, num_updates=18200, lr=0.000104828, gnorm=17.383, clip=41, loss_scale=0.125, train_wall=60, gb_free=17.3, wall=14987
2023-09-03 07:13:22 | INFO | train_inner | epoch 013:    627 / 1474 loss=2.957, trans_loss=5.987, nll_loss=3.541, w2v_ctc_loss=1.756, task_loss=2.839, task_loss_gen=3.323, contrastive_loss=0, total=4146.26, n_correct=1511.53, ppl=11.64, accuracy=36.455, wps=13555.9, ups=1.63, wpb=8292.5, bsz=303.5, num_updates=18300, lr=0.000104542, gnorm=8.126, clip=15, loss_scale=0.125, train_wall=60, gb_free=16.5, wall=15048
2023-09-03 07:14:24 | INFO | train_inner | epoch 013:    727 / 1474 loss=2.946, trans_loss=5.992, nll_loss=3.548, w2v_ctc_loss=1.691, task_loss=3.016, task_loss_gen=3.616, contrastive_loss=0, total=4109.15, n_correct=1494.63, ppl=11.69, accuracy=36.373, wps=13358.3, ups=1.63, wpb=8218.3, bsz=290.1, num_updates=18400, lr=0.000104257, gnorm=7.993, clip=13, loss_scale=0.125, train_wall=61, gb_free=12.4, wall=15110
2023-09-03 07:15:26 | INFO | train_inner | epoch 013:    827 / 1474 loss=2.932, trans_loss=5.983, nll_loss=3.536, w2v_ctc_loss=1.679, task_loss=2.885, task_loss_gen=3.433, contrastive_loss=0, total=4124.47, n_correct=1506.97, ppl=11.6, accuracy=36.537, wps=13282.6, ups=1.61, wpb=8248.9, bsz=305.2, num_updates=18500, lr=0.000103975, gnorm=9.723, clip=31, loss_scale=0.125, train_wall=61, gb_free=16.5, wall=15172
2023-09-03 07:16:27 | INFO | train_inner | epoch 013:    927 / 1474 loss=2.931, trans_loss=5.993, nll_loss=3.549, w2v_ctc_loss=1.652, task_loss=2.828, task_loss_gen=3.446, contrastive_loss=0, total=4093.34, n_correct=1487.56, ppl=11.71, accuracy=36.341, wps=13399.3, ups=1.64, wpb=8186.7, bsz=294.1, num_updates=18600, lr=0.000103695, gnorm=7.404, clip=13, loss_scale=0.125, train_wall=60, gb_free=17.6, wall=15233
2023-09-03 07:17:28 | INFO | train_inner | epoch 013:   1027 / 1474 loss=2.956, trans_loss=5.993, nll_loss=3.548, w2v_ctc_loss=1.736, task_loss=2.797, task_loss_gen=3.499, contrastive_loss=0, total=4106.92, n_correct=1491.5, ppl=11.7, accuracy=36.317, wps=13374, ups=1.63, wpb=8213.8, bsz=298.7, num_updates=18700, lr=0.000103418, gnorm=11.396, clip=17, loss_scale=0.125, train_wall=61, gb_free=17.4, wall=15294
2023-09-03 07:18:29 | INFO | train_inner | epoch 013:   1127 / 1474 loss=2.952, trans_loss=5.992, nll_loss=3.548, w2v_ctc_loss=1.722, task_loss=2.841, task_loss_gen=3.405, contrastive_loss=0, total=4080.47, n_correct=1478.79, ppl=11.69, accuracy=36.241, wps=13452.1, ups=1.65, wpb=8160.9, bsz=299.2, num_updates=18800, lr=0.000103142, gnorm=9.3, clip=22, loss_scale=0.125, train_wall=60, gb_free=14.2, wall=15355
2023-09-03 07:19:30 | INFO | train_inner | epoch 013:   1227 / 1474 loss=2.959, trans_loss=5.998, nll_loss=3.554, w2v_ctc_loss=1.737, task_loss=2.872, task_loss_gen=3.646, contrastive_loss=0, total=4106.99, n_correct=1493.07, ppl=11.75, accuracy=36.354, wps=13387.9, ups=1.63, wpb=8214, bsz=293.5, num_updates=18900, lr=0.000102869, gnorm=9.156, clip=19, loss_scale=0.125, train_wall=61, gb_free=10.3, wall=15416
2023-09-03 07:20:32 | INFO | train_inner | epoch 013:   1327 / 1474 loss=2.95, trans_loss=5.987, nll_loss=3.541, w2v_ctc_loss=1.741, task_loss=2.697, task_loss_gen=3.263, contrastive_loss=0, total=4137.27, n_correct=1507.95, ppl=11.64, accuracy=36.448, wps=13399.1, ups=1.62, wpb=8274.5, bsz=314.4, num_updates=19000, lr=0.000102598, gnorm=7.777, clip=21, loss_scale=0.125, train_wall=61, gb_free=15, wall=15478
2023-09-03 07:21:34 | INFO | train_inner | epoch 013:   1427 / 1474 loss=2.949, trans_loss=5.987, nll_loss=3.542, w2v_ctc_loss=1.73, task_loss=3.26, task_loss_gen=3.581, contrastive_loss=0, total=4173.15, n_correct=1518.24, ppl=11.65, accuracy=36.381, wps=13570.9, ups=1.63, wpb=8346.3, bsz=309.4, num_updates=19100, lr=0.000102329, gnorm=15.274, clip=52, loss_scale=0.125, train_wall=61, gb_free=14.6, wall=15540
2023-09-03 07:22:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:22:37 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 5.675 | trans_loss 7.241 | nll_loss 5.131 | w2v_ctc_loss 2.599 | task_loss 9.285 | task_loss_gen 9.201 | contrastive_loss 0 | total 4003.4 | n_correct 1434.5 | ppl 35.04 | accuracy 35.832 | uer 37.868 | wer 38.966 | raw_wer 38.966 | bleu 0.16 | wps 1543 | wpb 4003.4 | bsz 141.8 | num_updates 19147 | best_bleu 0.25
2023-09-03 07:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19147 updates
2023-09-03 07:22:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1604.pt
2023-09-03 07:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1604.pt
2023-09-03 07:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1604.pt (epoch 13 @ 19147 updates, score 0.16) (writing took 7.083583532017656 seconds)
2023-09-03 07:22:44 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-03 07:22:44 | INFO | train | epoch 013 | loss 2.936 | trans_loss 5.985 | nll_loss 3.538 | w2v_ctc_loss 1.686 | task_loss 2.774 | task_loss_gen 3.417 | contrastive_loss 0 | total 4138.68 | n_correct 1509.54 | ppl 11.62 | accuracy 36.474 | wps 12258.7 | ups 1.48 | wpb 8277.4 | bsz 305.6 | num_updates 19147 | lr 0.000102203 | gnorm 8.688 | clip 19.9 | loss_scale 0.125 | train_wall 894 | gb_free 17.4 | wall 15610
2023-09-03 07:22:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 07:22:44 | INFO | fairseq.trainer | begin training epoch 14
2023-09-03 07:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 07:23:24 | INFO | train_inner | epoch 014:     53 / 1474 loss=2.928, trans_loss=5.969, nll_loss=3.518, w2v_ctc_loss=1.693, task_loss=2.528, task_loss_gen=3.034, contrastive_loss=0, total=4181.61, n_correct=1535.72, ppl=11.46, accuracy=36.726, wps=7592.6, ups=0.91, wpb=8363.2, bsz=324.7, num_updates=19200, lr=0.000102062, gnorm=5.449, clip=10, loss_scale=0.125, train_wall=60, gb_free=15.5, wall=15650
2023-09-03 07:24:24 | INFO | train_inner | epoch 014:    153 / 1474 loss=2.929, trans_loss=5.968, nll_loss=3.517, w2v_ctc_loss=1.673, task_loss=3.035, task_loss_gen=3.394, contrastive_loss=0, total=4075.71, n_correct=1494.2, ppl=11.45, accuracy=36.661, wps=13465.4, ups=1.65, wpb=8151.4, bsz=297.3, num_updates=19300, lr=0.000101797, gnorm=9.581, clip=22, loss_scale=0.125, train_wall=60, gb_free=15.7, wall=15710
2023-09-03 07:25:26 | INFO | train_inner | epoch 014:    253 / 1474 loss=2.939, trans_loss=5.972, nll_loss=3.521, w2v_ctc_loss=1.705, task_loss=2.945, task_loss_gen=3.42, contrastive_loss=0, total=4123.23, n_correct=1510.14, ppl=11.48, accuracy=36.625, wps=13451.3, ups=1.63, wpb=8246.5, bsz=301.4, num_updates=19400, lr=0.000101535, gnorm=9.918, clip=22, loss_scale=0.125, train_wall=61, gb_free=16.8, wall=15772
2023-09-03 07:26:27 | INFO | train_inner | epoch 014:    353 / 1474 loss=2.949, trans_loss=5.973, nll_loss=3.522, w2v_ctc_loss=1.756, task_loss=2.683, task_loss_gen=3.269, contrastive_loss=0, total=4153.01, n_correct=1520.86, ppl=11.49, accuracy=36.621, wps=13509.8, ups=1.63, wpb=8306, bsz=312.8, num_updates=19500, lr=0.000101274, gnorm=9.804, clip=18, loss_scale=0.125, train_wall=61, gb_free=16.1, wall=15833
2023-09-03 07:27:29 | INFO | train_inner | epoch 014:    453 / 1474 loss=2.94, trans_loss=5.971, nll_loss=3.52, w2v_ctc_loss=1.724, task_loss=2.888, task_loss_gen=3.346, contrastive_loss=0, total=4152.7, n_correct=1526.47, ppl=11.47, accuracy=36.758, wps=13512.3, ups=1.63, wpb=8305.4, bsz=306.1, num_updates=19600, lr=0.000101015, gnorm=10.471, clip=21, loss_scale=0.125, train_wall=61, gb_free=16.9, wall=15895
2023-09-03 07:28:31 | INFO | train_inner | epoch 014:    553 / 1474 loss=2.947, trans_loss=5.981, nll_loss=3.533, w2v_ctc_loss=1.701, task_loss=2.767, task_loss_gen=3.745, contrastive_loss=0, total=4060.33, n_correct=1474.51, ppl=11.58, accuracy=36.315, wps=13052.3, ups=1.61, wpb=8120.7, bsz=284.9, num_updates=19700, lr=0.000100759, gnorm=7.881, clip=13, loss_scale=0.125, train_wall=61, gb_free=17.4, wall=15957
2023-09-03 07:29:33 | INFO | train_inner | epoch 014:    653 / 1474 loss=2.953, trans_loss=5.98, nll_loss=3.532, w2v_ctc_loss=1.757, task_loss=2.514, task_loss_gen=3.281, contrastive_loss=0, total=4183.92, n_correct=1531.41, ppl=11.57, accuracy=36.602, wps=13577.7, ups=1.62, wpb=8367.8, bsz=314.5, num_updates=19800, lr=0.000100504, gnorm=10.218, clip=20, loss_scale=0.125, train_wall=61, gb_free=15.4, wall=16018
2023-09-03 07:30:34 | INFO | train_inner | epoch 014:    753 / 1474 loss=2.951, trans_loss=5.977, nll_loss=3.527, w2v_ctc_loss=1.744, task_loss=2.866, task_loss_gen=3.362, contrastive_loss=0, total=4113.6, n_correct=1501.78, ppl=11.52, accuracy=36.508, wps=13507.6, ups=1.64, wpb=8227.2, bsz=303.9, num_updates=19900, lr=0.000100251, gnorm=11.284, clip=43, loss_scale=0.125, train_wall=60, gb_free=16.5, wall=16079
2023-09-03 07:31:35 | INFO | train_inner | epoch 014:    853 / 1474 loss=2.935, trans_loss=5.965, nll_loss=3.513, w2v_ctc_loss=1.718, task_loss=2.643, task_loss_gen=3.202, contrastive_loss=0, total=4191.56, n_correct=1543.28, ppl=11.41, accuracy=36.819, wps=13602.9, ups=1.62, wpb=8383.1, bsz=320.3, num_updates=20000, lr=0.0001, gnorm=7.582, clip=14, loss_scale=0.125, train_wall=61, gb_free=16.3, wall=16141
2023-09-03 07:31:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:32:06 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.687 | trans_loss 7.255 | nll_loss 5.139 | w2v_ctc_loss 2.607 | task_loss 9.459 | task_loss_gen 9.188 | contrastive_loss 0 | total 4003.4 | n_correct 1433.6 | ppl 35.23 | accuracy 35.81 | uer 36.713 | wer 37.821 | raw_wer 37.821 | bleu 0.17 | wps 1800 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 0.25
2023-09-03 07:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-09-03 07:32:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-03 07:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-03 07:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 0.17) (writing took 8.05925972800469 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:0')
2023-09-03 07:33:16 | INFO | train_inner | epoch 014:    953 / 1474 loss=2.928, trans_loss=5.979, nll_loss=3.53, w2v_ctc_loss=1.669, task_loss=2.714, task_loss_gen=3.421, contrastive_loss=0, total=4161.21, n_correct=1518.7, ppl=11.55, accuracy=36.497, wps=8231.2, ups=0.99, wpb=8322.4, bsz=308.9, num_updates=20100, lr=9.97509e-05, gnorm=7.869, clip=11, loss_scale=0.125, train_wall=61, gb_free=12.3, wall=16242
2023-09-03 07:34:18 | INFO | train_inner | epoch 014:   1053 / 1474 loss=2.921, trans_loss=5.973, nll_loss=3.523, w2v_ctc_loss=1.654, task_loss=2.662, task_loss_gen=3.449, contrastive_loss=0, total=4152.42, n_correct=1525.69, ppl=11.5, accuracy=36.742, wps=13361.2, ups=1.61, wpb=8304.8, bsz=301.9, num_updates=20200, lr=9.95037e-05, gnorm=7.23, clip=11, loss_scale=0.25, train_wall=61, gb_free=15.4, wall=16304
2023-09-03 07:35:20 | INFO | train_inner | epoch 014:   1153 / 1474 loss=2.935, trans_loss=5.966, nll_loss=3.514, w2v_ctc_loss=1.718, task_loss=2.717, task_loss_gen=3.341, contrastive_loss=0, total=4220.07, n_correct=1546.55, ppl=11.42, accuracy=36.647, wps=13627, ups=1.61, wpb=8440.1, bsz=325, num_updates=20300, lr=9.92583e-05, gnorm=6.522, clip=21, loss_scale=0.25, train_wall=61, gb_free=15.3, wall=16366
2023-09-03 07:36:21 | INFO | train_inner | epoch 014:   1253 / 1474 loss=2.941, trans_loss=5.981, nll_loss=3.534, w2v_ctc_loss=1.679, task_loss=3.035, task_loss_gen=3.823, contrastive_loss=0, total=4034.27, n_correct=1471.01, ppl=11.59, accuracy=36.463, wps=13225.7, ups=1.64, wpb=8068.5, bsz=276.5, num_updates=20400, lr=9.90148e-05, gnorm=4.516, clip=11, loss_scale=0.25, train_wall=60, gb_free=16, wall=16427
2023-09-03 07:37:23 | INFO | train_inner | epoch 014:   1353 / 1474 loss=2.915, trans_loss=5.971, nll_loss=3.521, w2v_ctc_loss=1.639, task_loss=2.397, task_loss_gen=3.299, contrastive_loss=0, total=4201.97, n_correct=1545.98, ppl=11.48, accuracy=36.792, wps=13693.8, ups=1.63, wpb=8403.9, bsz=315.5, num_updates=20500, lr=9.8773e-05, gnorm=4.576, clip=10, loss_scale=0.25, train_wall=61, gb_free=11.3, wall=16489
2023-09-03 07:38:24 | INFO | train_inner | epoch 014:   1453 / 1474 loss=2.947, trans_loss=5.981, nll_loss=3.533, w2v_ctc_loss=1.728, task_loss=2.391, task_loss_gen=3.477, contrastive_loss=0, total=4121.07, n_correct=1505.45, ppl=11.58, accuracy=36.531, wps=13528.1, ups=1.64, wpb=8242.1, bsz=304.5, num_updates=20600, lr=9.85329e-05, gnorm=8.244, clip=21, loss_scale=0.25, train_wall=60, gb_free=11.9, wall=16549
2023-09-03 07:38:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:7')
2023-09-03 07:39:09 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.695 | trans_loss 7.243 | nll_loss 5.13 | w2v_ctc_loss 2.662 | task_loss 10.267 | task_loss_gen 9.253 | contrastive_loss 0 | total 4003.4 | n_correct 1432.8 | ppl 35.01 | accuracy 35.79 | uer 37.958 | wer 38.921 | raw_wer 38.921 | bleu 0.15 | wps 1677.8 | wpb 4003.4 | bsz 141.8 | num_updates 20621 | best_bleu 0.25
2023-09-03 07:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20621 updates
2023-09-03 07:39:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 07:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 07:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt (epoch 14 @ 20621 updates, score 0.15) (writing took 7.133784489007667 seconds)
2023-09-03 07:39:16 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-03 07:39:16 | INFO | train | epoch 014 | loss 2.938 | trans_loss 5.974 | nll_loss 3.524 | w2v_ctc_loss 1.707 | task_loss 2.718 | task_loss_gen 3.401 | contrastive_loss 0 | total 4138.65 | n_correct 1515.28 | ppl 11.51 | accuracy 36.613 | wps 12294.2 | ups 1.49 | wpb 8277.3 | bsz 305.7 | num_updates 20621 | lr 9.84827e-05 | gnorm 8.069 | clip 17.9 | loss_scale 0.25 | train_wall 895 | gb_free 16 | wall 16602
2023-09-03 07:39:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 07:39:16 | INFO | fairseq.trainer | begin training epoch 15
2023-09-03 07:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 07:40:12 | INFO | train_inner | epoch 015:     79 / 1474 loss=2.945, trans_loss=5.968, nll_loss=3.516, w2v_ctc_loss=1.743, task_loss=2.393, task_loss_gen=3.424, contrastive_loss=0, total=4099.9, n_correct=1504.8, ppl=11.44, accuracy=36.703, wps=7568.6, ups=0.92, wpb=8199.8, bsz=302.3, num_updates=20700, lr=9.82946e-05, gnorm=5.84, clip=11, loss_scale=0.25, train_wall=60, gb_free=15.4, wall=16658
2023-09-03 07:41:13 | INFO | train_inner | epoch 015:    179 / 1474 loss=2.945, trans_loss=5.967, nll_loss=3.513, w2v_ctc_loss=1.735, task_loss=3.282, task_loss_gen=3.552, contrastive_loss=0, total=4103.05, n_correct=1506.68, ppl=11.42, accuracy=36.721, wps=13392.8, ups=1.63, wpb=8206.1, bsz=295.9, num_updates=20800, lr=9.80581e-05, gnorm=8.088, clip=30, loss_scale=0.25, train_wall=60, gb_free=17, wall=16719
2023-09-03 07:42:14 | INFO | train_inner | epoch 015:    279 / 1474 loss=2.934, trans_loss=5.966, nll_loss=3.513, w2v_ctc_loss=1.706, task_loss=2.818, task_loss_gen=3.224, contrastive_loss=0, total=4182.89, n_correct=1539.19, ppl=11.42, accuracy=36.797, wps=13701.2, ups=1.64, wpb=8365.8, bsz=311.1, num_updates=20900, lr=9.78232e-05, gnorm=4.054, clip=8, loss_scale=0.25, train_wall=60, gb_free=12.3, wall=16780
2023-09-03 07:43:15 | INFO | train_inner | epoch 015:    379 / 1474 loss=2.922, trans_loss=5.953, nll_loss=3.497, w2v_ctc_loss=1.677, task_loss=3.017, task_loss_gen=3.391, contrastive_loss=0, total=4169.5, n_correct=1539.3, ppl=11.29, accuracy=36.918, wps=13668.3, ups=1.64, wpb=8339, bsz=307.2, num_updates=21000, lr=9.759e-05, gnorm=6.419, clip=13, loss_scale=0.25, train_wall=60, gb_free=12.6, wall=16841
2023-09-03 07:44:17 | INFO | train_inner | epoch 015:    479 / 1474 loss=2.932, trans_loss=5.962, nll_loss=3.508, w2v_ctc_loss=1.697, task_loss=2.946, task_loss_gen=3.507, contrastive_loss=0, total=4090.54, n_correct=1506.26, ppl=11.37, accuracy=36.823, wps=13293.6, ups=1.62, wpb=8181.1, bsz=295.9, num_updates=21100, lr=9.73585e-05, gnorm=6.035, clip=10, loss_scale=0.25, train_wall=61, gb_free=16.5, wall=16903
2023-09-03 07:45:18 | INFO | train_inner | epoch 015:    579 / 1474 loss=2.936, trans_loss=5.961, nll_loss=3.508, w2v_ctc_loss=1.71, task_loss=2.698, task_loss_gen=3.623, contrastive_loss=0, total=4133.14, n_correct=1520.51, ppl=11.37, accuracy=36.788, wps=13457.6, ups=1.63, wpb=8266.3, bsz=298.1, num_updates=21200, lr=9.71286e-05, gnorm=5.383, clip=14, loss_scale=0.25, train_wall=61, gb_free=15.4, wall=16964
2023-09-03 07:46:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-03 07:46:20 | INFO | train_inner | epoch 015:    680 / 1474 loss=2.927, trans_loss=5.953, nll_loss=3.498, w2v_ctc_loss=1.693, task_loss=2.645, task_loss_gen=3.433, contrastive_loss=0, total=4144.87, n_correct=1531.62, ppl=11.3, accuracy=36.952, wps=13375.7, ups=1.61, wpb=8289.7, bsz=308.7, num_updates=21300, lr=9.69003e-05, gnorm=7.387, clip=12, loss_scale=0.125, train_wall=61, gb_free=11.9, wall=17026
2023-09-03 07:47:21 | INFO | train_inner | epoch 015:    780 / 1474 loss=2.933, trans_loss=5.968, nll_loss=3.516, w2v_ctc_loss=1.695, task_loss=2.581, task_loss_gen=3.489, contrastive_loss=0, total=4175.69, n_correct=1532.59, ppl=11.44, accuracy=36.703, wps=13658.1, ups=1.64, wpb=8351.4, bsz=304.3, num_updates=21400, lr=9.66736e-05, gnorm=10.434, clip=19, loss_scale=0.125, train_wall=60, gb_free=12.4, wall=17087
2023-09-03 07:48:22 | INFO | train_inner | epoch 015:    880 / 1474 loss=2.942, trans_loss=5.973, nll_loss=3.522, w2v_ctc_loss=1.709, task_loss=2.911, task_loss_gen=3.664, contrastive_loss=0, total=4053.89, n_correct=1483.88, ppl=11.49, accuracy=36.604, wps=13303.6, ups=1.64, wpb=8107.8, bsz=287.5, num_updates=21500, lr=9.64486e-05, gnorm=7.897, clip=28, loss_scale=0.125, train_wall=60, gb_free=15.3, wall=17148
2023-09-03 07:49:23 | INFO | train_inner | epoch 015:    980 / 1474 loss=2.941, trans_loss=5.971, nll_loss=3.52, w2v_ctc_loss=1.722, task_loss=2.56, task_loss_gen=3.414, contrastive_loss=0, total=4124.59, n_correct=1518.24, ppl=11.47, accuracy=36.809, wps=13539.4, ups=1.64, wpb=8249.2, bsz=302.7, num_updates=21600, lr=9.6225e-05, gnorm=10.614, clip=27, loss_scale=0.125, train_wall=60, gb_free=15.5, wall=17209
2023-09-03 07:50:26 | INFO | train_inner | epoch 015:   1080 / 1474 loss=2.911, trans_loss=5.964, nll_loss=3.511, w2v_ctc_loss=1.669, task_loss=2.428, task_loss_gen=3.18, contrastive_loss=0, total=4193.9, n_correct=1549.19, ppl=11.4, accuracy=36.939, wps=13494.2, ups=1.61, wpb=8387.8, bsz=328.3, num_updates=21700, lr=9.60031e-05, gnorm=9.396, clip=10, loss_scale=0.125, train_wall=62, gb_free=17.4, wall=17271
2023-09-03 07:51:27 | INFO | train_inner | epoch 015:   1180 / 1474 loss=2.922, trans_loss=5.973, nll_loss=3.523, w2v_ctc_loss=1.699, task_loss=2.427, task_loss_gen=3.072, contrastive_loss=0, total=4196.22, n_correct=1553.49, ppl=11.49, accuracy=37.021, wps=13740.9, ups=1.64, wpb=8392.4, bsz=328, num_updates=21800, lr=9.57826e-05, gnorm=11.223, clip=26, loss_scale=0.125, train_wall=60, gb_free=16.8, wall=17332
2023-09-03 07:52:28 | INFO | train_inner | epoch 015:   1280 / 1474 loss=2.952, trans_loss=5.978, nll_loss=3.528, w2v_ctc_loss=1.746, task_loss=2.817, task_loss_gen=3.514, contrastive_loss=0, total=4140.09, n_correct=1512.09, ppl=11.53, accuracy=36.523, wps=13531.4, ups=1.63, wpb=8280.2, bsz=301.9, num_updates=21900, lr=9.55637e-05, gnorm=9.982, clip=31, loss_scale=0.125, train_wall=60, gb_free=16.2, wall=17394
2023-09-03 07:53:30 | INFO | train_inner | epoch 015:   1380 / 1474 loss=2.946, trans_loss=5.972, nll_loss=3.522, w2v_ctc_loss=1.737, task_loss=2.985, task_loss_gen=3.526, contrastive_loss=0, total=4101.42, n_correct=1506.59, ppl=11.49, accuracy=36.733, wps=13237.8, ups=1.61, wpb=8202.8, bsz=293.1, num_updates=22000, lr=9.53463e-05, gnorm=11.125, clip=34, loss_scale=0.125, train_wall=61, gb_free=12.3, wall=17456
2023-09-03 07:53:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:54:01 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 5.708 | trans_loss 7.244 | nll_loss 5.13 | w2v_ctc_loss 2.702 | task_loss 30.186 | task_loss_gen 16.03 | contrastive_loss 0 | total 4003.4 | n_correct 1440.3 | ppl 35.01 | accuracy 35.977 | uer 39.094 | wer 39.98 | raw_wer 39.98 | bleu 0.17 | wps 1791.2 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 0.25
2023-09-03 07:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-09-03 07:54:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-03 07:54:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-03 07:54:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 0.17) (writing took 11.257220725005027 seconds)
2023-09-03 07:55:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 07:55:44 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 5.699 | trans_loss 7.237 | nll_loss 5.119 | w2v_ctc_loss 2.69 | task_loss 8.219 | task_loss_gen 9.148 | contrastive_loss 0 | total 4003.4 | n_correct 1441.9 | ppl 34.76 | accuracy 36.017 | uer 38.72 | wer 39.663 | raw_wer 39.663 | bleu 0.16 | wps 1569.6 | wpb 4003.4 | bsz 141.8 | num_updates 22094 | best_bleu 0.25
2023-09-03 07:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22094 updates
2023-09-03 07:55:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1603.pt
2023-09-03 07:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1603.pt
2023-09-03 07:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1603.pt (epoch 15 @ 22094 updates, score 0.16) (writing took 7.565560473012738 seconds)
2023-09-03 07:55:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-03 07:55:52 | INFO | train | epoch 015 | loss 2.934 | trans_loss 5.966 | nll_loss 3.514 | w2v_ctc_loss 1.709 | task_loss 2.752 | task_loss_gen 3.407 | contrastive_loss 0 | total 4139.07 | n_correct 1523.02 | ppl 11.42 | accuracy 36.796 | wps 12240.6 | ups 1.48 | wpb 8278.1 | bsz 305.8 | num_updates 22094 | lr 9.51432e-05 | gnorm 8.25 | clip 19.9 | loss_scale 0.125 | train_wall 892 | gb_free 16.6 | wall 17598
2023-09-03 07:55:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 07:55:53 | INFO | fairseq.trainer | begin training epoch 16
2023-09-03 07:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 07:56:04 | INFO | train_inner | epoch 016:      6 / 1474 loss=2.94, trans_loss=5.975, nll_loss=3.525, w2v_ctc_loss=1.733, task_loss=2.769, task_loss_gen=3.195, contrastive_loss=0, total=4154.54, n_correct=1527.88, ppl=11.51, accuracy=36.776, wps=5388.3, ups=0.65, wpb=8309.1, bsz=318.7, num_updates=22100, lr=9.51303e-05, gnorm=8.853, clip=21, loss_scale=0.125, train_wall=61, gb_free=17.5, wall=17610
2023-09-03 07:57:05 | INFO | train_inner | epoch 016:    106 / 1474 loss=2.943, trans_loss=5.953, nll_loss=3.497, w2v_ctc_loss=1.767, task_loss=2.723, task_loss_gen=3.221, contrastive_loss=0, total=4127.78, n_correct=1523.27, ppl=11.29, accuracy=36.903, wps=13502.1, ups=1.64, wpb=8255.6, bsz=315.5, num_updates=22200, lr=9.49158e-05, gnorm=8.811, clip=17, loss_scale=0.125, train_wall=60, gb_free=14.9, wall=17671
2023-09-03 07:58:07 | INFO | train_inner | epoch 016:    206 / 1474 loss=2.953, trans_loss=5.953, nll_loss=3.497, w2v_ctc_loss=1.774, task_loss=3.041, task_loss_gen=3.539, contrastive_loss=0, total=4098.72, n_correct=1512.94, ppl=11.29, accuracy=36.912, wps=13186.3, ups=1.61, wpb=8197.4, bsz=293.5, num_updates=22300, lr=9.47027e-05, gnorm=10.44, clip=39, loss_scale=0.125, train_wall=61, gb_free=11.1, wall=17733
2023-09-03 07:59:08 | INFO | train_inner | epoch 016:    306 / 1474 loss=2.944, trans_loss=5.957, nll_loss=3.502, w2v_ctc_loss=1.746, task_loss=2.804, task_loss_gen=3.412, contrastive_loss=0, total=4150.54, n_correct=1528.51, ppl=11.33, accuracy=36.827, wps=13636.2, ups=1.64, wpb=8301.1, bsz=306.6, num_updates=22400, lr=9.44911e-05, gnorm=10.85, clip=31, loss_scale=0.125, train_wall=60, gb_free=13.6, wall=17794
2023-09-03 08:00:09 | INFO | train_inner | epoch 016:    406 / 1474 loss=2.952, trans_loss=5.949, nll_loss=3.49, w2v_ctc_loss=1.771, task_loss=2.839, task_loss_gen=3.584, contrastive_loss=0, total=4083.73, n_correct=1504.31, ppl=11.24, accuracy=36.837, wps=13337.4, ups=1.63, wpb=8167.5, bsz=290.3, num_updates=22500, lr=9.42809e-05, gnorm=11.262, clip=21, loss_scale=0.125, train_wall=60, gb_free=16, wall=17855
2023-09-03 08:01:11 | INFO | train_inner | epoch 016:    506 / 1474 loss=2.941, trans_loss=5.957, nll_loss=3.502, w2v_ctc_loss=1.751, task_loss=2.633, task_loss_gen=3.296, contrastive_loss=0, total=4156.28, n_correct=1536.89, ppl=11.33, accuracy=36.978, wps=13481.3, ups=1.62, wpb=8312.6, bsz=316.9, num_updates=22600, lr=9.40721e-05, gnorm=10.171, clip=29, loss_scale=0.125, train_wall=61, gb_free=16.5, wall=17917
2023-09-03 08:02:12 | INFO | train_inner | epoch 016:    606 / 1474 loss=2.942, trans_loss=5.964, nll_loss=3.511, w2v_ctc_loss=1.731, task_loss=2.614, task_loss_gen=3.339, contrastive_loss=0, total=4143.19, n_correct=1527.37, ppl=11.4, accuracy=36.865, wps=13689.2, ups=1.65, wpb=8286.4, bsz=302.4, num_updates=22700, lr=9.38647e-05, gnorm=6.323, clip=11, loss_scale=0.125, train_wall=60, gb_free=16, wall=17977
2023-09-03 08:03:13 | INFO | train_inner | epoch 016:    706 / 1474 loss=2.936, trans_loss=5.964, nll_loss=3.51, w2v_ctc_loss=1.722, task_loss=2.708, task_loss_gen=3.474, contrastive_loss=0, total=4098.39, n_correct=1512.35, ppl=11.39, accuracy=36.901, wps=13417.3, ups=1.64, wpb=8196.8, bsz=296.8, num_updates=22800, lr=9.36586e-05, gnorm=8.27, clip=18, loss_scale=0.125, train_wall=60, gb_free=16.9, wall=18039
2023-09-03 08:04:14 | INFO | train_inner | epoch 016:    806 / 1474 loss=2.947, trans_loss=5.96, nll_loss=3.506, w2v_ctc_loss=1.771, task_loss=2.67, task_loss_gen=3.2, contrastive_loss=0, total=4177.54, n_correct=1545.58, ppl=11.36, accuracy=36.997, wps=13645, ups=1.63, wpb=8355.1, bsz=312.8, num_updates=22900, lr=9.34539e-05, gnorm=10.086, clip=28, loss_scale=0.125, train_wall=60, gb_free=15.5, wall=18100
2023-09-03 08:05:15 | INFO | train_inner | epoch 016:    906 / 1474 loss=2.947, trans_loss=5.955, nll_loss=3.498, w2v_ctc_loss=1.771, task_loss=2.802, task_loss_gen=3.322, contrastive_loss=0, total=4144.38, n_correct=1531.89, ppl=11.3, accuracy=36.963, wps=13507.2, ups=1.63, wpb=8288.8, bsz=305, num_updates=23000, lr=9.32505e-05, gnorm=11.844, clip=29, loss_scale=0.125, train_wall=61, gb_free=17.1, wall=18161
2023-09-03 08:06:17 | INFO | train_inner | epoch 016:   1006 / 1474 loss=2.959, trans_loss=5.967, nll_loss=3.514, w2v_ctc_loss=1.793, task_loss=2.851, task_loss_gen=3.485, contrastive_loss=0, total=4126.08, n_correct=1521.62, ppl=11.42, accuracy=36.878, wps=13479.9, ups=1.63, wpb=8252.2, bsz=302.2, num_updates=23100, lr=9.30484e-05, gnorm=10.109, clip=23, loss_scale=0.125, train_wall=61, gb_free=15.6, wall=18222
2023-09-03 08:07:18 | INFO | train_inner | epoch 016:   1106 / 1474 loss=2.975, trans_loss=5.971, nll_loss=3.519, w2v_ctc_loss=1.823, task_loss=2.816, task_loss_gen=3.651, contrastive_loss=0, total=4102.61, n_correct=1505.56, ppl=11.46, accuracy=36.698, wps=13305.6, ups=1.62, wpb=8205.2, bsz=293.4, num_updates=23200, lr=9.28477e-05, gnorm=8.184, clip=27, loss_scale=0.125, train_wall=61, gb_free=16.9, wall=18284
2023-09-03 08:08:21 | INFO | train_inner | epoch 016:   1206 / 1474 loss=2.941, trans_loss=5.962, nll_loss=3.509, w2v_ctc_loss=1.735, task_loss=2.91, task_loss_gen=3.465, contrastive_loss=0, total=4149.51, n_correct=1527.61, ppl=11.38, accuracy=36.814, wps=13256.4, ups=1.6, wpb=8299, bsz=305.4, num_updates=23300, lr=9.26482e-05, gnorm=9.464, clip=29, loss_scale=0.125, train_wall=62, gb_free=13.6, wall=18347
2023-09-03 08:09:22 | INFO | train_inner | epoch 016:   1306 / 1474 loss=2.945, trans_loss=5.957, nll_loss=3.502, w2v_ctc_loss=1.768, task_loss=2.657, task_loss_gen=3.288, contrastive_loss=0, total=4164.31, n_correct=1540.36, ppl=11.33, accuracy=36.99, wps=13544.8, ups=1.63, wpb=8328.6, bsz=315.1, num_updates=23400, lr=9.245e-05, gnorm=7.681, clip=19, loss_scale=0.25, train_wall=61, gb_free=16, wall=18408
2023-09-03 08:10:24 | INFO | train_inner | epoch 016:   1406 / 1474 loss=2.939, trans_loss=5.952, nll_loss=3.495, w2v_ctc_loss=1.763, task_loss=2.507, task_loss_gen=3.209, contrastive_loss=0, total=4202.02, n_correct=1558.26, ppl=11.28, accuracy=37.084, wps=13716.2, ups=1.63, wpb=8404, bsz=323.5, num_updates=23500, lr=9.22531e-05, gnorm=6.379, clip=13, loss_scale=0.25, train_wall=60, gb_free=17.1, wall=18469
2023-09-03 08:11:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 08:11:37 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 5.688 | trans_loss 7.25 | nll_loss 5.135 | w2v_ctc_loss 2.622 | task_loss 9.613 | task_loss_gen 9.006 | contrastive_loss 0 | total 4003.4 | n_correct 1431.2 | ppl 35.14 | accuracy 35.75 | uer 38.102 | wer 39.148 | raw_wer 39.148 | bleu 0.24 | wps 1795.4 | wpb 4003.4 | bsz 141.8 | num_updates 23568 | best_bleu 0.25
2023-09-03 08:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23568 updates
2023-09-03 08:11:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.2407.pt
2023-09-03 08:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.2407.pt
2023-09-03 08:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.2407.pt (epoch 16 @ 23568 updates, score 0.24) (writing took 8.434153767011594 seconds)
2023-09-03 08:11:46 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-03 08:11:46 | INFO | train | epoch 016 | loss 2.946 | trans_loss 5.958 | nll_loss 3.503 | w2v_ctc_loss 1.76 | task_loss 2.771 | task_loss_gen 3.393 | contrastive_loss 0 | total 4138.65 | n_correct 1527.32 | ppl 11.34 | accuracy 36.904 | wps 12798.5 | ups 1.55 | wpb 8277.3 | bsz 305.7 | num_updates 23568 | lr 9.21199e-05 | gnorm 9.13 | clip 23.3 | loss_scale 0.25 | train_wall 894 | gb_free 15 | wall 18552
2023-09-03 08:11:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 08:11:46 | INFO | fairseq.trainer | begin training epoch 17
2023-09-03 08:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 08:12:13 | INFO | train_inner | epoch 017:     32 / 1474 loss=2.919, trans_loss=5.944, nll_loss=3.485, w2v_ctc_loss=1.677, task_loss=3.1, task_loss_gen=3.576, contrastive_loss=0, total=4144.69, n_correct=1534.59, ppl=11.2, accuracy=37.025, wps=7563.5, ups=0.91, wpb=8289.4, bsz=301, num_updates=23600, lr=9.20575e-05, gnorm=5.452, clip=12, loss_scale=0.25, train_wall=61, gb_free=12.4, wall=18579
2023-09-03 08:13:14 | INFO | train_inner | epoch 017:    132 / 1474 loss=2.934, trans_loss=5.942, nll_loss=3.481, w2v_ctc_loss=1.727, task_loss=2.967, task_loss_gen=3.425, contrastive_loss=0, total=4107, n_correct=1521.41, ppl=11.17, accuracy=37.044, wps=13417.3, ups=1.63, wpb=8214, bsz=297.4, num_updates=23700, lr=9.1863e-05, gnorm=7.88, clip=17, loss_scale=0.25, train_wall=60, gb_free=15.5, wall=18640
2023-09-03 08:14:16 | INFO | train_inner | epoch 017:    232 / 1474 loss=2.927, trans_loss=5.935, nll_loss=3.473, w2v_ctc_loss=1.729, task_loss=2.508, task_loss_gen=3.281, contrastive_loss=0, total=4168.52, n_correct=1549.05, ppl=11.1, accuracy=37.161, wps=13613.7, ups=1.63, wpb=8337, bsz=316.6, num_updates=23800, lr=9.16698e-05, gnorm=4.849, clip=10, loss_scale=0.25, train_wall=60, gb_free=17, wall=18701
2023-09-03 08:15:17 | INFO | train_inner | epoch 017:    332 / 1474 loss=2.915, trans_loss=5.938, nll_loss=3.477, w2v_ctc_loss=1.684, task_loss=2.65, task_loss_gen=3.405, contrastive_loss=0, total=4156.21, n_correct=1541.83, ppl=11.13, accuracy=37.097, wps=13614.6, ups=1.64, wpb=8312.4, bsz=305.6, num_updates=23900, lr=9.14779e-05, gnorm=7.423, clip=13, loss_scale=0.25, train_wall=60, gb_free=9.1, wall=18763
2023-09-03 08:16:18 | INFO | train_inner | epoch 017:    432 / 1474 loss=2.942, trans_loss=5.948, nll_loss=3.49, w2v_ctc_loss=1.752, task_loss=2.617, task_loss_gen=3.498, contrastive_loss=0, total=4149.73, n_correct=1538.7, ppl=11.23, accuracy=37.08, wps=13516.9, ups=1.63, wpb=8299.5, bsz=306.6, num_updates=24000, lr=9.12871e-05, gnorm=9.253, clip=19, loss_scale=0.25, train_wall=61, gb_free=15.9, wall=18824
2023-09-03 08:16:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 08:16:51 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.699 | trans_loss 7.234 | nll_loss 5.114 | w2v_ctc_loss 2.694 | task_loss 8.243 | task_loss_gen 8.879 | contrastive_loss 0 | total 4003.4 | n_correct 1441.2 | ppl 34.63 | accuracy 35.999 | uer 40.002 | wer 40.897 | raw_wer 40.897 | bleu 0.17 | wps 1644.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 0.25
2023-09-03 08:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-09-03 08:16:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-03 08:16:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-03 08:17:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 0.17) (writing took 9.452045683050528 seconds)
2023-09-03 08:18:03 | INFO | train_inner | epoch 017:    532 / 1474 loss=2.93, trans_loss=5.939, nll_loss=3.479, w2v_ctc_loss=1.736, task_loss=2.772, task_loss_gen=3.53, contrastive_loss=0, total=4178.91, n_correct=1556.29, ppl=11.15, accuracy=37.242, wps=7968, ups=0.95, wpb=8357.8, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=5.575, clip=12, loss_scale=0.25, train_wall=61, gb_free=15.8, wall=18929
2023-09-03 08:19:05 | INFO | train_inner | epoch 017:    632 / 1474 loss=2.931, trans_loss=5.951, nll_loss=3.493, w2v_ctc_loss=1.705, task_loss=2.565, task_loss_gen=3.583, contrastive_loss=0, total=4153.46, n_correct=1535.57, ppl=11.26, accuracy=36.971, wps=13469.8, ups=1.62, wpb=8306.9, bsz=297.8, num_updates=24200, lr=9.09091e-05, gnorm=6.048, clip=15, loss_scale=0.25, train_wall=61, gb_free=12.9, wall=18990
2023-09-03 08:20:06 | INFO | train_inner | epoch 017:    732 / 1474 loss=2.931, trans_loss=5.943, nll_loss=3.483, w2v_ctc_loss=1.738, task_loss=2.42, task_loss_gen=3.32, contrastive_loss=0, total=4187.75, n_correct=1553.29, ppl=11.18, accuracy=37.091, wps=13670.1, ups=1.63, wpb=8375.5, bsz=313.1, num_updates=24300, lr=9.07218e-05, gnorm=6.137, clip=15, loss_scale=0.25, train_wall=60, gb_free=16.2, wall=19052
2023-09-03 08:21:07 | INFO | train_inner | epoch 017:    832 / 1474 loss=2.946, trans_loss=5.953, nll_loss=3.496, w2v_ctc_loss=1.758, task_loss=2.763, task_loss_gen=3.535, contrastive_loss=0, total=4078.38, n_correct=1506.64, ppl=11.28, accuracy=36.942, wps=13441.1, ups=1.65, wpb=8156.8, bsz=294.3, num_updates=24400, lr=9.05357e-05, gnorm=7.949, clip=26, loss_scale=0.25, train_wall=60, gb_free=16, wall=19112
2023-09-03 08:22:07 | INFO | train_inner | epoch 017:    932 / 1474 loss=2.909, trans_loss=5.944, nll_loss=3.486, w2v_ctc_loss=1.658, task_loss=2.962, task_loss_gen=3.235, contrastive_loss=0, total=4118.64, n_correct=1530.49, ppl=11.2, accuracy=37.16, wps=13701.8, ups=1.66, wpb=8237.3, bsz=307.9, num_updates=24500, lr=9.03508e-05, gnorm=4.149, clip=7, loss_scale=0.25, train_wall=59, gb_free=12.6, wall=19173
2023-09-03 08:23:09 | INFO | train_inner | epoch 017:   1032 / 1474 loss=2.917, trans_loss=5.947, nll_loss=3.489, w2v_ctc_loss=1.672, task_loss=3.005, task_loss_gen=3.395, contrastive_loss=0, total=4087.61, n_correct=1514.51, ppl=11.23, accuracy=37.051, wps=13244.1, ups=1.62, wpb=8175.2, bsz=298.4, num_updates=24600, lr=9.0167e-05, gnorm=6.888, clip=12, loss_scale=0.25, train_wall=61, gb_free=15.8, wall=19234
2023-09-03 08:24:09 | INFO | train_inner | epoch 017:   1132 / 1474 loss=2.927, trans_loss=5.944, nll_loss=3.486, w2v_ctc_loss=1.704, task_loss=3.135, task_loss_gen=3.41, contrastive_loss=0, total=4112.72, n_correct=1523.74, ppl=11.2, accuracy=37.049, wps=13610.7, ups=1.65, wpb=8225.4, bsz=301.4, num_updates=24700, lr=8.99843e-05, gnorm=5.957, clip=18, loss_scale=0.25, train_wall=60, gb_free=17.4, wall=19295
2023-09-03 08:25:11 | INFO | train_inner | epoch 017:   1232 / 1474 loss=2.914, trans_loss=5.944, nll_loss=3.486, w2v_ctc_loss=1.685, task_loss=2.573, task_loss_gen=3.288, contrastive_loss=0, total=4171.42, n_correct=1545.91, ppl=11.2, accuracy=37.06, wps=13425.7, ups=1.61, wpb=8342.8, bsz=324.6, num_updates=24800, lr=8.98027e-05, gnorm=7.616, clip=14, loss_scale=0.25, train_wall=61, gb_free=16.1, wall=19357
2023-09-03 08:26:12 | INFO | train_inner | epoch 017:   1332 / 1474 loss=2.925, trans_loss=5.949, nll_loss=3.493, w2v_ctc_loss=1.691, task_loss=2.561, task_loss_gen=3.528, contrastive_loss=0, total=4142.75, n_correct=1530.2, ppl=11.26, accuracy=36.937, wps=13518.2, ups=1.63, wpb=8285.5, bsz=302.7, num_updates=24900, lr=8.96221e-05, gnorm=5.788, clip=10, loss_scale=0.25, train_wall=61, gb_free=16.2, wall=19418
2023-09-03 08:27:14 | INFO | train_inner | epoch 017:   1432 / 1474 loss=2.916, trans_loss=5.947, nll_loss=3.489, w2v_ctc_loss=1.67, task_loss=2.471, task_loss_gen=3.535, contrastive_loss=0, total=4125.64, n_correct=1528.99, ppl=11.23, accuracy=37.061, wps=13418.1, ups=1.63, wpb=8251.3, bsz=304.9, num_updates=25000, lr=8.94427e-05, gnorm=7.061, clip=13, loss_scale=0.25, train_wall=61, gb_free=15, wall=19480
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:0')
2023-09-03 08:27:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5339, device='cuda:3')
2023-09-03 08:28:16 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.662 | trans_loss 7.217 | nll_loss 5.097 | w2v_ctc_loss 2.61 | task_loss 6.915 | task_loss_gen 9.11 | contrastive_loss 0 | total 4003.4 | n_correct 1451.2 | ppl 34.22 | accuracy 36.249 | uer 37.913 | wer 39.066 | raw_wer 39.066 | bleu 0.11 | wps 1390.2 | wpb 4003.4 | bsz 141.8 | num_updates 25042 | best_bleu 0.25
2023-09-03 08:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25042 updates
2023-09-03 08:28:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 08:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 08:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt (epoch 17 @ 25042 updates, score 0.11) (writing took 6.718997724994551 seconds)
2023-09-03 08:28:23 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-03 08:28:23 | INFO | train | epoch 017 | loss 2.926 | trans_loss 5.944 | nll_loss 3.485 | w2v_ctc_loss 1.707 | task_loss 2.702 | task_loss_gen 3.427 | contrastive_loss 0 | total 4138.65 | n_correct 1534.54 | ppl 11.2 | accuracy 37.078 | wps 12234.9 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 25042 | lr 8.93677e-05 | gnorm 6.501 | clip 14.2 | loss_scale 0.25 | train_wall 892 | gb_free 16.1 | wall 19549
2023-09-03 08:28:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 08:28:23 | INFO | fairseq.trainer | begin training epoch 18
2023-09-03 08:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 08:29:06 | INFO | train_inner | epoch 018:     58 / 1474 loss=2.924, trans_loss=5.94, nll_loss=3.48, w2v_ctc_loss=1.706, task_loss=2.552, task_loss_gen=3.566, contrastive_loss=0, total=4113.59, n_correct=1531.8, ppl=11.16, accuracy=37.238, wps=7307.9, ups=0.89, wpb=8227.2, bsz=299.1, num_updates=25100, lr=8.92644e-05, gnorm=3.875, clip=10, loss_scale=0.25, train_wall=61, gb_free=14.6, wall=19592
2023-09-03 08:30:07 | INFO | train_inner | epoch 018:    158 / 1474 loss=2.898, trans_loss=5.93, nll_loss=3.466, w2v_ctc_loss=1.654, task_loss=2.27, task_loss_gen=3.247, contrastive_loss=0, total=4175.95, n_correct=1567.24, ppl=11.05, accuracy=37.53, wps=13762.9, ups=1.65, wpb=8351.9, bsz=317.4, num_updates=25200, lr=8.90871e-05, gnorm=4.986, clip=11, loss_scale=0.25, train_wall=60, gb_free=15, wall=19653
2023-09-03 08:31:09 | INFO | train_inner | epoch 018:    258 / 1474 loss=2.916, trans_loss=5.934, nll_loss=3.471, w2v_ctc_loss=1.696, task_loss=3.026, task_loss_gen=3.581, contrastive_loss=0, total=4147.3, n_correct=1544.99, ppl=11.09, accuracy=37.253, wps=13468.1, ups=1.62, wpb=8294.6, bsz=310.6, num_updates=25300, lr=8.89108e-05, gnorm=6.817, clip=19, loss_scale=0.25, train_wall=61, gb_free=15.9, wall=19715
2023-09-03 08:32:11 | INFO | train_inner | epoch 018:    358 / 1474 loss=2.912, trans_loss=5.933, nll_loss=3.47, w2v_ctc_loss=1.673, task_loss=2.988, task_loss_gen=3.412, contrastive_loss=0, total=4176.81, n_correct=1558.6, ppl=11.08, accuracy=37.316, wps=13523.5, ups=1.62, wpb=8353.6, bsz=301.4, num_updates=25400, lr=8.87357e-05, gnorm=5.125, clip=13, loss_scale=0.5, train_wall=61, gb_free=17.2, wall=19776
2023-09-03 08:33:12 | INFO | train_inner | epoch 018:    458 / 1474 loss=2.9, trans_loss=5.929, nll_loss=3.465, w2v_ctc_loss=1.638, task_loss=3.021, task_loss_gen=3.582, contrastive_loss=0, total=4080.84, n_correct=1522.29, ppl=11.04, accuracy=37.303, wps=13214.2, ups=1.62, wpb=8161.7, bsz=295.4, num_updates=25500, lr=8.85615e-05, gnorm=3.292, clip=6, loss_scale=0.5, train_wall=61, gb_free=15.2, wall=19838
2023-09-03 08:34:13 | INFO | train_inner | epoch 018:    558 / 1474 loss=2.883, trans_loss=5.922, nll_loss=3.458, w2v_ctc_loss=1.607, task_loss=2.322, task_loss_gen=3.128, contrastive_loss=0, total=4205.5, n_correct=1574.18, ppl=10.99, accuracy=37.431, wps=13782.6, ups=1.64, wpb=8411, bsz=327.2, num_updates=25600, lr=8.83883e-05, gnorm=2.68, clip=3, loss_scale=0.5, train_wall=60, gb_free=17.4, wall=19899
2023-09-03 08:35:14 | INFO | train_inner | epoch 018:    658 / 1474 loss=2.89, trans_loss=5.933, nll_loss=3.471, w2v_ctc_loss=1.601, task_loss=3.06, task_loss_gen=3.62, contrastive_loss=0, total=4095.86, n_correct=1527.52, ppl=11.09, accuracy=37.294, wps=13410.6, ups=1.64, wpb=8191.7, bsz=298.3, num_updates=25700, lr=8.82162e-05, gnorm=2.603, clip=2, loss_scale=0.5, train_wall=60, gb_free=17.6, wall=19960
2023-09-03 08:36:16 | INFO | train_inner | epoch 018:    758 / 1474 loss=2.877, trans_loss=5.923, nll_loss=3.459, w2v_ctc_loss=1.587, task_loss=2.588, task_loss_gen=3.138, contrastive_loss=0, total=4209.86, n_correct=1575.88, ppl=11, accuracy=37.433, wps=13725.3, ups=1.63, wpb=8419.7, bsz=325.2, num_updates=25800, lr=8.80451e-05, gnorm=2.398, clip=5, loss_scale=0.5, train_wall=61, gb_free=15.6, wall=20022
2023-09-03 08:37:18 | INFO | train_inner | epoch 018:    858 / 1474 loss=2.877, trans_loss=5.933, nll_loss=3.471, w2v_ctc_loss=1.56, task_loss=2.527, task_loss_gen=3.408, contrastive_loss=0, total=4185.65, n_correct=1559.71, ppl=11.09, accuracy=37.263, wps=13504.8, ups=1.61, wpb=8371.3, bsz=307.9, num_updates=25900, lr=8.7875e-05, gnorm=2.749, clip=6, loss_scale=0.5, train_wall=61, gb_free=15.9, wall=20084
2023-09-03 08:38:18 | INFO | train_inner | epoch 018:    958 / 1474 loss=2.867, trans_loss=5.932, nll_loss=3.469, w2v_ctc_loss=1.53, task_loss=2.245, task_loss_gen=3.349, contrastive_loss=0, total=4125.61, n_correct=1537.13, ppl=11.08, accuracy=37.258, wps=13630.3, ups=1.65, wpb=8251.2, bsz=310.7, num_updates=26000, lr=8.77058e-05, gnorm=2.055, clip=4, loss_scale=0.5, train_wall=60, gb_free=13.3, wall=20144
2023-09-03 08:38:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 08:38:52 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 5.637 | trans_loss 7.223 | nll_loss 5.103 | w2v_ctc_loss 2.513 | task_loss 7.563 | task_loss_gen 9.165 | contrastive_loss 0 | total 4003.4 | n_correct 1451.1 | ppl 34.36 | accuracy 36.247 | uer 35.333 | wer 36.479 | raw_wer 36.479 | bleu 0.15 | wps 1560 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 0.25
2023-09-03 08:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-09-03 08:38:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-03 08:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-03 08:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 0.15) (writing took 6.55755272397073 seconds)
2023-09-03 08:40:01 | INFO | train_inner | epoch 018:   1058 / 1474 loss=2.886, trans_loss=5.938, nll_loss=3.477, w2v_ctc_loss=1.567, task_loss=2.977, task_loss_gen=3.648, contrastive_loss=0, total=4123.9, n_correct=1527.38, ppl=11.13, accuracy=37.037, wps=8057.8, ups=0.98, wpb=8247.8, bsz=296.8, num_updates=26100, lr=8.75376e-05, gnorm=3.872, clip=5, loss_scale=0.5, train_wall=61, gb_free=16.4, wall=20246
2023-09-03 08:41:02 | INFO | train_inner | epoch 018:   1158 / 1474 loss=2.865, trans_loss=5.922, nll_loss=3.457, w2v_ctc_loss=1.537, task_loss=2.6, task_loss_gen=3.247, contrastive_loss=0, total=4165.61, n_correct=1560.8, ppl=10.98, accuracy=37.469, wps=13638.6, ups=1.64, wpb=8331.2, bsz=316.9, num_updates=26200, lr=8.73704e-05, gnorm=3.192, clip=2, loss_scale=0.5, train_wall=60, gb_free=14.9, wall=20308
2023-09-03 08:42:03 | INFO | train_inner | epoch 018:   1258 / 1474 loss=2.886, trans_loss=5.939, nll_loss=3.479, w2v_ctc_loss=1.568, task_loss=2.919, task_loss_gen=3.563, contrastive_loss=0, total=4103.01, n_correct=1522.11, ppl=11.15, accuracy=37.097, wps=13432.5, ups=1.64, wpb=8206, bsz=290, num_updates=26300, lr=8.72041e-05, gnorm=3.431, clip=4, loss_scale=0.5, train_wall=60, gb_free=16.1, wall=20369
2023-09-03 08:43:04 | INFO | train_inner | epoch 018:   1358 / 1474 loss=2.895, trans_loss=5.942, nll_loss=3.483, w2v_ctc_loss=1.588, task_loss=3.137, task_loss_gen=3.984, contrastive_loss=0, total=4041.49, n_correct=1495.31, ppl=11.18, accuracy=36.999, wps=13196.5, ups=1.63, wpb=8083, bsz=286, num_updates=26400, lr=8.70388e-05, gnorm=3.852, clip=6, loss_scale=0.5, train_wall=61, gb_free=15.6, wall=20430
2023-09-03 08:44:05 | INFO | train_inner | epoch 018:   1458 / 1474 loss=2.873, trans_loss=5.935, nll_loss=3.474, w2v_ctc_loss=1.535, task_loss=2.847, task_loss_gen=3.499, contrastive_loss=0, total=4133.84, n_correct=1534.65, ppl=11.11, accuracy=37.124, wps=13481.7, ups=1.63, wpb=8267.7, bsz=301, num_updates=26500, lr=8.68744e-05, gnorm=1.866, clip=1, loss_scale=0.5, train_wall=61, gb_free=14.4, wall=20491
2023-09-03 08:44:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 08:44:52 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 5.585 | trans_loss 7.218 | nll_loss 5.098 | w2v_ctc_loss 2.349 | task_loss 7.062 | task_loss_gen 9.19 | contrastive_loss 0 | total 4003.4 | n_correct 1456.3 | ppl 34.24 | accuracy 36.377 | uer 34.903 | wer 35.808 | raw_wer 35.808 | bleu 0.12 | wps 1349.9 | wpb 4003.4 | bsz 141.8 | num_updates 26516 | best_bleu 0.25
2023-09-03 08:44:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26516 updates
2023-09-03 08:44:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 08:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 08:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt (epoch 18 @ 26516 updates, score 0.12) (writing took 6.733168169972487 seconds)
2023-09-03 08:44:59 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-03 08:44:59 | INFO | train | epoch 018 | loss 2.888 | trans_loss 5.932 | nll_loss 3.469 | w2v_ctc_loss 1.598 | task_loss 2.733 | task_loss_gen 3.453 | contrastive_loss 0 | total 4138.65 | n_correct 1542.75 | ppl 11.08 | accuracy 37.277 | wps 12247.1 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 26516 | lr 8.68482e-05 | gnorm 3.45 | clip 6.2 | loss_scale 0.5 | train_wall 893 | gb_free 15.5 | wall 20545
2023-09-03 08:44:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 08:44:59 | INFO | fairseq.trainer | begin training epoch 19
2023-09-03 08:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 08:45:58 | INFO | train_inner | epoch 019:     84 / 1474 loss=2.865, trans_loss=5.915, nll_loss=3.448, w2v_ctc_loss=1.531, task_loss=2.612, task_loss_gen=3.405, contrastive_loss=0, total=4105.84, n_correct=1540.19, ppl=10.91, accuracy=37.512, wps=7274.7, ups=0.89, wpb=8211.7, bsz=297.1, num_updates=26600, lr=8.6711e-05, gnorm=2.587, clip=4, loss_scale=0.5, train_wall=60, gb_free=13.6, wall=20604
2023-09-03 08:47:00 | INFO | train_inner | epoch 019:    184 / 1474 loss=2.865, trans_loss=5.911, nll_loss=3.443, w2v_ctc_loss=1.552, task_loss=2.424, task_loss_gen=3.334, contrastive_loss=0, total=4213.06, n_correct=1585.05, ppl=10.88, accuracy=37.622, wps=13554.9, ups=1.61, wpb=8426.1, bsz=322.8, num_updates=26700, lr=8.65485e-05, gnorm=3.459, clip=6, loss_scale=0.5, train_wall=61, gb_free=16.1, wall=20666
2023-09-03 08:48:02 | INFO | train_inner | epoch 019:    284 / 1474 loss=2.872, trans_loss=5.915, nll_loss=3.448, w2v_ctc_loss=1.559, task_loss=2.087, task_loss_gen=3.512, contrastive_loss=0, total=4202.31, n_correct=1572.11, ppl=10.91, accuracy=37.411, wps=13757.8, ups=1.64, wpb=8404.6, bsz=311.7, num_updates=26800, lr=8.63868e-05, gnorm=2.965, clip=5, loss_scale=0.5, train_wall=60, gb_free=15.8, wall=20727
2023-09-03 08:49:03 | INFO | train_inner | epoch 019:    384 / 1474 loss=2.855, trans_loss=5.909, nll_loss=3.44, w2v_ctc_loss=1.518, task_loss=2.178, task_loss_gen=3.544, contrastive_loss=0, total=4166.62, n_correct=1565.89, ppl=10.85, accuracy=37.582, wps=13552.8, ups=1.63, wpb=8333.2, bsz=310.1, num_updates=26900, lr=8.62261e-05, gnorm=1.969, clip=2, loss_scale=0.5, train_wall=61, gb_free=16.8, wall=20789
2023-09-03 08:50:04 | INFO | train_inner | epoch 019:    484 / 1474 loss=2.872, trans_loss=5.924, nll_loss=3.458, w2v_ctc_loss=1.55, task_loss=2.038, task_loss_gen=3.87, contrastive_loss=0, total=4100.4, n_correct=1531.6, ppl=10.99, accuracy=37.352, wps=13468.7, ups=1.64, wpb=8200.8, bsz=297.6, num_updates=27000, lr=8.60663e-05, gnorm=3.536, clip=10, loss_scale=0.5, train_wall=60, gb_free=14.9, wall=20850
2023-09-03 08:51:05 | INFO | train_inner | epoch 019:    584 / 1474 loss=2.871, trans_loss=5.924, nll_loss=3.458, w2v_ctc_loss=1.551, task_loss=2.441, task_loss_gen=3.554, contrastive_loss=0, total=4132.2, n_correct=1542.68, ppl=10.99, accuracy=37.333, wps=13570.4, ups=1.64, wpb=8264.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=3.611, clip=4, loss_scale=0.5, train_wall=60, gb_free=16.7, wall=20911
2023-09-03 08:52:06 | INFO | train_inner | epoch 019:    684 / 1474 loss=2.851, trans_loss=5.932, nll_loss=3.471, w2v_ctc_loss=1.483, task_loss=2.457, task_loss_gen=3.048, contrastive_loss=0, total=4211.87, n_correct=1571.94, ppl=11.08, accuracy=37.322, wps=13828.9, ups=1.64, wpb=8423.7, bsz=323.5, num_updates=27200, lr=8.57493e-05, gnorm=2.801, clip=2, loss_scale=0.5, train_wall=60, gb_free=16.5, wall=20972
2023-09-03 08:53:08 | INFO | train_inner | epoch 019:    784 / 1474 loss=2.864, trans_loss=5.918, nll_loss=3.452, w2v_ctc_loss=1.532, task_loss=2.793, task_loss_gen=3.45, contrastive_loss=0, total=4132.27, n_correct=1547.96, ppl=10.94, accuracy=37.46, wps=13394.5, ups=1.62, wpb=8264.5, bsz=303.3, num_updates=27300, lr=8.55921e-05, gnorm=2.629, clip=4, loss_scale=0.5, train_wall=61, gb_free=16.4, wall=21033
2023-09-03 08:54:09 | INFO | train_inner | epoch 019:    884 / 1474 loss=2.859, trans_loss=5.922, nll_loss=3.457, w2v_ctc_loss=1.506, task_loss=2.908, task_loss_gen=3.482, contrastive_loss=0, total=4154.88, n_correct=1551.71, ppl=10.98, accuracy=37.347, wps=13532.5, ups=1.63, wpb=8309.8, bsz=303.7, num_updates=27400, lr=8.54358e-05, gnorm=2.368, clip=2, loss_scale=0.5, train_wall=61, gb_free=15.8, wall=21095
2023-09-03 08:55:11 | INFO | train_inner | epoch 019:    984 / 1474 loss=2.854, trans_loss=5.92, nll_loss=3.454, w2v_ctc_loss=1.508, task_loss=3.226, task_loss_gen=3.459, contrastive_loss=0, total=4100.56, n_correct=1535.76, ppl=10.96, accuracy=37.452, wps=13172.3, ups=1.61, wpb=8201.1, bsz=309.1, num_updates=27500, lr=8.52803e-05, gnorm=2.174, clip=0, loss_scale=1, train_wall=61, gb_free=16.8, wall=21157
2023-09-03 08:56:12 | INFO | train_inner | epoch 019:   1084 / 1474 loss=2.857, trans_loss=5.922, nll_loss=3.457, w2v_ctc_loss=1.502, task_loss=2.813, task_loss_gen=3.644, contrastive_loss=0, total=4035.91, n_correct=1511.11, ppl=10.98, accuracy=37.442, wps=13251.8, ups=1.64, wpb=8071.8, bsz=291.4, num_updates=27600, lr=8.51257e-05, gnorm=1.775, clip=1, loss_scale=1, train_wall=60, gb_free=12.9, wall=21218
2023-09-03 08:57:14 | INFO | train_inner | epoch 019:   1184 / 1474 loss=2.851, trans_loss=5.913, nll_loss=3.445, w2v_ctc_loss=1.498, task_loss=2.378, task_loss_gen=3.676, contrastive_loss=0, total=4139.45, n_correct=1555.42, ppl=10.89, accuracy=37.576, wps=13365.5, ups=1.61, wpb=8278.9, bsz=306.3, num_updates=27700, lr=8.49719e-05, gnorm=1.681, clip=2, loss_scale=1, train_wall=61, gb_free=15.3, wall=21280
2023-09-03 08:57:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-03 08:58:15 | INFO | train_inner | epoch 019:   1285 / 1474 loss=2.852, trans_loss=5.923, nll_loss=3.459, w2v_ctc_loss=1.484, task_loss=2.393, task_loss_gen=3.568, contrastive_loss=0, total=4151.72, n_correct=1553.42, ppl=11, accuracy=37.416, wps=13525.3, ups=1.63, wpb=8303.4, bsz=304.1, num_updates=27800, lr=8.48189e-05, gnorm=2.148, clip=3, loss_scale=0.5, train_wall=61, gb_free=11.7, wall=21341
2023-09-03 08:59:17 | INFO | train_inner | epoch 019:   1385 / 1474 loss=2.856, trans_loss=5.919, nll_loss=3.452, w2v_ctc_loss=1.506, task_loss=2.378, task_loss_gen=3.625, contrastive_loss=0, total=4119.9, n_correct=1542.02, ppl=10.94, accuracy=37.429, wps=13472, ups=1.63, wpb=8239.8, bsz=300.9, num_updates=27900, lr=8.46668e-05, gnorm=3.108, clip=8, loss_scale=0.5, train_wall=60, gb_free=17.2, wall=21402
2023-09-03 09:00:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 09:00:44 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 5.611 | trans_loss 7.225 | nll_loss 5.098 | w2v_ctc_loss 2.419 | task_loss 11.917 | task_loss_gen 9.661 | contrastive_loss 0 | total 4003.4 | n_correct 1451.1 | ppl 34.26 | accuracy 36.247 | uer 35.118 | wer 36.199 | raw_wer 36.199 | bleu 0.18 | wps 1664.4 | wpb 4003.4 | bsz 141.8 | num_updates 27989 | best_bleu 0.25
2023-09-03 09:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27989 updates
2023-09-03 09:00:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1807.pt
2023-09-03 09:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1807.pt
2023-09-03 09:00:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint.best_bleu_0.1807.pt (epoch 19 @ 27989 updates, score 0.18) (writing took 7.8618254929897375 seconds)
2023-09-03 09:00:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-03 09:00:52 | INFO | train | epoch 019 | loss 2.861 | trans_loss 5.919 | nll_loss 3.452 | w2v_ctc_loss 1.522 | task_loss 2.525 | task_loss_gen 3.519 | contrastive_loss 0 | total 4138.93 | n_correct 1550.04 | ppl 10.95 | accuracy 37.45 | wps 12791.3 | ups 1.55 | wpb 8277.9 | bsz 305.7 | num_updates 27989 | lr 8.4532e-05 | gnorm 2.662 | clip 3.8 | loss_scale 0.5 | train_wall 893 | gb_free 17 | wall 21498
2023-09-03 09:00:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 09:00:53 | INFO | fairseq.trainer | begin training epoch 20
2023-09-03 09:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 09:01:07 | INFO | train_inner | epoch 020:     11 / 1474 loss=2.864, trans_loss=5.913, nll_loss=3.446, w2v_ctc_loss=1.54, task_loss=2.657, task_loss_gen=3.503, contrastive_loss=0, total=4125.77, n_correct=1549.87, ppl=10.9, accuracy=37.566, wps=7462.6, ups=0.9, wpb=8251.5, bsz=304.9, num_updates=28000, lr=8.45154e-05, gnorm=3.044, clip=4, loss_scale=0.5, train_wall=61, gb_free=9.6, wall=21513
2023-09-03 09:01:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 09:01:39 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 5.605 | trans_loss 7.225 | nll_loss 5.098 | w2v_ctc_loss 2.404 | task_loss 15.666 | task_loss_gen 10.579 | contrastive_loss 0 | total 4003.4 | n_correct 1453.4 | ppl 34.24 | accuracy 36.304 | uer 34.94 | wer 36.035 | raw_wer 36.035 | bleu 0.18 | wps 1698.5 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 0.25
2023-09-03 09:01:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-09-03 09:01:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-03 09:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-03 09:01:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 0.18) (writing took 8.147466849011835 seconds)
2023-09-03 09:02:49 | INFO | train_inner | epoch 020:    111 / 1474 loss=2.869, trans_loss=5.909, nll_loss=3.44, w2v_ctc_loss=1.564, task_loss=2.466, task_loss_gen=3.376, contrastive_loss=0, total=4195.07, n_correct=1577.92, ppl=10.85, accuracy=37.614, wps=8223.6, ups=0.98, wpb=8390.1, bsz=311.4, num_updates=28100, lr=8.43649e-05, gnorm=5.159, clip=9, loss_scale=0.5, train_wall=60, gb_free=15.7, wall=21615
2023-09-03 09:03:51 | INFO | train_inner | epoch 020:    211 / 1474 loss=2.877, trans_loss=5.915, nll_loss=3.446, w2v_ctc_loss=1.575, task_loss=2.794, task_loss_gen=3.663, contrastive_loss=0, total=4151.42, n_correct=1552.56, ppl=10.9, accuracy=37.398, wps=13388.8, ups=1.61, wpb=8302.8, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=4.529, clip=11, loss_scale=0.5, train_wall=61, gb_free=16.2, wall=21677
2023-09-03 09:04:52 | INFO | train_inner | epoch 020:    311 / 1474 loss=2.867, trans_loss=5.906, nll_loss=3.435, w2v_ctc_loss=1.575, task_loss=2.142, task_loss_gen=3.231, contrastive_loss=0, total=4195.39, n_correct=1581.57, ppl=10.82, accuracy=37.698, wps=13717.8, ups=1.63, wpb=8390.8, bsz=325.4, num_updates=28300, lr=8.40663e-05, gnorm=4.771, clip=11, loss_scale=0.5, train_wall=60, gb_free=15.2, wall=21738
2023-09-03 09:05:54 | INFO | train_inner | epoch 020:    411 / 1474 loss=2.867, trans_loss=5.903, nll_loss=3.431, w2v_ctc_loss=1.554, task_loss=2.571, task_loss_gen=3.5, contrastive_loss=0, total=4101.39, n_correct=1543.34, ppl=10.79, accuracy=37.63, wps=13344.4, ups=1.63, wpb=8202.8, bsz=296.2, num_updates=28400, lr=8.39181e-05, gnorm=3.254, clip=8, loss_scale=0.5, train_wall=61, gb_free=15.8, wall=21800
2023-09-03 09:06:55 | INFO | train_inner | epoch 020:    511 / 1474 loss=2.852, trans_loss=5.909, nll_loss=3.44, w2v_ctc_loss=1.507, task_loss=2.599, task_loss_gen=3.492, contrastive_loss=0, total=4125.09, n_correct=1550.47, ppl=10.85, accuracy=37.586, wps=13401.5, ups=1.62, wpb=8250.2, bsz=303.8, num_updates=28500, lr=8.37708e-05, gnorm=2.564, clip=4, loss_scale=0.5, train_wall=61, gb_free=16.2, wall=21861
2023-09-03 09:07:56 | INFO | train_inner | epoch 020:    611 / 1474 loss=2.865, trans_loss=5.911, nll_loss=3.442, w2v_ctc_loss=1.541, task_loss=2.9, task_loss_gen=3.696, contrastive_loss=0, total=4078.71, n_correct=1531.8, ppl=10.86, accuracy=37.556, wps=13435.6, ups=1.65, wpb=8157.4, bsz=292.3, num_updates=28600, lr=8.36242e-05, gnorm=3.262, clip=5, loss_scale=0.5, train_wall=60, gb_free=16, wall=21922
2023-09-03 09:08:57 | INFO | train_inner | epoch 020:    711 / 1474 loss=2.859, trans_loss=5.916, nll_loss=3.448, w2v_ctc_loss=1.514, task_loss=2.515, task_loss_gen=3.475, contrastive_loss=0, total=4142.11, n_correct=1555.93, ppl=10.92, accuracy=37.564, wps=13614.9, ups=1.64, wpb=8284.2, bsz=301.3, num_updates=28700, lr=8.34784e-05, gnorm=3.21, clip=5, loss_scale=0.5, train_wall=60, gb_free=16.1, wall=21983
2023-09-03 09:09:58 | INFO | train_inner | epoch 020:    811 / 1474 loss=2.854, trans_loss=5.914, nll_loss=3.447, w2v_ctc_loss=1.512, task_loss=2.332, task_loss_gen=3.409, contrastive_loss=0, total=4154.59, n_correct=1557.93, ppl=10.91, accuracy=37.499, wps=13652.7, ups=1.64, wpb=8309.2, bsz=311, num_updates=28800, lr=8.33333e-05, gnorm=4.453, clip=7, loss_scale=0.5, train_wall=60, gb_free=15.5, wall=22044
2023-09-03 09:11:00 | INFO | train_inner | epoch 020:    911 / 1474 loss=2.832, trans_loss=5.901, nll_loss=3.429, w2v_ctc_loss=1.471, task_loss=2.425, task_loss_gen=3.311, contrastive_loss=0, total=4156.71, n_correct=1575.19, ppl=10.77, accuracy=37.895, wps=13392, ups=1.61, wpb=8313.4, bsz=320.5, num_updates=28900, lr=8.3189e-05, gnorm=2.202, clip=3, loss_scale=0.5, train_wall=61, gb_free=16.2, wall=22106
2023-09-03 09:12:02 | INFO | train_inner | epoch 020:   1011 / 1474 loss=2.832, trans_loss=5.913, nll_loss=3.445, w2v_ctc_loss=1.447, task_loss=2.771, task_loss_gen=3.32, contrastive_loss=0, total=4191.9, n_correct=1580.15, ppl=10.89, accuracy=37.695, wps=13505.2, ups=1.61, wpb=8383.8, bsz=314.6, num_updates=29000, lr=8.30455e-05, gnorm=2.399, clip=2, loss_scale=0.5, train_wall=61, gb_free=16.3, wall=22168
2023-09-03 09:13:03 | INFO | train_inner | epoch 020:   1111 / 1474 loss=2.853, trans_loss=5.914, nll_loss=3.447, w2v_ctc_loss=1.497, task_loss=3.027, task_loss_gen=3.394, contrastive_loss=0, total=4134, n_correct=1550.7, ppl=10.9, accuracy=37.511, wps=13566.3, ups=1.64, wpb=8268, bsz=306, num_updates=29100, lr=8.29027e-05, gnorm=2.603, clip=2, loss_scale=0.5, train_wall=60, gb_free=15.3, wall=22229
2023-09-03 09:14:04 | INFO | train_inner | epoch 020:   1211 / 1474 loss=2.852, trans_loss=5.905, nll_loss=3.435, w2v_ctc_loss=1.489, task_loss=2.965, task_loss_gen=3.788, contrastive_loss=0, total=4027.67, n_correct=1511.69, ppl=10.82, accuracy=37.533, wps=13126.6, ups=1.63, wpb=8055.3, bsz=283.1, num_updates=29200, lr=8.27606e-05, gnorm=2.688, clip=6, loss_scale=0.5, train_wall=61, gb_free=16.5, wall=22290
2023-09-03 09:15:06 | INFO | train_inner | epoch 020:   1311 / 1474 loss=2.849, trans_loss=5.915, nll_loss=3.447, w2v_ctc_loss=1.487, task_loss=2.842, task_loss_gen=3.564, contrastive_loss=0, total=4140.59, n_correct=1555.15, ppl=10.91, accuracy=37.559, wps=13451, ups=1.62, wpb=8281.2, bsz=302.8, num_updates=29300, lr=8.26192e-05, gnorm=3.536, clip=4, loss_scale=0.5, train_wall=61, gb_free=16.9, wall=22352
2023-09-03 09:16:08 | INFO | train_inner | epoch 020:   1411 / 1474 loss=2.855, trans_loss=5.915, nll_loss=3.448, w2v_ctc_loss=1.492, task_loss=2.696, task_loss_gen=3.702, contrastive_loss=0, total=4114.68, n_correct=1540.97, ppl=10.91, accuracy=37.451, wps=13357.6, ups=1.62, wpb=8229.4, bsz=291, num_updates=29400, lr=8.24786e-05, gnorm=3.569, clip=5, loss_scale=0.5, train_wall=61, gb_free=11.4, wall=22413
2023-09-03 09:16:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 09:17:21 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 5.557 | trans_loss 7.214 | nll_loss 5.087 | w2v_ctc_loss 2.265 | task_loss 5.683 | task_loss_gen 9.748 | contrastive_loss 0 | total 4003.4 | n_correct 1459 | ppl 34 | accuracy 36.444 | uer 34.221 | wer 35.368 | raw_wer 35.368 | bleu 0.16 | wps 1491 | wpb 4003.4 | bsz 141.8 | num_updates 29463 | best_bleu 0.25
2023-09-03 09:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29463 updates
2023-09-03 09:17:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 09:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 09:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha1.5_mt0.5/checkpoint_last.pt (epoch 20 @ 29463 updates, score 0.16) (writing took 6.7149204990128055 seconds)
2023-09-03 09:17:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-03 09:17:27 | INFO | train | epoch 020 | loss 2.855 | trans_loss 5.91 | nll_loss 3.441 | w2v_ctc_loss 1.515 | task_loss 2.621 | task_loss_gen 3.465 | contrastive_loss 0 | total 4138.65 | n_correct 1555.97 | ppl 10.86 | accuracy 37.596 | wps 12263.9 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 29463 | lr 8.23904e-05 | gnorm 3.455 | clip 6.1 | loss_scale 0.5 | train_wall 893 | gb_free 15.9 | wall 22493
2023-09-03 09:17:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 09:17:27 | INFO | fairseq.trainer | begin training epoch 21
2023-09-03 09:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 09:17:58 | INFO | train_inner | epoch 021:     37 / 1474 loss=2.841, trans_loss=5.903, nll_loss=3.433, w2v_ctc_loss=1.495, task_loss=2.394, task_loss_gen=3.291, contrastive_loss=0, total=4150.5, n_correct=1569.54, ppl=10.8, accuracy=37.816, wps=7519.8, ups=0.91, wpb=8301, bsz=315.8, num_updates=29500, lr=8.23387e-05, gnorm=3.409, clip=10, loss_scale=0.5, train_wall=60, gb_free=15.2, wall=22524
2023-09-03 09:18:59 | INFO | train_inner | epoch 021:    137 / 1474 loss=2.829, trans_loss=5.89, nll_loss=3.414, w2v_ctc_loss=1.468, task_loss=2.16, task_loss_gen=3.374, contrastive_loss=0, total=4185.93, n_correct=1587.79, ppl=10.66, accuracy=37.932, wps=13623.9, ups=1.63, wpb=8371.9, bsz=319.2, num_updates=29600, lr=8.21995e-05, gnorm=2.423, clip=3, loss_scale=0.5, train_wall=61, gb_free=15.4, wall=22585
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1001 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
