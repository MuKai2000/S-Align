2023-08-14 01:44:31 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14892
2023-08-14 01:44:31 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14892
2023-08-14 01:44:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-14 01:44:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-14 01:44:33 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-14 01:44:37 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14892', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-14 01:44:37 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-14 01:44:37 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-14 01:44:37 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-14 01:44:37 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-14 01:44:37 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 01:44:41 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-14 01:44:41 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-14 01:44:41 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-14 01:44:43 | INFO | root | load pretrained hubert
2023-08-14 01:44:46 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 01:44:47 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 01:44:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 01:44:48 | INFO | root | share the sematic adapter and textual encoder
2023-08-14 01:44:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-14 01:44:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-14 01:44:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-14 01:44:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-14 01:44:48 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-14 01:44:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-14 01:44:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 01:44:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 01:44:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 01:44:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 01:44:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-14 01:44:55 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-14 01:44:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-14 01:44:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 01:44:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 01:44:55 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-14 01:44:55 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-14 01:44:55 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 01:44:55 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 01:44:55 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-14 01:44:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 01:44:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 01:44:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 01:44:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 01:44:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 01:45:47 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-14 01:45:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 01:45:47 | INFO | fairseq.trainer | begin training epoch 1
2023-08-14 01:45:47 | INFO | fairseq_cli.train | Start iterating over samples
None None None
2023-08-14 01:46:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
None None None
2023-08-14 01:46:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
None None None
2023-08-14 01:46:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 01:46:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
None None None
None None None
None None None
2023-08-14 01:47:11 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.045, trans_loss=5.873, nll_loss=4.681, w2v_ctc_loss=22.325, task_loss=1.769, contrastive_loss=3.271, total=4215.43, n_correct=123.43, ppl=25.65, accuracy=2.928, wps=18652.2, ups=1.49, wpb=12576.1, bsz=475.2, num_updates=100, lr=4.098e-06, gnorm=2.805, clip=0, loss_scale=8, train_wall=75, gb_free=18.6, wall=135
2023-08-14 01:47:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-14 01:48:17 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.5, trans_loss=5.854, nll_loss=4.683, w2v_ctc_loss=16.949, task_loss=1.711, contrastive_loss=3.235, total=4113.81, n_correct=114.36, ppl=25.68, accuracy=2.78, wps=18389.8, ups=1.5, wpb=12282.4, bsz=458.1, num_updates=200, lr=8.096e-06, gnorm=7.273, clip=18, loss_scale=4, train_wall=66, gb_free=19.4, wall=202
2023-08-14 01:48:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-14 01:48:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-14 01:49:23 | INFO | train_inner | epoch 001:    307 / 1474 loss=9.911, trans_loss=5.851, nll_loss=4.718, w2v_ctc_loss=6.86, task_loss=1.638, contrastive_loss=3.18, total=4096.34, n_correct=109.43, ppl=26.32, accuracy=2.671, wps=18502.2, ups=1.51, wpb=12237.7, bsz=442.4, num_updates=300, lr=1.2094e-05, gnorm=2.109, clip=0, loss_scale=1, train_wall=66, gb_free=18.6, wall=268
2023-08-14 01:50:28 | INFO | train_inner | epoch 001:    407 / 1474 loss=9.384, trans_loss=5.77, nll_loss=4.648, w2v_ctc_loss=6.1, task_loss=1.408, contrastive_loss=3.204, total=4177.57, n_correct=102.54, ppl=25.08, accuracy=2.455, wps=19210.8, ups=1.54, wpb=12474.5, bsz=461.4, num_updates=400, lr=1.6092e-05, gnorm=1.395, clip=0, loss_scale=1, train_wall=64, gb_free=18.7, wall=333
2023-08-14 01:51:33 | INFO | train_inner | epoch 001:    507 / 1474 loss=9.193, trans_loss=5.721, nll_loss=4.605, w2v_ctc_loss=5.805, task_loss=1.275, contrastive_loss=3.304, total=4176.79, n_correct=99.38, ppl=24.33, accuracy=2.379, wps=19221.7, ups=1.54, wpb=12481.2, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.305, clip=0, loss_scale=1, train_wall=64, gb_free=19.2, wall=398
2023-08-14 01:52:39 | INFO | train_inner | epoch 001:    607 / 1474 loss=9.153, trans_loss=5.862, nll_loss=4.79, w2v_ctc_loss=5.652, task_loss=1.24, contrastive_loss=3.251, total=4146.02, n_correct=82.21, ppl=27.66, accuracy=1.983, wps=18701.6, ups=1.51, wpb=12362.3, bsz=474.7, num_updates=600, lr=2.4088e-05, gnorm=1.321, clip=0, loss_scale=1, train_wall=66, gb_free=19.2, wall=464
2023-08-14 01:53:44 | INFO | train_inner | epoch 001:    707 / 1474 loss=9.125, trans_loss=5.942, nll_loss=4.892, w2v_ctc_loss=5.607, task_loss=1.314, contrastive_loss=3.124, total=4136.69, n_correct=65.87, ppl=29.69, accuracy=1.592, wps=19257, ups=1.56, wpb=12353.2, bsz=453, num_updates=700, lr=2.8086e-05, gnorm=1.223, clip=0, loss_scale=1, train_wall=64, gb_free=19.4, wall=528
2023-08-14 01:54:48 | INFO | train_inner | epoch 001:    807 / 1474 loss=9.015, trans_loss=5.995, nll_loss=4.953, w2v_ctc_loss=5.428, task_loss=1.268, contrastive_loss=3.143, total=4132.5, n_correct=60.79, ppl=30.98, accuracy=1.471, wps=19061, ups=1.55, wpb=12330.1, bsz=464, num_updates=800, lr=3.2084e-05, gnorm=1.241, clip=0, loss_scale=1, train_wall=64, gb_free=18.9, wall=593
2023-08-14 01:55:53 | INFO | train_inner | epoch 001:    907 / 1474 loss=8.819, trans_loss=5.956, nll_loss=4.898, w2v_ctc_loss=5.235, task_loss=1.296, contrastive_loss=3.052, total=4165.04, n_correct=74.14, ppl=29.82, accuracy=1.78, wps=19315.9, ups=1.55, wpb=12438.6, bsz=458.3, num_updates=900, lr=3.6082e-05, gnorm=1.828, clip=1, loss_scale=1, train_wall=64, gb_free=18.8, wall=657
2023-08-14 01:56:58 | INFO | train_inner | epoch 001:   1007 / 1474 loss=8.681, trans_loss=6.034, nll_loss=4.989, w2v_ctc_loss=4.978, task_loss=1.297, contrastive_loss=3.046, total=4135.88, n_correct=80.52, ppl=31.76, accuracy=1.947, wps=18929.5, ups=1.53, wpb=12354.5, bsz=457.9, num_updates=1000, lr=4.008e-05, gnorm=1.876, clip=0, loss_scale=1, train_wall=65, gb_free=19.3, wall=723
2023-08-14 01:58:03 | INFO | train_inner | epoch 001:   1107 / 1474 loss=8.494, trans_loss=6.089, nll_loss=5.055, w2v_ctc_loss=4.746, task_loss=1.32, contrastive_loss=2.956, total=4152.66, n_correct=74.29, ppl=33.24, accuracy=1.789, wps=18989.4, ups=1.53, wpb=12385.6, bsz=454, num_updates=1100, lr=4.4078e-05, gnorm=1.893, clip=0, loss_scale=1, train_wall=65, gb_free=18.6, wall=788
2023-08-14 01:59:08 | INFO | train_inner | epoch 001:   1207 / 1474 loss=8.31, trans_loss=6.111, nll_loss=5.087, w2v_ctc_loss=4.562, task_loss=1.391, contrastive_loss=2.843, total=4122.37, n_correct=67.49, ppl=34, accuracy=1.637, wps=19141.8, ups=1.55, wpb=12314, bsz=436.2, num_updates=1200, lr=4.8076e-05, gnorm=2.142, clip=0, loss_scale=1, train_wall=64, gb_free=18.7, wall=852
2023-08-14 02:00:12 | INFO | train_inner | epoch 001:   1307 / 1474 loss=8.164, trans_loss=6.118, nll_loss=5.094, w2v_ctc_loss=4.368, task_loss=1.292, contrastive_loss=2.802, total=4071.58, n_correct=66.99, ppl=34.16, accuracy=1.645, wps=18950.2, ups=1.56, wpb=12154.5, bsz=447.9, num_updates=1300, lr=5.2074e-05, gnorm=2.389, clip=0, loss_scale=1, train_wall=64, gb_free=18.7, wall=916
2023-08-14 02:01:16 | INFO | train_inner | epoch 001:   1407 / 1474 loss=7.984, trans_loss=6.082, nll_loss=5.05, w2v_ctc_loss=4.208, task_loss=1.327, contrastive_loss=2.865, total=4117.88, n_correct=71.71, ppl=33.13, accuracy=1.741, wps=19101.3, ups=1.55, wpb=12305.9, bsz=449.1, num_updates=1400, lr=5.6072e-05, gnorm=2.275, clip=0, loss_scale=1, train_wall=64, gb_free=18.8, wall=981
2023-08-14 02:01:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
2023-08-14 02:02:40 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.389 | trans_loss 13.729 | nll_loss 13.537 | w2v_ctc_loss 5.457 | task_loss 7.545 | contrastive_loss 4.127 | total 4003.4 | n_correct 48.2 | ppl 11888.4 | accuracy 1.204 | uer 69.615 | wer 67.783 | raw_wer 67.783 | bleu 0 | wps 1146.8 | wpb 4003.4 | bsz 141.8 | num_updates 1467
2023-08-14 02:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1467 updates
2023-08-14 02:02:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1467 updates, score 0.0) (writing took 6.2103342693299055 seconds)
2023-08-14 02:02:46 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-14 02:02:46 | INFO | train | epoch 001 | loss 10.105 | trans_loss 5.953 | nll_loss 4.875 | w2v_ctc_loss 7.213 | task_loss 1.389 | contrastive_loss 3.083 | total 4139.74 | n_correct 84.5583 | ppl 29.35 | accuracy 2.043 | wps 18079.3 | ups 1.46 | wpb 12359.1 | bsz 458.9 | num_updates 1467 | lr 5.87507e-05 | gnorm 2.241 | clip 1.3 | loss_scale 1 | train_wall 957 | gb_free 18.9 | wall 1071
2023-08-14 02:02:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 02:02:46 | INFO | fairseq.trainer | begin training epoch 2
2023-08-14 02:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 02:03:16 | INFO | train_inner | epoch 002:     33 / 1474 loss=7.886, trans_loss=6.091, nll_loss=5.059, w2v_ctc_loss=4.053, task_loss=1.252, contrastive_loss=2.845, total=4166.55, n_correct=70.62, ppl=33.34, accuracy=1.695, wps=10342.9, ups=0.83, wpb=12424.8, bsz=469.9, num_updates=1500, lr=6.007e-05, gnorm=2.595, clip=0, loss_scale=1, train_wall=65, gb_free=18.8, wall=1101
2023-08-14 02:04:21 | INFO | train_inner | epoch 002:    133 / 1474 loss=7.751, trans_loss=6.087, nll_loss=5.056, w2v_ctc_loss=3.959, task_loss=1.308, contrastive_loss=2.706, total=4154.58, n_correct=68.28, ppl=33.28, accuracy=1.643, wps=19145.8, ups=1.54, wpb=12394, bsz=455, num_updates=1600, lr=6.4068e-05, gnorm=2.338, clip=0, loss_scale=1, train_wall=64, gb_free=18.7, wall=1166
2023-08-14 02:05:25 | INFO | train_inner | epoch 002:    233 / 1474 loss=7.687, trans_loss=6.11, nll_loss=5.089, w2v_ctc_loss=3.806, task_loss=1.146, contrastive_loss=2.769, total=4202.18, n_correct=66.15, ppl=34.04, accuracy=1.574, wps=19526.1, ups=1.56, wpb=12548.4, bsz=492.4, num_updates=1700, lr=6.8066e-05, gnorm=2.495, clip=0, loss_scale=1, train_wall=64, gb_free=18.8, wall=1230
2023-08-14 02:06:29 | INFO | train_inner | epoch 002:    333 / 1474 loss=7.493, trans_loss=6.086, nll_loss=5.058, w2v_ctc_loss=3.746, task_loss=1.33, contrastive_loss=2.542, total=4125.8, n_correct=65.4, ppl=33.32, accuracy=1.585, wps=19270.5, ups=1.56, wpb=12318.7, bsz=447, num_updates=1800, lr=7.2064e-05, gnorm=2.665, clip=0, loss_scale=1, train_wall=63, gb_free=19.6, wall=1294
2023-08-14 02:07:34 | INFO | train_inner | epoch 002:    433 / 1474 loss=7.341, trans_loss=6.08, nll_loss=5.054, w2v_ctc_loss=3.693, task_loss=1.483, contrastive_loss=2.338, total=4029.94, n_correct=65.22, ppl=33.21, accuracy=1.618, wps=18716.6, ups=1.55, wpb=12045.2, bsz=410.6, num_updates=1900, lr=7.6062e-05, gnorm=2.517, clip=0, loss_scale=1, train_wall=64, gb_free=18.9, wall=1358
2023-08-14 02:08:39 | INFO | train_inner | epoch 002:    533 / 1474 loss=7.256, trans_loss=6.048, nll_loss=5.009, w2v_ctc_loss=3.549, task_loss=1.26, contrastive_loss=2.483, total=4192.5, n_correct=76.88, ppl=32.19, accuracy=1.834, wps=19242.8, ups=1.54, wpb=12507.1, bsz=470.4, num_updates=2000, lr=8.006e-05, gnorm=2.336, clip=0, loss_scale=1, train_wall=65, gb_free=19.1, wall=1423
2023-08-14 02:08:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 02:09:18 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.65 | trans_loss 13.391 | nll_loss 13.109 | w2v_ctc_loss 4.593 | task_loss 7.545 | contrastive_loss 3.48 | total 4003.4 | n_correct 61.3 | ppl 8834.92 | accuracy 1.531 | uer 62.087 | wer 60.277 | raw_wer 60.277 | bleu 0 | wps 1180.2 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-14 02:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-14 02:09:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-14 02:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-14 02:10:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 47.21748107112944 seconds)
2023-08-14 02:11:09 | INFO | train_inner | epoch 002:    633 / 1474 loss=7.118, trans_loss=6.05, nll_loss=5.01, w2v_ctc_loss=3.459, task_loss=1.299, contrastive_loss=2.294, total=4121.32, n_correct=71.41, ppl=32.23, accuracy=1.733, wps=8188.2, ups=0.67, wpb=12299.3, bsz=449.2, num_updates=2100, lr=8.4058e-05, gnorm=2.393, clip=0, loss_scale=1, train_wall=63, gb_free=19.5, wall=1573
2023-08-14 02:12:13 | INFO | train_inner | epoch 002:    733 / 1474 loss=7.05, trans_loss=6.049, nll_loss=5.008, w2v_ctc_loss=3.398, task_loss=1.281, contrastive_loss=2.388, total=4155.52, n_correct=74.14, ppl=32.17, accuracy=1.784, wps=19342.7, ups=1.56, wpb=12404.1, bsz=466, num_updates=2200, lr=8.8056e-05, gnorm=2.334, clip=0, loss_scale=1, train_wall=64, gb_free=17.6, wall=1638
2023-08-14 02:13:18 | INFO | train_inner | epoch 002:    833 / 1474 loss=6.93, trans_loss=6.035, nll_loss=4.993, w2v_ctc_loss=3.34, task_loss=1.323, contrastive_loss=2.263, total=4157.05, n_correct=76.82, ppl=31.84, accuracy=1.848, wps=19141.3, ups=1.54, wpb=12420.1, bsz=457.6, num_updates=2300, lr=9.2054e-05, gnorm=2.204, clip=0, loss_scale=1, train_wall=64, gb_free=19.1, wall=1702
2023-08-14 02:14:23 | INFO | train_inner | epoch 002:    933 / 1474 loss=6.806, trans_loss=6.023, nll_loss=4.975, w2v_ctc_loss=3.251, task_loss=1.35, contrastive_loss=2.223, total=4105.43, n_correct=76.39, ppl=31.45, accuracy=1.861, wps=18684, ups=1.52, wpb=12253.9, bsz=443.6, num_updates=2400, lr=9.6052e-05, gnorm=2.404, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=1768
2023-08-14 02:15:28 | INFO | train_inner | epoch 002:   1033 / 1474 loss=6.72, trans_loss=6.018, nll_loss=4.969, w2v_ctc_loss=3.195, task_loss=1.318, contrastive_loss=2.115, total=4097.3, n_correct=76.67, ppl=31.31, accuracy=1.871, wps=19037.4, ups=1.56, wpb=12232.3, bsz=452.7, num_updates=2500, lr=0.00010005, gnorm=2.166, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1832
2023-08-14 02:16:33 | INFO | train_inner | epoch 002:   1133 / 1474 loss=6.689, trans_loss=6.001, nll_loss=4.949, w2v_ctc_loss=3.102, task_loss=1.157, contrastive_loss=2.337, total=4213.49, n_correct=81.53, ppl=30.89, accuracy=1.935, wps=19334.3, ups=1.54, wpb=12579.3, bsz=498.9, num_updates=2600, lr=0.000104048, gnorm=2.248, clip=0, loss_scale=2, train_wall=65, gb_free=18.8, wall=1897
2023-08-14 02:17:38 | INFO | train_inner | epoch 002:   1233 / 1474 loss=6.586, trans_loss=5.99, nll_loss=4.934, w2v_ctc_loss=3.073, task_loss=1.215, contrastive_loss=2.144, total=4212.12, n_correct=81.92, ppl=30.57, accuracy=1.945, wps=19313.6, ups=1.54, wpb=12569.9, bsz=486.3, num_updates=2700, lr=0.000108046, gnorm=2.093, clip=0, loss_scale=2, train_wall=65, gb_free=19.1, wall=1962
2023-08-14 02:18:42 | INFO | train_inner | epoch 002:   1333 / 1474 loss=6.462, trans_loss=5.974, nll_loss=4.918, w2v_ctc_loss=3.034, task_loss=1.277, contrastive_loss=1.92, total=4139.37, n_correct=84.97, ppl=30.24, accuracy=2.053, wps=19244.9, ups=1.56, wpb=12372.6, bsz=455.1, num_updates=2800, lr=0.000112044, gnorm=2.028, clip=0, loss_scale=2, train_wall=64, gb_free=19.5, wall=2027
2023-08-14 02:19:47 | INFO | train_inner | epoch 002:   1433 / 1474 loss=6.386, trans_loss=5.987, nll_loss=4.93, w2v_ctc_loss=2.986, task_loss=1.376, contrastive_loss=1.978, total=4066.75, n_correct=78.97, ppl=30.49, accuracy=1.942, wps=18613.6, ups=1.53, wpb=12139.7, bsz=445.6, num_updates=2900, lr=0.000116042, gnorm=1.948, clip=0, loss_scale=2, train_wall=65, gb_free=19.2, wall=2092
2023-08-14 02:20:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 02:20:54 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.828 | trans_loss 13.009 | nll_loss 12.592 | w2v_ctc_loss 3.792 | task_loss 7.545 | contrastive_loss 2.642 | total 4003.4 | n_correct 88.6 | ppl 6172.76 | accuracy 2.213 | uer 53.065 | wer 52.354 | raw_wer 52.354 | bleu 0 | wps 1139.4 | wpb 4003.4 | bsz 141.8 | num_updates 2941 | best_bleu 0
2023-08-14 02:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2941 updates
2023-08-14 02:20:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:21:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2941 updates, score 0.0) (writing took 28.365443009883165 seconds)
2023-08-14 02:21:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-14 02:21:22 | INFO | train | epoch 002 | loss 7.02 | trans_loss 6.038 | nll_loss 4.996 | w2v_ctc_loss 3.401 | task_loss 1.292 | contrastive_loss 2.322 | total 4138.65 | n_correct 74.6995 | ppl 31.91 | accuracy 1.805 | wps 16312.1 | ups 1.32 | wpb 12355.8 | bsz 458.5 | num_updates 2941 | lr 0.000117681 | gnorm 2.285 | clip 0 | loss_scale 2 | train_wall 946 | gb_free 19 | wall 2187
2023-08-14 02:21:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 02:21:23 | INFO | fairseq.trainer | begin training epoch 3
2023-08-14 02:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 02:22:09 | INFO | train_inner | epoch 003:     59 / 1474 loss=6.282, trans_loss=5.965, nll_loss=4.903, w2v_ctc_loss=2.934, task_loss=1.36, contrastive_loss=1.834, total=4050.57, n_correct=80.92, ppl=29.93, accuracy=1.998, wps=8556.9, ups=0.71, wpb=12091.9, bsz=434.7, num_updates=3000, lr=0.00012004, gnorm=1.788, clip=0, loss_scale=2, train_wall=64, gb_free=19.3, wall=2233
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 316, in train
    log_output = trainer.train_step(samples)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq/trainer.py", line 863, in train_step
    raise e
  File "/mnt/zhangyh/fairseq-AT/fairseq/trainer.py", line 830, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining_merge.py", line 619, in train_step
    loss, sample_size, logging_output, norm_list = self._per_task_train_loss(
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining_merge.py", line 488, in _per_task_train_loss
    loss_at, loss_st, loss_mt, sample_size, logging_output = criterion(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge.py", line 214, in forward
    encoder_out_st = model.acoustic_encoder(src_tokens_st, src_lengths_st, mixup_rate=self.mixup_rate if ((per_task == 'at' or multi_st) and st_update) else 0.0, mixup_for_whole_model=self.mixup_for_whole_model, textual_encoder=model.textual_encoder, update_num=update_num)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 963, in forward
    mixup_mask = torch.rand(tokens_after_shrink.shape) < gen_mixup_rate.repeat(1, tokens_after_shrink.shape[1])      # [bs, len]
RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor

/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 96 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13838
2023-08-14 02:23:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-14 02:23:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-14 02:23:50 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-14 02:23:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13838', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-14 02:23:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-14 02:23:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-14 02:23:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-14 02:23:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-14 02:23:55 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 02:23:59 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-14 02:23:59 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-14 02:23:59 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-14 02:24:01 | INFO | root | load pretrained hubert
2023-08-14 02:24:04 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 02:24:04 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 02:24:07 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 02:24:07 | INFO | root | share the sematic adapter and textual encoder
2023-08-14 02:24:07 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-14 02:24:07 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-14 02:24:07 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-14 02:24:07 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-14 02:24:07 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-14 02:24:07 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-14 02:24:07 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 02:24:07 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:24:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:24:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 02:24:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-14 02:24:13 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-14 02:24:13 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-14 02:24:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:24:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 02:24:13 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-14 02:24:13 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-14 02:24:13 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 02:24:16 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-14 02:24:17 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-14 02:24:17 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 3 @ 2941 updates)
2023-08-14 02:24:17 | INFO | fairseq.trainer | loading train data for epoch 3
2023-08-14 02:24:17 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 02:24:17 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:24:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:24:23 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 02:24:26 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-14 02:25:22 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16578
2023-08-14 02:25:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-14 02:25:23 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-14 02:25:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16578', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-14 02:25:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-14 02:25:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-14 02:25:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-14 02:25:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-14 02:25:28 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 02:25:33 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-14 02:25:33 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-14 02:25:33 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-14 02:25:35 | INFO | root | load pretrained hubert
2023-08-14 02:25:37 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 02:25:38 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 02:25:40 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 02:25:41 | INFO | root | share the sematic adapter and textual encoder
2023-08-14 02:25:41 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-14 02:25:41 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-14 02:25:41 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-14 02:25:41 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-14 02:25:41 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-14 02:25:41 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-14 02:25:41 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 02:25:41 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:25:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:25:41 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 02:25:45 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-14 02:25:45 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-14 02:25:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-14 02:25:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 02:25:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 02:25:45 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-14 02:25:45 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-14 02:25:45 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 02:25:49 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-14 02:25:49 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-14 02:25:50 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 3 @ 2941 updates)
2023-08-14 02:25:50 | INFO | fairseq.trainer | loading train data for epoch 3
2023-08-14 02:25:50 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 02:25:50 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:25:50 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 02:25:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 02:25:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 02:26:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 02:26:46 | INFO | fairseq.trainer | begin training epoch 3
2023-08-14 02:26:46 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-14 02:27:44 | INFO | train_inner | epoch 003:     59 / 1474 loss=6.279, trans_loss=5.962, nll_loss=4.901, w2v_ctc_loss=2.917, task_loss=1.346, contrastive_loss=1.898, total=4097.1, n_correct=81.2712, ppl=29.88, accuracy=1.984, wps=18093.8, ups=1.48, wpb=12235.1, bsz=447.9, num_updates=3000, lr=0.00012004, gnorm=1.955, clip=0, loss_scale=2, train_wall=49, gb_free=19.3, wall=119
2023-08-14 02:29:17 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.608, trans_loss=5.208, nll_loss=3.94, w2v_ctc_loss=2.709, task_loss=0.901, contrastive_loss=1.815, total=4157.08, n_correct=354.97, ppl=15.34, accuracy=8.539, wps=13391.1, ups=1.08, wpb=12413.1, bsz=461.9, num_updates=3100, lr=0.000124038, gnorm=3.897, clip=6, loss_scale=2, train_wall=92, gb_free=16.2, wall=212
2023-08-14 02:30:51 | INFO | train_inner | epoch 003:    259 / 1474 loss=4.636, trans_loss=4.416, nll_loss=2.889, w2v_ctc_loss=2.4, task_loss=0.929, contrastive_loss=1.594, total=4155.72, n_correct=996.93, ppl=7.41, accuracy=23.989, wps=13172.3, ups=1.06, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=2.381, clip=0, loss_scale=2, train_wall=94, gb_free=17.4, wall=306
2023-08-14 02:32:24 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.316, trans_loss=4.246, nll_loss=2.667, w2v_ctc_loss=2.271, task_loss=0.916, contrastive_loss=1.493, total=4154.07, n_correct=1225.33, ppl=6.35, accuracy=29.497, wps=13284.5, ups=1.07, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=2.094, clip=0, loss_scale=2, train_wall=93, gb_free=15.3, wall=399
2023-08-14 02:33:58 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.079, trans_loss=4.181, nll_loss=2.585, w2v_ctc_loss=2.153, task_loss=0.902, contrastive_loss=1.294, total=4212.17, n_correct=1336.25, ppl=6, accuracy=31.724, wps=13356.1, ups=1.06, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.854, clip=0, loss_scale=2, train_wall=94, gb_free=15.4, wall=493
2023-08-14 02:35:31 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.896, trans_loss=4.151, nll_loss=2.55, w2v_ctc_loss=2.05, task_loss=0.982, contrastive_loss=1.174, total=4081.04, n_correct=1336.85, ppl=5.86, accuracy=32.758, wps=13138.3, ups=1.08, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.776, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=586
2023-08-14 02:37:06 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.813, trans_loss=4.121, nll_loss=2.507, w2v_ctc_loss=1.977, task_loss=0.873, contrastive_loss=1.235, total=4231.09, n_correct=1443.72, ppl=5.68, accuracy=34.122, wps=13337.5, ups=1.06, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.658, clip=0, loss_scale=2, train_wall=94, gb_free=15.7, wall=681
2023-08-14 02:38:39 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.644, trans_loss=4.084, nll_loss=2.463, w2v_ctc_loss=1.931, task_loss=0.884, contrastive_loss=0.936, total=4160.74, n_correct=1472.25, ppl=5.51, accuracy=35.384, wps=13368.6, ups=1.08, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.477, clip=0, loss_scale=2, train_wall=92, gb_free=16.6, wall=774
2023-08-14 02:40:13 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.531, trans_loss=4.062, nll_loss=2.433, w2v_ctc_loss=1.886, task_loss=0.935, contrastive_loss=0.852, total=4160.47, n_correct=1517.38, ppl=5.4, accuracy=36.471, wps=13253.6, ups=1.07, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.48, clip=0, loss_scale=2, train_wall=93, gb_free=16, wall=867
2023-08-14 02:41:46 | INFO | train_inner | epoch 003:    959 / 1474 loss=3.452, trans_loss=4.027, nll_loss=2.385, w2v_ctc_loss=1.856, task_loss=0.9, contrastive_loss=0.832, total=4162.26, n_correct=1584.55, ppl=5.22, accuracy=38.069, wps=13262.4, ups=1.07, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.486, clip=0, loss_scale=2, train_wall=93, gb_free=17.6, wall=961
2023-08-14 02:43:19 | INFO | train_inner | epoch 003:   1059 / 1474 loss=3.358, trans_loss=3.993, nll_loss=2.344, w2v_ctc_loss=1.835, task_loss=0.98, contrastive_loss=0.739, total=4062.67, n_correct=1591.41, ppl=5.08, accuracy=39.172, wps=13118.5, ups=1.08, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.43, clip=0, loss_scale=2, train_wall=92, gb_free=15.4, wall=1053
2023-08-14 02:43:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 02:43:49 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.504 | trans_loss 6.723 | nll_loss 4.417 | w2v_ctc_loss 2.152 | task_loss 4.272 | contrastive_loss 0.992 | total 4003.4 | n_correct 1751.3 | ppl 21.36 | accuracy 43.745 | uer 31.532 | wer 31.997 | raw_wer 31.997 | bleu 5.27 | wps 1547.1 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 5.27
2023-08-14 02:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-14 02:43:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-14 02:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-14 02:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 5.27) (writing took 30.38268474675715 seconds)
2023-08-14 02:45:52 | INFO | train_inner | epoch 003:   1159 / 1474 loss=3.272, trans_loss=3.971, nll_loss=2.314, w2v_ctc_loss=1.797, task_loss=0.997, contrastive_loss=0.674, total=4046.76, n_correct=1633.02, ppl=4.97, accuracy=40.354, wps=7883.8, ups=0.65, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.417, clip=0, loss_scale=2, train_wall=92, gb_free=15.8, wall=1207
2023-08-14 02:47:26 | INFO | train_inner | epoch 003:   1259 / 1474 loss=3.197, trans_loss=3.936, nll_loss=2.27, w2v_ctc_loss=1.764, task_loss=0.981, contrastive_loss=0.627, total=4064.26, n_correct=1687.97, ppl=4.82, accuracy=41.532, wps=12936, ups=1.07, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.408, clip=0, loss_scale=2, train_wall=93, gb_free=16.4, wall=1301
2023-08-14 02:48:59 | INFO | train_inner | epoch 003:   1359 / 1474 loss=3.164, trans_loss=3.91, nll_loss=2.236, w2v_ctc_loss=1.73, task_loss=0.932, contrastive_loss=0.716, total=4137.36, n_correct=1764.6, ppl=4.71, accuracy=42.65, wps=13244.4, ups=1.07, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.352, clip=0, loss_scale=2, train_wall=93, gb_free=15.8, wall=1394
2023-08-14 02:50:32 | INFO | train_inner | epoch 003:   1459 / 1474 loss=3.1, trans_loss=3.88, nll_loss=2.199, w2v_ctc_loss=1.698, task_loss=0.882, contrastive_loss=0.671, total=4207.75, n_correct=1851.9, ppl=4.59, accuracy=44.012, wps=13479.4, ups=1.07, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.264, clip=0, loss_scale=2, train_wall=93, gb_free=17.1, wall=1487
2023-08-14 02:50:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 02:51:16 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.1 | trans_loss 6.313 | nll_loss 3.889 | w2v_ctc_loss 1.987 | task_loss 4.201 | contrastive_loss 0.776 | total 4003.4 | n_correct 1980.3 | ppl 14.81 | accuracy 49.465 | uer 30.051 | wer 30.513 | raw_wer 30.513 | bleu 9.29 | wps 1553.1 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 9.29
2023-08-14 02:51:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-14 02:51:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 02:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4415 updates, score 9.29) (writing took 30.144849564880133 seconds)
2023-08-14 02:51:46 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-14 02:51:46 | INFO | train | epoch 003 | loss 3.884 | trans_loss 4.226 | nll_loss 2.646 | w2v_ctc_loss 2.038 | task_loss 0.944 | contrastive_loss 1.079 | total 4138.65 | n_correct 1364.14 | ppl 6.26 | accuracy 32.961 | wps 12288.2 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 4415 | lr 0.000176612 | gnorm 1.785 | clip 0.4 | loss_scale 2 | train_wall 1363 | gb_free 16.1 | wall 1561
2023-08-14 02:51:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 02:51:46 | INFO | fairseq.trainer | begin training epoch 4
2023-08-14 02:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 02:53:12 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.982, trans_loss=3.85, nll_loss=2.157, w2v_ctc_loss=1.663, task_loss=0.968, contrastive_loss=0.497, total=4095.18, n_correct=1848.26, ppl=4.46, accuracy=45.133, wps=7651.9, ups=0.63, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.241, clip=0, loss_scale=2, train_wall=91, gb_free=12.2, wall=1647
2023-08-14 02:54:46 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.943, trans_loss=3.818, nll_loss=2.116, w2v_ctc_loss=1.636, task_loss=0.882, contrastive_loss=0.511, total=4178.83, n_correct=1939.61, ppl=4.34, accuracy=46.415, wps=13321.4, ups=1.07, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=1.186, clip=0, loss_scale=2, train_wall=93, gb_free=14.4, wall=1740
2023-08-14 02:56:19 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.941, trans_loss=3.811, nll_loss=2.109, w2v_ctc_loss=1.628, task_loss=0.937, contrastive_loss=0.62, total=4142.3, n_correct=1933.86, ppl=4.31, accuracy=46.686, wps=13277.3, ups=1.07, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.222, clip=0, loss_scale=2, train_wall=93, gb_free=13, wall=1834
2023-08-14 02:57:51 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.875, trans_loss=3.795, nll_loss=2.085, w2v_ctc_loss=1.611, task_loss=0.965, contrastive_loss=0.45, total=4124.92, n_correct=1956.85, ppl=4.24, accuracy=47.44, wps=13292.8, ups=1.08, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=1.186, clip=0, loss_scale=2, train_wall=92, gb_free=12, wall=1926
2023-08-14 02:59:24 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.906, trans_loss=3.768, nll_loss=2.052, w2v_ctc_loss=1.569, task_loss=0.842, contrastive_loss=0.828, total=4216.09, n_correct=2045.5, ppl=4.15, accuracy=48.517, wps=13525.4, ups=1.07, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.121, clip=0, loss_scale=2, train_wall=93, gb_free=16.5, wall=2019
2023-08-14 03:00:58 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.826, trans_loss=3.751, nll_loss=2.03, w2v_ctc_loss=1.58, task_loss=0.864, contrastive_loss=0.504, total=4231.12, n_correct=2084.63, ppl=4.09, accuracy=49.269, wps=13455, ups=1.07, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=1.105, clip=0, loss_scale=4, train_wall=93, gb_free=15.8, wall=2113
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:0')
2023-08-14 03:02:33 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.786, trans_loss=3.745, nll_loss=2.018, w2v_ctc_loss=1.55, task_loss=0.96, contrastive_loss=0.531, total=4176.95, n_correct=2079.68, ppl=4.05, accuracy=49.789, wps=13201.1, ups=1.06, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.76, clip=0, loss_scale=4, train_wall=94, gb_free=14.7, wall=2207
2023-08-14 03:04:05 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.745, trans_loss=3.726, nll_loss=1.999, w2v_ctc_loss=1.561, task_loss=1.028, contrastive_loss=0.394, total=4016.91, n_correct=2016.57, ppl=4, accuracy=50.202, wps=12938, ups=1.08, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.765, clip=0, loss_scale=4, train_wall=92, gb_free=15.8, wall=2300
2023-08-14 03:05:38 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.772, trans_loss=3.711, nll_loss=1.98, w2v_ctc_loss=1.545, task_loss=0.933, contrastive_loss=0.57, total=4183.4, n_correct=2121.74, ppl=3.94, accuracy=50.718, wps=13449.3, ups=1.08, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.788, clip=0, loss_scale=4, train_wall=92, gb_free=15.2, wall=2393
2023-08-14 03:07:13 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.71, trans_loss=3.698, nll_loss=1.964, w2v_ctc_loss=1.529, task_loss=0.943, contrastive_loss=0.434, total=4128.78, n_correct=2117.67, ppl=3.9, accuracy=51.29, wps=13071.7, ups=1.06, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.718, clip=0, loss_scale=4, train_wall=94, gb_free=15.6, wall=2487
2023-08-14 03:08:45 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.692, trans_loss=3.696, nll_loss=1.961, w2v_ctc_loss=1.527, task_loss=0.995, contrastive_loss=0.401, total=4080.2, n_correct=2102.18, ppl=3.89, accuracy=51.521, wps=13134.8, ups=1.08, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.72, clip=0, loss_scale=4, train_wall=92, gb_free=15.8, wall=2580
2023-08-14 03:10:18 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.702, trans_loss=3.68, nll_loss=1.942, w2v_ctc_loss=1.513, task_loss=0.868, contrastive_loss=0.508, total=4163.45, n_correct=2173.41, ppl=3.84, accuracy=52.202, wps=13400.5, ups=1.08, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.719, clip=0, loss_scale=4, train_wall=92, gb_free=14.9, wall=2673
2023-08-14 03:11:50 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.673, trans_loss=3.664, nll_loss=1.921, w2v_ctc_loss=1.504, task_loss=0.89, contrastive_loss=0.464, total=4152.41, n_correct=2189.35, ppl=3.79, accuracy=52.725, wps=13446.4, ups=1.08, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.7, clip=0, loss_scale=4, train_wall=92, gb_free=12.5, wall=2765
2023-08-14 03:13:22 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.615, trans_loss=3.655, nll_loss=1.909, w2v_ctc_loss=1.486, task_loss=0.958, contrastive_loss=0.336, total=4103.57, n_correct=2175.03, ppl=3.76, accuracy=53.003, wps=13319.1, ups=1.09, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.675, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=2857
2023-08-14 03:14:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5412, device='cuda:4')
2023-08-14 03:15:10 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.474 | trans_loss 5.656 | nll_loss 3.046 | w2v_ctc_loss 1.677 | task_loss 4.47 | contrastive_loss 0.511 | total 4003.4 | n_correct 2359.7 | ppl 8.26 | accuracy 58.942 | uer 25.132 | wer 26.714 | raw_wer 26.714 | bleu 16.6 | wps 1866.1 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.6
2023-08-14 03:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-14 03:15:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 03:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 03:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.6) (writing took 28.95994810014963 seconds)
2023-08-14 03:15:39 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-14 03:15:39 | INFO | train | epoch 004 | loss 2.784 | trans_loss 3.734 | nll_loss 2.009 | w2v_ctc_loss 1.557 | task_loss 0.93 | contrastive_loss 0.498 | total 4138.65 | n_correct 2065.25 | ppl 4.03 | accuracy 49.902 | wps 12707.2 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.904 | clip 0 | loss_scale 4 | train_wall 1362 | gb_free 14.5 | wall 2994
2023-08-14 03:15:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 03:15:40 | INFO | fairseq.trainer | begin training epoch 5
2023-08-14 03:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 03:15:57 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.586, trans_loss=3.646, nll_loss=1.897, w2v_ctc_loss=1.458, task_loss=0.975, contrastive_loss=0.347, total=4031.51, n_correct=2154.31, ppl=3.72, accuracy=53.437, wps=7794.8, ups=0.65, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.678, clip=0, loss_scale=4, train_wall=91, gb_free=14, wall=3012
2023-08-14 03:17:30 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.527, trans_loss=3.609, nll_loss=1.849, w2v_ctc_loss=1.388, task_loss=0.835, contrastive_loss=0.369, total=4256.63, n_correct=2329.37, ppl=3.6, accuracy=54.723, wps=13684, ups=1.08, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.638, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=3105
2023-08-14 03:17:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 03:17:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.442 | trans_loss 5.634 | nll_loss 3.016 | w2v_ctc_loss 1.626 | task_loss 4.483 | contrastive_loss 0.504 | total 4003.4 | n_correct 2370.5 | ppl 8.09 | accuracy 59.212 | uer 24.463 | wer 26.047 | raw_wer 26.047 | bleu 16.68 | wps 1977.7 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.68
2023-08-14 03:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-14 03:17:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-14 03:17:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-14 03:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.68) (writing took 30.71869271621108 seconds)
2023-08-14 03:19:58 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.559, trans_loss=3.614, nll_loss=1.854, w2v_ctc_loss=1.395, task_loss=0.868, contrastive_loss=0.553, total=4186.83, n_correct=2292.4, ppl=3.61, accuracy=54.753, wps=8440.2, ups=0.68, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.647, clip=0, loss_scale=4, train_wall=92, gb_free=15.8, wall=3253
2023-08-14 03:21:30 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.539, trans_loss=3.601, nll_loss=1.842, w2v_ctc_loss=1.418, task_loss=0.953, contrastive_loss=0.411, total=4094.07, n_correct=2240.21, ppl=3.59, accuracy=54.718, wps=13226, ups=1.08, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.644, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=3345
2023-08-14 03:23:04 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.518, trans_loss=3.59, nll_loss=1.827, w2v_ctc_loss=1.377, task_loss=0.915, contrastive_loss=0.483, total=4140.39, n_correct=2289.71, ppl=3.55, accuracy=55.302, wps=13266.1, ups=1.07, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.648, clip=0, loss_scale=4, train_wall=93, gb_free=15.7, wall=3438
2023-08-14 03:24:35 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.472, trans_loss=3.592, nll_loss=1.829, w2v_ctc_loss=1.387, task_loss=1.038, contrastive_loss=0.279, total=4026.21, n_correct=2226.62, ppl=3.55, accuracy=55.303, wps=13112.2, ups=1.09, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.633, clip=0, loss_scale=4, train_wall=91, gb_free=16.7, wall=3530
2023-08-14 03:26:08 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.503, trans_loss=3.598, nll_loss=1.833, w2v_ctc_loss=1.376, task_loss=0.963, contrastive_loss=0.453, total=4109.94, n_correct=2274.2, ppl=3.56, accuracy=55.334, wps=13169.5, ups=1.07, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.663, clip=0, loss_scale=4, train_wall=93, gb_free=15.1, wall=3623
2023-08-14 03:27:42 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.49, trans_loss=3.587, nll_loss=1.822, w2v_ctc_loss=1.367, task_loss=0.876, contrastive_loss=0.424, total=4176.83, n_correct=2331.5, ppl=3.53, accuracy=55.82, wps=13333.3, ups=1.07, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.633, clip=0, loss_scale=4, train_wall=93, gb_free=16.8, wall=3717
2023-08-14 03:29:15 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.461, trans_loss=3.58, nll_loss=1.811, w2v_ctc_loss=1.362, task_loss=0.963, contrastive_loss=0.347, total=4127.9, n_correct=2308.28, ppl=3.51, accuracy=55.919, wps=13249.6, ups=1.08, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.623, clip=0, loss_scale=4, train_wall=93, gb_free=15.4, wall=3810
2023-08-14 03:30:47 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.428, trans_loss=3.57, nll_loss=1.8, w2v_ctc_loss=1.346, task_loss=0.959, contrastive_loss=0.306, total=4101.19, n_correct=2308.05, ppl=3.48, accuracy=56.278, wps=13294.5, ups=1.09, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.618, clip=0, loss_scale=4, train_wall=92, gb_free=16.9, wall=3902
2023-08-14 03:32:19 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.442, trans_loss=3.571, nll_loss=1.8, w2v_ctc_loss=1.349, task_loss=0.923, contrastive_loss=0.38, total=4164.27, n_correct=2349.65, ppl=3.48, accuracy=56.424, wps=13502.4, ups=1.09, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.598, clip=0, loss_scale=4, train_wall=91, gb_free=14.7, wall=3994
2023-08-14 03:33:53 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.452, trans_loss=3.569, nll_loss=1.796, w2v_ctc_loss=1.356, task_loss=0.929, contrastive_loss=0.384, total=4168.94, n_correct=2357.12, ppl=3.47, accuracy=56.54, wps=13195.3, ups=1.06, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.618, clip=0, loss_scale=4, train_wall=94, gb_free=16.3, wall=4088
2023-08-14 03:35:27 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.415, trans_loss=3.566, nll_loss=1.794, w2v_ctc_loss=1.342, task_loss=0.945, contrastive_loss=0.291, total=4171.16, n_correct=2361.4, ppl=3.47, accuracy=56.613, wps=13355.9, ups=1.07, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.611, clip=0, loss_scale=8, train_wall=93, gb_free=15.5, wall=4181
2023-08-14 03:36:59 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.376, trans_loss=3.556, nll_loss=1.781, w2v_ctc_loss=1.32, task_loss=0.95, contrastive_loss=0.246, total=4126.97, n_correct=2353.96, ppl=3.44, accuracy=57.038, wps=13274.2, ups=1.08, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.595, clip=0, loss_scale=8, train_wall=92, gb_free=15.2, wall=4274
2023-08-14 03:38:32 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.394, trans_loss=3.556, nll_loss=1.784, w2v_ctc_loss=1.321, task_loss=0.939, contrastive_loss=0.31, total=4138.54, n_correct=2361.13, ppl=3.44, accuracy=57.052, wps=13362.4, ups=1.08, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.604, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=4367
2023-08-14 03:39:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 03:39:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.273 | trans_loss 5.484 | nll_loss 2.832 | w2v_ctc_loss 1.471 | task_loss 4.511 | contrastive_loss 0.443 | total 4003.4 | n_correct 2464.1 | ppl 7.12 | accuracy 61.55 | uer 22.363 | wer 23.925 | raw_wer 23.925 | bleu 18.4 | wps 1896.2 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 18.4
2023-08-14 03:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-14 03:39:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 03:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 03:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7363 updates, score 18.4) (writing took 29.382930528372526 seconds)
2023-08-14 03:40:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-14 03:40:24 | INFO | train | epoch 005 | loss 2.467 | trans_loss 3.581 | nll_loss 1.814 | w2v_ctc_loss 1.363 | task_loss 0.932 | contrastive_loss 0.373 | total 4138.65 | n_correct 2313.32 | ppl 3.52 | accuracy 55.895 | wps 12264.1 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.626 | clip 0 | loss_scale 8 | train_wall 1361 | gb_free 15.9 | wall 4479
2023-08-14 03:40:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 03:40:25 | INFO | fairseq.trainer | begin training epoch 6
2023-08-14 03:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 03:41:06 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.374, trans_loss=3.538, nll_loss=1.758, w2v_ctc_loss=1.308, task_loss=0.958, contrastive_loss=0.303, total=4113.87, n_correct=2369.27, ppl=3.38, accuracy=57.592, wps=7944.2, ups=0.65, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.604, clip=0, loss_scale=8, train_wall=93, gb_free=17.6, wall=4521
2023-08-14 03:42:39 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.326, trans_loss=3.51, nll_loss=1.723, w2v_ctc_loss=1.253, task_loss=0.926, contrastive_loss=0.344, total=4161.2, n_correct=2425.05, ppl=3.3, accuracy=58.278, wps=13490.3, ups=1.09, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.594, clip=0, loss_scale=8, train_wall=92, gb_free=16.6, wall=4613
2023-08-14 03:44:11 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.334, trans_loss=3.519, nll_loss=1.736, w2v_ctc_loss=1.287, task_loss=1.002, contrastive_loss=0.252, total=4110.12, n_correct=2381.76, ppl=3.33, accuracy=57.949, wps=13286.2, ups=1.08, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.585, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=4706
2023-08-14 03:45:46 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.367, trans_loss=3.509, nll_loss=1.723, w2v_ctc_loss=1.239, task_loss=0.875, contrastive_loss=0.559, total=4170.52, n_correct=2436.95, ppl=3.3, accuracy=58.433, wps=13163.5, ups=1.06, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.604, clip=0, loss_scale=8, train_wall=94, gb_free=15.3, wall=4800
2023-08-14 03:47:18 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.293, trans_loss=3.507, nll_loss=1.72, w2v_ctc_loss=1.246, task_loss=0.897, contrastive_loss=0.259, total=4154.89, n_correct=2439.59, ppl=3.29, accuracy=58.716, wps=13456, ups=1.08, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.585, clip=0, loss_scale=8, train_wall=92, gb_free=16, wall=4893
2023-08-14 03:48:50 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.301, trans_loss=3.51, nll_loss=1.722, w2v_ctc_loss=1.26, task_loss=0.93, contrastive_loss=0.249, total=4174.46, n_correct=2447.59, ppl=3.3, accuracy=58.632, wps=13500.8, ups=1.08, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.584, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=4985
2023-08-14 03:50:22 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.293, trans_loss=3.509, nll_loss=1.722, w2v_ctc_loss=1.233, task_loss=0.886, contrastive_loss=0.298, total=4145.19, n_correct=2433.46, ppl=3.3, accuracy=58.706, wps=13427.6, ups=1.09, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.576, clip=0, loss_scale=8, train_wall=92, gb_free=15.5, wall=5077
2023-08-14 03:50:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 03:50:48 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.414 | nll_loss 2.743 | w2v_ctc_loss 1.481 | task_loss 4.561 | contrastive_loss 0.398 | total 4003.4 | n_correct 2494 | ppl 6.7 | accuracy 62.297 | uer 21.864 | wer 23.47 | raw_wer 23.47 | bleu 18.95 | wps 2212.1 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.95
2023-08-14 03:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-14 03:50:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-14 03:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-14 03:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.95) (writing took 50.99972332082689 seconds)
2023-08-14 03:53:13 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.302, trans_loss=3.509, nll_loss=1.722, w2v_ctc_loss=1.266, task_loss=0.952, contrastive_loss=0.252, total=4151.01, n_correct=2436.64, ppl=3.3, accuracy=58.7, wps=7248.7, ups=0.58, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.575, clip=0, loss_scale=8, train_wall=94, gb_free=12.6, wall=5248
2023-08-14 03:54:46 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.289, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.252, task_loss=0.989, contrastive_loss=0.234, total=4108.83, n_correct=2407.5, ppl=3.31, accuracy=58.593, wps=13283.4, ups=1.08, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.581, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=5340
2023-08-14 03:56:18 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.31, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.25, task_loss=0.979, contrastive_loss=0.33, total=4076.46, n_correct=2392.47, ppl=3.31, accuracy=58.69, wps=13162.5, ups=1.08, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.584, clip=0, loss_scale=8, train_wall=92, gb_free=12.3, wall=5433
2023-08-14 03:57:50 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.308, trans_loss=3.499, nll_loss=1.71, w2v_ctc_loss=1.235, task_loss=0.877, contrastive_loss=0.4, total=4175.9, n_correct=2465.34, ppl=3.27, accuracy=59.037, wps=13494.7, ups=1.08, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.583, clip=0, loss_scale=8, train_wall=92, gb_free=13.9, wall=5525
2023-08-14 03:59:23 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.276, trans_loss=3.498, nll_loss=1.709, w2v_ctc_loss=1.246, task_loss=1.025, contrastive_loss=0.235, total=4077.2, n_correct=2400.61, ppl=3.27, accuracy=58.879, wps=13115.9, ups=1.08, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.577, clip=0, loss_scale=8, train_wall=92, gb_free=16, wall=5618
2023-08-14 04:00:56 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.322, trans_loss=3.491, nll_loss=1.701, w2v_ctc_loss=1.223, task_loss=0.916, contrastive_loss=0.544, total=4133.46, n_correct=2446.46, ppl=3.25, accuracy=59.187, wps=13279.1, ups=1.08, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.599, clip=0, loss_scale=8, train_wall=93, gb_free=11.9, wall=5711
2023-08-14 04:02:28 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.251, trans_loss=3.494, nll_loss=1.701, w2v_ctc_loss=1.227, task_loss=0.927, contrastive_loss=0.216, total=4127.77, n_correct=2455.39, ppl=3.25, accuracy=59.485, wps=13394.4, ups=1.09, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.565, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5803
2023-08-14 04:04:01 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.245, trans_loss=3.488, nll_loss=1.695, w2v_ctc_loss=1.223, task_loss=0.937, contrastive_loss=0.222, total=4190.32, n_correct=2496.13, ppl=3.24, accuracy=59.569, wps=13467.6, ups=1.08, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.562, clip=0, loss_scale=8, train_wall=92, gb_free=16.6, wall=5896
2023-08-14 04:04:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 04:04:59 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.148 | trans_loss 5.358 | nll_loss 2.675 | w2v_ctc_loss 1.405 | task_loss 4.576 | contrastive_loss 0.387 | total 4003.4 | n_correct 2527.7 | ppl 6.39 | accuracy 63.139 | uer 20.651 | wer 22.322 | raw_wer 22.322 | bleu 19.36 | wps 2152.8 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 19.36
2023-08-14 04:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-14 04:04:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:05:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8837 updates, score 19.36) (writing took 29.3407428227365 seconds)
2023-08-14 04:05:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-14 04:05:28 | INFO | train | epoch 006 | loss 2.3 | trans_loss 3.505 | nll_loss 1.717 | w2v_ctc_loss 1.245 | task_loss 0.934 | contrastive_loss 0.313 | total 4138.65 | n_correct 2432.66 | ppl 3.29 | accuracy 58.779 | wps 12112.9 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.582 | clip 0 | loss_scale 8 | train_wall 1358 | gb_free 14.7 | wall 5983
2023-08-14 04:05:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 04:05:28 | INFO | fairseq.trainer | begin training epoch 7
2023-08-14 04:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 04:06:35 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.22, trans_loss=3.472, nll_loss=1.676, w2v_ctc_loss=1.194, task_loss=0.911, contrastive_loss=0.235, total=4110.43, n_correct=2464.14, ppl=3.2, accuracy=59.948, wps=7948.3, ups=0.65, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.564, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=6050
2023-08-14 04:08:07 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.216, trans_loss=3.465, nll_loss=1.667, w2v_ctc_loss=1.178, task_loss=0.947, contrastive_loss=0.306, total=4109.53, n_correct=2470.45, ppl=3.17, accuracy=60.115, wps=13337.8, ups=1.09, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.564, clip=0, loss_scale=8, train_wall=91, gb_free=13.2, wall=6142
2023-08-14 04:09:39 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.194, trans_loss=3.457, nll_loss=1.655, w2v_ctc_loss=1.177, task_loss=0.934, contrastive_loss=0.209, total=4133.29, n_correct=2497.79, ppl=3.15, accuracy=60.431, wps=13428.1, ups=1.09, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.571, clip=0, loss_scale=16, train_wall=91, gb_free=14.9, wall=6234
2023-08-14 04:11:13 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.243, trans_loss=3.465, nll_loss=1.665, w2v_ctc_loss=1.167, task_loss=0.908, contrastive_loss=0.47, total=4194.76, n_correct=2525.74, ppl=3.17, accuracy=60.212, wps=13392.5, ups=1.07, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.566, clip=0, loss_scale=16, train_wall=93, gb_free=12.7, wall=6327
2023-08-14 04:12:46 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.225, trans_loss=3.461, nll_loss=1.662, w2v_ctc_loss=1.167, task_loss=0.924, contrastive_loss=0.39, total=4153.22, n_correct=2504.48, ppl=3.17, accuracy=60.302, wps=13310.4, ups=1.07, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.562, clip=0, loss_scale=16, train_wall=93, gb_free=16.4, wall=6421
2023-08-14 04:14:18 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.179, trans_loss=3.459, nll_loss=1.656, w2v_ctc_loss=1.161, task_loss=0.916, contrastive_loss=0.216, total=4168.14, n_correct=2524.84, ppl=3.15, accuracy=60.575, wps=13550.1, ups=1.09, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.55, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=6512
2023-08-14 04:15:51 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.174, trans_loss=3.456, nll_loss=1.654, w2v_ctc_loss=1.162, task_loss=0.926, contrastive_loss=0.2, total=4157.82, n_correct=2520.4, ppl=3.15, accuracy=60.618, wps=13353.4, ups=1.08, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.557, clip=0, loss_scale=16, train_wall=92, gb_free=15.3, wall=6605
2023-08-14 04:17:23 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.182, trans_loss=3.453, nll_loss=1.652, w2v_ctc_loss=1.175, task_loss=0.976, contrastive_loss=0.198, total=4122.1, n_correct=2493.72, ppl=3.14, accuracy=60.496, wps=13260.8, ups=1.08, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.561, clip=0, loss_scale=16, train_wall=92, gb_free=15.3, wall=6698
2023-08-14 04:18:57 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.175, trans_loss=3.457, nll_loss=1.656, w2v_ctc_loss=1.159, task_loss=0.942, contrastive_loss=0.216, total=4147.23, n_correct=2513.34, ppl=3.15, accuracy=60.603, wps=13160.6, ups=1.06, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.558, clip=0, loss_scale=16, train_wall=94, gb_free=17.3, wall=6792
2023-08-14 04:20:31 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.191, trans_loss=3.451, nll_loss=1.649, w2v_ctc_loss=1.154, task_loss=0.889, contrastive_loss=0.308, total=4140.14, n_correct=2511.94, ppl=3.14, accuracy=60.673, wps=13272.6, ups=1.07, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.559, clip=0, loss_scale=16, train_wall=93, gb_free=15.6, wall=6885
2023-08-14 04:22:03 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.165, trans_loss=3.457, nll_loss=1.657, w2v_ctc_loss=1.161, task_loss=0.981, contrastive_loss=0.181, total=4103.51, n_correct=2490.86, ppl=3.15, accuracy=60.701, wps=13323, ups=1.09, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.551, clip=0, loss_scale=16, train_wall=91, gb_free=16.5, wall=6977
2023-08-14 04:23:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-14 04:23:36 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.204, trans_loss=3.444, nll_loss=1.642, w2v_ctc_loss=1.155, task_loss=0.932, contrastive_loss=0.384, total=4115.79, n_correct=2507.92, ppl=3.12, accuracy=60.934, wps=13124.5, ups=1.07, wpb=12298, bsz=460.5, num_updates=10000, lr=0.000141421, gnorm=0.563, clip=0, loss_scale=8, train_wall=93, gb_free=16.3, wall=7071
2023-08-14 04:23:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 04:23:59 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.086 | trans_loss 5.305 | nll_loss 2.611 | w2v_ctc_loss 1.345 | task_loss 4.563 | contrastive_loss 0.369 | total 4003.4 | n_correct 2565.6 | ppl 6.11 | accuracy 64.086 | uer 19.475 | wer 21.386 | raw_wer 21.386 | bleu 19.85 | wps 2217 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.85
2023-08-14 04:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-14 04:23:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-14 04:24:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-14 04:24:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.85) (writing took 52.58901168964803 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 04:26:28 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.153, trans_loss=3.446, nll_loss=1.643, w2v_ctc_loss=1.147, task_loss=0.95, contrastive_loss=0.205, total=4129.16, n_correct=2512.38, ppl=3.12, accuracy=60.845, wps=7189, ups=0.58, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.421, clip=0, loss_scale=8, train_wall=93, gb_free=16.5, wall=7243
2023-08-14 04:28:00 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.17, trans_loss=3.439, nll_loss=1.635, w2v_ctc_loss=1.152, task_loss=0.872, contrastive_loss=0.242, total=4177.71, n_correct=2554.92, ppl=3.11, accuracy=61.156, wps=13555.3, ups=1.09, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.427, clip=0, loss_scale=8, train_wall=91, gb_free=16.4, wall=7335
2023-08-14 04:29:34 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.183, trans_loss=3.447, nll_loss=1.646, w2v_ctc_loss=1.155, task_loss=1.007, contrastive_loss=0.306, total=4107.01, n_correct=2499.99, ppl=3.13, accuracy=60.871, wps=12994.7, ups=1.06, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.437, clip=0, loss_scale=8, train_wall=94, gb_free=12.8, wall=7429
2023-08-14 04:29:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
2023-08-14 04:30:06 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.3 | nll_loss 2.602 | w2v_ctc_loss 1.386 | task_loss 4.601 | contrastive_loss 0.369 | total 4003.4 | n_correct 2565.1 | ppl 6.07 | accuracy 64.073 | uer 20.383 | wer 22.184 | raw_wer 22.184 | bleu 19.96 | wps 2306.7 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 19.96
2023-08-14 04:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-14 04:30:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:30:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10310 updates, score 19.96) (writing took 30.95140557177365 seconds)
2023-08-14 04:30:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-14 04:30:36 | INFO | train | epoch 007 | loss 2.19 | trans_loss 3.454 | nll_loss 1.653 | w2v_ctc_loss 1.163 | task_loss 0.936 | contrastive_loss 0.272 | total 4137.22 | n_correct 2506.89 | ppl 3.14 | accuracy 60.594 | wps 12061.3 | ups 0.98 | wpb 12351.6 | bsz 457.8 | num_updates 10310 | lr 0.000139279 | gnorm 0.533 | clip 0 | loss_scale 8 | train_wall 1361 | gb_free 12.8 | wall 7491
2023-08-14 04:30:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 04:30:37 | INFO | fairseq.trainer | begin training epoch 8
2023-08-14 04:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 04:32:07 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.128, trans_loss=3.435, nll_loss=1.625, w2v_ctc_loss=1.121, task_loss=0.994, contrastive_loss=0.199, total=4106.01, n_correct=2522.5, ppl=3.08, accuracy=61.434, wps=8025.6, ups=0.66, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.425, clip=0, loss_scale=8, train_wall=91, gb_free=16.9, wall=7582
2023-08-14 04:33:39 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.126, trans_loss=3.426, nll_loss=1.613, w2v_ctc_loss=1.119, task_loss=1.01, contrastive_loss=0.219, total=4043.12, n_correct=2493.29, ppl=3.06, accuracy=61.667, wps=13027, ups=1.08, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.427, clip=0, loss_scale=8, train_wall=92, gb_free=12.9, wall=7674
2023-08-14 04:35:12 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.122, trans_loss=3.42, nll_loss=1.609, w2v_ctc_loss=1.116, task_loss=0.877, contrastive_loss=0.215, total=4207.9, n_correct=2598.39, ppl=3.05, accuracy=61.75, wps=13568.8, ups=1.08, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.425, clip=0, loss_scale=8, train_wall=92, gb_free=13.6, wall=7767
2023-08-14 04:36:46 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.138, trans_loss=3.425, nll_loss=1.614, w2v_ctc_loss=1.13, task_loss=0.983, contrastive_loss=0.238, total=4134.6, n_correct=2546.61, ppl=3.06, accuracy=61.593, wps=13154.1, ups=1.07, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.425, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=7860
2023-08-14 04:38:20 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.195, trans_loss=3.423, nll_loss=1.614, w2v_ctc_loss=1.114, task_loss=0.845, contrastive_loss=0.499, total=4196.6, n_correct=2584.53, ppl=3.06, accuracy=61.586, wps=13339.2, ups=1.06, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.434, clip=0, loss_scale=8, train_wall=93, gb_free=12.4, wall=7954
2023-08-14 04:39:53 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.121, trans_loss=3.42, nll_loss=1.613, w2v_ctc_loss=1.132, task_loss=1.018, contrastive_loss=0.172, total=4065.55, n_correct=2501.55, ppl=3.06, accuracy=61.53, wps=13026.7, ups=1.07, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.425, clip=0, loss_scale=8, train_wall=93, gb_free=15.9, wall=8048
2023-08-14 04:41:25 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.119, trans_loss=3.419, nll_loss=1.608, w2v_ctc_loss=1.13, task_loss=0.967, contrastive_loss=0.183, total=4135.41, n_correct=2557.06, ppl=3.05, accuracy=61.833, wps=13332.9, ups=1.08, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.42, clip=0, loss_scale=8, train_wall=92, gb_free=15.6, wall=8140
2023-08-14 04:42:57 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.124, trans_loss=3.41, nll_loss=1.599, w2v_ctc_loss=1.112, task_loss=0.946, contrastive_loss=0.269, total=4128.86, n_correct=2562.36, ppl=3.03, accuracy=62.06, wps=13428.6, ups=1.09, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.422, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=8232
2023-08-14 04:44:30 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.133, trans_loss=3.416, nll_loss=1.606, w2v_ctc_loss=1.114, task_loss=0.904, contrastive_loss=0.278, total=4166.92, n_correct=2579.81, ppl=3.04, accuracy=61.912, wps=13507.2, ups=1.09, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.429, clip=0, loss_scale=8, train_wall=92, gb_free=14.1, wall=8324
2023-08-14 04:46:02 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.1, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.109, task_loss=0.901, contrastive_loss=0.177, total=4150.39, n_correct=2574.42, ppl=3.04, accuracy=62.028, wps=13393.2, ups=1.08, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.418, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=8417
2023-08-14 04:47:35 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.148, trans_loss=3.418, nll_loss=1.607, w2v_ctc_loss=1.107, task_loss=0.927, contrastive_loss=0.4, total=4197.39, n_correct=2598.16, ppl=3.05, accuracy=61.899, wps=13423.7, ups=1.07, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.419, clip=0, loss_scale=8, train_wall=93, gb_free=16.5, wall=8510
2023-08-14 04:49:08 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.105, trans_loss=3.41, nll_loss=1.598, w2v_ctc_loss=1.109, task_loss=0.884, contrastive_loss=0.189, total=4180.55, n_correct=2597.71, ppl=3.03, accuracy=62.138, wps=13542.8, ups=1.08, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=8602
2023-08-14 04:50:39 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.111, trans_loss=3.415, nll_loss=1.604, w2v_ctc_loss=1.114, task_loss=0.977, contrastive_loss=0.211, total=4062.6, n_correct=2510.68, ppl=3.04, accuracy=61.8, wps=13219.4, ups=1.09, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.424, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=8694
2023-08-14 04:52:12 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.129, trans_loss=3.416, nll_loss=1.606, w2v_ctc_loss=1.113, task_loss=0.909, contrastive_loss=0.279, total=4159.11, n_correct=2582.14, ppl=3.04, accuracy=62.084, wps=13467.1, ups=1.08, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.433, clip=0, loss_scale=8, train_wall=92, gb_free=13, wall=8786
2023-08-14 04:53:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 04:53:52 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.04 | trans_loss 5.256 | nll_loss 2.544 | w2v_ctc_loss 1.321 | task_loss 4.602 | contrastive_loss 0.348 | total 4003.4 | n_correct 2601.2 | ppl 5.83 | accuracy 64.975 | uer 19.298 | wer 21.185 | raw_wer 21.185 | bleu 20.6 | wps 2155.9 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 20.6
2023-08-14 04:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-14 04:53:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 04:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 20.6) (writing took 29.084863966330886 seconds)
2023-08-14 04:54:22 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-14 04:54:22 | INFO | train | epoch 008 | loss 2.127 | trans_loss 3.419 | nll_loss 1.608 | w2v_ctc_loss 1.116 | task_loss 0.935 | contrastive_loss 0.258 | total 4138.65 | n_correct 2559.2 | ppl 3.05 | accuracy 61.837 | wps 12775.7 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.423 | clip 0 | loss_scale 8 | train_wall 1357 | gb_free 16.6 | wall 8917
2023-08-14 04:54:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 04:54:22 | INFO | fairseq.trainer | begin training epoch 9
2023-08-14 04:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 04:54:46 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.117, trans_loss=3.409, nll_loss=1.595, w2v_ctc_loss=1.086, task_loss=0.917, contrastive_loss=0.373, total=4121.25, n_correct=2568.75, ppl=3.02, accuracy=62.329, wps=8038.6, ups=0.65, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.41, clip=0, loss_scale=8, train_wall=92, gb_free=17.5, wall=8939
2023-08-14 04:56:18 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.066, trans_loss=3.385, nll_loss=1.566, w2v_ctc_loss=1.069, task_loss=0.879, contrastive_loss=0.203, total=4191.82, n_correct=2638.04, ppl=2.96, accuracy=62.933, wps=13664.5, ups=1.09, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.415, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=9033
2023-08-14 04:57:51 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.053, trans_loss=3.39, nll_loss=1.571, w2v_ctc_loss=1.068, task_loss=1.006, contrastive_loss=0.16, total=4061.27, n_correct=2549.82, ppl=2.97, accuracy=62.784, wps=13035.7, ups=1.07, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.414, clip=0, loss_scale=8, train_wall=92, gb_free=17.3, wall=9126
2023-08-14 04:57:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 04:58:14 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.04 | trans_loss 5.259 | nll_loss 2.548 | w2v_ctc_loss 1.316 | task_loss 4.566 | contrastive_loss 0.347 | total 4003.4 | n_correct 2596.2 | ppl 5.85 | accuracy 64.85 | uer 19.494 | wer 21.278 | raw_wer 21.278 | bleu 20.83 | wps 2203.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.83
2023-08-14 04:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-14 04:58:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-14 04:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-14 04:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.83) (writing took 52.45724550448358 seconds)
2023-08-14 05:00:40 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.053, trans_loss=3.377, nll_loss=1.557, w2v_ctc_loss=1.056, task_loss=0.884, contrastive_loss=0.21, total=4146.43, n_correct=2616.74, ppl=2.94, accuracy=63.108, wps=7336.4, ups=0.59, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=9295
2023-08-14 05:02:13 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.059, trans_loss=3.394, nll_loss=1.576, w2v_ctc_loss=1.067, task_loss=0.919, contrastive_loss=0.177, total=4194.84, n_correct=2627.04, ppl=2.98, accuracy=62.626, wps=13431.2, ups=1.07, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.412, clip=0, loss_scale=16, train_wall=93, gb_free=15.8, wall=9388
2023-08-14 05:03:45 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.085, trans_loss=3.392, nll_loss=1.573, w2v_ctc_loss=1.089, task_loss=0.982, contrastive_loss=0.226, total=4124.3, n_correct=2584.63, ppl=2.97, accuracy=62.668, wps=13380.1, ups=1.09, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.418, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9480
2023-08-14 05:05:18 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.054, trans_loss=3.383, nll_loss=1.565, w2v_ctc_loss=1.065, task_loss=0.959, contrastive_loss=0.186, total=4120.96, n_correct=2594.58, ppl=2.96, accuracy=62.961, wps=13281.1, ups=1.08, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.411, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=9573
2023-08-14 05:06:50 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.089, trans_loss=3.393, nll_loss=1.577, w2v_ctc_loss=1.087, task_loss=0.952, contrastive_loss=0.264, total=4088.53, n_correct=2557.13, ppl=2.98, accuracy=62.544, wps=13208.2, ups=1.08, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.419, clip=0, loss_scale=16, train_wall=92, gb_free=16.7, wall=9665
2023-08-14 05:08:23 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.124, trans_loss=3.387, nll_loss=1.57, w2v_ctc_loss=1.076, task_loss=0.845, contrastive_loss=0.408, total=4220.43, n_correct=2648.01, ppl=2.97, accuracy=62.743, wps=13567.6, ups=1.08, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.418, clip=0, loss_scale=16, train_wall=92, gb_free=14, wall=9758
2023-08-14 05:09:57 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.094, trans_loss=3.39, nll_loss=1.57, w2v_ctc_loss=1.067, task_loss=0.963, contrastive_loss=0.393, total=4146.05, n_correct=2605.62, ppl=2.97, accuracy=62.846, wps=13206.4, ups=1.07, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.412, clip=0, loss_scale=16, train_wall=93, gb_free=17.4, wall=9852
2023-08-14 05:11:30 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.061, trans_loss=3.397, nll_loss=1.579, w2v_ctc_loss=1.077, task_loss=1.044, contrastive_loss=0.175, total=4101.48, n_correct=2571.21, ppl=2.99, accuracy=62.69, wps=13161.6, ups=1.08, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.417, clip=0, loss_scale=16, train_wall=92, gb_free=15.6, wall=9945
2023-08-14 05:13:02 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.067, trans_loss=3.396, nll_loss=1.575, w2v_ctc_loss=1.074, task_loss=0.881, contrastive_loss=0.198, total=4179.09, n_correct=2624.71, ppl=2.98, accuracy=62.806, wps=13512.3, ups=1.08, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=14.9, wall=10037
2023-08-14 05:14:35 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.067, trans_loss=3.391, nll_loss=1.574, w2v_ctc_loss=1.083, task_loss=0.991, contrastive_loss=0.182, total=4140.66, n_correct=2594.93, ppl=2.98, accuracy=62.669, wps=13296.5, ups=1.08, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=16.8, wall=10130
2023-08-14 05:16:07 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.092, trans_loss=3.385, nll_loss=1.564, w2v_ctc_loss=1.058, task_loss=0.851, contrastive_loss=0.369, total=4204.43, n_correct=2650.42, ppl=2.96, accuracy=63.039, wps=13573.9, ups=1.08, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.412, clip=0, loss_scale=16, train_wall=92, gb_free=17.4, wall=10222
2023-08-14 05:17:40 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.061, trans_loss=3.398, nll_loss=1.581, w2v_ctc_loss=1.082, task_loss=1.013, contrastive_loss=0.156, total=4069.19, n_correct=2550.31, ppl=2.99, accuracy=62.674, wps=13156.8, ups=1.08, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.412, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=10315
2023-08-14 05:18:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 05:18:58 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.023 | trans_loss 5.229 | nll_loss 2.514 | w2v_ctc_loss 1.334 | task_loss 4.584 | contrastive_loss 0.34 | total 4003.4 | n_correct 2609 | ppl 5.71 | accuracy 65.17 | uer 18.958 | wer 20.76 | raw_wer 20.76 | bleu 20.9 | wps 1901.2 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 20.9
2023-08-14 05:18:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-14 05:18:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 05:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 05:19:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 20.9) (writing took 28.32626185566187 seconds)
2023-08-14 05:19:27 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-14 05:19:27 | INFO | train | epoch 009 | loss 2.074 | trans_loss 3.39 | nll_loss 1.571 | w2v_ctc_loss 1.073 | task_loss 0.936 | contrastive_loss 0.242 | total 4138.65 | n_correct 2599.27 | ppl 2.97 | accuracy 62.805 | wps 12102.9 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.414 | clip 0 | loss_scale 16 | train_wall 1356 | gb_free 11.1 | wall 10422
2023-08-14 05:19:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 05:19:27 | INFO | fairseq.trainer | begin training epoch 10
2023-08-14 05:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 05:20:13 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.052, trans_loss=3.38, nll_loss=1.557, w2v_ctc_loss=1.048, task_loss=0.892, contrastive_loss=0.249, total=4100.8, n_correct=2594.32, ppl=2.94, accuracy=63.264, wps=7972.2, ups=0.65, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.416, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=10468
2023-08-14 05:21:46 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.011, trans_loss=3.362, nll_loss=1.536, w2v_ctc_loss=1.026, task_loss=0.882, contrastive_loss=0.175, total=4247.35, n_correct=2708.83, ppl=2.9, accuracy=63.777, wps=13751.1, ups=1.08, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.402, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=10560
2023-08-14 05:23:18 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.035, trans_loss=3.36, nll_loss=1.531, w2v_ctc_loss=1.03, task_loss=0.925, contrastive_loss=0.294, total=4122.82, n_correct=2630.54, ppl=2.89, accuracy=63.804, wps=13334.3, ups=1.08, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=10653
2023-08-14 05:24:51 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.026, trans_loss=3.359, nll_loss=1.535, w2v_ctc_loss=1.037, task_loss=0.945, contrastive_loss=0.209, total=4138.27, n_correct=2635.56, ppl=2.9, accuracy=63.687, wps=13267.6, ups=1.07, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.409, clip=0, loss_scale=16, train_wall=93, gb_free=16.1, wall=10746
2023-08-14 05:26:25 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.045, trans_loss=3.365, nll_loss=1.539, w2v_ctc_loss=1.016, task_loss=0.9, contrastive_loss=0.384, total=4196.37, n_correct=2672.64, ppl=2.91, accuracy=63.689, wps=13357.8, ups=1.07, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.41, clip=0, loss_scale=16, train_wall=93, gb_free=15.7, wall=10840
2023-08-14 05:27:57 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.035, trans_loss=3.378, nll_loss=1.552, w2v_ctc_loss=1.059, task_loss=1.005, contrastive_loss=0.163, total=4102.8, n_correct=2598.73, ppl=2.93, accuracy=63.34, wps=13223.7, ups=1.08, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.412, clip=0, loss_scale=16, train_wall=92, gb_free=16.7, wall=10932
2023-08-14 05:29:30 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.049, trans_loss=3.371, nll_loss=1.546, w2v_ctc_loss=1.04, task_loss=0.889, contrastive_loss=0.278, total=4176.56, n_correct=2652.96, ppl=2.92, accuracy=63.52, wps=13410.8, ups=1.08, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.409, clip=0, loss_scale=16, train_wall=92, gb_free=15.8, wall=11025
2023-08-14 05:31:02 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.033, trans_loss=3.37, nll_loss=1.545, w2v_ctc_loss=1.06, task_loss=0.937, contrastive_loss=0.161, total=4125.87, n_correct=2618.13, ppl=2.92, accuracy=63.456, wps=13362.9, ups=1.09, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.418, clip=0, loss_scale=16, train_wall=92, gb_free=14, wall=11117
2023-08-14 05:31:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 05:31:26 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.02 | trans_loss 5.222 | nll_loss 2.504 | w2v_ctc_loss 1.347 | task_loss 4.599 | contrastive_loss 0.337 | total 4003.4 | n_correct 2621.4 | ppl 5.67 | accuracy 65.479 | uer 19.26 | wer 21.163 | raw_wer 21.163 | bleu 21.52 | wps 2107.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.52
2023-08-14 05:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-14 05:31:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-14 05:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-14 05:32:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.52) (writing took 58.61775934509933 seconds)
2023-08-14 05:34:01 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.012, trans_loss=3.366, nll_loss=1.541, w2v_ctc_loss=1.032, task_loss=0.924, contrastive_loss=0.165, total=4128.44, n_correct=2628.68, ppl=2.91, accuracy=63.672, wps=6905.1, ups=0.56, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.41, clip=0, loss_scale=32, train_wall=92, gb_free=14.4, wall=11296
2023-08-14 05:35:33 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.03, trans_loss=3.368, nll_loss=1.54, w2v_ctc_loss=1.045, task_loss=0.899, contrastive_loss=0.199, total=4160.94, n_correct=2646.87, ppl=2.91, accuracy=63.612, wps=13554.7, ups=1.09, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.411, clip=0, loss_scale=32, train_wall=91, gb_free=15.1, wall=11387
2023-08-14 05:37:05 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.021, trans_loss=3.367, nll_loss=1.541, w2v_ctc_loss=1.044, task_loss=1.013, contrastive_loss=0.173, total=4067.53, n_correct=2582.71, ppl=2.91, accuracy=63.496, wps=13095.4, ups=1.08, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.412, clip=0, loss_scale=32, train_wall=92, gb_free=16.6, wall=11480
2023-08-14 05:38:38 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.027, trans_loss=3.373, nll_loss=1.55, w2v_ctc_loss=1.053, task_loss=1.042, contrastive_loss=0.158, total=4044.03, n_correct=2561.22, ppl=2.93, accuracy=63.333, wps=13072.9, ups=1.08, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.413, clip=0, loss_scale=32, train_wall=92, gb_free=17, wall=11572
2023-08-14 05:40:10 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.019, trans_loss=3.361, nll_loss=1.538, w2v_ctc_loss=1.05, task_loss=0.96, contrastive_loss=0.153, total=4110.41, n_correct=2610.5, ppl=2.9, accuracy=63.509, wps=13302.6, ups=1.08, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.409, clip=0, loss_scale=32, train_wall=92, gb_free=16.2, wall=11665
2023-08-14 05:41:43 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.019, trans_loss=3.365, nll_loss=1.54, w2v_ctc_loss=1.043, task_loss=0.956, contrastive_loss=0.164, total=4121.38, n_correct=2627.21, ppl=2.91, accuracy=63.746, wps=13284.6, ups=1.08, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.413, clip=0, loss_scale=32, train_wall=92, gb_free=13.6, wall=11758
2023-08-14 05:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 05:43:16 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.042, trans_loss=3.376, nll_loss=1.551, w2v_ctc_loss=1.031, task_loss=0.897, contrastive_loss=0.269, total=4177.73, n_correct=2655.34, ppl=2.93, accuracy=63.559, wps=13297.2, ups=1.07, wpb=12461.7, bsz=472.7, num_updates=14700, lr=0.000116642, gnorm=0.411, clip=0, loss_scale=16, train_wall=93, gb_free=16.1, wall=11851
2023-08-14 05:43:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 05:44:08 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.011 | trans_loss 5.214 | nll_loss 2.494 | w2v_ctc_loss 1.332 | task_loss 4.616 | contrastive_loss 0.342 | total 4003.4 | n_correct 2629.7 | ppl 5.63 | accuracy 65.687 | uer 18.493 | wer 20.353 | raw_wer 20.353 | bleu 21.49 | wps 2195.8 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.52
2023-08-14 05:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-14 05:44:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt
2023-08-14 05:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt
2023-08-14 05:44:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt (epoch 10 @ 14731 updates, score 21.49) (writing took 22.717196261510253 seconds)
2023-08-14 05:44:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-14 05:44:34 | INFO | train | epoch 010 | loss 2.03 | trans_loss 3.367 | nll_loss 1.542 | w2v_ctc_loss 1.039 | task_loss 0.937 | contrastive_loss 0.221 | total 4137.35 | n_correct 2630.96 | ppl 2.91 | accuracy 63.591 | wps 12072 | ups 0.98 | wpb 12351.9 | bsz 457.7 | num_updates 14731 | lr 0.00011652 | gnorm 0.41 | clip 0 | loss_scale 16 | train_wall 1357 | gb_free 17 | wall 11929
2023-08-14 05:44:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 05:44:34 | INFO | fairseq.trainer | begin training epoch 11
2023-08-14 05:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 05:45:46 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.006, trans_loss=3.348, nll_loss=1.517, w2v_ctc_loss=1.015, task_loss=0.873, contrastive_loss=0.242, total=4166, n_correct=2675.93, ppl=2.86, accuracy=64.233, wps=8329.3, ups=0.67, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.399, clip=0, loss_scale=16, train_wall=92, gb_free=17.6, wall=12001
2023-08-14 05:47:18 | INFO | train_inner | epoch 011:    169 / 1474 loss=1.982, trans_loss=3.346, nll_loss=1.517, w2v_ctc_loss=1.007, task_loss=0.957, contrastive_loss=0.16, total=4100.74, n_correct=2634.3, ppl=2.86, accuracy=64.24, wps=13345, ups=1.09, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.404, clip=0, loss_scale=16, train_wall=91, gb_free=14.1, wall=12092
2023-08-14 05:48:50 | INFO | train_inner | epoch 011:    269 / 1474 loss=1.975, trans_loss=3.344, nll_loss=1.513, w2v_ctc_loss=1.004, task_loss=0.966, contrastive_loss=0.147, total=4115.58, n_correct=2646.62, ppl=2.85, accuracy=64.307, wps=13355.4, ups=1.09, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.403, clip=0, loss_scale=16, train_wall=92, gb_free=15.7, wall=12184
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 05:49:59 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.052, trans_loss=4.972, nll_loss=2.252, w2v_ctc_loss=0.75, task_loss=1.443, contrastive_loss=0.118, total=4094.16, n_correct=2629.1, ppl=4.76, accuracy=64.216, wps=11882.3, ups=1.44, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=12254
2023-08-14 05:51:10 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.072, trans_loss=5.006, nll_loss=2.275, w2v_ctc_loss=0.75, task_loss=1.455, contrastive_loss=0.238, total=4112.8, n_correct=2632.43, ppl=4.84, accuracy=64.006, wps=11641.4, ups=1.42, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.54, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=12324
2023-08-14 05:52:19 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.072, trans_loss=5.004, nll_loss=2.273, w2v_ctc_loss=0.757, task_loss=1.514, contrastive_loss=0.233, total=4071.06, n_correct=2606.42, ppl=4.83, accuracy=64.023, wps=11757.4, ups=1.44, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=12394
2023-08-14 05:53:28 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.074, trans_loss=4.996, nll_loss=2.263, w2v_ctc_loss=0.755, task_loss=1.375, contrastive_loss=0.296, total=4156.4, n_correct=2664.68, ppl=4.8, accuracy=64.11, wps=12026.1, ups=1.45, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=12463
2023-08-14 05:54:38 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.063, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.764, task_loss=1.425, contrastive_loss=0.116, total=4169.17, n_correct=2673.13, ppl=4.84, accuracy=64.117, wps=11959.9, ups=1.43, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=12532
2023-08-14 05:55:48 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.064, trans_loss=5.008, nll_loss=2.278, w2v_ctc_loss=0.763, task_loss=1.471, contrastive_loss=0.108, total=4120.01, n_correct=2631.58, ppl=4.85, accuracy=63.873, wps=11740.2, ups=1.42, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.529, clip=0, loss_scale=16, train_wall=70, gb_free=13, wall=12603
2023-08-14 05:56:57 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.063, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.763, task_loss=1.42, contrastive_loss=0.121, total=4145.45, n_correct=2652.06, ppl=4.84, accuracy=63.975, wps=11938.1, ups=1.44, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=12672
2023-08-14 05:58:06 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.063, trans_loss=5.001, nll_loss=2.271, w2v_ctc_loss=0.767, task_loss=1.377, contrastive_loss=0.138, total=4141.18, n_correct=2654.73, ppl=4.83, accuracy=64.106, wps=11980.2, ups=1.45, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=12741
2023-08-14 05:59:16 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.061, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.76, task_loss=1.403, contrastive_loss=0.123, total=4173.93, n_correct=2670.63, ppl=4.85, accuracy=63.984, wps=11971, ups=1.43, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=12811
2023-08-14 06:00:27 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.071, trans_loss=5.001, nll_loss=2.271, w2v_ctc_loss=0.767, task_loss=1.35, contrastive_loss=0.194, total=4174.26, n_correct=2670.58, ppl=4.83, accuracy=63.977, wps=11837.3, ups=1.42, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.544, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=12881
2023-08-14 06:00:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
2023-08-14 06:00:50 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.019 | trans_loss 5.204 | nll_loss 2.481 | w2v_ctc_loss 1.383 | task_loss 4.671 | contrastive_loss 0.337 | total 4003.4 | n_correct 2636.8 | ppl 5.58 | accuracy 65.864 | uer 18.504 | wer 20.357 | raw_wer 20.357 | bleu 21.19 | wps 2196.5 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.52
2023-08-14 06:00:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-14 06:00:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-14 06:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-14 06:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.19) (writing took 39.97574491612613 seconds)
2023-08-14 06:02:41 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.075, trans_loss=4.998, nll_loss=2.267, w2v_ctc_loss=0.749, task_loss=1.295, contrastive_loss=0.353, total=4191.56, n_correct=2685.14, ppl=4.81, accuracy=64.061, wps=6228.8, ups=0.74, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=13016
2023-08-14 06:03:51 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.058, trans_loss=5.004, nll_loss=2.274, w2v_ctc_loss=0.756, task_loss=1.348, contrastive_loss=0.129, total=4161.81, n_correct=2669.27, ppl=4.84, accuracy=64.137, wps=11994.2, ups=1.44, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=13085
2023-08-14 06:03:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 06:04:19 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.995 | trans_loss 5.201 | nll_loss 2.475 | w2v_ctc_loss 1.312 | task_loss 4.657 | contrastive_loss 0.336 | total 4003.4 | n_correct 2637.1 | ppl 5.56 | accuracy 65.872 | uer 18.406 | wer 20.156 | raw_wer 20.156 | bleu 21.39 | wps 2018.3 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.52
2023-08-14 06:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-14 06:04:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3907.pt
2023-08-14 06:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3907.pt
2023-08-14 06:04:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3907.pt (epoch 11 @ 16205 updates, score 21.39) (writing took 22.20242513716221 seconds)
2023-08-14 06:04:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-14 06:04:42 | INFO | train | epoch 011 | loss 2.045 | trans_loss 4.588 | nll_loss 2.082 | w2v_ctc_loss 0.82 | task_loss 1.287 | contrastive_loss 0.174 | total 4138.65 | n_correct 2652.69 | ppl 4.23 | accuracy 64.095 | wps 11015.4 | ups 1.22 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.512 | clip 0 | loss_scale 16 | train_wall 1080 | gb_free 16.9 | wall 13136
2023-08-14 06:04:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 06:04:42 | INFO | fairseq.trainer | begin training epoch 12
2023-08-14 06:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 06:05:55 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.037, trans_loss=4.961, nll_loss=2.217, w2v_ctc_loss=0.739, task_loss=1.355, contrastive_loss=0.158, total=4139.2, n_correct=2686.69, ppl=4.65, accuracy=64.908, wps=6656.4, ups=0.8, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=13210
2023-08-14 06:07:05 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.044, trans_loss=4.97, nll_loss=2.229, w2v_ctc_loss=0.751, task_loss=1.44, contrastive_loss=0.111, total=4126.87, n_correct=2665.83, ppl=4.69, accuracy=64.597, wps=11796.1, ups=1.43, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.534, clip=0, loss_scale=16, train_wall=70, gb_free=16.1, wall=13280
2023-08-14 06:08:14 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.038, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.735, task_loss=1.315, contrastive_loss=0.139, total=4203.54, n_correct=2723.21, ppl=4.69, accuracy=64.784, wps=12186.4, ups=1.45, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=13349
2023-08-14 06:09:23 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.041, trans_loss=4.973, nll_loss=2.233, w2v_ctc_loss=0.746, task_loss=1.378, contrastive_loss=0.124, total=4149.28, n_correct=2681.14, ppl=4.7, accuracy=64.617, wps=12009.9, ups=1.45, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=13418
2023-08-14 06:10:33 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.048, trans_loss=4.984, nll_loss=2.249, w2v_ctc_loss=0.748, task_loss=1.42, contrastive_loss=0.131, total=4106.46, n_correct=2651.27, ppl=4.75, accuracy=64.563, wps=11761.5, ups=1.43, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=13488
2023-08-14 06:11:44 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.051, trans_loss=4.974, nll_loss=2.236, w2v_ctc_loss=0.749, task_loss=1.34, contrastive_loss=0.197, total=4190.91, n_correct=2709.01, ppl=4.71, accuracy=64.64, wps=11845.8, ups=1.41, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.539, clip=0, loss_scale=32, train_wall=70, gb_free=15.6, wall=13559
2023-08-14 06:12:53 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.049, trans_loss=4.972, nll_loss=2.233, w2v_ctc_loss=0.736, task_loss=1.294, contrastive_loss=0.282, total=4203.66, n_correct=2725.39, ppl=4.7, accuracy=64.834, wps=12153.4, ups=1.45, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=13628
2023-08-14 06:14:02 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.042, trans_loss=4.971, nll_loss=2.23, w2v_ctc_loss=0.75, task_loss=1.424, contrastive_loss=0.12, total=4095.72, n_correct=2651.97, ppl=4.69, accuracy=64.75, wps=11822.5, ups=1.44, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=13697
2023-08-14 06:15:12 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.05, trans_loss=4.974, nll_loss=2.235, w2v_ctc_loss=0.748, task_loss=1.438, contrastive_loss=0.172, total=4162.82, n_correct=2689.27, ppl=4.71, accuracy=64.602, wps=11932.6, ups=1.43, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=13767
2023-08-14 06:16:22 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.049, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.748, task_loss=1.43, contrastive_loss=0.182, total=4117.63, n_correct=2660.97, ppl=4.72, accuracy=64.624, wps=11739.1, ups=1.43, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=13837
2023-08-14 06:17:31 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.062, trans_loss=4.983, nll_loss=2.247, w2v_ctc_loss=0.757, task_loss=1.473, contrastive_loss=0.226, total=4046.48, n_correct=2610.97, ppl=4.75, accuracy=64.524, wps=11693.4, ups=1.44, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.544, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=13906
2023-08-14 06:18:41 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.065, trans_loss=4.998, nll_loss=2.267, w2v_ctc_loss=0.765, task_loss=1.369, contrastive_loss=0.194, total=4201.13, n_correct=2696.46, ppl=4.81, accuracy=64.184, wps=12101, ups=1.44, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=13976
2023-08-14 06:19:51 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.053, trans_loss=4.981, nll_loss=2.244, w2v_ctc_loss=0.766, task_loss=1.567, contrastive_loss=0.107, total=4070.27, n_correct=2624.21, ppl=4.74, accuracy=64.473, wps=11671.4, ups=1.43, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=14045
2023-08-14 06:21:00 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.053, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.746, task_loss=1.413, contrastive_loss=0.209, total=4139.63, n_correct=2667.86, ppl=4.76, accuracy=64.447, wps=11855.1, ups=1.43, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=14115
2023-08-14 06:21:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 06:22:20 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.992 | trans_loss 5.194 | nll_loss 2.467 | w2v_ctc_loss 1.321 | task_loss 4.599 | contrastive_loss 0.338 | total 4003.4 | n_correct 2644.2 | ppl 5.53 | accuracy 66.049 | uer 18.329 | wer 20.242 | raw_wer 20.242 | bleu 21.72 | wps 2002.9 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 21.72
2023-08-14 06:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-14 06:22:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 06:22:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 06:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17679 updates, score 21.72) (writing took 34.97842286340892 seconds)
2023-08-14 06:22:56 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-14 06:22:56 | INFO | train | epoch 012 | loss 2.049 | trans_loss 4.977 | nll_loss 2.239 | w2v_ctc_loss 0.749 | task_loss 1.404 | contrastive_loss 0.166 | total 4138.65 | n_correct 2673.64 | ppl 4.72 | accuracy 64.602 | wps 11149.1 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 12.5 | wall 14231
2023-08-14 06:22:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 06:22:56 | INFO | fairseq.trainer | begin training epoch 13
2023-08-14 06:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 06:23:18 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.051, trans_loss=4.986, nll_loss=2.251, w2v_ctc_loss=0.762, task_loss=1.458, contrastive_loss=0.115, total=4096.49, n_correct=2641.3, ppl=4.76, accuracy=64.477, wps=5963, ups=0.73, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=14.2, wall=14253
2023-08-14 06:24:27 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.029, trans_loss=4.949, nll_loss=2.202, w2v_ctc_loss=0.737, task_loss=1.406, contrastive_loss=0.128, total=4160.97, n_correct=2711.28, ppl=4.6, accuracy=65.16, wps=11993.2, ups=1.44, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=14322
2023-08-14 06:25:38 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.049, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.731, task_loss=1.296, contrastive_loss=0.339, total=4212.08, n_correct=2736.94, ppl=4.66, accuracy=64.978, wps=11946, ups=1.42, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=14.3, wall=14392
2023-08-14 06:26:47 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.025, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.734, task_loss=1.46, contrastive_loss=0.11, total=4102.3, n_correct=2678.44, ppl=4.59, accuracy=65.291, wps=11823.9, ups=1.44, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=14462
2023-08-14 06:26:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 06:27:12 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.985 | trans_loss 5.195 | nll_loss 2.469 | w2v_ctc_loss 1.293 | task_loss 4.621 | contrastive_loss 0.342 | total 4003.4 | n_correct 2642.1 | ppl 5.54 | accuracy 65.996 | uer 18.549 | wer 20.581 | raw_wer 20.581 | bleu 21.61 | wps 1959.7 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.72
2023-08-14 06:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-14 06:27:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-14 06:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-14 06:27:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.61) (writing took 46.74615095183253 seconds)
2023-08-14 06:29:11 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.029, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.732, task_loss=1.317, contrastive_loss=0.158, total=4177.29, n_correct=2723.91, ppl=4.61, accuracy=65.208, wps=5810, ups=0.7, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=14606
2023-08-14 06:30:20 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.034, trans_loss=4.956, nll_loss=2.211, w2v_ctc_loss=0.734, task_loss=1.362, contrastive_loss=0.195, total=4201.22, n_correct=2732.1, ppl=4.63, accuracy=65.031, wps=12079.5, ups=1.44, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=12.5, wall=14675
2023-08-14 06:31:30 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.021, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.73, task_loss=1.361, contrastive_loss=0.106, total=4161.98, n_correct=2716.4, ppl=4.61, accuracy=65.267, wps=11938.3, ups=1.43, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=14745
2023-08-14 06:32:39 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.04, trans_loss=4.96, nll_loss=2.216, w2v_ctc_loss=0.754, task_loss=1.562, contrastive_loss=0.106, total=4096.76, n_correct=2655.71, ppl=4.65, accuracy=64.825, wps=11833.8, ups=1.44, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=14814
2023-08-14 06:33:49 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.04, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.743, task_loss=1.421, contrastive_loss=0.155, total=4121.73, n_correct=2669.15, ppl=4.66, accuracy=64.758, wps=11806.4, ups=1.43, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.541, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=14884
2023-08-14 06:34:58 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.033, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.742, task_loss=1.435, contrastive_loss=0.118, total=4107.01, n_correct=2672.08, ppl=4.65, accuracy=65.061, wps=11899.6, ups=1.45, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=14953
2023-08-14 06:36:08 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.045, trans_loss=4.963, nll_loss=2.221, w2v_ctc_loss=0.752, task_loss=1.486, contrastive_loss=0.167, total=4081.02, n_correct=2645.22, ppl=4.66, accuracy=64.818, wps=11778.4, ups=1.44, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=15022
2023-08-14 06:37:16 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.029, trans_loss=4.952, nll_loss=2.207, w2v_ctc_loss=0.736, task_loss=1.386, contrastive_loss=0.148, total=4105.62, n_correct=2676.85, ppl=4.62, accuracy=65.2, wps=11931.5, ups=1.45, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=15091
2023-08-14 06:38:26 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.039, trans_loss=4.965, nll_loss=2.224, w2v_ctc_loss=0.749, task_loss=1.494, contrastive_loss=0.11, total=4110.35, n_correct=2663.41, ppl=4.67, accuracy=64.798, wps=11875.1, ups=1.44, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=14.6, wall=15160
2023-08-14 06:39:35 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.034, trans_loss=4.951, nll_loss=2.207, w2v_ctc_loss=0.736, task_loss=1.385, contrastive_loss=0.204, total=4112.2, n_correct=2681.96, ppl=4.62, accuracy=65.22, wps=11856.9, ups=1.44, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=15230
2023-08-14 06:40:45 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.038, trans_loss=4.957, nll_loss=2.214, w2v_ctc_loss=0.731, task_loss=1.376, contrastive_loss=0.218, total=4180.88, n_correct=2720.81, ppl=4.64, accuracy=65.077, wps=11972.3, ups=1.43, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=15300
2023-08-14 06:41:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 06:41:45 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.986 | trans_loss 5.189 | nll_loss 2.456 | w2v_ctc_loss 1.318 | task_loss 4.623 | contrastive_loss 0.332 | total 4003.4 | n_correct 2645.7 | ppl 5.49 | accuracy 66.086 | uer 18.438 | wer 20.193 | raw_wer 20.193 | bleu 21.5 | wps 2129 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 21.72
2023-08-14 06:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-08-14 06:41:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5007.pt
2023-08-14 06:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5007.pt
2023-08-14 06:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5007.pt (epoch 13 @ 19153 updates, score 21.5) (writing took 25.16093866340816 seconds)
2023-08-14 06:42:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-14 06:42:11 | INFO | train | epoch 013 | loss 2.034 | trans_loss 4.955 | nll_loss 2.211 | w2v_ctc_loss 0.739 | task_loss 1.404 | contrastive_loss 0.162 | total 4138.65 | n_correct 2692.62 | ppl 4.63 | accuracy 65.06 | wps 10562.2 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.532 | clip 0 | loss_scale 64 | train_wall 1016 | gb_free 17.4 | wall 15386
2023-08-14 06:42:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 06:42:11 | INFO | fairseq.trainer | begin training epoch 14
2023-08-14 06:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 06:42:52 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.012, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.727, task_loss=1.284, contrastive_loss=0.121, total=4176.2, n_correct=2742.06, ppl=4.52, accuracy=65.659, wps=6577, ups=0.79, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=10.2, wall=15427
2023-08-14 06:44:01 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.011, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.729, task_loss=1.418, contrastive_loss=0.103, total=4080.86, n_correct=2682.93, ppl=4.49, accuracy=65.744, wps=11887.6, ups=1.46, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=15495
2023-08-14 06:45:09 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.027, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.728, task_loss=1.481, contrastive_loss=0.203, total=4106.97, n_correct=2687.43, ppl=4.56, accuracy=65.436, wps=11945.2, ups=1.45, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=11.9, wall=15564
2023-08-14 06:46:19 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.013, trans_loss=4.933, nll_loss=2.182, w2v_ctc_loss=0.721, task_loss=1.29, contrastive_loss=0.137, total=4179.8, n_correct=2741.26, ppl=4.54, accuracy=65.584, wps=11997.6, ups=1.44, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=15634
2023-08-14 06:47:28 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.012, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.72, task_loss=1.449, contrastive_loss=0.1, total=4120.38, n_correct=2700.06, ppl=4.55, accuracy=65.529, wps=11940.2, ups=1.45, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.517, clip=0, loss_scale=64, train_wall=69, gb_free=16.8, wall=15703
2023-08-14 06:48:37 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.031, trans_loss=4.941, nll_loss=2.192, w2v_ctc_loss=0.747, task_loss=1.486, contrastive_loss=0.135, total=4089.86, n_correct=2669.65, ppl=4.57, accuracy=65.275, wps=11781, ups=1.44, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.546, clip=0, loss_scale=64, train_wall=69, gb_free=11.7, wall=15772
2023-08-14 06:49:47 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.026, trans_loss=4.94, nll_loss=2.191, w2v_ctc_loss=0.729, task_loss=1.405, contrastive_loss=0.179, total=4158.94, n_correct=2719.76, ppl=4.57, accuracy=65.396, wps=11944.9, ups=1.44, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=15842
2023-08-14 06:50:57 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.012, trans_loss=4.927, nll_loss=2.174, w2v_ctc_loss=0.727, task_loss=1.365, contrastive_loss=0.112, total=4150.03, n_correct=2725.52, ppl=4.51, accuracy=65.675, wps=11901.1, ups=1.43, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=15912
2023-08-14 06:51:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 06:52:07 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.01, trans_loss=4.927, nll_loss=2.174, w2v_ctc_loss=0.724, task_loss=1.37, contrastive_loss=0.11, total=4145.38, n_correct=2723.08, ppl=4.51, accuracy=65.69, wps=11841.6, ups=1.43, wpb=8290.8, bsz=311.4, num_updates=20000, lr=0.0001, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=15982
2023-08-14 06:52:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 06:52:32 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.998 | trans_loss 5.184 | nll_loss 2.452 | w2v_ctc_loss 1.377 | task_loss 4.635 | contrastive_loss 0.319 | total 4003.4 | n_correct 2648.7 | ppl 5.47 | accuracy 66.161 | uer 18.305 | wer 20.174 | raw_wer 20.174 | bleu 21.71 | wps 1938.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.72
2023-08-14 06:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-14 06:52:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-14 06:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-14 06:53:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.71) (writing took 39.90312000364065 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 06:54:23 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.024, trans_loss=4.94, nll_loss=2.191, w2v_ctc_loss=0.728, task_loss=1.408, contrastive_loss=0.153, total=4167.75, n_correct=2720.05, ppl=4.57, accuracy=65.264, wps=6133.5, ups=0.74, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=16118
2023-08-14 06:55:33 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.014, trans_loss=4.933, nll_loss=2.184, w2v_ctc_loss=0.719, task_loss=1.429, contrastive_loss=0.131, total=4143.92, n_correct=2721.86, ppl=4.54, accuracy=65.683, wps=11828.3, ups=1.43, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=15.6, wall=16188
2023-08-14 06:56:43 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.045, trans_loss=4.938, nll_loss=2.191, w2v_ctc_loss=0.728, task_loss=1.315, contrastive_loss=0.404, total=4228.69, n_correct=2763.11, ppl=4.56, accuracy=65.342, wps=12006.7, ups=1.42, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=16258
2023-08-14 06:57:52 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.026, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.744, task_loss=1.647, contrastive_loss=0.094, total=4021.19, n_correct=2627.64, ppl=4.58, accuracy=65.345, wps=11655.4, ups=1.45, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=16327
2023-08-14 06:59:01 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.011, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.719, task_loss=1.326, contrastive_loss=0.108, total=4213.9, n_correct=2759.45, ppl=4.56, accuracy=65.484, wps=12171.7, ups=1.44, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=16396
2023-08-14 07:00:10 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.021, trans_loss=4.942, nll_loss=2.195, w2v_ctc_loss=0.725, task_loss=1.404, contrastive_loss=0.15, total=4130.28, n_correct=2702.26, ppl=4.58, accuracy=65.426, wps=11971.8, ups=1.45, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15, wall=16465
2023-08-14 07:00:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
2023-08-14 07:00:52 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.98 | trans_loss 5.18 | nll_loss 2.45 | w2v_ctc_loss 1.326 | task_loss 4.619 | contrastive_loss 0.323 | total 4003.4 | n_correct 2652.7 | ppl 5.46 | accuracy 66.261 | uer 18.286 | wer 20.037 | raw_wer 20.037 | bleu 21.88 | wps 2217 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 21.88
2023-08-14 07:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-14 07:00:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 07:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 07:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 20626 updates, score 21.88) (writing took 35.89942966774106 seconds)
2023-08-14 07:01:29 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-14 07:01:29 | INFO | train | epoch 014 | loss 2.02 | trans_loss 4.935 | nll_loss 2.186 | w2v_ctc_loss 0.728 | task_loss 1.408 | contrastive_loss 0.151 | total 4137.12 | n_correct 2709.64 | ppl 4.55 | accuracy 65.496 | wps 10527 | ups 1.27 | wpb 8274.2 | bsz 305.2 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 16 | wall 16544
2023-08-14 07:01:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 07:01:29 | INFO | fairseq.trainer | begin training epoch 15
2023-08-14 07:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 07:02:27 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.017, trans_loss=4.926, nll_loss=2.174, w2v_ctc_loss=0.718, task_loss=1.407, contrastive_loss=0.197, total=4083.88, n_correct=2684.6, ppl=4.51, accuracy=65.737, wps=5962.3, ups=0.73, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=16602
2023-08-14 07:03:37 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.003, trans_loss=4.913, nll_loss=2.156, w2v_ctc_loss=0.719, task_loss=1.463, contrastive_loss=0.106, total=4115.73, n_correct=2716.46, ppl=4.46, accuracy=66.002, wps=11879.8, ups=1.44, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=16672
2023-08-14 07:04:46 | INFO | train_inner | epoch 015:    274 / 1474 loss=1.998, trans_loss=4.915, nll_loss=2.159, w2v_ctc_loss=0.712, task_loss=1.349, contrastive_loss=0.098, total=4193.15, n_correct=2773.61, ppl=4.47, accuracy=66.146, wps=12104.1, ups=1.44, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=12.3, wall=16741
2023-08-14 07:05:56 | INFO | train_inner | epoch 015:    374 / 1474 loss=1.999, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.709, task_loss=1.417, contrastive_loss=0.121, total=4167.66, n_correct=2752.46, ppl=4.44, accuracy=66.043, wps=11996.9, ups=1.44, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=16810
2023-08-14 07:07:05 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.015, trans_loss=4.918, nll_loss=2.162, w2v_ctc_loss=0.712, task_loss=1.467, contrastive_loss=0.215, total=4074.53, n_correct=2680.56, ppl=4.48, accuracy=65.788, wps=11741.3, ups=1.44, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=16880
2023-08-14 07:08:14 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.004, trans_loss=4.914, nll_loss=2.158, w2v_ctc_loss=0.723, task_loss=1.454, contrastive_loss=0.105, total=4140.59, n_correct=2727.64, ppl=4.46, accuracy=65.876, wps=12016.8, ups=1.45, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=16949
2023-08-14 07:09:24 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.015, trans_loss=4.915, nll_loss=2.16, w2v_ctc_loss=0.721, task_loss=1.416, contrastive_loss=0.186, total=4134.99, n_correct=2721.73, ppl=4.47, accuracy=65.822, wps=11855, ups=1.43, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=10.1, wall=17018
2023-08-14 07:10:34 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.007, trans_loss=4.921, nll_loss=2.167, w2v_ctc_loss=0.722, task_loss=1.416, contrastive_loss=0.108, total=4173.66, n_correct=2745.51, ppl=4.49, accuracy=65.782, wps=11948, ups=1.43, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=17088
2023-08-14 07:11:43 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.008, trans_loss=4.921, nll_loss=2.168, w2v_ctc_loss=0.724, task_loss=1.516, contrastive_loss=0.102, total=4059.35, n_correct=2671.03, ppl=4.49, accuracy=65.799, wps=11683.4, ups=1.44, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=17158
2023-08-14 07:12:52 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.013, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.719, task_loss=1.416, contrastive_loss=0.188, total=4122.87, n_correct=2712.25, ppl=4.49, accuracy=65.785, wps=11930.7, ups=1.45, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=17227
2023-08-14 07:14:02 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.026, trans_loss=4.926, nll_loss=2.174, w2v_ctc_loss=0.716, task_loss=1.319, contrastive_loss=0.343, total=4192.24, n_correct=2755.29, ppl=4.51, accuracy=65.724, wps=11917.8, ups=1.42, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=16.9, wall=17297
2023-08-14 07:15:12 | INFO | train_inner | epoch 015:   1174 / 1474 loss=1.994, trans_loss=4.913, nll_loss=2.159, w2v_ctc_loss=0.697, task_loss=1.259, contrastive_loss=0.15, total=4185, n_correct=2767.1, ppl=4.47, accuracy=66.119, wps=12103.9, ups=1.45, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=17366
2023-08-14 07:16:21 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.008, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.728, task_loss=1.43, contrastive_loss=0.106, total=4152.04, n_correct=2733.39, ppl=4.47, accuracy=65.832, wps=11924.4, ups=1.44, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=17436
2023-08-14 07:17:30 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.004, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.721, task_loss=1.449, contrastive_loss=0.094, total=4100.21, n_correct=2701.17, ppl=4.48, accuracy=65.879, wps=11903.9, ups=1.45, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=17505
2023-08-14 07:17:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 07:17:54 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.952 | trans_loss 5.177 | nll_loss 2.444 | w2v_ctc_loss 1.244 | task_loss 4.619 | contrastive_loss 0.322 | total 4003.4 | n_correct 2660.5 | ppl 5.44 | accuracy 66.456 | uer 17.532 | wer 19.287 | raw_wer 19.287 | bleu 22.09 | wps 2178.2 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.09
2023-08-14 07:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-14 07:17:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-14 07:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-14 07:18:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 22.09) (writing took 55.073780816048384 seconds)
2023-08-14 07:18:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 07:20:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 07:20:24 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.174 | nll_loss 2.442 | w2v_ctc_loss 1.282 | task_loss 4.63 | contrastive_loss 0.325 | total 4003.4 | n_correct 2658.3 | ppl 5.43 | accuracy 66.401 | uer 17.872 | wer 19.701 | raw_wer 19.701 | bleu 22.25 | wps 2093.5 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 22.25
2023-08-14 07:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-14 07:20:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 07:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 07:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 15 @ 22099 updates, score 22.25) (writing took 30.99939677864313 seconds)
2023-08-14 07:20:56 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-14 07:20:56 | INFO | train | epoch 015 | loss 2.008 | trans_loss 4.917 | nll_loss 2.163 | w2v_ctc_loss 0.717 | task_loss 1.406 | contrastive_loss 0.155 | total 4138.09 | n_correct 2726.38 | ppl 4.48 | accuracy 65.885 | wps 10447.5 | ups 1.26 | wpb 8276.2 | bsz 305.4 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 16.7 | wall 17711
2023-08-14 07:20:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 07:20:56 | INFO | fairseq.trainer | begin training epoch 16
2023-08-14 07:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 07:21:04 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.013, trans_loss=4.926, nll_loss=2.174, w2v_ctc_loss=0.717, task_loss=1.376, contrastive_loss=0.175, total=4135.3, n_correct=2717.02, ppl=4.51, accuracy=65.703, wps=3869.8, ups=0.47, wpb=8270.6, bsz=311.5, num_updates=22100, lr=9.51303e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=17719
2023-08-14 07:22:13 | INFO | train_inner | epoch 016:    101 / 1474 loss=1.989, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.705, task_loss=1.349, contrastive_loss=0.121, total=4118.73, n_correct=2733.82, ppl=4.4, accuracy=66.375, wps=11923.8, ups=1.45, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=17788
2023-08-14 07:23:22 | INFO | train_inner | epoch 016:    201 / 1474 loss=1.984, trans_loss=4.889, nll_loss=2.125, w2v_ctc_loss=0.697, task_loss=1.441, contrastive_loss=0.097, total=4106.45, n_correct=2730.34, ppl=4.36, accuracy=66.489, wps=11876.3, ups=1.45, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=17857
2023-08-14 07:24:32 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.001, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.711, task_loss=1.391, contrastive_loss=0.172, total=4169.65, n_correct=2762.87, ppl=4.41, accuracy=66.261, wps=12002.5, ups=1.44, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=10.3, wall=17926
2023-08-14 07:25:41 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.002, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.709, task_loss=1.503, contrastive_loss=0.188, total=4063.79, n_correct=2693.24, ppl=4.39, accuracy=66.274, wps=11775.3, ups=1.45, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=12.2, wall=17995
2023-08-14 07:26:50 | INFO | train_inner | epoch 016:    501 / 1474 loss=1.994, trans_loss=4.902, nll_loss=2.143, w2v_ctc_loss=0.708, task_loss=1.346, contrastive_loss=0.128, total=4179.53, n_correct=2772.56, ppl=4.42, accuracy=66.337, wps=11974.1, ups=1.43, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=18065
2023-08-14 07:27:59 | INFO | train_inner | epoch 016:    601 / 1474 loss=1.989, trans_loss=4.901, nll_loss=2.14, w2v_ctc_loss=0.702, task_loss=1.415, contrastive_loss=0.092, total=4121.37, n_correct=2731.4, ppl=4.41, accuracy=66.274, wps=11999.9, ups=1.46, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=18134
2023-08-14 07:29:08 | INFO | train_inner | epoch 016:    701 / 1474 loss=1.992, trans_loss=4.902, nll_loss=2.142, w2v_ctc_loss=0.711, task_loss=1.435, contrastive_loss=0.096, total=4099.17, n_correct=2715.08, ppl=4.41, accuracy=66.235, wps=11906.7, ups=1.45, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=18203
2023-08-14 07:30:17 | INFO | train_inner | epoch 016:    801 / 1474 loss=1.993, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.7, task_loss=1.339, contrastive_loss=0.157, total=4184.53, n_correct=2776.71, ppl=4.4, accuracy=66.357, wps=12136.5, ups=1.45, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=13.1, wall=18272
2023-08-14 07:31:26 | INFO | train_inner | epoch 016:    901 / 1474 loss=1.996, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.706, task_loss=1.376, contrastive_loss=0.147, total=4151.84, n_correct=2748.86, ppl=4.41, accuracy=66.208, wps=11992.1, ups=1.44, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=18341
2023-08-14 07:32:36 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.003, trans_loss=4.906, nll_loss=2.147, w2v_ctc_loss=0.72, task_loss=1.454, contrastive_loss=0.146, total=4112.79, n_correct=2717.92, ppl=4.43, accuracy=66.085, wps=11864.3, ups=1.44, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=18410
2023-08-14 07:33:45 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.006, trans_loss=4.913, nll_loss=2.157, w2v_ctc_loss=0.724, task_loss=1.498, contrastive_loss=0.123, total=4111.6, n_correct=2710.31, ppl=4.46, accuracy=65.919, wps=11782.7, ups=1.43, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=18480
2023-08-14 07:34:55 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.008, trans_loss=4.911, nll_loss=2.155, w2v_ctc_loss=0.704, task_loss=1.434, contrastive_loss=0.22, total=4157.51, n_correct=2741.21, ppl=4.45, accuracy=65.934, wps=11908, ups=1.43, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=18550
2023-08-14 07:36:05 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.003, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.713, task_loss=1.362, contrastive_loss=0.196, total=4151.03, n_correct=2749.29, ppl=4.42, accuracy=66.232, wps=11833.1, ups=1.43, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=70, gb_free=15.8, wall=18620
2023-08-14 07:37:15 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.991, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.707, task_loss=1.342, contrastive_loss=0.124, total=4201.47, n_correct=2783.97, ppl=4.41, accuracy=66.262, wps=12120.6, ups=1.44, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=18689
2023-08-14 07:38:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 07:38:30 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.161 | nll_loss 2.421 | w2v_ctc_loss 1.284 | task_loss 4.647 | contrastive_loss 0.314 | total 4003.4 | n_correct 2675.5 | ppl 5.36 | accuracy 66.831 | uer 17.601 | wer 19.388 | raw_wer 19.388 | bleu 22.11 | wps 2082.7 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 22.25
2023-08-14 07:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-14 07:38:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1105.pt
2023-08-14 07:38:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1105.pt
2023-08-14 07:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1105.pt (epoch 16 @ 23573 updates, score 22.11) (writing took 20.703256469219923 seconds)
2023-08-14 07:38:51 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-14 07:38:51 | INFO | train | epoch 016 | loss 1.997 | trans_loss 4.901 | nll_loss 2.142 | w2v_ctc_loss 0.708 | task_loss 1.404 | contrastive_loss 0.152 | total 4138.65 | n_correct 2741.16 | ppl 4.41 | accuracy 66.233 | wps 11349.5 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1015 | gb_free 15.1 | wall 18786
2023-08-14 07:38:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 07:38:51 | INFO | fairseq.trainer | begin training epoch 17
2023-08-14 07:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 07:39:18 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.997, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.695, task_loss=1.436, contrastive_loss=0.263, total=4145.04, n_correct=2754.47, ppl=4.37, accuracy=66.452, wps=6742.8, ups=0.81, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=18812
2023-08-14 07:40:27 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.983, trans_loss=4.879, nll_loss=2.112, w2v_ctc_loss=0.705, task_loss=1.441, contrastive_loss=0.098, total=4117.27, n_correct=2745.74, ppl=4.32, accuracy=66.688, wps=11872.6, ups=1.44, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=18882
2023-08-14 07:40:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 07:41:38 | INFO | train_inner | epoch 017:    228 / 1474 loss=1.978, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.688, task_loss=1.358, contrastive_loss=0.153, total=4133.06, n_correct=2760.31, ppl=4.3, accuracy=66.786, wps=11715.9, ups=1.42, wpb=8266.1, bsz=310.7, num_updates=23800, lr=9.16698e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=70, gb_free=15.6, wall=18952
2023-08-14 07:42:46 | INFO | train_inner | epoch 017:    328 / 1474 loss=1.993, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.692, task_loss=1.4, contrastive_loss=0.266, total=4157.94, n_correct=2767.73, ppl=4.34, accuracy=66.565, wps=12106, ups=1.46, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=19021
2023-08-14 07:43:56 | INFO | train_inner | epoch 017:    428 / 1474 loss=1.976, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.693, task_loss=1.4, contrastive_loss=0.094, total=4141.8, n_correct=2764.83, ppl=4.33, accuracy=66.754, wps=11872.7, ups=1.43, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=19091
2023-08-14 07:43:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 07:44:20 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.17 | nll_loss 2.435 | w2v_ctc_loss 1.351 | task_loss 4.629 | contrastive_loss 0.314 | total 4003.4 | n_correct 2667.1 | ppl 5.41 | accuracy 66.621 | uer 18.284 | wer 20.133 | raw_wer 20.133 | bleu 22.17 | wps 2164 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.25
2023-08-14 07:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-14 07:44:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-14 07:44:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-14 07:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 22.17) (writing took 39.529916575178504 seconds)
2023-08-14 07:46:13 | INFO | train_inner | epoch 017:    528 / 1474 loss=1.988, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.702, task_loss=1.46, contrastive_loss=0.14, total=4180.09, n_correct=2779.45, ppl=4.36, accuracy=66.493, wps=6087.5, ups=0.73, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=16.9, wall=19228
2023-08-14 07:47:23 | INFO | train_inner | epoch 017:    628 / 1474 loss=1.981, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.695, task_loss=1.41, contrastive_loss=0.093, total=4166.6, n_correct=2773.13, ppl=4.36, accuracy=66.556, wps=11977.5, ups=1.44, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=19298
2023-08-14 07:48:32 | INFO | train_inner | epoch 017:    728 / 1474 loss=1.996, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.714, task_loss=1.384, contrastive_loss=0.14, total=4168.97, n_correct=2768.24, ppl=4.38, accuracy=66.401, wps=12006, ups=1.44, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=19367
2023-08-14 07:49:41 | INFO | train_inner | epoch 017:    828 / 1474 loss=1.989, trans_loss=4.892, nll_loss=2.129, w2v_ctc_loss=0.709, task_loss=1.414, contrastive_loss=0.107, total=4097.38, n_correct=2723.73, ppl=4.37, accuracy=66.475, wps=11902.3, ups=1.45, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=10.1, wall=19436
2023-08-14 07:50:50 | INFO | train_inner | epoch 017:    928 / 1474 loss=1.978, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.693, task_loss=1.388, contrastive_loss=0.101, total=4105.01, n_correct=2736.33, ppl=4.35, accuracy=66.658, wps=12029.1, ups=1.47, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=19504
2023-08-14 07:51:59 | INFO | train_inner | epoch 017:   1028 / 1474 loss=1.982, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.701, task_loss=1.404, contrastive_loss=0.106, total=4105.88, n_correct=2731.4, ppl=4.36, accuracy=66.524, wps=11831.9, ups=1.44, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=19574
2023-08-14 07:53:07 | INFO | train_inner | epoch 017:   1128 / 1474 loss=1.975, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.688, task_loss=1.434, contrastive_loss=0.096, total=4095.58, n_correct=2730.45, ppl=4.33, accuracy=66.668, wps=11946.3, ups=1.46, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=19642
2023-08-14 07:54:17 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.009, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.695, task_loss=1.378, contrastive_loss=0.336, total=4162.14, n_correct=2755.66, ppl=4.4, accuracy=66.208, wps=11911.7, ups=1.43, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=19712
2023-08-14 07:55:26 | INFO | train_inner | epoch 017:   1328 / 1474 loss=1.987, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.69, task_loss=1.397, contrastive_loss=0.176, total=4149.03, n_correct=2759.81, ppl=4.37, accuracy=66.517, wps=12012.1, ups=1.45, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=19781
2023-08-14 07:56:36 | INFO | train_inner | epoch 017:   1428 / 1474 loss=1.982, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.698, task_loss=1.413, contrastive_loss=0.097, total=4117.13, n_correct=2738.34, ppl=4.38, accuracy=66.511, wps=11845.5, ups=1.44, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=19851
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 07:57:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
2023-08-14 07:57:31 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.164 | nll_loss 2.427 | w2v_ctc_loss 1.29 | task_loss 4.662 | contrastive_loss 0.327 | total 4003.4 | n_correct 2669.2 | ppl 5.38 | accuracy 66.673 | uer 17.644 | wer 19.459 | raw_wer 19.459 | bleu 21.89 | wps 2277.9 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 22.25
2023-08-14 07:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-14 07:57:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt
2023-08-14 07:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt
2023-08-14 07:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt (epoch 17 @ 25046 updates, score 21.89) (writing took 23.005244936794043 seconds)
2023-08-14 07:57:54 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-14 07:57:54 | INFO | train | epoch 017 | loss 1.985 | trans_loss 4.886 | nll_loss 2.122 | w2v_ctc_loss 0.698 | task_loss 1.407 | contrastive_loss 0.142 | total 4136.62 | n_correct 2753.49 | ppl 4.35 | accuracy 66.564 | wps 10658.6 | ups 1.29 | wpb 8273.2 | bsz 305.1 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 16.1 | wall 19929
2023-08-14 07:57:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 07:57:54 | INFO | fairseq.trainer | begin training epoch 18
2023-08-14 07:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 07:58:42 | INFO | train_inner | epoch 018:     54 / 1474 loss=1.982, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.703, task_loss=1.433, contrastive_loss=0.106, total=4138.21, n_correct=2757.38, ppl=4.34, accuracy=66.632, wps=6583.9, ups=0.8, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=17.5, wall=19976
2023-08-14 07:59:51 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.977, trans_loss=4.863, nll_loss=2.092, w2v_ctc_loss=0.674, task_loss=1.335, contrastive_loss=0.229, total=4158.88, n_correct=2786.84, ppl=4.26, accuracy=67.009, wps=12050.5, ups=1.45, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=20046
2023-08-14 08:01:00 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.966, trans_loss=4.862, nll_loss=2.091, w2v_ctc_loss=0.687, task_loss=1.365, contrastive_loss=0.096, total=4164.11, n_correct=2792.53, ppl=4.26, accuracy=67.062, wps=11988.6, ups=1.44, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=20115
2023-08-14 08:02:10 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.967, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.679, task_loss=1.426, contrastive_loss=0.109, total=4163.13, n_correct=2790.23, ppl=4.28, accuracy=67.022, wps=11898.4, ups=1.43, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=17.3, wall=20185
2023-08-14 08:03:21 | INFO | train_inner | epoch 018:    454 / 1474 loss=1.987, trans_loss=4.877, nll_loss=2.11, w2v_ctc_loss=0.693, task_loss=1.502, contrastive_loss=0.201, total=4087.83, n_correct=2724.65, ppl=4.32, accuracy=66.653, wps=11604.4, ups=1.42, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=70, gb_free=16, wall=20255
2023-08-14 08:04:30 | INFO | train_inner | epoch 018:    554 / 1474 loss=1.965, trans_loss=4.863, nll_loss=2.093, w2v_ctc_loss=0.682, task_loss=1.264, contrastive_loss=0.109, total=4204.41, n_correct=2818.67, ppl=4.27, accuracy=67.041, wps=12103.7, ups=1.44, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=20325
2023-08-14 08:05:39 | INFO | train_inner | epoch 018:    654 / 1474 loss=1.987, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.697, task_loss=1.452, contrastive_loss=0.181, total=4096.81, n_correct=2731.01, ppl=4.33, accuracy=66.662, wps=11918.7, ups=1.45, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=20394
2023-08-14 08:06:49 | INFO | train_inner | epoch 018:    754 / 1474 loss=1.992, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.696, task_loss=1.334, contrastive_loss=0.272, total=4208.29, n_correct=2808.95, ppl=4.33, accuracy=66.748, wps=12070, ups=1.43, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=20463
2023-08-14 08:07:58 | INFO | train_inner | epoch 018:    854 / 1474 loss=1.969, trans_loss=4.872, nll_loss=2.103, w2v_ctc_loss=0.684, task_loss=1.426, contrastive_loss=0.088, total=4166.81, n_correct=2787.1, ppl=4.3, accuracy=66.888, wps=11979.1, ups=1.44, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=12.2, wall=20533
2023-08-14 08:09:07 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.965, trans_loss=4.866, nll_loss=2.097, w2v_ctc_loss=0.678, task_loss=1.303, contrastive_loss=0.11, total=4142.65, n_correct=2777.66, ppl=4.28, accuracy=67.05, wps=12068.7, ups=1.46, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=14.5, wall=20602
2023-08-14 08:09:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 08:09:30 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.972 | trans_loss 5.168 | nll_loss 2.428 | w2v_ctc_loss 1.333 | task_loss 4.625 | contrastive_loss 0.322 | total 4003.4 | n_correct 2670.3 | ppl 5.38 | accuracy 66.701 | uer 17.907 | wer 19.708 | raw_wer 19.708 | bleu 22.36 | wps 2178 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.36
2023-08-14 08:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-14 08:09:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-14 08:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-14 08:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.36) (writing took 49.03252488747239 seconds)
2023-08-14 08:11:30 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.968, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.681, task_loss=1.46, contrastive_loss=0.098, total=4137.77, n_correct=2769.15, ppl=4.29, accuracy=66.924, wps=5766.2, ups=0.7, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=20745
2023-08-14 08:12:40 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.978, trans_loss=4.864, nll_loss=2.094, w2v_ctc_loss=0.685, task_loss=1.332, contrastive_loss=0.206, total=4153.69, n_correct=2780.6, ppl=4.27, accuracy=66.943, wps=11927.5, ups=1.44, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=20815
2023-08-14 08:13:49 | INFO | train_inner | epoch 018:   1254 / 1474 loss=1.976, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.69, task_loss=1.508, contrastive_loss=0.091, total=4087.62, n_correct=2727.59, ppl=4.34, accuracy=66.728, wps=11842.9, ups=1.45, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=20884
2023-08-14 08:14:58 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.987, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.709, task_loss=1.498, contrastive_loss=0.119, total=4070.69, n_correct=2710.54, ppl=4.34, accuracy=66.587, wps=11804.3, ups=1.45, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=20953
2023-08-14 08:16:08 | INFO | train_inner | epoch 018:   1454 / 1474 loss=1.977, trans_loss=4.877, nll_loss=2.111, w2v_ctc_loss=0.696, task_loss=1.484, contrastive_loss=0.103, total=4113.2, n_correct=2749.77, ppl=4.32, accuracy=66.852, wps=11826.3, ups=1.44, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=21022
2023-08-14 08:16:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 08:16:44 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.155 | nll_loss 2.416 | w2v_ctc_loss 1.306 | task_loss 4.654 | contrastive_loss 0.315 | total 4003.4 | n_correct 2671.1 | ppl 5.34 | accuracy 66.721 | uer 17.631 | wer 19.44 | raw_wer 19.44 | bleu 22.3 | wps 2282.1 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 22.36
2023-08-14 08:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-14 08:16:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3009.pt
2023-08-14 08:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3009.pt
2023-08-14 08:17:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3009.pt (epoch 18 @ 26520 updates, score 22.3) (writing took 20.26951175928116 seconds)
2023-08-14 08:17:05 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-14 08:17:05 | INFO | train | epoch 018 | loss 1.976 | trans_loss 4.872 | nll_loss 2.104 | w2v_ctc_loss 0.688 | task_loss 1.404 | contrastive_loss 0.147 | total 4138.65 | n_correct 2767.2 | ppl 4.3 | accuracy 66.862 | wps 10603.2 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 15.6 | wall 21080
2023-08-14 08:17:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 08:17:05 | INFO | fairseq.trainer | begin training epoch 19
2023-08-14 08:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 08:18:08 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.969, trans_loss=4.855, nll_loss=2.083, w2v_ctc_loss=0.683, task_loss=1.408, contrastive_loss=0.155, total=4102.06, n_correct=2754.52, ppl=4.24, accuracy=67.15, wps=6819.3, ups=0.83, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=21143
2023-08-14 08:19:17 | INFO | train_inner | epoch 019:    180 / 1474 loss=1.965, trans_loss=4.851, nll_loss=2.077, w2v_ctc_loss=0.685, task_loss=1.308, contrastive_loss=0.144, total=4227.7, n_correct=2847.27, ppl=4.22, accuracy=67.348, wps=12153.7, ups=1.44, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=21212
2023-08-14 08:20:26 | INFO | train_inner | epoch 019:    280 / 1474 loss=1.955, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.677, task_loss=1.387, contrastive_loss=0.088, total=4187.34, n_correct=2821.72, ppl=4.2, accuracy=67.387, wps=12152, ups=1.45, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=21281
2023-08-14 08:21:36 | INFO | train_inner | epoch 019:    380 / 1474 loss=1.969, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.676, task_loss=1.384, contrastive_loss=0.194, total=4170.52, n_correct=2802.47, ppl=4.22, accuracy=67.197, wps=12018.7, ups=1.44, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=21351
2023-08-14 08:22:45 | INFO | train_inner | epoch 019:    480 / 1474 loss=1.963, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.682, task_loss=1.441, contrastive_loss=0.102, total=4113.89, n_correct=2767.55, ppl=4.24, accuracy=67.273, wps=11865.9, ups=1.44, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=21420
2023-08-14 08:23:55 | INFO | train_inner | epoch 019:    580 / 1474 loss=1.963, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.675, task_loss=1.374, contrastive_loss=0.168, total=4128.58, n_correct=2777.84, ppl=4.22, accuracy=67.283, wps=11877.7, ups=1.44, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=21489
2023-08-14 08:25:04 | INFO | train_inner | epoch 019:    680 / 1474 loss=1.952, trans_loss=4.857, nll_loss=2.086, w2v_ctc_loss=0.664, task_loss=1.274, contrastive_loss=0.094, total=4201.56, n_correct=2827.44, ppl=4.24, accuracy=67.295, wps=12200.8, ups=1.45, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=21558
2023-08-14 08:26:13 | INFO | train_inner | epoch 019:    780 / 1474 loss=1.965, trans_loss=4.857, nll_loss=2.084, w2v_ctc_loss=0.688, task_loss=1.442, contrastive_loss=0.1, total=4124.03, n_correct=2770.52, ppl=4.24, accuracy=67.18, wps=11851, ups=1.44, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=21628
2023-08-14 08:27:23 | INFO | train_inner | epoch 019:    880 / 1474 loss=1.965, trans_loss=4.863, nll_loss=2.092, w2v_ctc_loss=0.685, task_loss=1.403, contrastive_loss=0.098, total=4177.8, n_correct=2799.86, ppl=4.26, accuracy=67.018, wps=12004, ups=1.44, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=21698
2023-08-14 08:28:33 | INFO | train_inner | epoch 019:    980 / 1474 loss=1.988, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.68, task_loss=1.428, contrastive_loss=0.327, total=4084.26, n_correct=2731.34, ppl=4.29, accuracy=66.875, wps=11596.4, ups=1.42, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=70, gb_free=15.9, wall=21768
2023-08-14 08:29:42 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.969, trans_loss=4.865, nll_loss=2.095, w2v_ctc_loss=0.681, task_loss=1.472, contrastive_loss=0.133, total=4042.73, n_correct=2709.38, ppl=4.27, accuracy=67.019, wps=11756.4, ups=1.45, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=21837
2023-08-14 08:30:52 | INFO | train_inner | epoch 019:   1180 / 1474 loss=1.981, trans_loss=4.867, nll_loss=2.098, w2v_ctc_loss=0.685, task_loss=1.434, contrastive_loss=0.215, total=4140.95, n_correct=2769.34, ppl=4.28, accuracy=66.877, wps=11814.7, ups=1.43, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=70, gb_free=12.3, wall=21907
2023-08-14 08:32:01 | INFO | train_inner | epoch 019:   1280 / 1474 loss=1.966, trans_loss=4.864, nll_loss=2.094, w2v_ctc_loss=0.677, task_loss=1.424, contrastive_loss=0.114, total=4135.79, n_correct=2772.94, ppl=4.27, accuracy=67.047, wps=12001.7, ups=1.45, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21976
2023-08-14 08:33:11 | INFO | train_inner | epoch 019:   1380 / 1474 loss=1.968, trans_loss=4.865, nll_loss=2.096, w2v_ctc_loss=0.686, task_loss=1.434, contrastive_loss=0.1, total=4138.67, n_correct=2770.14, ppl=4.27, accuracy=66.933, wps=11904.8, ups=1.44, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=22045
2023-08-14 08:34:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 08:34:40 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.162 | nll_loss 2.422 | w2v_ctc_loss 1.324 | task_loss 4.664 | contrastive_loss 0.318 | total 4003.4 | n_correct 2676 | ppl 5.36 | accuracy 66.843 | uer 17.538 | wer 19.306 | raw_wer 19.306 | bleu 22.45 | wps 2087.1 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 22.45
2023-08-14 08:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-08-14 08:34:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 08:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 08:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 19 @ 27994 updates, score 22.45) (writing took 29.995584024116397 seconds)
2023-08-14 08:35:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-14 08:35:10 | INFO | train | epoch 019 | loss 1.967 | trans_loss 4.858 | nll_loss 2.086 | w2v_ctc_loss 0.68 | task_loss 1.404 | contrastive_loss 0.144 | total 4138.65 | n_correct 2779.08 | ppl 4.25 | accuracy 67.149 | wps 11240.2 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 1016 | gb_free 17 | wall 22165
2023-08-14 08:35:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 08:35:11 | INFO | fairseq.trainer | begin training epoch 20
2023-08-14 08:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 08:35:22 | INFO | train_inner | epoch 020:      6 / 1474 loss=1.966, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.675, task_loss=1.422, contrastive_loss=0.183, total=4117.61, n_correct=2769.81, ppl=4.23, accuracy=67.267, wps=6264.3, ups=0.76, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=22177
2023-08-14 08:35:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 08:35:47 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.942 | trans_loss 5.162 | nll_loss 2.421 | w2v_ctc_loss 1.254 | task_loss 4.665 | contrastive_loss 0.316 | total 4003.4 | n_correct 2670.9 | ppl 5.36 | accuracy 66.716 | uer 17.402 | wer 19.265 | raw_wer 19.265 | bleu 22.4 | wps 2011 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.45
2023-08-14 08:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-14 08:35:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-14 08:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-14 08:36:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.4) (writing took 17.986249666661024 seconds)
2023-08-14 08:36:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 08:37:16 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.946, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.664, task_loss=1.354, contrastive_loss=0.107, total=4197.09, n_correct=2840.37, ppl=4.16, accuracy=67.675, wps=7343.4, ups=0.87, wpb=8394.2, bsz=314.5, num_updates=28100, lr=8.43649e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=70, gb_free=14.7, wall=22291
2023-08-14 08:38:26 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.957, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.668, task_loss=1.459, contrastive_loss=0.16, total=4154.14, n_correct=2803.18, ppl=4.18, accuracy=67.479, wps=11978.8, ups=1.44, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=22360
2023-08-14 08:39:35 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.942, trans_loss=4.834, nll_loss=2.056, w2v_ctc_loss=0.663, task_loss=1.267, contrastive_loss=0.095, total=4188.05, n_correct=2836.77, ppl=4.16, accuracy=67.735, wps=12126.6, ups=1.45, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=22430
2023-08-14 08:40:44 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.947, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.666, task_loss=1.422, contrastive_loss=0.094, total=4115.16, n_correct=2784.4, ppl=4.15, accuracy=67.662, wps=11882.3, ups=1.44, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=22499
2023-08-14 08:41:54 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.963, trans_loss=4.85, nll_loss=2.075, w2v_ctc_loss=0.669, task_loss=1.437, contrastive_loss=0.182, total=4108.46, n_correct=2766.09, ppl=4.21, accuracy=67.327, wps=11753.1, ups=1.43, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=22569
2023-08-14 08:43:03 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.966, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.672, task_loss=1.48, contrastive_loss=0.181, total=4094.9, n_correct=2756.02, ppl=4.21, accuracy=67.304, wps=11846.5, ups=1.45, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=22638
2023-08-14 08:44:12 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.953, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.672, task_loss=1.408, contrastive_loss=0.088, total=4140.23, n_correct=2788.24, ppl=4.2, accuracy=67.345, wps=12021.2, ups=1.45, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=22707
2023-08-14 08:45:21 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.954, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.676, task_loss=1.395, contrastive_loss=0.091, total=4140.66, n_correct=2791.85, ppl=4.21, accuracy=67.425, wps=11954.2, ups=1.44, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=22776
2023-08-14 08:46:32 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.985, trans_loss=4.854, nll_loss=2.082, w2v_ctc_loss=0.671, task_loss=1.34, contrastive_loss=0.384, total=4157.15, n_correct=2794.37, ppl=4.23, accuracy=67.218, wps=11695, ups=1.41, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=71, gb_free=17.5, wall=22847
2023-08-14 08:47:42 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.947, trans_loss=4.844, nll_loss=2.067, w2v_ctc_loss=0.661, task_loss=1.387, contrastive_loss=0.096, total=4171.86, n_correct=2817.51, ppl=4.19, accuracy=67.536, wps=12003.3, ups=1.44, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=22917
2023-08-14 08:48:51 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.97, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.67, task_loss=1.356, contrastive_loss=0.236, total=4162.96, n_correct=2800.13, ppl=4.22, accuracy=67.263, wps=11969, ups=1.44, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=22986
2023-08-14 08:50:01 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.958, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.688, task_loss=1.539, contrastive_loss=0.085, total=4033.74, n_correct=2717.6, ppl=4.18, accuracy=67.372, wps=11663.4, ups=1.45, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=23055
2023-08-14 08:51:11 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.956, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.672, task_loss=1.484, contrastive_loss=0.089, total=4124.42, n_correct=2772.86, ppl=4.22, accuracy=67.23, wps=11737.8, ups=1.42, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=70, gb_free=15.6, wall=23126
2023-08-14 08:52:20 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.674, task_loss=1.486, contrastive_loss=0.087, total=4114.1, n_correct=2772.3, ppl=4.21, accuracy=67.385, wps=11859.5, ups=1.44, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=14, wall=23195
2023-08-14 08:53:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 08:53:30 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.94 | trans_loss 5.154 | nll_loss 2.412 | w2v_ctc_loss 1.267 | task_loss 4.63 | contrastive_loss 0.315 | total 4003.4 | n_correct 2678.5 | ppl 5.32 | accuracy 66.906 | uer 17.278 | wer 19.063 | raw_wer 19.063 | bleu 22.39 | wps 2193.4 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 22.45
2023-08-14 08:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-14 08:53:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3905.pt
2023-08-14 08:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3905.pt
2023-08-14 08:53:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3905.pt (epoch 20 @ 29467 updates, score 22.39) (writing took 26.181854946538806 seconds)
2023-08-14 08:53:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-14 08:53:57 | INFO | train | epoch 020 | loss 1.957 | trans_loss 4.845 | nll_loss 2.069 | w2v_ctc_loss 0.67 | task_loss 1.405 | contrastive_loss 0.142 | total 4138.8 | n_correct 2790.62 | ppl 4.2 | accuracy 67.426 | wps 10826.4 | ups 1.31 | wpb 8277.6 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 15.9 | wall 23291
2023-08-14 08:53:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 08:53:57 | INFO | fairseq.trainer | begin training epoch 21
2023-08-14 08:53:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 08:54:27 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.962, trans_loss=4.846, nll_loss=2.071, w2v_ctc_loss=0.666, task_loss=1.327, contrastive_loss=0.208, total=4155.01, n_correct=2803.25, ppl=4.2, accuracy=67.467, wps=6549.9, ups=0.79, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=23322
2023-08-14 08:55:37 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.948, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.653, task_loss=1.328, contrastive_loss=0.199, total=4186.67, n_correct=2842.28, ppl=4.12, accuracy=67.889, wps=12034, ups=1.44, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=12.6, wall=23392
2023-08-14 08:56:46 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.942, trans_loss=4.829, nll_loss=2.049, w2v_ctc_loss=0.653, task_loss=1.322, contrastive_loss=0.156, total=4166.37, n_correct=2821.87, ppl=4.14, accuracy=67.73, wps=11963.3, ups=1.44, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=13.7, wall=23461
2023-08-14 08:57:57 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.951, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.667, task_loss=1.423, contrastive_loss=0.155, total=4132.25, n_correct=2794.09, ppl=4.14, accuracy=67.617, wps=11779.5, ups=1.43, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=23531
2023-08-14 08:59:06 | INFO | train_inner | epoch 021:    433 / 1474 loss=1.938, trans_loss=4.828, nll_loss=2.046, w2v_ctc_loss=0.656, task_loss=1.339, contrastive_loss=0.086, total=4195.53, n_correct=2847.76, ppl=4.13, accuracy=67.876, wps=12162.6, ups=1.45, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=23600
2023-08-14 09:00:15 | INFO | train_inner | epoch 021:    533 / 1474 loss=1.94, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.664, task_loss=1.446, contrastive_loss=0.082, total=4085.05, n_correct=2775.31, ppl=4.11, accuracy=67.938, wps=11846.1, ups=1.45, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=23669
2023-08-14 09:00:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 09:00:38 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.157 | nll_loss 2.414 | w2v_ctc_loss 1.286 | task_loss 4.604 | contrastive_loss 0.302 | total 4003.4 | n_correct 2673.7 | ppl 5.33 | accuracy 66.786 | uer 17.094 | wer 18.769 | raw_wer 18.769 | bleu 22.24 | wps 2204.8 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.45
2023-08-14 09:00:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-14 09:00:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-14 09:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-14 09:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.24) (writing took 40.40139248408377 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 09:02:29 | INFO | train_inner | epoch 021:    633 / 1474 loss=1.958, trans_loss=4.831, nll_loss=2.051, w2v_ctc_loss=0.66, task_loss=1.385, contrastive_loss=0.254, total=4220.3, n_correct=2854.95, ppl=4.14, accuracy=67.648, wps=6254.3, ups=0.74, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=70, gb_free=15.4, wall=23804
2023-08-14 09:03:39 | INFO | train_inner | epoch 021:    733 / 1474 loss=1.948, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.659, task_loss=1.406, contrastive_loss=0.114, total=4148.18, n_correct=2804.35, ppl=4.17, accuracy=67.604, wps=11971.7, ups=1.44, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=69, gb_free=11.5, wall=23874
2023-08-14 09:04:48 | INFO | train_inner | epoch 021:    833 / 1474 loss=1.954, trans_loss=4.843, nll_loss=2.066, w2v_ctc_loss=0.663, task_loss=1.493, contrastive_loss=0.127, total=4062.56, n_correct=2739.56, ppl=4.19, accuracy=67.434, wps=11691.5, ups=1.44, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=23943
2023-08-14 09:05:57 | INFO | train_inner | epoch 021:    933 / 1474 loss=1.947, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.667, task_loss=1.401, contrastive_loss=0.1, total=4103.66, n_correct=2774.95, ppl=4.15, accuracy=67.621, wps=11897.6, ups=1.45, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=24012
2023-08-14 09:07:06 | INFO | train_inner | epoch 021:   1033 / 1474 loss=1.95, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.67, task_loss=1.44, contrastive_loss=0.096, total=4100.54, n_correct=2768.83, ppl=4.18, accuracy=67.524, wps=11872.4, ups=1.45, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=24081
2023-08-14 09:08:16 | INFO | train_inner | epoch 021:   1133 / 1474 loss=1.948, trans_loss=4.832, nll_loss=2.051, w2v_ctc_loss=0.667, task_loss=1.507, contrastive_loss=0.101, total=4119.98, n_correct=2790.11, ppl=4.15, accuracy=67.721, wps=11904.4, ups=1.44, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=24150
2023-08-14 09:09:24 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.954, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.667, task_loss=1.324, contrastive_loss=0.152, total=4161.49, n_correct=2809.07, ppl=4.17, accuracy=67.502, wps=12087.2, ups=1.45, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=24219
2023-08-14 09:10:34 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.946, trans_loss=4.835, nll_loss=2.057, w2v_ctc_loss=0.661, task_loss=1.363, contrastive_loss=0.113, total=4141.76, n_correct=2802.19, ppl=4.16, accuracy=67.657, wps=11940.3, ups=1.44, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=24289
2023-08-14 09:11:44 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.967, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.686, task_loss=1.484, contrastive_loss=0.159, total=4127.02, n_correct=2778.61, ppl=4.2, accuracy=67.327, wps=11725.3, ups=1.42, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=70, gb_free=16.2, wall=24359
2023-08-14 09:12:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
2023-08-14 09:12:36 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.16 | nll_loss 2.418 | w2v_ctc_loss 1.304 | task_loss 4.61 | contrastive_loss 0.314 | total 4003.4 | n_correct 2678.8 | ppl 5.34 | accuracy 66.913 | uer 17.288 | wer 19.157 | raw_wer 19.157 | bleu 22.4 | wps 2161.9 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 22.45
2023-08-14 09:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-08-14 09:12:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4004.pt
2023-08-14 09:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4004.pt
2023-08-14 09:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4004.pt (epoch 21 @ 30941 updates, score 22.4) (writing took 22.645472342148423 seconds)
2023-08-14 09:12:59 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-14 09:12:59 | INFO | train | epoch 021 | loss 1.95 | trans_loss 4.834 | nll_loss 2.055 | w2v_ctc_loss 0.663 | task_loss 1.405 | contrastive_loss 0.14 | total 4138.65 | n_correct 2799.92 | ppl 4.15 | accuracy 67.653 | wps 10678.2 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.529 | clip 0 | loss_scale 64 | train_wall 1017 | gb_free 15.1 | wall 24434
2023-08-14 09:12:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 09:12:59 | INFO | fairseq.trainer | begin training epoch 22
2023-08-14 09:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 09:13:48 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.939, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.661, task_loss=1.418, contrastive_loss=0.083, total=4140.16, n_correct=2815.37, ppl=4.11, accuracy=68.001, wps=6706.8, ups=0.81, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=17.5, wall=24482
2023-08-14 09:14:57 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.943, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.659, task_loss=1.413, contrastive_loss=0.161, total=4115.86, n_correct=2796.28, ppl=4.09, accuracy=67.939, wps=11812.5, ups=1.43, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=24552
2023-08-14 09:14:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 09:15:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 09:16:08 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.926, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.641, task_loss=1.248, contrastive_loss=0.1, total=4263.9, n_correct=2907.47, ppl=4.08, accuracy=68.188, wps=12027.4, ups=1.41, wpb=8527.8, bsz=327.8, num_updates=31200, lr=8.00641e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=24623
2023-08-14 09:17:19 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.963, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.666, task_loss=1.424, contrastive_loss=0.261, total=4178.4, n_correct=2826.73, ppl=4.13, accuracy=67.651, wps=11793.6, ups=1.41, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=24694
2023-08-14 09:18:29 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.946, trans_loss=4.822, nll_loss=2.039, w2v_ctc_loss=0.658, task_loss=1.473, contrastive_loss=0.144, total=4132.96, n_correct=2807.98, ppl=4.11, accuracy=67.941, wps=11887, ups=1.44, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=24763
2023-08-14 09:19:39 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.937, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.66, task_loss=1.409, contrastive_loss=0.091, total=4158.17, n_correct=2827.14, ppl=4.1, accuracy=67.99, wps=11888.8, ups=1.43, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=24833
2023-08-14 09:20:48 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.936, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.645, task_loss=1.342, contrastive_loss=0.175, total=4139.66, n_correct=2822.81, ppl=4.08, accuracy=68.189, wps=12014, ups=1.45, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=24902
2023-08-14 09:21:57 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.938, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.661, task_loss=1.443, contrastive_loss=0.096, total=4167.89, n_correct=2830.19, ppl=4.09, accuracy=67.905, wps=11917.4, ups=1.43, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=24972
2023-08-14 09:23:07 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.94, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.658, task_loss=1.521, contrastive_loss=0.081, total=4075.79, n_correct=2762.37, ppl=4.13, accuracy=67.775, wps=11694.4, ups=1.43, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=25042
2023-08-14 09:24:17 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.933, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.655, task_loss=1.416, contrastive_loss=0.081, total=4134.72, n_correct=2812.84, ppl=4.1, accuracy=68.03, wps=11922.9, ups=1.44, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=13.8, wall=25111
2023-08-14 09:25:26 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.946, trans_loss=4.818, nll_loss=2.035, w2v_ctc_loss=0.648, task_loss=1.343, contrastive_loss=0.252, total=4160.57, n_correct=2829.15, ppl=4.1, accuracy=67.999, wps=11999.5, ups=1.44, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=25181
2023-08-14 09:25:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 09:25:49 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.16 | nll_loss 2.421 | w2v_ctc_loss 1.312 | task_loss 4.646 | contrastive_loss 0.302 | total 4003.4 | n_correct 2671 | ppl 5.35 | accuracy 66.718 | uer 17.45 | wer 19.324 | raw_wer 19.324 | bleu 22.45 | wps 2277.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.45
2023-08-14 09:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-14 09:25:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-14 09:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-14 09:26:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.45) (writing took 55.24610824882984 seconds)
2023-08-14 09:27:54 | INFO | train_inner | epoch 022:   1161 / 1474 loss=1.954, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.669, task_loss=1.451, contrastive_loss=0.133, total=4099.59, n_correct=2771.06, ppl=4.17, accuracy=67.594, wps=5530, ups=0.67, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=25329
2023-08-14 09:29:03 | INFO | train_inner | epoch 022:   1261 / 1474 loss=1.944, trans_loss=4.835, nll_loss=2.057, w2v_ctc_loss=0.658, task_loss=1.299, contrastive_loss=0.128, total=4182.05, n_correct=2829.47, ppl=4.16, accuracy=67.657, wps=12119.6, ups=1.45, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=25398
2023-08-14 09:30:12 | INFO | train_inner | epoch 022:   1361 / 1474 loss=1.939, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.65, task_loss=1.41, contrastive_loss=0.153, total=4062.31, n_correct=2762.71, ppl=4.1, accuracy=68.008, wps=11802.2, ups=1.45, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=25467
2023-08-14 09:31:21 | INFO | train_inner | epoch 022:   1461 / 1474 loss=1.949, trans_loss=4.835, nll_loss=2.055, w2v_ctc_loss=0.672, task_loss=1.507, contrastive_loss=0.098, total=4081.88, n_correct=2758.76, ppl=4.16, accuracy=67.586, wps=11844.7, ups=1.45, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=25536
2023-08-14 09:31:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 09:31:53 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.94 | trans_loss 5.149 | nll_loss 2.406 | w2v_ctc_loss 1.288 | task_loss 4.636 | contrastive_loss 0.298 | total 4003.4 | n_correct 2679.2 | ppl 5.3 | accuracy 66.923 | uer 17.572 | wer 19.44 | raw_wer 19.44 | bleu 22.14 | wps 2217.2 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 22.45
2023-08-14 09:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-14 09:31:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 09:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 09:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 22 @ 32413 updates, score 22.14) (writing took 15.843504762277007 seconds)
2023-08-14 09:32:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-14 09:32:09 | INFO | train | epoch 022 | loss 1.942 | trans_loss 4.823 | nll_loss 2.04 | w2v_ctc_loss 0.657 | task_loss 1.406 | contrastive_loss 0.138 | total 4138.03 | n_correct 2809.68 | ppl 4.11 | accuracy 67.899 | wps 10592.8 | ups 1.28 | wpb 8276.1 | bsz 305.5 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 11.3 | wall 25584
2023-08-14 09:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 09:32:09 | INFO | fairseq.trainer | begin training epoch 23
2023-08-14 09:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 09:33:17 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.933, trans_loss=4.808, nll_loss=2.022, w2v_ctc_loss=0.66, task_loss=1.439, contrastive_loss=0.089, total=4096.09, n_correct=2790.95, ppl=4.06, accuracy=68.137, wps=7075.6, ups=0.86, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=25652
2023-08-14 09:34:26 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.925, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.645, task_loss=1.499, contrastive_loss=0.085, total=4107.77, n_correct=2808.57, ppl=4.02, accuracy=68.372, wps=11835.4, ups=1.44, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=25721
2023-08-14 09:35:36 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.935, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.641, task_loss=1.411, contrastive_loss=0.163, total=4153.12, n_correct=2829.77, ppl=4.07, accuracy=68.136, wps=11910.4, ups=1.43, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=25791
2023-08-14 09:36:45 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.924, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.646, task_loss=1.46, contrastive_loss=0.078, total=4116.7, n_correct=2814.91, ppl=4.03, accuracy=68.378, wps=11892.7, ups=1.44, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=25860
2023-08-14 09:37:55 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.933, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.647, task_loss=1.363, contrastive_loss=0.133, total=4157.6, n_correct=2833.51, ppl=4.07, accuracy=68.153, wps=11933.4, ups=1.44, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=25930
2023-08-14 09:39:04 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.925, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.649, task_loss=1.326, contrastive_loss=0.083, total=4173.42, n_correct=2850.77, ppl=4.05, accuracy=68.308, wps=12014.8, ups=1.44, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=12.2, wall=25999
2023-08-14 09:40:13 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.935, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.652, task_loss=1.403, contrastive_loss=0.123, total=4137.82, n_correct=2818.55, ppl=4.07, accuracy=68.117, wps=11988.5, ups=1.45, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=26068
2023-08-14 09:41:22 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.933, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.652, task_loss=1.414, contrastive_loss=0.101, total=4150.99, n_correct=2828.39, ppl=4.08, accuracy=68.138, wps=12018.2, ups=1.45, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=26137
2023-08-14 09:42:32 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.93, trans_loss=4.804, nll_loss=2.016, w2v_ctc_loss=0.642, task_loss=1.285, contrastive_loss=0.182, total=4181.99, n_correct=2860.89, ppl=4.05, accuracy=68.41, wps=11980.7, ups=1.43, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=26207
2023-08-14 09:43:42 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.954, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.65, task_loss=1.4, contrastive_loss=0.336, total=4168.73, n_correct=2835.91, ppl=4.08, accuracy=68.028, wps=11897.4, ups=1.43, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=10.5, wall=26277
2023-08-14 09:44:52 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.939, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.66, task_loss=1.496, contrastive_loss=0.09, total=4088.49, n_correct=2778.7, ppl=4.1, accuracy=67.964, wps=11785.1, ups=1.44, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=26346
2023-08-14 09:46:02 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.931, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.654, task_loss=1.394, contrastive_loss=0.083, total=4162.7, n_correct=2831.3, ppl=4.1, accuracy=68.016, wps=11873.4, ups=1.43, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=70, gb_free=15.8, wall=26417
2023-08-14 09:47:11 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.926, trans_loss=4.811, nll_loss=2.026, w2v_ctc_loss=0.645, task_loss=1.365, contrastive_loss=0.094, total=4135.53, n_correct=2818.8, ppl=4.07, accuracy=68.161, wps=11878.8, ups=1.44, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=26486
2023-08-14 09:48:21 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.943, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.654, task_loss=1.418, contrastive_loss=0.15, total=4143.98, n_correct=2815.65, ppl=4.12, accuracy=67.946, wps=11877.2, ups=1.43, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=26556
2023-08-14 09:49:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 09:49:45 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.155 | nll_loss 2.412 | w2v_ctc_loss 1.351 | task_loss 4.649 | contrastive_loss 0.311 | total 4003.4 | n_correct 2678.4 | ppl 5.32 | accuracy 66.903 | uer 17.408 | wer 19.145 | raw_wer 19.145 | bleu 22.31 | wps 2197.8 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 22.45
2023-08-14 09:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-14 09:49:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3106.pt
2023-08-14 09:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3106.pt
2023-08-14 09:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3106.pt (epoch 23 @ 33887 updates, score 22.31) (writing took 28.742514733225107 seconds)
2023-08-14 09:50:14 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-14 09:50:14 | INFO | train | epoch 023 | loss 1.934 | trans_loss 4.812 | nll_loss 2.026 | w2v_ctc_loss 0.65 | task_loss 1.404 | contrastive_loss 0.136 | total 4138.65 | n_correct 2820.39 | ppl 4.07 | accuracy 68.148 | wps 11246.1 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 13.2 | wall 26669
2023-08-14 09:50:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 09:50:14 | INFO | fairseq.trainer | begin training epoch 24
2023-08-14 09:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 09:50:31 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.947, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.646, task_loss=1.409, contrastive_loss=0.228, total=4085.11, n_correct=2776.92, ppl=4.11, accuracy=67.977, wps=6286.7, ups=0.77, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=12.2, wall=26686
2023-08-14 09:51:41 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.931, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.635, task_loss=1.296, contrastive_loss=0.245, total=4171.44, n_correct=2856.37, ppl=4, accuracy=68.474, wps=12003.7, ups=1.44, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=26756
2023-08-14 09:51:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 09:52:04 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.161 | nll_loss 2.417 | w2v_ctc_loss 1.285 | task_loss 4.64 | contrastive_loss 0.316 | total 4003.4 | n_correct 2673.6 | ppl 5.34 | accuracy 66.783 | uer 17.248 | wer 19.201 | raw_wer 19.201 | bleu 22.25 | wps 2196.1 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.45
2023-08-14 09:52:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-14 09:52:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-14 09:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-14 09:52:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.25) (writing took 40.689677702263 seconds)
2023-08-14 09:53:55 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.933, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.627, task_loss=1.23, contrastive_loss=0.296, total=4251.29, n_correct=2911.46, ppl=4.02, accuracy=68.484, wps=6313.3, ups=0.74, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=26890
2023-08-14 09:55:05 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.915, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.636, task_loss=1.376, contrastive_loss=0.079, total=4128.18, n_correct=2827.72, ppl=4, accuracy=68.498, wps=11939.3, ups=1.45, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=26959
2023-08-14 09:56:14 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.947, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.654, task_loss=1.471, contrastive_loss=0.223, total=4158.92, n_correct=2837.01, ppl=4.04, accuracy=68.215, wps=12007.3, ups=1.44, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=27029
2023-08-14 09:57:24 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.932, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.651, task_loss=1.43, contrastive_loss=0.151, total=4144.91, n_correct=2831.88, ppl=4.03, accuracy=68.322, wps=11829.5, ups=1.43, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=27099
2023-08-14 09:58:34 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.926, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.644, task_loss=1.41, contrastive_loss=0.112, total=4165.3, n_correct=2847.39, ppl=4.03, accuracy=68.36, wps=11952.4, ups=1.43, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=27168
2023-08-14 09:59:43 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.929, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.643, task_loss=1.445, contrastive_loss=0.124, total=4102.21, n_correct=2801.16, ppl=4.05, accuracy=68.284, wps=11821.1, ups=1.44, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=27238
2023-08-14 10:00:53 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.923, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.641, task_loss=1.416, contrastive_loss=0.098, total=4110.6, n_correct=2807.82, ppl=4.05, accuracy=68.307, wps=11831.5, ups=1.44, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=27307
2023-08-14 10:02:02 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.932, trans_loss=4.807, nll_loss=2.018, w2v_ctc_loss=0.658, task_loss=1.556, contrastive_loss=0.076, total=4043.03, n_correct=2755.51, ppl=4.05, accuracy=68.155, wps=11710.2, ups=1.45, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=10.8, wall=27376
2023-08-14 10:03:11 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.924, trans_loss=4.807, nll_loss=2.019, w2v_ctc_loss=0.641, task_loss=1.446, contrastive_loss=0.078, total=4136.81, n_correct=2827.73, ppl=4.05, accuracy=68.355, wps=11914.6, ups=1.44, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=27446
2023-08-14 10:04:20 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.924, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.646, task_loss=1.356, contrastive_loss=0.122, total=4135.73, n_correct=2833.27, ppl=4.01, accuracy=68.507, wps=11951.7, ups=1.44, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=27515
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 10:05:30 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.926, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.641, task_loss=1.392, contrastive_loss=0.111, total=4148.3, n_correct=2832.29, ppl=4.05, accuracy=68.276, wps=11939.8, ups=1.44, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=27585
2023-08-14 10:06:39 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.927, trans_loss=4.804, nll_loss=2.016, w2v_ctc_loss=0.652, task_loss=1.496, contrastive_loss=0.083, total=4110.05, n_correct=2809.45, ppl=4.05, accuracy=68.356, wps=11795, ups=1.43, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=27654
2023-08-14 10:07:48 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.928, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.653, task_loss=1.469, contrastive_loss=0.081, total=4090.91, n_correct=2794.1, ppl=4.06, accuracy=68.3, wps=11859.9, ups=1.45, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.7, wall=27723
2023-08-14 10:08:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
2023-08-14 10:08:54 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.154 | nll_loss 2.412 | w2v_ctc_loss 1.287 | task_loss 4.657 | contrastive_loss 0.312 | total 4003.4 | n_correct 2681.6 | ppl 5.32 | accuracy 66.983 | uer 17.068 | wer 18.87 | raw_wer 18.87 | bleu 22.43 | wps 2217.8 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 22.45
2023-08-14 10:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-14 10:08:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt
2023-08-14 10:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt
2023-08-14 10:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt (epoch 24 @ 35361 updates, score 22.43) (writing took 22.00991960428655 seconds)
2023-08-14 10:09:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-14 10:09:17 | INFO | train | epoch 024 | loss 1.928 | trans_loss 4.801 | nll_loss 2.013 | w2v_ctc_loss 0.644 | task_loss 1.404 | contrastive_loss 0.134 | total 4138.65 | n_correct 2829.15 | ppl 4.03 | accuracy 68.359 | wps 10679.6 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.526 | clip 0 | loss_scale 64 | train_wall 1016 | gb_free 15.9 | wall 27811
2023-08-14 10:09:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 10:09:17 | INFO | fairseq.trainer | begin training epoch 25
2023-08-14 10:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 10:09:51 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.915, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.637, task_loss=1.345, contrastive_loss=0.088, total=4166.95, n_correct=2861.14, ppl=4.01, accuracy=68.663, wps=6787.2, ups=0.81, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=27846
2023-08-14 10:11:00 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.909, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.631, task_loss=1.374, contrastive_loss=0.086, total=4133.64, n_correct=2844.61, ppl=3.96, accuracy=68.816, wps=11975.7, ups=1.45, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=27915
2023-08-14 10:12:10 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.916, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.638, task_loss=1.438, contrastive_loss=0.092, total=4114.53, n_correct=2822.85, ppl=3.99, accuracy=68.607, wps=11774.6, ups=1.43, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=27985
2023-08-14 10:13:20 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.92, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.636, task_loss=1.494, contrastive_loss=0.12, total=4148.7, n_correct=2846.47, ppl=3.98, accuracy=68.611, wps=11886.4, ups=1.43, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=28055
2023-08-14 10:14:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 10:14:30 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.921, trans_loss=4.785, nll_loss=1.99, w2v_ctc_loss=0.649, task_loss=1.512, contrastive_loss=0.08, total=4142.33, n_correct=2845.79, ppl=3.97, accuracy=68.7, wps=11742.2, ups=1.42, wpb=8284.7, bsz=289.3, num_updates=35800, lr=7.47435e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=15.5, wall=28125
2023-08-14 10:15:40 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.916, trans_loss=4.796, nll_loss=2.005, w2v_ctc_loss=0.635, task_loss=1.369, contrastive_loss=0.09, total=4160.61, n_correct=2852.25, ppl=4.01, accuracy=68.554, wps=12003, ups=1.44, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=28195
2023-08-14 10:16:49 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.921, trans_loss=4.784, nll_loss=1.991, w2v_ctc_loss=0.64, task_loss=1.39, contrastive_loss=0.159, total=4153.68, n_correct=2853.25, ppl=3.97, accuracy=68.692, wps=11975.2, ups=1.44, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=28264
2023-08-14 10:16:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 10:17:13 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.151 | nll_loss 2.407 | w2v_ctc_loss 1.296 | task_loss 4.638 | contrastive_loss 0.299 | total 4003.4 | n_correct 2681.2 | ppl 5.3 | accuracy 66.973 | uer 17.254 | wer 19.149 | raw_wer 19.149 | bleu 22.53 | wps 2130.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.53
2023-08-14 10:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-14 10:17:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-14 10:17:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-14 10:18:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.53) (writing took 53.383288487792015 seconds)
2023-08-14 10:19:17 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.923, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.635, task_loss=1.424, contrastive_loss=0.15, total=4128.34, n_correct=2833.12, ppl=3.98, accuracy=68.626, wps=5569.8, ups=0.67, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=28412
2023-08-14 10:20:27 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.911, trans_loss=4.789, nll_loss=1.997, w2v_ctc_loss=0.632, task_loss=1.298, contrastive_loss=0.099, total=4182.4, n_correct=2872.81, ppl=3.99, accuracy=68.688, wps=12056.1, ups=1.44, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=28482
2023-08-14 10:21:36 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.923, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.64, task_loss=1.335, contrastive_loss=0.155, total=4155.21, n_correct=2852.33, ppl=4, accuracy=68.645, wps=12017.7, ups=1.45, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=13.7, wall=28551
2023-08-14 10:22:46 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.938, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.636, task_loss=1.396, contrastive_loss=0.266, total=4177.7, n_correct=2853.43, ppl=4.04, accuracy=68.301, wps=12009.3, ups=1.44, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=28620
2023-08-14 10:23:55 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.918, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.64, task_loss=1.519, contrastive_loss=0.074, total=4039.24, n_correct=2767.21, ppl=4.01, accuracy=68.508, wps=11718.2, ups=1.45, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28689
2023-08-14 10:25:03 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.917, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.634, task_loss=1.424, contrastive_loss=0.083, total=4090.59, n_correct=2801.27, ppl=4.02, accuracy=68.481, wps=11940.6, ups=1.46, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28758
2023-08-14 10:26:12 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.925, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.638, task_loss=1.371, contrastive_loss=0.178, total=4164.34, n_correct=2854.4, ppl=4, accuracy=68.544, wps=12054.6, ups=1.45, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=28827
2023-08-14 10:27:22 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.931, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.647, task_loss=1.463, contrastive_loss=0.128, total=4099.11, n_correct=2795.88, ppl=4.06, accuracy=68.207, wps=11689.2, ups=1.43, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=70, gb_free=11.9, wall=28897
2023-08-14 10:27:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 10:28:10 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.157 | nll_loss 2.414 | w2v_ctc_loss 1.294 | task_loss 4.638 | contrastive_loss 0.309 | total 4003.4 | n_correct 2677.4 | ppl 5.33 | accuracy 66.878 | uer 16.999 | wer 18.829 | raw_wer 18.829 | bleu 22.36 | wps 2119.3 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 22.53
2023-08-14 10:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-14 10:28:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3606.pt
2023-08-14 10:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3606.pt
2023-08-14 10:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3606.pt (epoch 25 @ 36834 updates, score 22.36) (writing took 38.69855198636651 seconds)
2023-08-14 10:28:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-14 10:28:49 | INFO | train | epoch 025 | loss 1.92 | trans_loss 4.792 | nll_loss 2 | w2v_ctc_loss 0.638 | task_loss 1.407 | contrastive_loss 0.125 | total 4137.25 | n_correct 2836.96 | ppl 4 | accuracy 68.571 | wps 10395.6 | ups 1.26 | wpb 8274.5 | bsz 305.1 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 13.9 | wall 28984
2023-08-14 10:28:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 10:28:49 | INFO | fairseq.trainer | begin training epoch 26
2023-08-14 10:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 10:29:42 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.905, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.621, task_loss=1.322, contrastive_loss=0.11, total=4180.21, n_correct=2881.34, ppl=3.95, accuracy=68.928, wps=5972, ups=0.71, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=29037
2023-08-14 10:30:52 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.919, trans_loss=4.777, nll_loss=1.982, w2v_ctc_loss=0.612, task_loss=1.238, contrastive_loss=0.298, total=4270.78, n_correct=2948.91, ppl=3.95, accuracy=69.049, wps=12255.8, ups=1.43, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=15, wall=29107
2023-08-14 10:32:02 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.915, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.63, task_loss=1.395, contrastive_loss=0.173, total=4125.04, n_correct=2841.9, ppl=3.93, accuracy=68.894, wps=11802.1, ups=1.43, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=29177
2023-08-14 10:33:12 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.91, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.629, task_loss=1.345, contrastive_loss=0.126, total=4165.74, n_correct=2870.1, ppl=3.94, accuracy=68.898, wps=11910.2, ups=1.43, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=29247
2023-08-14 10:34:21 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.913, trans_loss=4.77, nll_loss=1.973, w2v_ctc_loss=0.63, task_loss=1.338, contrastive_loss=0.172, total=4170.23, n_correct=2877.17, ppl=3.92, accuracy=68.993, wps=12136.7, ups=1.46, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=29315
2023-08-14 10:34:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 10:35:31 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.913, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.639, task_loss=1.412, contrastive_loss=0.094, total=4156.11, n_correct=2860.33, ppl=3.96, accuracy=68.822, wps=11787.6, ups=1.42, wpb=8312.2, bsz=305, num_updates=37400, lr=7.31272e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=29386
2023-08-14 10:36:41 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.909, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.631, task_loss=1.438, contrastive_loss=0.08, total=4129.11, n_correct=2839.36, ppl=3.96, accuracy=68.764, wps=11863.9, ups=1.44, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=13.5, wall=29455
2023-08-14 10:37:50 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.921, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.626, task_loss=1.417, contrastive_loss=0.192, total=4096.84, n_correct=2815.23, ppl=3.97, accuracy=68.717, wps=11764.7, ups=1.44, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=29525
2023-08-14 10:38:59 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.915, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.64, task_loss=1.403, contrastive_loss=0.094, total=4176.27, n_correct=2869.35, ppl=3.96, accuracy=68.706, wps=12131.3, ups=1.45, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=29594
2023-08-14 10:40:09 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.921, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.633, task_loss=1.446, contrastive_loss=0.147, total=4141.01, n_correct=2834.49, ppl=3.99, accuracy=68.449, wps=11927.4, ups=1.44, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=29663
2023-08-14 10:41:18 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.913, trans_loss=4.785, nll_loss=1.99, w2v_ctc_loss=0.636, task_loss=1.483, contrastive_loss=0.079, total=4113.69, n_correct=2826.84, ppl=3.97, accuracy=68.718, wps=11832.7, ups=1.44, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=29733
2023-08-14 10:42:28 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.919, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.637, task_loss=1.467, contrastive_loss=0.12, total=4116.78, n_correct=2823.3, ppl=4, accuracy=68.58, wps=11783.6, ups=1.43, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=29803
2023-08-14 10:42:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 10:42:51 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.33 | task_loss 4.666 | contrastive_loss 0.294 | total 4003.4 | n_correct 2681.2 | ppl 5.35 | accuracy 66.973 | uer 17.071 | wer 18.81 | raw_wer 18.81 | bleu 22.33 | wps 2201.1 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.53
2023-08-14 10:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-14 10:42:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-14 10:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-14 10:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.33) (writing took 38.90490977279842 seconds)
2023-08-14 10:44:40 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.922, trans_loss=4.797, nll_loss=2.006, w2v_ctc_loss=0.645, task_loss=1.556, contrastive_loss=0.082, total=4001.06, n_correct=2739.06, ppl=4.02, accuracy=68.458, wps=6042.3, ups=0.76, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=29935
2023-08-14 10:45:50 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.912, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.626, task_loss=1.404, contrastive_loss=0.093, total=4157.69, n_correct=2854.32, ppl=4, accuracy=68.652, wps=11927.3, ups=1.43, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=30005
2023-08-14 10:47:00 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.903, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.619, task_loss=1.333, contrastive_loss=0.088, total=4158.47, n_correct=2864.43, ppl=3.96, accuracy=68.882, wps=11993.1, ups=1.44, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=30074
2023-08-14 10:47:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 10:47:28 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.94 | trans_loss 5.153 | nll_loss 2.412 | w2v_ctc_loss 1.286 | task_loss 4.641 | contrastive_loss 0.297 | total 4003.4 | n_correct 2674.2 | ppl 5.32 | accuracy 66.798 | uer 16.959 | wer 18.758 | raw_wer 18.758 | bleu 22.38 | wps 2139 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 22.53
2023-08-14 10:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-14 10:47:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3809.pt
2023-08-14 10:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3809.pt
2023-08-14 10:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3809.pt (epoch 26 @ 38307 updates, score 22.38) (writing took 21.26560950279236 seconds)
2023-08-14 10:47:50 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-14 10:47:50 | INFO | train | epoch 026 | loss 1.914 | trans_loss 4.782 | nll_loss 1.987 | w2v_ctc_loss 0.631 | task_loss 1.404 | contrastive_loss 0.131 | total 4138.52 | n_correct 2846.45 | ppl 3.96 | accuracy 68.779 | wps 10687.8 | ups 1.29 | wpb 8277 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.7 | wall 30125
2023-08-14 10:47:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 10:47:50 | INFO | fairseq.trainer | begin training epoch 27
2023-08-14 10:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 10:49:01 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.896, trans_loss=4.753, nll_loss=1.949, w2v_ctc_loss=0.621, task_loss=1.497, contrastive_loss=0.07, total=4067.62, n_correct=2818.21, ppl=3.86, accuracy=69.284, wps=6721.4, ups=0.83, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=30195
2023-08-14 10:50:10 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.896, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.618, task_loss=1.341, contrastive_loss=0.096, total=4185.52, n_correct=2897.15, ppl=3.89, accuracy=69.218, wps=12052.2, ups=1.44, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=30265
2023-08-14 10:51:19 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.904, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.627, task_loss=1.399, contrastive_loss=0.081, total=4167.92, n_correct=2879.35, ppl=3.92, accuracy=69.084, wps=12016.7, ups=1.44, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=30334
2023-08-14 10:52:30 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.924, trans_loss=4.775, nll_loss=1.979, w2v_ctc_loss=0.625, task_loss=1.473, contrastive_loss=0.265, total=4075.21, n_correct=2808.75, ppl=3.94, accuracy=68.923, wps=11611.6, ups=1.42, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=70, gb_free=17.4, wall=30404
2023-08-14 10:53:40 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.917, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.624, task_loss=1.286, contrastive_loss=0.196, total=4249.35, n_correct=2920.68, ppl=3.97, accuracy=68.732, wps=12114, ups=1.43, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=11.7, wall=30475
2023-08-14 10:54:49 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.908, trans_loss=4.769, nll_loss=1.971, w2v_ctc_loss=0.625, task_loss=1.375, contrastive_loss=0.138, total=4133.39, n_correct=2849.42, ppl=3.92, accuracy=68.937, wps=11951.1, ups=1.45, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=30544
2023-08-14 10:55:58 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.911, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.629, task_loss=1.406, contrastive_loss=0.119, total=4162.71, n_correct=2867.39, ppl=3.94, accuracy=68.883, wps=11985, ups=1.44, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=30613
2023-08-14 10:57:08 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.905, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.629, task_loss=1.479, contrastive_loss=0.081, total=4103.81, n_correct=2830.51, ppl=3.92, accuracy=68.973, wps=11823.1, ups=1.44, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=30683
2023-08-14 10:58:17 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.902, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.619, task_loss=1.464, contrastive_loss=0.072, total=4101.56, n_correct=2827.62, ppl=3.95, accuracy=68.94, wps=11893.4, ups=1.45, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=30752
2023-08-14 10:59:27 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.924, trans_loss=4.78, nll_loss=1.986, w2v_ctc_loss=0.628, task_loss=1.362, contrastive_loss=0.26, total=4199.56, n_correct=2888.85, ppl=3.96, accuracy=68.789, wps=12003.3, ups=1.43, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=11.2, wall=30822
2023-08-14 11:00:36 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.903, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.623, task_loss=1.411, contrastive_loss=0.089, total=4150.97, n_correct=2859.84, ppl=3.93, accuracy=68.896, wps=12012.1, ups=1.45, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=11.7, wall=30891
2023-08-14 11:01:45 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.909, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.631, task_loss=1.467, contrastive_loss=0.094, total=4103.06, n_correct=2823.41, ppl=3.95, accuracy=68.812, wps=11821.4, ups=1.44, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=30960
2023-08-14 11:02:55 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.918, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.632, task_loss=1.505, contrastive_loss=0.147, total=4062.52, n_correct=2796.86, ppl=3.96, accuracy=68.845, wps=11705.6, ups=1.44, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31030
2023-08-14 11:04:03 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.91, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.627, task_loss=1.331, contrastive_loss=0.128, total=4152, n_correct=2859.21, ppl=3.96, accuracy=68.863, wps=12129.8, ups=1.46, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=31098
2023-08-14 11:04:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 11:05:23 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.944 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.296 | task_loss 4.648 | contrastive_loss 0.3 | total 4003.4 | n_correct 2681.6 | ppl 5.31 | accuracy 66.983 | uer 17.286 | wer 19.265 | raw_wer 19.265 | bleu 22.42 | wps 2236.2 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 22.53
2023-08-14 11:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-14 11:05:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4201.pt
2023-08-14 11:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4201.pt
2023-08-14 11:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4201.pt (epoch 27 @ 39781 updates, score 22.42) (writing took 21.67777500487864 seconds)
2023-08-14 11:05:45 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-14 11:05:45 | INFO | train | epoch 027 | loss 1.908 | trans_loss 4.773 | nll_loss 1.976 | w2v_ctc_loss 0.625 | task_loss 1.406 | contrastive_loss 0.13 | total 4138.65 | n_correct 2853.37 | ppl 3.93 | accuracy 68.945 | wps 11350.2 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 17.5 | wall 31200
2023-08-14 11:05:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 11:05:45 | INFO | fairseq.trainer | begin training epoch 28
2023-08-14 11:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 11:06:05 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.896, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.616, task_loss=1.362, contrastive_loss=0.08, total=4108.43, n_correct=2838.79, ppl=3.92, accuracy=69.097, wps=6748.2, ups=0.82, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=31220
2023-08-14 11:07:14 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.893, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.616, task_loss=1.466, contrastive_loss=0.076, total=4113.41, n_correct=2856.55, ppl=3.85, accuracy=69.445, wps=11856, ups=1.44, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=31289
2023-08-14 11:08:23 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.892, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.613, task_loss=1.333, contrastive_loss=0.083, total=4191.56, n_correct=2906.77, ppl=3.88, accuracy=69.348, wps=12148.6, ups=1.45, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=31358
2023-08-14 11:08:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 11:08:46 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.161 | nll_loss 2.418 | w2v_ctc_loss 1.3 | task_loss 4.647 | contrastive_loss 0.299 | total 4003.4 | n_correct 2678.2 | ppl 5.34 | accuracy 66.898 | uer 17.1 | wer 18.873 | raw_wer 18.873 | bleu 22.26 | wps 2238.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.53
2023-08-14 11:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-14 11:08:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-14 11:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-14 11:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.26) (writing took 19.580180184915662 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 11:10:16 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.929, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.61, task_loss=1.397, contrastive_loss=0.414, total=4145.32, n_correct=2858.28, ppl=3.91, accuracy=68.952, wps=7336, ups=0.88, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=15.3, wall=31471
2023-08-14 11:11:25 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.894, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.619, task_loss=1.454, contrastive_loss=0.071, total=4092.14, n_correct=2837.65, ppl=3.87, accuracy=69.344, wps=11870.8, ups=1.45, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=31540
2023-08-14 11:12:35 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.896, trans_loss=4.761, nll_loss=1.96, w2v_ctc_loss=0.615, task_loss=1.463, contrastive_loss=0.083, total=4096.35, n_correct=2833.1, ppl=3.89, accuracy=69.162, wps=11821.1, ups=1.44, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=31609
2023-08-14 11:13:44 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.903, trans_loss=4.772, nll_loss=1.973, w2v_ctc_loss=0.626, task_loss=1.417, contrastive_loss=0.084, total=4178.12, n_correct=2886.19, ppl=3.93, accuracy=69.079, wps=12045.1, ups=1.44, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=31679
2023-08-14 11:14:53 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.908, trans_loss=4.771, nll_loss=1.974, w2v_ctc_loss=0.616, task_loss=1.279, contrastive_loss=0.191, total=4185.82, n_correct=2890.94, ppl=3.93, accuracy=69.065, wps=12064.8, ups=1.44, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=31748
2023-08-14 11:16:02 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.893, trans_loss=4.764, nll_loss=1.964, w2v_ctc_loss=0.613, task_loss=1.38, contrastive_loss=0.076, total=4096.2, n_correct=2834.68, ppl=3.9, accuracy=69.203, wps=11927, ups=1.46, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=31817
2023-08-14 11:17:12 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.905, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.618, task_loss=1.442, contrastive_loss=0.137, total=4120.27, n_correct=2846.04, ppl=3.91, accuracy=69.074, wps=11770.2, ups=1.43, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=70, gb_free=17.2, wall=31887
2023-08-14 11:18:21 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.911, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.622, task_loss=1.369, contrastive_loss=0.188, total=4177.86, n_correct=2885.28, ppl=3.91, accuracy=69.061, wps=12057.9, ups=1.44, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=31956
2023-08-14 11:19:31 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.899, trans_loss=4.764, nll_loss=1.965, w2v_ctc_loss=0.621, task_loss=1.362, contrastive_loss=0.095, total=4210.86, n_correct=2912.37, ppl=3.9, accuracy=69.163, wps=12134.7, ups=1.44, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=32026
2023-08-14 11:20:40 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.894, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.61, task_loss=1.39, contrastive_loss=0.082, total=4104.61, n_correct=2837.9, ppl=3.92, accuracy=69.139, wps=11876.1, ups=1.45, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=32095
2023-08-14 11:21:50 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.907, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.627, task_loss=1.541, contrastive_loss=0.097, total=4087.78, n_correct=2818.09, ppl=3.92, accuracy=68.939, wps=11673.6, ups=1.43, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=70, gb_free=14.7, wall=32165
2023-08-14 11:22:59 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.909, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.626, task_loss=1.475, contrastive_loss=0.121, total=4145.03, n_correct=2858.36, ppl=3.92, accuracy=68.959, wps=12002.7, ups=1.45, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=32234
2023-08-14 11:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 11:23:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
2023-08-14 11:24:00 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.155 | nll_loss 2.411 | w2v_ctc_loss 1.316 | task_loss 4.657 | contrastive_loss 0.297 | total 4003.4 | n_correct 2684.3 | ppl 5.32 | accuracy 67.051 | uer 16.978 | wer 18.75 | raw_wer 18.75 | bleu 22.62 | wps 2266.4 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 22.62
2023-08-14 11:24:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-14 11:24:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 11:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 11:24:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 28 @ 41254 updates, score 22.62) (writing took 29.947210496291518 seconds)
2023-08-14 11:24:31 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-14 11:24:31 | INFO | train | epoch 028 | loss 1.902 | trans_loss 4.765 | nll_loss 1.965 | w2v_ctc_loss 0.618 | task_loss 1.406 | contrastive_loss 0.128 | total 4138.56 | n_correct 2861.72 | ppl 3.9 | accuracy 69.148 | wps 10831.1 | ups 1.31 | wpb 8277.1 | bsz 305.6 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 16.2 | wall 32325
2023-08-14 11:24:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 11:24:31 | INFO | fairseq.trainer | begin training epoch 29
2023-08-14 11:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 11:25:10 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.894, trans_loss=4.755, nll_loss=1.954, w2v_ctc_loss=0.62, task_loss=1.348, contrastive_loss=0.095, total=4171.15, n_correct=2894.03, ppl=3.87, accuracy=69.382, wps=6387.7, ups=0.77, wpb=8342.3, bsz=317.2, num_updates=41300, lr=6.95889e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=32364
2023-08-14 11:26:19 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.898, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.617, task_loss=1.401, contrastive_loss=0.11, total=4105.72, n_correct=2844.52, ppl=3.88, accuracy=69.282, wps=11833, ups=1.44, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=32434
2023-08-14 11:27:30 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.897, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.607, task_loss=1.282, contrastive_loss=0.195, total=4199.67, n_correct=2918.2, ppl=3.85, accuracy=69.486, wps=11915.4, ups=1.42, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=70, gb_free=15.4, wall=32504
2023-08-14 11:28:39 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.901, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.627, task_loss=1.505, contrastive_loss=0.077, total=4095.17, n_correct=2833.68, ppl=3.9, accuracy=69.196, wps=11859, ups=1.45, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=32573
2023-08-14 11:29:48 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.886, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.615, task_loss=1.356, contrastive_loss=0.073, total=4157.44, n_correct=2895.89, ppl=3.81, accuracy=69.656, wps=11931, ups=1.43, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=32643
2023-08-14 11:30:58 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.91, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.619, task_loss=1.494, contrastive_loss=0.169, total=4150.87, n_correct=2869.14, ppl=3.9, accuracy=69.121, wps=11931.1, ups=1.44, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=32713
2023-08-14 11:32:08 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.903, trans_loss=4.754, nll_loss=1.952, w2v_ctc_loss=0.611, task_loss=1.331, contrastive_loss=0.237, total=4143.02, n_correct=2872.75, ppl=3.87, accuracy=69.34, wps=11865, ups=1.43, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=32783
2023-08-14 11:33:18 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.896, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.611, task_loss=1.295, contrastive_loss=0.156, total=4249.79, n_correct=2949.9, ppl=3.86, accuracy=69.413, wps=12188, ups=1.43, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=32852
2023-08-14 11:33:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 11:33:40 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.156 | nll_loss 2.412 | w2v_ctc_loss 1.326 | task_loss 4.66 | contrastive_loss 0.306 | total 4003.4 | n_correct 2682.5 | ppl 5.32 | accuracy 67.006 | uer 17.124 | wer 19.045 | raw_wer 19.045 | bleu 22.1 | wps 2272.8 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.62
2023-08-14 11:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-14 11:33:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-14 11:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-14 11:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.1) (writing took 21.63241995126009 seconds)
2023-08-14 11:35:12 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.902, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.62, task_loss=1.56, contrastive_loss=0.073, total=4027.19, n_correct=2778.87, ppl=3.92, accuracy=69.003, wps=7057.3, ups=0.88, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=32966
2023-08-14 11:36:21 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.899, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.624, task_loss=1.431, contrastive_loss=0.082, total=4082.14, n_correct=2824.28, ppl=3.9, accuracy=69.186, wps=11820.9, ups=1.45, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=33036
2023-08-14 11:37:30 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.895, trans_loss=4.753, nll_loss=1.949, w2v_ctc_loss=0.609, task_loss=1.394, contrastive_loss=0.157, total=4148.18, n_correct=2879.32, ppl=3.86, accuracy=69.412, wps=11919.1, ups=1.44, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=33105
2023-08-14 11:38:39 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.897, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.62, task_loss=1.536, contrastive_loss=0.069, total=4063.95, n_correct=2810.12, ppl=3.9, accuracy=69.148, wps=11818.2, ups=1.45, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=33174
2023-08-14 11:39:48 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.899, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.62, task_loss=1.428, contrastive_loss=0.076, total=4158.81, n_correct=2878, ppl=3.91, accuracy=69.202, wps=11993.7, ups=1.44, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=33243
2023-08-14 11:40:58 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.896, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.61, task_loss=1.384, contrastive_loss=0.136, total=4166.34, n_correct=2888.43, ppl=3.86, accuracy=69.328, wps=11970.8, ups=1.44, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=33313
2023-08-14 11:42:07 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.898, trans_loss=4.755, nll_loss=1.953, w2v_ctc_loss=0.613, task_loss=1.38, contrastive_loss=0.165, total=4162.2, n_correct=2886.12, ppl=3.87, accuracy=69.341, wps=12070.8, ups=1.45, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=33382
2023-08-14 11:42:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 11:42:49 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.155 | nll_loss 2.409 | w2v_ctc_loss 1.302 | task_loss 4.66 | contrastive_loss 0.305 | total 4003.4 | n_correct 2684.6 | ppl 5.31 | accuracy 67.058 | uer 16.999 | wer 18.989 | raw_wer 18.989 | bleu 22.52 | wps 2224.1 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 22.62
2023-08-14 11:42:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-14 11:42:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5207.pt
2023-08-14 11:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5207.pt
2023-08-14 11:43:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5207.pt (epoch 29 @ 42728 updates, score 22.52) (writing took 22.61188411153853 seconds)
2023-08-14 11:43:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-14 11:43:12 | INFO | train | epoch 029 | loss 1.898 | trans_loss 4.757 | nll_loss 1.955 | w2v_ctc_loss 0.616 | task_loss 1.404 | contrastive_loss 0.127 | total 4138.65 | n_correct 2868.47 | ppl 3.88 | accuracy 69.309 | wps 10880.5 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 15.8 | wall 33447
2023-08-14 11:43:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 11:43:12 | INFO | fairseq.trainer | begin training epoch 30
2023-08-14 11:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 11:44:10 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.895, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.606, task_loss=1.331, contrastive_loss=0.186, total=4182.65, n_correct=2908.94, ppl=3.84, accuracy=69.548, wps=6831.5, ups=0.82, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=13.1, wall=33504
2023-08-14 11:45:19 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.884, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.606, task_loss=1.317, contrastive_loss=0.118, total=4203.05, n_correct=2935.42, ppl=3.79, accuracy=69.84, wps=12153.7, ups=1.45, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=33573
2023-08-14 11:46:28 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.889, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.614, task_loss=1.448, contrastive_loss=0.072, total=4116.93, n_correct=2864.5, ppl=3.84, accuracy=69.579, wps=11923.2, ups=1.45, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=33643
2023-08-14 11:47:38 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.879, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.601, task_loss=1.409, contrastive_loss=0.074, total=4173.13, n_correct=2912.63, ppl=3.81, accuracy=69.795, wps=11900, ups=1.43, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=11.4, wall=33713
2023-08-14 11:48:47 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.89, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.606, task_loss=1.339, contrastive_loss=0.135, total=4135.2, n_correct=2873.96, ppl=3.84, accuracy=69.5, wps=11989, ups=1.45, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=33782
2023-08-14 11:49:56 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.886, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.607, task_loss=1.366, contrastive_loss=0.099, total=4168.65, n_correct=2905.46, ppl=3.84, accuracy=69.698, wps=12022.4, ups=1.44, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=33851
2023-08-14 11:51:06 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.889, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.609, task_loss=1.385, contrastive_loss=0.11, total=4183.65, n_correct=2905.03, ppl=3.84, accuracy=69.438, wps=11922.9, ups=1.42, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=33921
2023-08-14 11:52:16 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.907, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.62, task_loss=1.435, contrastive_loss=0.191, total=4106.9, n_correct=2844.81, ppl=3.87, accuracy=69.269, wps=11736.1, ups=1.43, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=69, gb_free=11.6, wall=33991
2023-08-14 11:53:26 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.893, trans_loss=4.753, nll_loss=1.949, w2v_ctc_loss=0.615, task_loss=1.474, contrastive_loss=0.076, total=4089.18, n_correct=2839.17, ppl=3.86, accuracy=69.431, wps=11822.7, ups=1.45, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=34060
2023-08-14 11:54:35 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.895, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.617, task_loss=1.417, contrastive_loss=0.095, total=4140.03, n_correct=2870.28, ppl=3.87, accuracy=69.33, wps=11944.8, ups=1.44, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=13.5, wall=34130
2023-08-14 11:55:45 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.901, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.61, task_loss=1.571, contrastive_loss=0.164, total=4101.12, n_correct=2839.05, ppl=3.87, accuracy=69.226, wps=11657, ups=1.42, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=34200
2023-08-14 11:56:55 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.894, trans_loss=4.751, nll_loss=1.948, w2v_ctc_loss=0.609, task_loss=1.346, contrastive_loss=0.144, total=4168.22, n_correct=2896.89, ppl=3.86, accuracy=69.499, wps=12004.2, ups=1.44, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=34269
2023-08-14 11:58:04 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.898, trans_loss=4.757, nll_loss=1.955, w2v_ctc_loss=0.623, task_loss=1.571, contrastive_loss=0.077, total=4032.74, n_correct=2793.83, ppl=3.88, accuracy=69.279, wps=11605.2, ups=1.44, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=34339
2023-08-14 11:58:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 11:58:28 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.155 | nll_loss 2.409 | w2v_ctc_loss 1.318 | task_loss 4.676 | contrastive_loss 0.306 | total 4003.4 | n_correct 2684.3 | ppl 5.31 | accuracy 67.051 | uer 16.85 | wer 18.586 | raw_wer 18.586 | bleu 22.49 | wps 2151.4 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.62
2023-08-14 11:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-14 11:58:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-14 11:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-14 11:59:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.49) (writing took 39.609949531033635 seconds)
2023-08-14 12:00:17 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.881, trans_loss=4.747, nll_loss=1.943, w2v_ctc_loss=0.602, task_loss=1.326, contrastive_loss=0.087, total=4166.96, n_correct=2901.59, ppl=3.85, accuracy=69.633, wps=6255.1, ups=0.75, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=34472
2023-08-14 12:01:27 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.897, trans_loss=4.751, nll_loss=1.948, w2v_ctc_loss=0.598, task_loss=1.343, contrastive_loss=0.236, total=4125.17, n_correct=2864.33, ppl=3.86, accuracy=69.435, wps=11891.9, ups=1.44, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=34542
2023-08-14 12:01:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 12:01:51 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.158 | nll_loss 2.415 | w2v_ctc_loss 1.325 | task_loss 4.64 | contrastive_loss 0.297 | total 4003.4 | n_correct 2683.4 | ppl 5.33 | accuracy 67.028 | uer 17.275 | wer 19.265 | raw_wer 19.265 | bleu 22.56 | wps 2218.7 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 22.62
2023-08-14 12:01:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-08-14 12:01:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5600.pt
2023-08-14 12:01:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5600.pt
2023-08-14 12:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5600.pt (epoch 30 @ 44202 updates, score 22.56) (writing took 21.75196637585759 seconds)
2023-08-14 12:02:13 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-14 12:02:13 | INFO | train | epoch 030 | loss 1.892 | trans_loss 4.749 | nll_loss 1.944 | w2v_ctc_loss 0.609 | task_loss 1.404 | contrastive_loss 0.126 | total 4138.65 | n_correct 2876.39 | ppl 3.85 | accuracy 69.501 | wps 10688.4 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 16.8 | wall 34588
2023-08-14 12:02:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 12:02:14 | INFO | fairseq.trainer | begin training epoch 31
2023-08-14 12:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 12:03:29 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.883, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.607, task_loss=1.458, contrastive_loss=0.075, total=4081.34, n_correct=2845.31, ppl=3.81, accuracy=69.715, wps=6669.9, ups=0.82, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=34664
2023-08-14 12:04:39 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.884, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.603, task_loss=1.437, contrastive_loss=0.098, total=4146.03, n_correct=2888.76, ppl=3.81, accuracy=69.675, wps=11934.9, ups=1.44, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=34733
2023-08-14 12:05:48 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.889, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.608, task_loss=1.441, contrastive_loss=0.139, total=4146.75, n_correct=2894.96, ppl=3.8, accuracy=69.813, wps=11900.3, ups=1.43, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=34803
2023-08-14 12:06:58 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.885, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.603, task_loss=1.534, contrastive_loss=0.076, total=4089.43, n_correct=2846.92, ppl=3.83, accuracy=69.617, wps=11735.1, ups=1.43, wpb=8178.9, bsz=285.5, num_updates=44600, lr=6.6965e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=34873
2023-08-14 12:08:08 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.889, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.619, task_loss=1.461, contrastive_loss=0.085, total=4114.41, n_correct=2862.8, ppl=3.82, accuracy=69.58, wps=11842.7, ups=1.44, wpb=8228.8, bsz=300.9, num_updates=44700, lr=6.689e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=34942
2023-08-14 12:09:17 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.879, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.6, task_loss=1.462, contrastive_loss=0.075, total=4084.36, n_correct=2848.11, ppl=3.8, accuracy=69.732, wps=11802.5, ups=1.44, wpb=8168.7, bsz=295, num_updates=44800, lr=6.68153e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=35012
2023-08-14 12:10:26 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.878, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.601, task_loss=1.34, contrastive_loss=0.075, total=4210.09, n_correct=2936.71, ppl=3.8, accuracy=69.754, wps=12196.9, ups=1.45, wpb=8420.2, bsz=314.9, num_updates=44900, lr=6.67409e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=35081
2023-08-14 12:11:36 | INFO | train_inner | epoch 031:    798 / 1474 loss=1.894, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.606, task_loss=1.472, contrastive_loss=0.145, total=4098.1, n_correct=2845.68, ppl=3.84, accuracy=69.439, wps=11648.8, ups=1.42, wpb=8196.2, bsz=295.7, num_updates=45000, lr=6.66667e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=35151
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:0')
2023-08-14 12:12:45 | INFO | train_inner | epoch 031:    898 / 1474 loss=1.881, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.604, task_loss=1.458, contrastive_loss=0.089, total=4101.05, n_correct=2859.4, ppl=3.79, accuracy=69.724, wps=11864.7, ups=1.45, wpb=8202.1, bsz=296.9, num_updates=45100, lr=6.65927e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=35220
2023-08-14 12:13:55 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.891, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.601, task_loss=1.332, contrastive_loss=0.174, total=4186.3, n_correct=2914.35, ppl=3.85, accuracy=69.616, wps=12060.6, ups=1.44, wpb=8372.6, bsz=318.6, num_updates=45200, lr=6.6519e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=35290
2023-08-14 12:15:04 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.887, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.601, task_loss=1.382, contrastive_loss=0.12, total=4147.34, n_correct=2886.29, ppl=3.83, accuracy=69.594, wps=11902.2, ups=1.43, wpb=8294.7, bsz=314.6, num_updates=45300, lr=6.64455e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=35359
2023-08-14 12:16:14 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.898, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.606, task_loss=1.308, contrastive_loss=0.238, total=4185.34, n_correct=2909.69, ppl=3.84, accuracy=69.521, wps=12064.3, ups=1.44, wpb=8370.7, bsz=321.6, num_updates=45400, lr=6.63723e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.8, wall=35429
2023-08-14 12:17:23 | INFO | train_inner | epoch 031:   1298 / 1474 loss=1.883, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.608, task_loss=1.27, contrastive_loss=0.08, total=4223.54, n_correct=2942.55, ppl=3.84, accuracy=69.67, wps=12257.4, ups=1.45, wpb=8447.1, bsz=325, num_updates=45500, lr=6.62994e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=68, gb_free=13.2, wall=35498
2023-08-14 12:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 12:18:33 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.892, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.604, task_loss=1.309, contrastive_loss=0.181, total=4164.93, n_correct=2899.11, ppl=3.83, accuracy=69.608, wps=11785.6, ups=1.41, wpb=8329.9, bsz=319.7, num_updates=45600, lr=6.62266e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=17.2, wall=35568
2023-08-14 12:19:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2393, device='cuda:1')
2023-08-14 12:19:49 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.156 | nll_loss 2.41 | w2v_ctc_loss 1.336 | task_loss 4.691 | contrastive_loss 0.294 | total 4003.4 | n_correct 2682.6 | ppl 5.32 | accuracy 67.008 | uer 16.858 | wer 18.903 | raw_wer 18.903 | bleu 22.47 | wps 2210.3 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 22.62
2023-08-14 12:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-14 12:19:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4704.pt
2023-08-14 12:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4704.pt
2023-08-14 12:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4704.pt (epoch 31 @ 45675 updates, score 22.47) (writing took 21.535028472542763 seconds)
2023-08-14 12:20:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-14 12:20:11 | INFO | train | epoch 031 | loss 1.887 | trans_loss 4.742 | nll_loss 1.934 | w2v_ctc_loss 0.605 | task_loss 1.406 | contrastive_loss 0.116 | total 4136.77 | n_correct 2880.93 | ppl 3.82 | accuracy 69.642 | wps 11314.2 | ups 1.37 | wpb 8273.5 | bsz 305.1 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 11.7 | wall 35665
2023-08-14 12:20:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 12:20:11 | INFO | fairseq.trainer | begin training epoch 32
2023-08-14 12:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 12:20:35 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.883, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.607, task_loss=1.484, contrastive_loss=0.071, total=4042.6, n_correct=2816.52, ppl=3.81, accuracy=69.671, wps=6624.4, ups=0.82, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=35690
2023-08-14 12:21:45 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.862, trans_loss=4.717, nll_loss=1.902, w2v_ctc_loss=0.581, task_loss=1.296, contrastive_loss=0.08, total=4227.68, n_correct=2967.32, ppl=3.74, accuracy=70.188, wps=12183.4, ups=1.44, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=35760
2023-08-14 12:22:55 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.876, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.599, task_loss=1.333, contrastive_loss=0.089, total=4157.32, n_correct=2902.05, ppl=3.8, accuracy=69.806, wps=11875.4, ups=1.43, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=17, wall=35830
2023-08-14 12:24:04 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.865, trans_loss=4.718, nll_loss=1.904, w2v_ctc_loss=0.583, task_loss=1.324, contrastive_loss=0.083, total=4183.45, n_correct=2938.78, ppl=3.74, accuracy=70.248, wps=12148.4, ups=1.45, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=35899
2023-08-14 12:24:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 12:24:26 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.966 | trans_loss 5.162 | nll_loss 2.417 | w2v_ctc_loss 1.352 | task_loss 4.649 | contrastive_loss 0.299 | total 4003.4 | n_correct 2683.6 | ppl 5.34 | accuracy 67.033 | uer 17.089 | wer 19.145 | raw_wer 19.145 | bleu 22.73 | wps 2288.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.73
2023-08-14 12:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-14 12:24:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-14 12:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-14 12:25:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.73) (writing took 52.61906107328832 seconds)
2023-08-14 12:26:32 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.875, trans_loss=4.726, nll_loss=1.915, w2v_ctc_loss=0.599, task_loss=1.398, contrastive_loss=0.08, total=4157.28, n_correct=2910.08, ppl=3.77, accuracy=70, wps=5616.2, ups=0.68, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=36047
2023-08-14 12:27:42 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.892, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.61, task_loss=1.357, contrastive_loss=0.164, total=4198.93, n_correct=2927.68, ppl=3.81, accuracy=69.724, wps=11930.8, ups=1.42, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=36117
2023-08-14 12:28:52 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.881, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.602, task_loss=1.451, contrastive_loss=0.09, total=4142.69, n_correct=2887.77, ppl=3.8, accuracy=69.708, wps=11855.5, ups=1.43, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=36187
2023-08-14 12:30:02 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.61, task_loss=1.435, contrastive_loss=0.073, total=4154.59, n_correct=2897.73, ppl=3.81, accuracy=69.748, wps=11872.7, ups=1.43, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=70, gb_free=15.5, wall=36257
2023-08-14 12:31:11 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.873, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.594, task_loss=1.448, contrastive_loss=0.069, total=4114.54, n_correct=2873.27, ppl=3.78, accuracy=69.832, wps=11928.8, ups=1.45, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=36326
2023-08-14 12:32:21 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.875, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.596, task_loss=1.456, contrastive_loss=0.068, total=4139.67, n_correct=2889.88, ppl=3.8, accuracy=69.809, wps=11840.5, ups=1.43, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=36396
2023-08-14 12:33:30 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.888, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.602, task_loss=1.39, contrastive_loss=0.163, total=4119.15, n_correct=2870.1, ppl=3.81, accuracy=69.677, wps=11925, ups=1.45, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=36465
2023-08-14 12:34:40 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.891, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.611, task_loss=1.653, contrastive_loss=0.107, total=4019.61, n_correct=2798.27, ppl=3.81, accuracy=69.615, wps=11551.9, ups=1.44, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=36535
2023-08-14 12:35:50 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.898, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.602, task_loss=1.394, contrastive_loss=0.211, total=4149.28, n_correct=2884.25, ppl=3.84, accuracy=69.512, wps=11840.2, ups=1.43, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=70, gb_free=15.7, wall=36605
2023-08-14 12:36:59 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.878, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.605, task_loss=1.438, contrastive_loss=0.068, total=4079.22, n_correct=2847.2, ppl=3.8, accuracy=69.798, wps=11820.8, ups=1.45, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=36674
2023-08-14 12:38:08 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.903, trans_loss=4.737, nll_loss=1.93, w2v_ctc_loss=0.607, task_loss=1.409, contrastive_loss=0.307, total=4111.41, n_correct=2863.18, ppl=3.81, accuracy=69.64, wps=11893.2, ups=1.45, wpb=8222.8, bsz=306.1, num_updates=47100, lr=6.51635e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=36743
2023-08-14 12:38:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 12:39:04 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.155 | nll_loss 2.41 | w2v_ctc_loss 1.349 | task_loss 4.67 | contrastive_loss 0.301 | total 4003.4 | n_correct 2685.2 | ppl 5.32 | accuracy 67.073 | uer 16.946 | wer 18.761 | raw_wer 18.761 | bleu 22.33 | wps 2306 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 22.73
2023-08-14 12:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-08-14 12:39:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 12:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 12:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 32 @ 47149 updates, score 22.33) (writing took 15.665917940437794 seconds)
2023-08-14 12:39:20 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-14 12:39:20 | INFO | train | epoch 032 | loss 1.882 | trans_loss 4.734 | nll_loss 1.924 | w2v_ctc_loss 0.6 | task_loss 1.403 | contrastive_loss 0.123 | total 4138.65 | n_correct 2889.12 | ppl 3.79 | accuracy 69.808 | wps 10615.5 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 16.1 | wall 36815
2023-08-14 12:39:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 12:39:20 | INFO | fairseq.trainer | begin training epoch 33
2023-08-14 12:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 12:40:03 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.881, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.589, task_loss=1.312, contrastive_loss=0.171, total=4156.71, n_correct=2908.53, ppl=3.79, accuracy=69.972, wps=7216.5, ups=0.87, wpb=8313.4, bsz=322.5, num_updates=47200, lr=6.50945e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=36858
2023-08-14 12:41:13 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.864, trans_loss=4.714, nll_loss=1.898, w2v_ctc_loss=0.582, task_loss=1.511, contrastive_loss=0.061, total=4071.44, n_correct=2861.42, ppl=3.73, accuracy=70.28, wps=11715.4, ups=1.44, wpb=8142.9, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=36927
2023-08-14 12:42:23 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.881, trans_loss=4.716, nll_loss=1.902, w2v_ctc_loss=0.587, task_loss=1.198, contrastive_loss=0.236, total=4281.28, n_correct=3005.74, ppl=3.74, accuracy=70.207, wps=12202.6, ups=1.43, wpb=8562.6, bsz=346.3, num_updates=47400, lr=6.4957e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=16.2, wall=36998
2023-08-14 12:43:32 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.875, trans_loss=4.725, nll_loss=1.912, w2v_ctc_loss=0.599, task_loss=1.444, contrastive_loss=0.087, total=4111.69, n_correct=2877.74, ppl=3.76, accuracy=69.989, wps=11889.2, ups=1.45, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=37067
2023-08-14 12:44:41 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.857, trans_loss=4.712, nll_loss=1.896, w2v_ctc_loss=0.581, task_loss=1.318, contrastive_loss=0.069, total=4147.28, n_correct=2918.57, ppl=3.72, accuracy=70.373, wps=12036.5, ups=1.45, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=37136
2023-08-14 12:45:50 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.881, trans_loss=4.73, nll_loss=1.918, w2v_ctc_loss=0.603, task_loss=1.47, contrastive_loss=0.09, total=4127.68, n_correct=2883.82, ppl=3.78, accuracy=69.865, wps=11876, ups=1.44, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=37205
2023-08-14 12:47:00 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.883, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.597, task_loss=1.436, contrastive_loss=0.124, total=4164.1, n_correct=2903.24, ppl=3.81, accuracy=69.721, wps=11964.9, ups=1.44, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=15.1, wall=37275
2023-08-14 12:48:09 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.884, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.613, task_loss=1.535, contrastive_loss=0.07, total=4064.29, n_correct=2835.64, ppl=3.79, accuracy=69.77, wps=11741.8, ups=1.44, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=37344
2023-08-14 12:49:19 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.871, trans_loss=4.723, nll_loss=1.912, w2v_ctc_loss=0.586, task_loss=1.326, contrastive_loss=0.14, total=4141.12, n_correct=2905.77, ppl=3.76, accuracy=70.169, wps=11898.7, ups=1.44, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=37414
2023-08-14 12:49:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 12:49:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.163 | nll_loss 2.417 | w2v_ctc_loss 1.3 | task_loss 4.651 | contrastive_loss 0.3 | total 4003.4 | n_correct 2679.1 | ppl 5.34 | accuracy 66.921 | uer 17.116 | wer 19.03 | raw_wer 19.03 | bleu 22.31 | wps 2184.8 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.73
2023-08-14 12:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-14 12:49:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-14 12:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-14 12:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.31) (writing took 21.236454823985696 seconds)
2023-08-14 12:51:14 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.878, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.604, task_loss=1.401, contrastive_loss=0.082, total=4147.76, n_correct=2898.42, ppl=3.78, accuracy=69.879, wps=7218.8, ups=0.87, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=17.3, wall=37529
2023-08-14 12:51:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 12:52:24 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.877, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.605, task_loss=1.451, contrastive_loss=0.072, total=4116.77, n_correct=2876.57, ppl=3.77, accuracy=69.874, wps=11694.6, ups=1.42, wpb=8233.5, bsz=299.3, num_updates=48200, lr=6.44157e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=11.2, wall=37599
2023-08-14 12:53:34 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.882, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.588, task_loss=1.41, contrastive_loss=0.171, total=4182.67, n_correct=2917.7, ppl=3.8, accuracy=69.757, wps=11995.9, ups=1.43, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=37669
2023-08-14 12:54:44 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.877, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.603, task_loss=1.479, contrastive_loss=0.074, total=4110.02, n_correct=2873.69, ppl=3.77, accuracy=69.919, wps=11790.6, ups=1.43, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=37738
2023-08-14 12:55:54 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.876, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.6, task_loss=1.38, contrastive_loss=0.091, total=4128.82, n_correct=2886.86, ppl=3.79, accuracy=69.92, wps=11734.4, ups=1.42, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=70, gb_free=15.7, wall=37809
2023-08-14 12:57:04 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.888, trans_loss=4.73, nll_loss=1.921, w2v_ctc_loss=0.595, task_loss=1.399, contrastive_loss=0.24, total=4123.47, n_correct=2876.43, ppl=3.79, accuracy=69.758, wps=11847.5, ups=1.44, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=37878
2023-08-14 12:57:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 12:57:43 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.162 | nll_loss 2.415 | w2v_ctc_loss 1.337 | task_loss 4.679 | contrastive_loss 0.308 | total 4003.4 | n_correct 2677 | ppl 5.33 | accuracy 66.868 | uer 16.917 | wer 18.776 | raw_wer 18.776 | bleu 22.2 | wps 2102.4 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 22.73
2023-08-14 12:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-14 12:57:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 12:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 12:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48622 updates, score 22.2) (writing took 15.557662954553962 seconds)
2023-08-14 12:57:58 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-14 12:57:58 | INFO | train | epoch 033 | loss 1.876 | trans_loss 4.726 | nll_loss 1.915 | w2v_ctc_loss 0.596 | task_loss 1.407 | contrastive_loss 0.114 | total 4137.28 | n_correct 2894.97 | ppl 3.77 | accuracy 69.973 | wps 10898.5 | ups 1.32 | wpb 8274.6 | bsz 305.2 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 17.5 | wall 37933
2023-08-14 12:57:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 12:57:58 | INFO | fairseq.trainer | begin training epoch 34
2023-08-14 12:57:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 12:59:01 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.868, trans_loss=4.717, nll_loss=1.901, w2v_ctc_loss=0.594, task_loss=1.385, contrastive_loss=0.074, total=4128.94, n_correct=2895.97, ppl=3.74, accuracy=70.138, wps=7048.4, ups=0.85, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=70, gb_free=14.9, wall=37996
2023-08-14 13:00:10 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.86, trans_loss=4.704, nll_loss=1.885, w2v_ctc_loss=0.584, task_loss=1.466, contrastive_loss=0.076, total=4071.22, n_correct=2870.25, ppl=3.69, accuracy=70.501, wps=11763.3, ups=1.44, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=38065
2023-08-14 13:01:21 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.89, trans_loss=4.724, nll_loss=1.911, w2v_ctc_loss=0.587, task_loss=1.324, contrastive_loss=0.283, total=4237.89, n_correct=2966.69, ppl=3.76, accuracy=70.004, wps=11987.6, ups=1.41, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=70, gb_free=10, wall=38136
2023-08-14 13:02:30 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.87, trans_loss=4.71, nll_loss=1.894, w2v_ctc_loss=0.584, task_loss=1.324, contrastive_loss=0.176, total=4167, n_correct=2927.84, ppl=3.72, accuracy=70.263, wps=12041.1, ups=1.44, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=38205
2023-08-14 13:03:40 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.875, trans_loss=4.722, nll_loss=1.907, w2v_ctc_loss=0.602, task_loss=1.534, contrastive_loss=0.07, total=4071.65, n_correct=2851.56, ppl=3.75, accuracy=70.035, wps=11682.1, ups=1.43, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=38274
2023-08-14 13:04:48 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.865, trans_loss=4.708, nll_loss=1.891, w2v_ctc_loss=0.591, task_loss=1.425, contrastive_loss=0.073, total=4110.13, n_correct=2888.83, ppl=3.71, accuracy=70.286, wps=11979.8, ups=1.46, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=38343
2023-08-14 13:05:58 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.868, trans_loss=4.72, nll_loss=1.907, w2v_ctc_loss=0.59, task_loss=1.423, contrastive_loss=0.068, total=4128.65, n_correct=2895.12, ppl=3.75, accuracy=70.123, wps=11937.2, ups=1.45, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=38412
2023-08-14 13:07:07 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.879, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.588, task_loss=1.476, contrastive_loss=0.136, total=4075.69, n_correct=2847.28, ppl=3.8, accuracy=69.86, wps=11766.4, ups=1.44, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=38482
2023-08-14 13:08:17 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.873, trans_loss=4.724, nll_loss=1.911, w2v_ctc_loss=0.592, task_loss=1.489, contrastive_loss=0.093, total=4104.97, n_correct=2878.07, ppl=3.76, accuracy=70.112, wps=11748, ups=1.43, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=38551
2023-08-14 13:09:26 | INFO | train_inner | epoch 034:    978 / 1474 loss=1.87, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.592, task_loss=1.377, contrastive_loss=0.088, total=4168.94, n_correct=2921.91, ppl=3.75, accuracy=70.088, wps=12003.5, ups=1.44, wpb=8337.9, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=38621
2023-08-14 13:10:35 | INFO | train_inner | epoch 034:   1078 / 1474 loss=1.871, trans_loss=4.723, nll_loss=1.909, w2v_ctc_loss=0.6, task_loss=1.355, contrastive_loss=0.072, total=4155.12, n_correct=2911.49, ppl=3.76, accuracy=70.07, wps=12030.9, ups=1.45, wpb=8310.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=38690
2023-08-14 13:11:45 | INFO | train_inner | epoch 034:   1178 / 1474 loss=1.871, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.593, task_loss=1.453, contrastive_loss=0.085, total=4096.48, n_correct=2868.79, ppl=3.76, accuracy=70.031, wps=11817.2, ups=1.44, wpb=8193, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=38759
2023-08-14 13:12:54 | INFO | train_inner | epoch 034:   1278 / 1474 loss=1.867, trans_loss=4.718, nll_loss=1.903, w2v_ctc_loss=0.591, task_loss=1.423, contrastive_loss=0.067, total=4149.03, n_correct=2906.4, ppl=3.74, accuracy=70.05, wps=11991, ups=1.45, wpb=8298.1, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=38829
2023-08-14 13:14:04 | INFO | train_inner | epoch 034:   1378 / 1474 loss=1.878, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.596, task_loss=1.345, contrastive_loss=0.132, total=4200.34, n_correct=2938.12, ppl=3.77, accuracy=69.95, wps=12001.9, ups=1.43, wpb=8400.7, bsz=321.9, num_updates=50000, lr=6.32456e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=14.7, wall=38899
2023-08-14 13:14:04 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-14 13:14:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 13:14:27 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.161 | nll_loss 2.415 | w2v_ctc_loss 1.3 | task_loss 4.659 | contrastive_loss 0.296 | total 4003.4 | n_correct 2684.5 | ppl 5.33 | accuracy 67.056 | uer 16.901 | wer 18.821 | raw_wer 18.821 | bleu 22.14 | wps 2254.2 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.73
2023-08-14 13:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-14 13:14:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-14 13:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-14 13:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.14) (writing took 20.18024007603526 seconds)
2023-08-14 13:14:48 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-14 13:14:48 | INFO | train | epoch 034 | loss 1.872 | trans_loss 4.719 | nll_loss 1.906 | w2v_ctc_loss 0.592 | task_loss 1.414 | contrastive_loss 0.109 | total 4133.33 | n_correct 2897.88 | ppl 3.75 | accuracy 70.11 | wps 11286 | ups 1.37 | wpb 8266.7 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.535 | clip 0 | loss_scale 32 | train_wall 951 | gb_free 14.7 | wall 38942
2023-08-14 13:14:48 | INFO | fairseq_cli.train | done training in 38881.5 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-9:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1392 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
