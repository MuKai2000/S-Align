2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17437
2023-09-03 21:28:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-03 21:28:01 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-03 21:28:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17437', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-03 21:28:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-03 21:28:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-03 21:28:05 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-03 21:28:05 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-09-03 21:28:05 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 21:28:09 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-03 21:28:09 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-03 21:28:09 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-03 21:28:10 | INFO | root | load pretrained hubert
2023-09-03 21:28:18 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 21:28:22 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 21:28:28 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 21:28:28 | INFO | root | share the sematic adapter and textual encoder
2023-09-03 21:28:28 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-03 21:28:28 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-03 21:28:28 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-03 21:28:28 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-03 21:28:28 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-03 21:28:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-03 21:28:28 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 21:28:28 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 21:28:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 21:28:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 21:28:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-03 21:28:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-03 21:28:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-03 21:28:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 21:28:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 21:28:44 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-03 21:28:44 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-03 21:28:44 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_last.pt
2023-09-03 21:28:44 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_last.pt
2023-09-03 21:28:44 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-03 21:28:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 21:28:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 21:28:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 21:28:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 21:28:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 21:29:30 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-03 21:29:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 21:29:30 | INFO | fairseq.trainer | begin training epoch 1
2023-09-03 21:29:30 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 21:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 21:30:40 | INFO | train_inner | epoch 001:    101 / 1474 loss=17.385, trans_loss=5.873, nll_loss=4.681, w2v_ctc_loss=22.309, task_loss=1.373, task_loss_gen=1.395, contrastive_loss=0, total=4212.33, n_correct=124.57, ppl=25.65, accuracy=2.957, wps=21343.4, ups=1.7, wpb=12566.1, bsz=472.9, num_updates=100, lr=4.098e-06, gnorm=2.701, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=115
2023-09-03 21:30:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-03 21:31:38 | INFO | train_inner | epoch 001:    202 / 1474 loss=13.475, trans_loss=5.85, nll_loss=4.681, w2v_ctc_loss=16.308, task_loss=1.123, task_loss_gen=1.428, contrastive_loss=0, total=4127.88, n_correct=127.28, ppl=25.65, accuracy=3.083, wps=21071.8, ups=1.71, wpb=12326, bsz=463, num_updates=200, lr=8.096e-06, gnorm=7.327, clip=15, loss_scale=32, train_wall=58, gb_free=18.7, wall=174
2023-09-03 21:32:37 | INFO | train_inner | epoch 001:    302 / 1474 loss=7.228, trans_loss=5.785, nll_loss=4.639, w2v_ctc_loss=6.751, task_loss=0.832, task_loss_gen=1.781, contrastive_loss=0, total=4077.62, n_correct=133.71, ppl=24.92, accuracy=3.279, wps=20546, ups=1.69, wpb=12179.5, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=1.417, clip=0, loss_scale=32, train_wall=59, gb_free=19.3, wall=233
2023-09-03 21:33:35 | INFO | train_inner | epoch 001:    402 / 1474 loss=6.699, trans_loss=5.714, nll_loss=4.576, w2v_ctc_loss=6.013, task_loss=0.413, task_loss_gen=2.252, contrastive_loss=0, total=4177.45, n_correct=120.53, ppl=23.86, accuracy=2.885, wps=21487.9, ups=1.72, wpb=12474.2, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=57, gb_free=18.7, wall=291
2023-09-03 21:34:34 | INFO | train_inner | epoch 001:    502 / 1474 loss=6.513, trans_loss=5.744, nll_loss=4.622, w2v_ctc_loss=5.692, task_loss=0.158, task_loss_gen=3.066, contrastive_loss=0, total=4202.06, n_correct=99.39, ppl=24.63, accuracy=2.365, wps=21560.7, ups=1.72, wpb=12556.3, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=58, gb_free=14.6, wall=349
2023-09-03 21:35:31 | INFO | train_inner | epoch 001:    602 / 1474 loss=6.458, trans_loss=5.88, nll_loss=4.788, w2v_ctc_loss=5.467, task_loss=0.047, task_loss_gen=4.443, contrastive_loss=0, total=4124.52, n_correct=81.49, ppl=27.63, accuracy=1.976, wps=21300.6, ups=1.73, wpb=12301.1, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=57, gb_free=18.8, wall=407
2023-09-03 21:36:29 | INFO | train_inner | epoch 001:    702 / 1474 loss=6.292, trans_loss=5.963, nll_loss=4.894, w2v_ctc_loss=5.118, task_loss=0.013, task_loss_gen=6.072, contrastive_loss=0, total=4147.01, n_correct=54.5, ppl=29.74, accuracy=1.314, wps=21353.5, ups=1.72, wpb=12381.3, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.461, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=465
2023-09-03 21:37:27 | INFO | train_inner | epoch 001:    802 / 1474 loss=6.019, trans_loss=5.991, nll_loss=4.927, w2v_ctc_loss=4.671, task_loss=0.004, task_loss_gen=7.211, contrastive_loss=0, total=4121.11, n_correct=43.75, ppl=30.42, accuracy=1.062, wps=21373.8, ups=1.74, wpb=12298.3, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.763, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=523
2023-09-03 21:38:26 | INFO | train_inner | epoch 001:    902 / 1474 loss=5.838, trans_loss=6.019, nll_loss=4.958, w2v_ctc_loss=4.363, task_loss=0.001, task_loss_gen=8.482, contrastive_loss=0, total=4167.98, n_correct=53.91, ppl=31.09, accuracy=1.293, wps=21142.2, ups=1.7, wpb=12446.6, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.791, clip=0, loss_scale=32, train_wall=58, gb_free=19, wall=581
2023-09-03 21:39:24 | INFO | train_inner | epoch 001:   1002 / 1474 loss=5.697, trans_loss=6.051, nll_loss=4.993, w2v_ctc_loss=4.107, task_loss=0, task_loss_gen=9.474, contrastive_loss=0, total=4136.38, n_correct=99.03, ppl=31.85, accuracy=2.394, wps=21241, ups=1.72, wpb=12354.6, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=0.988, clip=0, loss_scale=32, train_wall=57, gb_free=19.2, wall=640
2023-09-03 21:40:22 | INFO | train_inner | epoch 001:   1102 / 1474 loss=5.605, trans_loss=6.084, nll_loss=5.03, w2v_ctc_loss=3.934, task_loss=0, task_loss_gen=10.621, contrastive_loss=0, total=4148.31, n_correct=129.92, ppl=32.68, accuracy=3.132, wps=21333.6, ups=1.72, wpb=12371.7, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=0.999, clip=0, loss_scale=32, train_wall=57, gb_free=18.6, wall=698
2023-09-03 21:40:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 21:41:23 | INFO | train_inner | epoch 001:   1203 / 1474 loss=5.531, trans_loss=6.09, nll_loss=5.04, w2v_ctc_loss=3.807, task_loss=0, task_loss_gen=12.488, contrastive_loss=0, total=4116.39, n_correct=147.51, ppl=32.9, accuracy=3.583, wps=20935.2, ups=1.7, wpb=12295.1, bsz=430, num_updates=1200, lr=4.8076e-05, gnorm=1.088, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=756
2023-09-03 21:42:20 | INFO | train_inner | epoch 001:   1303 / 1474 loss=5.43, trans_loss=6.085, nll_loss=5.034, w2v_ctc_loss=3.661, task_loss=0, task_loss_gen=12.672, contrastive_loss=0, total=4055.88, n_correct=146.17, ppl=32.77, accuracy=3.604, wps=21066.9, ups=1.74, wpb=12109.1, bsz=443.9, num_updates=1300, lr=5.2074e-05, gnorm=1.09, clip=0, loss_scale=16, train_wall=57, gb_free=19.2, wall=816
2023-09-03 21:43:19 | INFO | train_inner | epoch 001:   1403 / 1474 loss=5.339, trans_loss=6.072, nll_loss=5.02, w2v_ctc_loss=3.537, task_loss=0, task_loss_gen=13.61, contrastive_loss=0, total=4127.47, n_correct=151.48, ppl=32.44, accuracy=3.67, wps=21052.4, ups=1.71, wpb=12332.8, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.103, clip=0, loss_scale=16, train_wall=58, gb_free=19.1, wall=874
2023-09-03 21:44:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-03 21:44:46 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.311 | trans_loss 13.261 | nll_loss 12.881 | w2v_ctc_loss 4.487 | task_loss 0 | task_loss_gen 86.121 | contrastive_loss 0 | total 4003.4 | n_correct 242.7 | ppl 7544.47 | accuracy 6.062 | uer 60.189 | wer 58.805 | raw_wer 58.805 | bleu 0 | wps 1040.8 | wpb 4003.4 | bsz 141.8 | num_updates 1471
2023-09-03 21:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1471 updates
2023-09-03 21:44:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 21:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 21:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 1 @ 1471 updates, score 0.0) (writing took 5.078615050995722 seconds)
2023-09-03 21:44:51 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-03 21:44:51 | INFO | train | epoch 001 | loss 7.305 | trans_loss 5.949 | nll_loss 4.856 | w2v_ctc_loss 6.696 | task_loss 0.272 | task_loss_gen 7.046 | contrastive_loss 0 | total 4138.13 | n_correct 110.218 | ppl 28.96 | accuracy 2.663 | wps 19953.5 | ups 1.62 | wpb 12354.2 | bsz 458.2 | num_updates 1471 | lr 5.89106e-05 | gnorm 1.435 | clip 1 | loss_scale 16 | train_wall 849 | gb_free 18.9 | wall 967
2023-09-03 21:44:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 21:44:52 | INFO | fairseq.trainer | begin training epoch 2
2023-09-03 21:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 21:45:17 | INFO | train_inner | epoch 002:     29 / 1474 loss=5.267, trans_loss=6.07, nll_loss=5.014, w2v_ctc_loss=3.427, task_loss=0, task_loss_gen=13.487, contrastive_loss=0, total=4165.52, n_correct=152.25, ppl=32.3, accuracy=3.655, wps=10512.4, ups=0.85, wpb=12425.3, bsz=471.4, num_updates=1500, lr=6.007e-05, gnorm=1.371, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=993
2023-09-03 21:46:15 | INFO | train_inner | epoch 002:    129 / 1474 loss=5.216, trans_loss=6.062, nll_loss=5.003, w2v_ctc_loss=3.355, task_loss=0, task_loss_gen=14.964, contrastive_loss=0, total=4149.27, n_correct=151.3, ppl=32.06, accuracy=3.646, wps=21437.6, ups=1.73, wpb=12375.1, bsz=451.7, num_updates=1600, lr=6.4068e-05, gnorm=1.096, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1050
2023-09-03 21:47:12 | INFO | train_inner | epoch 002:    229 / 1474 loss=5.122, trans_loss=6.038, nll_loss=4.978, w2v_ctc_loss=3.238, task_loss=0, task_loss_gen=13.228, contrastive_loss=0, total=4199.2, n_correct=153.03, ppl=31.52, accuracy=3.644, wps=21769.2, ups=1.74, wpb=12541.6, bsz=494.4, num_updates=1700, lr=6.8066e-05, gnorm=1.144, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1108
2023-09-03 21:48:10 | INFO | train_inner | epoch 002:    329 / 1474 loss=5.1, trans_loss=6.031, nll_loss=4.967, w2v_ctc_loss=3.201, task_loss=0, task_loss_gen=16.228, contrastive_loss=0, total=4130.92, n_correct=156.92, ppl=31.27, accuracy=3.799, wps=21381.5, ups=1.73, wpb=12331.6, bsz=442.3, num_updates=1800, lr=7.2064e-05, gnorm=1.16, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1166
2023-09-03 21:49:08 | INFO | train_inner | epoch 002:    429 / 1474 loss=5.063, trans_loss=6.023, nll_loss=4.96, w2v_ctc_loss=3.152, task_loss=0, task_loss_gen=17.974, contrastive_loss=0, total=4036.18, n_correct=154.76, ppl=31.13, accuracy=3.834, wps=20902.1, ups=1.73, wpb=12064.4, bsz=416.3, num_updates=1900, lr=7.6062e-05, gnorm=0.994, clip=0, loss_scale=16, train_wall=57, gb_free=18.9, wall=1223
2023-09-03 21:50:06 | INFO | train_inner | epoch 002:    529 / 1474 loss=4.994, trans_loss=6.029, nll_loss=4.964, w2v_ctc_loss=3.047, task_loss=0, task_loss_gen=15.887, contrastive_loss=0, total=4185.63, n_correct=151.45, ppl=31.21, accuracy=3.618, wps=21290.5, ups=1.7, wpb=12487.7, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=1.003, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1282
2023-09-03 21:50:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 21:50:53 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.031 | trans_loss 13.1 | nll_loss 12.678 | w2v_ctc_loss 3.918 | task_loss 0 | task_loss_gen 99.334 | contrastive_loss 0 | total 4003.4 | n_correct 241.4 | ppl 6555.41 | accuracy 6.03 | uer 54.453 | wer 53.63 | raw_wer 53.63 | bleu 0 | wps 1043.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-09-03 21:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-03 21:50:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_2_2000.pt
2023-09-03 21:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_2_2000.pt
2023-09-03 21:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.716295025951695 seconds)
2023-09-03 21:52:03 | INFO | train_inner | epoch 002:    629 / 1474 loss=4.952, trans_loss=6.025, nll_loss=4.96, w2v_ctc_loss=2.983, task_loss=0, task_loss_gen=16.88, contrastive_loss=0, total=4116.05, n_correct=150.11, ppl=31.13, accuracy=3.647, wps=10545.5, ups=0.86, wpb=12285, bsz=443.4, num_updates=2100, lr=8.4058e-05, gnorm=1.076, clip=0, loss_scale=16, train_wall=56, gb_free=19.5, wall=1398
2023-09-03 21:53:00 | INFO | train_inner | epoch 002:    729 / 1474 loss=4.923, trans_loss=6.025, nll_loss=4.961, w2v_ctc_loss=2.944, task_loss=0, task_loss_gen=16.806, contrastive_loss=0, total=4152.4, n_correct=151.74, ppl=31.15, accuracy=3.654, wps=21656.4, ups=1.75, wpb=12393.8, bsz=463.6, num_updates=2200, lr=8.8056e-05, gnorm=0.982, clip=0, loss_scale=16, train_wall=56, gb_free=18.8, wall=1456
2023-09-03 21:53:58 | INFO | train_inner | epoch 002:    829 / 1474 loss=4.893, trans_loss=6.014, nll_loss=4.951, w2v_ctc_loss=2.908, task_loss=0, task_loss_gen=17.335, contrastive_loss=0, total=4168.87, n_correct=147.05, ppl=30.93, accuracy=3.527, wps=21546.7, ups=1.73, wpb=12453.5, bsz=461.2, num_updates=2300, lr=9.2054e-05, gnorm=0.873, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1513
2023-09-03 21:54:55 | INFO | train_inner | epoch 002:    929 / 1474 loss=4.848, trans_loss=6.006, nll_loss=4.94, w2v_ctc_loss=2.844, task_loss=0, task_loss_gen=17.79, contrastive_loss=0, total=4104.79, n_correct=146.32, ppl=30.69, accuracy=3.565, wps=21325.3, ups=1.74, wpb=12254.8, bsz=445.6, num_updates=2400, lr=9.6052e-05, gnorm=0.903, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1571
2023-09-03 21:55:54 | INFO | train_inner | epoch 002:   1029 / 1474 loss=4.821, trans_loss=6.003, nll_loss=4.937, w2v_ctc_loss=2.803, task_loss=0, task_loss_gen=17.702, contrastive_loss=0, total=4100.85, n_correct=138.18, ppl=30.63, accuracy=3.37, wps=20818.5, ups=1.7, wpb=12245.2, bsz=455.2, num_updates=2500, lr=0.00010005, gnorm=0.857, clip=0, loss_scale=16, train_wall=58, gb_free=19.2, wall=1630
2023-09-03 21:56:52 | INFO | train_inner | epoch 002:   1129 / 1474 loss=4.772, trans_loss=6.002, nll_loss=4.935, w2v_ctc_loss=2.738, task_loss=0, task_loss_gen=15.944, contrastive_loss=0, total=4195.47, n_correct=135.99, ppl=30.59, accuracy=3.241, wps=21599.2, ups=1.72, wpb=12522.7, bsz=489.6, num_updates=2600, lr=0.000104048, gnorm=0.781, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1688
2023-09-03 21:57:50 | INFO | train_inner | epoch 002:   1229 / 1474 loss=4.758, trans_loss=6.002, nll_loss=4.933, w2v_ctc_loss=2.717, task_loss=0, task_loss_gen=16.331, contrastive_loss=0, total=4220.45, n_correct=146.28, ppl=30.54, accuracy=3.466, wps=21784.1, ups=1.73, wpb=12591.7, bsz=492, num_updates=2700, lr=0.000108046, gnorm=0.749, clip=0, loss_scale=16, train_wall=57, gb_free=19.6, wall=1746
2023-09-03 21:58:47 | INFO | train_inner | epoch 002:   1329 / 1474 loss=4.739, trans_loss=5.989, nll_loss=4.921, w2v_ctc_loss=2.692, task_loss=0, task_loss_gen=17.179, contrastive_loss=0, total=4159.97, n_correct=138.83, ppl=30.29, accuracy=3.337, wps=21675.8, ups=1.74, wpb=12433.6, bsz=462.1, num_updates=2800, lr=0.000112044, gnorm=0.71, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1803
2023-09-03 21:59:45 | INFO | train_inner | epoch 002:   1429 / 1474 loss=4.73, trans_loss=5.998, nll_loss=4.93, w2v_ctc_loss=2.67, task_loss=0, task_loss_gen=19.494, contrastive_loss=0, total=4050.6, n_correct=137.44, ppl=30.48, accuracy=3.393, wps=21033.8, ups=1.74, wpb=12095, bsz=438.3, num_updates=2900, lr=0.000116042, gnorm=0.811, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1860
2023-09-03 22:00:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 22:00:58 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.759 | trans_loss 12.925 | nll_loss 12.47 | w2v_ctc_loss 3.404 | task_loss 0 | task_loss_gen 107.617 | contrastive_loss 0 | total 4003.4 | n_correct 232.3 | ppl 5672.8 | accuracy 5.803 | uer 48.549 | wer 47.422 | raw_wer 47.422 | bleu 0 | wps 1041.5 | wpb 4003.4 | bsz 141.8 | num_updates 2945 | best_bleu 0
2023-09-03 22:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2945 updates
2023-09-03 22:00:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 2 @ 2945 updates, score 0.0) (writing took 12.638850567978807 seconds)
2023-09-03 22:01:11 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-03 22:01:11 | INFO | train | epoch 002 | loss 4.924 | trans_loss 6.018 | nll_loss 4.953 | w2v_ctc_loss 2.949 | task_loss 0 | task_loss_gen 16.644 | contrastive_loss 0 | total 4138.65 | n_correct 146.771 | ppl 30.98 | accuracy 3.546 | wps 18600.3 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 2945 | lr 0.000117841 | gnorm 0.94 | clip 0 | loss_scale 16 | train_wall 839 | gb_free 19 | wall 1946
2023-09-03 22:01:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 22:01:11 | INFO | fairseq.trainer | begin training epoch 3
2023-09-03 22:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 22:01:50 | INFO | train_inner | epoch 003:     55 / 1474 loss=4.695, trans_loss=5.986, nll_loss=4.915, w2v_ctc_loss=2.621, task_loss=0, task_loss_gen=18.487, contrastive_loss=0, total=4066.57, n_correct=136.88, ppl=30.16, accuracy=3.366, wps=9711.7, ups=0.8, wpb=12139.2, bsz=441.1, num_updates=3000, lr=0.00012004, gnorm=0.752, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1985
2023-09-03 22:01:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 22:03:15 | INFO | train_inner | epoch 003:    156 / 1474 loss=4.008, trans_loss=5.283, nll_loss=4.053, w2v_ctc_loss=2.303, task_loss=0.367, task_loss_gen=5.872, contrastive_loss=0, total=4139, n_correct=288.26, ppl=16.59, accuracy=6.964, wps=14550.7, ups=1.18, wpb=12357.5, bsz=453.7, num_updates=3100, lr=0.000124038, gnorm=1.596, clip=0, loss_scale=8, train_wall=84, gb_free=15.9, wall=2070
2023-09-03 22:04:41 | INFO | train_inner | epoch 003:    256 / 1474 loss=3.36, trans_loss=4.574, nll_loss=3.109, w2v_ctc_loss=2.051, task_loss=0.25, task_loss_gen=3.017, contrastive_loss=0, total=4148.62, n_correct=862.73, ppl=8.63, accuracy=20.796, wps=14457.7, ups=1.17, wpb=12396.7, bsz=463.7, num_updates=3200, lr=0.000128036, gnorm=1.095, clip=0, loss_scale=8, train_wall=85, gb_free=16.2, wall=2156
2023-09-03 22:06:05 | INFO | train_inner | epoch 003:    356 / 1474 loss=3.036, trans_loss=4.198, nll_loss=2.611, w2v_ctc_loss=1.951, task_loss=0.225, task_loss_gen=2.918, contrastive_loss=0, total=4171.73, n_correct=1269.24, ppl=6.11, accuracy=30.425, wps=14707.7, ups=1.18, wpb=12449.7, bsz=468.2, num_updates=3300, lr=0.000132034, gnorm=1.066, clip=0, loss_scale=8, train_wall=84, gb_free=15.1, wall=2241
2023-09-03 22:07:31 | INFO | train_inner | epoch 003:    456 / 1474 loss=2.974, trans_loss=4.171, nll_loss=2.576, w2v_ctc_loss=1.884, task_loss=0.194, task_loss_gen=3.412, contrastive_loss=0, total=4197.48, n_correct=1318.51, ppl=5.96, accuracy=31.412, wps=14593.7, ups=1.16, wpb=12527.9, bsz=474.4, num_updates=3400, lr=0.000136032, gnorm=0.991, clip=0, loss_scale=8, train_wall=85, gb_free=12, wall=2327
2023-09-03 22:08:56 | INFO | train_inner | epoch 003:    556 / 1474 loss=2.92, trans_loss=4.161, nll_loss=2.567, w2v_ctc_loss=1.81, task_loss=0.193, task_loss_gen=4.398, contrastive_loss=0, total=4095.16, n_correct=1299.87, ppl=5.93, accuracy=31.742, wps=14450.3, ups=1.18, wpb=12233.8, bsz=440.6, num_updates=3500, lr=0.00014003, gnorm=0.923, clip=0, loss_scale=8, train_wall=84, gb_free=15.4, wall=2411
2023-09-03 22:10:23 | INFO | train_inner | epoch 003:    656 / 1474 loss=2.867, trans_loss=4.15, nll_loss=2.549, w2v_ctc_loss=1.745, task_loss=0.168, task_loss_gen=4.72, contrastive_loss=0, total=4223.37, n_correct=1365.2, ppl=5.85, accuracy=32.325, wps=14438.7, ups=1.15, wpb=12593.2, bsz=484, num_updates=3600, lr=0.000144028, gnorm=0.848, clip=0, loss_scale=8, train_wall=87, gb_free=16.2, wall=2499
2023-09-03 22:11:48 | INFO | train_inner | epoch 003:    756 / 1474 loss=2.843, trans_loss=4.136, nll_loss=2.536, w2v_ctc_loss=1.721, task_loss=0.191, task_loss_gen=4.786, contrastive_loss=0, total=4165.36, n_correct=1362.36, ppl=5.8, accuracy=32.707, wps=14676.1, ups=1.18, wpb=12442.1, bsz=470.9, num_updates=3700, lr=0.000148026, gnorm=0.888, clip=0, loss_scale=8, train_wall=84, gb_free=14.8, wall=2583
2023-09-03 22:13:13 | INFO | train_inner | epoch 003:    856 / 1474 loss=2.815, trans_loss=4.137, nll_loss=2.536, w2v_ctc_loss=1.677, task_loss=0.178, task_loss_gen=5.295, contrastive_loss=0, total=4164.94, n_correct=1364.95, ppl=5.8, accuracy=32.772, wps=14636.1, ups=1.18, wpb=12434.8, bsz=457.9, num_updates=3800, lr=0.000152024, gnorm=0.846, clip=0, loss_scale=8, train_wall=84, gb_free=14.7, wall=2668
2023-09-03 22:14:39 | INFO | train_inner | epoch 003:    956 / 1474 loss=2.796, trans_loss=4.127, nll_loss=2.521, w2v_ctc_loss=1.659, task_loss=0.181, task_loss_gen=5.105, contrastive_loss=0, total=4156.71, n_correct=1382.24, ppl=5.74, accuracy=33.253, wps=14452.5, ups=1.17, wpb=12401.4, bsz=465.4, num_updates=3900, lr=0.000156022, gnorm=0.866, clip=0, loss_scale=8, train_wall=85, gb_free=16.6, wall=2754
2023-09-03 22:16:03 | INFO | train_inner | epoch 003:   1056 / 1474 loss=2.793, trans_loss=4.123, nll_loss=2.518, w2v_ctc_loss=1.651, task_loss=0.229, task_loss_gen=5.521, contrastive_loss=0, total=4063.38, n_correct=1351.09, ppl=5.73, accuracy=33.25, wps=14277.8, ups=1.18, wpb=12134.6, bsz=439.1, num_updates=4000, lr=0.00016002, gnorm=0.87, clip=0, loss_scale=8, train_wall=84, gb_free=17.2, wall=2839
2023-09-03 22:16:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 22:16:38 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.543 | trans_loss 7.377 | nll_loss 5.304 | w2v_ctc_loss 1.852 | task_loss 0.007 | task_loss_gen 21.339 | contrastive_loss 0 | total 4003.4 | n_correct 1384.1 | ppl 39.5 | accuracy 34.573 | uer 28.739 | wer 29.626 | raw_wer 29.626 | bleu 0.32 | wps 1466.6 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 0.32
2023-09-03 22:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-09-03 22:16:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_3_4000.pt
2023-09-03 22:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_3_4000.pt
2023-09-03 22:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.32) (writing took 13.66325050900923 seconds)
2023-09-03 22:18:17 | INFO | train_inner | epoch 003:   1156 / 1474 loss=2.759, trans_loss=4.124, nll_loss=2.518, w2v_ctc_loss=1.605, task_loss=0.226, task_loss_gen=5.871, contrastive_loss=0, total=4049.57, n_correct=1355.22, ppl=5.73, accuracy=33.466, wps=9046.7, ups=0.75, wpb=12084.5, bsz=438, num_updates=4100, lr=0.000164018, gnorm=0.824, clip=0, loss_scale=8, train_wall=84, gb_free=16.5, wall=2973
2023-09-03 22:19:41 | INFO | train_inner | epoch 003:   1256 / 1474 loss=2.74, trans_loss=4.116, nll_loss=2.509, w2v_ctc_loss=1.583, task_loss=0.226, task_loss_gen=5.094, contrastive_loss=0, total=4061.36, n_correct=1360.98, ppl=5.69, accuracy=33.51, wps=14380.4, ups=1.19, wpb=12130, bsz=433.6, num_updates=4200, lr=0.000168016, gnorm=0.856, clip=0, loss_scale=8, train_wall=84, gb_free=16.1, wall=3057
2023-09-03 22:21:07 | INFO | train_inner | epoch 003:   1356 / 1474 loss=2.711, trans_loss=4.106, nll_loss=2.496, w2v_ctc_loss=1.547, task_loss=0.167, task_loss_gen=5.159, contrastive_loss=0, total=4141.12, n_correct=1405.23, ppl=5.64, accuracy=33.934, wps=14448.8, ups=1.17, wpb=12364.3, bsz=463.2, num_updates=4300, lr=0.000172014, gnorm=0.813, clip=0, loss_scale=8, train_wall=85, gb_free=14.4, wall=3143
2023-09-03 22:22:32 | INFO | train_inner | epoch 003:   1456 / 1474 loss=2.697, trans_loss=4.108, nll_loss=2.498, w2v_ctc_loss=1.531, task_loss=0.198, task_loss_gen=4.952, contrastive_loss=0, total=4211.06, n_correct=1432.83, ppl=5.65, accuracy=34.025, wps=14716.1, ups=1.17, wpb=12576.2, bsz=477.6, num_updates=4400, lr=0.000176012, gnorm=0.802, clip=0, loss_scale=8, train_wall=85, gb_free=16.9, wall=3228
2023-09-03 22:22:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 22:23:21 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.466 | trans_loss 7.32 | nll_loss 5.232 | w2v_ctc_loss 1.725 | task_loss 0.002 | task_loss_gen 26.839 | contrastive_loss 0 | total 4003.4 | n_correct 1411.7 | ppl 37.58 | accuracy 35.263 | uer 27.293 | wer 28.291 | raw_wer 28.291 | bleu 0.41 | wps 1557.6 | wpb 4003.4 | bsz 141.8 | num_updates 4418 | best_bleu 0.41
2023-09-03 22:23:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4418 updates
2023-09-03 22:23:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:23:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 3 @ 4418 updates, score 0.41) (writing took 12.379923189990222 seconds)
2023-09-03 22:23:34 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-03 22:23:34 | INFO | train | epoch 003 | loss 3.013 | trans_loss 4.314 | nll_loss 2.766 | w2v_ctc_loss 1.794 | task_loss 0.205 | task_loss_gen 5.223 | contrastive_loss 0 | total 4139.04 | n_correct 1204.14 | ppl 6.8 | accuracy 29.092 | wps 13552.7 | ups 1.1 | wpb 12357 | bsz 458.6 | num_updates 4418 | lr 0.000176732 | gnorm 0.941 | clip 0 | loss_scale 8 | train_wall 1231 | gb_free 16.1 | wall 3289
2023-09-03 22:23:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 22:23:34 | INFO | fairseq.trainer | begin training epoch 4
2023-09-03 22:23:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 22:24:51 | INFO | train_inner | epoch 004:     82 / 1474 loss=2.666, trans_loss=4.095, nll_loss=2.48, w2v_ctc_loss=1.484, task_loss=0.238, task_loss_gen=5.32, contrastive_loss=0, total=4090.08, n_correct=1400.78, ppl=5.58, accuracy=34.248, wps=8825.3, ups=0.72, wpb=12208.2, bsz=437, num_updates=4500, lr=0.00018001, gnorm=0.783, clip=0, loss_scale=8, train_wall=84, gb_free=16.2, wall=3366
2023-09-03 22:26:16 | INFO | train_inner | epoch 004:    182 / 1474 loss=2.649, trans_loss=4.086, nll_loss=2.468, w2v_ctc_loss=1.468, task_loss=0.177, task_loss_gen=4.752, contrastive_loss=0, total=4179.17, n_correct=1436.03, ppl=5.53, accuracy=34.362, wps=14686.3, ups=1.18, wpb=12477, bsz=468, num_updates=4600, lr=0.000184008, gnorm=0.796, clip=0, loss_scale=8, train_wall=84, gb_free=10.4, wall=3451
2023-09-03 22:27:41 | INFO | train_inner | epoch 004:    282 / 1474 loss=2.65, trans_loss=4.093, nll_loss=2.479, w2v_ctc_loss=1.464, task_loss=0.262, task_loss_gen=4.884, contrastive_loss=0, total=4139.78, n_correct=1418.35, ppl=5.57, accuracy=34.261, wps=14555, ups=1.18, wpb=12367.7, bsz=462.4, num_updates=4700, lr=0.000188006, gnorm=0.763, clip=0, loss_scale=8, train_wall=84, gb_free=16.7, wall=3536
2023-09-03 22:29:05 | INFO | train_inner | epoch 004:    382 / 1474 loss=2.65, trans_loss=4.103, nll_loss=2.486, w2v_ctc_loss=1.455, task_loss=0.251, task_loss_gen=4.714, contrastive_loss=0, total=4132.58, n_correct=1408.08, ppl=5.6, accuracy=34.073, wps=14611.2, ups=1.19, wpb=12328, bsz=443.4, num_updates=4800, lr=0.000192004, gnorm=0.786, clip=0, loss_scale=8, train_wall=84, gb_free=15.8, wall=3621
2023-09-03 22:30:30 | INFO | train_inner | epoch 004:    482 / 1474 loss=2.621, trans_loss=4.095, nll_loss=2.479, w2v_ctc_loss=1.419, task_loss=0.25, task_loss_gen=3.718, contrastive_loss=0, total=4193.12, n_correct=1436.21, ppl=5.57, accuracy=34.252, wps=14784.5, ups=1.18, wpb=12516.7, bsz=487.4, num_updates=4900, lr=0.000196002, gnorm=0.8, clip=0, loss_scale=8, train_wall=84, gb_free=13.3, wall=3705
2023-09-03 22:31:56 | INFO | train_inner | epoch 004:    582 / 1474 loss=2.624, trans_loss=4.084, nll_loss=2.464, w2v_ctc_loss=1.435, task_loss=0.479, task_loss_gen=3.806, contrastive_loss=0, total=4234.09, n_correct=1470.17, ppl=5.52, accuracy=34.722, wps=14707.6, ups=1.16, wpb=12638.3, bsz=495.1, num_updates=5000, lr=0.0002, gnorm=0.788, clip=0, loss_scale=8, train_wall=85, gb_free=16.3, wall=3791
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:0')
2023-09-03 22:33:23 | INFO | train_inner | epoch 004:    682 / 1474 loss=2.594, trans_loss=4.079, nll_loss=2.455, w2v_ctc_loss=1.394, task_loss=0.616, task_loss_gen=4.097, contrastive_loss=0, total=4195.52, n_correct=1469.51, ppl=5.48, accuracy=35.026, wps=14406.6, ups=1.15, wpb=12507.9, bsz=461.1, num_updates=5100, lr=0.00019803, gnorm=0.386, clip=0, loss_scale=16, train_wall=86, gb_free=13.3, wall=3878
2023-09-03 22:34:48 | INFO | train_inner | epoch 004:    782 / 1474 loss=2.598, trans_loss=4.066, nll_loss=2.443, w2v_ctc_loss=1.408, task_loss=0.369, task_loss_gen=4.322, contrastive_loss=0, total=4009.24, n_correct=1414.47, ppl=5.44, accuracy=35.28, wps=14100.3, ups=1.18, wpb=11973.6, bsz=415.7, num_updates=5200, lr=0.000196116, gnorm=0.392, clip=0, loss_scale=16, train_wall=84, gb_free=16.8, wall=3963
2023-09-03 22:36:13 | INFO | train_inner | epoch 004:    882 / 1474 loss=2.588, trans_loss=4.051, nll_loss=2.424, w2v_ctc_loss=1.406, task_loss=0.265, task_loss_gen=3.902, contrastive_loss=0, total=4191.91, n_correct=1496.62, ppl=5.37, accuracy=35.703, wps=14664.5, ups=1.17, wpb=12517.7, bsz=467.3, num_updates=5300, lr=0.000194257, gnorm=0.374, clip=0, loss_scale=16, train_wall=85, gb_free=14.6, wall=4048
2023-09-03 22:37:38 | INFO | train_inner | epoch 004:    982 / 1474 loss=2.568, trans_loss=4.044, nll_loss=2.415, w2v_ctc_loss=1.385, task_loss=0.363, task_loss_gen=5.098, contrastive_loss=0, total=4129.3, n_correct=1495.7, ppl=5.33, accuracy=36.222, wps=14452.4, ups=1.17, wpb=12332.9, bsz=458.1, num_updates=5400, lr=0.00019245, gnorm=0.376, clip=0, loss_scale=16, train_wall=85, gb_free=17.5, wall=4134
2023-09-03 22:39:04 | INFO | train_inner | epoch 004:   1082 / 1474 loss=2.574, trans_loss=4.045, nll_loss=2.415, w2v_ctc_loss=1.391, task_loss=0.37, task_loss_gen=4.456, contrastive_loss=0, total=4072.56, n_correct=1470.83, ppl=5.33, accuracy=36.116, wps=14236, ups=1.17, wpb=12155.9, bsz=436.5, num_updates=5500, lr=0.000190693, gnorm=0.374, clip=0, loss_scale=16, train_wall=85, gb_free=16, wall=4219
2023-09-03 22:40:29 | INFO | train_inner | epoch 004:   1182 / 1474 loss=2.554, trans_loss=4.031, nll_loss=2.399, w2v_ctc_loss=1.385, task_loss=0.182, task_loss_gen=4.4, contrastive_loss=0, total=4164, n_correct=1529.32, ppl=5.27, accuracy=36.727, wps=14653.2, ups=1.18, wpb=12440.4, bsz=483.3, num_updates=5600, lr=0.000188982, gnorm=0.366, clip=0, loss_scale=16, train_wall=84, gb_free=15.7, wall=4304
2023-09-03 22:41:53 | INFO | train_inner | epoch 004:   1282 / 1474 loss=2.538, trans_loss=4.019, nll_loss=2.383, w2v_ctc_loss=1.369, task_loss=0.154, task_loss_gen=4.882, contrastive_loss=0, total=4155.14, n_correct=1538.85, ppl=5.22, accuracy=37.035, wps=14637.9, ups=1.18, wpb=12409.1, bsz=472.5, num_updates=5700, lr=0.000187317, gnorm=0.366, clip=0, loss_scale=16, train_wall=84, gb_free=16.2, wall=4389
2023-09-03 22:43:17 | INFO | train_inner | epoch 004:   1382 / 1474 loss=2.533, trans_loss=4.013, nll_loss=2.375, w2v_ctc_loss=1.364, task_loss=0.14, task_loss_gen=5.763, contrastive_loss=0, total=4101.03, n_correct=1528.15, ppl=5.19, accuracy=37.263, wps=14636.3, ups=1.19, wpb=12248.2, bsz=438, num_updates=5800, lr=0.000185695, gnorm=0.373, clip=0, loss_scale=16, train_wall=83, gb_free=16.7, wall=4473
2023-09-03 22:44:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2941, device='cuda:7')
2023-09-03 22:45:11 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.164 | trans_loss 6.968 | nll_loss 4.771 | w2v_ctc_loss 1.512 | task_loss 0 | task_loss_gen 43.347 | contrastive_loss 0 | total 4003.4 | n_correct 1609.4 | ppl 27.3 | accuracy 40.201 | uer 22.722 | wer 24.417 | raw_wer 24.417 | bleu 1.5 | wps 1402.6 | wpb 4003.4 | bsz 141.8 | num_updates 5892 | best_bleu 1.5
2023-09-03 22:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5892 updates
2023-09-03 22:45:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 22:45:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 4 @ 5892 updates, score 1.5) (writing took 12.504220103961416 seconds)
2023-09-03 22:45:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-03 22:45:23 | INFO | train | epoch 004 | loss 2.594 | trans_loss 4.061 | nll_loss 2.435 | w2v_ctc_loss 1.411 | task_loss 0.287 | task_loss_gen 4.649 | contrastive_loss 0 | total 4138.65 | n_correct 1470.48 | ppl 5.41 | accuracy 35.53 | wps 13909 | ups 1.13 | wpb 12355.8 | bsz 458.5 | num_updates 5892 | lr 0.00018424 | gnorm 0.537 | clip 0 | loss_scale 16 | train_wall 1242 | gb_free 14.5 | wall 4599
2023-09-03 22:45:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 22:45:23 | INFO | fairseq.trainer | begin training epoch 5
2023-09-03 22:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 22:45:37 | INFO | train_inner | epoch 005:      8 / 1474 loss=2.512, trans_loss=4.003, nll_loss=2.36, w2v_ctc_loss=1.34, task_loss=0.152, task_loss_gen=6.26, contrastive_loss=0, total=4036.88, n_correct=1521.71, ppl=5.14, accuracy=37.695, wps=8616.1, ups=0.71, wpb=12051.7, bsz=437.2, num_updates=5900, lr=0.000184115, gnorm=0.373, clip=0, loss_scale=16, train_wall=83, gb_free=16.3, wall=4612
2023-09-03 22:47:01 | INFO | train_inner | epoch 005:    108 / 1474 loss=2.431, trans_loss=3.949, nll_loss=2.29, w2v_ctc_loss=1.26, task_loss=0.136, task_loss_gen=5.474, contrastive_loss=0, total=4241.19, n_correct=1671.39, ppl=4.89, accuracy=39.409, wps=14985.8, ups=1.18, wpb=12664.5, bsz=494.6, num_updates=6000, lr=0.000182574, gnorm=0.359, clip=0, loss_scale=16, train_wall=84, gb_free=16.8, wall=4697
2023-09-03 22:47:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 22:47:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.099 | trans_loss 6.879 | nll_loss 4.648 | w2v_ctc_loss 1.494 | task_loss 0.001 | task_loss_gen 30.009 | contrastive_loss 0 | total 4003.4 | n_correct 1661 | ppl 25.07 | accuracy 41.49 | uer 22.454 | wer 24.022 | raw_wer 24.022 | bleu 1.94 | wps 1385.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 1.94
2023-09-03 22:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-09-03 22:47:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_5_6000.pt
2023-09-03 22:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_5_6000.pt
2023-09-03 22:47:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 1.94) (writing took 13.299142508010846 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0006, -0.0013, -0.0003, -0.0012, -0.0004], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2764,  0.3735,  0.1503,  ...,  0.0093,  0.0144, -0.0467],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0965,  0.4951,  0.4143,  ...,  0.0792,  0.1527, -0.0974]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0006, -0.0013, -0.0003, -0.0012, -0.0004], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-03 22:49:15 | INFO | train_inner | epoch 005:    208 / 1474 loss=2.434, trans_loss=3.939, nll_loss=2.275, w2v_ctc_loss=1.283, task_loss=0.124, task_loss_gen=5.126, contrastive_loss=0, total=4184.8, n_correct=1673.07, ppl=4.84, accuracy=39.98, wps=9362.7, ups=0.75, wpb=12486.5, bsz=486.4, num_updates=6100, lr=0.000181071, gnorm=0.371, clip=0, loss_scale=16, train_wall=83, gb_free=16.3, wall=4830
2023-09-03 22:50:39 | INFO | train_inner | epoch 005:    308 / 1474 loss=2.433, trans_loss=3.915, nll_loss=2.247, w2v_ctc_loss=1.301, task_loss=0.154, task_loss_gen=5.77, contrastive_loss=0, total=4104.88, n_correct=1661.35, ppl=4.75, accuracy=40.473, wps=14529.4, ups=1.18, wpb=12271.4, bsz=449.2, num_updates=6200, lr=0.000179605, gnorm=0.377, clip=0, loss_scale=16, train_wall=84, gb_free=15.3, wall=4915
2023-09-03 22:52:04 | INFO | train_inner | epoch 005:    408 / 1474 loss=2.394, trans_loss=3.88, nll_loss=2.201, w2v_ctc_loss=1.274, task_loss=0.223, task_loss_gen=4.588, contrastive_loss=0, total=4146.85, n_correct=1736.77, ppl=4.6, accuracy=41.882, wps=14653.4, ups=1.18, wpb=12393.9, bsz=473.3, num_updates=6300, lr=0.000178174, gnorm=0.386, clip=0, loss_scale=16, train_wall=84, gb_free=15.7, wall=4999
2023-09-03 22:53:28 | INFO | train_inner | epoch 005:    508 / 1474 loss=2.395, trans_loss=3.864, nll_loss=2.177, w2v_ctc_loss=1.295, task_loss=0.208, task_loss_gen=5.571, contrastive_loss=0, total=4030.36, n_correct=1716.62, ppl=4.52, accuracy=42.592, wps=14309.5, ups=1.19, wpb=12039.6, bsz=417.1, num_updates=6400, lr=0.000176777, gnorm=0.391, clip=0, loss_scale=16, train_wall=83, gb_free=14.4, wall=5084
2023-09-03 22:54:53 | INFO | train_inner | epoch 005:    608 / 1474 loss=2.37, trans_loss=3.838, nll_loss=2.14, w2v_ctc_loss=1.288, task_loss=0.164, task_loss_gen=5.506, contrastive_loss=0, total=4110.02, n_correct=1813.72, ppl=4.41, accuracy=44.129, wps=14376.4, ups=1.17, wpb=12261.7, bsz=450.3, num_updates=6500, lr=0.000175412, gnorm=0.404, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=5169
2023-09-03 22:56:18 | INFO | train_inner | epoch 005:    708 / 1474 loss=2.344, trans_loss=3.799, nll_loss=2.09, w2v_ctc_loss=1.296, task_loss=0.177, task_loss_gen=4.786, contrastive_loss=0, total=4163.49, n_correct=1906.63, ppl=4.26, accuracy=45.794, wps=14669.5, ups=1.18, wpb=12427.8, bsz=479, num_updates=6600, lr=0.000174078, gnorm=0.402, clip=0, loss_scale=16, train_wall=84, gb_free=11.3, wall=5254
2023-09-03 22:57:44 | INFO | train_inner | epoch 005:    808 / 1474 loss=2.322, trans_loss=3.768, nll_loss=2.049, w2v_ctc_loss=1.287, task_loss=0.164, task_loss_gen=5.282, contrastive_loss=0, total=4130.46, n_correct=1940.26, ppl=4.14, accuracy=46.974, wps=14298.6, ups=1.16, wpb=12327.4, bsz=448, num_updates=6700, lr=0.000172774, gnorm=0.408, clip=0, loss_scale=16, train_wall=86, gb_free=12, wall=5340
2023-09-03 22:59:09 | INFO | train_inner | epoch 005:    908 / 1474 loss=2.297, trans_loss=3.738, nll_loss=2.013, w2v_ctc_loss=1.283, task_loss=0.248, task_loss_gen=4.817, contrastive_loss=0, total=4091.87, n_correct=1970.43, ppl=4.04, accuracy=48.155, wps=14474.1, ups=1.18, wpb=12217.7, bsz=444, num_updates=6800, lr=0.000171499, gnorm=0.413, clip=0, loss_scale=16, train_wall=84, gb_free=14.9, wall=5424
2023-09-03 23:00:32 | INFO | train_inner | epoch 005:   1008 / 1474 loss=2.284, trans_loss=3.718, nll_loss=1.986, w2v_ctc_loss=1.287, task_loss=0.191, task_loss_gen=4.714, contrastive_loss=0, total=4164.94, n_correct=2049.36, ppl=3.96, accuracy=49.205, wps=14842.8, ups=1.19, wpb=12434.2, bsz=465, num_updates=6900, lr=0.000170251, gnorm=0.408, clip=0, loss_scale=16, train_wall=83, gb_free=15.4, wall=5508
2023-09-03 23:01:58 | INFO | train_inner | epoch 005:   1108 / 1474 loss=2.276, trans_loss=3.696, nll_loss=1.957, w2v_ctc_loss=1.294, task_loss=0.177, task_loss_gen=4.763, contrastive_loss=0, total=4176.06, n_correct=2091.15, ppl=3.88, accuracy=50.075, wps=14512.7, ups=1.16, wpb=12460.6, bsz=465.6, num_updates=7000, lr=0.000169031, gnorm=0.41, clip=0, loss_scale=16, train_wall=85, gb_free=16.6, wall=5594
2023-09-03 23:03:24 | INFO | train_inner | epoch 005:   1208 / 1474 loss=2.254, trans_loss=3.682, nll_loss=1.937, w2v_ctc_loss=1.276, task_loss=0.154, task_loss_gen=5.245, contrastive_loss=0, total=4160.61, n_correct=2113.31, ppl=3.83, accuracy=50.793, wps=14473.4, ups=1.17, wpb=12406.9, bsz=449.4, num_updates=7100, lr=0.000167836, gnorm=0.414, clip=0, loss_scale=32, train_wall=85, gb_free=16.4, wall=5680
2023-09-03 23:04:49 | INFO | train_inner | epoch 005:   1308 / 1474 loss=2.233, trans_loss=3.66, nll_loss=1.912, w2v_ctc_loss=1.265, task_loss=0.196, task_loss_gen=4.906, contrastive_loss=0, total=4145.72, n_correct=2137.84, ppl=3.76, accuracy=51.567, wps=14488.5, ups=1.17, wpb=12374.5, bsz=450.8, num_updates=7200, lr=0.000166667, gnorm=0.411, clip=0, loss_scale=32, train_wall=85, gb_free=17.2, wall=5765
2023-09-03 23:06:14 | INFO | train_inner | epoch 005:   1408 / 1474 loss=2.224, trans_loss=3.652, nll_loss=1.904, w2v_ctc_loss=1.263, task_loss=0.182, task_loss_gen=4.986, contrastive_loss=0, total=4134.3, n_correct=2148.7, ppl=3.74, accuracy=51.973, wps=14666.8, ups=1.19, wpb=12348.1, bsz=458.6, num_updates=7300, lr=0.000165521, gnorm=0.413, clip=0, loss_scale=32, train_wall=83, gb_free=17.2, wall=5849
2023-09-03 23:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 23:06:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 23:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-03 23:06:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-03 23:06:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-03 23:07:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-03 23:07:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-03 23:07:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0009, -0.0021, -0.0003, -0.0016, -0.0005], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2212,  0.1206, -0.0509,  ...,  0.0037, -0.0343, -0.0068],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0282,  0.1117,  0.1206,  ...,  0.1031,  0.0772, -0.0671]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0009, -0.0021, -0.0003, -0.0016, -0.0005], device='cuda:4',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.5630e-04, -6.3944e-04, -1.4007e-05, -3.9339e-04, -1.0473e-04],
       device='cuda:5', dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1022, -0.0124,  0.1100,  ..., -0.0215, -0.0143,  0.0093],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0026, -0.0988, -0.0724,  ...,  0.0438,  0.0698, -0.0195]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.5630e-04, -6.3944e-04, -1.4007e-05, -3.9339e-04, -1.0473e-04],
       device='cuda:5', dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.9097e-04, -4.3845e-04, -1.9729e-05, -2.8515e-04, -1.0002e-04],
       device='cuda:3', dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1370,  0.0145,  0.1141,  ..., -0.0388, -0.0058, -0.0146],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0291, -0.1015, -0.0503,  ...,  0.0348,  0.0407, -0.0081]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.9097e-04, -4.3845e-04, -1.9729e-05, -2.8515e-04, -1.0002e-04],
       device='cuda:3', dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0003, -0.0010, -0.0004, -0.0009, -0.0004], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2568,  0.1520,  0.1316,  ..., -0.0157, -0.0263, -0.0282],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.2607, -0.1299,  ...,  0.0924,  0.0829, -0.0299]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0003, -0.0010, -0.0004, -0.0009, -0.0004], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.9635e-04, -6.2895e-04, -4.9293e-05, -4.3440e-04, -1.2887e-04],
       device='cuda:1', dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1350, -0.0668,  0.0301,  ..., -0.0241, -0.0254, -0.0027],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0013, -0.0611, -0.0500,  ...,  0.0591,  0.0254, -0.0157]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.9635e-04, -6.2895e-04, -4.9293e-05, -4.3440e-04, -1.2887e-04],
       device='cuda:1', dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0004, -0.0010, -0.0003, -0.0009, -0.0004], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1871,  0.0394,  0.0915,  ..., -0.0122, -0.0422, -0.0492],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0009, -0.2864, -0.3643,  ...,  0.1227,  0.1006, -0.0395]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0004, -0.0010, -0.0003, -0.0009, -0.0004], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0007, -0.0021, -0.0003, -0.0015, -0.0005], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.4648e-01, -9.7412e-02, -2.5818e-02,  ...,  4.2847e-02,
          8.8806e-03, -6.4026e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 3.5095e-04, -2.6758e-01, -4.8975e-01,  ...,  2.4487e-01,
          9.2529e-02, -1.1334e-01]], device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0007, -0.0021, -0.0003, -0.0015, -0.0005], device='cuda:2',
       dtype=torch.float16)
--------------------
2023-09-03 23:07:54 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.475 | trans_loss 7.292 | nll_loss 5.168 | w2v_ctc_loss 1.818 | task_loss 0.041 | task_loss_gen 17.878 | contrastive_loss 0 | total 4003.4 | n_correct 1436 | ppl 35.95 | accuracy 35.87 | uer 25.488 | wer 27.572 | raw_wer 27.572 | bleu 3.02 | wps 1096.7 | wpb 4003.4 | bsz 141.8 | num_updates 7359 | best_bleu 3.02
2023-09-03 23:07:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7359 updates
2023-09-03 23:07:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 23:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 23:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 5 @ 7359 updates, score 3.02) (writing took 12.968665397027507 seconds)
2023-09-03 23:08:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-03 23:08:07 | INFO | train | epoch 005 | loss 2.34 | trans_loss 3.796 | nll_loss 2.088 | w2v_ctc_loss 1.287 | task_loss 0.176 | task_loss_gen 5.115 | contrastive_loss 0 | total 4138.74 | n_correct 1897.38 | ppl 4.25 | accuracy 45.844 | wps 13291.8 | ups 1.08 | wpb 12356.2 | bsz 458.6 | num_updates 7359 | lr 0.000164856 | gnorm 0.519 | clip 0.3 | loss_scale 0.25 | train_wall 1238 | gb_free 15.9 | wall 5962
2023-09-03 23:08:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 23:08:07 | INFO | fairseq.trainer | begin training epoch 6
2023-09-03 23:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 23:08:49 | INFO | train_inner | epoch 006:     41 / 1474 loss=2.632, trans_loss=3.958, nll_loss=2.299, w2v_ctc_loss=1.563, task_loss=0.407, task_loss_gen=3.902, contrastive_loss=0, total=4110.54, n_correct=1640.35, ppl=4.92, accuracy=39.906, wps=7891.2, ups=0.64, wpb=12265.6, bsz=447.2, num_updates=7400, lr=0.000164399, gnorm=8.247, clip=21, loss_scale=0.25, train_wall=90, gb_free=15.8, wall=6005
2023-09-03 23:09:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-03 23:10:14 | INFO | train_inner | epoch 006:    142 / 1474 loss=2.849, trans_loss=4.081, nll_loss=2.459, w2v_ctc_loss=1.769, task_loss=1.076, task_loss_gen=1.429, contrastive_loss=0, total=4166.34, n_correct=1430.84, ppl=5.5, accuracy=34.343, wps=14587.5, ups=1.17, wpb=12446.2, bsz=457.5, num_updates=7500, lr=0.000163299, gnorm=15.543, clip=48, loss_scale=0.125, train_wall=85, gb_free=9.9, wall=6090
2023-09-03 23:11:39 | INFO | train_inner | epoch 006:    242 / 1474 loss=2.812, trans_loss=4.035, nll_loss=2.401, w2v_ctc_loss=1.766, task_loss=0.993, task_loss_gen=1.344, contrastive_loss=0, total=4127, n_correct=1495.45, ppl=5.28, accuracy=36.236, wps=14529.1, ups=1.18, wpb=12325.9, bsz=451, num_updates=7600, lr=0.000162221, gnorm=12.644, clip=22, loss_scale=0.125, train_wall=84, gb_free=16.6, wall=6175
2023-09-03 23:13:06 | INFO | train_inner | epoch 006:    342 / 1474 loss=2.66, trans_loss=3.966, nll_loss=2.312, w2v_ctc_loss=1.602, task_loss=0.7, task_loss_gen=1.198, contrastive_loss=0, total=4151.56, n_correct=1609.81, ppl=4.97, accuracy=38.776, wps=14268.7, ups=1.15, wpb=12396.9, bsz=479.6, num_updates=7700, lr=0.000161165, gnorm=7.608, clip=8, loss_scale=0.125, train_wall=86, gb_free=16.2, wall=6262
2023-09-03 23:14:30 | INFO | train_inner | epoch 006:    442 / 1474 loss=2.756, trans_loss=3.998, nll_loss=2.352, w2v_ctc_loss=1.721, task_loss=0.588, task_loss_gen=1.313, contrastive_loss=0, total=4163.13, n_correct=1585.37, ppl=5.1, accuracy=38.081, wps=14856.6, ups=1.2, wpb=12431, bsz=469.5, num_updates=7800, lr=0.000160128, gnorm=5.789, clip=9, loss_scale=0.125, train_wall=83, gb_free=16.5, wall=6345
2023-09-03 23:15:54 | INFO | train_inner | epoch 006:    542 / 1474 loss=2.773, trans_loss=4.07, nll_loss=2.442, w2v_ctc_loss=1.676, task_loss=0.706, task_loss_gen=1.369, contrastive_loss=0, total=4157.56, n_correct=1490.37, ppl=5.43, accuracy=35.847, wps=14777.8, ups=1.19, wpb=12410.3, bsz=453.4, num_updates=7900, lr=0.000159111, gnorm=10.98, clip=15, loss_scale=0.125, train_wall=83, gb_free=12.2, wall=6429
2023-09-03 23:17:18 | INFO | train_inner | epoch 006:    642 / 1474 loss=2.794, trans_loss=4.061, nll_loss=2.43, w2v_ctc_loss=1.723, task_loss=0.594, task_loss_gen=1.302, contrastive_loss=0, total=4156.54, n_correct=1506.13, ppl=5.39, accuracy=36.235, wps=14765.7, ups=1.19, wpb=12409.1, bsz=473.4, num_updates=8000, lr=0.000158114, gnorm=10.444, clip=9, loss_scale=0.125, train_wall=83, gb_free=12.9, wall=6513
2023-09-03 23:17:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 23:17:58 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.205 | trans_loss 6.859 | nll_loss 4.608 | w2v_ctc_loss 1.895 | task_loss 2.844 | task_loss_gen 5.558 | contrastive_loss 0 | total 4003.4 | n_correct 1667.1 | ppl 24.38 | accuracy 41.642 | uer 26.491 | wer 28.261 | raw_wer 28.261 | bleu 3.16 | wps 1216.4 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 3.16
2023-09-03 23:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-09-03 23:17:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_6_8000.pt
2023-09-03 23:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_6_8000.pt
2023-09-03 23:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 3.16) (writing took 14.098227837996092 seconds)
2023-09-03 23:19:37 | INFO | train_inner | epoch 006:    742 / 1474 loss=2.856, trans_loss=4.092, nll_loss=2.474, w2v_ctc_loss=1.788, task_loss=0.618, task_loss_gen=1.424, contrastive_loss=0, total=4144.04, n_correct=1450.14, ppl=5.55, accuracy=34.993, wps=8866.5, ups=0.72, wpb=12371, bsz=455.4, num_updates=8100, lr=0.000157135, gnorm=10.606, clip=21, loss_scale=0.125, train_wall=84, gb_free=15.9, wall=6653
2023-09-03 23:21:02 | INFO | train_inner | epoch 006:    842 / 1474 loss=2.773, trans_loss=4.093, nll_loss=2.471, w2v_ctc_loss=1.659, task_loss=0.691, task_loss_gen=1.374, contrastive_loss=0, total=4128.68, n_correct=1450.65, ppl=5.54, accuracy=35.136, wps=14523.2, ups=1.18, wpb=12323.5, bsz=444.8, num_updates=8200, lr=0.000156174, gnorm=7.965, clip=13, loss_scale=0.125, train_wall=84, gb_free=16.9, wall=6738
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 361 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12101
2023-09-03 23:22:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-03 23:22:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-03 23:22:37 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 23:22:37 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-03 23:22:41 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12101', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-03 23:22:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-03 23:22:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-03 23:22:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-03 23:22:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-09-03 23:22:41 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 23:22:45 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-03 23:22:45 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-03 23:22:45 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-03 23:22:47 | INFO | root | load pretrained hubert
2023-09-03 23:22:54 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 23:22:58 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 23:23:06 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 23:23:06 | INFO | root | share the sematic adapter and textual encoder
2023-09-03 23:23:06 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-03 23:23:06 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-03 23:23:06 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-03 23:23:06 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-03 23:23:06 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-03 23:23:06 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-03 23:23:06 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 23:23:06 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 23:23:06 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 23:23:06 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 23:23:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-03 23:23:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-03 23:23:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-03 23:23:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 23:23:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 23:23:21 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-03 23:23:21 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-03 23:23:21 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_last.pt
2023-09-03 23:23:23 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2941)
mt_weight tensor(1.)
2023-09-03 23:23:41 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-03 23:23:43 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_last.pt (epoch 6 @ 8000 updates)
2023-09-03 23:23:43 | INFO | fairseq.trainer | loading train data for epoch 6
2023-09-03 23:23:43 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 23:23:43 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 23:23:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 23:23:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 23:23:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
asr_weight tensor(0.2941)
mt_weight tensor(1.)
2023-09-03 23:24:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 23:24:29 | INFO | fairseq.trainer | begin training epoch 6
2023-09-03 23:24:29 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2941)
mt_weight tensor(1.)
2023-09-03 23:26:05 | INFO | train_inner | epoch 006:    742 / 1474 loss=2.832, trans_loss=4.169, nll_loss=2.571, w2v_ctc_loss=1.669, task_loss=0.637, task_loss_gen=1.386, contrastive_loss=0, total=4144.04, n_correct=1349.46, ppl=5.94, accuracy=32.564, wps=6776.7, ups=0.55, wpb=12371, bsz=455.4, num_updates=8100, lr=0.000157135, gnorm=6.84, clip=15, loss_scale=0.125, train_wall=88, gb_free=15.9, wall=0
2023-09-03 23:26:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2023-09-03 23:27:32 | INFO | train_inner | epoch 006:    843 / 1474 loss=2.876, trans_loss=4.192, nll_loss=2.6, w2v_ctc_loss=1.72, task_loss=0.719, task_loss_gen=1.346, contrastive_loss=0, total=4128.1, n_correct=1307.78, ppl=6.06, accuracy=31.68, wps=14244.3, ups=1.16, wpb=12321.1, bsz=444.5, num_updates=8200, lr=0.000156174, gnorm=16.446, clip=66, loss_scale=0.0625, train_wall=86, gb_free=16.6, wall=0
2023-09-03 23:28:59 | INFO | train_inner | epoch 006:    943 / 1474 loss=2.787, trans_loss=4.123, nll_loss=2.51, w2v_ctc_loss=1.657, task_loss=0.806, task_loss_gen=1.355, contrastive_loss=0, total=4058.38, n_correct=1377.38, ppl=5.7, accuracy=33.939, wps=13862.1, ups=1.14, wpb=12116.2, bsz=434.9, num_updates=8300, lr=0.00015523, gnorm=15.057, clip=63, loss_scale=0.0625, train_wall=87, gb_free=16.3, wall=0
2023-09-03 23:30:24 | INFO | train_inner | epoch 006:   1043 / 1474 loss=2.645, trans_loss=4.083, nll_loss=2.457, w2v_ctc_loss=1.481, task_loss=0.683, task_loss_gen=1.146, contrastive_loss=0, total=4193.13, n_correct=1477.75, ppl=5.49, accuracy=35.242, wps=14729.6, ups=1.18, wpb=12514, bsz=483.7, num_updates=8400, lr=0.000154303, gnorm=11.719, clip=58, loss_scale=0.0625, train_wall=84, gb_free=16.5, wall=0
2023-09-03 23:31:49 | INFO | train_inner | epoch 006:   1143 / 1474 loss=2.64, trans_loss=4.075, nll_loss=2.447, w2v_ctc_loss=1.479, task_loss=0.786, task_loss_gen=1.336, contrastive_loss=0, total=4068.27, n_correct=1453.41, ppl=5.45, accuracy=35.726, wps=14206.9, ups=1.17, wpb=12145.6, bsz=435.3, num_updates=8500, lr=0.000153393, gnorm=13.24, clip=64, loss_scale=0.0625, train_wall=85, gb_free=17.5, wall=0
2023-09-03 23:33:16 | INFO | train_inner | epoch 006:   1243 / 1474 loss=2.536, trans_loss=4, nll_loss=2.353, w2v_ctc_loss=1.395, task_loss=0.775, task_loss_gen=1.224, contrastive_loss=0, total=4127.13, n_correct=1582.25, ppl=5.11, accuracy=38.338, wps=14311, ups=1.16, wpb=12327.8, bsz=460.7, num_updates=8600, lr=0.000152499, gnorm=11.814, clip=61, loss_scale=0.0625, train_wall=85, gb_free=11.5, wall=0
2023-09-03 23:34:40 | INFO | train_inner | epoch 006:   1343 / 1474 loss=2.577, trans_loss=4.003, nll_loss=2.353, w2v_ctc_loss=1.457, task_loss=0.698, task_loss_gen=1.203, contrastive_loss=0, total=4126.68, n_correct=1586.34, ppl=5.11, accuracy=38.441, wps=14590.5, ups=1.18, wpb=12312.8, bsz=456, num_updates=8700, lr=0.00015162, gnorm=10.021, clip=41, loss_scale=0.0625, train_wall=83, gb_free=16.2, wall=0
2023-09-03 23:36:06 | INFO | train_inner | epoch 006:   1443 / 1474 loss=2.514, trans_loss=3.964, nll_loss=2.304, w2v_ctc_loss=1.4, task_loss=0.718, task_loss_gen=1.192, contrastive_loss=0, total=4205.75, n_correct=1681.12, ppl=4.94, accuracy=39.972, wps=14606.6, ups=1.16, wpb=12553.6, bsz=466.8, num_updates=8800, lr=0.000150756, gnorm=10.399, clip=50, loss_scale=0.0625, train_wall=85, gb_free=17.1, wall=0
2023-09-03 23:36:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-03 23:37:14 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.211 | trans_loss 6.95 | nll_loss 4.714 | w2v_ctc_loss 1.708 | task_loss 3.42 | task_loss_gen 4.976 | contrastive_loss 0 | total 4003.4 | n_correct 1670.1 | ppl 26.25 | accuracy 41.717 | uer 24.495 | wer 26.427 | raw_wer 26.427 | bleu 4.2 | wps 1134.2 | wpb 4003.4 | bsz 141.8 | num_updates 8831 | best_bleu 4.2
2023-09-03 23:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8831 updates
2023-09-03 23:37:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 23:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-03 23:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 6 @ 8831 updates, score 4.2) (writing took 13.023760901996866 seconds)
2023-09-03 23:37:27 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-03 23:37:27 | INFO | train | epoch 006 | loss 2.719 | trans_loss 4.059 | nll_loss 2.428 | w2v_ctc_loss 1.61 | task_loss 0.746 | task_loss_gen 1.317 | contrastive_loss 0 | total 4138.85 | n_correct 1493.06 | ppl 5.38 | accuracy 36.074 | wps 12849.6 | ups 1.04 | wpb 12356.4 | bsz 458.6 | num_updates 8831 | lr 0.000150491 | gnorm 11.443 | clip 38.5 | loss_scale 0.0625 | train_wall 1248 | gb_free 14.8 | wall 0
2023-09-03 23:37:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 23:37:27 | INFO | fairseq.trainer | begin training epoch 7
2023-09-03 23:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 23:38:34 | INFO | train_inner | epoch 007:     69 / 1474 loss=2.512, trans_loss=3.963, nll_loss=2.302, w2v_ctc_loss=1.397, task_loss=0.671, task_loss_gen=1.237, contrastive_loss=0, total=4101.25, n_correct=1636.27, ppl=4.93, accuracy=39.897, wps=8288.2, ups=0.68, wpb=12241.4, bsz=459.1, num_updates=8900, lr=0.000149906, gnorm=9.68, clip=45, loss_scale=0.0625, train_wall=85, gb_free=14.5, wall=0
2023-09-03 23:39:59 | INFO | train_inner | epoch 007:    169 / 1474 loss=2.487, trans_loss=3.954, nll_loss=2.29, w2v_ctc_loss=1.369, task_loss=0.694, task_loss_gen=1.209, contrastive_loss=0, total=4131.3, n_correct=1655.86, ppl=4.89, accuracy=40.081, wps=14516.1, ups=1.18, wpb=12335.3, bsz=467.4, num_updates=9000, lr=0.000149071, gnorm=11.222, clip=56, loss_scale=0.0625, train_wall=84, gb_free=15.7, wall=0
2023-09-03 23:41:23 | INFO | train_inner | epoch 007:    269 / 1474 loss=2.438, trans_loss=3.899, nll_loss=2.216, w2v_ctc_loss=1.352, task_loss=0.737, task_loss_gen=1.244, contrastive_loss=0, total=4128.64, n_correct=1751.51, ppl=4.65, accuracy=42.423, wps=14524.5, ups=1.18, wpb=12320.5, bsz=449.9, num_updates=9100, lr=0.00014825, gnorm=11.114, clip=55, loss_scale=0.0625, train_wall=84, gb_free=15, wall=0
2023-09-03 23:42:49 | INFO | train_inner | epoch 007:    369 / 1474 loss=2.411, trans_loss=3.871, nll_loss=2.18, w2v_ctc_loss=1.341, task_loss=0.726, task_loss_gen=1.212, contrastive_loss=0, total=4160.1, n_correct=1811.43, ppl=4.53, accuracy=43.543, wps=14532.3, ups=1.17, wpb=12416.3, bsz=466.9, num_updates=9200, lr=0.000147442, gnorm=11.742, clip=58, loss_scale=0.0625, train_wall=85, gb_free=17.3, wall=0
2023-09-03 23:44:15 | INFO | train_inner | epoch 007:    469 / 1474 loss=2.394, trans_loss=3.853, nll_loss=2.159, w2v_ctc_loss=1.334, task_loss=0.715, task_loss_gen=1.161, contrastive_loss=0, total=4175.91, n_correct=1849.47, ppl=4.47, accuracy=44.289, wps=14476.1, ups=1.16, wpb=12469.7, bsz=468.6, num_updates=9300, lr=0.000146647, gnorm=11.222, clip=57, loss_scale=0.0625, train_wall=85, gb_free=17.5, wall=0
2023-09-03 23:45:40 | INFO | train_inner | epoch 007:    569 / 1474 loss=2.373, trans_loss=3.831, nll_loss=2.129, w2v_ctc_loss=1.325, task_loss=0.735, task_loss_gen=1.194, contrastive_loss=0, total=4159.23, n_correct=1894.78, ppl=4.37, accuracy=45.556, wps=14677.8, ups=1.18, wpb=12410.4, bsz=455.6, num_updates=9400, lr=0.000145865, gnorm=12.005, clip=63, loss_scale=0.0625, train_wall=84, gb_free=11.9, wall=0
2023-09-03 23:47:05 | INFO | train_inner | epoch 007:    669 / 1474 loss=2.351, trans_loss=3.81, nll_loss=2.103, w2v_ctc_loss=1.315, task_loss=0.763, task_loss_gen=1.18, contrastive_loss=0, total=4175.4, n_correct=1933.48, ppl=4.29, accuracy=46.306, wps=14580.5, ups=1.17, wpb=12460.9, bsz=462.2, num_updates=9500, lr=0.000145095, gnorm=10.41, clip=45, loss_scale=0.0625, train_wall=85, gb_free=16.3, wall=0
2023-09-03 23:48:30 | INFO | train_inner | epoch 007:    769 / 1474 loss=2.339, trans_loss=3.783, nll_loss=2.069, w2v_ctc_loss=1.315, task_loss=0.793, task_loss_gen=1.258, contrastive_loss=0, total=4111.11, n_correct=1933.16, ppl=4.2, accuracy=47.023, wps=14356.6, ups=1.17, wpb=12276.3, bsz=445.6, num_updates=9600, lr=0.000144338, gnorm=12.279, clip=61, loss_scale=0.0625, train_wall=85, gb_free=15.9, wall=0
2023-09-03 23:49:55 | INFO | train_inner | epoch 007:    869 / 1474 loss=2.331, trans_loss=3.78, nll_loss=2.061, w2v_ctc_loss=1.314, task_loss=0.758, task_loss_gen=1.195, contrastive_loss=0, total=4140.21, n_correct=1967.58, ppl=4.17, accuracy=47.524, wps=14545.8, ups=1.18, wpb=12350.1, bsz=457.9, num_updates=9700, lr=0.000143592, gnorm=9.946, clip=45, loss_scale=0.0625, train_wall=84, gb_free=15.9, wall=0
2023-09-03 23:51:23 | INFO | train_inner | epoch 007:    969 / 1474 loss=2.32, trans_loss=3.768, nll_loss=2.051, w2v_ctc_loss=1.307, task_loss=0.724, task_loss_gen=1.167, contrastive_loss=0, total=4138.92, n_correct=1982.55, ppl=4.14, accuracy=47.9, wps=14153.1, ups=1.15, wpb=12360.4, bsz=471.4, num_updates=9800, lr=0.000142857, gnorm=10.565, clip=58, loss_scale=0.0625, train_wall=87, gb_free=17.4, wall=0
2023-09-03 23:52:48 | INFO | train_inner | epoch 007:   1069 / 1474 loss=2.314, trans_loss=3.757, nll_loss=2.035, w2v_ctc_loss=1.312, task_loss=0.777, task_loss_gen=1.25, contrastive_loss=0, total=4117.61, n_correct=1998.7, ppl=4.1, accuracy=48.54, wps=14472.7, ups=1.18, wpb=12292.4, bsz=442.7, num_updates=9900, lr=0.000142134, gnorm=10.441, clip=46, loss_scale=0.0625, train_wall=84, gb_free=15.7, wall=0
2023-09-03 23:54:12 | INFO | train_inner | epoch 007:   1169 / 1474 loss=2.299, trans_loss=3.735, nll_loss=2.01, w2v_ctc_loss=1.308, task_loss=0.734, task_loss_gen=1.169, contrastive_loss=0, total=4122.78, n_correct=2020.83, ppl=4.03, accuracy=49.016, wps=14532.4, ups=1.18, wpb=12317, bsz=464.6, num_updates=10000, lr=0.000141421, gnorm=10.212, clip=48, loss_scale=0.0625, train_wall=84, gb_free=14.4, wall=0
2023-09-03 23:54:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 23:54:54 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.545 | trans_loss 6.042 | nll_loss 3.526 | w2v_ctc_loss 1.535 | task_loss 3.43 | task_loss_gen 4.844 | contrastive_loss 0 | total 4003.4 | n_correct 2126.1 | ppl 11.52 | accuracy 53.107 | uer 22.661 | wer 24.604 | raw_wer 24.604 | bleu 11.67 | wps 1210.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 11.67
2023-09-03 23:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-09-03 23:54:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_7_10000.pt
2023-09-03 23:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_7_10000.pt
2023-09-03 23:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 11.67) (writing took 14.131057404971216 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-03 23:56:33 | INFO | train_inner | epoch 007:   1269 / 1474 loss=2.278, trans_loss=3.719, nll_loss=1.989, w2v_ctc_loss=1.291, task_loss=0.792, task_loss_gen=1.199, contrastive_loss=0, total=4127.57, n_correct=2050.61, ppl=3.97, accuracy=49.681, wps=8791.2, ups=0.71, wpb=12328.1, bsz=450.9, num_updates=10100, lr=0.00014072, gnorm=10.106, clip=48, loss_scale=0.0625, train_wall=84, gb_free=16.1, wall=0
2023-09-03 23:57:59 | INFO | train_inner | epoch 007:   1369 / 1474 loss=2.254, trans_loss=3.686, nll_loss=1.945, w2v_ctc_loss=1.288, task_loss=0.724, task_loss_gen=1.112, contrastive_loss=0, total=4175.42, n_correct=2133.63, ppl=3.85, accuracy=51.1, wps=14510.5, ups=1.16, wpb=12465.2, bsz=475.8, num_updates=10200, lr=0.000140028, gnorm=6.733, clip=16, loss_scale=0.125, train_wall=85, gb_free=16.1, wall=0
2023-09-03 23:59:25 | INFO | train_inner | epoch 007:   1469 / 1474 loss=2.224, trans_loss=3.659, nll_loss=1.914, w2v_ctc_loss=1.265, task_loss=0.798, task_loss_gen=1.254, contrastive_loss=0, total=4129.23, n_correct=2150.2, ppl=3.77, accuracy=52.073, wps=14303.5, ups=1.16, wpb=12337.1, bsz=450.9, num_updates=10300, lr=0.000139347, gnorm=5.032, clip=5, loss_scale=0.125, train_wall=86, gb_free=16.1, wall=0
2023-09-03 23:59:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
2023-09-04 00:00:09 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.806 | nll_loss 3.232 | w2v_ctc_loss 1.496 | task_loss 3.515 | task_loss_gen 4.825 | contrastive_loss 0 | total 4003.4 | n_correct 2278.4 | ppl 9.39 | accuracy 56.912 | uer 21.949 | wer 23.84 | raw_wer 23.84 | bleu 14.49 | wps 1203.4 | wpb 4003.4 | bsz 141.8 | num_updates 10305 | best_bleu 14.49
2023-09-04 00:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10305 updates
2023-09-04 00:00:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 7 @ 10305 updates, score 14.49) (writing took 11.711620368005242 seconds)
2023-09-04 00:00:21 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-04 00:00:21 | INFO | train | epoch 007 | loss 2.351 | trans_loss 3.8 | nll_loss 2.091 | w2v_ctc_loss 1.32 | task_loss 0.745 | task_loss_gen 1.203 | contrastive_loss 0 | total 4138.65 | n_correct 1924.5 | ppl 4.26 | accuracy 46.501 | wps 13256.1 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 10305 | lr 0.000139313 | gnorm 10.131 | clip 46.4 | loss_scale 0.125 | train_wall 1248 | gb_free 12.8 | wall 0
2023-09-04 00:00:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 00:00:21 | INFO | fairseq.trainer | begin training epoch 8
2023-09-04 00:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 00:01:49 | INFO | train_inner | epoch 008:     95 / 1474 loss=2.214, trans_loss=3.662, nll_loss=1.912, w2v_ctc_loss=1.247, task_loss=0.84, task_loss_gen=1.305, contrastive_loss=0, total=4102.05, n_correct=2135.45, ppl=3.76, accuracy=52.058, wps=8512.8, ups=0.7, wpb=12230.8, bsz=437.8, num_updates=10400, lr=0.000138675, gnorm=5.796, clip=4, loss_scale=0.125, train_wall=84, gb_free=16.4, wall=0
2023-09-04 00:03:13 | INFO | train_inner | epoch 008:    195 / 1474 loss=2.191, trans_loss=3.63, nll_loss=1.872, w2v_ctc_loss=1.233, task_loss=0.862, task_loss_gen=1.306, contrastive_loss=0, total=4014.31, n_correct=2133.3, ppl=3.66, accuracy=53.142, wps=14118, ups=1.18, wpb=11972.1, bsz=423.9, num_updates=10500, lr=0.000138013, gnorm=5.055, clip=5, loss_scale=0.125, train_wall=84, gb_free=17, wall=0
2023-09-04 00:04:38 | INFO | train_inner | epoch 008:    295 / 1474 loss=2.162, trans_loss=3.605, nll_loss=1.842, w2v_ctc_loss=1.221, task_loss=0.761, task_loss_gen=1.104, contrastive_loss=0, total=4215.99, n_correct=2283.6, ppl=3.59, accuracy=54.165, wps=14892.2, ups=1.18, wpb=12584.3, bsz=489.3, num_updates=10600, lr=0.000137361, gnorm=5.125, clip=3, loss_scale=0.125, train_wall=84, gb_free=16.7, wall=0
2023-09-04 00:06:04 | INFO | train_inner | epoch 008:    395 / 1474 loss=2.167, trans_loss=3.61, nll_loss=1.846, w2v_ctc_loss=1.224, task_loss=0.84, task_loss_gen=1.221, contrastive_loss=0, total=4145.49, n_correct=2237.01, ppl=3.59, accuracy=53.962, wps=14297.6, ups=1.16, wpb=12366.7, bsz=448.9, num_updates=10700, lr=0.000136717, gnorm=4.595, clip=0, loss_scale=0.125, train_wall=86, gb_free=16.7, wall=0
2023-09-04 00:07:30 | INFO | train_inner | epoch 008:    495 / 1474 loss=2.145, trans_loss=3.601, nll_loss=1.838, w2v_ctc_loss=1.202, task_loss=0.745, task_loss_gen=1.078, contrastive_loss=0, total=4186.4, n_correct=2270.63, ppl=3.58, accuracy=54.238, wps=14546.6, ups=1.16, wpb=12500.9, bsz=496.6, num_updates=10800, lr=0.000136083, gnorm=4.995, clip=2, loss_scale=0.125, train_wall=85, gb_free=15.3, wall=0
2023-09-04 00:08:56 | INFO | train_inner | epoch 008:    595 / 1474 loss=2.153, trans_loss=3.586, nll_loss=1.821, w2v_ctc_loss=1.222, task_loss=0.898, task_loss_gen=1.269, contrastive_loss=0, total=4078.2, n_correct=2229.72, ppl=3.53, accuracy=54.674, wps=14145.7, ups=1.16, wpb=12190.9, bsz=435.4, num_updates=10900, lr=0.000135457, gnorm=4.582, clip=2, loss_scale=0.125, train_wall=85, gb_free=16, wall=0
2023-09-04 00:10:22 | INFO | train_inner | epoch 008:    695 / 1474 loss=2.15, trans_loss=3.58, nll_loss=1.809, w2v_ctc_loss=1.225, task_loss=0.862, task_loss_gen=1.242, contrastive_loss=0, total=4140.97, n_correct=2287.34, ppl=3.51, accuracy=55.237, wps=14506, ups=1.17, wpb=12359.2, bsz=444.8, num_updates=11000, lr=0.00013484, gnorm=4.897, clip=3, loss_scale=0.125, train_wall=84, gb_free=15.9, wall=0
2023-09-04 00:11:46 | INFO | train_inner | epoch 008:    795 / 1474 loss=2.124, trans_loss=3.564, nll_loss=1.794, w2v_ctc_loss=1.199, task_loss=0.836, task_loss_gen=1.192, contrastive_loss=0, total=4115.38, n_correct=2282.39, ppl=3.47, accuracy=55.46, wps=14564.5, ups=1.18, wpb=12302.2, bsz=450.6, num_updates=11100, lr=0.000134231, gnorm=4.285, clip=0, loss_scale=0.125, train_wall=84, gb_free=16, wall=0
2023-09-04 00:13:11 | INFO | train_inner | epoch 008:    895 / 1474 loss=2.118, trans_loss=3.571, nll_loss=1.8, w2v_ctc_loss=1.19, task_loss=0.796, task_loss_gen=1.132, contrastive_loss=0, total=4176.16, n_correct=2319.5, ppl=3.48, accuracy=55.541, wps=14671.4, ups=1.18, wpb=12467.5, bsz=475.6, num_updates=11200, lr=0.000133631, gnorm=4.774, clip=2, loss_scale=0.125, train_wall=84, gb_free=15.7, wall=0
2023-09-04 00:14:35 | INFO | train_inner | epoch 008:    995 / 1474 loss=2.103, trans_loss=3.552, nll_loss=1.777, w2v_ctc_loss=1.184, task_loss=0.799, task_loss_gen=1.13, contrastive_loss=0, total=4163.46, n_correct=2344.46, ppl=3.43, accuracy=56.31, wps=14750.6, ups=1.19, wpb=12433.7, bsz=467.3, num_updates=11300, lr=0.000133038, gnorm=3.806, clip=0, loss_scale=0.125, train_wall=84, gb_free=15.1, wall=0
2023-09-04 00:16:02 | INFO | train_inner | epoch 008:   1095 / 1474 loss=2.11, trans_loss=3.556, nll_loss=1.78, w2v_ctc_loss=1.187, task_loss=0.871, task_loss_gen=1.22, contrastive_loss=0, total=4174.3, n_correct=2341.26, ppl=3.43, accuracy=56.087, wps=14453.9, ups=1.16, wpb=12460.5, bsz=457.5, num_updates=11400, lr=0.000132453, gnorm=4.834, clip=5, loss_scale=0.125, train_wall=85, gb_free=15.3, wall=0
2023-09-04 00:17:26 | INFO | train_inner | epoch 008:   1195 / 1474 loss=2.101, trans_loss=3.543, nll_loss=1.766, w2v_ctc_loss=1.19, task_loss=0.801, task_loss_gen=1.117, contrastive_loss=0, total=4173.58, n_correct=2359.55, ppl=3.4, accuracy=56.535, wps=14782.2, ups=1.19, wpb=12464.7, bsz=470.9, num_updates=11500, lr=0.000131876, gnorm=3.818, clip=0, loss_scale=0.125, train_wall=84, gb_free=15.9, wall=0
2023-09-04 00:18:50 | INFO | train_inner | epoch 008:   1295 / 1474 loss=2.092, trans_loss=3.535, nll_loss=1.756, w2v_ctc_loss=1.18, task_loss=0.887, task_loss_gen=1.201, contrastive_loss=0, total=4089.6, n_correct=2321.16, ppl=3.38, accuracy=56.758, wps=14491.5, ups=1.19, wpb=12215.6, bsz=445.6, num_updates=11600, lr=0.000131306, gnorm=4.412, clip=1, loss_scale=0.125, train_wall=84, gb_free=15.4, wall=0
2023-09-04 00:20:15 | INFO | train_inner | epoch 008:   1395 / 1474 loss=2.093, trans_loss=3.54, nll_loss=1.761, w2v_ctc_loss=1.181, task_loss=0.844, task_loss_gen=1.163, contrastive_loss=0, total=4150.55, n_correct=2359.3, ppl=3.39, accuracy=56.843, wps=14703.9, ups=1.19, wpb=12394.6, bsz=466.1, num_updates=11700, lr=0.000130744, gnorm=3.867, clip=1, loss_scale=0.125, train_wall=84, gb_free=12.1, wall=0
2023-09-04 00:21:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 00:21:55 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.114 | trans_loss 5.468 | nll_loss 2.819 | w2v_ctc_loss 1.391 | task_loss 3.427 | task_loss_gen 4.776 | contrastive_loss 0 | total 4003.4 | n_correct 2469.8 | ppl 7.06 | accuracy 61.693 | uer 20.176 | wer 21.964 | raw_wer 21.964 | bleu 17.93 | wps 1545.8 | wpb 4003.4 | bsz 141.8 | num_updates 11779 | best_bleu 17.93
2023-09-04 00:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11779 updates
2023-09-04 00:21:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 8 @ 11779 updates, score 17.93) (writing took 11.844236923963763 seconds)
2023-09-04 00:22:07 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-04 00:22:07 | INFO | train | epoch 008 | loss 2.133 | trans_loss 3.578 | nll_loss 1.809 | w2v_ctc_loss 1.203 | task_loss 0.831 | task_loss_gen 1.186 | contrastive_loss 0 | total 4138.65 | n_correct 2284.57 | ppl 3.5 | accuracy 55.201 | wps 13943.1 | ups 1.13 | wpb 12355.8 | bsz 458.5 | num_updates 11779 | lr 0.000130305 | gnorm 4.56 | clip 1.9 | loss_scale 0.125 | train_wall 1242 | gb_free 16.6 | wall 0
2023-09-04 00:22:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 00:22:07 | INFO | fairseq.trainer | begin training epoch 9
2023-09-04 00:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 00:22:32 | INFO | train_inner | epoch 009:     21 / 1474 loss=2.062, trans_loss=3.522, nll_loss=1.738, w2v_ctc_loss=1.146, task_loss=0.852, task_loss_gen=1.16, contrastive_loss=0, total=4110.01, n_correct=2358.53, ppl=3.34, accuracy=57.385, wps=8911.9, ups=0.73, wpb=12266.8, bsz=461.3, num_updates=11800, lr=0.000130189, gnorm=3.512, clip=0, loss_scale=0.125, train_wall=84, gb_free=16.2, wall=0
2023-09-04 00:23:58 | INFO | train_inner | epoch 009:    121 / 1474 loss=2.043, trans_loss=3.501, nll_loss=1.711, w2v_ctc_loss=1.135, task_loss=0.824, task_loss_gen=1.113, contrastive_loss=0, total=4183.61, n_correct=2427.09, ppl=3.27, accuracy=58.014, wps=14555.7, ups=1.17, wpb=12492.2, bsz=481.6, num_updates=11900, lr=0.000129641, gnorm=3.671, clip=1, loss_scale=0.125, train_wall=85, gb_free=11.7, wall=0
2023-09-04 00:25:23 | INFO | train_inner | epoch 009:    221 / 1474 loss=2.04, trans_loss=3.504, nll_loss=1.714, w2v_ctc_loss=1.125, task_loss=0.977, task_loss_gen=1.303, contrastive_loss=0, total=4071.87, n_correct=2363.09, ppl=3.28, accuracy=58.035, wps=14330.4, ups=1.18, wpb=12157.4, bsz=428.8, num_updates=12000, lr=0.000129099, gnorm=3.581, clip=5, loss_scale=0.125, train_wall=84, gb_free=16.5, wall=0
2023-09-04 00:25:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 00:25:58 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.128 | trans_loss 5.462 | nll_loss 2.796 | w2v_ctc_loss 1.452 | task_loss 5.223 | task_loss_gen 4.703 | contrastive_loss 0 | total 4003.4 | n_correct 2473.3 | ppl 6.94 | accuracy 61.78 | uer 20.083 | wer 22.016 | raw_wer 22.016 | bleu 17.84 | wps 1486.3 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 17.93
2023-09-04 00:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-09-04 00:25:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_9_12000.pt
2023-09-04 00:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_9_12000.pt
2023-09-04 00:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 17.84) (writing took 9.053458468988538 seconds)
2023-09-04 00:27:31 | INFO | train_inner | epoch 009:    321 / 1474 loss=2.031, trans_loss=3.496, nll_loss=1.706, w2v_ctc_loss=1.118, task_loss=0.794, task_loss_gen=1.095, contrastive_loss=0, total=4172.75, n_correct=2423.67, ppl=3.26, accuracy=58.083, wps=9704.8, ups=0.78, wpb=12465.7, bsz=486.5, num_updates=12100, lr=0.000128565, gnorm=3.32, clip=1, loss_scale=0.125, train_wall=84, gb_free=16.5, wall=0
2023-09-04 00:28:57 | INFO | train_inner | epoch 009:    421 / 1474 loss=2.038, trans_loss=3.498, nll_loss=1.707, w2v_ctc_loss=1.129, task_loss=0.848, task_loss_gen=1.176, contrastive_loss=0, total=4182.18, n_correct=2430.98, ppl=3.27, accuracy=58.127, wps=14625.5, ups=1.17, wpb=12487.3, bsz=461.6, num_updates=12200, lr=0.000128037, gnorm=3.152, clip=1, loss_scale=0.125, train_wall=85, gb_free=16, wall=0
2023-09-04 00:30:21 | INFO | train_inner | epoch 009:    521 / 1474 loss=2.043, trans_loss=3.491, nll_loss=1.697, w2v_ctc_loss=1.145, task_loss=0.884, task_loss_gen=1.243, contrastive_loss=0, total=4117.47, n_correct=2406.23, ppl=3.24, accuracy=58.44, wps=14564.9, ups=1.19, wpb=12290.6, bsz=440.5, num_updates=12300, lr=0.000127515, gnorm=1.706, clip=0, loss_scale=0.25, train_wall=84, gb_free=16.4, wall=0
2023-09-04 00:31:47 | INFO | train_inner | epoch 009:    621 / 1474 loss=2.022, trans_loss=3.482, nll_loss=1.689, w2v_ctc_loss=1.119, task_loss=0.85, task_loss_gen=1.202, contrastive_loss=0, total=4138.74, n_correct=2426.51, ppl=3.22, accuracy=58.629, wps=14374.5, ups=1.16, wpb=12367.9, bsz=458.4, num_updates=12400, lr=0.000127, gnorm=1.762, clip=0, loss_scale=0.25, train_wall=85, gb_free=14.5, wall=0
2023-09-04 00:33:11 | INFO | train_inner | epoch 009:    721 / 1474 loss=2.043, trans_loss=3.487, nll_loss=1.696, w2v_ctc_loss=1.149, task_loss=0.909, task_loss_gen=1.247, contrastive_loss=0, total=4071.53, n_correct=2380.59, ppl=3.24, accuracy=58.469, wps=14437.6, ups=1.19, wpb=12170.1, bsz=443.9, num_updates=12500, lr=0.000126491, gnorm=1.923, clip=0, loss_scale=0.25, train_wall=84, gb_free=16, wall=0
2023-09-04 00:34:37 | INFO | train_inner | epoch 009:    821 / 1474 loss=2.02, trans_loss=3.473, nll_loss=1.679, w2v_ctc_loss=1.124, task_loss=0.801, task_loss_gen=1.086, contrastive_loss=0, total=4204.72, n_correct=2482.67, ppl=3.2, accuracy=59.045, wps=14704.1, ups=1.17, wpb=12562.3, bsz=496.6, num_updates=12600, lr=0.000125988, gnorm=1.759, clip=0, loss_scale=0.25, train_wall=85, gb_free=16.2, wall=0
2023-09-04 00:36:03 | INFO | train_inner | epoch 009:    921 / 1474 loss=2.018, trans_loss=3.478, nll_loss=1.68, w2v_ctc_loss=1.117, task_loss=0.865, task_loss_gen=1.23, contrastive_loss=0, total=4160.21, n_correct=2456.13, ppl=3.2, accuracy=59.039, wps=14475.1, ups=1.17, wpb=12409.8, bsz=450.7, num_updates=12700, lr=0.000125491, gnorm=1.431, clip=0, loss_scale=0.25, train_wall=85, gb_free=11.1, wall=0
2023-09-04 00:37:28 | INFO | train_inner | epoch 009:   1021 / 1474 loss=2.023, trans_loss=3.484, nll_loss=1.689, w2v_ctc_loss=1.121, task_loss=0.951, task_loss_gen=1.334, contrastive_loss=0, total=4097.6, n_correct=2409.22, ppl=3.22, accuracy=58.796, wps=14406.9, ups=1.18, wpb=12232.3, bsz=425.1, num_updates=12800, lr=0.000125, gnorm=1.551, clip=0, loss_scale=0.25, train_wall=84, gb_free=12.2, wall=0
2023-09-04 00:38:53 | INFO | train_inner | epoch 009:   1121 / 1474 loss=2.017, trans_loss=3.478, nll_loss=1.679, w2v_ctc_loss=1.121, task_loss=0.843, task_loss_gen=1.134, contrastive_loss=0, total=4166.05, n_correct=2468.42, ppl=3.2, accuracy=59.251, wps=14566.3, ups=1.17, wpb=12417.6, bsz=469.4, num_updates=12900, lr=0.000124515, gnorm=1.754, clip=0, loss_scale=0.25, train_wall=85, gb_free=15.1, wall=0
2023-09-04 00:40:19 | INFO | train_inner | epoch 009:   1221 / 1474 loss=2.023, trans_loss=3.474, nll_loss=1.677, w2v_ctc_loss=1.132, task_loss=0.915, task_loss_gen=1.246, contrastive_loss=0, total=4149.87, n_correct=2455.93, ppl=3.2, accuracy=59.181, wps=14437.9, ups=1.17, wpb=12390.1, bsz=451.2, num_updates=13000, lr=0.000124035, gnorm=1.7, clip=0, loss_scale=0.25, train_wall=85, gb_free=14.8, wall=0
2023-09-04 00:41:43 | INFO | train_inner | epoch 009:   1321 / 1474 loss=1.993, trans_loss=3.459, nll_loss=1.658, w2v_ctc_loss=1.099, task_loss=0.795, task_loss_gen=1.093, contrastive_loss=0, total=4196.35, n_correct=2506.88, ppl=3.15, accuracy=59.74, wps=14902.1, ups=1.19, wpb=12522.2, bsz=490.7, num_updates=13100, lr=0.00012356, gnorm=1.349, clip=0, loss_scale=0.25, train_wall=83, gb_free=16.1, wall=0
2023-09-04 00:43:07 | INFO | train_inner | epoch 009:   1421 / 1474 loss=2.011, trans_loss=3.471, nll_loss=1.672, w2v_ctc_loss=1.117, task_loss=0.913, task_loss_gen=1.251, contrastive_loss=0, total=4080.31, n_correct=2426.44, ppl=3.19, accuracy=59.467, wps=14412, ups=1.18, wpb=12174.6, bsz=433.5, num_updates=13200, lr=0.000123091, gnorm=1.336, clip=0, loss_scale=0.25, train_wall=84, gb_free=15.3, wall=0
2023-09-04 00:43:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 00:44:25 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.031 | trans_loss 5.366 | nll_loss 2.683 | w2v_ctc_loss 1.344 | task_loss 4.629 | task_loss_gen 4.736 | contrastive_loss 0 | total 4003.4 | n_correct 2531.5 | ppl 6.42 | accuracy 63.234 | uer 19.107 | wer 20.786 | raw_wer 20.786 | bleu 19.3 | wps 1569 | wpb 4003.4 | bsz 141.8 | num_updates 13253 | best_bleu 19.3
2023-09-04 00:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13253 updates
2023-09-04 00:44:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:44:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 00:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 9 @ 13253 updates, score 19.3) (writing took 11.932326785987243 seconds)
2023-09-04 00:44:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-04 00:44:37 | INFO | train | epoch 009 | loss 2.025 | trans_loss 3.483 | nll_loss 1.689 | w2v_ctc_loss 1.125 | task_loss 0.865 | task_loss_gen 1.19 | contrastive_loss 0 | total 4138.65 | n_correct 2431.94 | ppl 3.22 | accuracy 58.762 | wps 13495 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 13253 | lr 0.000122845 | gnorm 2.146 | clip 0.5 | loss_scale 0.25 | train_wall 1241 | gb_free 11.1 | wall 0
2023-09-04 00:44:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 00:44:37 | INFO | fairseq.trainer | begin training epoch 10
2023-09-04 00:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 00:45:24 | INFO | train_inner | epoch 010:     47 / 1474 loss=1.982, trans_loss=3.45, nll_loss=1.646, w2v_ctc_loss=1.094, task_loss=0.791, task_loss_gen=1.1, contrastive_loss=0, total=4122.25, n_correct=2475.48, ppl=3.13, accuracy=60.052, wps=9011.8, ups=0.73, wpb=12305.7, bsz=476.5, num_updates=13300, lr=0.000122628, gnorm=1.449, clip=0, loss_scale=0.25, train_wall=83, gb_free=16.7, wall=0
2023-09-04 00:46:49 | INFO | train_inner | epoch 010:    147 / 1474 loss=1.958, trans_loss=3.433, nll_loss=1.626, w2v_ctc_loss=1.065, task_loss=0.825, task_loss_gen=1.126, contrastive_loss=0, total=4233.75, n_correct=2564.88, ppl=3.09, accuracy=60.582, wps=14887.4, ups=1.18, wpb=12643.4, bsz=474.2, num_updates=13400, lr=0.000122169, gnorm=1.443, clip=0, loss_scale=0.25, train_wall=84, gb_free=15.7, wall=0
2023-09-04 00:48:13 | INFO | train_inner | epoch 010:    247 / 1474 loss=1.968, trans_loss=3.432, nll_loss=1.622, w2v_ctc_loss=1.078, task_loss=0.871, task_loss_gen=1.168, contrastive_loss=0, total=4132.48, n_correct=2505.03, ppl=3.08, accuracy=60.618, wps=14544, ups=1.18, wpb=12333.3, bsz=463, num_updates=13500, lr=0.000121716, gnorm=1.547, clip=0, loss_scale=0.25, train_wall=84, gb_free=16.4, wall=0
2023-09-04 00:49:38 | INFO | train_inner | epoch 010:    347 / 1474 loss=1.965, trans_loss=3.426, nll_loss=1.619, w2v_ctc_loss=1.073, task_loss=0.861, task_loss_gen=1.195, contrastive_loss=0, total=4126.94, n_correct=2499.56, ppl=3.07, accuracy=60.567, wps=14528.9, ups=1.18, wpb=12334.8, bsz=452.9, num_updates=13600, lr=0.000121268, gnorm=1.374, clip=0, loss_scale=0.25, train_wall=84, gb_free=16.5, wall=0
2023-09-04 00:51:04 | INFO | train_inner | epoch 010:    447 / 1474 loss=1.951, trans_loss=3.435, nll_loss=1.628, w2v_ctc_loss=1.055, task_loss=0.821, task_loss_gen=1.154, contrastive_loss=0, total=4190.03, n_correct=2532.86, ppl=3.09, accuracy=60.45, wps=14630.4, ups=1.17, wpb=12510.5, bsz=478.6, num_updates=13700, lr=0.000120824, gnorm=1.303, clip=0, loss_scale=0.25, train_wall=85, gb_free=15.9, wall=0
2023-09-04 00:52:29 | INFO | train_inner | epoch 010:    547 / 1474 loss=1.981, trans_loss=3.445, nll_loss=1.636, w2v_ctc_loss=1.091, task_loss=0.94, task_loss_gen=1.29, contrastive_loss=0, total=4086.26, n_correct=2466.08, ppl=3.11, accuracy=60.351, wps=14327.4, ups=1.18, wpb=12182.3, bsz=431.5, num_updates=13800, lr=0.000120386, gnorm=1.425, clip=0, loss_scale=0.25, train_wall=84, gb_free=14.7, wall=0
2023-09-04 00:53:54 | INFO | train_inner | epoch 010:    647 / 1474 loss=1.967, trans_loss=3.437, nll_loss=1.63, w2v_ctc_loss=1.078, task_loss=0.77, task_loss_gen=1.092, contrastive_loss=0, total=4215.3, n_correct=2552.21, ppl=3.09, accuracy=60.546, wps=14853, ups=1.18, wpb=12578.4, bsz=489.6, num_updates=13900, lr=0.000119952, gnorm=1.285, clip=0, loss_scale=0.25, train_wall=84, gb_free=16.2, wall=0
2023-09-04 00:55:19 | INFO | train_inner | epoch 010:    747 / 1474 loss=1.98, trans_loss=3.435, nll_loss=1.628, w2v_ctc_loss=1.097, task_loss=0.846, task_loss_gen=1.219, contrastive_loss=0, total=4098.44, n_correct=2475.02, ppl=3.09, accuracy=60.389, wps=14363.4, ups=1.17, wpb=12239.7, bsz=445.2, num_updates=14000, lr=0.000119523, gnorm=1.196, clip=0, loss_scale=0.25, train_wall=85, gb_free=12, wall=0
2023-09-04 00:55:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 00:55:52 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.029 | trans_loss 5.339 | nll_loss 2.653 | w2v_ctc_loss 1.398 | task_loss 4.019 | task_loss_gen 4.814 | contrastive_loss 0 | total 4003.4 | n_correct 2556 | ppl 6.29 | accuracy 63.846 | uer 19.693 | wer 21.468 | raw_wer 21.468 | bleu 19.35 | wps 1564.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.35
2023-09-04 00:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-09-04 00:55:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_10_14000.pt
2023-09-04 00:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_10_14000.pt
2023-09-04 00:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.35) (writing took 12.825053439999465 seconds)
2023-09-04 00:57:30 | INFO | train_inner | epoch 010:    847 / 1474 loss=1.966, trans_loss=3.436, nll_loss=1.629, w2v_ctc_loss=1.074, task_loss=0.848, task_loss_gen=1.181, contrastive_loss=0, total=4135.55, n_correct=2507.29, ppl=3.09, accuracy=60.628, wps=9384.3, ups=0.76, wpb=12343.9, bsz=455.6, num_updates=14100, lr=0.000119098, gnorm=1.351, clip=0, loss_scale=0.25, train_wall=84, gb_free=15.4, wall=0
2023-09-04 00:58:54 | INFO | train_inner | epoch 010:    947 / 1474 loss=1.966, trans_loss=3.436, nll_loss=1.626, w2v_ctc_loss=1.08, task_loss=0.786, task_loss_gen=1.134, contrastive_loss=0, total=4160.29, n_correct=2521.83, ppl=3.09, accuracy=60.617, wps=14800.7, ups=1.19, wpb=12409.5, bsz=472.4, num_updates=14200, lr=0.000118678, gnorm=1.308, clip=0, loss_scale=0.25, train_wall=83, gb_free=16.8, wall=0
2023-09-04 01:00:19 | INFO | train_inner | epoch 010:   1047 / 1474 loss=1.972, trans_loss=3.433, nll_loss=1.626, w2v_ctc_loss=1.083, task_loss=0.902, task_loss_gen=1.302, contrastive_loss=0, total=4063.09, n_correct=2454.73, ppl=3.09, accuracy=60.415, wps=14345.1, ups=1.18, wpb=12133, bsz=431.7, num_updates=14300, lr=0.000118262, gnorm=1.036, clip=0, loss_scale=0.5, train_wall=84, gb_free=11.8, wall=0
2023-09-04 01:01:43 | INFO | train_inner | epoch 010:   1147 / 1474 loss=1.975, trans_loss=3.437, nll_loss=1.63, w2v_ctc_loss=1.087, task_loss=0.891, task_loss_gen=1.344, contrastive_loss=0, total=4039.19, n_correct=2442.5, ppl=3.09, accuracy=60.47, wps=14310, ups=1.19, wpb=12057.5, bsz=420.4, num_updates=14400, lr=0.000117851, gnorm=0.792, clip=0, loss_scale=0.5, train_wall=83, gb_free=15.6, wall=0
2023-09-04 01:03:09 | INFO | train_inner | epoch 010:   1247 / 1474 loss=1.966, trans_loss=3.422, nll_loss=1.617, w2v_ctc_loss=1.086, task_loss=0.78, task_loss_gen=1.242, contrastive_loss=0, total=4106.65, n_correct=2489.3, ppl=3.07, accuracy=60.616, wps=14316, ups=1.17, wpb=12284.6, bsz=446.1, num_updates=14500, lr=0.000117444, gnorm=0.675, clip=0, loss_scale=0.5, train_wall=85, gb_free=16.5, wall=0
2023-09-04 01:04:34 | INFO | train_inner | epoch 010:   1347 / 1474 loss=1.963, trans_loss=3.428, nll_loss=1.62, w2v_ctc_loss=1.076, task_loss=0.758, task_loss_gen=1.222, contrastive_loss=0, total=4150.9, n_correct=2526.8, ppl=3.07, accuracy=60.874, wps=14632.7, ups=1.18, wpb=12394.6, bsz=456.8, num_updates=14600, lr=0.000117041, gnorm=0.726, clip=0, loss_scale=0.5, train_wall=84, gb_free=16.1, wall=0
2023-09-04 01:05:59 | INFO | train_inner | epoch 010:   1447 / 1474 loss=1.952, trans_loss=3.437, nll_loss=1.629, w2v_ctc_loss=1.057, task_loss=0.712, task_loss_gen=1.145, contrastive_loss=0, total=4193.92, n_correct=2546.13, ppl=3.09, accuracy=60.71, wps=14617.5, ups=1.17, wpb=12507.1, bsz=485, num_updates=14700, lr=0.000116642, gnorm=0.783, clip=0, loss_scale=0.5, train_wall=85, gb_free=11.9, wall=0
2023-09-04 01:06:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 01:06:55 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.001 | trans_loss 5.319 | nll_loss 2.626 | w2v_ctc_loss 1.351 | task_loss 3.929 | task_loss_gen 4.768 | contrastive_loss 0 | total 4003.4 | n_correct 2561.5 | ppl 6.17 | accuracy 63.983 | uer 19.061 | wer 20.715 | raw_wer 20.715 | bleu 20.04 | wps 1597.7 | wpb 4003.4 | bsz 141.8 | num_updates 14727 | best_bleu 20.04
2023-09-04 01:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14727 updates
2023-09-04 01:06:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:07:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 10 @ 14727 updates, score 20.04) (writing took 13.10576296702493 seconds)
2023-09-04 01:07:08 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-04 01:07:08 | INFO | train | epoch 010 | loss 1.966 | trans_loss 3.434 | nll_loss 1.626 | w2v_ctc_loss 1.076 | task_loss 0.825 | task_loss_gen 1.194 | contrastive_loss 0 | total 4138.65 | n_correct 2506.08 | ppl 3.09 | accuracy 60.553 | wps 13478.6 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 14727 | lr 0.000116535 | gnorm 1.163 | clip 0 | loss_scale 0.5 | train_wall 1239 | gb_free 17 | wall 0
2023-09-04 01:07:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 01:07:08 | INFO | fairseq.trainer | begin training epoch 11
2023-09-04 01:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 01:08:16 | INFO | train_inner | epoch 011:     73 / 1474 loss=1.93, trans_loss=3.407, nll_loss=1.592, w2v_ctc_loss=1.042, task_loss=0.735, task_loss_gen=1.153, contrastive_loss=0, total=4134.34, n_correct=2534.54, ppl=3.02, accuracy=61.305, wps=9019.3, ups=0.73, wpb=12344.6, bsz=468.5, num_updates=14800, lr=0.000116248, gnorm=0.78, clip=0, loss_scale=0.5, train_wall=82, gb_free=17.3, wall=0
2023-09-04 01:09:41 | INFO | train_inner | epoch 011:    173 / 1474 loss=1.935, trans_loss=3.408, nll_loss=1.595, w2v_ctc_loss=1.047, task_loss=0.784, task_loss_gen=1.243, contrastive_loss=0, total=4120.83, n_correct=2527.94, ppl=3.02, accuracy=61.345, wps=14562.4, ups=1.18, wpb=12311.3, bsz=455.2, num_updates=14900, lr=0.000115857, gnorm=0.833, clip=0, loss_scale=0.5, train_wall=84, gb_free=11, wall=0
2023-09-04 01:11:05 | INFO | train_inner | epoch 011:    273 / 1474 loss=1.93, trans_loss=3.403, nll_loss=1.589, w2v_ctc_loss=1.041, task_loss=0.804, task_loss_gen=1.269, contrastive_loss=0, total=4107.04, n_correct=2524.89, ppl=3.01, accuracy=61.477, wps=14476.3, ups=1.18, wpb=12266.9, bsz=439.6, num_updates=15000, lr=0.00011547, gnorm=0.897, clip=0, loss_scale=0.5, train_wall=84, gb_free=16.3, wall=0
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 01:12:06 | INFO | train_inner | epoch 011:    373 / 1474 loss=2.08, trans_loss=5.062, nll_loss=2.367, w2v_ctc_loss=0.774, task_loss=1.195, task_loss_gen=1.908, contrastive_loss=0, total=4098.83, n_correct=2514.41, ppl=5.16, accuracy=61.345, wps=13514.3, ups=1.64, wpb=8240.6, bsz=296.3, num_updates=15100, lr=0.000115087, gnorm=1.226, clip=0, loss_scale=0.5, train_wall=60, gb_free=16.7, wall=0
2023-09-04 01:13:08 | INFO | train_inner | epoch 011:    473 / 1474 loss=2.082, trans_loss=5.088, nll_loss=2.379, w2v_ctc_loss=0.77, task_loss=1.219, task_loss_gen=1.891, contrastive_loss=0, total=4123, n_correct=2528.74, ppl=5.2, accuracy=61.333, wps=13305.1, ups=1.61, wpb=8246, bsz=306.3, num_updates=15200, lr=0.000114708, gnorm=1.38, clip=0, loss_scale=0.5, train_wall=61, gb_free=16.6, wall=0
2023-09-04 01:14:10 | INFO | train_inner | epoch 011:    573 / 1474 loss=2.088, trans_loss=5.089, nll_loss=2.382, w2v_ctc_loss=0.783, task_loss=1.24, task_loss_gen=1.96, contrastive_loss=0, total=4060.55, n_correct=2491.26, ppl=5.21, accuracy=61.353, wps=13227.7, ups=1.63, wpb=8121.1, bsz=291.3, num_updates=15300, lr=0.000114332, gnorm=1.213, clip=0, loss_scale=0.5, train_wall=61, gb_free=16.1, wall=0
2023-09-04 01:15:11 | INFO | train_inner | epoch 011:    673 / 1474 loss=2.089, trans_loss=5.088, nll_loss=2.378, w2v_ctc_loss=0.786, task_loss=1.111, task_loss_gen=1.842, contrastive_loss=0, total=4158.05, n_correct=2546.6, ppl=5.2, accuracy=61.245, wps=13528.9, ups=1.63, wpb=8316.1, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=1.132, clip=0, loss_scale=0.5, train_wall=61, gb_free=15.4, wall=0
2023-09-04 01:16:13 | INFO | train_inner | epoch 011:    773 / 1474 loss=2.094, trans_loss=5.097, nll_loss=2.392, w2v_ctc_loss=0.797, task_loss=1.195, task_loss_gen=1.917, contrastive_loss=0, total=4146.84, n_correct=2542.74, ppl=5.25, accuracy=61.318, wps=13347, ups=1.61, wpb=8293.7, bsz=300.8, num_updates=15500, lr=0.000113592, gnorm=1.224, clip=0, loss_scale=0.5, train_wall=61, gb_free=11.7, wall=0
2023-09-04 01:17:14 | INFO | train_inner | epoch 011:    873 / 1474 loss=2.091, trans_loss=5.094, nll_loss=2.388, w2v_ctc_loss=0.79, task_loss=1.199, task_loss_gen=1.892, contrastive_loss=0, total=4140.19, n_correct=2534.24, ppl=5.23, accuracy=61.211, wps=13534.4, ups=1.63, wpb=8280.4, bsz=297.3, num_updates=15600, lr=0.000113228, gnorm=1.25, clip=0, loss_scale=0.5, train_wall=60, gb_free=15.2, wall=0
2023-09-04 01:18:16 | INFO | train_inner | epoch 011:    973 / 1474 loss=2.085, trans_loss=5.086, nll_loss=2.377, w2v_ctc_loss=0.792, task_loss=1.154, task_loss_gen=1.863, contrastive_loss=0, total=4145.42, n_correct=2547.79, ppl=5.2, accuracy=61.46, wps=13485.9, ups=1.63, wpb=8290.8, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=1.191, clip=0, loss_scale=0.5, train_wall=61, gb_free=16.1, wall=0
2023-09-04 01:19:17 | INFO | train_inner | epoch 011:   1073 / 1474 loss=2.081, trans_loss=5.081, nll_loss=2.372, w2v_ctc_loss=0.789, task_loss=1.117, task_loss_gen=1.776, contrastive_loss=0, total=4159.95, n_correct=2561.38, ppl=5.18, accuracy=61.572, wps=13641.9, ups=1.64, wpb=8319.9, bsz=312.3, num_updates=15800, lr=0.000112509, gnorm=1.266, clip=0, loss_scale=0.5, train_wall=60, gb_free=16.5, wall=0
2023-09-04 01:20:19 | INFO | train_inner | epoch 011:   1173 / 1474 loss=2.087, trans_loss=5.091, nll_loss=2.384, w2v_ctc_loss=0.792, task_loss=1.145, task_loss_gen=1.852, contrastive_loss=0, total=4171.12, n_correct=2560.75, ppl=5.22, accuracy=61.392, wps=13537.4, ups=1.62, wpb=8342.2, bsz=309.5, num_updates=15900, lr=0.000112154, gnorm=1.333, clip=0, loss_scale=0.5, train_wall=61, gb_free=14.4, wall=0
2023-09-04 01:21:21 | INFO | train_inner | epoch 011:   1273 / 1474 loss=2.083, trans_loss=5.079, nll_loss=2.37, w2v_ctc_loss=0.795, task_loss=1.157, task_loss_gen=1.806, contrastive_loss=0, total=4164.89, n_correct=2564.83, ppl=5.17, accuracy=61.582, wps=13340.2, ups=1.6, wpb=8329.8, bsz=311.8, num_updates=16000, lr=0.000111803, gnorm=1.563, clip=0, loss_scale=0.5, train_wall=62, gb_free=16, wall=0
2023-09-04 01:21:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
2023-09-04 01:21:54 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.292 | nll_loss 2.592 | w2v_ctc_loss 1.352 | task_loss 5.952 | task_loss_gen 4.877 | contrastive_loss 0 | total 4003.4 | n_correct 2577.8 | ppl 6.03 | accuracy 64.39 | uer 18.592 | wer 20.368 | raw_wer 20.368 | bleu 19.66 | wps 1575.7 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 20.04
2023-09-04 01:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-09-04 01:21:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_11_16000.pt
2023-09-04 01:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_11_16000.pt
2023-09-04 01:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.66) (writing took 8.474333268997725 seconds)
2023-09-04 01:23:06 | INFO | train_inner | epoch 011:   1373 / 1474 loss=2.073, trans_loss=5.075, nll_loss=2.365, w2v_ctc_loss=0.775, task_loss=1.129, task_loss_gen=1.762, contrastive_loss=0, total=4180.06, n_correct=2578.59, ppl=5.15, accuracy=61.688, wps=7974, ups=0.95, wpb=8360.1, bsz=322.9, num_updates=16100, lr=0.000111456, gnorm=1.62, clip=0, loss_scale=0.5, train_wall=61, gb_free=15.6, wall=0
2023-09-04 01:24:07 | INFO | train_inner | epoch 011:   1473 / 1474 loss=2.076, trans_loss=5.077, nll_loss=2.367, w2v_ctc_loss=0.786, task_loss=1.09, task_loss_gen=1.784, contrastive_loss=0, total=4166.03, n_correct=2573.14, ppl=5.16, accuracy=61.765, wps=13631.9, ups=1.64, wpb=8332.1, bsz=315.3, num_updates=16200, lr=0.000111111, gnorm=1.191, clip=0, loss_scale=0.5, train_wall=60, gb_free=15.9, wall=0
2023-09-04 01:24:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 01:24:41 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.982 | trans_loss 5.288 | nll_loss 2.583 | w2v_ctc_loss 1.354 | task_loss 3.961 | task_loss_gen 4.778 | contrastive_loss 0 | total 4003.4 | n_correct 2580.1 | ppl 5.99 | accuracy 64.448 | uer 18.799 | wer 20.67 | raw_wer 20.67 | bleu 19.91 | wps 1590.1 | wpb 4003.4 | bsz 141.8 | num_updates 16201 | best_bleu 20.04
2023-09-04 01:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16201 updates
2023-09-04 01:24:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_19.9106.pt
2023-09-04 01:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_19.9106.pt
2023-09-04 01:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_19.9106.pt (epoch 11 @ 16201 updates, score 19.91) (writing took 7.261664171004668 seconds)
2023-09-04 01:24:49 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-04 01:24:49 | INFO | train | epoch 011 | loss 2.045 | trans_loss 4.659 | nll_loss 2.178 | w2v_ctc_loss 0.85 | task_loss 1.062 | task_loss_gen 1.693 | contrastive_loss 0 | total 4138.65 | n_correct 2542.97 | ppl 4.52 | accuracy 61.445 | wps 12554.1 | ups 1.39 | wpb 9034.6 | bsz 333.9 | num_updates 16201 | lr 0.000111108 | gnorm 1.211 | clip 0 | loss_scale 0.5 | train_wall 957 | gb_free 16.9 | wall 0
2023-09-04 01:24:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 01:24:49 | INFO | fairseq.trainer | begin training epoch 12
2023-09-04 01:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 01:25:56 | INFO | train_inner | epoch 012:     99 / 1474 loss=2.051, trans_loss=5.033, nll_loss=2.309, w2v_ctc_loss=0.763, task_loss=1.035, task_loss_gen=1.775, contrastive_loss=0, total=4148.71, n_correct=2594.9, ppl=4.95, accuracy=62.547, wps=7610.7, ups=0.92, wpb=8297.4, bsz=315.5, num_updates=16300, lr=0.00011077, gnorm=1.16, clip=0, loss_scale=1, train_wall=60, gb_free=16.3, wall=0
2023-09-04 01:26:57 | INFO | train_inner | epoch 012:    199 / 1474 loss=2.059, trans_loss=5.041, nll_loss=2.318, w2v_ctc_loss=0.769, task_loss=1.086, task_loss_gen=1.897, contrastive_loss=0, total=4140.57, n_correct=2582.05, ppl=4.99, accuracy=62.36, wps=13572.7, ups=1.64, wpb=8281.1, bsz=300.4, num_updates=16400, lr=0.000110432, gnorm=0.747, clip=0, loss_scale=1, train_wall=60, gb_free=17.2, wall=0
2023-09-04 01:27:59 | INFO | train_inner | epoch 012:    299 / 1474 loss=2.053, trans_loss=5.042, nll_loss=2.321, w2v_ctc_loss=0.76, task_loss=0.971, task_loss_gen=1.803, contrastive_loss=0, total=4199.51, n_correct=2623.27, ppl=5, accuracy=62.466, wps=13571.2, ups=1.62, wpb=8399, bsz=318.6, num_updates=16500, lr=0.000110096, gnorm=0.697, clip=0, loss_scale=1, train_wall=61, gb_free=16.7, wall=0
2023-09-04 01:29:01 | INFO | train_inner | epoch 012:    399 / 1474 loss=2.057, trans_loss=5.041, nll_loss=2.32, w2v_ctc_loss=0.769, task_loss=1.056, task_loss_gen=1.914, contrastive_loss=0, total=4135.31, n_correct=2586.34, ppl=4.99, accuracy=62.543, wps=13344.8, ups=1.61, wpb=8270.6, bsz=301.3, num_updates=16600, lr=0.000109764, gnorm=0.778, clip=0, loss_scale=1, train_wall=61, gb_free=16.9, wall=0
2023-09-04 01:30:02 | INFO | train_inner | epoch 012:    499 / 1474 loss=2.065, trans_loss=5.052, nll_loss=2.334, w2v_ctc_loss=0.779, task_loss=1.015, task_loss_gen=1.974, contrastive_loss=0, total=4087.67, n_correct=2547.9, ppl=5.04, accuracy=62.331, wps=13458.1, ups=1.65, wpb=8175.3, bsz=299.4, num_updates=16700, lr=0.000109435, gnorm=0.799, clip=0, loss_scale=1, train_wall=60, gb_free=14.5, wall=0
2023-09-04 01:31:04 | INFO | train_inner | epoch 012:    599 / 1474 loss=2.056, trans_loss=5.043, nll_loss=2.323, w2v_ctc_loss=0.77, task_loss=0.958, task_loss_gen=1.802, contrastive_loss=0, total=4218.35, n_correct=2635.93, ppl=5.01, accuracy=62.487, wps=13567.3, ups=1.61, wpb=8436.7, bsz=321.4, num_updates=16800, lr=0.000109109, gnorm=0.807, clip=0, loss_scale=1, train_wall=61, gb_free=15.9, wall=0
2023-09-04 01:32:05 | INFO | train_inner | epoch 012:    699 / 1474 loss=2.044, trans_loss=5.032, nll_loss=2.309, w2v_ctc_loss=0.752, task_loss=0.977, task_loss_gen=1.78, contrastive_loss=0, total=4191.35, n_correct=2631.04, ppl=4.95, accuracy=62.773, wps=13703.4, ups=1.63, wpb=8382.7, bsz=322.4, num_updates=16900, lr=0.000108786, gnorm=0.863, clip=0, loss_scale=1, train_wall=60, gb_free=16.2, wall=0
2023-09-04 01:33:07 | INFO | train_inner | epoch 012:    799 / 1474 loss=2.056, trans_loss=5.036, nll_loss=2.313, w2v_ctc_loss=0.771, task_loss=1.076, task_loss_gen=1.948, contrastive_loss=0, total=4083.28, n_correct=2554.06, ppl=4.97, accuracy=62.549, wps=13184.9, ups=1.61, wpb=8166.6, bsz=296.7, num_updates=17000, lr=0.000108465, gnorm=0.859, clip=0, loss_scale=1, train_wall=61, gb_free=16.9, wall=0
2023-09-04 01:34:09 | INFO | train_inner | epoch 012:    899 / 1474 loss=2.058, trans_loss=5.042, nll_loss=2.321, w2v_ctc_loss=0.771, task_loss=1.077, task_loss_gen=1.956, contrastive_loss=0, total=4175.19, n_correct=2607.67, ppl=5, accuracy=62.456, wps=13540.2, ups=1.62, wpb=8350.4, bsz=305.8, num_updates=17100, lr=0.000108148, gnorm=0.86, clip=0, loss_scale=1, train_wall=61, gb_free=16.9, wall=0
2023-09-04 01:35:10 | INFO | train_inner | epoch 012:    999 / 1474 loss=2.064, trans_loss=5.047, nll_loss=2.329, w2v_ctc_loss=0.782, task_loss=1.045, task_loss_gen=1.974, contrastive_loss=0, total=4117.25, n_correct=2568.5, ppl=5.02, accuracy=62.384, wps=13487.2, ups=1.64, wpb=8234.5, bsz=302.4, num_updates=17200, lr=0.000107833, gnorm=0.884, clip=0, loss_scale=1, train_wall=60, gb_free=16.2, wall=0
2023-09-04 01:36:11 | INFO | train_inner | epoch 012:   1099 / 1474 loss=2.063, trans_loss=5.047, nll_loss=2.329, w2v_ctc_loss=0.776, task_loss=1.12, task_loss_gen=2.014, contrastive_loss=0, total=4063.87, n_correct=2534.98, ppl=5.02, accuracy=62.378, wps=13330.9, ups=1.64, wpb=8127.7, bsz=291.1, num_updates=17300, lr=0.000107521, gnorm=0.875, clip=0, loss_scale=1, train_wall=60, gb_free=13, wall=0
2023-09-04 01:37:12 | INFO | train_inner | epoch 012:   1199 / 1474 loss=2.072, trans_loss=5.063, nll_loss=2.349, w2v_ctc_loss=0.793, task_loss=1, task_loss_gen=1.89, contrastive_loss=0, total=4185.74, n_correct=2595.51, ppl=5.1, accuracy=62.008, wps=13586.3, ups=1.62, wpb=8371.5, bsz=318.1, num_updates=17400, lr=0.000107211, gnorm=0.785, clip=0, loss_scale=1, train_wall=61, gb_free=16.4, wall=0
2023-09-04 01:38:14 | INFO | train_inner | epoch 012:   1299 / 1474 loss=2.068, trans_loss=5.045, nll_loss=2.326, w2v_ctc_loss=0.79, task_loss=1.162, task_loss_gen=2.138, contrastive_loss=0, total=4072.36, n_correct=2541.76, ppl=5.01, accuracy=62.415, wps=13273.1, ups=1.63, wpb=8144.7, bsz=285.7, num_updates=17500, lr=0.000106904, gnorm=0.858, clip=0, loss_scale=1, train_wall=61, gb_free=16, wall=0
2023-09-04 01:39:16 | INFO | train_inner | epoch 012:   1399 / 1474 loss=2.059, trans_loss=5.052, nll_loss=2.336, w2v_ctc_loss=0.769, task_loss=0.969, task_loss_gen=2.001, contrastive_loss=0, total=4138.49, n_correct=2579.83, ppl=5.05, accuracy=62.337, wps=13298.8, ups=1.61, wpb=8277, bsz=305.6, num_updates=17600, lr=0.0001066, gnorm=0.839, clip=0, loss_scale=1, train_wall=62, gb_free=14.1, wall=0
2023-09-04 01:40:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 01:40:35 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.269 | nll_loss 2.558 | w2v_ctc_loss 1.343 | task_loss 4.716 | task_loss_gen 4.886 | contrastive_loss 0 | total 4003.4 | n_correct 2587 | ppl 5.89 | accuracy 64.62 | uer 18.61 | wer 20.249 | raw_wer 20.249 | bleu 20.44 | wps 1614.6 | wpb 4003.4 | bsz 141.8 | num_updates 17675 | best_bleu 20.44
2023-09-04 01:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17675 updates
2023-09-04 01:40:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:40:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 12 @ 17675 updates, score 20.44) (writing took 14.183377565001138 seconds)
2023-09-04 01:40:50 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-04 01:40:50 | INFO | train | epoch 012 | loss 2.059 | trans_loss 5.045 | nll_loss 2.325 | w2v_ctc_loss 0.773 | task_loss 1.036 | task_loss_gen 1.922 | contrastive_loss 0 | total 4138.65 | n_correct 2583.65 | ppl 5.01 | accuracy 62.427 | wps 12697 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 17675 | lr 0.000106374 | gnorm 0.844 | clip 0 | loss_scale 1 | train_wall 893 | gb_free 12.4 | wall 0
2023-09-04 01:40:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 01:40:50 | INFO | fairseq.trainer | begin training epoch 13
2023-09-04 01:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 01:41:12 | INFO | train_inner | epoch 013:     25 / 1474 loss=2.064, trans_loss=5.05, nll_loss=2.332, w2v_ctc_loss=0.782, task_loss=1.023, task_loss_gen=2.033, contrastive_loss=0, total=4094.69, n_correct=2555.28, ppl=5.03, accuracy=62.405, wps=7035.5, ups=0.86, wpb=8189.4, bsz=297.7, num_updates=17700, lr=0.000106299, gnorm=0.863, clip=0, loss_scale=1, train_wall=60, gb_free=17, wall=0
2023-09-04 01:42:14 | INFO | train_inner | epoch 013:    125 / 1474 loss=2.04, trans_loss=5.015, nll_loss=2.286, w2v_ctc_loss=0.752, task_loss=1.075, task_loss_gen=1.908, contrastive_loss=0, total=4174.39, n_correct=2630.42, ppl=4.88, accuracy=63.013, wps=13629.3, ups=1.63, wpb=8348.8, bsz=303.7, num_updates=17800, lr=0.000106, gnorm=0.919, clip=0, loss_scale=1, train_wall=61, gb_free=16.1, wall=0
2023-09-04 01:43:15 | INFO | train_inner | epoch 013:    225 / 1474 loss=2.04, trans_loss=5.023, nll_loss=2.297, w2v_ctc_loss=0.749, task_loss=1.052, task_loss_gen=1.785, contrastive_loss=0, total=4188.05, n_correct=2634.08, ppl=4.91, accuracy=62.895, wps=13606.7, ups=1.62, wpb=8376.1, bsz=326.2, num_updates=17900, lr=0.000105703, gnorm=0.92, clip=0, loss_scale=1, train_wall=61, gb_free=15.4, wall=0
2023-09-04 01:44:16 | INFO | train_inner | epoch 013:    325 / 1474 loss=2.04, trans_loss=5.011, nll_loss=2.28, w2v_ctc_loss=0.752, task_loss=1.074, task_loss_gen=2.053, contrastive_loss=0, total=4099.96, n_correct=2590.56, ppl=4.86, accuracy=63.185, wps=13408.5, ups=1.64, wpb=8199.9, bsz=292.3, num_updates=18000, lr=0.000105409, gnorm=0.886, clip=0, loss_scale=1, train_wall=60, gb_free=16.8, wall=0
2023-09-04 01:44:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 01:44:49 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.259 | nll_loss 2.544 | w2v_ctc_loss 1.355 | task_loss 3.118 | task_loss_gen 5.108 | contrastive_loss 0 | total 4003.4 | n_correct 2597.4 | ppl 5.83 | accuracy 64.88 | uer 18.684 | wer 20.469 | raw_wer 20.469 | bleu 20.45 | wps 1630.5 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 20.45
2023-09-04 01:44:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-09-04 01:44:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_13_18000.pt
2023-09-04 01:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_13_18000.pt
2023-09-04 01:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 20.45) (writing took 13.78916924400255 seconds)
2023-09-04 01:46:05 | INFO | train_inner | epoch 013:    425 / 1474 loss=2.034, trans_loss=5.009, nll_loss=2.279, w2v_ctc_loss=0.757, task_loss=0.975, task_loss_gen=1.749, contrastive_loss=0, total=4208.72, n_correct=2666.54, ppl=4.85, accuracy=63.358, wps=7729.1, ups=0.92, wpb=8417.4, bsz=324.7, num_updates=18100, lr=0.000105118, gnorm=0.83, clip=0, loss_scale=1, train_wall=61, gb_free=11.2, wall=0
2023-09-04 01:47:07 | INFO | train_inner | epoch 013:    525 / 1474 loss=2.043, trans_loss=5.02, nll_loss=2.293, w2v_ctc_loss=0.761, task_loss=1.005, task_loss_gen=1.88, contrastive_loss=0, total=4184.32, n_correct=2634.91, ppl=4.9, accuracy=62.971, wps=13549.3, ups=1.62, wpb=8368.6, bsz=317.7, num_updates=18200, lr=0.000104828, gnorm=0.845, clip=0, loss_scale=1, train_wall=61, gb_free=16.5, wall=0
2023-09-04 01:48:08 | INFO | train_inner | epoch 013:    625 / 1474 loss=2.038, trans_loss=5.014, nll_loss=2.285, w2v_ctc_loss=0.758, task_loss=1.028, task_loss_gen=1.956, contrastive_loss=0, total=4149.45, n_correct=2626.17, ppl=4.87, accuracy=63.29, wps=13560.5, ups=1.63, wpb=8298.9, bsz=303, num_updates=18300, lr=0.000104542, gnorm=0.857, clip=0, loss_scale=1, train_wall=60, gb_free=14.8, wall=0
2023-09-04 01:49:09 | INFO | train_inner | epoch 013:    725 / 1474 loss=2.05, trans_loss=5.019, nll_loss=2.292, w2v_ctc_loss=0.77, task_loss=1.136, task_loss_gen=2.08, contrastive_loss=0, total=4109.65, n_correct=2586.32, ppl=4.9, accuracy=62.933, wps=13442.2, ups=1.64, wpb=8219.3, bsz=289.8, num_updates=18400, lr=0.000104257, gnorm=0.806, clip=0, loss_scale=2, train_wall=60, gb_free=17.5, wall=0
2023-09-04 01:50:11 | INFO | train_inner | epoch 013:    825 / 1474 loss=2.043, trans_loss=5.019, nll_loss=2.292, w2v_ctc_loss=0.763, task_loss=1.024, task_loss_gen=1.983, contrastive_loss=0, total=4127.98, n_correct=2601.48, ppl=4.9, accuracy=63.021, wps=13283.3, ups=1.61, wpb=8256, bsz=306.9, num_updates=18500, lr=0.000103975, gnorm=0.642, clip=0, loss_scale=2, train_wall=61, gb_free=17, wall=0
2023-09-04 01:51:13 | INFO | train_inner | epoch 013:    925 / 1474 loss=2.039, trans_loss=5.013, nll_loss=2.285, w2v_ctc_loss=0.76, task_loss=0.955, task_loss_gen=2.087, contrastive_loss=0, total=4093.25, n_correct=2587.74, ppl=4.87, accuracy=63.22, wps=13344.4, ups=1.63, wpb=8186.5, bsz=294, num_updates=18600, lr=0.000103695, gnorm=0.63, clip=0, loss_scale=2, train_wall=61, gb_free=15.3, wall=0
2023-09-04 01:52:15 | INFO | train_inner | epoch 013:   1025 / 1474 loss=2.043, trans_loss=5.016, nll_loss=2.288, w2v_ctc_loss=0.763, task_loss=1.001, task_loss_gen=2.1, contrastive_loss=0, total=4101.15, n_correct=2583.98, ppl=4.89, accuracy=63.006, wps=13299.5, ups=1.62, wpb=8202.3, bsz=297, num_updates=18700, lr=0.000103418, gnorm=0.647, clip=0, loss_scale=2, train_wall=61, gb_free=12.1, wall=0
2023-09-04 01:53:15 | INFO | train_inner | epoch 013:   1125 / 1474 loss=2.033, trans_loss=5.005, nll_loss=2.274, w2v_ctc_loss=0.755, task_loss=0.975, task_loss_gen=1.992, contrastive_loss=0, total=4078.67, n_correct=2582.28, ppl=4.84, accuracy=63.312, wps=13382, ups=1.64, wpb=8157.3, bsz=300.6, num_updates=18800, lr=0.000103142, gnorm=0.634, clip=0, loss_scale=2, train_wall=60, gb_free=16.7, wall=0
2023-09-04 01:54:17 | INFO | train_inner | epoch 013:   1225 / 1474 loss=2.049, trans_loss=5.021, nll_loss=2.295, w2v_ctc_loss=0.771, task_loss=0.974, task_loss_gen=2.169, contrastive_loss=0, total=4117.29, n_correct=2593.01, ppl=4.91, accuracy=62.979, wps=13388.2, ups=1.63, wpb=8234.6, bsz=294.9, num_updates=18900, lr=0.000102869, gnorm=0.629, clip=0, loss_scale=2, train_wall=61, gb_free=16.4, wall=0
2023-09-04 01:55:18 | INFO | train_inner | epoch 013:   1325 / 1474 loss=2.03, trans_loss=5.001, nll_loss=2.27, w2v_ctc_loss=0.752, task_loss=0.874, task_loss_gen=2.018, contrastive_loss=0, total=4127.54, n_correct=2624.22, ppl=4.82, accuracy=63.578, wps=13474.5, ups=1.63, wpb=8255.1, bsz=312.3, num_updates=19000, lr=0.000102598, gnorm=0.641, clip=0, loss_scale=2, train_wall=61, gb_free=15.2, wall=0
2023-09-04 01:56:20 | INFO | train_inner | epoch 013:   1425 / 1474 loss=2.038, trans_loss=5.012, nll_loss=2.284, w2v_ctc_loss=0.758, task_loss=0.926, task_loss_gen=2.043, contrastive_loss=0, total=4167.75, n_correct=2631.03, ppl=4.87, accuracy=63.128, wps=13439.5, ups=1.61, wpb=8335.5, bsz=308.7, num_updates=19100, lr=0.000102329, gnorm=0.678, clip=0, loss_scale=2, train_wall=61, gb_free=14.7, wall=0
2023-09-04 01:56:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 01:57:23 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.94 | trans_loss 5.24 | nll_loss 2.521 | w2v_ctc_loss 1.325 | task_loss 3.49 | task_loss_gen 5.198 | contrastive_loss 0 | total 4003.4 | n_correct 2608.4 | ppl 5.74 | accuracy 65.155 | uer 18.488 | wer 20.037 | raw_wer 20.037 | bleu 20.83 | wps 1621.6 | wpb 4003.4 | bsz 141.8 | num_updates 19149 | best_bleu 20.83
2023-09-04 01:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19149 updates
2023-09-04 01:57:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:57:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 01:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 13 @ 19149 updates, score 20.83) (writing took 15.687052650027908 seconds)
2023-09-04 01:57:39 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-04 01:57:39 | INFO | train | epoch 013 | loss 2.04 | trans_loss 5.014 | nll_loss 2.285 | w2v_ctc_loss 0.759 | task_loss 1 | task_loss_gen 1.98 | contrastive_loss 0 | total 4138.65 | n_correct 2613.26 | ppl 4.87 | accuracy 63.143 | wps 12086.7 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 19149 | lr 0.000102198 | gnorm 0.752 | clip 0 | loss_scale 2 | train_wall 895 | gb_free 17.4 | wall 0
2023-09-04 01:57:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 01:57:39 | INFO | fairseq.trainer | begin training epoch 14
2023-09-04 01:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 01:58:18 | INFO | train_inner | epoch 014:     51 / 1474 loss=2.016, trans_loss=4.981, nll_loss=2.245, w2v_ctc_loss=0.741, task_loss=0.899, task_loss_gen=1.98, contrastive_loss=0, total=4180.57, n_correct=2670.85, ppl=4.74, accuracy=63.887, wps=7114.6, ups=0.85, wpb=8361.1, bsz=322.6, num_updates=19200, lr=0.000102062, gnorm=0.688, clip=0, loss_scale=2, train_wall=61, gb_free=16.8, wall=0
2023-09-04 01:59:18 | INFO | train_inner | epoch 014:    151 / 1474 loss=2.015, trans_loss=4.969, nll_loss=2.227, w2v_ctc_loss=0.741, task_loss=0.941, task_loss_gen=2.035, contrastive_loss=0, total=4088.97, n_correct=2617.86, ppl=4.68, accuracy=64.022, wps=13536.2, ups=1.66, wpb=8177.9, bsz=301.4, num_updates=19300, lr=0.000101797, gnorm=0.65, clip=0, loss_scale=2, train_wall=60, gb_free=13.7, wall=0
2023-09-04 02:00:19 | INFO | train_inner | epoch 014:    251 / 1474 loss=2.023, trans_loss=4.986, nll_loss=2.249, w2v_ctc_loss=0.743, task_loss=0.931, task_loss_gen=2.112, contrastive_loss=0, total=4115.44, n_correct=2621.28, ppl=4.75, accuracy=63.694, wps=13515.1, ups=1.64, wpb=8230.9, bsz=298.6, num_updates=19400, lr=0.000101535, gnorm=0.633, clip=0, loss_scale=2, train_wall=60, gb_free=15.7, wall=0
2023-09-04 02:01:20 | INFO | train_inner | epoch 014:    351 / 1474 loss=2.02, trans_loss=4.99, nll_loss=2.255, w2v_ctc_loss=0.741, task_loss=0.856, task_loss_gen=2.048, contrastive_loss=0, total=4147.57, n_correct=2641.71, ppl=4.77, accuracy=63.693, wps=13616.7, ups=1.64, wpb=8295.1, bsz=312.6, num_updates=19500, lr=0.000101274, gnorm=0.658, clip=0, loss_scale=2, train_wall=60, gb_free=17, wall=0
2023-09-04 02:02:22 | INFO | train_inner | epoch 014:    451 / 1474 loss=2.019, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.741, task_loss=0.95, task_loss_gen=2.019, contrastive_loss=0, total=4163.12, n_correct=2656.46, ppl=4.76, accuracy=63.809, wps=13476.7, ups=1.62, wpb=8326.2, bsz=308.5, num_updates=19600, lr=0.000101015, gnorm=0.676, clip=0, loss_scale=2, train_wall=61, gb_free=15.3, wall=0
2023-09-04 02:03:24 | INFO | train_inner | epoch 014:    551 / 1474 loss=2.034, trans_loss=4.99, nll_loss=2.254, w2v_ctc_loss=0.763, task_loss=0.987, task_loss_gen=2.251, contrastive_loss=0, total=4058.74, n_correct=2578.34, ppl=4.77, accuracy=63.526, wps=13086.9, ups=1.61, wpb=8117.5, bsz=285.9, num_updates=19700, lr=0.000100759, gnorm=0.639, clip=0, loss_scale=2, train_wall=61, gb_free=11.3, wall=0
2023-09-04 02:04:25 | INFO | train_inner | epoch 014:    651 / 1474 loss=2.025, trans_loss=4.992, nll_loss=2.257, w2v_ctc_loss=0.747, task_loss=0.883, task_loss_gen=2.031, contrastive_loss=0, total=4172.19, n_correct=2653.29, ppl=4.78, accuracy=63.595, wps=13621.5, ups=1.63, wpb=8344.4, bsz=310.7, num_updates=19800, lr=0.000100504, gnorm=0.637, clip=0, loss_scale=2, train_wall=61, gb_free=15.4, wall=0
2023-09-04 02:05:26 | INFO | train_inner | epoch 014:    751 / 1474 loss=2.022, trans_loss=4.98, nll_loss=2.242, w2v_ctc_loss=0.751, task_loss=0.879, task_loss_gen=2.099, contrastive_loss=0, total=4119.45, n_correct=2632.53, ppl=4.73, accuracy=63.905, wps=13508.5, ups=1.64, wpb=8238.9, bsz=304.4, num_updates=19900, lr=0.000100251, gnorm=0.632, clip=0, loss_scale=2, train_wall=60, gb_free=16.2, wall=0
2023-09-04 02:06:28 | INFO | train_inner | epoch 014:    851 / 1474 loss=2.017, trans_loss=4.981, nll_loss=2.244, w2v_ctc_loss=0.741, task_loss=0.859, task_loss_gen=1.959, contrastive_loss=0, total=4196.19, n_correct=2678.29, ppl=4.74, accuracy=63.827, wps=13651.4, ups=1.63, wpb=8392.4, bsz=322.6, num_updates=20000, lr=0.0001, gnorm=0.63, clip=0, loss_scale=2, train_wall=61, gb_free=14.4, wall=0
2023-09-04 02:06:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 02:07:00 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.23 | nll_loss 2.51 | w2v_ctc_loss 1.413 | task_loss 3.974 | task_loss_gen 5.005 | contrastive_loss 0 | total 4003.4 | n_correct 2617.2 | ppl 5.7 | accuracy 65.374 | uer 18.621 | wer 20.35 | raw_wer 20.35 | bleu 21.15 | wps 1657.3 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.15
2023-09-04 02:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-09-04 02:07:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_14_20000.pt
2023-09-04 02:07:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_14_20000.pt
2023-09-04 02:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.15) (writing took 13.355525346996728 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 02:08:15 | INFO | train_inner | epoch 014:    951 / 1474 loss=2.025, trans_loss=4.991, nll_loss=2.257, w2v_ctc_loss=0.748, task_loss=0.894, task_loss_gen=2.056, contrastive_loss=0, total=4163.97, n_correct=2644.93, ppl=4.78, accuracy=63.519, wps=7729.6, ups=0.93, wpb=8327.9, bsz=309.5, num_updates=20100, lr=9.97509e-05, gnorm=0.635, clip=0, loss_scale=2, train_wall=60, gb_free=16.7, wall=0
2023-09-04 02:09:18 | INFO | train_inner | epoch 014:   1051 / 1474 loss=2.026, trans_loss=4.992, nll_loss=2.258, w2v_ctc_loss=0.746, task_loss=0.961, task_loss_gen=2.176, contrastive_loss=0, total=4148.16, n_correct=2638.64, ppl=4.78, accuracy=63.61, wps=13272.2, ups=1.6, wpb=8296.3, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.716, clip=0, loss_scale=2, train_wall=62, gb_free=15.3, wall=0
2023-09-04 02:10:20 | INFO | train_inner | epoch 014:   1151 / 1474 loss=2.025, trans_loss=4.99, nll_loss=2.256, w2v_ctc_loss=0.753, task_loss=0.858, task_loss_gen=1.948, contrastive_loss=0, total=4223.98, n_correct=2684.12, ppl=4.78, accuracy=63.545, wps=13703.8, ups=1.62, wpb=8448, bsz=326.4, num_updates=20300, lr=9.92583e-05, gnorm=0.648, clip=0, loss_scale=2, train_wall=61, gb_free=16.6, wall=0
2023-09-04 02:11:21 | INFO | train_inner | epoch 014:   1251 / 1474 loss=2.037, trans_loss=4.999, nll_loss=2.265, w2v_ctc_loss=0.761, task_loss=1.099, task_loss_gen=2.312, contrastive_loss=0, total=4028.78, n_correct=2556.34, ppl=4.81, accuracy=63.452, wps=13201.4, ups=1.64, wpb=8057.6, bsz=274.5, num_updates=20400, lr=9.90148e-05, gnorm=0.686, clip=0, loss_scale=4, train_wall=60, gb_free=15.5, wall=0
2023-09-04 02:12:21 | INFO | train_inner | epoch 014:   1351 / 1474 loss=2.016, trans_loss=4.985, nll_loss=2.249, w2v_ctc_loss=0.738, task_loss=0.76, task_loss_gen=2.025, contrastive_loss=0, total=4193.2, n_correct=2679.52, ppl=4.75, accuracy=63.902, wps=13792.3, ups=1.64, wpb=8386.4, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=0.539, clip=0, loss_scale=4, train_wall=60, gb_free=16.7, wall=0
2023-09-04 02:13:23 | INFO | train_inner | epoch 014:   1451 / 1474 loss=2.025, trans_loss=4.992, nll_loss=2.258, w2v_ctc_loss=0.748, task_loss=0.775, task_loss_gen=2.174, contrastive_loss=0, total=4132.58, n_correct=2633.26, ppl=4.78, accuracy=63.72, wps=13483.9, ups=1.63, wpb=8265.2, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=61, gb_free=16.3, wall=0
2023-09-04 02:13:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
2023-09-04 02:14:10 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.928 | trans_loss 5.226 | nll_loss 2.508 | w2v_ctc_loss 1.316 | task_loss 5.505 | task_loss_gen 5.073 | contrastive_loss 0 | total 4003.4 | n_correct 2624.4 | ppl 5.69 | accuracy 65.554 | uer 18.093 | wer 19.731 | raw_wer 19.731 | bleu 20.97 | wps 1613 | wpb 4003.4 | bsz 141.8 | num_updates 20623 | best_bleu 21.15
2023-09-04 02:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20623 updates
2023-09-04 02:14:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_20.9709.pt
2023-09-04 02:14:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_20.9709.pt
2023-09-04 02:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_20.9709.pt (epoch 14 @ 20623 updates, score 20.97) (writing took 7.194573490996845 seconds)
2023-09-04 02:14:17 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-04 02:14:17 | INFO | train | epoch 014 | loss 2.023 | trans_loss 4.987 | nll_loss 2.251 | w2v_ctc_loss 0.747 | task_loss 0.9 | task_loss_gen 2.087 | contrastive_loss 0 | total 4138.65 | n_correct 2636.74 | ppl 4.76 | accuracy 63.71 | wps 12223.2 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 20623 | lr 9.8478e-05 | gnorm 0.641 | clip 0 | loss_scale 4 | train_wall 893 | gb_free 16 | wall 0
2023-09-04 02:14:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 02:14:17 | INFO | fairseq.trainer | begin training epoch 15
2023-09-04 02:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 02:15:12 | INFO | train_inner | epoch 015:     77 / 1474 loss=2.012, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.737, task_loss=0.775, task_loss_gen=2.177, contrastive_loss=0, total=4093.65, n_correct=2622.19, ppl=4.68, accuracy=64.055, wps=7491.7, ups=0.92, wpb=8187.3, bsz=302.1, num_updates=20700, lr=9.82946e-05, gnorm=0.559, clip=0, loss_scale=4, train_wall=60, gb_free=16, wall=0
2023-09-04 02:16:13 | INFO | train_inner | epoch 015:    177 / 1474 loss=2.01, trans_loss=4.961, nll_loss=2.218, w2v_ctc_loss=0.74, task_loss=0.732, task_loss_gen=2.298, contrastive_loss=0, total=4112.43, n_correct=2645.16, ppl=4.65, accuracy=64.321, wps=13479.9, ups=1.64, wpb=8224.9, bsz=298, num_updates=20800, lr=9.80581e-05, gnorm=0.54, clip=0, loss_scale=4, train_wall=60, gb_free=15.7, wall=0
2023-09-04 02:17:14 | INFO | train_inner | epoch 015:    277 / 1474 loss=2.005, trans_loss=4.963, nll_loss=2.22, w2v_ctc_loss=0.732, task_loss=0.753, task_loss_gen=2.179, contrastive_loss=0, total=4185.73, n_correct=2695, ppl=4.66, accuracy=64.385, wps=13753.3, ups=1.64, wpb=8371.5, bsz=311, num_updates=20900, lr=9.78232e-05, gnorm=0.565, clip=0, loss_scale=4, train_wall=60, gb_free=12.8, wall=0
2023-09-04 02:18:15 | INFO | train_inner | epoch 015:    377 / 1474 loss=2.005, trans_loss=4.955, nll_loss=2.21, w2v_ctc_loss=0.73, task_loss=0.782, task_loss_gen=2.172, contrastive_loss=0, total=4173.44, n_correct=2684.86, ppl=4.63, accuracy=64.332, wps=13650, ups=1.64, wpb=8346.9, bsz=307.4, num_updates=21000, lr=9.759e-05, gnorm=0.583, clip=0, loss_scale=4, train_wall=60, gb_free=14.6, wall=0
2023-09-04 02:19:16 | INFO | train_inner | epoch 015:    477 / 1474 loss=2.011, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.734, task_loss=0.713, task_loss_gen=2.305, contrastive_loss=0, total=4076.89, n_correct=2615, ppl=4.67, accuracy=64.142, wps=13331.8, ups=1.64, wpb=8153.8, bsz=294.4, num_updates=21100, lr=9.73585e-05, gnorm=0.565, clip=0, loss_scale=4, train_wall=60, gb_free=16.4, wall=0
2023-09-04 02:20:18 | INFO | train_inner | epoch 015:    577 / 1474 loss=2.01, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.738, task_loss=0.721, task_loss_gen=2.306, contrastive_loss=0, total=4145.22, n_correct=2662.49, ppl=4.66, accuracy=64.23, wps=13328.8, ups=1.61, wpb=8290.4, bsz=300.4, num_updates=21200, lr=9.71286e-05, gnorm=0.577, clip=0, loss_scale=4, train_wall=62, gb_free=16.6, wall=0
2023-09-04 02:21:20 | INFO | train_inner | epoch 015:    677 / 1474 loss=2.01, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.738, task_loss=0.783, task_loss_gen=2.107, contrastive_loss=0, total=4127.9, n_correct=2650.5, ppl=4.65, accuracy=64.209, wps=13466.7, ups=1.63, wpb=8255.8, bsz=304.9, num_updates=21300, lr=9.69003e-05, gnorm=0.569, clip=0, loss_scale=4, train_wall=61, gb_free=16.6, wall=0
2023-09-04 02:22:21 | INFO | train_inner | epoch 015:    777 / 1474 loss=2.012, trans_loss=4.968, nll_loss=2.227, w2v_ctc_loss=0.739, task_loss=0.694, task_loss_gen=2.18, contrastive_loss=0, total=4182.81, n_correct=2681.98, ppl=4.68, accuracy=64.119, wps=13604.8, ups=1.63, wpb=8365.6, bsz=306.5, num_updates=21400, lr=9.66736e-05, gnorm=0.555, clip=0, loss_scale=4, train_wall=61, gb_free=12.6, wall=0
2023-09-04 02:23:22 | INFO | train_inner | epoch 015:    877 / 1474 loss=2.014, trans_loss=4.965, nll_loss=2.224, w2v_ctc_loss=0.742, task_loss=0.803, task_loss_gen=2.284, contrastive_loss=0, total=4047.26, n_correct=2597.47, ppl=4.67, accuracy=64.178, wps=13313.6, ups=1.64, wpb=8094.5, bsz=286.2, num_updates=21500, lr=9.64486e-05, gnorm=0.588, clip=0, loss_scale=4, train_wall=60, gb_free=14.8, wall=0
2023-09-04 02:24:23 | INFO | train_inner | epoch 015:    977 / 1474 loss=2.007, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.731, task_loss=0.706, task_loss_gen=2.135, contrastive_loss=0, total=4140.07, n_correct=2659.99, ppl=4.67, accuracy=64.25, wps=13554.2, ups=1.64, wpb=8280.1, bsz=304.7, num_updates=21600, lr=9.6225e-05, gnorm=0.573, clip=0, loss_scale=4, train_wall=60, gb_free=15.1, wall=0
2023-09-04 02:25:26 | INFO | train_inner | epoch 015:   1077 / 1474 loss=2.003, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.727, task_loss=0.708, task_loss_gen=1.935, contrastive_loss=0, total=4182.98, n_correct=2689.15, ppl=4.68, accuracy=64.288, wps=13308.3, ups=1.59, wpb=8366, bsz=325, num_updates=21700, lr=9.60031e-05, gnorm=0.565, clip=0, loss_scale=4, train_wall=62, gb_free=12.9, wall=0
2023-09-04 02:26:27 | INFO | train_inner | epoch 015:   1177 / 1474 loss=1.996, trans_loss=4.96, nll_loss=2.218, w2v_ctc_loss=0.721, task_loss=0.622, task_loss_gen=1.966, contrastive_loss=0, total=4187.88, n_correct=2697.48, ppl=4.65, accuracy=64.412, wps=13651.1, ups=1.63, wpb=8375.8, bsz=329.1, num_updates=21800, lr=9.57826e-05, gnorm=0.559, clip=0, loss_scale=4, train_wall=61, gb_free=16.6, wall=0
2023-09-04 02:27:29 | INFO | train_inner | epoch 015:   1277 / 1474 loss=2.01, trans_loss=4.958, nll_loss=2.214, w2v_ctc_loss=0.744, task_loss=0.741, task_loss_gen=2.161, contrastive_loss=0, total=4136.5, n_correct=2658.05, ppl=4.64, accuracy=64.258, wps=13516.9, ups=1.63, wpb=8273, bsz=300.6, num_updates=21900, lr=9.55637e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=60, gb_free=11.8, wall=0
2023-09-04 02:28:30 | INFO | train_inner | epoch 015:   1377 / 1474 loss=2.012, trans_loss=4.963, nll_loss=2.221, w2v_ctc_loss=0.742, task_loss=0.672, task_loss_gen=2.258, contrastive_loss=0, total=4103.74, n_correct=2637.11, ppl=4.66, accuracy=64.261, wps=13422, ups=1.64, wpb=8207.5, bsz=294.1, num_updates=22000, lr=9.53463e-05, gnorm=0.568, clip=0, loss_scale=4, train_wall=60, gb_free=16, wall=0
2023-09-04 02:28:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 02:29:02 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.916 | trans_loss 5.212 | nll_loss 2.485 | w2v_ctc_loss 1.309 | task_loss 3.34 | task_loss_gen 5.584 | contrastive_loss 0 | total 4003.4 | n_correct 2631.6 | ppl 5.6 | accuracy 65.734 | uer 17.798 | wer 19.544 | raw_wer 19.544 | bleu 20.86 | wps 1641.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.15
2023-09-04 02:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-09-04 02:29:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_15_22000.pt
2023-09-04 02:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_15_22000.pt
2023-09-04 02:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 20.86) (writing took 7.967823981016409 seconds)
2023-09-04 02:30:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 02:30:44 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.924 | trans_loss 5.211 | nll_loss 2.489 | w2v_ctc_loss 1.338 | task_loss 2.08 | task_loss_gen 6.219 | contrastive_loss 0 | total 4003.4 | n_correct 2626.1 | ppl 5.61 | accuracy 65.597 | uer 18.395 | wer 20.092 | raw_wer 20.092 | bleu 21.03 | wps 1634.6 | wpb 4003.4 | bsz 141.8 | num_updates 22097 | best_bleu 21.15
2023-09-04 02:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22097 updates
2023-09-04 02:30:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.0308.pt
2023-09-04 02:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.0308.pt
2023-09-04 02:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.0308.pt (epoch 15 @ 22097 updates, score 21.03) (writing took 7.981012404023204 seconds)
2023-09-04 02:30:53 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-04 02:30:53 | INFO | train | epoch 015 | loss 2.008 | trans_loss 4.963 | nll_loss 2.22 | w2v_ctc_loss 0.735 | task_loss 0.723 | task_loss_gen 2.159 | contrastive_loss 0 | total 4138.65 | n_correct 2659.5 | ppl 4.66 | accuracy 64.26 | wps 12256.9 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 22097 | lr 9.51368e-05 | gnorm 0.568 | clip 0 | loss_scale 4 | train_wall 894 | gb_free 16.6 | wall 0
2023-09-04 02:30:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 02:30:53 | INFO | fairseq.trainer | begin training epoch 16
2023-09-04 02:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 02:31:02 | INFO | train_inner | epoch 016:      3 / 1474 loss=2.007, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.734, task_loss=0.673, task_loss_gen=2.011, contrastive_loss=0, total=4154.85, n_correct=2669.34, ppl=4.69, accuracy=64.246, wps=5458.7, ups=0.66, wpb=8309.7, bsz=316.5, num_updates=22100, lr=9.51303e-05, gnorm=0.583, clip=0, loss_scale=4, train_wall=61, gb_free=16.4, wall=0
2023-09-04 02:32:03 | INFO | train_inner | epoch 016:    103 / 1474 loss=1.992, trans_loss=4.941, nll_loss=2.192, w2v_ctc_loss=0.723, task_loss=0.665, task_loss_gen=1.987, contrastive_loss=0, total=4116.45, n_correct=2664.33, ppl=4.57, accuracy=64.724, wps=13459.7, ups=1.63, wpb=8232.9, bsz=314.3, num_updates=22200, lr=9.49158e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=60, gb_free=16.7, wall=0
2023-09-04 02:33:05 | INFO | train_inner | epoch 016:    203 / 1474 loss=1.984, trans_loss=4.929, nll_loss=2.176, w2v_ctc_loss=0.706, task_loss=0.735, task_loss_gen=2.2, contrastive_loss=0, total=4112.07, n_correct=2671.4, ppl=4.52, accuracy=64.965, wps=13360.4, ups=1.62, wpb=8224.1, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.601, clip=0, loss_scale=4, train_wall=61, gb_free=16.6, wall=0
2023-09-04 02:34:06 | INFO | train_inner | epoch 016:    303 / 1474 loss=1.998, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.728, task_loss=0.706, task_loss_gen=1.996, contrastive_loss=0, total=4160.84, n_correct=2687.89, ppl=4.58, accuracy=64.6, wps=13565.1, ups=1.63, wpb=8321.7, bsz=308.1, num_updates=22400, lr=9.44911e-05, gnorm=0.572, clip=0, loss_scale=4, train_wall=61, gb_free=16.7, wall=0
2023-09-04 02:35:07 | INFO | train_inner | epoch 016:    403 / 1474 loss=2.001, trans_loss=4.94, nll_loss=2.19, w2v_ctc_loss=0.732, task_loss=0.642, task_loss_gen=2.456, contrastive_loss=0, total=4066.97, n_correct=2629.49, ppl=4.56, accuracy=64.655, wps=13432.3, ups=1.65, wpb=8133.9, bsz=287, num_updates=22500, lr=9.42809e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=60, gb_free=14.4, wall=0
2023-09-04 02:36:08 | INFO | train_inner | epoch 016:    503 / 1474 loss=1.992, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.722, task_loss=0.626, task_loss_gen=2.127, contrastive_loss=0, total=4168.86, n_correct=2701.87, ppl=4.58, accuracy=64.811, wps=13489.5, ups=1.62, wpb=8337.7, bsz=318.4, num_updates=22600, lr=9.40721e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=61, gb_free=16.1, wall=0
2023-09-04 02:37:10 | INFO | train_inner | epoch 016:    603 / 1474 loss=1.99, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.718, task_loss=0.552, task_loss_gen=2.336, contrastive_loss=0, total=4132.12, n_correct=2681.27, ppl=4.55, accuracy=64.888, wps=13531, ups=1.64, wpb=8264.2, bsz=300.3, num_updates=22700, lr=9.38647e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=60, gb_free=15.8, wall=0
2023-09-04 02:38:11 | INFO | train_inner | epoch 016:    703 / 1474 loss=1.993, trans_loss=4.938, nll_loss=2.188, w2v_ctc_loss=0.725, task_loss=0.576, task_loss_gen=2.397, contrastive_loss=0, total=4102.33, n_correct=2658.49, ppl=4.56, accuracy=64.804, wps=13386.5, ups=1.63, wpb=8204.7, bsz=298.1, num_updates=22800, lr=9.36586e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=60, gb_free=15.9, wall=0
2023-09-04 02:39:12 | INFO | train_inner | epoch 016:    803 / 1474 loss=1.986, trans_loss=4.936, nll_loss=2.186, w2v_ctc_loss=0.712, task_loss=0.6, task_loss_gen=2.264, contrastive_loss=0, total=4176.5, n_correct=2709.71, ppl=4.55, accuracy=64.88, wps=13685.4, ups=1.64, wpb=8353, bsz=311.3, num_updates=22900, lr=9.34539e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=0
2023-09-04 02:40:13 | INFO | train_inner | epoch 016:    903 / 1474 loss=1.989, trans_loss=4.937, nll_loss=2.188, w2v_ctc_loss=0.717, task_loss=0.579, task_loss_gen=2.286, contrastive_loss=0, total=4150.45, n_correct=2690.85, ppl=4.56, accuracy=64.833, wps=13545, ups=1.63, wpb=8300.9, bsz=305.8, num_updates=23000, lr=9.32505e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=61, gb_free=11.3, wall=0
2023-09-04 02:41:15 | INFO | train_inner | epoch 016:   1003 / 1474 loss=2.001, trans_loss=4.947, nll_loss=2.2, w2v_ctc_loss=0.735, task_loss=0.583, task_loss_gen=2.45, contrastive_loss=0, total=4118.26, n_correct=2660.93, ppl=4.6, accuracy=64.613, wps=13417.9, ups=1.63, wpb=8236.5, bsz=301.7, num_updates=23100, lr=9.30484e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=16.1, wall=0
2023-09-04 02:42:17 | INFO | train_inner | epoch 016:   1103 / 1474 loss=2.004, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.737, task_loss=0.562, task_loss_gen=2.446, contrastive_loss=0, total=4113.57, n_correct=2652.55, ppl=4.61, accuracy=64.483, wps=13279.8, ups=1.61, wpb=8227.1, bsz=296.2, num_updates=23200, lr=9.28477e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=61, gb_free=16.7, wall=0
2023-09-04 02:43:19 | INFO | train_inner | epoch 016:   1203 / 1474 loss=1.994, trans_loss=4.945, nll_loss=2.199, w2v_ctc_loss=0.716, task_loss=0.635, task_loss_gen=2.334, contrastive_loss=0, total=4157.18, n_correct=2683.02, ppl=4.59, accuracy=64.539, wps=13308.5, ups=1.6, wpb=8314.4, bsz=306.3, num_updates=23300, lr=9.26482e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=62, gb_free=16.1, wall=0
2023-09-04 02:44:20 | INFO | train_inner | epoch 016:   1303 / 1474 loss=1.997, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.734, task_loss=0.549, task_loss_gen=2.224, contrastive_loss=0, total=4150.54, n_correct=2685.4, ppl=4.58, accuracy=64.7, wps=13506.3, ups=1.63, wpb=8301.1, bsz=312.3, num_updates=23400, lr=9.245e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=61, gb_free=12.4, wall=0
2023-09-04 02:45:22 | INFO | train_inner | epoch 016:   1403 / 1474 loss=1.992, trans_loss=4.941, nll_loss=2.194, w2v_ctc_loss=0.728, task_loss=0.577, task_loss_gen=2.162, contrastive_loss=0, total=4198.78, n_correct=2720.76, ppl=4.57, accuracy=64.799, wps=13698.3, ups=1.63, wpb=8397.6, bsz=322.4, num_updates=23500, lr=9.22531e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=61, gb_free=17.4, wall=0
2023-09-04 02:46:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 02:46:38 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.911 | trans_loss 5.203 | nll_loss 2.476 | w2v_ctc_loss 1.312 | task_loss 3.627 | task_loss_gen 6.275 | contrastive_loss 0 | total 4003.4 | n_correct 2633.7 | ppl 5.56 | accuracy 65.787 | uer 17.639 | wer 19.28 | raw_wer 19.28 | bleu 21.25 | wps 1645.4 | wpb 4003.4 | bsz 141.8 | num_updates 23571 | best_bleu 21.25
2023-09-04 02:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23571 updates
2023-09-04 02:46:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 02:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 02:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 16 @ 23571 updates, score 21.25) (writing took 14.112586836039554 seconds)
2023-09-04 02:46:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-04 02:46:53 | INFO | train | epoch 016 | loss 1.994 | trans_loss 4.941 | nll_loss 2.192 | w2v_ctc_loss 0.724 | task_loss 0.614 | task_loss_gen 2.26 | contrastive_loss 0 | total 4138.65 | n_correct 2679.08 | ppl 4.57 | accuracy 64.733 | wps 12710.7 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 23571 | lr 9.21141e-05 | gnorm 0.55 | clip 0 | loss_scale 8 | train_wall 894 | gb_free 15.1 | wall 0
2023-09-04 02:46:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 02:46:53 | INFO | fairseq.trainer | begin training epoch 17
2023-09-04 02:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 02:47:18 | INFO | train_inner | epoch 017:     29 / 1474 loss=1.986, trans_loss=4.926, nll_loss=2.173, w2v_ctc_loss=0.713, task_loss=0.611, task_loss_gen=2.349, contrastive_loss=0, total=4138.06, n_correct=2686.32, ppl=4.51, accuracy=64.917, wps=7128.8, ups=0.86, wpb=8276.1, bsz=300.4, num_updates=23600, lr=9.20575e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=17.4, wall=0
2023-09-04 02:48:19 | INFO | train_inner | epoch 017:    129 / 1474 loss=1.987, trans_loss=4.918, nll_loss=2.162, w2v_ctc_loss=0.723, task_loss=0.476, task_loss_gen=2.419, contrastive_loss=0, total=4110.37, n_correct=2677.34, ppl=4.47, accuracy=65.136, wps=13370.3, ups=1.63, wpb=8220.7, bsz=295.6, num_updates=23700, lr=9.1863e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=61, gb_free=16.2, wall=0
2023-09-04 02:49:21 | INFO | train_inner | epoch 017:    229 / 1474 loss=1.977, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.707, task_loss=0.441, task_loss_gen=2.148, contrastive_loss=0, total=4181.59, n_correct=2723.72, ppl=4.47, accuracy=65.136, wps=13584.2, ups=1.62, wpb=8363.2, bsz=322.2, num_updates=23800, lr=9.16698e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=61, gb_free=15.4, wall=0
2023-09-04 02:50:22 | INFO | train_inner | epoch 017:    329 / 1474 loss=1.984, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.713, task_loss=0.648, task_loss_gen=2.314, contrastive_loss=0, total=4157.97, n_correct=2707.94, ppl=4.49, accuracy=65.126, wps=13555.7, ups=1.63, wpb=8315.9, bsz=304, num_updates=23900, lr=9.14779e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=60, gb_free=15.5, wall=0
2023-09-04 02:51:24 | INFO | train_inner | epoch 017:    429 / 1474 loss=1.982, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.715, task_loss=0.592, task_loss_gen=2.231, contrastive_loss=0, total=4135.12, n_correct=2698.34, ppl=4.49, accuracy=65.254, wps=13473.6, ups=1.63, wpb=8270.2, bsz=306.1, num_updates=24000, lr=9.12871e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=61, gb_free=12.2, wall=0
2023-09-04 02:51:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 02:51:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.918 | trans_loss 5.203 | nll_loss 2.473 | w2v_ctc_loss 1.333 | task_loss 2.034 | task_loss_gen 6.915 | contrastive_loss 0 | total 4003.4 | n_correct 2634.3 | ppl 5.55 | accuracy 65.802 | uer 17.941 | wer 19.72 | raw_wer 19.72 | bleu 21.09 | wps 1556.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.25
2023-09-04 02:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-09-04 02:51:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_17_24000.pt
2023-09-04 02:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_17_24000.pt
2023-09-04 02:52:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.09) (writing took 10.031379494990688 seconds)
2023-09-04 02:53:10 | INFO | train_inner | epoch 017:    529 / 1474 loss=1.986, trans_loss=4.926, nll_loss=2.173, w2v_ctc_loss=0.719, task_loss=0.548, task_loss_gen=2.284, contrastive_loss=0, total=4185.81, n_correct=2721.34, ppl=4.51, accuracy=65.013, wps=7896.6, ups=0.94, wpb=8371.6, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=61, gb_free=15.8, wall=0
2023-09-04 02:54:11 | INFO | train_inner | epoch 017:    629 / 1474 loss=1.981, trans_loss=4.923, nll_loss=2.17, w2v_ctc_loss=0.711, task_loss=0.553, task_loss_gen=2.237, contrastive_loss=0, total=4168.62, n_correct=2717.45, ppl=4.5, accuracy=65.188, wps=13560.8, ups=1.63, wpb=8337.2, bsz=303.2, num_updates=24200, lr=9.09091e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=61, gb_free=13.9, wall=0
2023-09-04 02:55:13 | INFO | train_inner | epoch 017:    729 / 1474 loss=1.99, trans_loss=4.927, nll_loss=2.174, w2v_ctc_loss=0.729, task_loss=0.516, task_loss_gen=2.193, contrastive_loss=0, total=4167.34, n_correct=2710.43, ppl=4.51, accuracy=65.04, wps=13468.6, ups=1.62, wpb=8334.7, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=61, gb_free=9.5, wall=0
2023-09-04 02:56:14 | INFO | train_inner | epoch 017:    829 / 1474 loss=1.985, trans_loss=4.924, nll_loss=2.17, w2v_ctc_loss=0.72, task_loss=0.446, task_loss_gen=2.28, contrastive_loss=0, total=4092.64, n_correct=2665.76, ppl=4.5, accuracy=65.135, wps=13462.4, ups=1.64, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=60, gb_free=15.4, wall=0
2023-09-04 02:57:14 | INFO | train_inner | epoch 017:    929 / 1474 loss=1.979, trans_loss=4.92, nll_loss=2.166, w2v_ctc_loss=0.71, task_loss=0.472, task_loss_gen=2.153, contrastive_loss=0, total=4109.5, n_correct=2681.44, ppl=4.49, accuracy=65.25, wps=13695.5, ups=1.67, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=59, gb_free=16.3, wall=0
2023-09-04 02:58:15 | INFO | train_inner | epoch 017:   1029 / 1474 loss=1.981, trans_loss=4.921, nll_loss=2.168, w2v_ctc_loss=0.715, task_loss=0.516, task_loss_gen=2.3, contrastive_loss=0, total=4098.36, n_correct=2667.32, ppl=4.49, accuracy=65.083, wps=13436.5, ups=1.64, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=0
2023-09-04 02:59:16 | INFO | train_inner | epoch 017:   1129 / 1474 loss=1.973, trans_loss=4.915, nll_loss=2.159, w2v_ctc_loss=0.697, task_loss=0.447, task_loss_gen=2.397, contrastive_loss=0, total=4100.14, n_correct=2678.64, ppl=4.47, accuracy=65.33, wps=13411.8, ups=1.64, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=0
2023-09-04 03:00:19 | INFO | train_inner | epoch 017:   1229 / 1474 loss=1.984, trans_loss=4.932, nll_loss=2.183, w2v_ctc_loss=0.708, task_loss=0.343, task_loss_gen=2.446, contrastive_loss=0, total=4173.98, n_correct=2705.47, ppl=4.54, accuracy=64.818, wps=13351.2, ups=1.6, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=62, gb_free=15.6, wall=0
2023-09-04 03:01:20 | INFO | train_inner | epoch 017:   1329 / 1474 loss=1.983, trans_loss=4.923, nll_loss=2.17, w2v_ctc_loss=0.715, task_loss=0.344, task_loss_gen=2.622, contrastive_loss=0, total=4146.07, n_correct=2703.27, ppl=4.5, accuracy=65.201, wps=13545.4, ups=1.63, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=0
2023-09-04 03:02:21 | INFO | train_inner | epoch 017:   1429 / 1474 loss=1.983, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.717, task_loss=0.327, task_loss_gen=2.692, contrastive_loss=0, total=4119.23, n_correct=2683.02, ppl=4.51, accuracy=65.134, wps=13396.2, ups=1.63, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=61, gb_free=12.8, wall=0
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 03:02:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
2023-09-04 03:03:22 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.912 | trans_loss 5.19 | nll_loss 2.462 | w2v_ctc_loss 1.346 | task_loss 2.712 | task_loss_gen 7.841 | contrastive_loss 0 | total 4003.4 | n_correct 2638.8 | ppl 5.51 | accuracy 65.914 | uer 17.875 | wer 19.526 | raw_wer 19.526 | bleu 21.16 | wps 1644.2 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 21.25
2023-09-04 03:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-09-04 03:03:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.1605.pt
2023-09-04 03:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.1605.pt
2023-09-04 03:03:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.1605.pt (epoch 17 @ 25045 updates, score 21.16) (writing took 7.303401264012791 seconds)
2023-09-04 03:03:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-04 03:03:30 | INFO | train | epoch 017 | loss 1.982 | trans_loss 4.922 | nll_loss 2.168 | w2v_ctc_loss 0.714 | task_loss 0.475 | task_loss_gen 2.349 | contrastive_loss 0 | total 4138.65 | n_correct 2695.94 | ppl 4.49 | accuracy 65.141 | wps 12236 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.534 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 16.1 | wall 0
2023-09-04 03:03:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 03:03:30 | INFO | fairseq.trainer | begin training epoch 18
2023-09-04 03:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 03:04:12 | INFO | train_inner | epoch 018:     55 / 1474 loss=1.98, trans_loss=4.913, nll_loss=2.157, w2v_ctc_loss=0.718, task_loss=0.389, task_loss_gen=2.741, contrastive_loss=0, total=4128.93, n_correct=2698.53, ppl=4.46, accuracy=65.357, wps=7484.3, ups=0.91, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=0
2023-09-04 03:05:13 | INFO | train_inner | epoch 018:    155 / 1474 loss=1.962, trans_loss=4.894, nll_loss=2.133, w2v_ctc_loss=0.689, task_loss=0.287, task_loss_gen=2.676, contrastive_loss=0, total=4158.38, n_correct=2733.74, ppl=4.39, accuracy=65.741, wps=13536.1, ups=1.63, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=0
2023-09-04 03:06:15 | INFO | train_inner | epoch 018:    255 / 1474 loss=1.963, trans_loss=4.893, nll_loss=2.131, w2v_ctc_loss=0.697, task_loss=0.445, task_loss_gen=2.84, contrastive_loss=0, total=4161.92, n_correct=2739.52, ppl=4.38, accuracy=65.823, wps=13486.3, ups=1.62, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=0
2023-09-04 03:06:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-04 03:07:17 | INFO | train_inner | epoch 018:    356 / 1474 loss=1.97, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.698, task_loss=0.406, task_loss_gen=2.457, contrastive_loss=0, total=4166.95, n_correct=2729.16, ppl=4.42, accuracy=65.495, wps=13374.4, ups=1.6, wpb=8333.9, bsz=299.7, num_updates=25400, lr=8.87357e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=62, gb_free=16.2, wall=0
2023-09-04 03:08:19 | INFO | train_inner | epoch 018:    456 / 1474 loss=1.978, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.709, task_loss=0.436, task_loss_gen=2.433, contrastive_loss=0, total=4069.37, n_correct=2656.94, ppl=4.44, accuracy=65.291, wps=13163.8, ups=1.62, wpb=8138.7, bsz=293.6, num_updates=25500, lr=8.85615e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=61, gb_free=15.2, wall=0
2023-09-04 03:09:20 | INFO | train_inner | epoch 018:    556 / 1474 loss=1.958, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.694, task_loss=0.351, task_loss_gen=2.001, contrastive_loss=0, total=4224.88, n_correct=2785.38, ppl=4.37, accuracy=65.928, wps=13814.3, ups=1.63, wpb=8449.8, bsz=330.4, num_updates=25600, lr=8.83883e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=60, gb_free=16.5, wall=0
2023-09-04 03:10:21 | INFO | train_inner | epoch 018:    656 / 1474 loss=1.979, trans_loss=4.913, nll_loss=2.156, w2v_ctc_loss=0.711, task_loss=0.487, task_loss_gen=2.268, contrastive_loss=0, total=4087.72, n_correct=2670.38, ppl=4.46, accuracy=65.327, wps=13370.6, ups=1.64, wpb=8175.4, bsz=298.1, num_updates=25700, lr=8.82162e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=0
2023-09-04 03:11:23 | INFO | train_inner | epoch 018:    756 / 1474 loss=1.975, trans_loss=4.91, nll_loss=2.153, w2v_ctc_loss=0.712, task_loss=0.459, task_loss_gen=2.008, contrastive_loss=0, total=4202.56, n_correct=2748.58, ppl=4.45, accuracy=65.403, wps=13648.3, ups=1.62, wpb=8405.1, bsz=322.9, num_updates=25800, lr=8.80451e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=61, gb_free=17.5, wall=0
2023-09-04 03:12:24 | INFO | train_inner | epoch 018:    856 / 1474 loss=1.974, trans_loss=4.908, nll_loss=2.151, w2v_ctc_loss=0.706, task_loss=0.446, task_loss_gen=2.171, contrastive_loss=0, total=4181.64, n_correct=2737.16, ppl=4.44, accuracy=65.457, wps=13659.4, ups=1.63, wpb=8363.3, bsz=306.1, num_updates=25900, lr=8.7875e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=60, gb_free=15.3, wall=0
2023-09-04 03:13:25 | INFO | train_inner | epoch 018:    956 / 1474 loss=1.962, trans_loss=4.899, nll_loss=2.139, w2v_ctc_loss=0.691, task_loss=0.437, task_loss_gen=1.91, contrastive_loss=0, total=4133.45, n_correct=2715.86, ppl=4.4, accuracy=65.704, wps=13664.9, ups=1.65, wpb=8266.9, bsz=312.7, num_updates=26000, lr=8.77058e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=60, gb_free=14.2, wall=0
2023-09-04 03:13:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:13:58 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.189 | nll_loss 2.458 | w2v_ctc_loss 1.291 | task_loss 4.344 | task_loss_gen 5.785 | contrastive_loss 0 | total 4003.4 | n_correct 2641.5 | ppl 5.5 | accuracy 65.981 | uer 17.716 | wer 19.455 | raw_wer 19.455 | bleu 21.41 | wps 1585 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 21.41
2023-09-04 03:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-09-04 03:13:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_18_26000.pt
2023-09-04 03:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_18_26000.pt
2023-09-04 03:14:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.41) (writing took 13.442463618994225 seconds)
2023-09-04 03:15:14 | INFO | train_inner | epoch 018:   1056 / 1474 loss=1.973, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.701, task_loss=0.429, task_loss_gen=2.25, contrastive_loss=0, total=4133.66, n_correct=2708.84, ppl=4.43, accuracy=65.531, wps=7556.2, ups=0.91, wpb=8267.3, bsz=298.3, num_updates=26100, lr=8.75376e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=61, gb_free=16.6, wall=0
2023-09-04 03:16:15 | INFO | train_inner | epoch 018:   1156 / 1474 loss=1.965, trans_loss=4.897, nll_loss=2.137, w2v_ctc_loss=0.699, task_loss=0.412, task_loss_gen=1.973, contrastive_loss=0, total=4156.35, n_correct=2729.63, ppl=4.4, accuracy=65.674, wps=13612, ups=1.64, wpb=8312.7, bsz=315.8, num_updates=26200, lr=8.73704e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=60, gb_free=13.4, wall=0
2023-09-04 03:17:17 | INFO | train_inner | epoch 018:   1256 / 1474 loss=1.976, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.705, task_loss=0.472, task_loss_gen=2.172, contrastive_loss=0, total=4093.35, n_correct=2674.46, ppl=4.45, accuracy=65.337, wps=13339.5, ups=1.63, wpb=8186.7, bsz=288, num_updates=26300, lr=8.72041e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=60, gb_free=15.8, wall=0
2023-09-04 03:18:18 | INFO | train_inner | epoch 018:   1356 / 1474 loss=1.986, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.725, task_loss=0.464, task_loss_gen=2.243, contrastive_loss=0, total=4056.71, n_correct=2641.98, ppl=4.47, accuracy=65.126, wps=13191.8, ups=1.63, wpb=8113.4, bsz=289.2, num_updates=26400, lr=8.70388e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=61, gb_free=16.9, wall=0
2023-09-04 03:19:20 | INFO | train_inner | epoch 018:   1456 / 1474 loss=1.979, trans_loss=4.913, nll_loss=2.156, w2v_ctc_loss=0.715, task_loss=0.485, task_loss_gen=2.103, contrastive_loss=0, total=4125.39, n_correct=2699.01, ppl=4.46, accuracy=65.424, wps=13417, ups=1.63, wpb=8250.8, bsz=299, num_updates=26500, lr=8.68744e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=61, gb_free=15.8, wall=0
2023-09-04 03:19:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:20:04 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.907 | trans_loss 5.192 | nll_loss 2.465 | w2v_ctc_loss 1.322 | task_loss 3.865 | task_loss_gen 6.22 | contrastive_loss 0 | total 4003.4 | n_correct 2642.2 | ppl 5.52 | accuracy 65.999 | uer 17.519 | wer 19.283 | raw_wer 19.283 | bleu 21.44 | wps 1595.3 | wpb 4003.4 | bsz 141.8 | num_updates 26518 | best_bleu 21.44
2023-09-04 03:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26518 updates
2023-09-04 03:20:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 03:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 03:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 18 @ 26518 updates, score 21.44) (writing took 12.098497961007524 seconds)
2023-09-04 03:20:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-04 03:20:17 | INFO | train | epoch 018 | loss 1.971 | trans_loss 4.905 | nll_loss 2.146 | w2v_ctc_loss 0.704 | task_loss 0.427 | task_loss_gen 2.262 | contrastive_loss 0 | total 4138.23 | n_correct 2711.23 | ppl 4.43 | accuracy 65.517 | wps 12105.7 | ups 1.46 | wpb 8276.5 | bsz 305.6 | num_updates 26518 | lr 8.6845e-05 | gnorm 0.535 | clip 0 | loss_scale 8 | train_wall 893 | gb_free 15.6 | wall 0
2023-09-04 03:20:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 03:20:17 | INFO | fairseq.trainer | begin training epoch 19
2023-09-04 03:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 03:21:14 | INFO | train_inner | epoch 019:     82 / 1474 loss=1.966, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.701, task_loss=0.428, task_loss_gen=1.971, contrastive_loss=0, total=4098.8, n_correct=2696.57, ppl=4.36, accuracy=65.789, wps=7162.6, ups=0.87, wpb=8197.6, bsz=296.6, num_updates=26600, lr=8.6711e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=0
2023-09-04 03:22:16 | INFO | train_inner | epoch 019:    182 / 1474 loss=1.956, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.695, task_loss=0.32, task_loss_gen=1.894, contrastive_loss=0, total=4227.47, n_correct=2790.03, ppl=4.34, accuracy=65.998, wps=13600.8, ups=1.61, wpb=8454.9, bsz=325, num_updates=26700, lr=8.65485e-05, gnorm=0.517, clip=0, loss_scale=8, train_wall=61, gb_free=15.9, wall=0
2023-09-04 03:23:18 | INFO | train_inner | epoch 019:    282 / 1474 loss=1.954, trans_loss=4.878, nll_loss=2.111, w2v_ctc_loss=0.687, task_loss=0.365, task_loss_gen=1.986, contrastive_loss=0, total=4188.96, n_correct=2768.9, ppl=4.32, accuracy=66.1, wps=13666.3, ups=1.63, wpb=8377.9, bsz=308.1, num_updates=26800, lr=8.63868e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=60, gb_free=16.5, wall=0
2023-09-04 03:24:19 | INFO | train_inner | epoch 019:    382 / 1474 loss=1.957, trans_loss=4.882, nll_loss=2.116, w2v_ctc_loss=0.687, task_loss=0.497, task_loss_gen=2.052, contrastive_loss=0, total=4168.76, n_correct=2746.23, ppl=4.34, accuracy=65.876, wps=13479.9, ups=1.62, wpb=8337.5, bsz=310.6, num_updates=26900, lr=8.62261e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=61, gb_free=14.2, wall=0
2023-09-04 03:25:21 | INFO | train_inner | epoch 019:    482 / 1474 loss=1.964, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.697, task_loss=0.444, task_loss_gen=2.101, contrastive_loss=0, total=4107.91, n_correct=2701.09, ppl=4.37, accuracy=65.753, wps=13424.2, ups=1.63, wpb=8215.8, bsz=299.6, num_updates=27000, lr=8.60663e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=60, gb_free=11.5, wall=0
2023-09-04 03:26:21 | INFO | train_inner | epoch 019:    582 / 1474 loss=1.96, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.691, task_loss=0.392, task_loss_gen=1.836, contrastive_loss=0, total=4133.95, n_correct=2721.6, ppl=4.36, accuracy=65.835, wps=13602.1, ups=1.65, wpb=8267.9, bsz=306.3, num_updates=27100, lr=8.59074e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=60, gb_free=15.6, wall=0
2023-09-04 03:27:22 | INFO | train_inner | epoch 019:    682 / 1474 loss=1.953, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.679, task_loss=0.356, task_loss_gen=1.734, contrastive_loss=0, total=4199.37, n_correct=2769.9, ppl=4.38, accuracy=65.96, wps=13836.4, ups=1.65, wpb=8398.7, bsz=321.7, num_updates=27200, lr=8.57493e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=60, gb_free=16.7, wall=0
2023-09-04 03:28:24 | INFO | train_inner | epoch 019:    782 / 1474 loss=1.967, trans_loss=4.89, nll_loss=2.126, w2v_ctc_loss=0.707, task_loss=0.32, task_loss_gen=2.044, contrastive_loss=0, total=4142.94, n_correct=2724.03, ppl=4.37, accuracy=65.751, wps=13492.4, ups=1.63, wpb=8285.9, bsz=305.4, num_updates=27300, lr=8.55921e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=60, gb_free=16.2, wall=0
2023-09-04 03:29:25 | INFO | train_inner | epoch 019:    882 / 1474 loss=1.969, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.702, task_loss=0.332, task_loss_gen=2.029, contrastive_loss=0, total=4153.23, n_correct=2725.48, ppl=4.4, accuracy=65.623, wps=13434.2, ups=1.62, wpb=8306.5, bsz=303.4, num_updates=27400, lr=8.54358e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=0
2023-09-04 03:30:28 | INFO | train_inner | epoch 019:    982 / 1474 loss=1.968, trans_loss=4.903, nll_loss=2.145, w2v_ctc_loss=0.694, task_loss=0.298, task_loss_gen=2.123, contrastive_loss=0, total=4102.27, n_correct=2688.27, ppl=4.42, accuracy=65.531, wps=13192.7, ups=1.61, wpb=8204.5, bsz=308.7, num_updates=27500, lr=8.52803e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=0
2023-09-04 03:31:29 | INFO | train_inner | epoch 019:   1082 / 1474 loss=1.969, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.699, task_loss=0.448, task_loss_gen=2.264, contrastive_loss=0, total=4036.79, n_correct=2650.49, ppl=4.41, accuracy=65.658, wps=13195.3, ups=1.63, wpb=8073.6, bsz=291.6, num_updates=27600, lr=8.51257e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=0
2023-09-04 03:32:30 | INFO | train_inner | epoch 019:   1182 / 1474 loss=1.969, trans_loss=4.899, nll_loss=2.139, w2v_ctc_loss=0.701, task_loss=0.289, task_loss_gen=2.221, contrastive_loss=0, total=4129.82, n_correct=2705.3, ppl=4.4, accuracy=65.506, wps=13406.1, ups=1.62, wpb=8259.6, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=0
2023-09-04 03:33:31 | INFO | train_inner | epoch 019:   1282 / 1474 loss=1.964, trans_loss=4.896, nll_loss=2.135, w2v_ctc_loss=0.693, task_loss=0.337, task_loss_gen=2.159, contrastive_loss=0, total=4147.96, n_correct=2725.01, ppl=4.39, accuracy=65.695, wps=13575.5, ups=1.64, wpb=8295.9, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=0
2023-09-04 03:34:33 | INFO | train_inner | epoch 019:   1382 / 1474 loss=1.966, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.7, task_loss=0.272, task_loss_gen=2.313, contrastive_loss=0, total=4125.32, n_correct=2711.61, ppl=4.38, accuracy=65.731, wps=13400.9, ups=1.62, wpb=8250.6, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=0
2023-09-04 03:35:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:36:03 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.18 | nll_loss 2.448 | w2v_ctc_loss 1.334 | task_loss 5.66 | task_loss_gen 6.918 | contrastive_loss 0 | total 4003.4 | n_correct 2655.8 | ppl 5.46 | accuracy 66.339 | uer 17.872 | wer 19.671 | raw_wer 19.671 | bleu 21.48 | wps 1650.6 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 21.48
2023-09-04 03:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-09-04 03:36:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 03:36:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 03:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 19 @ 27992 updates, score 21.48) (writing took 13.78394805296557 seconds)
2023-09-04 03:36:17 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-04 03:36:17 | INFO | train | epoch 019 | loss 1.962 | trans_loss 4.891 | nll_loss 2.128 | w2v_ctc_loss 0.695 | task_loss 0.366 | task_loss_gen 2.055 | contrastive_loss 0 | total 4138.65 | n_correct 2722.87 | ppl 4.37 | accuracy 65.791 | wps 12705.1 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.533 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 17 | wall 0
2023-09-04 03:36:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 03:36:17 | INFO | fairseq.trainer | begin training epoch 20
2023-09-04 03:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 03:36:30 | INFO | train_inner | epoch 020:      8 / 1474 loss=1.955, trans_loss=4.879, nll_loss=2.114, w2v_ctc_loss=0.688, task_loss=0.398, task_loss_gen=2.083, contrastive_loss=0, total=4124.63, n_correct=2723.89, ppl=4.33, accuracy=66.04, wps=7066.6, ups=0.86, wpb=8249.3, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=0
2023-09-04 03:36:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:37:03 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.188 | nll_loss 2.455 | w2v_ctc_loss 1.317 | task_loss 3.373 | task_loss_gen 7.695 | contrastive_loss 0 | total 4003.4 | n_correct 2652.3 | ppl 5.48 | accuracy 66.251 | uer 17.777 | wer 19.544 | raw_wer 19.544 | bleu 21.58 | wps 1638.8 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 21.58
2023-09-04 03:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-09-04 03:37:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_20_28000.pt
2023-09-04 03:37:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_20_28000.pt
2023-09-04 03:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.58) (writing took 13.433006793959066 seconds)
2023-09-04 03:38:17 | INFO | train_inner | epoch 020:    108 / 1474 loss=1.947, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.68, task_loss=0.341, task_loss_gen=1.959, contrastive_loss=0, total=4199.19, n_correct=2783.14, ppl=4.28, accuracy=66.278, wps=7800.4, ups=0.93, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=60, gb_free=14.4, wall=0
2023-09-04 03:39:19 | INFO | train_inner | epoch 020:    208 / 1474 loss=1.95, trans_loss=4.868, nll_loss=2.098, w2v_ctc_loss=0.683, task_loss=0.292, task_loss_gen=2.284, contrastive_loss=0, total=4148.29, n_correct=2748.92, ppl=4.28, accuracy=66.266, wps=13397.7, ups=1.61, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=0
2023-09-04 03:40:21 | INFO | train_inner | epoch 020:    308 / 1474 loss=1.939, trans_loss=4.862, nll_loss=2.091, w2v_ctc_loss=0.676, task_loss=0.261, task_loss_gen=1.983, contrastive_loss=0, total=4191.34, n_correct=2785.29, ppl=4.26, accuracy=66.453, wps=13721.1, ups=1.64, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=0
2023-09-04 03:41:22 | INFO | train_inner | epoch 020:    408 / 1474 loss=1.947, trans_loss=4.862, nll_loss=2.091, w2v_ctc_loss=0.682, task_loss=0.27, task_loss_gen=2.189, contrastive_loss=0, total=4114.19, n_correct=2732.72, ppl=4.26, accuracy=66.422, wps=13353.6, ups=1.62, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=14.9, wall=0
2023-09-04 03:42:24 | INFO | train_inner | epoch 020:    508 / 1474 loss=1.95, trans_loss=4.874, nll_loss=2.107, w2v_ctc_loss=0.678, task_loss=0.322, task_loss_gen=2.256, contrastive_loss=0, total=4108.2, n_correct=2717.59, ppl=4.31, accuracy=66.15, wps=13326.4, ups=1.62, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=0
2023-09-04 03:43:25 | INFO | train_inner | epoch 020:    608 / 1474 loss=1.955, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.686, task_loss=0.243, task_loss_gen=2.339, contrastive_loss=0, total=4092.44, n_correct=2704.15, ppl=4.31, accuracy=66.077, wps=13431.5, ups=1.64, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=0
2023-09-04 03:44:25 | INFO | train_inner | epoch 020:    708 / 1474 loss=1.955, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.693, task_loss=0.239, task_loss_gen=2.253, contrastive_loss=0, total=4137.06, n_correct=2734.92, ppl=4.31, accuracy=66.108, wps=13624.7, ups=1.65, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=0
2023-09-04 03:45:27 | INFO | train_inner | epoch 020:    808 / 1474 loss=1.953, trans_loss=4.876, nll_loss=2.11, w2v_ctc_loss=0.69, task_loss=0.228, task_loss_gen=2.221, contrastive_loss=0, total=4146.78, n_correct=2743.48, ppl=4.32, accuracy=66.159, wps=13555.7, ups=1.63, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=0
2023-09-04 03:46:29 | INFO | train_inner | epoch 020:    908 / 1474 loss=1.956, trans_loss=4.882, nll_loss=2.118, w2v_ctc_loss=0.689, task_loss=0.24, task_loss_gen=2.091, contrastive_loss=0, total=4161, n_correct=2743.59, ppl=4.34, accuracy=65.936, wps=13362.6, ups=1.61, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=61, gb_free=17.1, wall=0
2023-09-04 03:47:31 | INFO | train_inner | epoch 020:   1008 / 1474 loss=1.95, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.681, task_loss=0.295, task_loss_gen=2.123, contrastive_loss=0, total=4168.14, n_correct=2761.84, ppl=4.31, accuracy=66.261, wps=13419.7, ups=1.61, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=0
2023-09-04 03:48:32 | INFO | train_inner | epoch 020:   1108 / 1474 loss=1.956, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.689, task_loss=0.213, task_loss_gen=2.207, contrastive_loss=0, total=4166.49, n_correct=2750.32, ppl=4.34, accuracy=66.01, wps=13594.8, ups=1.63, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=14.4, wall=0
2023-09-04 03:49:34 | INFO | train_inner | epoch 020:   1208 / 1474 loss=1.96, trans_loss=4.87, nll_loss=2.101, w2v_ctc_loss=0.702, task_loss=0.278, task_loss_gen=2.343, contrastive_loss=0, total=4029.18, n_correct=2665.12, ppl=4.29, accuracy=66.145, wps=13171.2, ups=1.63, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=11.4, wall=0
2023-09-04 03:50:35 | INFO | train_inner | epoch 020:   1308 / 1474 loss=1.955, trans_loss=4.877, nll_loss=2.111, w2v_ctc_loss=0.688, task_loss=0.298, task_loss_gen=2.123, contrastive_loss=0, total=4123.21, n_correct=2727.7, ppl=4.32, accuracy=66.155, wps=13368.6, ups=1.62, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=0
2023-09-04 03:51:37 | INFO | train_inner | epoch 020:   1408 / 1474 loss=1.957, trans_loss=4.877, nll_loss=2.111, w2v_ctc_loss=0.691, task_loss=0.27, task_loss_gen=2.301, contrastive_loss=0, total=4116.28, n_correct=2723.47, ppl=4.32, accuracy=66.163, wps=13418.5, ups=1.63, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=0
2023-09-04 03:52:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:52:50 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.887 | trans_loss 5.18 | nll_loss 2.446 | w2v_ctc_loss 1.284 | task_loss 2.513 | task_loss_gen 8.117 | contrastive_loss 0 | total 4003.4 | n_correct 2650.1 | ppl 5.45 | accuracy 66.196 | uer 17.471 | wer 19.231 | raw_wer 19.231 | bleu 21.54 | wps 1609.7 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 21.58
2023-09-04 03:52:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-09-04 03:52:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.5405.pt
2023-09-04 03:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.5405.pt
2023-09-04 03:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.5405.pt (epoch 20 @ 29466 updates, score 21.54) (writing took 7.954449167998973 seconds)
2023-09-04 03:52:59 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-04 03:52:59 | INFO | train | epoch 020 | loss 1.952 | trans_loss 4.873 | nll_loss 2.106 | w2v_ctc_loss 0.686 | task_loss 0.266 | task_loss_gen 2.181 | contrastive_loss 0 | total 4138.65 | n_correct 2739.33 | ppl 4.3 | accuracy 66.189 | wps 12177.2 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 893 | gb_free 15.9 | wall 0
2023-09-04 03:52:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 03:52:59 | INFO | fairseq.trainer | begin training epoch 21
2023-09-04 03:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 03:53:27 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.947, trans_loss=4.872, nll_loss=2.105, w2v_ctc_loss=0.68, task_loss=0.193, task_loss_gen=2.228, contrastive_loss=0, total=4152.26, n_correct=2753.63, ppl=4.3, accuracy=66.316, wps=7498.9, ups=0.9, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=0
2023-09-04 03:54:29 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.936, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.672, task_loss=0.175, task_loss_gen=2.298, contrastive_loss=0, total=4195.08, n_correct=2792.57, ppl=4.22, accuracy=66.568, wps=13657, ups=1.63, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=0
2023-09-04 03:55:30 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.933, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.662, task_loss=0.204, task_loss_gen=2.351, contrastive_loss=0, total=4155.31, n_correct=2770.86, ppl=4.22, accuracy=66.682, wps=13636.5, ups=1.64, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-09-04 03:56:31 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.945, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.684, task_loss=0.158, task_loss_gen=2.557, contrastive_loss=0, total=4151.51, n_correct=2754.52, ppl=4.25, accuracy=66.35, wps=13528.4, ups=1.63, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=0
2023-09-04 03:57:32 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.938, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.673, task_loss=0.15, task_loss_gen=2.538, contrastive_loss=0, total=4180.85, n_correct=2788.19, ppl=4.23, accuracy=66.69, wps=13789, ups=1.65, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=0
2023-09-04 03:58:33 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.944, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.686, task_loss=0.169, task_loss_gen=2.706, contrastive_loss=0, total=4083.98, n_correct=2721.29, ppl=4.22, accuracy=66.633, wps=13244.4, ups=1.62, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=12.6, wall=0
2023-09-04 03:58:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 03:59:07 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.179 | nll_loss 2.445 | w2v_ctc_loss 1.324 | task_loss 1.605 | task_loss_gen 9.159 | contrastive_loss 0 | total 4003.4 | n_correct 2651.4 | ppl 5.45 | accuracy 66.229 | uer 17.331 | wer 19.045 | raw_wer 19.045 | bleu 21.33 | wps 1578 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 21.58
2023-09-04 03:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-09-04 03:59:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_21_30000.pt
2023-09-04 03:59:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_21_30000.pt
2023-09-04 03:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 21.33) (writing took 9.196884247008711 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 04:00:19 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.939, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.672, task_loss=0.187, task_loss_gen=2.498, contrastive_loss=0, total=4215.41, n_correct=2805.91, ppl=4.23, accuracy=66.563, wps=8010.8, ups=0.95, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=10.8, wall=0
2023-09-04 04:00:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-04 04:01:21 | INFO | train_inner | epoch 021:    735 / 1474 loss=1.943, trans_loss=4.863, nll_loss=2.093, w2v_ctc_loss=0.673, task_loss=0.143, task_loss_gen=2.692, contrastive_loss=0, total=4147.56, n_correct=2754.6, ppl=4.27, accuracy=66.415, wps=13394, ups=1.61, wpb=8295.1, bsz=308, num_updates=30200, lr=8.13788e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=0
2023-09-04 04:02:22 | INFO | train_inner | epoch 021:    835 / 1474 loss=1.95, trans_loss=4.869, nll_loss=2.101, w2v_ctc_loss=0.682, task_loss=0.2, task_loss_gen=2.528, contrastive_loss=0, total=4075.99, n_correct=2699.32, ppl=4.29, accuracy=66.225, wps=13288.7, ups=1.63, wpb=8152, bsz=295.7, num_updates=30300, lr=8.12444e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=0
2023-09-04 04:03:23 | INFO | train_inner | epoch 021:    935 / 1474 loss=1.941, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.676, task_loss=0.182, task_loss_gen=2.271, contrastive_loss=0, total=4091.88, n_correct=2722.55, ppl=4.24, accuracy=66.535, wps=13455.3, ups=1.64, wpb=8183.8, bsz=300, num_updates=30400, lr=8.11107e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=0
2023-09-04 04:04:24 | INFO | train_inner | epoch 021:   1035 / 1474 loss=1.948, trans_loss=4.866, nll_loss=2.097, w2v_ctc_loss=0.683, task_loss=0.16, task_loss_gen=2.371, contrastive_loss=0, total=4107.66, n_correct=2725.55, ppl=4.28, accuracy=66.353, wps=13429, ups=1.63, wpb=8215.3, bsz=299.5, num_updates=30500, lr=8.09776e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=14.2, wall=0
2023-09-04 04:05:25 | INFO | train_inner | epoch 021:   1135 / 1474 loss=1.946, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.683, task_loss=0.165, task_loss_gen=2.496, contrastive_loss=0, total=4118.94, n_correct=2737.97, ppl=4.25, accuracy=66.473, wps=13490.2, ups=1.64, wpb=8237.9, bsz=294.9, num_updates=30600, lr=8.08452e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=0
2023-09-04 04:06:26 | INFO | train_inner | epoch 021:   1235 / 1474 loss=1.944, trans_loss=4.862, nll_loss=2.092, w2v_ctc_loss=0.679, task_loss=0.151, task_loss_gen=2.126, contrastive_loss=0, total=4151.84, n_correct=2757.02, ppl=4.26, accuracy=66.405, wps=13596, ups=1.64, wpb=8303.7, bsz=309.1, num_updates=30700, lr=8.07134e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=60, gb_free=14.7, wall=0
2023-09-04 04:07:28 | INFO | train_inner | epoch 021:   1335 / 1474 loss=1.944, trans_loss=4.86, nll_loss=2.09, w2v_ctc_loss=0.683, task_loss=0.171, task_loss_gen=2.217, contrastive_loss=0, total=4145.91, n_correct=2756.57, ppl=4.26, accuracy=66.489, wps=13507.3, ups=1.63, wpb=8291.8, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=0
2023-09-04 04:08:30 | INFO | train_inner | epoch 021:   1435 / 1474 loss=1.957, trans_loss=4.872, nll_loss=2.105, w2v_ctc_loss=0.697, task_loss=0.168, task_loss_gen=2.338, contrastive_loss=0, total=4136.27, n_correct=2738.47, ppl=4.3, accuracy=66.206, wps=13325.1, ups=1.61, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=0
2023-09-04 04:08:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
2023-09-04 04:09:26 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.894 | trans_loss 5.182 | nll_loss 2.45 | w2v_ctc_loss 1.302 | task_loss 2.378 | task_loss_gen 8.743 | contrastive_loss 0 | total 4003.4 | n_correct 2652.5 | ppl 5.46 | accuracy 66.256 | uer 17.617 | wer 19.425 | raw_wer 19.425 | bleu 21.87 | wps 1627.4 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 21.87
2023-09-04 04:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-09-04 04:09:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 04:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 04:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 21 @ 30939 updates, score 21.87) (writing took 13.150170408014674 seconds)
2023-09-04 04:09:40 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-04 04:09:40 | INFO | train | epoch 021 | loss 1.943 | trans_loss 4.859 | nll_loss 2.087 | w2v_ctc_loss 0.679 | task_loss 0.171 | task_loss_gen 2.424 | contrastive_loss 0 | total 4138.43 | n_correct 2751.06 | ppl 4.25 | accuracy 66.476 | wps 12179.5 | ups 1.47 | wpb 8276.9 | bsz 305.6 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.525 | clip 0 | loss_scale 16 | train_wall 892 | gb_free 15.1 | wall 0
2023-09-04 04:09:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 04:09:40 | INFO | fairseq.trainer | begin training epoch 22
2023-09-04 04:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 04:10:25 | INFO | train_inner | epoch 022:     61 / 1474 loss=1.936, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.674, task_loss=0.174, task_loss_gen=2.186, contrastive_loss=0, total=4133.81, n_correct=2767.12, ppl=4.19, accuracy=66.939, wps=7164.7, ups=0.87, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=0
2023-09-04 04:11:27 | INFO | train_inner | epoch 022:    161 / 1474 loss=1.938, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.676, task_loss=0.172, task_loss_gen=2.177, contrastive_loss=0, total=4116.11, n_correct=2745.72, ppl=4.2, accuracy=66.707, wps=13237.9, ups=1.61, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=0
2023-09-04 04:12:28 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.923, trans_loss=4.836, nll_loss=2.058, w2v_ctc_loss=0.659, task_loss=0.158, task_loss_gen=1.845, contrastive_loss=0, total=4272.11, n_correct=2866.46, ppl=4.16, accuracy=67.097, wps=13975.7, ups=1.64, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=0
2023-09-04 04:13:31 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.942, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.678, task_loss=0.194, task_loss_gen=1.97, contrastive_loss=0, total=4178.4, n_correct=2781.09, ppl=4.22, accuracy=66.559, wps=13406.6, ups=1.6, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=0
2023-09-04 04:14:32 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.941, trans_loss=4.849, nll_loss=2.073, w2v_ctc_loss=0.676, task_loss=0.2, task_loss_gen=2.02, contrastive_loss=0, total=4132.96, n_correct=2757.59, ppl=4.21, accuracy=66.722, wps=13394.5, ups=1.62, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=0
2023-09-04 04:15:35 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.934, trans_loss=4.843, nll_loss=2.065, w2v_ctc_loss=0.674, task_loss=0.163, task_loss_gen=1.979, contrastive_loss=0, total=4158.17, n_correct=2779.53, ppl=4.18, accuracy=66.845, wps=13376.7, ups=1.61, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=0
2023-09-04 04:16:35 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.924, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.656, task_loss=0.158, task_loss_gen=1.947, contrastive_loss=0, total=4139.66, n_correct=2775.45, ppl=4.16, accuracy=67.045, wps=13645.6, ups=1.65, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=0
2023-09-04 04:17:37 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.936, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.674, task_loss=0.183, task_loss_gen=1.951, contrastive_loss=0, total=4167.89, n_correct=2783.53, ppl=4.19, accuracy=66.785, wps=13480.2, ups=1.62, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=12.4, wall=0
2023-09-04 04:18:39 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.94, trans_loss=4.851, nll_loss=2.077, w2v_ctc_loss=0.674, task_loss=0.193, task_loss_gen=2.133, contrastive_loss=0, total=4075.79, n_correct=2711.37, ppl=4.22, accuracy=66.524, wps=13259.1, ups=1.63, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=0
2023-09-04 04:19:40 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.934, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.669, task_loss=0.212, task_loss_gen=1.893, contrastive_loss=0, total=4134.72, n_correct=2762.5, ppl=4.19, accuracy=66.812, wps=13470.8, ups=1.63, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=13.8, wall=0
2023-09-04 04:20:41 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.929, trans_loss=4.841, nll_loss=2.065, w2v_ctc_loss=0.661, task_loss=0.176, task_loss_gen=1.784, contrastive_loss=0, total=4160.57, n_correct=2782.5, ppl=4.18, accuracy=66.878, wps=13654.4, ups=1.64, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=0
2023-09-04 04:20:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 04:21:14 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.881 | trans_loss 5.175 | nll_loss 2.44 | w2v_ctc_loss 1.277 | task_loss 5.01 | task_loss_gen 7.381 | contrastive_loss 0 | total 4003.4 | n_correct 2657.7 | ppl 5.43 | accuracy 66.386 | uer 17.402 | wer 19.116 | raw_wer 19.116 | bleu 21.79 | wps 1665.7 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 21.87
2023-09-04 04:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-09-04 04:21:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_22_32000.pt
2023-09-04 04:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_22_32000.pt
2023-09-04 04:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 21.79) (writing took 9.346568824024871 seconds)
2023-09-04 04:22:24 | INFO | train_inner | epoch 022:   1161 / 1474 loss=1.945, trans_loss=4.862, nll_loss=2.091, w2v_ctc_loss=0.678, task_loss=0.164, task_loss_gen=1.986, contrastive_loss=0, total=4099.59, n_correct=2722.17, ppl=4.26, accuracy=66.401, wps=7938.9, ups=0.97, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=0
2023-09-04 04:23:26 | INFO | train_inner | epoch 022:   1261 / 1474 loss=1.938, trans_loss=4.859, nll_loss=2.088, w2v_ctc_loss=0.674, task_loss=0.152, task_loss_gen=1.712, contrastive_loss=0, total=4182.05, n_correct=2783.73, ppl=4.25, accuracy=66.564, wps=13619.8, ups=1.63, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=61, gb_free=15.1, wall=0
2023-09-04 04:24:26 | INFO | train_inner | epoch 022:   1361 / 1474 loss=1.934, trans_loss=4.845, nll_loss=2.069, w2v_ctc_loss=0.666, task_loss=0.147, task_loss_gen=1.888, contrastive_loss=0, total=4062.31, n_correct=2713.86, ppl=4.2, accuracy=66.806, wps=13392.1, ups=1.65, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=14.7, wall=0
2023-09-04 04:25:27 | INFO | train_inner | epoch 022:   1461 / 1474 loss=1.943, trans_loss=4.856, nll_loss=2.082, w2v_ctc_loss=0.678, task_loss=0.145, task_loss_gen=2.192, contrastive_loss=0, total=4081.88, n_correct=2718.73, ppl=4.24, accuracy=66.605, wps=13397.7, ups=1.64, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-09-04 04:25:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 04:26:09 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.901 | trans_loss 5.179 | nll_loss 2.445 | w2v_ctc_loss 1.332 | task_loss 0.543 | task_loss_gen 13.806 | contrastive_loss 0 | total 4003.4 | n_correct 2654.9 | ppl 5.44 | accuracy 66.316 | uer 17.785 | wer 19.585 | raw_wer 19.585 | bleu 21.78 | wps 1591.6 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 21.87
2023-09-04 04:26:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-09-04 04:26:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7805.pt
2023-09-04 04:26:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7805.pt
2023-09-04 04:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7805.pt (epoch 22 @ 32413 updates, score 21.78) (writing took 7.8130642879987136 seconds)
2023-09-04 04:26:17 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-04 04:26:17 | INFO | train | epoch 022 | loss 1.935 | trans_loss 4.846 | nll_loss 2.071 | w2v_ctc_loss 0.671 | task_loss 0.172 | task_loss_gen 1.971 | contrastive_loss 0 | total 4138.65 | n_correct 2762.94 | ppl 4.2 | accuracy 66.76 | wps 12234.3 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 893 | gb_free 11.3 | wall 0
2023-09-04 04:26:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 04:26:18 | INFO | fairseq.trainer | begin training epoch 23
2023-09-04 04:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 04:27:18 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.928, trans_loss=4.828, nll_loss=2.048, w2v_ctc_loss=0.67, task_loss=0.126, task_loss_gen=2.11, contrastive_loss=0, total=4096.09, n_correct=2747.98, ppl=4.13, accuracy=67.088, wps=7378.1, ups=0.9, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=0
2023-09-04 04:28:20 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.928, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.666, task_loss=0.13, task_loss_gen=2.169, contrastive_loss=0, total=4107.77, n_correct=2756.26, ppl=4.12, accuracy=67.099, wps=13317, ups=1.62, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=0
2023-09-04 04:29:22 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.923, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.654, task_loss=0.138, task_loss_gen=2.067, contrastive_loss=0, total=4153.12, n_correct=2785.31, ppl=4.15, accuracy=67.065, wps=13426.6, ups=1.62, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=0
2023-09-04 04:30:23 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.921, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.655, task_loss=0.122, task_loss_gen=2.199, contrastive_loss=0, total=4116.7, n_correct=2767.82, ppl=4.11, accuracy=67.234, wps=13530.7, ups=1.64, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=15, wall=0
2023-09-04 04:31:23 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.92, trans_loss=4.828, nll_loss=2.048, w2v_ctc_loss=0.654, task_loss=0.089, task_loss_gen=2.005, contrastive_loss=0, total=4157.6, n_correct=2793.15, ppl=4.13, accuracy=67.182, wps=13699.7, ups=1.65, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=0
2023-09-04 04:32:24 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.919, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.657, task_loss=0.125, task_loss_gen=1.847, contrastive_loss=0, total=4173.42, n_correct=2805.27, ppl=4.12, accuracy=67.218, wps=13726.1, ups=1.64, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=60, gb_free=12.2, wall=0
2023-09-04 04:33:26 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.928, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.668, task_loss=0.088, task_loss_gen=2.163, contrastive_loss=0, total=4137.82, n_correct=2776, ppl=4.15, accuracy=67.088, wps=13494.1, ups=1.63, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-09-04 04:34:27 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.932, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.67, task_loss=0.1, task_loss_gen=2.075, contrastive_loss=0, total=4150.99, n_correct=2776.59, ppl=4.17, accuracy=66.89, wps=13532, ups=1.63, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=0
2023-09-04 04:35:28 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.926, trans_loss=4.831, nll_loss=2.052, w2v_ctc_loss=0.67, task_loss=0.115, task_loss_gen=1.924, contrastive_loss=0, total=4181.99, n_correct=2805.74, ppl=4.15, accuracy=67.091, wps=13763.2, ups=1.65, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-09-04 04:36:29 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.926, trans_loss=4.832, nll_loss=2.053, w2v_ctc_loss=0.659, task_loss=0.132, task_loss_gen=1.894, contrastive_loss=0, total=4168.73, n_correct=2791.3, ppl=4.15, accuracy=66.958, wps=13582.4, ups=1.63, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=10.4, wall=0
2023-09-04 04:37:30 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.935, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.675, task_loss=0.108, task_loss_gen=2.2, contrastive_loss=0, total=4088.49, n_correct=2738.09, ppl=4.16, accuracy=66.971, wps=13307.8, ups=1.63, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=0
2023-09-04 04:38:33 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.931, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.674, task_loss=0.1, task_loss_gen=2.009, contrastive_loss=0, total=4162.7, n_correct=2785.79, ppl=4.18, accuracy=66.923, wps=13400.3, ups=1.61, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=0
2023-09-04 04:39:34 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.925, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.663, task_loss=0.099, task_loss_gen=1.95, contrastive_loss=0, total=4135.53, n_correct=2775.52, ppl=4.15, accuracy=67.114, wps=13540.6, ups=1.64, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-09-04 04:40:35 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.935, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.671, task_loss=0.093, task_loss_gen=2.069, contrastive_loss=0, total=4143.98, n_correct=2765.89, ppl=4.2, accuracy=66.745, wps=13456.5, ups=1.62, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=0
2023-09-04 04:41:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 04:42:01 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.905 | trans_loss 5.172 | nll_loss 2.435 | w2v_ctc_loss 1.361 | task_loss 0.953 | task_loss_gen 11.753 | contrastive_loss 0 | total 4003.4 | n_correct 2662 | ppl 5.41 | accuracy 66.493 | uer 17.349 | wer 19.03 | raw_wer 19.03 | bleu 22.15 | wps 1646.8 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 22.15
2023-09-04 04:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-09-04 04:42:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 04:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 04:42:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 23 @ 33887 updates, score 22.15) (writing took 12.078457657014951 seconds)
2023-09-04 04:42:14 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-04 04:42:14 | INFO | train | epoch 023 | loss 1.927 | trans_loss 4.833 | nll_loss 2.053 | w2v_ctc_loss 0.665 | task_loss 0.11 | task_loss_gen 2.04 | contrastive_loss 0 | total 4138.65 | n_correct 2774.2 | ppl 4.15 | accuracy 67.032 | wps 12756.2 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 13.2 | wall 0
2023-09-04 04:42:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 04:42:14 | INFO | fairseq.trainer | begin training epoch 24
2023-09-04 04:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 04:42:29 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.932, trans_loss=4.845, nll_loss=2.07, w2v_ctc_loss=0.664, task_loss=0.09, task_loss_gen=1.962, contrastive_loss=0, total=4085.11, n_correct=2729.11, ppl=4.2, accuracy=66.806, wps=7157.2, ups=0.88, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=12.2, wall=0
2023-09-04 04:43:31 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.912, trans_loss=4.812, nll_loss=2.025, w2v_ctc_loss=0.65, task_loss=0.093, task_loss_gen=1.812, contrastive_loss=0, total=4171.44, n_correct=2809.91, ppl=4.07, accuracy=67.361, wps=13620.4, ups=1.63, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-09-04 04:43:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 04:44:04 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.904 | trans_loss 5.179 | nll_loss 2.441 | w2v_ctc_loss 1.341 | task_loss 1.405 | task_loss_gen 12.172 | contrastive_loss 0 | total 4003.4 | n_correct 2652.7 | ppl 5.43 | accuracy 66.261 | uer 17.278 | wer 19.168 | raw_wer 19.168 | bleu 21.73 | wps 1593.6 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.15
2023-09-04 04:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-09-04 04:44:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_24_34000.pt
2023-09-04 04:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_24_34000.pt
2023-09-04 04:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 21.73) (writing took 10.635466228006408 seconds)
2023-09-04 04:45:17 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.908, trans_loss=4.816, nll_loss=2.033, w2v_ctc_loss=0.64, task_loss=0.09, task_loss_gen=1.669, contrastive_loss=0, total=4251.29, n_correct=2866.77, ppl=4.09, accuracy=67.433, wps=8001.4, ups=0.94, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=0
2023-09-04 04:46:18 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.914, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.649, task_loss=0.075, task_loss_gen=1.972, contrastive_loss=0, total=4128.18, n_correct=2784.55, ppl=4.08, accuracy=67.452, wps=13527, ups=1.64, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 04:47:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-04 04:47:20 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.93, trans_loss=4.822, nll_loss=2.039, w2v_ctc_loss=0.668, task_loss=0.066, task_loss_gen=2.185, contrastive_loss=0, total=4156.29, n_correct=2786.92, ppl=4.11, accuracy=67.053, wps=13360.8, ups=1.61, wpb=8312.6, bsz=298.9, num_updates=34300, lr=7.63604e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=0
2023-09-04 04:48:22 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.919, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.658, task_loss=0.097, task_loss_gen=1.815, contrastive_loss=0, total=4141.88, n_correct=2787.58, ppl=4.09, accuracy=67.302, wps=13491.5, ups=1.63, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=0
2023-09-04 04:49:23 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.919, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.655, task_loss=0.068, task_loss_gen=1.853, contrastive_loss=0, total=4162.06, n_correct=2801.32, ppl=4.1, accuracy=67.306, wps=13600.5, ups=1.63, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=0
2023-09-04 04:50:25 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.922, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.656, task_loss=0.071, task_loss_gen=1.915, contrastive_loss=0, total=4097.35, n_correct=2754.54, ppl=4.12, accuracy=67.227, wps=13270.5, ups=1.62, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-09-04 04:51:26 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.918, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.654, task_loss=0.055, task_loss_gen=1.924, contrastive_loss=0, total=4124.25, n_correct=2776.15, ppl=4.13, accuracy=67.313, wps=13451.7, ups=1.63, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=0
2023-09-04 04:52:27 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.93, trans_loss=4.826, nll_loss=2.043, w2v_ctc_loss=0.668, task_loss=0.093, task_loss_gen=1.993, contrastive_loss=0, total=4041.44, n_correct=2712.55, ppl=4.12, accuracy=67.118, wps=13195.2, ups=1.63, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=0
2023-09-04 04:53:29 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.923, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.655, task_loss=0.076, task_loss_gen=1.852, contrastive_loss=0, total=4128.8, n_correct=2771.62, ppl=4.13, accuracy=67.129, wps=13443.2, ups=1.63, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=14.7, wall=0
2023-09-04 04:54:30 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.917, trans_loss=4.813, nll_loss=2.029, w2v_ctc_loss=0.66, task_loss=0.08, task_loss_gen=1.676, contrastive_loss=0, total=4130.49, n_correct=2785.66, ppl=4.08, accuracy=67.441, wps=13484.7, ups=1.63, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=0
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 04:55:32 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.917, trans_loss=4.822, nll_loss=2.04, w2v_ctc_loss=0.651, task_loss=0.083, task_loss_gen=1.685, contrastive_loss=0, total=4157.47, n_correct=2795.81, ppl=4.11, accuracy=67.248, wps=13481.3, ups=1.62, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=12.3, wall=0
2023-09-04 04:56:33 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.93, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.671, task_loss=0.077, task_loss_gen=1.804, contrastive_loss=0, total=4107.23, n_correct=2755.84, ppl=4.13, accuracy=67.097, wps=13272.6, ups=1.62, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=0
2023-09-04 04:57:35 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.929, trans_loss=4.829, nll_loss=2.05, w2v_ctc_loss=0.672, task_loss=0.073, task_loss_gen=1.846, contrastive_loss=0, total=4094.39, n_correct=2748.64, ppl=4.14, accuracy=67.132, wps=13376.3, ups=1.63, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=0
2023-09-04 04:58:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
2023-09-04 04:58:45 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.17 | nll_loss 2.435 | w2v_ctc_loss 1.324 | task_loss 0.379 | task_loss_gen 15.832 | contrastive_loss 0 | total 4003.4 | n_correct 2658.8 | ppl 5.41 | accuracy 66.414 | uer 17.195 | wer 18.952 | raw_wer 18.952 | bleu 21.64 | wps 1587.3 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 22.15
2023-09-04 04:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-09-04 04:58:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.6401.pt
2023-09-04 04:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.6401.pt
2023-09-04 04:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.6401.pt (epoch 24 @ 35360 updates, score 21.64) (writing took 8.02996945695486 seconds)
2023-09-04 04:58:53 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-04 04:58:53 | INFO | train | epoch 024 | loss 1.92 | trans_loss 4.821 | nll_loss 2.038 | w2v_ctc_loss 0.657 | task_loss 0.078 | task_loss_gen 1.846 | contrastive_loss 0 | total 4138.25 | n_correct 2783.43 | ppl 4.11 | accuracy 67.261 | wps 12194.7 | ups 1.47 | wpb 8276.5 | bsz 305.6 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 894 | gb_free 15.7 | wall 0
2023-09-04 04:58:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 04:58:54 | INFO | fairseq.trainer | begin training epoch 25
2023-09-04 04:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 04:59:25 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.912, trans_loss=4.812, nll_loss=2.028, w2v_ctc_loss=0.652, task_loss=0.052, task_loss_gen=1.734, contrastive_loss=0, total=4165.57, n_correct=2814.07, ppl=4.08, accuracy=67.555, wps=7547.6, ups=0.91, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=12.7, wall=0
2023-09-04 05:00:26 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.903, trans_loss=4.798, nll_loss=2.009, w2v_ctc_loss=0.638, task_loss=0.061, task_loss_gen=1.653, contrastive_loss=0, total=4135.43, n_correct=2804.98, ppl=4.02, accuracy=67.828, wps=13638.2, ups=1.65, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=0
2023-09-04 05:01:28 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.911, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.65, task_loss=0.078, task_loss_gen=1.58, contrastive_loss=0, total=4116.13, n_correct=2782.25, ppl=4.05, accuracy=67.594, wps=13252.8, ups=1.61, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=0
2023-09-04 05:02:30 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.912, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.648, task_loss=0.069, task_loss_gen=1.713, contrastive_loss=0, total=4141.49, n_correct=2800.28, ppl=4.04, accuracy=67.615, wps=13284.8, ups=1.6, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=62, gb_free=14.9, wall=0
2023-09-04 05:03:32 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.923, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.667, task_loss=0.045, task_loss_gen=1.694, contrastive_loss=0, total=4167.4, n_correct=2809.52, ppl=4.06, accuracy=67.417, wps=13445, ups=1.61, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=0
2023-09-04 05:04:33 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.911, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.647, task_loss=0.075, task_loss_gen=1.397, contrastive_loss=0, total=4160.61, n_correct=2807.58, ppl=4.08, accuracy=67.48, wps=13586.6, ups=1.63, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=0
2023-09-04 05:05:34 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.91, trans_loss=4.801, nll_loss=2.013, w2v_ctc_loss=0.649, task_loss=0.064, task_loss_gen=1.439, contrastive_loss=0, total=4153.68, n_correct=2810.24, ppl=4.04, accuracy=67.657, wps=13617.8, ups=1.64, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 05:05:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 05:06:08 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.894 | trans_loss 5.174 | nll_loss 2.437 | w2v_ctc_loss 1.32 | task_loss 0.227 | task_loss_gen 17.646 | contrastive_loss 0 | total 4003.4 | n_correct 2656.7 | ppl 5.42 | accuracy 66.361 | uer 17.012 | wer 18.944 | raw_wer 18.944 | bleu 22.04 | wps 1628.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.15
2023-09-04 05:06:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-09-04 05:06:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_25_36000.pt
2023-09-04 05:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_25_36000.pt
2023-09-04 05:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.04) (writing took 9.409163632954005 seconds)
--Backword ST Loss tensor(1379.1018, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1608.3359, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 05:07:19 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.913, trans_loss=4.804, nll_loss=2.017, w2v_ctc_loss=0.651, task_loss=0.052, task_loss_gen=1.517, contrastive_loss=0, total=4128.34, n_correct=2789.04, ppl=4.05, accuracy=67.558, wps=7919.5, ups=0.96, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=0
2023-09-04 05:08:20 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.909, trans_loss=4.81, nll_loss=2.025, w2v_ctc_loss=0.649, task_loss=0.046, task_loss_gen=1.374, contrastive_loss=0, total=4182.4, n_correct=2825.75, ppl=4.07, accuracy=67.563, wps=13576.6, ups=1.62, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=0
2023-09-04 05:09:22 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.912, trans_loss=4.811, nll_loss=2.026, w2v_ctc_loss=0.653, task_loss=0.032, task_loss_gen=1.455, contrastive_loss=0, total=4155.21, n_correct=2807.54, ppl=4.07, accuracy=67.567, wps=13478.5, ups=1.62, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=61, gb_free=13.6, wall=0
2023-09-04 05:10:24 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.915, trans_loss=4.818, nll_loss=2.035, w2v_ctc_loss=0.646, task_loss=0.046, task_loss_gen=1.434, contrastive_loss=0, total=4177.7, n_correct=2809.56, ppl=4.1, accuracy=67.251, wps=13563.3, ups=1.62, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=0
2023-09-04 05:11:25 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.915, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.648, task_loss=0.048, task_loss_gen=1.551, contrastive_loss=0, total=4039.24, n_correct=2726.13, ppl=4.07, accuracy=67.491, wps=13233.8, ups=1.64, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=0
2023-09-04 05:12:25 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.918, trans_loss=4.817, nll_loss=2.034, w2v_ctc_loss=0.654, task_loss=0.045, task_loss_gen=1.488, contrastive_loss=0, total=4090.59, n_correct=2756.23, ppl=4.09, accuracy=67.38, wps=13511, ups=1.65, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=0
2023-09-04 05:13:27 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.911, trans_loss=4.808, nll_loss=2.022, w2v_ctc_loss=0.647, task_loss=0.049, task_loss_gen=1.305, contrastive_loss=0, total=4164.34, n_correct=2814.01, ppl=4.06, accuracy=67.574, wps=13479.1, ups=1.62, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=0
2023-09-04 05:14:29 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.921, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.655, task_loss=0.039, task_loss_gen=1.508, contrastive_loss=0, total=4099.11, n_correct=2754.97, ppl=4.12, accuracy=67.209, wps=13227.1, ups=1.61, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=61, gb_free=11.8, wall=0
2023-09-04 05:14:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1246.4030, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1444.2585, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1286.8545, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1383.5048, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1664.5603, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1841.5200, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(982.9570, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1049.6003, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1788.1929, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(2125.4268, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(835.5084, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(964.1699, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1958.3823, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(2317.1174, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-04 05:15:27 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.871 | trans_loss 5.167 | nll_loss 2.432 | w2v_ctc_loss 1.257 | task_loss 0.21 | task_loss_gen 17.62 | contrastive_loss 0 | total 4003.4 | n_correct 2666.8 | ppl 5.4 | accuracy 66.613 | uer 16.964 | wer 18.911 | raw_wer 18.911 | bleu 22.01 | wps 1390.7 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 22.15
2023-09-04 05:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-09-04 05:15:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0105.pt
2023-09-04 05:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0105.pt
2023-09-04 05:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0105.pt (epoch 25 @ 36834 updates, score 22.01) (writing took 9.664991537982132 seconds)
2023-09-04 05:15:37 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-04 05:15:37 | INFO | train | epoch 025 | loss 1.913 | trans_loss 4.809 | nll_loss 2.023 | w2v_ctc_loss 0.65 | task_loss 0.053 | task_loss_gen 1.506 | contrastive_loss 0 | total 4138.65 | n_correct 2794.27 | ppl 4.06 | accuracy 67.517 | wps 12164.1 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.526 | clip 0 | loss_scale 64 | train_wall 895 | gb_free 13.8 | wall 0
2023-09-04 05:15:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 05:15:37 | INFO | fairseq.trainer | begin training epoch 26
2023-09-04 05:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 05:16:24 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.899, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.636, task_loss=0.032, task_loss_gen=1.297, contrastive_loss=0, total=4180.21, n_correct=2835.51, ppl=4.01, accuracy=67.832, wps=7260.2, ups=0.87, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=0
2023-09-04 05:17:26 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.897, trans_loss=4.798, nll_loss=2.009, w2v_ctc_loss=0.627, task_loss=0.039, task_loss_gen=1.138, contrastive_loss=0, total=4270.78, n_correct=2900.08, ppl=4.03, accuracy=67.905, wps=13849.1, ups=1.62, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=61, gb_free=14.9, wall=0
2023-09-04 05:18:28 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.907, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.648, task_loss=0.046, task_loss_gen=1.188, contrastive_loss=0, total=4125.04, n_correct=2792.35, ppl=4.01, accuracy=67.693, wps=13364.5, ups=1.62, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=61, gb_free=14.8, wall=0
2023-09-04 05:19:29 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.902, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.64, task_loss=0.045, task_loss_gen=1.083, contrastive_loss=0, total=4165.74, n_correct=2822.88, ppl=4.01, accuracy=67.764, wps=13638.9, ups=1.64, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=0
2023-09-04 05:20:29 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.902, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.646, task_loss=0.033, task_loss_gen=1.136, contrastive_loss=0, total=4170.23, n_correct=2834.6, ppl=3.98, accuracy=67.972, wps=13727.9, ups=1.65, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=0
2023-09-04 05:21:31 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.911, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.658, task_loss=0.029, task_loss_gen=1.195, contrastive_loss=0, total=4155.02, n_correct=2813.4, ppl=4.03, accuracy=67.711, wps=13495.2, ups=1.62, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=0
2023-09-04 05:22:32 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.903, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.636, task_loss=0.039, task_loss_gen=1.084, contrastive_loss=0, total=4136.96, n_correct=2808.63, ppl=4.01, accuracy=67.891, wps=13524.6, ups=1.63, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=0
2023-09-04 05:23:34 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.904, trans_loss=4.796, nll_loss=2.006, w2v_ctc_loss=0.637, task_loss=0.032, task_loss_gen=1.079, contrastive_loss=0, total=4086.28, n_correct=2765.75, ppl=4.02, accuracy=67.684, wps=13277.2, ups=1.62, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=14.7, wall=0
2023-09-04 05:24:35 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.908, trans_loss=4.796, nll_loss=2.006, w2v_ctc_loss=0.649, task_loss=0.03, task_loss_gen=1.029, contrastive_loss=0, total=4183.26, n_correct=2833.86, ppl=4.02, accuracy=67.743, wps=13625.8, ups=1.63, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=0
2023-09-04 05:25:37 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.911, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.644, task_loss=0.026, task_loss_gen=1.037, contrastive_loss=0, total=4137.96, n_correct=2792.47, ppl=4.05, accuracy=67.484, wps=13404.9, ups=1.62, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=0
2023-09-04 05:26:39 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.911, trans_loss=4.802, nll_loss=2.014, w2v_ctc_loss=0.65, task_loss=0.033, task_loss_gen=0.981, contrastive_loss=0, total=4120.53, n_correct=2789.21, ppl=4.04, accuracy=67.691, wps=13377.2, ups=1.62, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=0
2023-09-04 05:27:40 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.913, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.649, task_loss=0.025, task_loss_gen=0.981, contrastive_loss=0, total=4113.86, n_correct=2776.98, ppl=4.06, accuracy=67.503, wps=13361.7, ups=1.62, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=0
2023-09-04 05:27:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 05:28:14 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.907 | trans_loss 5.174 | nll_loss 2.436 | w2v_ctc_loss 1.364 | task_loss 0.029 | task_loss_gen 25.891 | contrastive_loss 0 | total 4003.4 | n_correct 2661.1 | ppl 5.41 | accuracy 66.471 | uer 17.357 | wer 19.194 | raw_wer 19.194 | bleu 21.93 | wps 1580.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.15
2023-09-04 05:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-09-04 05:28:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_26_38000.pt
2023-09-04 05:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_26_38000.pt
2023-09-04 05:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 21.93) (writing took 10.45611607801402 seconds)
--Backword ST Loss tensor(1131.5947, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1409.0081, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 05:29:26 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.924, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.664, task_loss=0.021, task_loss_gen=1.044, contrastive_loss=0, total=3996.19, n_correct=2688.55, ppl=4.09, accuracy=67.278, wps=7572.4, ups=0.95, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=0
2023-09-04 05:30:28 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.91, trans_loss=4.809, nll_loss=2.023, w2v_ctc_loss=0.647, task_loss=0.023, task_loss_gen=0.835, contrastive_loss=0, total=4159.74, n_correct=2815.72, ppl=4.06, accuracy=67.69, wps=13344.8, ups=1.6, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=0
2023-09-04 05:31:29 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.898, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.63, task_loss=0.018, task_loss_gen=0.784, contrastive_loss=0, total=4165.66, n_correct=2827.94, ppl=4.03, accuracy=67.887, wps=13576, ups=1.63, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=0
2023-09-04 05:31:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1585.1097, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1891.3206, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1486.2759, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1712.1488, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(873.5961, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(962.8003, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1491.8654, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1678.7617, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1406.6787, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1262.3363, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1811.1207, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(2067.4888, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1127.9657, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1338.2562, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-04 05:32:08 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.88 | trans_loss 5.166 | nll_loss 2.428 | w2v_ctc_loss 1.29 | task_loss 0.075 | task_loss_gen 21.086 | contrastive_loss 0 | total 4003.4 | n_correct 2664.7 | ppl 5.38 | accuracy 66.561 | uer 17.073 | wer 18.821 | raw_wer 18.821 | bleu 21.75 | wps 1575.4 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22.15
2023-09-04 05:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-09-04 05:32:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7500.pt
2023-09-04 05:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7500.pt
2023-09-04 05:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.7500.pt (epoch 26 @ 38308 updates, score 21.75) (writing took 10.262695950979833 seconds)
2023-09-04 05:32:19 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-04 05:32:19 | INFO | train | epoch 026 | loss 1.907 | trans_loss 4.799 | nll_loss 2.01 | w2v_ctc_loss 0.644 | task_loss 0.032 | task_loss_gen 1.057 | contrastive_loss 0 | total 4138.65 | n_correct 2802.98 | ppl 4.03 | accuracy 67.727 | wps 12173.8 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 894 | gb_free 15.7 | wall 0
2023-09-04 05:32:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 05:32:19 | INFO | fairseq.trainer | begin training epoch 27
2023-09-04 05:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 05:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-04 05:33:23 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.891, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.627, task_loss=0.021, task_loss_gen=0.823, contrastive_loss=0, total=4058.16, n_correct=2777.1, ppl=3.9, accuracy=68.432, wps=7165.2, ups=0.88, wpb=8116.3, bsz=283.6, num_updates=38400, lr=7.21688e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=60, gb_free=14.5, wall=0
2023-09-04 05:34:24 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.892, trans_loss=4.776, nll_loss=1.981, w2v_ctc_loss=0.635, task_loss=0.02, task_loss_gen=0.676, contrastive_loss=0, total=4185.52, n_correct=2854.51, ppl=3.95, accuracy=68.2, wps=13715.4, ups=1.64, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=0
2023-09-04 05:35:25 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.902, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.643, task_loss=0.022, task_loss_gen=0.629, contrastive_loss=0, total=4167.92, n_correct=2835.22, ppl=3.98, accuracy=68.025, wps=13497.3, ups=1.62, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=0
2023-09-04 05:36:28 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.901, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.634, task_loss=0.02, task_loss_gen=0.62, contrastive_loss=0, total=4075.21, n_correct=2769.18, ppl=3.98, accuracy=67.952, wps=13122.8, ups=1.61, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=0
2023-09-04 05:37:29 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.898, trans_loss=4.795, nll_loss=2.005, w2v_ctc_loss=0.634, task_loss=0.015, task_loss_gen=0.515, contrastive_loss=0, total=4249.35, n_correct=2885.37, ppl=4.01, accuracy=67.901, wps=13729.2, ups=1.62, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=61, gb_free=11.6, wall=0
2023-09-04 05:38:31 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.897, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.638, task_loss=0.016, task_loss_gen=0.5, contrastive_loss=0, total=4133.39, n_correct=2811.77, ppl=3.97, accuracy=68.026, wps=13537.4, ups=1.64, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=11.7, wall=0
2023-09-04 05:39:32 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.904, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.643, task_loss=0.014, task_loss_gen=0.468, contrastive_loss=0, total=4162.71, n_correct=2823.74, ppl=4, accuracy=67.834, wps=13608, ups=1.63, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 05:40:33 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.907, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.651, task_loss=0.014, task_loss_gen=0.445, contrastive_loss=0, total=4103.81, n_correct=2787.59, ppl=3.99, accuracy=67.927, wps=13483.4, ups=1.64, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-09-04 05:41:34 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.898, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.627, task_loss=0.012, task_loss_gen=0.397, contrastive_loss=0, total=4101.56, n_correct=2789.47, ppl=4, accuracy=68.01, wps=13341.8, ups=1.63, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=0
2023-09-04 05:42:36 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.905, trans_loss=4.796, nll_loss=2.007, w2v_ctc_loss=0.643, task_loss=0.01, task_loss_gen=0.322, contrastive_loss=0, total=4199.56, n_correct=2846.11, ppl=4.02, accuracy=67.772, wps=13611, ups=1.62, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=61, gb_free=11.2, wall=0
2023-09-04 05:43:37 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.9, trans_loss=4.789, nll_loss=1.997, w2v_ctc_loss=0.636, task_loss=0.01, task_loss_gen=0.298, contrastive_loss=0, total=4150.97, n_correct=2819.01, ppl=3.99, accuracy=67.912, wps=13555.3, ups=1.63, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=11.6, wall=0
2023-09-04 05:44:38 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.907, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.65, task_loss=0.01, task_loss_gen=0.247, contrastive_loss=0, total=4103.06, n_correct=2784.39, ppl=4, accuracy=67.861, wps=13392.7, ups=1.63, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-09-04 05:45:40 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.906, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.641, task_loss=0.005, task_loss_gen=0.23, contrastive_loss=0, total=4062.52, n_correct=2755.35, ppl=4.01, accuracy=67.824, wps=13273.1, ups=1.63, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=0
2023-09-04 05:46:40 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.9, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.635, task_loss=0.005, task_loss_gen=0.15, contrastive_loss=0, total=4152, n_correct=2820.26, ppl=4.01, accuracy=67.925, wps=13694.8, ups=1.65, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-09-04 05:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 05:48:02 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.878 | trans_loss 5.167 | nll_loss 2.429 | w2v_ctc_loss 1.283 | task_loss 0.089 | task_loss_gen 20.536 | contrastive_loss 0 | total 4003.4 | n_correct 2673.2 | ppl 5.39 | accuracy 66.773 | uer 17.124 | wer 19.16 | raw_wer 19.16 | bleu 22.24 | wps 1637.1 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 22.24
2023-09-04 05:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-09-04 05:48:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 05:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt
2023-09-04 05:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_best.pt (epoch 27 @ 39781 updates, score 22.24) (writing took 13.540489796025213 seconds)
2023-09-04 05:48:16 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-04 05:48:16 | INFO | train | epoch 027 | loss 1.9 | trans_loss 4.788 | nll_loss 1.996 | w2v_ctc_loss 0.638 | task_loss 0.013 | task_loss_gen 0.43 | contrastive_loss 0 | total 4138.45 | n_correct 2812.9 | ppl 3.99 | accuracy 67.97 | wps 12730.6 | ups 1.54 | wpb 8276.9 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 17.5 | wall 0
2023-09-04 05:48:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 05:48:17 | INFO | fairseq.trainer | begin training epoch 28
2023-09-04 05:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 05:48:35 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.896, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.634, task_loss=0.004, task_loss_gen=0.109, contrastive_loss=0, total=4108.43, n_correct=2797.18, ppl=3.98, accuracy=68.084, wps=7134.4, ups=0.87, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-09-04 05:49:36 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.886, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.624, task_loss=0.003, task_loss_gen=0.067, contrastive_loss=0, total=4113.41, n_correct=2821.79, ppl=3.89, accuracy=68.6, wps=13468.2, ups=1.64, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=0
2023-09-04 05:50:38 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.888, trans_loss=4.772, nll_loss=1.975, w2v_ctc_loss=0.625, task_loss=0, task_loss_gen=0.024, contrastive_loss=0, total=4191.56, n_correct=2864.62, ppl=3.93, accuracy=68.343, wps=13647.3, ups=1.63, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=0
2023-09-04 05:50:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 05:51:11 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.166 | nll_loss 2.426 | w2v_ctc_loss 1.344 | task_loss 0.041 | task_loss_gen 24.838 | contrastive_loss 0 | total 4003.4 | n_correct 2669.5 | ppl 5.37 | accuracy 66.681 | uer 17.179 | wer 19.052 | raw_wer 19.052 | bleu 22.38 | wps 1638.2 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.38
2023-09-04 05:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-09-04 05:51:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_28_40000.pt
2023-09-04 05:51:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_28_40000.pt
2023-09-04 05:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.38) (writing took 14.658173939969856 seconds)
--Backword ST Loss tensor(1131.7511, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1334.0168, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 05:52:27 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.89, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4145.32, n_correct=2823.02, ppl=3.96, accuracy=68.101, wps=7570, ups=0.91, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=0
2023-09-04 05:53:28 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.893, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.634, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4092.14, n_correct=2796.46, ppl=3.92, accuracy=68.337, wps=13430.9, ups=1.64, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 05:54:29 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.89, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.625, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4096.35, n_correct=2795.82, ppl=3.93, accuracy=68.251, wps=13456, ups=1.64, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=0
2023-09-04 05:55:30 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.901, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.643, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4178.12, n_correct=2841.02, ppl=3.98, accuracy=67.998, wps=13709.5, ups=1.64, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=0
2023-09-04 05:56:31 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.894, trans_loss=4.786, nll_loss=1.994, w2v_ctc_loss=0.633, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4185.82, n_correct=2851.26, ppl=3.98, accuracy=68.117, wps=13681.4, ups=1.63, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=15.5, wall=0
2023-09-04 05:57:32 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.89, trans_loss=4.777, nll_loss=1.981, w2v_ctc_loss=0.628, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4096.2, n_correct=2797.69, ppl=3.95, accuracy=68.3, wps=13521.7, ups=1.65, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=0
2023-09-04 05:58:34 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.901, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.639, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4120.27, n_correct=2796.37, ppl=3.98, accuracy=67.869, wps=13364.7, ups=1.62, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=0
2023-09-04 05:58:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-04 05:59:35 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.896, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.635, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4179.03, n_correct=2846.93, ppl=3.96, accuracy=68.124, wps=13584.9, ups=1.63, wpb=8358.1, bsz=311.7, num_updates=40800, lr=7.0014e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=0
2023-09-04 06:00:37 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.891, trans_loss=4.777, nll_loss=1.982, w2v_ctc_loss=0.631, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4220.16, n_correct=2878.42, ppl=3.95, accuracy=68.206, wps=13742.5, ups=1.63, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=0
2023-09-04 06:01:38 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.889, trans_loss=4.778, nll_loss=1.983, w2v_ctc_loss=0.622, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4092.46, n_correct=2795.31, ppl=3.95, accuracy=68.304, wps=13373.9, ups=1.63, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=0
2023-09-04 06:02:39 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.903, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.645, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4084.55, n_correct=2777.95, ppl=3.97, accuracy=68.011, wps=13319.1, ups=1.63, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=0
2023-09-04 06:03:40 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.902, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.64, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4154.09, n_correct=2823.87, ppl=3.98, accuracy=67.978, wps=13574.8, ups=1.63, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=0
2023-09-04 06:04:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1010.8534, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1111.1708, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
--Backword ST Loss tensor(3017.4028, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(3828.7930, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
--Backword ST Loss tensor(1429.2943, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1733.1469, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
--Backword ST Loss tensor(1609.2921, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1825.8004, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
--Backword ST Loss tensor(1759.2209, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1941.9600, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
--Backword ST Loss tensor(1553.8239, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1692.9802, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
--Backword ST Loss tensor(856.1364, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(955.9358, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
2023-09-04 06:04:47 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.884 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.316 | task_loss 0.005 | task_loss_gen 38.027 | contrastive_loss 0 | total 4003.4 | n_correct 2671.8 | ppl 5.35 | accuracy 66.738 | uer 16.996 | wer 18.754 | raw_wer 18.754 | bleu 21.84 | wps 1574.4 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 22.38
2023-09-04 06:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-09-04 06:04:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.8400.pt
2023-09-04 06:04:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.8400.pt
2023-09-04 06:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_21.8400.pt (epoch 28 @ 41254 updates, score 21.84) (writing took 7.567429699003696 seconds)
2023-09-04 06:04:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-04 06:04:55 | INFO | train | epoch 028 | loss 1.894 | trans_loss 4.778 | nll_loss 1.982 | w2v_ctc_loss 0.632 | task_loss 0 | task_loss_gen 0.007 | contrastive_loss 0 | total 4138.7 | n_correct 2822.31 | ppl 3.95 | accuracy 68.193 | wps 12214.3 | ups 1.48 | wpb 8277.4 | bsz 305.7 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 16.1 | wall 0
2023-09-04 06:04:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 06:04:55 | INFO | fairseq.trainer | begin training epoch 29
2023-09-04 06:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 06:05:30 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.887, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.63, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4169.12, n_correct=2852.26, ppl=3.92, accuracy=68.414, wps=7576, ups=0.91, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 06:06:32 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.893, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.634, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4105.72, n_correct=2803.02, ppl=3.93, accuracy=68.271, wps=13401.8, ups=1.63, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=0
2023-09-04 06:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-04 06:07:33 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.879, trans_loss=4.76, nll_loss=1.96, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4205.24, n_correct=2881.82, ppl=3.89, accuracy=68.529, wps=13636.6, ups=1.62, wpb=8410.5, bsz=331, num_updates=41500, lr=6.9421e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=0
2023-09-04 06:08:34 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.897, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.637, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4094.4, n_correct=2793.05, ppl=3.94, accuracy=68.216, wps=13425.1, ups=1.64, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=0
2023-09-04 06:09:35 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.877, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4157.41, n_correct=2859.38, ppl=3.85, accuracy=68.778, wps=13672.1, ups=1.64, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=14.3, wall=0
2023-09-04 06:10:36 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.895, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.624, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4149.27, n_correct=2825.1, ppl=3.94, accuracy=68.087, wps=13562.2, ups=1.63, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=0
2023-09-04 06:11:37 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.881, trans_loss=4.763, nll_loss=1.964, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4145.39, n_correct=2839.98, ppl=3.9, accuracy=68.509, wps=13631.7, ups=1.64, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=0
2023-09-04 06:12:39 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.886, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.628, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4242.46, n_correct=2903.9, ppl=3.92, accuracy=68.448, wps=13727.7, ups=1.62, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=0
2023-09-04 06:12:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 06:13:13 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.897 | trans_loss 5.172 | nll_loss 2.434 | w2v_ctc_loss 1.334 | task_loss 0.001 | task_loss_gen 42.932 | contrastive_loss 0 | total 4003.4 | n_correct 2666.5 | ppl 5.4 | accuracy 66.606 | uer 16.956 | wer 18.821 | raw_wer 18.821 | bleu 21.82 | wps 1557.8 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.38
2023-09-04 06:13:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-09-04 06:13:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_29_42000.pt
2023-09-04 06:13:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_29_42000.pt
2023-09-04 06:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 21.82) (writing took 7.9756826590164565 seconds)
--Backword ST Loss tensor(1527.6355, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1862.0496, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 06:14:22 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.896, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.627, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4027.03, n_correct=2743.72, ppl=3.95, accuracy=68.133, wps=7814.3, ups=0.97, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=0
2023-09-04 06:15:22 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.891, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.63, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4086.72, n_correct=2794.95, ppl=3.93, accuracy=68.391, wps=13546.8, ups=1.66, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=59, gb_free=15, wall=0
2023-09-04 06:16:24 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.888, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.623, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4139.4, n_correct=2830.35, ppl=3.92, accuracy=68.376, wps=13562.1, ups=1.64, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=0
2023-09-04 06:17:24 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.898, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.637, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4072.33, n_correct=2775.38, ppl=3.95, accuracy=68.152, wps=13371.2, ups=1.64, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=0
2023-09-04 06:18:26 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.893, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.634, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4160.52, n_correct=2843.09, ppl=3.94, accuracy=68.335, wps=13579, ups=1.63, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=0
2023-09-04 06:19:27 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.888, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.626, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4168.02, n_correct=2851, ppl=3.92, accuracy=68.402, wps=13535.8, ups=1.62, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=0
2023-09-04 06:20:28 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.89, trans_loss=4.769, nll_loss=1.971, w2v_ctc_loss=0.632, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4166.06, n_correct=2843.55, ppl=3.92, accuracy=68.255, wps=13743.1, ups=1.65, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=0
2023-09-04 06:20:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1400.9055, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1647.4836, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1198.3333, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1331.0239, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1196.8851, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1425.7944, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1505.2123, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1750.3907, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1721.9574, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1938.8687, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1341.0029, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1532.4724, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1251.1437, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1404.8063, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-04 06:21:17 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.162 | nll_loss 2.42 | w2v_ctc_loss 1.322 | task_loss 0 | task_loss_gen 47.466 | contrastive_loss 0 | total 4003.4 | n_correct 2670.9 | ppl 5.35 | accuracy 66.716 | uer 16.853 | wer 18.836 | raw_wer 18.836 | bleu 22.03 | wps 1646.9 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.38
2023-09-04 06:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-09-04 06:21:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0303.pt
2023-09-04 06:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0303.pt
2023-09-04 06:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0303.pt (epoch 29 @ 42727 updates, score 22.03) (writing took 7.210515819024295 seconds)
2023-09-04 06:21:25 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-04 06:21:25 | INFO | train | epoch 029 | loss 1.889 | trans_loss 4.769 | nll_loss 1.971 | w2v_ctc_loss 0.627 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4138.9 | n_correct 2829.23 | ppl 3.92 | accuracy 68.357 | wps 12317 | ups 1.49 | wpb 8277.8 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 888 | gb_free 15.8 | wall 0
2023-09-04 06:21:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 06:21:25 | INFO | fairseq.trainer | begin training epoch 30
2023-09-04 06:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 06:22:17 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.879, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.615, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4175.11, n_correct=2862.83, ppl=3.88, accuracy=68.569, wps=7654.3, ups=0.92, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=0
2023-09-04 06:23:18 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.875, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.619, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4202.64, n_correct=2893.64, ppl=3.83, accuracy=68.853, wps=13802.1, ups=1.64, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=0
2023-09-04 06:24:19 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.886, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.628, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4120.21, n_correct=2827.21, ppl=3.89, accuracy=68.618, wps=13498.5, ups=1.64, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=0
2023-09-04 06:25:21 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.878, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4178.23, n_correct=2872.77, ppl=3.85, accuracy=68.756, wps=13530.3, ups=1.62, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=9.6, wall=0
2023-09-04 06:26:21 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.878, trans_loss=4.757, nll_loss=1.956, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4124.47, n_correct=2830.55, ppl=3.88, accuracy=68.628, wps=13601.9, ups=1.65, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=0
2023-09-04 06:27:22 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.88, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.62, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4168.41, n_correct=2861.3, ppl=3.88, accuracy=68.642, wps=13745.2, ups=1.65, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=0
2023-09-04 06:28:24 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.885, trans_loss=4.761, nll_loss=1.96, w2v_ctc_loss=0.627, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4187.95, n_correct=2864.85, ppl=3.89, accuracy=68.407, wps=13545.9, ups=1.62, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=0
2023-09-04 06:29:25 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.89, trans_loss=4.765, nll_loss=1.966, w2v_ctc_loss=0.63, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4105.32, n_correct=2808.62, ppl=3.91, accuracy=68.414, wps=13411.6, ups=1.63, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=12.6, wall=0
2023-09-04 06:30:27 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.884, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4102.11, n_correct=2815.42, ppl=3.89, accuracy=68.633, wps=13362, ups=1.63, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-09-04 06:31:28 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.889, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.63, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4129.98, n_correct=2823.79, ppl=3.91, accuracy=68.373, wps=13501.2, ups=1.63, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 06:32:29 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.89, trans_loss=4.765, nll_loss=1.964, w2v_ctc_loss=0.624, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4101.17, n_correct=2805.55, ppl=3.9, accuracy=68.409, wps=13308.5, ups=1.62, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=0
2023-09-04 06:33:31 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.879, trans_loss=4.76, nll_loss=1.96, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4168.36, n_correct=2859.34, ppl=3.89, accuracy=68.596, wps=13617.2, ups=1.63, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=0
2023-09-04 06:34:32 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.891, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.63, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4036.17, n_correct=2763.11, ppl=3.91, accuracy=68.459, wps=13160.4, ups=1.63, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=0
2023-09-04 06:34:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 06:35:07 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.883 | trans_loss 5.164 | nll_loss 2.421 | w2v_ctc_loss 1.308 | task_loss 0 | task_loss_gen 54.708 | contrastive_loss 0 | total 4003.4 | n_correct 2672.1 | ppl 5.36 | accuracy 66.746 | uer 16.914 | wer 18.784 | raw_wer 18.784 | bleu 22.05 | wps 1505.5 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.38
2023-09-04 06:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-09-04 06:35:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_30_44000.pt
2023-09-04 06:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_30_44000.pt
2023-09-04 06:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.05) (writing took 9.519791733007878 seconds)
--Backword ST Loss tensor(1562.6602, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1803.7324, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 06:36:17 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.878, trans_loss=4.761, nll_loss=1.962, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4165.07, n_correct=2857.06, ppl=3.9, accuracy=68.596, wps=7898.7, ups=0.95, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-09-04 06:37:19 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.879, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.612, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4141.76, n_correct=2839.3, ppl=3.9, accuracy=68.553, wps=13545.2, ups=1.64, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 06:37:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(870.9293, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1020.4556, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1970.8209, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(2284.9048, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(921.8837, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1128.3702, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1296.6302, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1333.0278, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1666.9011, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1777.3777, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1260.6949, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1373.0259, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1743.4742, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1894.3118, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-04 06:37:53 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.889 | trans_loss 5.167 | nll_loss 2.428 | w2v_ctc_loss 1.319 | task_loss 0 | task_loss_gen 55.286 | contrastive_loss 0 | total 4003.4 | n_correct 2671.4 | ppl 5.38 | accuracy 66.728 | uer 17.073 | wer 19.071 | raw_wer 19.071 | bleu 22.12 | wps 1565.4 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 22.38
2023-09-04 06:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-09-04 06:37:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.1204.pt
2023-09-04 06:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.1204.pt
2023-09-04 06:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.1204.pt (epoch 30 @ 44201 updates, score 22.12) (writing took 7.665560431021731 seconds)
2023-09-04 06:38:01 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-04 06:38:01 | INFO | train | epoch 030 | loss 1.883 | trans_loss 4.76 | nll_loss 1.958 | w2v_ctc_loss 0.621 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4138.65 | n_correct 2837.93 | ppl 3.89 | accuracy 68.571 | wps 12241.3 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 16.8 | wall 0
2023-09-04 06:38:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 06:38:02 | INFO | fairseq.trainer | begin training epoch 31
2023-09-04 06:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 06:39:09 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.883, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.625, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4054.44, n_correct=2784.04, ppl=3.85, accuracy=68.666, wps=7326.8, ups=0.9, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 06:40:10 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.877, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.614, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4147.4, n_correct=2853.47, ppl=3.85, accuracy=68.801, wps=13588.8, ups=1.64, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-09-04 06:41:12 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.878, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4149.21, n_correct=2857.15, ppl=3.84, accuracy=68.86, wps=13364.8, ups=1.61, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=0
2023-09-04 06:42:14 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.882, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4092.62, n_correct=2810.58, ppl=3.87, accuracy=68.674, wps=13353.7, ups=1.63, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-09-04 06:43:15 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.882, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.626, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4111.85, n_correct=2827.77, ppl=3.85, accuracy=68.771, wps=13370.1, ups=1.63, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=10.6, wall=0
2023-09-04 06:44:16 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.878, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4083.44, n_correct=2806.77, ppl=3.85, accuracy=68.735, wps=13403.2, ups=1.64, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=0
2023-09-04 06:45:17 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.871, trans_loss=4.745, nll_loss=1.94, w2v_ctc_loss=0.608, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4213.98, n_correct=2902.99, ppl=3.84, accuracy=68.89, wps=13896.9, ups=1.65, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 06:46:19 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.881, trans_loss=4.755, nll_loss=1.953, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4097.37, n_correct=2809.41, ppl=3.87, accuracy=68.566, wps=13270.8, ups=1.62, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=12.5, wall=0
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:0')
2023-09-04 06:47:20 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.88, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.621, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4096.72, n_correct=2812.92, ppl=3.84, accuracy=68.663, wps=13434.6, ups=1.64, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-09-04 06:48:21 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.878, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.613, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4187.84, n_correct=2875.62, ppl=3.88, accuracy=68.666, wps=13638.8, ups=1.63, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=0
2023-09-04 06:49:21 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.878, trans_loss=4.753, nll_loss=1.951, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4149.44, n_correct=2852.87, ppl=3.87, accuracy=68.753, wps=13711.5, ups=1.65, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=0
2023-09-04 06:50:22 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.874, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.612, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4189.76, n_correct=2879.84, ppl=3.86, accuracy=68.735, wps=13836.8, ups=1.65, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=12.8, wall=0
2023-09-04 06:51:23 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.879, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.62, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4227.44, n_correct=2901.54, ppl=3.89, accuracy=68.636, wps=13805.2, ups=1.63, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 06:52:24 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.878, trans_loss=4.757, nll_loss=1.956, w2v_ctc_loss=0.613, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4186.05, n_correct=2870.73, ppl=3.88, accuracy=68.578, wps=13675, ups=1.63, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=0
2023-09-04 06:53:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2132, device='cuda:7')
2023-09-04 06:53:43 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.163 | nll_loss 2.421 | w2v_ctc_loss 1.313 | task_loss 0 | task_loss_gen 61.826 | contrastive_loss 0 | total 4003.4 | n_correct 2672.9 | ppl 5.35 | accuracy 66.766 | uer 16.529 | wer 18.594 | raw_wer 18.594 | bleu 22.09 | wps 1603.7 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 22.38
2023-09-04 06:53:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-09-04 06:53:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0900.pt
2023-09-04 06:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0900.pt
2023-09-04 06:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0900.pt (epoch 31 @ 45675 updates, score 22.09) (writing took 7.6763639619457535 seconds)
2023-09-04 06:53:52 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-04 06:53:52 | INFO | train | epoch 031 | loss 1.879 | trans_loss 4.752 | nll_loss 1.949 | w2v_ctc_loss 0.617 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4138.65 | n_correct 2843.52 | ppl 3.86 | accuracy 68.706 | wps 12839.3 | ups 1.55 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.534 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 11.7 | wall 0
2023-09-04 06:53:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 06:53:52 | INFO | fairseq.trainer | begin training epoch 32
2023-09-04 06:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 06:54:14 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.881, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.62, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4042.6, n_correct=2777.67, ppl=3.85, accuracy=68.71, wps=7365.7, ups=0.91, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=0
2023-09-04 06:55:15 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.857, trans_loss=4.726, nll_loss=1.916, w2v_ctc_loss=0.592, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4227.68, n_correct=2931.54, ppl=3.77, accuracy=69.342, wps=13902.1, ups=1.64, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=0
2023-09-04 06:55:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-04 06:56:17 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.87, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4160.02, n_correct=2866.66, ppl=3.84, accuracy=68.91, wps=13463.5, ups=1.62, wpb=8320, bsz=321.9, num_updates=45900, lr=6.60098e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=0
2023-09-04 06:57:17 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.864, trans_loss=4.73, nll_loss=1.921, w2v_ctc_loss=0.602, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4179.65, n_correct=2892.16, ppl=3.79, accuracy=69.196, wps=13815.4, ups=1.65, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 06:57:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 06:57:52 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.171 | nll_loss 2.431 | w2v_ctc_loss 1.344 | task_loss 0 | task_loss_gen 61.423 | contrastive_loss 0 | total 4003.4 | n_correct 2672.3 | ppl 5.39 | accuracy 66.751 | uer 16.874 | wer 18.705 | raw_wer 18.705 | bleu 22.33 | wps 1529.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.38
2023-09-04 06:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-09-04 06:57:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_32_46000.pt
2023-09-04 06:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_32_46000.pt
2023-09-04 06:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.33) (writing took 7.93557624402456 seconds)
--Backword ST Loss tensor(891.7504, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(954.7181, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 06:59:01 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.866, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.606, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4172.34, n_correct=2884.85, ppl=3.79, accuracy=69.142, wps=8068.5, ups=0.97, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=0
2023-09-04 07:00:03 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.875, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4191.15, n_correct=2886.56, ppl=3.84, accuracy=68.873, wps=13534.5, ups=1.61, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=14.7, wall=0
2023-09-04 07:01:04 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.877, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4138.05, n_correct=2844.89, ppl=3.84, accuracy=68.75, wps=13461.1, ups=1.63, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=12.9, wall=0
2023-09-04 07:02:06 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.876, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4156.23, n_correct=2864.46, ppl=3.83, accuracy=68.92, wps=13532.2, ups=1.63, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=0
2023-09-04 07:03:07 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.87, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.604, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4112.3, n_correct=2838.82, ppl=3.82, accuracy=69.032, wps=13526.1, ups=1.64, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=0
2023-09-04 07:04:08 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.874, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4139.37, n_correct=2850.74, ppl=3.83, accuracy=68.869, wps=13483.3, ups=1.63, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=12.3, wall=0
2023-09-04 07:05:09 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.874, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.612, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4121.85, n_correct=2834.77, ppl=3.84, accuracy=68.774, wps=13456.4, ups=1.63, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=0
2023-09-04 07:06:11 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.884, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4015.59, n_correct=2755.92, ppl=3.85, accuracy=68.631, wps=13083.6, ups=1.63, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=0
2023-09-04 07:07:12 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.879, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.613, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4153.44, n_correct=2851.11, ppl=3.87, accuracy=68.645, wps=13605.2, ups=1.64, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-09-04 07:08:12 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.878, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.618, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4075.86, n_correct=2807.29, ppl=3.84, accuracy=68.876, wps=13465.4, ups=1.65, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-09-04 07:09:13 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.881, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.622, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4116.4, n_correct=2828.17, ppl=3.85, accuracy=68.705, wps=13426.2, ups=1.63, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=0
2023-09-04 07:09:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(928.5753, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1089.1147, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1383.9115, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1640.7698, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(892.0282, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1004.3251, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1654.3218, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1814.2375, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1528.3284, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1672.5210, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1417.7937, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1709.8312, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1594.7246, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1787.8124, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-04 07:10:15 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.901 | trans_loss 5.165 | nll_loss 2.424 | w2v_ctc_loss 1.363 | task_loss 0 | task_loss_gen 66.676 | contrastive_loss 0 | total 4003.4 | n_correct 2675.3 | ppl 5.37 | accuracy 66.826 | uer 16.927 | wer 18.825 | raw_wer 18.825 | bleu 22.08 | wps 1647.2 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 22.38
2023-09-04 07:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-09-04 07:10:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0806.pt
2023-09-04 07:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0806.pt
2023-09-04 07:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.0806.pt (epoch 32 @ 47148 updates, score 22.08) (writing took 8.740501577034593 seconds)
2023-09-04 07:10:24 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-04 07:10:24 | INFO | train | epoch 032 | loss 1.873 | trans_loss 4.743 | nll_loss 1.937 | w2v_ctc_loss 0.611 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4138.86 | n_correct 2851.97 | ppl 3.83 | accuracy 68.907 | wps 12286.5 | ups 1.48 | wpb 8277.7 | bsz 305.8 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.533 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 16 | wall 0
2023-09-04 07:10:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 07:10:24 | INFO | fairseq.trainer | begin training epoch 33
2023-09-04 07:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 07:11:04 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.867, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.607, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4149.21, n_correct=2862.23, ppl=3.82, accuracy=68.983, wps=7536.8, ups=0.91, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=0
2023-09-04 07:12:05 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.859, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.586, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4073.9, n_correct=2826.56, ppl=3.76, accuracy=69.382, wps=13337.4, ups=1.64, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=0
2023-09-04 07:13:06 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.859, trans_loss=4.729, nll_loss=1.92, w2v_ctc_loss=0.598, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4280.14, n_correct=2963.5, ppl=3.78, accuracy=69.238, wps=14004.6, ups=1.64, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-09-04 07:14:07 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.874, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.616, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4120.27, n_correct=2841.74, ppl=3.81, accuracy=68.97, wps=13463.4, ups=1.63, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=0
2023-09-04 07:15:07 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.856, trans_loss=4.721, nll_loss=1.908, w2v_ctc_loss=0.594, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4141.22, n_correct=2874.99, ppl=3.75, accuracy=69.424, wps=13716.7, ups=1.66, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=0
2023-09-04 07:16:09 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.871, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4133.59, n_correct=2854.22, ppl=3.8, accuracy=69.049, wps=13528.2, ups=1.64, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=0
2023-09-04 07:17:10 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.873, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.606, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4157.63, n_correct=2861.3, ppl=3.84, accuracy=68.82, wps=13531.7, ups=1.63, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=0
2023-09-04 07:18:11 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.881, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.624, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4070.75, n_correct=2804.01, ppl=3.82, accuracy=68.882, wps=13376.3, ups=1.64, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=0
2023-09-04 07:19:11 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.861, trans_loss=4.733, nll_loss=1.925, w2v_ctc_loss=0.595, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4130.24, n_correct=2859.16, ppl=3.8, accuracy=69.225, wps=13625.6, ups=1.65, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=0
2023-09-04 07:19:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 07:19:44 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.892 | trans_loss 5.169 | nll_loss 2.426 | w2v_ctc_loss 1.326 | task_loss 0 | task_loss_gen 71.608 | contrastive_loss 0 | total 4003.4 | n_correct 2675.3 | ppl 5.37 | accuracy 66.826 | uer 16.834 | wer 18.668 | raw_wer 18.668 | bleu 22.2 | wps 1639.8 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.38
2023-09-04 07:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-09-04 07:19:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_33_48000.pt
2023-09-04 07:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_33_48000.pt
2023-09-04 07:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.2) (writing took 7.637788949010428 seconds)
--Backword ST Loss tensor(1670.1848, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(2065.3950, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-04 07:20:54 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.874, trans_loss=4.738, nll_loss=1.931, w2v_ctc_loss=0.62, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4151.18, n_correct=2865.18, ppl=3.81, accuracy=69.021, wps=8137.7, ups=0.98, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=60, gb_free=10.9, wall=0
2023-09-04 07:21:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-04 07:21:56 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.871, trans_loss=4.736, nll_loss=1.928, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4143.8, n_correct=2857.64, ppl=3.81, accuracy=68.962, wps=13332.1, ups=1.61, wpb=8287.6, bsz=307.8, num_updates=48200, lr=6.44157e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=0
2023-09-04 07:22:57 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.868, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.598, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4181.58, n_correct=2883.81, ppl=3.83, accuracy=68.965, wps=13543.8, ups=1.62, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=14.8, wall=0
2023-09-04 07:23:58 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.873, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4115.76, n_correct=2842.16, ppl=3.81, accuracy=69.056, wps=13511.9, ups=1.64, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-09-04 07:25:00 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.869, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.611, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4120.69, n_correct=2845.86, ppl=3.82, accuracy=69.063, wps=13457.1, ups=1.63, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-09-04 07:26:01 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.868, trans_loss=4.739, nll_loss=1.933, w2v_ctc_loss=0.601, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4125.28, n_correct=2844.23, ppl=3.82, accuracy=68.946, wps=13480.1, ups=1.63, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=0
2023-09-04 07:26:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1605.1661, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1732.7070, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1357.8292, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1640.0652, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1426.4148, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1728.7241, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1428.9790, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1581.4657, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(996.9385, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1201.8016, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(888.1398, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1039.3318, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1683.6301, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1961.2249, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-04 07:26:46 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.167 | nll_loss 2.426 | w2v_ctc_loss 1.362 | task_loss 0 | task_loss_gen 73.526 | contrastive_loss 0 | total 4003.4 | n_correct 2674.3 | ppl 5.38 | accuracy 66.801 | uer 16.914 | wer 18.631 | raw_wer 18.631 | bleu 22.31 | wps 1636.6 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 22.38
2023-09-04 07:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-09-04 07:26:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.3107.pt
2023-09-04 07:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.3107.pt
2023-09-04 07:26:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint.best_bleu_22.3107.pt (epoch 33 @ 48621 updates, score 22.31) (writing took 7.548177863995079 seconds)
2023-09-04 07:26:54 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-04 07:26:54 | INFO | train | epoch 033 | loss 1.868 | trans_loss 4.735 | nll_loss 1.927 | w2v_ctc_loss 0.606 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4138.84 | n_correct 2858.92 | ppl 3.8 | accuracy 69.075 | wps 12314.3 | ups 1.49 | wpb 8277.7 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.535 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 17.5 | wall 0
2023-09-04 07:26:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-04 07:26:54 | INFO | fairseq.trainer | begin training epoch 34
2023-09-04 07:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-04 07:27:50 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.863, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.602, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4131.47, n_correct=2861.48, ppl=3.76, accuracy=69.261, wps=7551.9, ups=0.91, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-09-04 07:28:52 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.86, trans_loss=4.714, nll_loss=1.899, w2v_ctc_loss=0.602, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4065.88, n_correct=2824.79, ppl=3.73, accuracy=69.475, wps=13268.2, ups=1.63, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=0
2023-09-04 07:29:53 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.862, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.594, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4246.3, n_correct=2932.97, ppl=3.79, accuracy=69.071, wps=13896, ups=1.64, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=0
2023-09-04 07:30:53 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.858, trans_loss=4.718, nll_loss=1.905, w2v_ctc_loss=0.601, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4156.17, n_correct=2883.37, ppl=3.74, accuracy=69.376, wps=13709.7, ups=1.65, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=0
2023-09-04 07:31:55 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.873, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.617, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4070.55, n_correct=2811.6, ppl=3.78, accuracy=69.072, wps=13298.5, ups=1.63, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=0
2023-09-04 07:32:55 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.855, trans_loss=4.714, nll_loss=1.899, w2v_ctc_loss=0.591, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4119.38, n_correct=2867.37, ppl=3.73, accuracy=69.607, wps=13559.2, ups=1.65, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=12.7, wall=0
2023-09-04 07:33:56 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.86, trans_loss=4.725, nll_loss=1.914, w2v_ctc_loss=0.595, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4124.83, n_correct=2857.97, ppl=3.77, accuracy=69.287, wps=13488.5, ups=1.64, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=60, gb_free=13.9, wall=0
2023-09-04 07:34:57 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.87, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.598, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4082.07, n_correct=2814.31, ppl=3.83, accuracy=68.943, wps=13407.2, ups=1.64, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=0
2023-09-04 07:35:59 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.869, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.606, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4100.9, n_correct=2837.09, ppl=3.8, accuracy=69.182, wps=13408.9, ups=1.63, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=11.8, wall=0
2023-09-04 07:37:00 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.868, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.612, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4168.39, n_correct=2879.66, ppl=3.79, accuracy=69.083, wps=13640.3, ups=1.64, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=0
2023-09-04 07:38:01 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.869, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.614, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4150.57, n_correct=2869.72, ppl=3.79, accuracy=69.14, wps=13615.7, ups=1.64, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=0
2023-09-04 07:39:02 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.866, trans_loss=4.731, nll_loss=1.922, w2v_ctc_loss=0.604, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4098.77, n_correct=2835.91, ppl=3.79, accuracy=69.189, wps=13344.6, ups=1.63, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=0
2023-09-04 07:40:03 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.862, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.601, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4150.54, n_correct=2876.44, ppl=3.76, accuracy=69.303, wps=13686, ups=1.65, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=0
2023-09-04 07:41:04 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.867, trans_loss=4.735, nll_loss=1.927, w2v_ctc_loss=0.607, task_loss=0, task_loss_gen=0, contrastive_loss=0, total=4196.91, n_correct=2897.15, ppl=3.8, accuracy=69.031, wps=13603.9, ups=1.62, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=0
2023-09-04 07:41:04 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-04 07:41:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-04 07:41:39 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.174 | nll_loss 2.433 | w2v_ctc_loss 1.336 | task_loss 0 | task_loss_gen 77.474 | contrastive_loss 0 | total 4003.4 | n_correct 2669.3 | ppl 5.4 | accuracy 66.676 | uer 16.829 | wer 18.657 | raw_wer 18.657 | bleu 21.84 | wps 1517.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.38
2023-09-04 07:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-09-04 07:41:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_34_50000.pt
2023-09-04 07:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_34_50000.pt
2023-09-04 07:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0903_shrink_soft_noCL_AT_sentence_mixup0005_changeid_3_scale1_alpha1.5_mt1/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 21.84) (writing took 7.57410011801403 seconds)
2023-09-04 07:41:47 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-04 07:41:47 | INFO | train | epoch 034 | loss 1.864 | trans_loss 4.728 | nll_loss 1.917 | w2v_ctc_loss 0.603 | task_loss 0 | task_loss_gen 0 | contrastive_loss 0 | total 4133.04 | n_correct 2860.75 | ppl 3.78 | accuracy 69.217 | wps 12762.1 | ups 1.54 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.536 | clip 0 | loss_scale 32 | train_wall 831 | gb_free 15.7 | wall 0
2023-09-04 07:41:47 | INFO | fairseq_cli.train | done training in 29838.6 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1248 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
