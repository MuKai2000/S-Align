2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-06 01:14:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13986', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-06 01:14:09 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 01:14:13 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-06 01:14:13 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-06 01:14:13 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-06 01:14:15 | INFO | root | load pretrained hubert
2023-09-06 01:14:23 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 01:14:27 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 01:14:33 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 01:14:33 | INFO | root | share the sematic adapter and textual encoder
2023-09-06 01:14:33 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-06 01:14:33 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-06 01:14:33 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-06 01:14:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-06 01:14:33 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-09-06 01:14:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-06 01:14:33 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 01:14:33 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:33 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:33 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:14:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-06 01:14:49 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-06 01:14:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 01:14:50 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-06 01:14:50 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-09-06 01:14:50 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 01:14:50 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 01:14:50 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-06 01:14:50 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 01:14:50 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:50 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:14:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:15:45 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-06 01:15:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:15:45 | INFO | fairseq.trainer | begin training epoch 1
2023-09-06 01:15:45 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 01:16:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 01:17:57 | INFO | train_inner | epoch 001:    101 / 1191 loss=17.16, trans_loss=6.401, nll_loss=5.175, w2v_ctc_loss=21.38, task_loss=3.03, task_loss_gen=3.551, contrastive_loss=0, total=6742.88, n_correct=205.42, ppl=36.13, accuracy=3.046, wps=17186.3, ups=0.88, wpb=19527.6, bsz=683.2, num_updates=100, lr=4.098e-06, gnorm=1.634, clip=0, loss_scale=64, train_wall=120, gb_free=17.7, wall=186
2023-09-06 01:18:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 01:19:59 | INFO | train_inner | epoch 001:    202 / 1191 loss=13.548, trans_loss=6.32, nll_loss=5.118, w2v_ctc_loss=15.898, task_loss=2.312, task_loss_gen=3.909, contrastive_loss=0, total=6677.34, n_correct=191.45, ppl=34.72, accuracy=2.867, wps=15869.1, ups=0.82, wpb=19352.7, bsz=677.6, num_updates=200, lr=8.096e-06, gnorm=6.139, clip=4, loss_scale=32, train_wall=121, gb_free=17.8, wall=308
2023-09-06 01:22:03 | INFO | train_inner | epoch 001:    302 / 1191 loss=8.437, trans_loss=6.223, nll_loss=5.054, w2v_ctc_loss=8.128, task_loss=1.177, task_loss_gen=4.482, contrastive_loss=0, total=6864.64, n_correct=200.05, ppl=33.21, accuracy=2.914, wps=15992.5, ups=0.8, wpb=19894.5, bsz=719.8, num_updates=300, lr=1.2094e-05, gnorm=1.619, clip=0, loss_scale=32, train_wall=124, gb_free=18.2, wall=433
2023-09-06 01:23:58 | INFO | train_inner | epoch 001:    402 / 1191 loss=7.904, trans_loss=6.136, nll_loss=4.986, w2v_ctc_loss=7.387, task_loss=0.573, task_loss_gen=7.44, contrastive_loss=0, total=6664.2, n_correct=185.4, ppl=31.69, accuracy=2.782, wps=16791.7, ups=0.87, wpb=19324, bsz=657.6, num_updates=400, lr=1.6092e-05, gnorm=0.833, clip=0, loss_scale=32, train_wall=106, gb_free=17.9, wall=548
2023-09-06 01:25:56 | INFO | train_inner | epoch 001:    502 / 1191 loss=7.647, trans_loss=6.107, nll_loss=4.961, w2v_ctc_loss=7.029, task_loss=0.17, task_loss_gen=9.748, contrastive_loss=0, total=6743.88, n_correct=179.93, ppl=31.15, accuracy=2.668, wps=16526.4, ups=0.85, wpb=19536.7, bsz=687.8, num_updates=500, lr=2.009e-05, gnorm=0.702, clip=0, loss_scale=32, train_wall=118, gb_free=17.7, wall=666
2023-09-06 01:27:52 | INFO | train_inner | epoch 001:    602 / 1191 loss=7.547, trans_loss=6.083, nll_loss=4.94, w2v_ctc_loss=6.898, task_loss=0.051, task_loss_gen=12.882, contrastive_loss=0, total=6761.26, n_correct=171.21, ppl=30.7, accuracy=2.532, wps=16854.2, ups=0.86, wpb=19590.9, bsz=685.7, num_updates=600, lr=2.4088e-05, gnorm=0.852, clip=0, loss_scale=32, train_wall=116, gb_free=18.9, wall=782
2023-09-06 01:29:44 | INFO | train_inner | epoch 001:    702 / 1191 loss=7.439, trans_loss=6.047, nll_loss=4.905, w2v_ctc_loss=6.768, task_loss=0.016, task_loss_gen=16.198, contrastive_loss=0, total=6642.51, n_correct=157.58, ppl=29.96, accuracy=2.372, wps=17275.5, ups=0.9, wpb=19237.1, bsz=677.7, num_updates=700, lr=2.8086e-05, gnorm=0.875, clip=0, loss_scale=32, train_wall=110, gb_free=17.6, wall=894
2023-09-06 01:31:25 | INFO | train_inner | epoch 001:    802 / 1191 loss=7.378, trans_loss=5.986, nll_loss=4.837, w2v_ctc_loss=6.738, task_loss=0.005, task_loss_gen=18.296, contrastive_loss=0, total=6747.81, n_correct=149.5, ppl=28.58, accuracy=2.216, wps=19386.2, ups=0.99, wpb=19542.8, bsz=688.1, num_updates=800, lr=3.2084e-05, gnorm=0.908, clip=0, loss_scale=32, train_wall=100, gb_free=17.7, wall=994
2023-09-06 01:32:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 01:32:53 | INFO | train_inner | epoch 001:    903 / 1191 loss=6.964, trans_loss=5.854, nll_loss=4.686, w2v_ctc_loss=6.237, task_loss=0.003, task_loss_gen=21.91, contrastive_loss=0, total=6690.14, n_correct=87.23, ppl=25.75, accuracy=1.304, wps=21835.9, ups=1.13, wpb=19388, bsz=669.3, num_updates=900, lr=3.6082e-05, gnorm=1.305, clip=0, loss_scale=16, train_wall=88, gb_free=17.6, wall=1083
2023-09-06 01:34:15 | INFO | train_inner | epoch 001:   1003 / 1191 loss=6.284, trans_loss=5.884, nll_loss=4.721, w2v_ctc_loss=5.158, task_loss=0, task_loss_gen=27.059, contrastive_loss=0, total=6668.9, n_correct=24.82, ppl=26.38, accuracy=0.372, wps=23850.3, ups=1.23, wpb=19321.9, bsz=662.2, num_updates=1000, lr=4.008e-05, gnorm=0.435, clip=0, loss_scale=16, train_wall=80, gb_free=18.5, wall=1164
2023-09-06 01:35:35 | INFO | train_inner | epoch 001:   1103 / 1191 loss=6.228, trans_loss=6.192, nll_loss=5.081, w2v_ctc_loss=4.742, task_loss=0.943, task_loss_gen=14.75, contrastive_loss=0, total=6578.13, n_correct=20.56, ppl=33.84, accuracy=0.313, wps=23821.3, ups=1.25, wpb=19050.5, bsz=647.4, num_updates=1100, lr=4.4078e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=79, gb_free=17.6, wall=1244
2023-09-06 01:36:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-06 01:37:35 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 11.667 | trans_loss 14.713 | nll_loss 14.863 | w2v_ctc_loss 5.648 | task_loss 10.08 | task_loss_gen 22.958 | contrastive_loss 0 | total 6138.43 | n_correct 0.428571 | ppl 29802.6 | accuracy 0.007 | uer 75.733 | wer 73.663 | raw_wer 73.663 | bleu 0 | wps 1203.2 | wpb 6138.4 | bsz 201.1 | num_updates 1188
2023-09-06 01:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1188 updates
2023-09-06 01:37:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:37:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 1 @ 1188 updates, score 0.0) (writing took 5.493970101000741 seconds)
2023-09-06 01:37:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-06 01:37:41 | INFO | train | epoch 001 | loss 8.576 | trans_loss 6.119 | nll_loss 4.966 | w2v_ctc_loss 8.445 | task_loss 0.876 | task_loss_gen 12.03 | contrastive_loss 0 | total 6702.44 | n_correct 134.058 | ppl 31.26 | accuracy 2 | wps 17779.6 | ups 0.92 | wpb 19419.2 | bsz 677.7 | num_updates 1188 | lr 4.75962e-05 | gnorm 1.37 | clip 0.3 | loss_scale 16 | train_wall 1226 | gb_free 18.5 | wall 1370
2023-09-06 01:37:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:37:41 | INFO | fairseq.trainer | begin training epoch 2
2023-09-06 01:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 01:37:56 | INFO | train_inner | epoch 002:     12 / 1191 loss=5.948, trans_loss=6.21, nll_loss=5.164, w2v_ctc_loss=4.295, task_loss=2.35, task_loss_gen=4.008, contrastive_loss=0, total=6631.26, n_correct=20.43, ppl=35.84, accuracy=0.308, wps=13550.5, ups=0.71, wpb=19218.6, bsz=679.5, num_updates=1200, lr=4.8076e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=71, gb_free=17.5, wall=1386
2023-09-06 01:39:01 | INFO | train_inner | epoch 002:    112 / 1191 loss=5.739, trans_loss=6.226, nll_loss=5.171, w2v_ctc_loss=3.956, task_loss=2.052, task_loss_gen=4.16, contrastive_loss=0, total=6617.43, n_correct=18.82, ppl=36.02, accuracy=0.284, wps=29573, ups=1.54, wpb=19164.1, bsz=662.2, num_updates=1300, lr=5.2074e-05, gnorm=0.641, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=1451
2023-09-06 01:40:07 | INFO | train_inner | epoch 002:    212 / 1191 loss=5.709, trans_loss=6.426, nll_loss=5.426, w2v_ctc_loss=3.698, task_loss=1.778, task_loss_gen=4.266, contrastive_loss=0, total=6716.9, n_correct=14.63, ppl=42.99, accuracy=0.218, wps=29643.3, ups=1.52, wpb=19456.2, bsz=672.8, num_updates=1400, lr=5.6072e-05, gnorm=0.689, clip=0, loss_scale=16, train_wall=65, gb_free=17.5, wall=1517
2023-09-06 01:41:12 | INFO | train_inner | epoch 002:    312 / 1191 loss=5.55, trans_loss=6.385, nll_loss=5.365, w2v_ctc_loss=3.498, task_loss=1.64, task_loss_gen=4.107, contrastive_loss=0, total=6776.25, n_correct=14.19, ppl=41.2, accuracy=0.209, wps=29990.2, ups=1.53, wpb=19634.6, bsz=690.8, num_updates=1500, lr=6.007e-05, gnorm=0.731, clip=0, loss_scale=16, train_wall=65, gb_free=18, wall=1582
2023-09-06 01:42:17 | INFO | train_inner | epoch 002:    412 / 1191 loss=5.37, trans_loss=6.272, nll_loss=5.226, w2v_ctc_loss=3.341, task_loss=1.231, task_loss_gen=4.668, contrastive_loss=0, total=6718.15, n_correct=8.83, ppl=37.43, accuracy=0.131, wps=29973.5, ups=1.54, wpb=19472.2, bsz=690.8, num_updates=1600, lr=6.4068e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=1647
2023-09-06 01:43:22 | INFO | train_inner | epoch 002:    512 / 1191 loss=5.156, trans_loss=6.071, nll_loss=4.979, w2v_ctc_loss=3.218, task_loss=1.035, task_loss_gen=5.221, contrastive_loss=0, total=6696.54, n_correct=19.66, ppl=31.55, accuracy=0.294, wps=29819.3, ups=1.54, wpb=19408.7, bsz=678.7, num_updates=1700, lr=6.8066e-05, gnorm=0.752, clip=0, loss_scale=16, train_wall=65, gb_free=18.1, wall=1712
2023-09-06 01:44:27 | INFO | train_inner | epoch 002:    612 / 1191 loss=5.126, trans_loss=6.153, nll_loss=5.069, w2v_ctc_loss=3.086, task_loss=1.028, task_loss_gen=5.422, contrastive_loss=0, total=6640.77, n_correct=13.21, ppl=33.58, accuracy=0.199, wps=29517, ups=1.54, wpb=19228.2, bsz=659.1, num_updates=1800, lr=7.2064e-05, gnorm=0.768, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=1777
2023-09-06 01:45:32 | INFO | train_inner | epoch 002:    712 / 1191 loss=5.042, trans_loss=6.13, nll_loss=5.038, w2v_ctc_loss=2.985, task_loss=0.65, task_loss_gen=5.788, contrastive_loss=0, total=6799.78, n_correct=13.39, ppl=32.85, accuracy=0.197, wps=30520.5, ups=1.55, wpb=19685.9, bsz=701.6, num_updates=1900, lr=7.6062e-05, gnorm=0.765, clip=0, loss_scale=16, train_wall=64, gb_free=17.9, wall=1842
2023-09-06 01:46:37 | INFO | train_inner | epoch 002:    812 / 1191 loss=5.001, trans_loss=6.14, nll_loss=5.03, w2v_ctc_loss=2.906, task_loss=0.475, task_loss_gen=6.615, contrastive_loss=0, total=6729.15, n_correct=10.27, ppl=32.67, accuracy=0.153, wps=29842.1, ups=1.53, wpb=19495.9, bsz=677.7, num_updates=2000, lr=8.006e-05, gnorm=0.75, clip=0, loss_scale=16, train_wall=65, gb_free=17.7, wall=1907
2023-09-06 01:46:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 01:47:21 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.846 | trans_loss 12.902 | nll_loss 12.568 | w2v_ctc_loss 3.672 | task_loss 7.175 | task_loss_gen 24.859 | contrastive_loss 0 | total 6138.43 | n_correct 32 | ppl 6070.99 | accuracy 0.521 | uer 55.069 | wer 53.589 | raw_wer 53.589 | bleu 0 | wps 1217.4 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-09-06 01:47:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-06 01:47:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 01:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 01:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 19.330662569962442 seconds)
2023-09-06 01:48:46 | INFO | train_inner | epoch 002:    912 / 1191 loss=4.945, trans_loss=6.136, nll_loss=5.065, w2v_ctc_loss=2.829, task_loss=0.279, task_loss_gen=7.663, contrastive_loss=0, total=6738.95, n_correct=14.6, ppl=33.48, accuracy=0.217, wps=15218.2, ups=0.78, wpb=19533.2, bsz=703.8, num_updates=2100, lr=8.4058e-05, gnorm=0.834, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=2036
2023-09-06 01:49:51 | INFO | train_inner | epoch 002:   1012 / 1191 loss=5.063, trans_loss=6.351, nll_loss=5.318, w2v_ctc_loss=2.779, task_loss=0.151, task_loss_gen=9.471, contrastive_loss=0, total=6774.79, n_correct=12.94, ppl=39.89, accuracy=0.191, wps=30232.3, ups=1.54, wpb=19640.8, bsz=687.3, num_updates=2200, lr=8.8056e-05, gnorm=0.689, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=2100
2023-09-06 01:50:55 | INFO | train_inner | epoch 002:   1112 / 1191 loss=4.888, trans_loss=6.15, nll_loss=5.066, w2v_ctc_loss=2.722, task_loss=0.081, task_loss_gen=11.642, contrastive_loss=0, total=6659.17, n_correct=33.27, ppl=33.49, accuracy=0.5, wps=29905.7, ups=1.55, wpb=19287, bsz=656.7, num_updates=2300, lr=9.2054e-05, gnorm=0.656, clip=0, loss_scale=16, train_wall=64, gb_free=18.4, wall=2165
2023-09-06 01:51:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 01:52:30 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.953 | trans_loss 14.672 | nll_loss 14.75 | w2v_ctc_loss 3.361 | task_loss 0.58 | task_loss_gen 55.969 | contrastive_loss 0 | total 6138.43 | n_correct 0.285714 | ppl 27553.3 | accuracy 0.005 | uer 50.836 | wer 50.643 | raw_wer 50.643 | bleu 0 | wps 1214.3 | wpb 6138.4 | bsz 201.1 | num_updates 2379 | best_bleu 0
2023-09-06 01:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2379 updates
2023-09-06 01:52:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 2 @ 2379 updates, score 0.0) (writing took 11.415338346036151 seconds)
2023-09-06 01:52:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-06 01:52:42 | INFO | train | epoch 002 | loss 5.227 | trans_loss 6.232 | nll_loss 5.172 | w2v_ctc_loss 3.16 | task_loss 0.899 | task_loss_gen 6.664 | contrastive_loss 0 | total 6703.69 | n_correct 16.2939 | ppl 36.05 | accuracy 0.243 | wps 25670.1 | ups 1.32 | wpb 19422.7 | bsz 678.2 | num_updates 2379 | lr 9.52124e-05 | gnorm 0.749 | clip 0 | loss_scale 16 | train_wall 767 | gb_free 17.7 | wall 2272
2023-09-06 01:52:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:52:42 | INFO | fairseq.trainer | begin training epoch 3
2023-09-06 01:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 01:53:03 | INFO | train_inner | epoch 003:     21 / 1191 loss=4.991, trans_loss=6.331, nll_loss=5.296, w2v_ctc_loss=2.688, task_loss=0.054, task_loss_gen=12.943, contrastive_loss=0, total=6599.17, n_correct=20.1, ppl=39.28, accuracy=0.305, wps=14979.5, ups=0.78, wpb=19129.9, bsz=657.1, num_updates=2400, lr=9.6052e-05, gnorm=0.791, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=2293
2023-09-06 01:54:07 | INFO | train_inner | epoch 003:    121 / 1191 loss=4.836, trans_loss=6.161, nll_loss=5.078, w2v_ctc_loss=2.625, task_loss=0.03, task_loss_gen=13.406, contrastive_loss=0, total=6686.57, n_correct=11.27, ppl=33.78, accuracy=0.169, wps=30079.7, ups=1.55, wpb=19387.8, bsz=684.3, num_updates=2500, lr=0.00010005, gnorm=0.694, clip=0, loss_scale=16, train_wall=64, gb_free=18.6, wall=2357
2023-09-06 01:55:13 | INFO | train_inner | epoch 003:    221 / 1191 loss=4.855, trans_loss=6.262, nll_loss=5.224, w2v_ctc_loss=2.554, task_loss=0.017, task_loss_gen=14.494, contrastive_loss=0, total=6719.64, n_correct=13.44, ppl=37.37, accuracy=0.2, wps=29567.4, ups=1.52, wpb=19473.2, bsz=686.5, num_updates=2600, lr=0.000104048, gnorm=0.652, clip=0, loss_scale=16, train_wall=65, gb_free=18.8, wall=2423
2023-09-06 01:56:18 | INFO | train_inner | epoch 003:    321 / 1191 loss=4.811, trans_loss=6.195, nll_loss=5.123, w2v_ctc_loss=2.549, task_loss=0.014, task_loss_gen=17.989, contrastive_loss=0, total=6583.91, n_correct=13.83, ppl=34.84, accuracy=0.21, wps=29251.8, ups=1.53, wpb=19066, bsz=626, num_updates=2700, lr=0.000108046, gnorm=0.685, clip=0, loss_scale=16, train_wall=65, gb_free=17.6, wall=2488
2023-09-06 01:57:23 | INFO | train_inner | epoch 003:    421 / 1191 loss=4.76, trans_loss=6.189, nll_loss=5.115, w2v_ctc_loss=2.481, task_loss=0.006, task_loss_gen=17.316, contrastive_loss=0, total=6692.35, n_correct=25.62, ppl=34.65, accuracy=0.383, wps=30126.9, ups=1.55, wpb=19390.6, bsz=688.7, num_updates=2800, lr=0.000112044, gnorm=0.559, clip=0, loss_scale=16, train_wall=64, gb_free=17.4, wall=2553
2023-09-06 01:58:28 | INFO | train_inner | epoch 003:    521 / 1191 loss=4.763, trans_loss=6.207, nll_loss=5.149, w2v_ctc_loss=2.471, task_loss=0.003, task_loss_gen=19.283, contrastive_loss=0, total=6739.55, n_correct=23.85, ppl=35.49, accuracy=0.354, wps=29987.3, ups=1.54, wpb=19529.7, bsz=674.5, num_updates=2900, lr=0.000116042, gnorm=0.597, clip=0, loss_scale=32, train_wall=65, gb_free=17.9, wall=2618
2023-09-06 01:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 01:59:34 | INFO | train_inner | epoch 003:    622 / 1191 loss=4.843, trans_loss=6.347, nll_loss=5.316, w2v_ctc_loss=2.437, task_loss=0.002, task_loss_gen=21.491, contrastive_loss=0, total=6744.3, n_correct=14.57, ppl=39.83, accuracy=0.216, wps=29731.3, ups=1.52, wpb=19545.7, bsz=659.7, num_updates=3000, lr=0.00012004, gnorm=0.584, clip=0, loss_scale=16, train_wall=65, gb_free=18.6, wall=2683
2023-09-06 01:59:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 01:59:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-06 01:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-06 02:01:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-06 02:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 02:01:22 | INFO | train_inner | epoch 003:    727 / 1191 loss=3.762, trans_loss=5.132, nll_loss=3.773, w2v_ctc_loss=2.091, task_loss=1.885, task_loss_gen=8.311, contrastive_loss=0, total=6728.46, n_correct=686.39, ppl=13.67, accuracy=10.201, wps=17945.6, ups=0.92, wpb=19499, bsz=693.3, num_updates=3100, lr=0.000124038, gnorm=2.158, clip=0, loss_scale=0.5, train_wall=108, gb_free=14.7, wall=2792
2023-09-06 02:03:05 | INFO | train_inner | epoch 003:    827 / 1191 loss=3.096, trans_loss=4.408, nll_loss=2.8, w2v_ctc_loss=1.9, task_loss=1.32, task_loss_gen=4.586, contrastive_loss=0, total=6787.8, n_correct=1900.47, ppl=6.96, accuracy=27.998, wps=19101.2, ups=0.97, wpb=19674.9, bsz=712, num_updates=3200, lr=0.000128036, gnorm=4.569, clip=3, loss_scale=0.5, train_wall=102, gb_free=12.9, wall=2895
2023-09-06 02:04:47 | INFO | train_inner | epoch 003:    927 / 1191 loss=2.921, trans_loss=4.259, nll_loss=2.606, w2v_ctc_loss=1.815, task_loss=1.249, task_loss_gen=4.273, contrastive_loss=0, total=6806.95, n_correct=2294.87, ppl=6.09, accuracy=33.714, wps=19458.5, ups=0.99, wpb=19716, bsz=716.9, num_updates=3300, lr=0.000132034, gnorm=3.962, clip=3, loss_scale=0.5, train_wall=101, gb_free=13.9, wall=2996
2023-09-06 02:06:30 | INFO | train_inner | epoch 003:   1027 / 1191 loss=2.893, trans_loss=4.294, nll_loss=2.652, w2v_ctc_loss=1.794, task_loss=1.377, task_loss_gen=5.329, contrastive_loss=0, total=6529.36, n_correct=2246.6, ppl=6.28, accuracy=34.408, wps=18267.6, ups=0.97, wpb=18923.2, bsz=611.4, num_updates=3400, lr=0.000136032, gnorm=3.663, clip=0, loss_scale=0.5, train_wall=103, gb_free=6.7, wall=3100
2023-09-06 02:08:14 | INFO | train_inner | epoch 003:   1127 / 1191 loss=2.818, trans_loss=4.339, nll_loss=2.705, w2v_ctc_loss=1.712, task_loss=1.309, task_loss_gen=3.991, contrastive_loss=0, total=6784.07, n_correct=2393.91, ppl=6.52, accuracy=35.287, wps=18932.7, ups=0.96, wpb=19637.9, bsz=711.9, num_updates=3500, lr=0.00014003, gnorm=3.994, clip=0, loss_scale=0.5, train_wall=103, gb_free=12.6, wall=3204
2023-09-06 02:09:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:09:55 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.396 | trans_loss 7.066 | nll_loss 4.915 | w2v_ctc_loss 2.021 | task_loss 25.672 | task_loss_gen 16.199 | contrastive_loss 0 | total 6138.43 | n_correct 2269.29 | ppl 30.17 | accuracy 36.969 | uer 33.073 | wer 33.005 | raw_wer 33.005 | bleu 0.09 | wps 1554.7 | wpb 6138.4 | bsz 201.1 | num_updates 3564 | best_bleu 0.09
2023-09-06 02:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3564 updates
2023-09-06 02:09:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 3 @ 3564 updates, score 0.09) (writing took 12.184983404004015 seconds)
2023-09-06 02:10:08 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-06 02:10:08 | INFO | train | epoch 003 | loss 3.98 | trans_loss 5.387 | nll_loss 4.076 | w2v_ctc_loss 2.199 | task_loss 0.696 | task_loss_gen 11.36 | contrastive_loss 0 | total 6703.78 | n_correct 937.923 | ppl 16.87 | accuracy 13.991 | wps 22004.4 | ups 1.13 | wpb 19422.8 | bsz 677.7 | num_updates 3564 | lr 0.000142589 | gnorm 2.127 | clip 0.8 | loss_scale 0.5 | train_wall 982 | gb_free 15.1 | wall 3318
2023-09-06 02:10:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:10:08 | INFO | fairseq.trainer | begin training epoch 4
2023-09-06 02:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:10:53 | INFO | train_inner | epoch 004:     36 / 1191 loss=2.794, trans_loss=4.259, nll_loss=2.605, w2v_ctc_loss=1.675, task_loss=1.587, task_loss_gen=4.082, contrastive_loss=0, total=6564.97, n_correct=2314.96, ppl=6.08, accuracy=35.262, wps=11926, ups=0.63, wpb=19003.4, bsz=642.3, num_updates=3600, lr=0.000144028, gnorm=4.645, clip=4, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=3363
2023-09-06 02:12:37 | INFO | train_inner | epoch 004:    136 / 1191 loss=2.751, trans_loss=4.211, nll_loss=2.547, w2v_ctc_loss=1.622, task_loss=1.416, task_loss_gen=3.955, contrastive_loss=0, total=6717.55, n_correct=2402.64, ppl=5.85, accuracy=35.767, wps=18746.7, ups=0.96, wpb=19456.2, bsz=654.6, num_updates=3700, lr=0.000148026, gnorm=3.954, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.6, wall=3467
2023-09-06 02:14:20 | INFO | train_inner | epoch 004:    236 / 1191 loss=2.728, trans_loss=4.242, nll_loss=2.588, w2v_ctc_loss=1.6, task_loss=1.725, task_loss_gen=4.09, contrastive_loss=0, total=6754.2, n_correct=2441.85, ppl=6.01, accuracy=36.153, wps=19099.9, ups=0.98, wpb=19575.6, bsz=702.5, num_updates=3800, lr=0.000152024, gnorm=5.421, clip=11, loss_scale=0.5, train_wall=102, gb_free=11.9, wall=3569
2023-09-06 02:16:01 | INFO | train_inner | epoch 004:    336 / 1191 loss=2.711, trans_loss=4.227, nll_loss=2.569, w2v_ctc_loss=1.577, task_loss=1.679, task_loss_gen=4.028, contrastive_loss=0, total=6663.4, n_correct=2413.26, ppl=5.94, accuracy=36.217, wps=19064.8, ups=0.99, wpb=19310.2, bsz=662.9, num_updates=3900, lr=0.000156022, gnorm=4.812, clip=6, loss_scale=0.5, train_wall=101, gb_free=10.4, wall=3671
2023-09-06 02:17:43 | INFO | train_inner | epoch 004:    436 / 1191 loss=2.693, trans_loss=4.197, nll_loss=2.532, w2v_ctc_loss=1.554, task_loss=1.704, task_loss_gen=3.665, contrastive_loss=0, total=6723.42, n_correct=2444.34, ppl=5.78, accuracy=36.356, wps=19006.7, ups=0.98, wpb=19479.8, bsz=685.4, num_updates=4000, lr=0.00016002, gnorm=4.812, clip=3, loss_scale=0.5, train_wall=102, gb_free=14, wall=3773
2023-09-06 02:17:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:18:15 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.28 | trans_loss 6.982 | nll_loss 4.809 | w2v_ctc_loss 1.824 | task_loss 9.196 | task_loss_gen 14.374 | contrastive_loss 0 | total 6138.43 | n_correct 2320 | ppl 28.03 | accuracy 37.795 | uer 29.65 | wer 30.231 | raw_wer 30.231 | bleu 0.09 | wps 1857.5 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 0.09
2023-09-06 02:18:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-09-06 02:18:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 02:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 02:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 0.09) (writing took 19.101495963986963 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.5288,  0.2123, -0.6753,  0.0806,  0.0916], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5342,  0.2090, -0.9287,  ..., -0.6470, -0.1570, -0.3625],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0408,  0.2778,  0.5347,  ..., -0.0736, -0.0948,  0.1440]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5288,  0.2123, -0.6753,  0.0806,  0.0916], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-06 02:20:17 | INFO | train_inner | epoch 004:    536 / 1191 loss=2.68, trans_loss=4.181, nll_loss=2.511, w2v_ctc_loss=1.537, task_loss=1.627, task_loss_gen=4.133, contrastive_loss=0, total=6675.14, n_correct=2432.58, ppl=5.7, accuracy=36.442, wps=12611.4, ups=0.65, wpb=19342.3, bsz=669.8, num_updates=4100, lr=0.000164018, gnorm=4.485, clip=3, loss_scale=0.5, train_wall=102, gb_free=13.9, wall=3927
2023-09-06 02:22:01 | INFO | train_inner | epoch 004:    636 / 1191 loss=2.651, trans_loss=4.186, nll_loss=2.517, w2v_ctc_loss=1.508, task_loss=1.373, task_loss_gen=3.646, contrastive_loss=0, total=6814.85, n_correct=2502, ppl=5.72, accuracy=36.714, wps=19003.6, ups=0.96, wpb=19752.2, bsz=705.4, num_updates=4200, lr=0.000168016, gnorm=4.003, clip=2, loss_scale=0.5, train_wall=103, gb_free=5, wall=4030
2023-09-06 02:23:42 | INFO | train_inner | epoch 004:    736 / 1191 loss=2.632, trans_loss=4.209, nll_loss=2.544, w2v_ctc_loss=1.473, task_loss=1.45, task_loss_gen=3.751, contrastive_loss=0, total=6699.76, n_correct=2462.44, ppl=5.83, accuracy=36.754, wps=19186.9, ups=0.99, wpb=19404.7, bsz=685.5, num_updates=4300, lr=0.000172014, gnorm=4.739, clip=4, loss_scale=0.5, train_wall=101, gb_free=4.7, wall=4132
2023-09-06 02:25:25 | INFO | train_inner | epoch 004:    836 / 1191 loss=2.621, trans_loss=4.205, nll_loss=2.541, w2v_ctc_loss=1.466, task_loss=1.623, task_loss_gen=3.612, contrastive_loss=0, total=6858.76, n_correct=2534.14, ppl=5.82, accuracy=36.947, wps=19220.8, ups=0.97, wpb=19866.4, bsz=725.5, num_updates=4400, lr=0.000176012, gnorm=5.22, clip=7, loss_scale=0.5, train_wall=103, gb_free=14, wall=4235
2023-09-06 02:27:08 | INFO | train_inner | epoch 004:    936 / 1191 loss=2.611, trans_loss=4.163, nll_loss=2.487, w2v_ctc_loss=1.451, task_loss=1.629, task_loss_gen=3.541, contrastive_loss=0, total=6732.9, n_correct=2490.1, ppl=5.61, accuracy=36.984, wps=19036.6, ups=0.98, wpb=19494.6, bsz=702.9, num_updates=4500, lr=0.00018001, gnorm=5.554, clip=5, loss_scale=0.5, train_wall=102, gb_free=10.6, wall=4337
2023-09-06 02:28:51 | INFO | train_inner | epoch 004:   1036 / 1191 loss=2.638, trans_loss=4.163, nll_loss=2.488, w2v_ctc_loss=1.484, task_loss=2.044, task_loss_gen=3.947, contrastive_loss=0, total=6643.82, n_correct=2441.78, ppl=5.61, accuracy=36.753, wps=18616.2, ups=0.97, wpb=19242.6, bsz=660.8, num_updates=4600, lr=0.000184008, gnorm=6.451, clip=16, loss_scale=0.5, train_wall=103, gb_free=13.6, wall=4441
2023-09-06 02:30:33 | INFO | train_inner | epoch 004:   1136 / 1191 loss=2.609, trans_loss=4.14, nll_loss=2.462, w2v_ctc_loss=1.443, task_loss=2.481, task_loss_gen=4.263, contrastive_loss=0, total=6570.21, n_correct=2413.91, ppl=5.51, accuracy=36.74, wps=18619.3, ups=0.98, wpb=19047.6, bsz=630.5, num_updates=4700, lr=0.000188006, gnorm=6.473, clip=16, loss_scale=0.5, train_wall=102, gb_free=7.3, wall=4543
2023-09-06 02:31:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.3906,  0.6953, -2.7422,  0.2268,  0.4775], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7168, -0.6748, -0.1230,  ..., -0.8296, -0.1957, -0.3242],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-3.0762,  1.9209,  1.0703,  ..., -0.2284, -0.1178,  0.2257]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.3906,  0.6953, -2.7422,  0.2268,  0.4775], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.4854,  0.2076, -0.7617,  0.0833,  0.1941], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8911,  0.0201, -0.7734,  ..., -0.7007, -0.0948, -0.3074],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0340,  0.0861,  0.3057,  ..., -0.0524, -0.1356,  0.1263]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.4854,  0.2076, -0.7617,  0.0833,  0.1941], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.4421,  0.1212, -0.5474,  0.0598,  0.1006], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6543, -0.1981, -0.8301,  ..., -0.5317, -0.2339, -0.3145],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2258,  0.2162,  0.7090,  ..., -0.0029, -0.1130,  0.1217]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.4421,  0.1212, -0.5474,  0.0598,  0.1006], device='cuda:2',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.5864,  0.0569, -0.4683,  0.0504,  0.0476], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.2100, -0.1753, -1.0479,  ..., -0.5049, -0.2585, -0.2400],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6597,  0.1205,  0.1935,  ..., -0.0883, -0.1137,  0.1422]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5864,  0.0569, -0.4683,  0.0504,  0.0476], device='cuda:3',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.7363,  0.7329, -2.7266,  0.2321,  0.5508], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-2.0215, -0.4119, -0.0682,  ..., -0.8091, -0.4429, -0.4141],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2449,  0.0909,  0.5928,  ..., -0.1858, -0.0492,  0.1995]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.7363,  0.7329, -2.7266,  0.2321,  0.5508], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.7578,  0.1697, -0.4973,  0.0600, -0.0742], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8774,  0.0917, -0.1871,  ..., -0.5190, -0.3176, -0.3264],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0555,  0.2472,  1.0244,  ..., -0.1166, -0.0806,  0.1254]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.7578,  0.1697, -0.4973,  0.0600, -0.0742], device='cuda:5',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.9355,  0.4683, -2.4688,  0.1725,  0.4819], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.8047,  0.3477,  0.6772,  ..., -0.8960, -0.2167, -0.3987],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.9175,  0.5156,  0.3853,  ..., -0.0902, -0.0969,  0.1753]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.9355,  0.4683, -2.4688,  0.1725,  0.4819], device='cuda:4',
       dtype=torch.float16)
--------------------
2023-09-06 02:32:11 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.236 | trans_loss 6.997 | nll_loss 4.833 | w2v_ctc_loss 1.647 | task_loss 13.01 | task_loss_gen 12.634 | contrastive_loss 0 | total 6138.43 | n_correct 2324 | ppl 28.5 | accuracy 37.86 | uer 27.026 | wer 27.94 | raw_wer 27.94 | bleu 0.08 | wps 1281.5 | wpb 6138.4 | bsz 201.1 | num_updates 4755 | best_bleu 0.09
2023-09-06 02:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4755 updates
2023-09-06 02:32:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt
2023-09-06 02:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt
2023-09-06 02:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt (epoch 4 @ 4755 updates, score 0.08) (writing took 8.001362738898024 seconds)
2023-09-06 02:32:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-06 02:32:19 | INFO | train | epoch 004 | loss 2.667 | trans_loss 4.191 | nll_loss 2.523 | w2v_ctc_loss 1.521 | task_loss 1.706 | task_loss_gen 3.86 | contrastive_loss 0 | total 6703.69 | n_correct 2449.01 | ppl 5.75 | accuracy 36.532 | wps 17369.9 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 4755 | lr 0.000190205 | gnorm 5.061 | clip 6.4 | loss_scale 0.5 | train_wall 1216 | gb_free 13.2 | wall 4649
2023-09-06 02:32:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:32:20 | INFO | fairseq.trainer | begin training epoch 5
2023-09-06 02:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:33:14 | INFO | train_inner | epoch 005:     45 / 1191 loss=2.584, trans_loss=4.12, nll_loss=2.437, w2v_ctc_loss=1.428, task_loss=1.747, task_loss_gen=3.205, contrastive_loss=0, total=6770.61, n_correct=2541.14, ppl=5.41, accuracy=37.532, wps=12237.9, ups=0.62, wpb=19623.2, bsz=716.6, num_updates=4800, lr=0.000192004, gnorm=5.242, clip=5, loss_scale=0.5, train_wall=102, gb_free=12.3, wall=4703
2023-09-06 02:34:56 | INFO | train_inner | epoch 005:    145 / 1191 loss=2.581, trans_loss=4.133, nll_loss=2.452, w2v_ctc_loss=1.412, task_loss=1.741, task_loss_gen=3.553, contrastive_loss=0, total=6699.77, n_correct=2494.77, ppl=5.47, accuracy=37.237, wps=18906.1, ups=0.97, wpb=19409.6, bsz=671.7, num_updates=4900, lr=0.000196002, gnorm=5.576, clip=8, loss_scale=0.5, train_wall=102, gb_free=5.9, wall=4806
2023-09-06 02:36:38 | INFO | train_inner | epoch 005:    245 / 1191 loss=2.557, trans_loss=4.114, nll_loss=2.429, w2v_ctc_loss=1.39, task_loss=1.734, task_loss_gen=3.263, contrastive_loss=0, total=6859.5, n_correct=2582.27, ppl=5.38, accuracy=37.645, wps=19473.5, ups=0.98, wpb=19870.2, bsz=728.4, num_updates=5000, lr=0.0002, gnorm=4.648, clip=1, loss_scale=0.5, train_wall=101, gb_free=12.6, wall=4908
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:0')
2023-09-06 02:38:20 | INFO | train_inner | epoch 005:    345 / 1191 loss=2.558, trans_loss=4.105, nll_loss=2.418, w2v_ctc_loss=1.389, task_loss=3.392, task_loss_gen=4.312, contrastive_loss=0, total=6631.13, n_correct=2494.96, ppl=5.35, accuracy=37.625, wps=18863.4, ups=0.98, wpb=19212.5, bsz=667.2, num_updates=5100, lr=0.00019803, gnorm=8.971, clip=31, loss_scale=0.5, train_wall=101, gb_free=13.8, wall=5010
2023-09-06 02:40:03 | INFO | train_inner | epoch 005:    445 / 1191 loss=2.563, trans_loss=4.081, nll_loss=2.39, w2v_ctc_loss=1.401, task_loss=3.23, task_loss_gen=3.89, contrastive_loss=0, total=6691.68, n_correct=2520.19, ppl=5.24, accuracy=37.662, wps=18867.5, ups=0.97, wpb=19399.7, bsz=680, num_updates=5200, lr=0.000196116, gnorm=5.936, clip=16, loss_scale=1, train_wall=102, gb_free=14, wall=5113
2023-09-06 02:41:47 | INFO | train_inner | epoch 005:    545 / 1191 loss=2.534, trans_loss=4.065, nll_loss=2.369, w2v_ctc_loss=1.359, task_loss=2.9, task_loss_gen=3.805, contrastive_loss=0, total=6658.28, n_correct=2516.89, ppl=5.17, accuracy=37.801, wps=18592.4, ups=0.96, wpb=19286.8, bsz=671.1, num_updates=5300, lr=0.000194257, gnorm=4.207, clip=1, loss_scale=1, train_wall=103, gb_free=13.1, wall=5217
2023-09-06 02:43:28 | INFO | train_inner | epoch 005:    645 / 1191 loss=2.544, trans_loss=4.063, nll_loss=2.365, w2v_ctc_loss=1.368, task_loss=2.813, task_loss_gen=3.865, contrastive_loss=0, total=6704.06, n_correct=2536.14, ppl=5.15, accuracy=37.83, wps=19132, ups=0.99, wpb=19409.9, bsz=666.1, num_updates=5400, lr=0.00019245, gnorm=3.572, clip=1, loss_scale=1, train_wall=101, gb_free=12.6, wall=5318
2023-09-06 02:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 02:45:13 | INFO | train_inner | epoch 005:    746 / 1191 loss=2.521, trans_loss=4.06, nll_loss=2.364, w2v_ctc_loss=1.344, task_loss=2.325, task_loss_gen=3.653, contrastive_loss=0, total=6728.31, n_correct=2553.76, ppl=5.15, accuracy=37.955, wps=18666.2, ups=0.96, wpb=19503.3, bsz=690.7, num_updates=5500, lr=0.000190693, gnorm=5.595, clip=7, loss_scale=0.5, train_wall=104, gb_free=14.4, wall=5422
2023-09-06 02:46:55 | INFO | train_inner | epoch 005:    846 / 1191 loss=2.529, trans_loss=4.069, nll_loss=2.372, w2v_ctc_loss=1.353, task_loss=2.1, task_loss_gen=3.197, contrastive_loss=0, total=6763.5, n_correct=2553.31, ppl=5.18, accuracy=37.751, wps=19145.1, ups=0.98, wpb=19589.8, bsz=684.5, num_updates=5600, lr=0.000188982, gnorm=5.862, clip=7, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=5525
2023-09-06 02:48:38 | INFO | train_inner | epoch 005:    946 / 1191 loss=2.517, trans_loss=4.078, nll_loss=2.386, w2v_ctc_loss=1.334, task_loss=2.579, task_loss_gen=3.578, contrastive_loss=0, total=6600.15, n_correct=2495.63, ppl=5.23, accuracy=37.812, wps=18643.5, ups=0.97, wpb=19125.2, bsz=657.6, num_updates=5700, lr=0.000187317, gnorm=6.761, clip=14, loss_scale=0.5, train_wall=102, gb_free=13.9, wall=5627
2023-09-06 02:50:20 | INFO | train_inner | epoch 005:   1046 / 1191 loss=2.546, trans_loss=4.064, nll_loss=2.368, w2v_ctc_loss=1.373, task_loss=2.834, task_loss_gen=3.698, contrastive_loss=0, total=6646.83, n_correct=2506.98, ppl=5.16, accuracy=37.717, wps=18733.2, ups=0.97, wpb=19258.1, bsz=646.9, num_updates=5800, lr=0.000185695, gnorm=6.221, clip=10, loss_scale=0.5, train_wall=102, gb_free=13.1, wall=5730
2023-09-06 02:52:03 | INFO | train_inner | epoch 005:   1146 / 1191 loss=2.522, trans_loss=4.053, nll_loss=2.354, w2v_ctc_loss=1.346, task_loss=2.389, task_loss_gen=3.367, contrastive_loss=0, total=6691.45, n_correct=2540.57, ppl=5.11, accuracy=37.967, wps=18960.9, ups=0.98, wpb=19389, bsz=668.7, num_updates=5900, lr=0.000184115, gnorm=5.5, clip=2, loss_scale=0.5, train_wall=102, gb_free=13, wall=5832
2023-09-06 02:52:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:2')
2023-09-06 02:53:24 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.135 | trans_loss 6.883 | nll_loss 4.686 | w2v_ctc_loss 1.568 | task_loss 24.442 | task_loss_gen 15.327 | contrastive_loss 0 | total 6138.43 | n_correct 2396.14 | ppl 25.74 | accuracy 39.035 | uer 25.994 | wer 27.084 | raw_wer 27.084 | bleu 0.15 | wps 1616.7 | wpb 6138.4 | bsz 201.1 | num_updates 5945 | best_bleu 0.15
2023-09-06 02:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5945 updates
2023-09-06 02:53:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 5 @ 5945 updates, score 0.15) (writing took 11.962950768065639 seconds)
2023-09-06 02:53:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-06 02:53:36 | INFO | train | epoch 005 | loss 2.542 | trans_loss 4.081 | nll_loss 2.388 | w2v_ctc_loss 1.369 | task_loss 2.507 | task_loss_gen 3.616 | contrastive_loss 0 | total 6703.59 | n_correct 2529.56 | ppl 5.24 | accuracy 37.734 | wps 18111 | ups 0.93 | wpb 19422.5 | bsz 678.2 | num_updates 5945 | lr 0.000183417 | gnorm 5.736 | clip 8.7 | loss_scale 0.5 | train_wall 1214 | gb_free 11.1 | wall 5925
2023-09-06 02:53:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:53:36 | INFO | fairseq.trainer | begin training epoch 6
2023-09-06 02:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:54:39 | INFO | train_inner | epoch 006:     55 / 1191 loss=2.5, trans_loss=4.042, nll_loss=2.339, w2v_ctc_loss=1.317, task_loss=2.395, task_loss_gen=3.322, contrastive_loss=0, total=6655.75, n_correct=2542.7, ppl=5.06, accuracy=38.203, wps=12334.1, ups=0.64, wpb=19286.4, bsz=662.9, num_updates=6000, lr=0.000182574, gnorm=5.35, clip=2, loss_scale=0.5, train_wall=101, gb_free=11.4, wall=5989
2023-09-06 02:54:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:55:13 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.139 | trans_loss 6.89 | nll_loss 4.694 | w2v_ctc_loss 1.563 | task_loss 19.681 | task_loss_gen 13.484 | contrastive_loss 0 | total 6138.43 | n_correct 2397.43 | ppl 25.89 | accuracy 39.056 | uer 25.991 | wer 27.125 | raw_wer 27.125 | bleu 0.2 | wps 1618 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 0.2
2023-09-06 02:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-09-06 02:55:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 02:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 02:55:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 0.2) (writing took 12.977749353041872 seconds)
2023-09-06 02:57:09 | INFO | train_inner | epoch 006:    155 / 1191 loss=2.481, trans_loss=4.041, nll_loss=2.336, w2v_ctc_loss=1.288, task_loss=2.382, task_loss_gen=3.293, contrastive_loss=0, total=6716.94, n_correct=2567.44, ppl=5.05, accuracy=38.223, wps=12925, ups=0.66, wpb=19447.8, bsz=676.1, num_updates=6100, lr=0.000181071, gnorm=5.318, clip=3, loss_scale=0.5, train_wall=102, gb_free=14.6, wall=6139
2023-09-06 02:58:52 | INFO | train_inner | epoch 006:    255 / 1191 loss=2.473, trans_loss=4.026, nll_loss=2.32, w2v_ctc_loss=1.286, task_loss=2.135, task_loss_gen=3.003, contrastive_loss=0, total=6862.39, n_correct=2636.6, ppl=4.99, accuracy=38.421, wps=19429.8, ups=0.98, wpb=19881.1, bsz=725.7, num_updates=6200, lr=0.000179605, gnorm=4.648, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.7, wall=6242
2023-09-06 03:00:36 | INFO | train_inner | epoch 006:    355 / 1191 loss=2.491, trans_loss=4.028, nll_loss=2.322, w2v_ctc_loss=1.305, task_loss=2.162, task_loss_gen=3.161, contrastive_loss=0, total=6708.81, n_correct=2572.84, ppl=5, accuracy=38.35, wps=18675.5, ups=0.96, wpb=19428.8, bsz=668.5, num_updates=6300, lr=0.000178174, gnorm=3.546, clip=0, loss_scale=0.5, train_wall=103, gb_free=11.2, wall=6346
2023-09-06 03:02:18 | INFO | train_inner | epoch 006:    455 / 1191 loss=2.485, trans_loss=4.039, nll_loss=2.336, w2v_ctc_loss=1.296, task_loss=2.117, task_loss_gen=3.288, contrastive_loss=0, total=6579.59, n_correct=2512.38, ppl=5.05, accuracy=38.184, wps=18621.8, ups=0.98, wpb=19065.8, bsz=655.4, num_updates=6400, lr=0.000176777, gnorm=4.221, clip=0, loss_scale=0.5, train_wall=102, gb_free=13.1, wall=6448
2023-09-06 03:04:01 | INFO | train_inner | epoch 006:    555 / 1191 loss=2.478, trans_loss=4.03, nll_loss=2.326, w2v_ctc_loss=1.294, task_loss=2.75, task_loss_gen=3.444, contrastive_loss=0, total=6695.79, n_correct=2564.62, ppl=5.02, accuracy=38.302, wps=18827.5, ups=0.97, wpb=19413.8, bsz=661.9, num_updates=6500, lr=0.000175412, gnorm=5.214, clip=6, loss_scale=0.5, train_wall=102, gb_free=13.8, wall=6551
2023-09-06 03:05:44 | INFO | train_inner | epoch 006:    655 / 1191 loss=2.483, trans_loss=4.021, nll_loss=2.313, w2v_ctc_loss=1.295, task_loss=2.554, task_loss_gen=3.216, contrastive_loss=0, total=6691.12, n_correct=2567.64, ppl=4.97, accuracy=38.374, wps=18846.2, ups=0.97, wpb=19377.3, bsz=661.5, num_updates=6600, lr=0.000174078, gnorm=4.547, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=6654
2023-09-06 03:07:27 | INFO | train_inner | epoch 006:    755 / 1191 loss=2.491, trans_loss=4.009, nll_loss=2.298, w2v_ctc_loss=1.319, task_loss=2.144, task_loss_gen=2.935, contrastive_loss=0, total=6834.57, n_correct=2637.79, ppl=4.92, accuracy=38.595, wps=19318.3, ups=0.98, wpb=19800.8, bsz=719.4, num_updates=6700, lr=0.000172774, gnorm=4.074, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.8, wall=6756
2023-09-06 03:09:10 | INFO | train_inner | epoch 006:    855 / 1191 loss=2.492, trans_loss=4.006, nll_loss=2.298, w2v_ctc_loss=1.318, task_loss=2.113, task_loss_gen=3.084, contrastive_loss=0, total=6618.09, n_correct=2542.74, ppl=4.92, accuracy=38.421, wps=18618.3, ups=0.97, wpb=19191.3, bsz=678.6, num_updates=6800, lr=0.000171499, gnorm=3.648, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.3, wall=6860
2023-09-06 03:10:54 | INFO | train_inner | epoch 006:    955 / 1191 loss=2.51, trans_loss=4.016, nll_loss=2.307, w2v_ctc_loss=1.336, task_loss=2.485, task_loss_gen=3.356, contrastive_loss=0, total=6622.17, n_correct=2542.14, ppl=4.95, accuracy=38.388, wps=18467.5, ups=0.96, wpb=19185.1, bsz=637.5, num_updates=6900, lr=0.000170251, gnorm=3.863, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.8, wall=6963
2023-09-06 03:12:36 | INFO | train_inner | epoch 006:   1055 / 1191 loss=2.466, trans_loss=4.005, nll_loss=2.295, w2v_ctc_loss=1.278, task_loss=2.14, task_loss_gen=3.135, contrastive_loss=0, total=6674.98, n_correct=2577.24, ppl=4.91, accuracy=38.61, wps=18917.8, ups=0.98, wpb=19341.4, bsz=667.2, num_updates=7000, lr=0.000169031, gnorm=3.333, clip=0, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=7066
2023-09-06 03:14:17 | INFO | train_inner | epoch 006:   1155 / 1191 loss=2.485, trans_loss=4.004, nll_loss=2.295, w2v_ctc_loss=1.308, task_loss=2.015, task_loss_gen=2.807, contrastive_loss=0, total=6754.15, n_correct=2600.71, ppl=4.91, accuracy=38.505, wps=19422.6, ups=0.99, wpb=19579.8, bsz=709.1, num_updates=7100, lr=0.000167836, gnorm=3.622, clip=3, loss_scale=0.5, train_wall=100, gb_free=13.3, wall=7167
2023-09-06 03:14:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:15:26 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.075 | trans_loss 6.854 | nll_loss 4.65 | w2v_ctc_loss 1.433 | task_loss 25.526 | task_loss_gen 15.184 | contrastive_loss 0 | total 6138.43 | n_correct 2415.86 | ppl 25.11 | accuracy 39.356 | uer 24.267 | wer 25.575 | raw_wer 25.575 | bleu 0.13 | wps 1738.5 | wpb 6138.4 | bsz 201.1 | num_updates 7136 | best_bleu 0.2
2023-09-06 03:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7136 updates
2023-09-06 03:15:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 03:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 03:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt (epoch 6 @ 7136 updates, score 0.13) (writing took 7.225076515926048 seconds)
2023-09-06 03:15:34 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-06 03:15:34 | INFO | train | epoch 006 | loss 2.485 | trans_loss 4.021 | nll_loss 2.313 | w2v_ctc_loss 1.302 | task_loss 2.26 | task_loss_gen 3.142 | contrastive_loss 0 | total 6703.69 | n_correct 2574.4 | ppl 4.97 | accuracy 38.403 | wps 17548.4 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 7136 | lr 0.000167412 | gnorm 4.163 | clip 1.3 | loss_scale 0.5 | train_wall 1215 | gb_free 13.5 | wall 7244
2023-09-06 03:15:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:15:34 | INFO | fairseq.trainer | begin training epoch 7
2023-09-06 03:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 03:16:48 | INFO | train_inner | epoch 007:     64 / 1191 loss=2.456, trans_loss=3.999, nll_loss=2.284, w2v_ctc_loss=1.265, task_loss=1.95, task_loss_gen=2.942, contrastive_loss=0, total=6722.13, n_correct=2602.2, ppl=4.87, accuracy=38.711, wps=12859.7, ups=0.66, wpb=19459.1, bsz=690, num_updates=7200, lr=0.000166667, gnorm=2.716, clip=0, loss_scale=0.5, train_wall=101, gb_free=14.4, wall=7318
2023-09-06 03:18:31 | INFO | train_inner | epoch 007:    164 / 1191 loss=2.446, trans_loss=3.99, nll_loss=2.278, w2v_ctc_loss=1.257, task_loss=2.206, task_loss_gen=3.099, contrastive_loss=0, total=6674.7, n_correct=2582.54, ppl=4.85, accuracy=38.691, wps=18782, ups=0.97, wpb=19358.1, bsz=674.9, num_updates=7300, lr=0.000165521, gnorm=3.186, clip=0, loss_scale=0.5, train_wall=103, gb_free=13.3, wall=7421
2023-09-06 03:20:14 | INFO | train_inner | epoch 007:    264 / 1191 loss=2.45, trans_loss=3.989, nll_loss=2.275, w2v_ctc_loss=1.257, task_loss=1.971, task_loss_gen=3.077, contrastive_loss=0, total=6691.93, n_correct=2593.05, ppl=4.84, accuracy=38.749, wps=18813, ups=0.97, wpb=19392.2, bsz=675.1, num_updates=7400, lr=0.000164399, gnorm=2.815, clip=0, loss_scale=0.5, train_wall=103, gb_free=13.7, wall=7524
2023-09-06 03:21:55 | INFO | train_inner | epoch 007:    364 / 1191 loss=2.44, trans_loss=3.982, nll_loss=2.266, w2v_ctc_loss=1.25, task_loss=2.043, task_loss_gen=2.868, contrastive_loss=0, total=6730.79, n_correct=2624.67, ppl=4.81, accuracy=38.995, wps=19334.7, ups=0.99, wpb=19508.1, bsz=689.9, num_updates=7500, lr=0.000163299, gnorm=2.952, clip=1, loss_scale=1, train_wall=100, gb_free=12.4, wall=7625
2023-09-06 03:23:36 | INFO | train_inner | epoch 007:    464 / 1191 loss=2.41, trans_loss=3.982, nll_loss=2.266, w2v_ctc_loss=1.207, task_loss=2.032, task_loss_gen=2.795, contrastive_loss=0, total=6783.66, n_correct=2639.59, ppl=4.81, accuracy=38.911, wps=19381.1, ups=0.99, wpb=19655.7, bsz=707.6, num_updates=7600, lr=0.000162221, gnorm=1.508, clip=0, loss_scale=1, train_wall=101, gb_free=14.4, wall=7726
2023-09-06 03:25:19 | INFO | train_inner | epoch 007:    564 / 1191 loss=2.426, trans_loss=3.981, nll_loss=2.264, w2v_ctc_loss=1.223, task_loss=2.106, task_loss_gen=3.036, contrastive_loss=0, total=6712.4, n_correct=2608.58, ppl=4.8, accuracy=38.862, wps=18885.4, ups=0.97, wpb=19445.4, bsz=675.5, num_updates=7700, lr=0.000161165, gnorm=1.422, clip=0, loss_scale=1, train_wall=102, gb_free=14.3, wall=7829
2023-09-06 03:27:03 | INFO | train_inner | epoch 007:    664 / 1191 loss=2.415, trans_loss=3.98, nll_loss=2.263, w2v_ctc_loss=1.211, task_loss=2.058, task_loss_gen=2.93, contrastive_loss=0, total=6762.84, n_correct=2634.68, ppl=4.8, accuracy=38.958, wps=18952.9, ups=0.97, wpb=19590.9, bsz=694.5, num_updates=7800, lr=0.000160128, gnorm=1.572, clip=0, loss_scale=1, train_wall=103, gb_free=11.1, wall=7933
2023-09-06 03:28:45 | INFO | train_inner | epoch 007:    764 / 1191 loss=2.415, trans_loss=3.979, nll_loss=2.26, w2v_ctc_loss=1.207, task_loss=2.118, task_loss_gen=3.03, contrastive_loss=0, total=6663.7, n_correct=2592.36, ppl=4.79, accuracy=38.903, wps=18876.5, ups=0.98, wpb=19298.6, bsz=664.1, num_updates=7900, lr=0.000159111, gnorm=1.256, clip=0, loss_scale=1, train_wall=102, gb_free=13.7, wall=8035
2023-09-06 03:29:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 03:30:30 | INFO | train_inner | epoch 007:    865 / 1191 loss=2.447, trans_loss=3.981, nll_loss=2.265, w2v_ctc_loss=1.254, task_loss=2.144, task_loss_gen=3.166, contrastive_loss=0, total=6642.22, n_correct=2573.79, ppl=4.81, accuracy=38.749, wps=18343, ups=0.95, wpb=19242.7, bsz=654.8, num_updates=8000, lr=0.000158114, gnorm=2.499, clip=1, loss_scale=0.5, train_wall=104, gb_free=12.3, wall=8140
2023-09-06 03:30:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:31:03 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.069 | trans_loss 6.836 | nll_loss 4.63 | w2v_ctc_loss 1.453 | task_loss 13.897 | task_loss_gen 12.034 | contrastive_loss 0 | total 6138.43 | n_correct 2435.57 | ppl 24.75 | accuracy 39.677 | uer 23.86 | wer 25.073 | raw_wer 25.073 | bleu 0.19 | wps 1704.5 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 0.2
2023-09-06 03:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-09-06 03:31:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 03:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 03:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 0.19) (writing took 9.393209382891655 seconds)
2023-09-06 03:32:55 | INFO | train_inner | epoch 007:    965 / 1191 loss=2.439, trans_loss=3.976, nll_loss=2.258, w2v_ctc_loss=1.243, task_loss=2.097, task_loss_gen=3.048, contrastive_loss=0, total=6662.44, n_correct=2586.42, ppl=4.78, accuracy=38.821, wps=13267.5, ups=0.69, wpb=19297.8, bsz=651.1, num_updates=8100, lr=0.000157135, gnorm=2.211, clip=0, loss_scale=0.5, train_wall=102, gb_free=14.5, wall=8285
2023-09-06 03:34:38 | INFO | train_inner | epoch 007:   1065 / 1191 loss=2.44, trans_loss=3.973, nll_loss=2.253, w2v_ctc_loss=1.255, task_loss=2.182, task_loss_gen=3.01, contrastive_loss=0, total=6680.36, n_correct=2613.71, ppl=4.77, accuracy=39.125, wps=18890.6, ups=0.98, wpb=19342.7, bsz=695.6, num_updates=8200, lr=0.000156174, gnorm=2.73, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.9, wall=8388
2023-09-06 03:36:20 | INFO | train_inner | epoch 007:   1165 / 1191 loss=2.431, trans_loss=3.974, nll_loss=2.257, w2v_ctc_loss=1.238, task_loss=2.263, task_loss_gen=3.033, contrastive_loss=0, total=6716.49, n_correct=2615.02, ppl=4.78, accuracy=38.934, wps=18977.5, ups=0.97, wpb=19469.2, bsz=674, num_updates=8300, lr=0.00015523, gnorm=2.856, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.2, wall=8490
2023-09-06 03:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:37:20 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.05 | trans_loss 6.831 | nll_loss 4.621 | w2v_ctc_loss 1.4 | task_loss 22.049 | task_loss_gen 13.945 | contrastive_loss 0 | total 6138.43 | n_correct 2431.71 | ppl 24.61 | accuracy 39.615 | uer 23.606 | wer 25.084 | raw_wer 25.084 | bleu 0.11 | wps 1724.5 | wpb 6138.4 | bsz 201.1 | num_updates 8326 | best_bleu 0.2
2023-09-06 03:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8326 updates
2023-09-06 03:37:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt
2023-09-06 03:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt
2023-09-06 03:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt (epoch 7 @ 8326 updates, score 0.11) (writing took 10.33597502799239 seconds)
2023-09-06 03:37:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-06 03:37:30 | INFO | train | epoch 007 | loss 2.433 | trans_loss 3.981 | nll_loss 2.265 | w2v_ctc_loss 1.236 | task_loss 2.101 | task_loss_gen 3.006 | contrastive_loss 0 | total 6704.01 | n_correct 2606.23 | ppl 4.81 | accuracy 38.876 | wps 17558.5 | ups 0.9 | wpb 19423.6 | bsz 678.4 | num_updates 8326 | lr 0.000154988 | gnorm 2.307 | clip 0.3 | loss_scale 0.5 | train_wall 1215 | gb_free 12.7 | wall 8560
2023-09-06 03:37:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:37:30 | INFO | fairseq.trainer | begin training epoch 8
2023-09-06 03:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 03:38:53 | INFO | train_inner | epoch 008:     74 / 1191 loss=2.386, trans_loss=3.968, nll_loss=2.246, w2v_ctc_loss=1.166, task_loss=2.284, task_loss_gen=2.929, contrastive_loss=0, total=6735.91, n_correct=2633.21, ppl=4.74, accuracy=39.092, wps=12745.4, ups=0.65, wpb=19506.1, bsz=674.3, num_updates=8400, lr=0.000154303, gnorm=2.513, clip=0, loss_scale=0.5, train_wall=101, gb_free=12.7, wall=8643
2023-09-06 03:40:36 | INFO | train_inner | epoch 008:    174 / 1191 loss=2.371, trans_loss=3.948, nll_loss=2.225, w2v_ctc_loss=1.161, task_loss=2.26, task_loss_gen=2.833, contrastive_loss=0, total=6733.69, n_correct=2654.55, ppl=4.68, accuracy=39.422, wps=19005.2, ups=0.97, wpb=19530.2, bsz=709.9, num_updates=8500, lr=0.000153393, gnorm=2.238, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.2, wall=8746
2023-09-06 03:42:20 | INFO | train_inner | epoch 008:    274 / 1191 loss=2.388, trans_loss=3.959, nll_loss=2.236, w2v_ctc_loss=1.178, task_loss=2.184, task_loss_gen=2.9, contrastive_loss=0, total=6723.6, n_correct=2638.84, ppl=4.71, accuracy=39.247, wps=18814.5, ups=0.97, wpb=19475.4, bsz=686.2, num_updates=8600, lr=0.000152499, gnorm=2.328, clip=0, loss_scale=0.5, train_wall=103, gb_free=12.7, wall=8850
2023-09-06 03:42:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 03:44:05 | INFO | train_inner | epoch 008:    375 / 1191 loss=2.448, trans_loss=3.963, nll_loss=2.243, w2v_ctc_loss=1.265, task_loss=2.39, task_loss_gen=3.075, contrastive_loss=0, total=6673.62, n_correct=2597.77, ppl=4.74, accuracy=38.926, wps=18395.7, ups=0.95, wpb=19350.5, bsz=653.2, num_updates=8700, lr=0.00015162, gnorm=3.385, clip=2, loss_scale=0.25, train_wall=105, gb_free=14, wall=8955
2023-09-06 03:45:48 | INFO | train_inner | epoch 008:    475 / 1191 loss=2.424, trans_loss=3.959, nll_loss=2.238, w2v_ctc_loss=1.228, task_loss=2.547, task_loss_gen=3.174, contrastive_loss=0, total=6653.57, n_correct=2598.79, ppl=4.72, accuracy=39.059, wps=18781.4, ups=0.97, wpb=19281.2, bsz=656.8, num_updates=8800, lr=0.000150756, gnorm=4.211, clip=4, loss_scale=0.25, train_wall=102, gb_free=10.1, wall=9057
2023-09-06 03:47:30 | INFO | train_inner | epoch 008:    575 / 1191 loss=2.447, trans_loss=3.963, nll_loss=2.242, w2v_ctc_loss=1.267, task_loss=2.267, task_loss_gen=2.98, contrastive_loss=0, total=6681.08, n_correct=2611.53, ppl=4.73, accuracy=39.088, wps=18978.9, ups=0.98, wpb=19359.5, bsz=671, num_updates=8900, lr=0.000149906, gnorm=4.51, clip=4, loss_scale=0.25, train_wall=101, gb_free=13.3, wall=9159
2023-09-06 03:49:11 | INFO | train_inner | epoch 008:    675 / 1191 loss=2.505, trans_loss=3.968, nll_loss=2.247, w2v_ctc_loss=1.351, task_loss=2.07, task_loss_gen=2.888, contrastive_loss=0, total=6718.74, n_correct=2620.39, ppl=4.75, accuracy=39.001, wps=19201.1, ups=0.99, wpb=19462.4, bsz=676, num_updates=9000, lr=0.000149071, gnorm=4.027, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.3, wall=9261
2023-09-06 03:50:54 | INFO | train_inner | epoch 008:    775 / 1191 loss=2.547, trans_loss=3.961, nll_loss=2.24, w2v_ctc_loss=1.421, task_loss=2.078, task_loss_gen=2.902, contrastive_loss=0, total=6698, n_correct=2614.38, ppl=4.72, accuracy=39.032, wps=18872.5, ups=0.97, wpb=19410.7, bsz=673.3, num_updates=9100, lr=0.00014825, gnorm=4.061, clip=3, loss_scale=0.25, train_wall=102, gb_free=10.5, wall=9364
2023-09-06 03:52:36 | INFO | train_inner | epoch 008:    875 / 1191 loss=2.525, trans_loss=3.958, nll_loss=2.236, w2v_ctc_loss=1.39, task_loss=1.94, task_loss_gen=2.654, contrastive_loss=0, total=6791.96, n_correct=2657.72, ppl=4.71, accuracy=39.13, wps=19321.3, ups=0.98, wpb=19682.7, bsz=706.1, num_updates=9200, lr=0.000147442, gnorm=4.034, clip=5, loss_scale=0.25, train_wall=101, gb_free=14.5, wall=9466
2023-09-06 03:54:18 | INFO | train_inner | epoch 008:    975 / 1191 loss=2.612, trans_loss=3.966, nll_loss=2.244, w2v_ctc_loss=1.516, task_loss=2.179, task_loss_gen=3.022, contrastive_loss=0, total=6642.41, n_correct=2590.86, ppl=4.74, accuracy=39.005, wps=18790.7, ups=0.98, wpb=19234, bsz=659.5, num_updates=9300, lr=0.000146647, gnorm=5.401, clip=8, loss_scale=0.25, train_wall=102, gb_free=14.5, wall=9568
2023-09-06 03:56:00 | INFO | train_inner | epoch 008:   1075 / 1191 loss=2.56, trans_loss=3.963, nll_loss=2.238, w2v_ctc_loss=1.436, task_loss=2.187, task_loss_gen=2.9, contrastive_loss=0, total=6715.11, n_correct=2631.24, ppl=4.72, accuracy=39.184, wps=19062.3, ups=0.98, wpb=19429.4, bsz=669.3, num_updates=9400, lr=0.000145865, gnorm=3.914, clip=4, loss_scale=0.25, train_wall=101, gb_free=12.1, wall=9670
2023-09-06 03:57:41 | INFO | train_inner | epoch 008:   1175 / 1191 loss=2.595, trans_loss=3.951, nll_loss=2.227, w2v_ctc_loss=1.504, task_loss=1.855, task_loss_gen=2.736, contrastive_loss=0, total=6699.8, n_correct=2635.56, ppl=4.68, accuracy=39.338, wps=19165, ups=0.99, wpb=19416.9, bsz=710.5, num_updates=9500, lr=0.000145095, gnorm=3.964, clip=5, loss_scale=0.25, train_wall=101, gb_free=12.5, wall=9771
2023-09-06 03:57:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:58:34 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 5.097 | trans_loss 6.825 | nll_loss 4.614 | w2v_ctc_loss 1.57 | task_loss 10.224 | task_loss_gen 11.759 | contrastive_loss 0 | total 6138.43 | n_correct 2439.29 | ppl 24.49 | accuracy 39.738 | uer 26.406 | wer 27.772 | raw_wer 27.772 | bleu 0.25 | wps 1488.2 | wpb 6138.4 | bsz 201.1 | num_updates 9516 | best_bleu 0.25
2023-09-06 03:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9516 updates
2023-09-06 03:58:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 03:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 03:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 8 @ 9516 updates, score 0.25) (writing took 14.169435539050028 seconds)
2023-09-06 03:58:48 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-06 03:58:48 | INFO | train | epoch 008 | loss 2.486 | trans_loss 3.96 | nll_loss 2.238 | w2v_ctc_loss 1.328 | task_loss 2.183 | task_loss_gen 2.913 | contrastive_loss 0 | total 6703.53 | n_correct 2623.17 | ppl 4.72 | accuracy 39.131 | wps 18086.5 | ups 0.93 | wpb 19422.3 | bsz 678.3 | num_updates 9516 | lr 0.000144973 | gnorm 3.735 | clip 3.2 | loss_scale 0.25 | train_wall 1212 | gb_free 14 | wall 9838
2023-09-06 03:58:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:58:48 | INFO | fairseq.trainer | begin training epoch 9
2023-09-06 03:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:00:21 | INFO | train_inner | epoch 009:     84 / 1191 loss=2.557, trans_loss=3.948, nll_loss=2.222, w2v_ctc_loss=1.442, task_loss=2.072, task_loss_gen=2.803, contrastive_loss=0, total=6707.41, n_correct=2639.53, ppl=4.67, accuracy=39.352, wps=12182.5, ups=0.63, wpb=19430.9, bsz=685.6, num_updates=9600, lr=0.000144338, gnorm=3.571, clip=2, loss_scale=0.25, train_wall=101, gb_free=12.7, wall=9931
2023-09-06 04:02:03 | INFO | train_inner | epoch 009:    184 / 1191 loss=2.529, trans_loss=3.943, nll_loss=2.218, w2v_ctc_loss=1.402, task_loss=2.472, task_loss_gen=3.2, contrastive_loss=0, total=6743.4, n_correct=2654.12, ppl=4.65, accuracy=39.359, wps=19087.1, ups=0.98, wpb=19547.1, bsz=682.2, num_updates=9700, lr=0.000143592, gnorm=7.979, clip=33, loss_scale=0.25, train_wall=102, gb_free=12.3, wall=10033
2023-09-06 04:03:45 | INFO | train_inner | epoch 009:    284 / 1191 loss=2.489, trans_loss=3.954, nll_loss=2.227, w2v_ctc_loss=1.341, task_loss=2.251, task_loss_gen=2.92, contrastive_loss=0, total=6831.36, n_correct=2689.6, ppl=4.68, accuracy=39.371, wps=19462.7, ups=0.98, wpb=19775.9, bsz=716.2, num_updates=9800, lr=0.000142857, gnorm=7.074, clip=14, loss_scale=0.25, train_wall=101, gb_free=12.8, wall=10135
2023-09-06 04:05:28 | INFO | train_inner | epoch 009:    384 / 1191 loss=2.467, trans_loss=3.951, nll_loss=2.227, w2v_ctc_loss=1.307, task_loss=2.374, task_loss_gen=2.958, contrastive_loss=0, total=6733.92, n_correct=2643.82, ppl=4.68, accuracy=39.261, wps=18829.6, ups=0.96, wpb=19513.2, bsz=681.5, num_updates=9900, lr=0.000142134, gnorm=5.122, clip=12, loss_scale=0.25, train_wall=103, gb_free=10.2, wall=10238
2023-09-06 04:07:12 | INFO | train_inner | epoch 009:    484 / 1191 loss=2.459, trans_loss=3.946, nll_loss=2.221, w2v_ctc_loss=1.292, task_loss=2.271, task_loss_gen=2.762, contrastive_loss=0, total=6750.99, n_correct=2666.34, ppl=4.66, accuracy=39.496, wps=18850.8, ups=0.96, wpb=19565.9, bsz=700, num_updates=10000, lr=0.000141421, gnorm=3.055, clip=0, loss_scale=0.25, train_wall=103, gb_free=13, wall=10342
2023-09-06 04:07:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:07:46 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.083 | trans_loss 6.814 | nll_loss 4.601 | w2v_ctc_loss 1.548 | task_loss 17.255 | task_loss_gen 12.749 | contrastive_loss 0 | total 6138.43 | n_correct 2446.43 | ppl 24.27 | accuracy 39.854 | uer 24.51 | wer 25.872 | raw_wer 25.872 | bleu 0.15 | wps 1690.6 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 0.25
2023-09-06 04:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-09-06 04:07:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 04:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 04:07:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 0.15) (writing took 10.600317260017619 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 04:09:38 | INFO | train_inner | epoch 009:    584 / 1191 loss=2.481, trans_loss=3.944, nll_loss=2.217, w2v_ctc_loss=1.327, task_loss=2.4, task_loss_gen=2.924, contrastive_loss=0, total=6599.16, n_correct=2601.45, ppl=4.65, accuracy=39.421, wps=13110, ups=0.69, wpb=19115.2, bsz=657.7, num_updates=10100, lr=0.00014072, gnorm=3.015, clip=1, loss_scale=0.25, train_wall=101, gb_free=13.6, wall=10488
2023-09-06 04:11:20 | INFO | train_inner | epoch 009:    684 / 1191 loss=2.459, trans_loss=3.95, nll_loss=2.225, w2v_ctc_loss=1.287, task_loss=2.537, task_loss_gen=3.132, contrastive_loss=0, total=6559.67, n_correct=2583.05, ppl=4.67, accuracy=39.378, wps=18585.3, ups=0.98, wpb=18998.9, bsz=622.4, num_updates=10200, lr=0.000140028, gnorm=2.884, clip=0, loss_scale=0.25, train_wall=102, gb_free=11.9, wall=10590
2023-09-06 04:13:02 | INFO | train_inner | epoch 009:    784 / 1191 loss=2.453, trans_loss=3.942, nll_loss=2.216, w2v_ctc_loss=1.287, task_loss=2.112, task_loss_gen=2.743, contrastive_loss=0, total=6703.36, n_correct=2648.96, ppl=4.65, accuracy=39.517, wps=19003.7, ups=0.98, wpb=19428.1, bsz=686.7, num_updates=10300, lr=0.000139347, gnorm=2.483, clip=0, loss_scale=0.25, train_wall=102, gb_free=9.1, wall=10692
2023-09-06 04:14:45 | INFO | train_inner | epoch 009:    884 / 1191 loss=2.553, trans_loss=3.947, nll_loss=2.222, w2v_ctc_loss=1.438, task_loss=2.187, task_loss_gen=2.919, contrastive_loss=0, total=6733.77, n_correct=2648.89, ppl=4.67, accuracy=39.337, wps=19051.6, ups=0.98, wpb=19512.4, bsz=674, num_updates=10400, lr=0.000138675, gnorm=4.506, clip=6, loss_scale=0.25, train_wall=102, gb_free=14, wall=10795
2023-09-06 04:16:27 | INFO | train_inner | epoch 009:    984 / 1191 loss=2.543, trans_loss=3.945, nll_loss=2.219, w2v_ctc_loss=1.423, task_loss=2.098, task_loss_gen=2.943, contrastive_loss=0, total=6699.46, n_correct=2635.49, ppl=4.66, accuracy=39.339, wps=18933.1, ups=0.98, wpb=19407.9, bsz=675.5, num_updates=10500, lr=0.000138013, gnorm=5.319, clip=4, loss_scale=0.25, train_wall=102, gb_free=11.6, wall=10897
2023-09-06 04:18:09 | INFO | train_inner | epoch 009:   1084 / 1191 loss=2.567, trans_loss=3.944, nll_loss=2.219, w2v_ctc_loss=1.46, task_loss=2.191, task_loss_gen=2.777, contrastive_loss=0, total=6665.1, n_correct=2627.32, ppl=4.65, accuracy=39.419, wps=18935.3, ups=0.98, wpb=19316.1, bsz=678.5, num_updates=10600, lr=0.000137361, gnorm=3.475, clip=4, loss_scale=0.25, train_wall=101, gb_free=13, wall=10999
2023-09-06 04:19:52 | INFO | train_inner | epoch 009:   1184 / 1191 loss=2.592, trans_loss=3.944, nll_loss=2.219, w2v_ctc_loss=1.495, task_loss=2.177, task_loss_gen=2.953, contrastive_loss=0, total=6683.3, n_correct=2629.83, ppl=4.65, accuracy=39.349, wps=18879.5, ups=0.97, wpb=19368.4, bsz=658.4, num_updates=10700, lr=0.000136717, gnorm=3.305, clip=6, loss_scale=0.5, train_wall=102, gb_free=12.9, wall=11102
2023-09-06 04:19:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
2023-09-06 04:20:32 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.114 | trans_loss 6.818 | nll_loss 4.603 | w2v_ctc_loss 1.641 | task_loss 11.013 | task_loss_gen 11.923 | contrastive_loss 0 | total 6138.43 | n_correct 2445.71 | ppl 24.29 | accuracy 39.843 | uer 27.259 | wer 28.773 | raw_wer 28.773 | bleu 0.16 | wps 1728 | wpb 6138.4 | bsz 201.1 | num_updates 10707 | best_bleu 0.25
2023-09-06 04:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10707 updates
2023-09-06 04:20:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt
2023-09-06 04:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt
2023-09-06 04:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt (epoch 9 @ 10707 updates, score 0.16) (writing took 7.803101063007489 seconds)
2023-09-06 04:20:41 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-06 04:20:41 | INFO | train | epoch 009 | loss 2.512 | trans_loss 3.946 | nll_loss 2.22 | w2v_ctc_loss 1.375 | task_loss 2.254 | task_loss_gen 2.91 | contrastive_loss 0 | total 6703.69 | n_correct 2640.89 | ppl 4.66 | accuracy 39.395 | wps 17624.7 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 10707 | lr 0.000136672 | gnorm 4.357 | clip 7.1 | loss_scale 0.5 | train_wall 1212 | gb_free 14.3 | wall 11150
2023-09-06 04:20:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 04:20:41 | INFO | fairseq.trainer | begin training epoch 10
2023-09-06 04:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:22:23 | INFO | train_inner | epoch 010:     93 / 1191 loss=2.563, trans_loss=3.928, nll_loss=2.198, w2v_ctc_loss=1.461, task_loss=2.073, task_loss_gen=2.877, contrastive_loss=0, total=6658.21, n_correct=2644.49, ppl=4.59, accuracy=39.718, wps=12765.7, ups=0.66, wpb=19289, bsz=675.2, num_updates=10800, lr=0.000136083, gnorm=2.321, clip=2, loss_scale=0.5, train_wall=101, gb_free=13.6, wall=11253
2023-09-06 04:24:04 | INFO | train_inner | epoch 010:    193 / 1191 loss=2.518, trans_loss=3.933, nll_loss=2.204, w2v_ctc_loss=1.395, task_loss=2.202, task_loss_gen=2.957, contrastive_loss=0, total=6661.46, n_correct=2645.38, ppl=4.61, accuracy=39.712, wps=19048.7, ups=0.99, wpb=19303.2, bsz=679.5, num_updates=10900, lr=0.000135457, gnorm=2.452, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.9, wall=11354
2023-09-06 04:25:47 | INFO | train_inner | epoch 010:    293 / 1191 loss=2.523, trans_loss=3.931, nll_loss=2.2, w2v_ctc_loss=1.402, task_loss=2.09, task_loss_gen=2.871, contrastive_loss=0, total=6782.88, n_correct=2692.29, ppl=4.59, accuracy=39.692, wps=19171.3, ups=0.98, wpb=19645.1, bsz=690.7, num_updates=11000, lr=0.00013484, gnorm=4.021, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.9, wall=11457
2023-09-06 04:27:30 | INFO | train_inner | epoch 010:    393 / 1191 loss=2.514, trans_loss=3.93, nll_loss=2.201, w2v_ctc_loss=1.391, task_loss=2.023, task_loss_gen=2.695, contrastive_loss=0, total=6818.2, n_correct=2709.6, ppl=4.6, accuracy=39.741, wps=19078.8, ups=0.97, wpb=19754, bsz=723.2, num_updates=11100, lr=0.000134231, gnorm=2.611, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.9, wall=11560
2023-09-06 04:29:13 | INFO | train_inner | epoch 010:    493 / 1191 loss=2.554, trans_loss=3.93, nll_loss=2.198, w2v_ctc_loss=1.445, task_loss=2.413, task_loss_gen=2.864, contrastive_loss=0, total=6725.27, n_correct=2663.43, ppl=4.59, accuracy=39.603, wps=19043.8, ups=0.98, wpb=19473.5, bsz=669.6, num_updates=11200, lr=0.000133631, gnorm=2.046, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.2, wall=11663
2023-09-06 04:30:54 | INFO | train_inner | epoch 010:    593 / 1191 loss=2.552, trans_loss=3.931, nll_loss=2.201, w2v_ctc_loss=1.446, task_loss=2.297, task_loss_gen=2.788, contrastive_loss=0, total=6731.17, n_correct=2669.98, ppl=4.6, accuracy=39.666, wps=19234.7, ups=0.99, wpb=19501.1, bsz=680.7, num_updates=11300, lr=0.000133038, gnorm=2.044, clip=1, loss_scale=0.5, train_wall=101, gb_free=12, wall=11764
2023-09-06 04:32:36 | INFO | train_inner | epoch 010:    693 / 1191 loss=2.526, trans_loss=3.928, nll_loss=2.198, w2v_ctc_loss=1.405, task_loss=2.248, task_loss_gen=2.777, contrastive_loss=0, total=6746.82, n_correct=2682, ppl=4.59, accuracy=39.752, wps=19112.3, ups=0.98, wpb=19545.4, bsz=690.7, num_updates=11400, lr=0.000132453, gnorm=2.634, clip=2, loss_scale=0.5, train_wall=102, gb_free=12.7, wall=11866
2023-09-06 04:34:18 | INFO | train_inner | epoch 010:    793 / 1191 loss=2.572, trans_loss=3.932, nll_loss=2.204, w2v_ctc_loss=1.471, task_loss=2.287, task_loss_gen=3.006, contrastive_loss=0, total=6630.78, n_correct=2615.68, ppl=4.61, accuracy=39.448, wps=18863, ups=0.98, wpb=19219.8, bsz=651.1, num_updates=11500, lr=0.000131876, gnorm=2.389, clip=3, loss_scale=0.5, train_wall=101, gb_free=14, wall=11968
2023-09-06 04:35:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 04:36:03 | INFO | train_inner | epoch 010:    894 / 1191 loss=2.601, trans_loss=3.928, nll_loss=2.199, w2v_ctc_loss=1.519, task_loss=2.227, task_loss_gen=3.109, contrastive_loss=0, total=6558.58, n_correct=2601.32, ppl=4.59, accuracy=39.663, wps=18099.4, ups=0.95, wpb=19006.2, bsz=639.1, num_updates=11600, lr=0.000131306, gnorm=3.7, clip=4, loss_scale=0.25, train_wall=104, gb_free=14.1, wall=12073
2023-09-06 04:37:45 | INFO | train_inner | epoch 010:    994 / 1191 loss=2.61, trans_loss=3.927, nll_loss=2.197, w2v_ctc_loss=1.534, task_loss=2.094, task_loss_gen=2.717, contrastive_loss=0, total=6753.84, n_correct=2681.4, ppl=4.58, accuracy=39.702, wps=19221.8, ups=0.98, wpb=19567.9, bsz=689.1, num_updates=11700, lr=0.000130744, gnorm=4.43, clip=2, loss_scale=0.25, train_wall=101, gb_free=13.5, wall=12175
2023-09-06 04:39:28 | INFO | train_inner | epoch 010:   1094 / 1191 loss=2.569, trans_loss=3.926, nll_loss=2.197, w2v_ctc_loss=1.472, task_loss=2.296, task_loss_gen=2.818, contrastive_loss=0, total=6689.47, n_correct=2651.39, ppl=4.59, accuracy=39.635, wps=18890.1, ups=0.97, wpb=19393.8, bsz=676.6, num_updates=11800, lr=0.000130189, gnorm=3.436, clip=1, loss_scale=0.25, train_wall=102, gb_free=7.3, wall=12278
2023-09-06 04:41:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:41:40 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 5.098 | trans_loss 6.809 | nll_loss 4.591 | w2v_ctc_loss 1.611 | task_loss 12.894 | task_loss_gen 11.775 | contrastive_loss 0 | total 6138.43 | n_correct 2446.43 | ppl 24.1 | accuracy 39.854 | uer 26.689 | wer 28.412 | raw_wer 28.412 | bleu 0.13 | wps 1696.9 | wpb 6138.4 | bsz 201.1 | num_updates 11897 | best_bleu 0.25
2023-09-06 04:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11897 updates
2023-09-06 04:41:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 04:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 04:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt (epoch 10 @ 11897 updates, score 0.13) (writing took 10.143143795896322 seconds)
2023-09-06 04:41:50 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-06 04:41:50 | INFO | train | epoch 010 | loss 2.554 | trans_loss 3.929 | nll_loss 2.199 | w2v_ctc_loss 1.449 | task_loss 2.203 | task_loss_gen 2.856 | contrastive_loss 0 | total 6704.88 | n_correct 2660.3 | ppl 4.59 | accuracy 39.677 | wps 18208.9 | ups 0.94 | wpb 19426.2 | bsz 678.5 | num_updates 11897 | lr 0.000129657 | gnorm 2.889 | clip 1.6 | loss_scale 0.25 | train_wall 1211 | gb_free 12.1 | wall 12420
2023-09-06 04:41:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 04:41:50 | INFO | fairseq.trainer | begin training epoch 11
2023-09-06 04:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:42:01 | INFO | train_inner | epoch 011:      3 / 1191 loss=2.556, trans_loss=3.926, nll_loss=2.194, w2v_ctc_loss=1.456, task_loss=2.177, task_loss_gen=2.795, contrastive_loss=0, total=6703.53, n_correct=2669.13, ppl=4.58, accuracy=39.817, wps=12715.4, ups=0.65, wpb=19417.9, bsz=681.5, num_updates=11900, lr=0.000129641, gnorm=3.052, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.2, wall=12430
2023-09-06 04:43:43 | INFO | train_inner | epoch 011:    103 / 1191 loss=2.594, trans_loss=3.917, nll_loss=2.185, w2v_ctc_loss=1.513, task_loss=2.365, task_loss_gen=2.969, contrastive_loss=0, total=6658.67, n_correct=2648.24, ppl=4.55, accuracy=39.771, wps=18782.3, ups=0.97, wpb=19302.4, bsz=654.5, num_updates=12000, lr=0.000129099, gnorm=3.022, clip=2, loss_scale=0.25, train_wall=102, gb_free=12.7, wall=12533
2023-09-06 04:43:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:44:16 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.085 | trans_loss 6.803 | nll_loss 4.584 | w2v_ctc_loss 1.58 | task_loss 11.122 | task_loss_gen 11.92 | contrastive_loss 0 | total 6138.43 | n_correct 2457.14 | ppl 23.98 | accuracy 40.029 | uer 26.542 | wer 28.1 | raw_wer 28.1 | bleu 0.14 | wps 1740.2 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 0.25
2023-09-06 04:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-09-06 04:44:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 04:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 04:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 0.14) (writing took 8.448308683000505 seconds)
2023-09-06 04:46:06 | INFO | train_inner | epoch 011:    203 / 1191 loss=2.562, trans_loss=3.917, nll_loss=2.182, w2v_ctc_loss=1.47, task_loss=2.181, task_loss_gen=2.745, contrastive_loss=0, total=6711.38, n_correct=2691.45, ppl=4.54, accuracy=40.103, wps=13577.7, ups=0.7, wpb=19433.4, bsz=694.6, num_updates=12100, lr=0.000128565, gnorm=3.129, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.7, wall=12676
2023-09-06 04:47:49 | INFO | train_inner | epoch 011:    303 / 1191 loss=2.596, trans_loss=3.916, nll_loss=2.182, w2v_ctc_loss=1.521, task_loss=2.266, task_loss_gen=2.939, contrastive_loss=0, total=6592.11, n_correct=2628.72, ppl=4.54, accuracy=39.877, wps=18655, ups=0.98, wpb=19100.7, bsz=661.6, num_updates=12200, lr=0.000128037, gnorm=4.463, clip=6, loss_scale=0.25, train_wall=102, gb_free=12.3, wall=12779
2023-09-06 04:49:31 | INFO | train_inner | epoch 011:    403 / 1191 loss=2.588, trans_loss=3.915, nll_loss=2.182, w2v_ctc_loss=1.505, task_loss=2.535, task_loss_gen=3.048, contrastive_loss=0, total=6592.18, n_correct=2631.34, ppl=4.54, accuracy=39.916, wps=18738.5, ups=0.98, wpb=19108.3, bsz=655.9, num_updates=12300, lr=0.000127515, gnorm=8.811, clip=38, loss_scale=0.25, train_wall=101, gb_free=11.3, wall=12881
2023-09-06 04:51:13 | INFO | train_inner | epoch 011:    503 / 1191 loss=2.653, trans_loss=3.932, nll_loss=2.203, w2v_ctc_loss=1.594, task_loss=2.253, task_loss_gen=3.054, contrastive_loss=0, total=6673.62, n_correct=2631.86, ppl=4.6, accuracy=39.437, wps=18834.9, ups=0.97, wpb=19341.4, bsz=656.4, num_updates=12400, lr=0.000127, gnorm=8.659, clip=32, loss_scale=0.25, train_wall=102, gb_free=13.9, wall=12983
2023-09-06 04:52:54 | INFO | train_inner | epoch 011:    603 / 1191 loss=2.703, trans_loss=3.922, nll_loss=2.192, w2v_ctc_loss=1.68, task_loss=2.29, task_loss_gen=2.879, contrastive_loss=0, total=6642.09, n_correct=2632.97, ppl=4.57, accuracy=39.641, wps=19095.9, ups=0.99, wpb=19264.4, bsz=664.6, num_updates=12500, lr=0.000126491, gnorm=5.732, clip=10, loss_scale=0.25, train_wall=100, gb_free=14.1, wall=13084
2023-09-06 04:54:37 | INFO | train_inner | epoch 011:    703 / 1191 loss=2.674, trans_loss=3.914, nll_loss=2.182, w2v_ctc_loss=1.642, task_loss=2.361, task_loss_gen=2.896, contrastive_loss=0, total=6685.05, n_correct=2662.87, ppl=4.54, accuracy=39.833, wps=18917.5, ups=0.98, wpb=19384.9, bsz=669.6, num_updates=12600, lr=0.000125988, gnorm=4.247, clip=6, loss_scale=0.25, train_wall=102, gb_free=13.3, wall=13187
2023-09-06 04:56:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-06 04:56:20 | INFO | train_inner | epoch 011:    804 / 1191 loss=2.703, trans_loss=3.921, nll_loss=2.189, w2v_ctc_loss=1.684, task_loss=2.158, task_loss_gen=2.781, contrastive_loss=0, total=6797.73, n_correct=2706.61, ppl=4.56, accuracy=39.816, wps=19007.4, ups=0.97, wpb=19694.7, bsz=701.1, num_updates=12700, lr=0.000125491, gnorm=4.551, clip=5, loss_scale=0.125, train_wall=103, gb_free=13.2, wall=13290
2023-09-06 04:58:03 | INFO | train_inner | epoch 011:    904 / 1191 loss=2.682, trans_loss=3.927, nll_loss=2.194, w2v_ctc_loss=1.645, task_loss=2.262, task_loss_gen=2.821, contrastive_loss=0, total=6775.73, n_correct=2696.8, ppl=4.57, accuracy=39.801, wps=19105.2, ups=0.97, wpb=19615.9, bsz=682.4, num_updates=12800, lr=0.000125, gnorm=6.703, clip=17, loss_scale=0.125, train_wall=102, gb_free=12.2, wall=13393
2023-09-06 04:59:46 | INFO | train_inner | epoch 011:   1004 / 1191 loss=2.63, trans_loss=3.92, nll_loss=2.186, w2v_ctc_loss=1.572, task_loss=2.09, task_loss_gen=2.634, contrastive_loss=0, total=6815.44, n_correct=2723.41, ppl=4.55, accuracy=39.959, wps=19143.3, ups=0.97, wpb=19730.4, bsz=713, num_updates=12900, lr=0.000124515, gnorm=4.218, clip=4, loss_scale=0.125, train_wall=102, gb_free=14.1, wall=13496
2023-09-06 05:01:28 | INFO | train_inner | epoch 011:   1104 / 1191 loss=2.641, trans_loss=3.918, nll_loss=2.185, w2v_ctc_loss=1.589, task_loss=2.159, task_loss_gen=2.827, contrastive_loss=0, total=6719.62, n_correct=2676.19, ppl=4.55, accuracy=39.827, wps=19208.6, ups=0.99, wpb=19466, bsz=691.7, num_updates=13000, lr=0.000124035, gnorm=12.859, clip=34, loss_scale=0.125, train_wall=101, gb_free=15, wall=13597
2023-09-06 05:02:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:03:30 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.162 | trans_loss 6.8 | nll_loss 4.578 | w2v_ctc_loss 1.845 | task_loss 12.561 | task_loss_gen 11.481 | contrastive_loss 0 | total 6138.43 | n_correct 2465.57 | ppl 23.88 | accuracy 40.166 | uer 29.717 | wer 31.231 | raw_wer 31.231 | bleu 0.2 | wps 1695.3 | wpb 6138.4 | bsz 201.1 | num_updates 13087 | best_bleu 0.25
2023-09-06 05:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13087 updates
2023-09-06 05:03:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt
2023-09-06 05:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt
2023-09-06 05:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt (epoch 11 @ 13087 updates, score 0.2) (writing took 8.01055621006526 seconds)
2023-09-06 05:03:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-06 05:03:39 | INFO | train | epoch 011 | loss 2.645 | trans_loss 3.921 | nll_loss 2.188 | w2v_ctc_loss 1.593 | task_loss 2.25 | task_loss_gen 2.857 | contrastive_loss 0 | total 6703.49 | n_correct 2668.72 | ppl 4.56 | accuracy 39.811 | wps 17664.2 | ups 0.91 | wpb 19422.2 | bsz 678.2 | num_updates 13087 | lr 0.000123622 | gnorm 6.205 | clip 14.9 | loss_scale 0.125 | train_wall 1210 | gb_free 13.2 | wall 13728
2023-09-06 05:03:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:03:39 | INFO | fairseq.trainer | begin training epoch 12
2023-09-06 05:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:04:00 | INFO | train_inner | epoch 012:     13 / 1191 loss=2.712, trans_loss=3.923, nll_loss=2.19, w2v_ctc_loss=1.699, task_loss=2.029, task_loss_gen=2.592, contrastive_loss=0, total=6840.98, n_correct=2730.87, ppl=4.56, accuracy=39.919, wps=13010.6, ups=0.66, wpb=19805.8, bsz=723.2, num_updates=13100, lr=0.00012356, gnorm=7.903, clip=20, loss_scale=0.125, train_wall=102, gb_free=10.5, wall=13750
2023-09-06 05:05:42 | INFO | train_inner | epoch 012:    113 / 1191 loss=2.714, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.702, task_loss=2.407, task_loss_gen=2.859, contrastive_loss=0, total=6706.17, n_correct=2670.63, ppl=4.53, accuracy=39.823, wps=18944.2, ups=0.98, wpb=19429.8, bsz=660.9, num_updates=13200, lr=0.000123091, gnorm=10.326, clip=18, loss_scale=0.125, train_wall=102, gb_free=12.6, wall=13852
2023-09-06 05:07:24 | INFO | train_inner | epoch 012:    213 / 1191 loss=2.8, trans_loss=3.916, nll_loss=2.183, w2v_ctc_loss=1.835, task_loss=2.191, task_loss_gen=2.772, contrastive_loss=0, total=6758.31, n_correct=2691.92, ppl=4.54, accuracy=39.831, wps=19178, ups=0.98, wpb=19580.8, bsz=678.4, num_updates=13300, lr=0.000122628, gnorm=12.77, clip=26, loss_scale=0.125, train_wall=101, gb_free=13.6, wall=13954
2023-09-06 05:09:07 | INFO | train_inner | epoch 012:    313 / 1191 loss=2.724, trans_loss=3.913, nll_loss=2.179, w2v_ctc_loss=1.721, task_loss=2.133, task_loss_gen=2.699, contrastive_loss=0, total=6707.15, n_correct=2680.79, ppl=4.53, accuracy=39.969, wps=18913.5, ups=0.97, wpb=19435.8, bsz=693.4, num_updates=13400, lr=0.000122169, gnorm=5.835, clip=10, loss_scale=0.125, train_wall=102, gb_free=11.2, wall=14057
2023-09-06 05:10:49 | INFO | train_inner | epoch 012:    413 / 1191 loss=2.65, trans_loss=3.914, nll_loss=2.18, w2v_ctc_loss=1.608, task_loss=2.114, task_loss_gen=2.611, contrastive_loss=0, total=6766.6, n_correct=2703.07, ppl=4.53, accuracy=39.947, wps=19269.4, ups=0.98, wpb=19605.1, bsz=706.7, num_updates=13500, lr=0.000121716, gnorm=5.894, clip=13, loss_scale=0.125, train_wall=101, gb_free=14.3, wall=14159
2023-09-06 05:12:30 | INFO | train_inner | epoch 012:    513 / 1191 loss=2.659, trans_loss=3.917, nll_loss=2.183, w2v_ctc_loss=1.615, task_loss=2.182, task_loss_gen=2.692, contrastive_loss=0, total=6741.73, n_correct=2692.34, ppl=4.54, accuracy=39.935, wps=19259.5, ups=0.99, wpb=19531.2, bsz=688.4, num_updates=13600, lr=0.000121268, gnorm=5.647, clip=3, loss_scale=0.125, train_wall=101, gb_free=13, wall=14260
2023-09-06 05:14:13 | INFO | train_inner | epoch 012:    613 / 1191 loss=2.63, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.574, task_loss=2.253, task_loss_gen=2.912, contrastive_loss=0, total=6697.76, n_correct=2677.67, ppl=4.53, accuracy=39.979, wps=18955.3, ups=0.98, wpb=19401.1, bsz=671, num_updates=13700, lr=0.000120824, gnorm=5.355, clip=3, loss_scale=0.125, train_wall=102, gb_free=13.3, wall=14363
2023-09-06 05:15:55 | INFO | train_inner | epoch 012:    713 / 1191 loss=2.619, trans_loss=3.906, nll_loss=2.172, w2v_ctc_loss=1.566, task_loss=2.375, task_loss_gen=2.71, contrastive_loss=0, total=6731.9, n_correct=2697.06, ppl=4.51, accuracy=40.064, wps=19001.9, ups=0.97, wpb=19527.6, bsz=685.1, num_updates=13800, lr=0.000120386, gnorm=5.772, clip=7, loss_scale=0.125, train_wall=102, gb_free=13.4, wall=14465
2023-09-06 05:17:38 | INFO | train_inner | epoch 012:    813 / 1191 loss=2.641, trans_loss=3.92, nll_loss=2.186, w2v_ctc_loss=1.586, task_loss=2.341, task_loss_gen=2.922, contrastive_loss=0, total=6659.05, n_correct=2659.29, ppl=4.55, accuracy=39.935, wps=18760.6, ups=0.97, wpb=19282.5, bsz=661.1, num_updates=13900, lr=0.000119952, gnorm=7.557, clip=22, loss_scale=0.125, train_wall=102, gb_free=11.8, wall=14568
2023-09-06 05:19:22 | INFO | train_inner | epoch 012:    913 / 1191 loss=2.626, trans_loss=3.918, nll_loss=2.184, w2v_ctc_loss=1.567, task_loss=2.317, task_loss_gen=2.887, contrastive_loss=0, total=6701.85, n_correct=2677.69, ppl=4.54, accuracy=39.954, wps=18776.8, ups=0.97, wpb=19408.4, bsz=671.8, num_updates=14000, lr=0.000119523, gnorm=5.265, clip=7, loss_scale=0.125, train_wall=103, gb_free=13.6, wall=14671
2023-09-06 05:19:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:19:55 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 5.144 | trans_loss 6.799 | nll_loss 4.577 | w2v_ctc_loss 1.784 | task_loss 13.356 | task_loss_gen 11.845 | contrastive_loss 0 | total 6138.43 | n_correct 2468.29 | ppl 23.87 | accuracy 40.21 | uer 28.572 | wer 30.253 | raw_wer 30.253 | bleu 0.16 | wps 1717.3 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 0.25
2023-09-06 05:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-09-06 05:19:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 05:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 05:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 0.16) (writing took 9.49134656705428 seconds)
2023-09-06 05:21:46 | INFO | train_inner | epoch 012:   1013 / 1191 loss=2.622, trans_loss=3.915, nll_loss=2.185, w2v_ctc_loss=1.56, task_loss=2.465, task_loss_gen=2.882, contrastive_loss=0, total=6584.36, n_correct=2621.24, ppl=4.55, accuracy=39.81, wps=13200.7, ups=0.69, wpb=19095.9, bsz=659, num_updates=14100, lr=0.000119098, gnorm=4.715, clip=2, loss_scale=0.125, train_wall=101, gb_free=14.1, wall=14816
2023-09-06 05:23:29 | INFO | train_inner | epoch 012:   1113 / 1191 loss=2.61, trans_loss=3.916, nll_loss=2.18, w2v_ctc_loss=1.542, task_loss=2.358, task_loss_gen=2.913, contrastive_loss=0, total=6644.98, n_correct=2653.7, ppl=4.53, accuracy=39.935, wps=18801.3, ups=0.98, wpb=19243.3, bsz=668.4, num_updates=14200, lr=0.000118678, gnorm=5.534, clip=11, loss_scale=0.125, train_wall=102, gb_free=13.2, wall=14919
2023-09-06 05:24:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:25:24 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 5.133 | trans_loss 6.8 | nll_loss 4.583 | w2v_ctc_loss 1.748 | task_loss 13.526 | task_loss_gen 11.777 | contrastive_loss 0 | total 6138.43 | n_correct 2454.86 | ppl 23.97 | accuracy 39.992 | uer 28.267 | wer 29.877 | raw_wer 29.877 | bleu 0.31 | wps 1578 | wpb 6138.4 | bsz 201.1 | num_updates 14278 | best_bleu 0.31
2023-09-06 05:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14278 updates
2023-09-06 05:25:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 05:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 05:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 12 @ 14278 updates, score 0.31) (writing took 12.971250363974832 seconds)
2023-09-06 05:25:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-06 05:25:37 | INFO | train | epoch 012 | loss 2.66 | trans_loss 3.915 | nll_loss 2.181 | w2v_ctc_loss 1.621 | task_loss 2.278 | task_loss_gen 2.794 | contrastive_loss 0 | total 6703.69 | n_correct 2677.29 | ppl 4.53 | accuracy 39.937 | wps 17546.4 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 14278 | lr 0.000118354 | gnorm 6.712 | clip 10.7 | loss_scale 0.125 | train_wall 1210 | gb_free 13.9 | wall 15047
2023-09-06 05:25:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:25:37 | INFO | fairseq.trainer | begin training epoch 13
2023-09-06 05:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:26:08 | INFO | train_inner | epoch 013:     22 / 1191 loss=2.613, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.549, task_loss=2.33, task_loss_gen=2.814, contrastive_loss=0, total=6692.41, n_correct=2676.93, ppl=4.53, accuracy=39.999, wps=12196, ups=0.63, wpb=19386.7, bsz=670.5, num_updates=14300, lr=0.000118262, gnorm=5.787, clip=6, loss_scale=0.125, train_wall=102, gb_free=12.6, wall=15077
2023-09-06 05:27:50 | INFO | train_inner | epoch 013:    122 / 1191 loss=2.596, trans_loss=3.902, nll_loss=2.164, w2v_ctc_loss=1.527, task_loss=2.401, task_loss_gen=2.89, contrastive_loss=0, total=6709.06, n_correct=2694.26, ppl=4.48, accuracy=40.159, wps=18979, ups=0.98, wpb=19438.9, bsz=666.1, num_updates=14400, lr=0.000117851, gnorm=5.154, clip=3, loss_scale=0.125, train_wall=102, gb_free=14.6, wall=15180
2023-09-06 05:29:33 | INFO | train_inner | epoch 013:    222 / 1191 loss=2.614, trans_loss=3.907, nll_loss=2.171, w2v_ctc_loss=1.557, task_loss=2.218, task_loss_gen=2.737, contrastive_loss=0, total=6683.81, n_correct=2683.82, ppl=4.5, accuracy=40.154, wps=18896.2, ups=0.98, wpb=19361.8, bsz=702.7, num_updates=14500, lr=0.000117444, gnorm=4.483, clip=3, loss_scale=0.125, train_wall=102, gb_free=14.3, wall=15282
2023-09-06 05:31:14 | INFO | train_inner | epoch 013:    322 / 1191 loss=2.627, trans_loss=3.902, nll_loss=2.165, w2v_ctc_loss=1.581, task_loss=1.971, task_loss_gen=2.593, contrastive_loss=0, total=6740.39, n_correct=2713.61, ppl=4.48, accuracy=40.259, wps=19250.6, ups=0.99, wpb=19531.1, bsz=716.4, num_updates=14600, lr=0.000117041, gnorm=5.729, clip=10, loss_scale=0.125, train_wall=101, gb_free=13.4, wall=15384
2023-09-06 05:32:56 | INFO | train_inner | epoch 013:    422 / 1191 loss=2.664, trans_loss=3.914, nll_loss=2.18, w2v_ctc_loss=1.625, task_loss=2.255, task_loss_gen=2.843, contrastive_loss=0, total=6715.72, n_correct=2677.64, ppl=4.53, accuracy=39.871, wps=19052.6, ups=0.98, wpb=19459.4, bsz=670.8, num_updates=14700, lr=0.000116642, gnorm=7.227, clip=13, loss_scale=0.125, train_wall=102, gb_free=14.1, wall=15486
2023-09-06 05:34:39 | INFO | train_inner | epoch 013:    522 / 1191 loss=2.69, trans_loss=3.909, nll_loss=2.173, w2v_ctc_loss=1.669, task_loss=2.335, task_loss_gen=3.016, contrastive_loss=0, total=6635.66, n_correct=2654.24, ppl=4.51, accuracy=40, wps=18675.6, ups=0.97, wpb=19230.2, bsz=649.9, num_updates=14800, lr=0.000116248, gnorm=4.158, clip=8, loss_scale=0.25, train_wall=102, gb_free=13.5, wall=15589
2023-09-06 05:36:21 | INFO | train_inner | epoch 013:    622 / 1191 loss=2.628, trans_loss=3.91, nll_loss=2.175, w2v_ctc_loss=1.574, task_loss=2.283, task_loss_gen=2.904, contrastive_loss=0, total=6711.43, n_correct=2687.97, ppl=4.51, accuracy=40.051, wps=18983.9, ups=0.98, wpb=19440.8, bsz=654.6, num_updates=14900, lr=0.000115857, gnorm=3.228, clip=2, loss_scale=0.25, train_wall=102, gb_free=11.9, wall=15691
2023-09-06 05:38:05 | INFO | train_inner | epoch 013:    722 / 1191 loss=2.563, trans_loss=3.909, nll_loss=2.173, w2v_ctc_loss=1.473, task_loss=2.334, task_loss_gen=2.89, contrastive_loss=0, total=6634.93, n_correct=2659.43, ppl=4.51, accuracy=40.082, wps=18588.2, ups=0.97, wpb=19220.1, bsz=660.1, num_updates=15000, lr=0.00011547, gnorm=2.479, clip=0, loss_scale=0.25, train_wall=103, gb_free=12.1, wall=15795
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 05:39:18 | INFO | train_inner | epoch 013:    822 / 1191 loss=2.612, trans_loss=5.635, nll_loss=3.129, w2v_ctc_loss=1.055, task_loss=3.175, task_loss_gen=3.996, contrastive_loss=0, total=6781.8, n_correct=2727.41, ppl=8.75, accuracy=40.217, wps=18641, ups=1.37, wpb=13616.6, bsz=465.9, num_updates=15100, lr=0.000115087, gnorm=2.416, clip=0, loss_scale=0.25, train_wall=72, gb_free=9.8, wall=15868
2023-09-06 05:40:30 | INFO | train_inner | epoch 013:    922 / 1191 loss=2.619, trans_loss=5.657, nll_loss=3.141, w2v_ctc_loss=1.05, task_loss=3.815, task_loss_gen=4.662, contrastive_loss=0, total=6544.72, n_correct=2622.05, ppl=8.82, accuracy=40.064, wps=18144.2, ups=1.39, wpb=13089.4, bsz=417.1, num_updates=15200, lr=0.000114708, gnorm=3.548, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.1, wall=15940
2023-09-06 05:41:43 | INFO | train_inner | epoch 013:   1022 / 1191 loss=2.61, trans_loss=5.655, nll_loss=3.139, w2v_ctc_loss=1.046, task_loss=3.169, task_loss_gen=4.046, contrastive_loss=0, total=6788.78, n_correct=2728.77, ppl=8.81, accuracy=40.195, wps=18644.9, ups=1.37, wpb=13577.6, bsz=466.8, num_updates=15300, lr=0.000114332, gnorm=2.921, clip=1, loss_scale=0.25, train_wall=72, gb_free=14.9, wall=16013
2023-09-06 05:42:56 | INFO | train_inner | epoch 013:   1122 / 1191 loss=2.607, trans_loss=5.655, nll_loss=3.139, w2v_ctc_loss=1.036, task_loss=3.236, task_loss_gen=4.137, contrastive_loss=0, total=6754.7, n_correct=2716.39, ppl=8.81, accuracy=40.215, wps=18537.6, ups=1.37, wpb=13509.4, bsz=465.2, num_updates=15400, lr=0.000113961, gnorm=3.342, clip=0, loss_scale=0.25, train_wall=72, gb_free=12.3, wall=16086
2023-09-06 05:43:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
2023-09-06 05:44:19 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 5.086 | trans_loss 6.786 | nll_loss 4.56 | w2v_ctc_loss 1.624 | task_loss 10.079 | task_loss_gen 11.638 | contrastive_loss 0 | total 6138.43 | n_correct 2477.71 | ppl 23.58 | accuracy 40.364 | uer 26.197 | wer 27.865 | raw_wer 27.865 | bleu 0.11 | wps 1697.4 | wpb 6138.4 | bsz 201.1 | num_updates 15469 | best_bleu 0.31
2023-09-06 05:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15469 updates
2023-09-06 05:44:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 05:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 05:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt (epoch 13 @ 15469 updates, score 0.11) (writing took 7.641052469029091 seconds)
2023-09-06 05:44:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-06 05:44:27 | INFO | train | epoch 013 | loss 2.621 | trans_loss 4.449 | nll_loss 2.471 | w2v_ctc_loss 1.406 | task_loss 2.569 | task_loss_gen 3.233 | contrastive_loss 0 | total 6703.69 | n_correct 2689.69 | ppl 5.55 | accuracy 40.123 | wps 17972.4 | ups 1.05 | wpb 17052.6 | bsz 588.7 | num_updates 15469 | lr 0.000113706 | gnorm 3.971 | clip 3.4 | loss_scale 0.25 | train_wall 1073 | gb_free 9.7 | wall 16177
2023-09-06 05:44:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:44:27 | INFO | fairseq.trainer | begin training epoch 14
2023-09-06 05:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:44:57 | INFO | train_inner | epoch 014:     31 / 1191 loss=2.603, trans_loss=5.656, nll_loss=3.141, w2v_ctc_loss=1.015, task_loss=3.155, task_loss_gen=4.009, contrastive_loss=0, total=6718.48, n_correct=2697.7, ppl=8.82, accuracy=40.153, wps=11091.7, ups=0.83, wpb=13437, bsz=458.1, num_updates=15500, lr=0.000113592, gnorm=2.512, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.5, wall=16207
2023-09-06 05:46:09 | INFO | train_inner | epoch 014:    131 / 1191 loss=2.618, trans_loss=5.653, nll_loss=3.135, w2v_ctc_loss=1.075, task_loss=2.93, task_loss_gen=4.048, contrastive_loss=0, total=6692.6, n_correct=2689.91, ppl=8.78, accuracy=40.192, wps=18535.6, ups=1.38, wpb=13385.2, bsz=463.1, num_updates=15600, lr=0.000113228, gnorm=5.458, clip=5, loss_scale=0.25, train_wall=72, gb_free=11.8, wall=16279
2023-09-06 05:47:22 | INFO | train_inner | epoch 014:    231 / 1191 loss=2.666, trans_loss=5.655, nll_loss=3.138, w2v_ctc_loss=1.214, task_loss=3.222, task_loss_gen=4.428, contrastive_loss=0, total=6609.27, n_correct=2647.6, ppl=8.8, accuracy=40.059, wps=18259.8, ups=1.38, wpb=13218.5, bsz=433.9, num_updates=15700, lr=0.000112867, gnorm=5.472, clip=10, loss_scale=0.25, train_wall=72, gb_free=12.5, wall=16351
2023-09-06 05:48:35 | INFO | train_inner | epoch 014:    331 / 1191 loss=2.64, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.136, task_loss=3.248, task_loss_gen=4.287, contrastive_loss=0, total=6742.67, n_correct=2707.11, ppl=8.78, accuracy=40.149, wps=18470.8, ups=1.37, wpb=13485.3, bsz=449.8, num_updates=15800, lr=0.000112509, gnorm=4.091, clip=2, loss_scale=0.25, train_wall=72, gb_free=14, wall=16424
2023-09-06 05:49:48 | INFO | train_inner | epoch 014:    431 / 1191 loss=2.639, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.142, task_loss=2.92, task_loss_gen=4.086, contrastive_loss=0, total=6792.33, n_correct=2731.74, ppl=8.78, accuracy=40.218, wps=18593.1, ups=1.37, wpb=13584.7, bsz=465.6, num_updates=15900, lr=0.000112154, gnorm=3.772, clip=4, loss_scale=0.25, train_wall=72, gb_free=6.9, wall=16497
2023-09-06 05:51:01 | INFO | train_inner | epoch 014:    531 / 1191 loss=2.624, trans_loss=5.645, nll_loss=3.126, w2v_ctc_loss=1.102, task_loss=3.227, task_loss_gen=3.983, contrastive_loss=0, total=6768.61, n_correct=2723.96, ppl=8.73, accuracy=40.244, wps=18559.1, ups=1.37, wpb=13537.2, bsz=471.9, num_updates=16000, lr=0.000111803, gnorm=3.562, clip=2, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=16570
2023-09-06 05:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:51:35 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.094 | trans_loss 6.797 | nll_loss 4.571 | w2v_ctc_loss 1.624 | task_loss 11.17 | task_loss_gen 11.62 | contrastive_loss 0 | total 6138.43 | n_correct 2459.29 | ppl 23.76 | accuracy 40.064 | uer 27.171 | wer 28.728 | raw_wer 28.728 | bleu 0.17 | wps 1674.3 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 0.31
2023-09-06 05:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-09-06 05:51:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 05:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 05:51:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 0.17) (writing took 9.014827652019449 seconds)
2023-09-06 05:52:56 | INFO | train_inner | epoch 014:    631 / 1191 loss=2.622, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.08, task_loss=3.155, task_loss_gen=4.195, contrastive_loss=0, total=6766.55, n_correct=2719.13, ppl=8.78, accuracy=40.185, wps=11690.1, ups=0.86, wpb=13533.1, bsz=452.5, num_updates=16100, lr=0.000111456, gnorm=3.275, clip=0, loss_scale=0.25, train_wall=71, gb_free=12.9, wall=16686
2023-09-06 05:54:09 | INFO | train_inner | epoch 014:    731 / 1191 loss=2.643, trans_loss=5.656, nll_loss=3.139, w2v_ctc_loss=1.145, task_loss=3.15, task_loss_gen=4.282, contrastive_loss=0, total=6693.79, n_correct=2681.62, ppl=8.81, accuracy=40.061, wps=18364.4, ups=1.37, wpb=13387.6, bsz=448.6, num_updates=16200, lr=0.000111111, gnorm=4.923, clip=5, loss_scale=0.25, train_wall=72, gb_free=13.4, wall=16759
2023-09-06 05:55:22 | INFO | train_inner | epoch 014:    831 / 1191 loss=2.628, trans_loss=5.651, nll_loss=3.133, w2v_ctc_loss=1.112, task_loss=3.358, task_loss_gen=4.275, contrastive_loss=0, total=6689.02, n_correct=2690.7, ppl=8.77, accuracy=40.226, wps=18434.4, ups=1.38, wpb=13378, bsz=458.4, num_updates=16300, lr=0.00011077, gnorm=3.163, clip=0, loss_scale=0.25, train_wall=72, gb_free=14, wall=16832
2023-09-06 05:56:35 | INFO | train_inner | epoch 014:    931 / 1191 loss=2.624, trans_loss=5.653, nll_loss=3.135, w2v_ctc_loss=1.087, task_loss=3.283, task_loss_gen=4.285, contrastive_loss=0, total=6649.73, n_correct=2668.63, ppl=8.79, accuracy=40.131, wps=18216.7, ups=1.37, wpb=13299.5, bsz=446.5, num_updates=16400, lr=0.000110432, gnorm=3.158, clip=3, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=16905
2023-09-06 05:57:47 | INFO | train_inner | epoch 014:   1031 / 1191 loss=2.616, trans_loss=5.656, nll_loss=3.14, w2v_ctc_loss=1.048, task_loss=3.596, task_loss_gen=4.623, contrastive_loss=0, total=6592.87, n_correct=2644.76, ppl=8.81, accuracy=40.115, wps=18175.8, ups=1.38, wpb=13185.7, bsz=426.6, num_updates=16500, lr=0.000110096, gnorm=2.769, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.5, wall=16977
2023-09-06 05:59:00 | INFO | train_inner | epoch 014:   1131 / 1191 loss=2.595, trans_loss=5.651, nll_loss=3.133, w2v_ctc_loss=1.001, task_loss=3.046, task_loss_gen=3.943, contrastive_loss=0, total=6802.52, n_correct=2739.83, ppl=8.77, accuracy=40.277, wps=18702.6, ups=1.37, wpb=13605, bsz=472.8, num_updates=16600, lr=0.000109764, gnorm=2.639, clip=1, loss_scale=0.25, train_wall=72, gb_free=12.6, wall=17050
2023-09-06 05:59:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:00:17 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.081 | trans_loss 6.788 | nll_loss 4.561 | w2v_ctc_loss 1.6 | task_loss 11.016 | task_loss_gen 11.608 | contrastive_loss 0 | total 6138.43 | n_correct 2471.43 | ppl 23.61 | accuracy 40.262 | uer 26.299 | wer 27.891 | raw_wer 27.891 | bleu 0.31 | wps 1696.1 | wpb 6138.4 | bsz 201.1 | num_updates 16660 | best_bleu 0.31
2023-09-06 06:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16660 updates
2023-09-06 06:00:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 14 @ 16660 updates, score 0.31) (writing took 18.231535727973096 seconds)
2023-09-06 06:00:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-06 06:00:35 | INFO | train | epoch 014 | loss 2.627 | trans_loss 5.652 | nll_loss 3.135 | w2v_ctc_loss 1.097 | task_loss 3.218 | task_loss_gen 4.233 | contrastive_loss 0 | total 6703.69 | n_correct 2692.23 | ppl 8.78 | accuracy 40.16 | wps 16499.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 16660 | lr 0.000109566 | gnorm 3.789 | clip 2.9 | loss_scale 0.25 | train_wall 858 | gb_free 14.3 | wall 17145
2023-09-06 06:00:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:00:35 | INFO | fairseq.trainer | begin training epoch 15
2023-09-06 06:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:01:11 | INFO | train_inner | epoch 015:     40 / 1191 loss=2.598, trans_loss=5.646, nll_loss=3.127, w2v_ctc_loss=1.002, task_loss=3.383, task_loss_gen=4.261, contrastive_loss=0, total=6688.09, n_correct=2686.48, ppl=8.74, accuracy=40.168, wps=10199.1, ups=0.76, wpb=13376.2, bsz=448.7, num_updates=16700, lr=0.000109435, gnorm=2.884, clip=2, loss_scale=0.25, train_wall=71, gb_free=12.1, wall=17181
2023-09-06 06:02:24 | INFO | train_inner | epoch 015:    140 / 1191 loss=2.585, trans_loss=5.64, nll_loss=3.118, w2v_ctc_loss=0.981, task_loss=3.187, task_loss_gen=4.19, contrastive_loss=0, total=6699.56, n_correct=2706.71, ppl=8.68, accuracy=40.401, wps=18556.2, ups=1.38, wpb=13399.1, bsz=451.7, num_updates=16800, lr=0.000109109, gnorm=2.791, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.8, wall=17253
2023-09-06 06:03:36 | INFO | train_inner | epoch 015:    240 / 1191 loss=2.596, trans_loss=5.644, nll_loss=3.123, w2v_ctc_loss=1.003, task_loss=3.038, task_loss_gen=4.196, contrastive_loss=0, total=6739.41, n_correct=2713.16, ppl=8.71, accuracy=40.258, wps=18645.8, ups=1.38, wpb=13478.8, bsz=454.6, num_updates=16900, lr=0.000108786, gnorm=2.262, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.2, wall=17326
2023-09-06 06:04:48 | INFO | train_inner | epoch 015:    340 / 1191 loss=2.596, trans_loss=5.638, nll_loss=3.116, w2v_ctc_loss=1.007, task_loss=3.275, task_loss_gen=4.324, contrastive_loss=0, total=6625.74, n_correct=2671.62, ppl=8.67, accuracy=40.322, wps=18289.9, ups=1.38, wpb=13251.5, bsz=441.8, num_updates=17000, lr=0.000108465, gnorm=1.879, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.5, wall=17398
2023-09-06 06:06:01 | INFO | train_inner | epoch 015:    440 / 1191 loss=2.592, trans_loss=5.642, nll_loss=3.122, w2v_ctc_loss=0.996, task_loss=3.094, task_loss_gen=4.302, contrastive_loss=0, total=6716.18, n_correct=2706.88, ppl=8.7, accuracy=40.304, wps=18441.6, ups=1.37, wpb=13432.4, bsz=452, num_updates=17100, lr=0.000108148, gnorm=1.353, clip=0, loss_scale=0.5, train_wall=72, gb_free=5.8, wall=17471
2023-09-06 06:07:14 | INFO | train_inner | epoch 015:    540 / 1191 loss=2.581, trans_loss=5.635, nll_loss=3.112, w2v_ctc_loss=0.972, task_loss=2.958, task_loss_gen=4.2, contrastive_loss=0, total=6719.43, n_correct=2719.63, ppl=8.65, accuracy=40.474, wps=18409.1, ups=1.37, wpb=13438.9, bsz=464, num_updates=17200, lr=0.000107833, gnorm=1.474, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=17544
2023-09-06 06:08:26 | INFO | train_inner | epoch 015:    640 / 1191 loss=2.594, trans_loss=5.645, nll_loss=3.125, w2v_ctc_loss=0.977, task_loss=3.493, task_loss_gen=4.717, contrastive_loss=0, total=6626.73, n_correct=2664.14, ppl=8.72, accuracy=40.203, wps=18384.4, ups=1.39, wpb=13253.5, bsz=415.7, num_updates=17300, lr=0.000107521, gnorm=1.745, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.1, wall=17616
2023-09-06 06:09:38 | INFO | train_inner | epoch 015:    740 / 1191 loss=2.587, trans_loss=5.633, nll_loss=3.11, w2v_ctc_loss=0.996, task_loss=3.243, task_loss_gen=4.341, contrastive_loss=0, total=6627.23, n_correct=2681.73, ppl=8.64, accuracy=40.465, wps=18341.8, ups=1.38, wpb=13254.5, bsz=450.2, num_updates=17400, lr=0.000107211, gnorm=2.003, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.7, wall=17688
2023-09-06 06:10:52 | INFO | train_inner | epoch 015:    840 / 1191 loss=2.597, trans_loss=5.643, nll_loss=3.123, w2v_ctc_loss=1.003, task_loss=3.155, task_loss_gen=4.253, contrastive_loss=0, total=6711.36, n_correct=2701.81, ppl=8.71, accuracy=40.257, wps=18279.5, ups=1.36, wpb=13422.7, bsz=446.3, num_updates=17500, lr=0.000106904, gnorm=1.747, clip=0, loss_scale=0.5, train_wall=73, gb_free=10.2, wall=17762
2023-09-06 06:12:05 | INFO | train_inner | epoch 015:    940 / 1191 loss=2.572, trans_loss=5.631, nll_loss=3.107, w2v_ctc_loss=0.963, task_loss=2.917, task_loss_gen=3.986, contrastive_loss=0, total=6789.2, n_correct=2757.75, ppl=8.62, accuracy=40.62, wps=18537.5, ups=1.37, wpb=13578.4, bsz=480.3, num_updates=17600, lr=0.0001066, gnorm=1.61, clip=1, loss_scale=0.5, train_wall=73, gb_free=14, wall=17835
2023-09-06 06:13:18 | INFO | train_inner | epoch 015:   1040 / 1191 loss=2.584, trans_loss=5.639, nll_loss=3.117, w2v_ctc_loss=0.98, task_loss=3.015, task_loss_gen=4.269, contrastive_loss=0, total=6692.46, n_correct=2708.17, ppl=8.68, accuracy=40.466, wps=18418.8, ups=1.38, wpb=13384.9, bsz=452.7, num_updates=17700, lr=0.000106299, gnorm=1.642, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=17908
2023-09-06 06:14:31 | INFO | train_inner | epoch 015:   1140 / 1191 loss=2.584, trans_loss=5.642, nll_loss=3.122, w2v_ctc_loss=0.967, task_loss=3.122, task_loss_gen=4.347, contrastive_loss=0, total=6746.33, n_correct=2728.63, ppl=8.71, accuracy=40.446, wps=18392.8, ups=1.36, wpb=13492.7, bsz=445.5, num_updates=17800, lr=0.000106, gnorm=1.616, clip=0, loss_scale=0.5, train_wall=73, gb_free=14.3, wall=17981
2023-09-06 06:15:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:15:42 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 5.09 | trans_loss 6.768 | nll_loss 4.535 | w2v_ctc_loss 1.677 | task_loss 8.946 | task_loss_gen 11.98 | contrastive_loss 0 | total 6138.43 | n_correct 2483.57 | ppl 23.18 | accuracy 40.459 | uer 26.155 | wer 28.074 | raw_wer 28.074 | bleu 0.25 | wps 1649.5 | wpb 6138.4 | bsz 201.1 | num_updates 17851 | best_bleu 0.31
2023-09-06 06:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17851 updates
2023-09-06 06:15:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt
2023-09-06 06:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt
2023-09-06 06:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt (epoch 15 @ 17851 updates, score 0.25) (writing took 9.645971847930923 seconds)
2023-09-06 06:15:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-06 06:15:52 | INFO | train | epoch 015 | loss 2.587 | trans_loss 5.639 | nll_loss 3.118 | w2v_ctc_loss 0.985 | task_loss 3.118 | task_loss_gen 4.247 | contrastive_loss 0 | total 6703.69 | n_correct 2707.58 | ppl 8.68 | accuracy 40.389 | wps 17411 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 17851 | lr 0.000105848 | gnorm 1.831 | clip 0.4 | loss_scale 0.5 | train_wall 858 | gb_free 11.5 | wall 18062
2023-09-06 06:15:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:15:52 | INFO | fairseq.trainer | begin training epoch 16
2023-09-06 06:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:16:35 | INFO | train_inner | epoch 016:     49 / 1191 loss=2.58, trans_loss=5.634, nll_loss=3.111, w2v_ctc_loss=0.969, task_loss=3.046, task_loss_gen=4.157, contrastive_loss=0, total=6660.79, n_correct=2699.18, ppl=8.64, accuracy=40.523, wps=10777.7, ups=0.81, wpb=13321.6, bsz=451.5, num_updates=17900, lr=0.000105703, gnorm=1.477, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.4, wall=18105
2023-09-06 06:17:48 | INFO | train_inner | epoch 016:    149 / 1191 loss=2.575, trans_loss=5.627, nll_loss=3.102, w2v_ctc_loss=0.956, task_loss=3.16, task_loss_gen=4.329, contrastive_loss=0, total=6745.67, n_correct=2739.99, ppl=8.59, accuracy=40.619, wps=18517.7, ups=1.37, wpb=13491.3, bsz=447, num_updates=18000, lr=0.000105409, gnorm=2.092, clip=1, loss_scale=0.5, train_wall=72, gb_free=12.6, wall=18177
2023-09-06 06:17:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:18:24 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 5.076 | trans_loss 6.771 | nll_loss 4.537 | w2v_ctc_loss 1.623 | task_loss 12.674 | task_loss_gen 11.639 | contrastive_loss 0 | total 6138.43 | n_correct 2493.14 | ppl 23.22 | accuracy 40.615 | uer 25.719 | wer 27.367 | raw_wer 27.367 | bleu 0.26 | wps 1508.7 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 0.31
2023-09-06 06:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-09-06 06:18:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 06:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 06:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 0.26) (writing took 8.767071555019356 seconds)
2023-09-06 06:19:46 | INFO | train_inner | epoch 016:    249 / 1191 loss=2.576, trans_loss=5.629, nll_loss=3.104, w2v_ctc_loss=0.959, task_loss=3.24, task_loss_gen=4.303, contrastive_loss=0, total=6687.43, n_correct=2708.79, ppl=8.6, accuracy=40.506, wps=11334.6, ups=0.85, wpb=13374.9, bsz=441.7, num_updates=18100, lr=0.000105118, gnorm=1.605, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.9, wall=18296
2023-09-06 06:20:58 | INFO | train_inner | epoch 016:    349 / 1191 loss=2.57, trans_loss=5.628, nll_loss=3.104, w2v_ctc_loss=0.953, task_loss=3.05, task_loss_gen=4.037, contrastive_loss=0, total=6770.99, n_correct=2752.25, ppl=8.6, accuracy=40.648, wps=18839, ups=1.39, wpb=13542, bsz=463.4, num_updates=18200, lr=0.000104828, gnorm=1.396, clip=1, loss_scale=0.5, train_wall=71, gb_free=13.6, wall=18367
2023-09-06 06:22:10 | INFO | train_inner | epoch 016:    449 / 1191 loss=2.574, trans_loss=5.631, nll_loss=3.107, w2v_ctc_loss=0.951, task_loss=3.059, task_loss_gen=4.165, contrastive_loss=0, total=6692.76, n_correct=2711.26, ppl=8.61, accuracy=40.51, wps=18542.1, ups=1.39, wpb=13385.5, bsz=451.7, num_updates=18300, lr=0.000104542, gnorm=1.612, clip=1, loss_scale=0.5, train_wall=72, gb_free=12.3, wall=18440
2023-09-06 06:23:23 | INFO | train_inner | epoch 016:    549 / 1191 loss=2.57, trans_loss=5.625, nll_loss=3.099, w2v_ctc_loss=0.939, task_loss=3.209, task_loss_gen=4.394, contrastive_loss=0, total=6668.49, n_correct=2699.45, ppl=8.57, accuracy=40.481, wps=18290.7, ups=1.37, wpb=13337, bsz=440.7, num_updates=18400, lr=0.000104257, gnorm=1.896, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=18513
2023-09-06 06:24:36 | INFO | train_inner | epoch 016:    649 / 1191 loss=2.57, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.956, task_loss=3.152, task_loss_gen=4.216, contrastive_loss=0, total=6705.69, n_correct=2731.1, ppl=8.56, accuracy=40.728, wps=18287.8, ups=1.36, wpb=13411.4, bsz=458.3, num_updates=18500, lr=0.000103975, gnorm=1.548, clip=0, loss_scale=0.5, train_wall=73, gb_free=10.5, wall=18586
2023-09-06 06:25:48 | INFO | train_inner | epoch 016:    749 / 1191 loss=2.576, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.963, task_loss=3.099, task_loss_gen=4.381, contrastive_loss=0, total=6640.16, n_correct=2696.17, ppl=8.56, accuracy=40.604, wps=18337.9, ups=1.38, wpb=13280.3, bsz=442.1, num_updates=18600, lr=0.000103695, gnorm=1.716, clip=0, loss_scale=0.5, train_wall=72, gb_free=12, wall=18658
2023-09-06 06:27:01 | INFO | train_inner | epoch 016:    849 / 1191 loss=2.585, trans_loss=5.629, nll_loss=3.104, w2v_ctc_loss=0.994, task_loss=3.048, task_loss_gen=4.393, contrastive_loss=0, total=6703.01, n_correct=2718.58, ppl=8.6, accuracy=40.558, wps=18363.4, ups=1.37, wpb=13406, bsz=444.4, num_updates=18700, lr=0.000103418, gnorm=2.045, clip=3, loss_scale=0.5, train_wall=72, gb_free=14.8, wall=18731
2023-09-06 06:28:14 | INFO | train_inner | epoch 016:    949 / 1191 loss=2.594, trans_loss=5.631, nll_loss=3.108, w2v_ctc_loss=1.027, task_loss=2.722, task_loss_gen=4.189, contrastive_loss=0, total=6726.21, n_correct=2727.7, ppl=8.62, accuracy=40.553, wps=18555.3, ups=1.38, wpb=13452.4, bsz=463.7, num_updates=18800, lr=0.000103142, gnorm=2.99, clip=6, loss_scale=0.5, train_wall=72, gb_free=12.7, wall=18804
2023-09-06 06:29:27 | INFO | train_inner | epoch 016:   1049 / 1191 loss=2.588, trans_loss=5.624, nll_loss=3.097, w2v_ctc_loss=1.02, task_loss=2.779, task_loss_gen=4.286, contrastive_loss=0, total=6699.97, n_correct=2724.97, ppl=8.56, accuracy=40.671, wps=18375.2, ups=1.37, wpb=13399.9, bsz=460.9, num_updates=18900, lr=0.000102869, gnorm=1.451, clip=1, loss_scale=1, train_wall=72, gb_free=14.2, wall=18877
2023-09-06 06:30:40 | INFO | train_inner | epoch 016:   1149 / 1191 loss=2.567, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.96, task_loss=2.492, task_loss_gen=4.213, contrastive_loss=0, total=6782.02, n_correct=2764.31, ppl=8.56, accuracy=40.759, wps=18468.9, ups=1.36, wpb=13564, bsz=474.4, num_updates=19000, lr=0.000102598, gnorm=1.036, clip=0, loss_scale=1, train_wall=73, gb_free=12.8, wall=18950
2023-09-06 06:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:31:45 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 5.08 | trans_loss 6.767 | nll_loss 4.537 | w2v_ctc_loss 1.643 | task_loss 9.738 | task_loss_gen 12.02 | contrastive_loss 0 | total 6138.43 | n_correct 2490.14 | ppl 23.22 | accuracy 40.566 | uer 26.529 | wer 28.141 | raw_wer 28.141 | bleu 0.34 | wps 1624.7 | wpb 6138.4 | bsz 201.1 | num_updates 19042 | best_bleu 0.34
2023-09-06 06:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 19042 updates
2023-09-06 06:31:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 16 @ 19042 updates, score 0.34) (writing took 13.521773665910587 seconds)
2023-09-06 06:31:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-06 06:31:59 | INFO | train | epoch 016 | loss 2.577 | trans_loss 5.627 | nll_loss 3.102 | w2v_ctc_loss 0.971 | task_loss 3.004 | task_loss_gen 4.281 | contrastive_loss 0 | total 6703.69 | n_correct 2721.95 | ppl 8.58 | accuracy 40.604 | wps 16518.8 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 19042 | lr 0.000102485 | gnorm 1.785 | clip 1.3 | loss_scale 1 | train_wall 858 | gb_free 13.6 | wall 19029
2023-09-06 06:31:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:31:59 | INFO | fairseq.trainer | begin training epoch 17
2023-09-06 06:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:32:48 | INFO | train_inner | epoch 017:     58 / 1191 loss=2.584, trans_loss=5.62, nll_loss=3.092, w2v_ctc_loss=1.002, task_loss=2.827, task_loss_gen=4.52, contrastive_loss=0, total=6627.43, n_correct=2697.89, ppl=8.53, accuracy=40.708, wps=10357.6, ups=0.78, wpb=13254.9, bsz=443.1, num_updates=19100, lr=0.000102329, gnorm=2.198, clip=3, loss_scale=1, train_wall=72, gb_free=14.2, wall=19078
2023-09-06 06:34:01 | INFO | train_inner | epoch 017:    158 / 1191 loss=2.579, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=0.998, task_loss=2.763, task_loss_gen=4.394, contrastive_loss=0, total=6710.52, n_correct=2741.06, ppl=8.48, accuracy=40.847, wps=18521.7, ups=1.38, wpb=13421, bsz=454.4, num_updates=19200, lr=0.000102062, gnorm=1.306, clip=1, loss_scale=1, train_wall=72, gb_free=14, wall=19151
2023-09-06 06:35:13 | INFO | train_inner | epoch 017:    258 / 1191 loss=2.578, trans_loss=5.611, nll_loss=3.081, w2v_ctc_loss=0.999, task_loss=2.772, task_loss_gen=4.161, contrastive_loss=0, total=6792.28, n_correct=2775.57, ppl=8.46, accuracy=40.864, wps=18759.6, ups=1.38, wpb=13584.6, bsz=466.5, num_updates=19300, lr=0.000101797, gnorm=1.987, clip=2, loss_scale=1, train_wall=72, gb_free=13.6, wall=19223
2023-09-06 06:36:26 | INFO | train_inner | epoch 017:    358 / 1191 loss=2.577, trans_loss=5.619, nll_loss=3.092, w2v_ctc_loss=0.977, task_loss=3.175, task_loss_gen=4.369, contrastive_loss=0, total=6640.64, n_correct=2704.12, ppl=8.53, accuracy=40.721, wps=18286, ups=1.38, wpb=13281.3, bsz=444.5, num_updates=19400, lr=0.000101535, gnorm=1.159, clip=0, loss_scale=1, train_wall=72, gb_free=11.8, wall=19296
2023-09-06 06:37:38 | INFO | train_inner | epoch 017:    458 / 1191 loss=2.567, trans_loss=5.614, nll_loss=3.085, w2v_ctc_loss=0.95, task_loss=3.221, task_loss_gen=4.338, contrastive_loss=0, total=6716.56, n_correct=2739.63, ppl=8.49, accuracy=40.789, wps=18563.4, ups=1.38, wpb=13433.1, bsz=446.4, num_updates=19500, lr=0.000101274, gnorm=1.068, clip=0, loss_scale=1, train_wall=72, gb_free=14.5, wall=19368
2023-09-06 06:38:51 | INFO | train_inner | epoch 017:    558 / 1191 loss=2.575, trans_loss=5.621, nll_loss=3.094, w2v_ctc_loss=0.963, task_loss=3.092, task_loss_gen=4.431, contrastive_loss=0, total=6670.63, n_correct=2711.67, ppl=8.54, accuracy=40.651, wps=18336.9, ups=1.37, wpb=13341.3, bsz=439.3, num_updates=19600, lr=0.000101015, gnorm=1.255, clip=0, loss_scale=1, train_wall=72, gb_free=14.1, wall=19441
2023-09-06 06:40:03 | INFO | train_inner | epoch 017:    658 / 1191 loss=2.568, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=0.964, task_loss=2.799, task_loss_gen=4.229, contrastive_loss=0, total=6688.85, n_correct=2730.86, ppl=8.47, accuracy=40.827, wps=18581.8, ups=1.39, wpb=13377.7, bsz=461.1, num_updates=19700, lr=0.000100759, gnorm=1.168, clip=0, loss_scale=1, train_wall=71, gb_free=12.8, wall=19513
2023-09-06 06:41:15 | INFO | train_inner | epoch 017:    758 / 1191 loss=2.573, trans_loss=5.625, nll_loss=3.099, w2v_ctc_loss=0.942, task_loss=3.215, task_loss_gen=4.611, contrastive_loss=0, total=6639.61, n_correct=2688.8, ppl=8.57, accuracy=40.496, wps=18325, ups=1.38, wpb=13279.2, bsz=425.8, num_updates=19800, lr=0.000100504, gnorm=1.034, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=19585
2023-09-06 06:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 06:42:29 | INFO | train_inner | epoch 017:    859 / 1191 loss=2.573, trans_loss=5.615, nll_loss=3.087, w2v_ctc_loss=0.967, task_loss=3.031, task_loss_gen=4.594, contrastive_loss=0, total=6638.86, n_correct=2708.29, ppl=8.5, accuracy=40.795, wps=18071, ups=1.36, wpb=13277.7, bsz=442.3, num_updates=19900, lr=0.000100251, gnorm=2.172, clip=3, loss_scale=0.5, train_wall=73, gb_free=14.1, wall=19659
2023-09-06 06:43:41 | INFO | train_inner | epoch 017:    959 / 1191 loss=2.573, trans_loss=5.611, nll_loss=3.082, w2v_ctc_loss=1, task_loss=2.695, task_loss_gen=3.796, contrastive_loss=0, total=6802.45, n_correct=2784.65, ppl=8.47, accuracy=40.936, wps=18786.2, ups=1.38, wpb=13604.9, bsz=496.6, num_updates=20000, lr=0.0001, gnorm=3.958, clip=7, loss_scale=0.5, train_wall=72, gb_free=14.4, wall=19731
2023-09-06 06:43:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:44:15 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.071 | trans_loss 6.765 | nll_loss 4.531 | w2v_ctc_loss 1.62 | task_loss 9.847 | task_loss_gen 12.261 | contrastive_loss 0 | total 6138.43 | n_correct 2493.71 | ppl 23.12 | accuracy 40.625 | uer 27.059 | wer 28.698 | raw_wer 28.698 | bleu 0.23 | wps 1678.9 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 0.34
2023-09-06 06:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-09-06 06:44:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 06:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 06:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 0.23) (writing took 10.74252112605609 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 06:45:39 | INFO | train_inner | epoch 017:   1059 / 1191 loss=2.589, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=1.031, task_loss=3.007, task_loss_gen=4.337, contrastive_loss=0, total=6661.9, n_correct=2719.45, ppl=8.47, accuracy=40.821, wps=11364.2, ups=0.85, wpb=13323.8, bsz=443.5, num_updates=20100, lr=9.97509e-05, gnorm=3.101, clip=4, loss_scale=0.5, train_wall=72, gb_free=14.7, wall=19848
2023-09-06 06:46:51 | INFO | train_inner | epoch 017:   1159 / 1191 loss=2.589, trans_loss=5.615, nll_loss=3.087, w2v_ctc_loss=1.028, task_loss=3.075, task_loss_gen=4.285, contrastive_loss=0, total=6784.06, n_correct=2769.59, ppl=8.5, accuracy=40.825, wps=18647.2, ups=1.37, wpb=13568.1, bsz=456.6, num_updates=20200, lr=9.95037e-05, gnorm=2.605, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.5, wall=19921
2023-09-06 06:47:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
2023-09-06 06:47:50 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.075 | trans_loss 6.757 | nll_loss 4.523 | w2v_ctc_loss 1.65 | task_loss 23.174 | task_loss_gen 14.443 | contrastive_loss 0 | total 6138.43 | n_correct 2494.57 | ppl 22.99 | accuracy 40.639 | uer 26.101 | wer 27.672 | raw_wer 27.672 | bleu 0.24 | wps 1560.3 | wpb 6138.4 | bsz 201.1 | num_updates 20232 | best_bleu 0.34
2023-09-06 06:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20232 updates
2023-09-06 06:47:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt
2023-09-06 06:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt
2023-09-06 06:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt (epoch 17 @ 20232 updates, score 0.24) (writing took 7.84795209497679 seconds)
2023-09-06 06:47:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-06 06:47:58 | INFO | train | epoch 017 | loss 2.577 | trans_loss 5.616 | nll_loss 3.087 | w2v_ctc_loss 0.986 | task_loss 2.969 | task_loss_gen 4.318 | contrastive_loss 0 | total 6703.76 | n_correct 2733.59 | ppl 8.5 | accuracy 40.777 | wps 16625.3 | ups 1.24 | wpb 13407.5 | bsz 452.2 | num_updates 20232 | lr 9.9425e-05 | gnorm 1.923 | clip 1.8 | loss_scale 0.5 | train_wall 856 | gb_free 14.2 | wall 19988
2023-09-06 06:47:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:47:59 | INFO | fairseq.trainer | begin training epoch 18
2023-09-06 06:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:48:55 | INFO | train_inner | epoch 018:     68 / 1191 loss=2.573, trans_loss=5.607, nll_loss=3.077, w2v_ctc_loss=0.983, task_loss=3.06, task_loss_gen=4.135, contrastive_loss=0, total=6778.58, n_correct=2772.18, ppl=8.44, accuracy=40.896, wps=10946.6, ups=0.81, wpb=13557.2, bsz=458.2, num_updates=20300, lr=9.92583e-05, gnorm=2.468, clip=1, loss_scale=0.5, train_wall=71, gb_free=14.3, wall=20045
2023-09-06 06:50:08 | INFO | train_inner | epoch 018:    168 / 1191 loss=2.584, trans_loss=5.611, nll_loss=3.081, w2v_ctc_loss=1.002, task_loss=3.724, task_loss_gen=4.696, contrastive_loss=0, total=6623.23, n_correct=2697.51, ppl=8.46, accuracy=40.728, wps=18163.6, ups=1.37, wpb=13246.5, bsz=419.3, num_updates=20400, lr=9.90148e-05, gnorm=2.53, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=20118
2023-09-06 06:51:21 | INFO | train_inner | epoch 018:    268 / 1191 loss=2.581, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=1.003, task_loss=3.006, task_loss_gen=4.554, contrastive_loss=0, total=6620.23, n_correct=2700.63, ppl=8.47, accuracy=40.794, wps=18074.4, ups=1.37, wpb=13240.5, bsz=447.8, num_updates=20500, lr=9.8773e-05, gnorm=2.609, clip=1, loss_scale=0.5, train_wall=73, gb_free=12.7, wall=20191
2023-09-06 06:52:34 | INFO | train_inner | epoch 018:    368 / 1191 loss=2.583, trans_loss=5.606, nll_loss=3.075, w2v_ctc_loss=1.028, task_loss=2.768, task_loss_gen=4.146, contrastive_loss=0, total=6770.44, n_correct=2774.31, ppl=8.43, accuracy=40.977, wps=18580.8, ups=1.37, wpb=13540.9, bsz=469, num_updates=20600, lr=9.85329e-05, gnorm=2.543, clip=3, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=20264
2023-09-06 06:53:46 | INFO | train_inner | epoch 018:    468 / 1191 loss=2.607, trans_loss=5.614, nll_loss=3.085, w2v_ctc_loss=1.091, task_loss=3.013, task_loss_gen=4.325, contrastive_loss=0, total=6684.28, n_correct=2723.96, ppl=8.49, accuracy=40.752, wps=18505.6, ups=1.38, wpb=13368.6, bsz=449.9, num_updates=20700, lr=9.82946e-05, gnorm=2.791, clip=3, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=20336
2023-09-06 06:54:59 | INFO | train_inner | epoch 018:    568 / 1191 loss=2.588, trans_loss=5.608, nll_loss=3.078, w2v_ctc_loss=1.043, task_loss=2.812, task_loss_gen=3.98, contrastive_loss=0, total=6821.08, n_correct=2790.59, ppl=8.44, accuracy=40.911, wps=18868, ups=1.38, wpb=13642.2, bsz=478.3, num_updates=20800, lr=9.80581e-05, gnorm=2.116, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.9, wall=20409
2023-09-06 06:56:11 | INFO | train_inner | epoch 018:    668 / 1191 loss=2.602, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=1.059, task_loss=3.086, task_loss_gen=4.674, contrastive_loss=0, total=6588.48, n_correct=2683.32, ppl=8.48, accuracy=40.727, wps=18338.3, ups=1.39, wpb=13177, bsz=429.5, num_updates=20900, lr=9.78232e-05, gnorm=2.81, clip=3, loss_scale=0.5, train_wall=71, gb_free=11, wall=20480
2023-09-06 06:57:24 | INFO | train_inner | epoch 018:    768 / 1191 loss=2.576, trans_loss=5.612, nll_loss=3.082, w2v_ctc_loss=1.001, task_loss=2.911, task_loss_gen=4.069, contrastive_loss=0, total=6821.72, n_correct=2788.83, ppl=8.47, accuracy=40.882, wps=18609.1, ups=1.36, wpb=13643.4, bsz=469.2, num_updates=21000, lr=9.759e-05, gnorm=1.742, clip=1, loss_scale=0.5, train_wall=73, gb_free=12.7, wall=20554
2023-09-06 06:58:37 | INFO | train_inner | epoch 018:    868 / 1191 loss=2.577, trans_loss=5.612, nll_loss=3.082, w2v_ctc_loss=0.993, task_loss=3.13, task_loss_gen=4.351, contrastive_loss=0, total=6705.27, n_correct=2739.14, ppl=8.47, accuracy=40.851, wps=18353.6, ups=1.37, wpb=13410.5, bsz=452.9, num_updates=21100, lr=9.73585e-05, gnorm=2.192, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.1, wall=20627
2023-09-06 06:59:49 | INFO | train_inner | epoch 018:    968 / 1191 loss=2.562, trans_loss=5.608, nll_loss=3.077, w2v_ctc_loss=0.952, task_loss=2.889, task_loss_gen=4.117, contrastive_loss=0, total=6746.67, n_correct=2762.49, ppl=8.44, accuracy=40.946, wps=18656.2, ups=1.38, wpb=13493.3, bsz=463.4, num_updates=21200, lr=9.71286e-05, gnorm=1.225, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.4, wall=20699
2023-09-06 07:01:01 | INFO | train_inner | epoch 018:   1068 / 1191 loss=2.564, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=0.942, task_loss=3.113, task_loss_gen=4.48, contrastive_loss=0, total=6593.82, n_correct=2695.05, ppl=8.48, accuracy=40.872, wps=18424.8, ups=1.4, wpb=13187.6, bsz=430.3, num_updates=21300, lr=9.69003e-05, gnorm=1.495, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.2, wall=20771
2023-09-06 07:02:14 | INFO | train_inner | epoch 018:   1168 / 1191 loss=2.548, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.914, task_loss=2.948, task_loss_gen=4.236, contrastive_loss=0, total=6737.04, n_correct=2765.41, ppl=8.42, accuracy=41.048, wps=18496.1, ups=1.37, wpb=13474.1, bsz=461.3, num_updates=21400, lr=9.66736e-05, gnorm=1.268, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=20844
2023-09-06 07:02:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:03:05 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 5.014 | trans_loss 6.746 | nll_loss 4.505 | w2v_ctc_loss 1.472 | task_loss 10.43 | task_loss_gen 11.782 | contrastive_loss 0 | total 6138.43 | n_correct 2509.86 | ppl 22.7 | accuracy 40.888 | uer 24.194 | wer 25.675 | raw_wer 25.675 | bleu 0.26 | wps 1599.4 | wpb 6138.4 | bsz 201.1 | num_updates 21423 | best_bleu 0.34
2023-09-06 07:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21423 updates
2023-09-06 07:03:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt
2023-09-06 07:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt
2023-09-06 07:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt (epoch 18 @ 21423 updates, score 0.26) (writing took 8.109685115050524 seconds)
2023-09-06 07:03:14 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-06 07:03:14 | INFO | train | epoch 018 | loss 2.578 | trans_loss 5.61 | nll_loss 3.08 | w2v_ctc_loss 0.999 | task_loss 3.031 | task_loss_gen 4.304 | contrastive_loss 0 | total 6703.69 | n_correct 2739.91 | ppl 8.46 | accuracy 40.872 | wps 17441.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 21423 | lr 9.66217e-05 | gnorm 2.104 | clip 1.3 | loss_scale 0.5 | train_wall 857 | gb_free 13.8 | wall 20904
2023-09-06 07:03:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:03:14 | INFO | fairseq.trainer | begin training epoch 19
2023-09-06 07:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:04:18 | INFO | train_inner | epoch 019:     77 / 1191 loss=2.553, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.91, task_loss=3.224, task_loss_gen=4.514, contrastive_loss=0, total=6595.79, n_correct=2695.35, ppl=8.42, accuracy=40.865, wps=10583.1, ups=0.8, wpb=13191.6, bsz=428, num_updates=21500, lr=9.64486e-05, gnorm=1.255, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.4, wall=20968
2023-09-06 07:05:31 | INFO | train_inner | epoch 019:    177 / 1191 loss=2.551, trans_loss=5.602, nll_loss=3.069, w2v_ctc_loss=0.916, task_loss=3.053, task_loss_gen=4.345, contrastive_loss=0, total=6660.08, n_correct=2730.11, ppl=8.39, accuracy=40.992, wps=18416.2, ups=1.38, wpb=13320.2, bsz=442, num_updates=21600, lr=9.6225e-05, gnorm=1.438, clip=0, loss_scale=0.5, train_wall=72, gb_free=11, wall=21041
2023-09-06 07:06:44 | INFO | train_inner | epoch 019:    277 / 1191 loss=2.54, trans_loss=5.597, nll_loss=3.061, w2v_ctc_loss=0.897, task_loss=2.899, task_loss_gen=4.023, contrastive_loss=0, total=6784.94, n_correct=2790.84, ppl=8.35, accuracy=41.133, wps=18619.8, ups=1.37, wpb=13569.9, bsz=465.1, num_updates=21700, lr=9.60031e-05, gnorm=1.327, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.8, wall=21113
2023-09-06 07:07:56 | INFO | train_inner | epoch 019:    377 / 1191 loss=2.541, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.886, task_loss=2.947, task_loss_gen=4.161, contrastive_loss=0, total=6697.58, n_correct=2743.48, ppl=8.42, accuracy=40.962, wps=18628, ups=1.39, wpb=13395.2, bsz=449.9, num_updates=21800, lr=9.57826e-05, gnorm=1.163, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.7, wall=21185
2023-09-06 07:09:08 | INFO | train_inner | epoch 019:    477 / 1191 loss=2.543, trans_loss=5.601, nll_loss=3.068, w2v_ctc_loss=0.907, task_loss=3.073, task_loss_gen=4.169, contrastive_loss=0, total=6742.97, n_correct=2774.05, ppl=8.38, accuracy=41.14, wps=18565.1, ups=1.38, wpb=13485.9, bsz=467, num_updates=21900, lr=9.55637e-05, gnorm=1.335, clip=0, loss_scale=1, train_wall=72, gb_free=8.9, wall=21258
2023-09-06 07:10:21 | INFO | train_inner | epoch 019:    577 / 1191 loss=2.534, trans_loss=5.601, nll_loss=3.069, w2v_ctc_loss=0.882, task_loss=3.09, task_loss_gen=4.159, contrastive_loss=0, total=6787.18, n_correct=2787.44, ppl=8.39, accuracy=41.069, wps=18616.9, ups=1.37, wpb=13574.4, bsz=467.7, num_updates=22000, lr=9.53463e-05, gnorm=1.291, clip=0, loss_scale=1, train_wall=72, gb_free=13, wall=21331
2023-09-06 07:10:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:10:56 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 5.013 | trans_loss 6.739 | nll_loss 4.499 | w2v_ctc_loss 1.482 | task_loss 11.987 | task_loss_gen 11.848 | contrastive_loss 0 | total 6138.43 | n_correct 2513.14 | ppl 22.61 | accuracy 40.941 | uer 23.825 | wer 25.218 | raw_wer 25.218 | bleu 0.36 | wps 1591.9 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 0.36
2023-09-06 07:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-09-06 07:10:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 07:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 07:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 0.36) (writing took 13.556856640032493 seconds)
2023-09-06 07:12:22 | INFO | train_inner | epoch 019:    677 / 1191 loss=2.539, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.895, task_loss=3.128, task_loss_gen=4.336, contrastive_loss=0, total=6625.21, n_correct=2726.18, ppl=8.32, accuracy=41.149, wps=10943, ups=0.83, wpb=13250.4, bsz=449.1, num_updates=22100, lr=9.51303e-05, gnorm=1.197, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=21452
2023-09-06 07:13:35 | INFO | train_inner | epoch 019:    777 / 1191 loss=2.545, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.918, task_loss=3.229, task_loss_gen=4.132, contrastive_loss=0, total=6792, n_correct=2792.91, ppl=8.32, accuracy=41.121, wps=18732.1, ups=1.38, wpb=13584, bsz=466.9, num_updates=22200, lr=9.49158e-05, gnorm=1.151, clip=0, loss_scale=1, train_wall=72, gb_free=9.9, wall=21525
2023-09-06 07:14:47 | INFO | train_inner | epoch 019:    877 / 1191 loss=2.558, trans_loss=5.597, nll_loss=3.064, w2v_ctc_loss=0.94, task_loss=3.143, task_loss_gen=4.507, contrastive_loss=0, total=6620.15, n_correct=2714.44, ppl=8.36, accuracy=41.003, wps=18232.6, ups=1.38, wpb=13240.3, bsz=439.6, num_updates=22300, lr=9.47027e-05, gnorm=1.166, clip=0, loss_scale=1, train_wall=72, gb_free=12.2, wall=21597
2023-09-06 07:16:00 | INFO | train_inner | epoch 019:    977 / 1191 loss=2.553, trans_loss=5.593, nll_loss=3.058, w2v_ctc_loss=0.932, task_loss=2.964, task_loss_gen=4.607, contrastive_loss=0, total=6616.49, n_correct=2718.25, ppl=8.33, accuracy=41.083, wps=18305.8, ups=1.38, wpb=13233, bsz=435.6, num_updates=22400, lr=9.44911e-05, gnorm=1.249, clip=0, loss_scale=1, train_wall=72, gb_free=14.2, wall=21669
2023-09-06 07:17:12 | INFO | train_inner | epoch 019:   1077 / 1191 loss=2.549, trans_loss=5.599, nll_loss=3.066, w2v_ctc_loss=0.915, task_loss=2.974, task_loss_gen=4.284, contrastive_loss=0, total=6732.97, n_correct=2764.36, ppl=8.37, accuracy=41.057, wps=18599.2, ups=1.38, wpb=13465.9, bsz=454.1, num_updates=22500, lr=9.42809e-05, gnorm=1.356, clip=0, loss_scale=1, train_wall=72, gb_free=12.9, wall=21742
2023-09-06 07:18:26 | INFO | train_inner | epoch 019:   1177 / 1191 loss=2.542, trans_loss=5.601, nll_loss=3.068, w2v_ctc_loss=0.903, task_loss=2.837, task_loss_gen=4.185, contrastive_loss=0, total=6792.13, n_correct=2793.12, ppl=8.39, accuracy=41.123, wps=18376.2, ups=1.35, wpb=13584.3, bsz=462.7, num_updates=22600, lr=9.40721e-05, gnorm=0.884, clip=0, loss_scale=1, train_wall=73, gb_free=13.8, wall=21816
2023-09-06 07:18:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:19:12 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 5.015 | trans_loss 6.736 | nll_loss 4.495 | w2v_ctc_loss 1.498 | task_loss 15.185 | task_loss_gen 12.217 | contrastive_loss 0 | total 6138.43 | n_correct 2513.29 | ppl 22.55 | accuracy 40.943 | uer 24.451 | wer 26.177 | raw_wer 26.177 | bleu 0.46 | wps 1516 | wpb 6138.4 | bsz 201.1 | num_updates 22614 | best_bleu 0.46
2023-09-06 07:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22614 updates
2023-09-06 07:19:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 07:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 07:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 19 @ 22614 updates, score 0.46) (writing took 12.896276931045577 seconds)
2023-09-06 07:19:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-06 07:19:25 | INFO | train | epoch 019 | loss 2.545 | trans_loss 5.599 | nll_loss 3.065 | w2v_ctc_loss 0.909 | task_loss 3.049 | task_loss_gen 4.289 | contrastive_loss 0 | total 6703.69 | n_correct 2752.68 | ppl 8.37 | accuracy 41.062 | wps 16439.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 22614 | lr 9.4043e-05 | gnorm 1.232 | clip 0 | loss_scale 1 | train_wall 858 | gb_free 14.3 | wall 21875
2023-09-06 07:19:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:19:25 | INFO | fairseq.trainer | begin training epoch 20
2023-09-06 07:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:20:35 | INFO | train_inner | epoch 020:     86 / 1191 loss=2.534, trans_loss=5.582, nll_loss=3.044, w2v_ctc_loss=0.887, task_loss=3.324, task_loss_gen=4.431, contrastive_loss=0, total=6677.37, n_correct=2759.26, ppl=8.25, accuracy=41.323, wps=10327, ups=0.77, wpb=13354.7, bsz=443.1, num_updates=22700, lr=9.38647e-05, gnorm=0.894, clip=0, loss_scale=1, train_wall=72, gb_free=13.7, wall=21945
2023-09-06 07:21:47 | INFO | train_inner | epoch 020:    186 / 1191 loss=2.535, trans_loss=5.583, nll_loss=3.046, w2v_ctc_loss=0.887, task_loss=3.129, task_loss_gen=4.453, contrastive_loss=0, total=6595.04, n_correct=2715.04, ppl=8.26, accuracy=41.168, wps=18383.4, ups=1.39, wpb=13190.1, bsz=437.3, num_updates=22800, lr=9.36586e-05, gnorm=1.086, clip=0, loss_scale=1, train_wall=71, gb_free=13.6, wall=22017
2023-09-06 07:22:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 07:23:01 | INFO | train_inner | epoch 020:    287 / 1191 loss=2.557, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.957, task_loss=2.988, task_loss_gen=4.247, contrastive_loss=0, total=6774.09, n_correct=2792.5, ppl=8.32, accuracy=41.223, wps=18436.8, ups=1.36, wpb=13548.2, bsz=460.8, num_updates=22900, lr=9.34539e-05, gnorm=2.336, clip=4, loss_scale=0.5, train_wall=73, gb_free=13.2, wall=22090
2023-09-06 07:24:12 | INFO | train_inner | epoch 020:    387 / 1191 loss=2.552, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.948, task_loss=3.025, task_loss_gen=4.01, contrastive_loss=0, total=6796.65, n_correct=2804.85, ppl=8.32, accuracy=41.268, wps=18928.4, ups=1.39, wpb=13593.3, bsz=467.1, num_updates=23000, lr=9.32505e-05, gnorm=2.143, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.1, wall=22162
2023-09-06 07:25:25 | INFO | train_inner | epoch 020:    487 / 1191 loss=2.552, trans_loss=5.589, nll_loss=3.053, w2v_ctc_loss=0.938, task_loss=3.156, task_loss_gen=4.302, contrastive_loss=0, total=6661.06, n_correct=2737.71, ppl=8.3, accuracy=41.1, wps=18408.6, ups=1.38, wpb=13322.1, bsz=441.8, num_updates=23100, lr=9.30484e-05, gnorm=2.075, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.5, wall=22235
2023-09-06 07:26:37 | INFO | train_inner | epoch 020:    587 / 1191 loss=2.543, trans_loss=5.583, nll_loss=3.045, w2v_ctc_loss=0.926, task_loss=3.188, task_loss_gen=4.241, contrastive_loss=0, total=6667.89, n_correct=2757.84, ppl=8.25, accuracy=41.36, wps=18403, ups=1.38, wpb=13335.8, bsz=453.6, num_updates=23200, lr=9.28477e-05, gnorm=2.151, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=22307
2023-09-06 07:27:49 | INFO | train_inner | epoch 020:    687 / 1191 loss=2.538, trans_loss=5.587, nll_loss=3.05, w2v_ctc_loss=0.913, task_loss=2.947, task_loss_gen=4.1, contrastive_loss=0, total=6676.16, n_correct=2756.01, ppl=8.28, accuracy=41.281, wps=18507.1, ups=1.39, wpb=13352.3, bsz=462.9, num_updates=23300, lr=9.26482e-05, gnorm=2.041, clip=2, loss_scale=0.5, train_wall=72, gb_free=12.8, wall=22379
2023-09-06 07:29:01 | INFO | train_inner | epoch 020:    787 / 1191 loss=2.544, trans_loss=5.591, nll_loss=3.056, w2v_ctc_loss=0.922, task_loss=2.862, task_loss_gen=4.027, contrastive_loss=0, total=6770.38, n_correct=2795.61, ppl=8.31, accuracy=41.292, wps=18824.4, ups=1.39, wpb=13540.8, bsz=460.7, num_updates=23400, lr=9.245e-05, gnorm=1.5, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.1, wall=22451
2023-09-06 07:30:14 | INFO | train_inner | epoch 020:    887 / 1191 loss=2.552, trans_loss=5.597, nll_loss=3.062, w2v_ctc_loss=0.93, task_loss=3.125, task_loss_gen=4.344, contrastive_loss=0, total=6728.68, n_correct=2763.65, ppl=8.35, accuracy=41.073, wps=18593.3, ups=1.38, wpb=13457.4, bsz=446.4, num_updates=23500, lr=9.22531e-05, gnorm=1.989, clip=1, loss_scale=0.5, train_wall=72, gb_free=8.7, wall=22524
2023-09-06 07:31:27 | INFO | train_inner | epoch 020:    987 / 1191 loss=2.553, trans_loss=5.595, nll_loss=3.061, w2v_ctc_loss=0.928, task_loss=3.552, task_loss_gen=4.587, contrastive_loss=0, total=6655.57, n_correct=2732.94, ppl=8.35, accuracy=41.062, wps=18240.1, ups=1.37, wpb=13311.1, bsz=431.8, num_updates=23600, lr=9.20575e-05, gnorm=2.066, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=22596
2023-09-06 07:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 07:32:40 | INFO | train_inner | epoch 020:   1088 / 1191 loss=2.559, trans_loss=5.601, nll_loss=3.067, w2v_ctc_loss=0.958, task_loss=2.882, task_loss_gen=4.193, contrastive_loss=0, total=6759.71, n_correct=2780.13, ppl=8.38, accuracy=41.128, wps=18472.2, ups=1.37, wpb=13519.4, bsz=458.8, num_updates=23700, lr=9.1863e-05, gnorm=4.253, clip=6, loss_scale=0.25, train_wall=72, gb_free=12.8, wall=22670
2023-09-06 07:33:53 | INFO | train_inner | epoch 020:   1188 / 1191 loss=2.554, trans_loss=5.605, nll_loss=3.072, w2v_ctc_loss=0.944, task_loss=3.502, task_loss_gen=4.189, contrastive_loss=0, total=6696.4, n_correct=2748.45, ppl=8.41, accuracy=41.044, wps=18305.2, ups=1.37, wpb=13392.8, bsz=460.1, num_updates=23800, lr=9.16698e-05, gnorm=3.711, clip=0, loss_scale=0.25, train_wall=73, gb_free=14.1, wall=22743
2023-09-06 07:33:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:34:29 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 5.011 | trans_loss 6.73 | nll_loss 4.481 | w2v_ctc_loss 1.5 | task_loss 21.165 | task_loss_gen 13.356 | contrastive_loss 0 | total 6138.43 | n_correct 2522.86 | ppl 22.34 | accuracy 41.099 | uer 24.248 | wer 25.958 | raw_wer 25.958 | bleu 0.25 | wps 1626.5 | wpb 6138.4 | bsz 201.1 | num_updates 23803 | best_bleu 0.46
2023-09-06 07:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23803 updates
2023-09-06 07:34:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt
2023-09-06 07:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt
2023-09-06 07:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt (epoch 20 @ 23803 updates, score 0.25) (writing took 11.4122632490471 seconds)
2023-09-06 07:34:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-06 07:34:41 | INFO | train | epoch 020 | loss 2.548 | trans_loss 5.591 | nll_loss 3.056 | w2v_ctc_loss 0.929 | task_loss 3.14 | task_loss_gen 4.254 | contrastive_loss 0 | total 6703.9 | n_correct 2761.63 | ppl 8.31 | accuracy 41.194 | wps 17410.3 | ups 1.3 | wpb 13407.8 | bsz 452.3 | num_updates 23803 | lr 9.16641e-05 | gnorm 2.208 | clip 1.2 | loss_scale 0.25 | train_wall 855 | gb_free 15.1 | wall 22791
2023-09-06 07:34:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:34:41 | INFO | fairseq.trainer | begin training epoch 21
2023-09-06 07:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:35:58 | INFO | train_inner | epoch 021:     97 / 1191 loss=2.524, trans_loss=5.575, nll_loss=3.034, w2v_ctc_loss=0.879, task_loss=3.307, task_loss_gen=4.004, contrastive_loss=0, total=6731.66, n_correct=2798.12, ppl=8.19, accuracy=41.567, wps=10739, ups=0.8, wpb=13463.3, bsz=466.6, num_updates=23900, lr=9.14779e-05, gnorm=2.956, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.7, wall=22868
2023-09-06 07:37:10 | INFO | train_inner | epoch 021:    197 / 1191 loss=2.524, trans_loss=5.577, nll_loss=3.037, w2v_ctc_loss=0.88, task_loss=3.067, task_loss_gen=3.868, contrastive_loss=0, total=6811.2, n_correct=2826.45, ppl=8.21, accuracy=41.497, wps=18909.7, ups=1.39, wpb=13622.4, bsz=476.2, num_updates=24000, lr=9.12871e-05, gnorm=2.555, clip=0, loss_scale=0.25, train_wall=71, gb_free=14, wall=22940
2023-09-06 07:37:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:37:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 5.018 | trans_loss 6.744 | nll_loss 4.498 | w2v_ctc_loss 1.489 | task_loss 12.654 | task_loss_gen 11.615 | contrastive_loss 0 | total 6138.43 | n_correct 2515 | ppl 22.6 | accuracy 40.971 | uer 24.606 | wer 26.326 | raw_wer 26.326 | bleu 0.27 | wps 1687.1 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 0.46
2023-09-06 07:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-09-06 07:37:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 07:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 07:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 0.27) (writing took 10.762539027957246 seconds)
2023-09-06 07:39:07 | INFO | train_inner | epoch 021:    297 / 1191 loss=2.545, trans_loss=5.59, nll_loss=3.054, w2v_ctc_loss=0.908, task_loss=3.339, task_loss_gen=4.352, contrastive_loss=0, total=6641.5, n_correct=2730.15, ppl=8.3, accuracy=41.107, wps=11389.1, ups=0.86, wpb=13283, bsz=437.2, num_updates=24100, lr=9.10975e-05, gnorm=2.637, clip=0, loss_scale=0.25, train_wall=71, gb_free=10, wall=23057
2023-09-06 07:40:19 | INFO | train_inner | epoch 021:    397 / 1191 loss=2.548, trans_loss=5.591, nll_loss=3.055, w2v_ctc_loss=0.924, task_loss=3.342, task_loss_gen=4.309, contrastive_loss=0, total=6646.52, n_correct=2732.96, ppl=8.31, accuracy=41.119, wps=18365.9, ups=1.38, wpb=13293, bsz=443, num_updates=24200, lr=9.09091e-05, gnorm=2.918, clip=1, loss_scale=0.25, train_wall=72, gb_free=15, wall=23129
2023-09-06 07:41:32 | INFO | train_inner | epoch 021:    497 / 1191 loss=2.549, trans_loss=5.593, nll_loss=3.057, w2v_ctc_loss=0.911, task_loss=3.276, task_loss_gen=4.369, contrastive_loss=0, total=6696.95, n_correct=2749.14, ppl=8.32, accuracy=41.051, wps=18361, ups=1.37, wpb=13393.9, bsz=437.3, num_updates=24300, lr=9.07218e-05, gnorm=2.214, clip=0, loss_scale=0.25, train_wall=72, gb_free=10.5, wall=23202
2023-09-06 07:42:44 | INFO | train_inner | epoch 021:    597 / 1191 loss=2.557, trans_loss=5.607, nll_loss=3.074, w2v_ctc_loss=0.915, task_loss=3.519, task_loss_gen=4.547, contrastive_loss=0, total=6605.02, n_correct=2692.49, ppl=8.42, accuracy=40.764, wps=18361.4, ups=1.39, wpb=13210, bsz=423.9, num_updates=24400, lr=9.05357e-05, gnorm=2.859, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.7, wall=23274
2023-09-06 07:43:57 | INFO | train_inner | epoch 021:    697 / 1191 loss=2.529, trans_loss=5.589, nll_loss=3.052, w2v_ctc_loss=0.883, task_loss=3.026, task_loss_gen=4.056, contrastive_loss=0, total=6736.1, n_correct=2783.78, ppl=8.29, accuracy=41.326, wps=18481.5, ups=1.37, wpb=13472.2, bsz=472, num_updates=24500, lr=9.03508e-05, gnorm=2.276, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23347
2023-09-06 07:45:10 | INFO | train_inner | epoch 021:    797 / 1191 loss=2.538, trans_loss=5.598, nll_loss=3.062, w2v_ctc_loss=0.879, task_loss=3.286, task_loss_gen=4.388, contrastive_loss=0, total=6639.88, n_correct=2724.37, ppl=8.35, accuracy=41.03, wps=18292.1, ups=1.38, wpb=13279.8, bsz=443.4, num_updates=24600, lr=9.0167e-05, gnorm=2.651, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.3, wall=23420
2023-09-06 07:46:22 | INFO | train_inner | epoch 021:    897 / 1191 loss=2.532, trans_loss=5.592, nll_loss=3.056, w2v_ctc_loss=0.873, task_loss=3.137, task_loss_gen=4.127, contrastive_loss=0, total=6739.89, n_correct=2777.26, ppl=8.31, accuracy=41.206, wps=18556.8, ups=1.38, wpb=13479.8, bsz=453.1, num_updates=24700, lr=8.99843e-05, gnorm=2.247, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.7, wall=23492
2023-09-06 07:47:35 | INFO | train_inner | epoch 021:    997 / 1191 loss=2.53, trans_loss=5.594, nll_loss=3.058, w2v_ctc_loss=0.872, task_loss=3.19, task_loss_gen=4.004, contrastive_loss=0, total=6785.1, n_correct=2790.63, ppl=8.33, accuracy=41.129, wps=18652.2, ups=1.37, wpb=13570.2, bsz=461.6, num_updates=24800, lr=8.98027e-05, gnorm=3.332, clip=1, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23565
2023-09-06 07:48:48 | INFO | train_inner | epoch 021:   1097 / 1191 loss=2.531, trans_loss=5.593, nll_loss=3.057, w2v_ctc_loss=0.873, task_loss=3.042, task_loss_gen=4.018, contrastive_loss=0, total=6750.57, n_correct=2782.68, ppl=8.32, accuracy=41.221, wps=18520.8, ups=1.37, wpb=13501.1, bsz=462.1, num_updates=24900, lr=8.96221e-05, gnorm=2.441, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23638
2023-09-06 07:49:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:50:30 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.978 | trans_loss 6.723 | nll_loss 4.47 | w2v_ctc_loss 1.404 | task_loss 13.299 | task_loss_gen 11.722 | contrastive_loss 0 | total 6138.43 | n_correct 2528.71 | ppl 22.17 | accuracy 41.195 | uer 23.082 | wer 24.734 | raw_wer 24.734 | bleu 0.32 | wps 1649.4 | wpb 6138.4 | bsz 201.1 | num_updates 24994 | best_bleu 0.46
2023-09-06 07:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24994 updates
2023-09-06 07:50:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt
2023-09-06 07:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt
2023-09-06 07:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt (epoch 21 @ 24994 updates, score 0.32) (writing took 7.580136829987168 seconds)
2023-09-06 07:50:38 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-06 07:50:38 | INFO | train | epoch 021 | loss 2.536 | trans_loss 5.591 | nll_loss 3.054 | w2v_ctc_loss 0.887 | task_loss 3.236 | task_loss_gen 4.187 | contrastive_loss 0 | total 6703.69 | n_correct 2760.63 | ppl 8.3 | accuracy 41.181 | wps 16678.4 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 24994 | lr 8.94535e-05 | gnorm 2.628 | clip 0.2 | loss_scale 0.25 | train_wall 856 | gb_free 13.4 | wall 23748
2023-09-06 07:50:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:50:38 | INFO | fairseq.trainer | begin training epoch 22
2023-09-06 07:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:50:50 | INFO | train_inner | epoch 022:      6 / 1191 loss=2.522, trans_loss=5.587, nll_loss=3.049, w2v_ctc_loss=0.846, task_loss=3.39, task_loss_gen=4.295, contrastive_loss=0, total=6645.47, n_correct=2736.29, ppl=8.28, accuracy=41.175, wps=10860.6, ups=0.82, wpb=13290.9, bsz=448.1, num_updates=25000, lr=8.94427e-05, gnorm=2.494, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.1, wall=23760
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 07:52:03 | INFO | train_inner | epoch 022:    106 / 1191 loss=2.514, trans_loss=5.573, nll_loss=3.031, w2v_ctc_loss=0.844, task_loss=3.264, task_loss_gen=4.048, contrastive_loss=0, total=6764.76, n_correct=2806.33, ppl=8.17, accuracy=41.485, wps=18741.3, ups=1.39, wpb=13529.5, bsz=459.7, num_updates=25100, lr=8.92644e-05, gnorm=2.724, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.3, wall=23833
2023-09-06 07:53:15 | INFO | train_inner | epoch 022:    206 / 1191 loss=2.521, trans_loss=5.581, nll_loss=3.041, w2v_ctc_loss=0.849, task_loss=3.246, task_loss_gen=4.269, contrastive_loss=0, total=6668.21, n_correct=2754.26, ppl=8.23, accuracy=41.304, wps=18375.6, ups=1.38, wpb=13336.4, bsz=445.8, num_updates=25200, lr=8.90871e-05, gnorm=2.274, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=23905
2023-09-06 07:54:28 | INFO | train_inner | epoch 022:    306 / 1191 loss=2.511, trans_loss=5.574, nll_loss=3.032, w2v_ctc_loss=0.835, task_loss=3.315, task_loss_gen=4.181, contrastive_loss=0, total=6707.19, n_correct=2782.94, ppl=8.18, accuracy=41.492, wps=18557.7, ups=1.38, wpb=13414.4, bsz=460.7, num_updates=25300, lr=8.89108e-05, gnorm=3.205, clip=1, loss_scale=0.25, train_wall=72, gb_free=12, wall=23977
2023-09-06 07:55:41 | INFO | train_inner | epoch 022:    406 / 1191 loss=2.509, trans_loss=5.572, nll_loss=3.03, w2v_ctc_loss=0.834, task_loss=3.372, task_loss_gen=4.161, contrastive_loss=0, total=6699.53, n_correct=2785.46, ppl=8.17, accuracy=41.577, wps=18344.5, ups=1.37, wpb=13399.1, bsz=461.5, num_updates=25400, lr=8.87357e-05, gnorm=3.321, clip=1, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=24050
2023-09-06 07:56:53 | INFO | train_inner | epoch 022:    506 / 1191 loss=2.512, trans_loss=5.573, nll_loss=3.031, w2v_ctc_loss=0.846, task_loss=3.248, task_loss_gen=4.154, contrastive_loss=0, total=6724.31, n_correct=2799.31, ppl=8.17, accuracy=41.63, wps=18604, ups=1.38, wpb=13448.6, bsz=458.1, num_updates=25500, lr=8.85615e-05, gnorm=2.502, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.1, wall=24123
2023-09-06 07:58:06 | INFO | train_inner | epoch 022:    606 / 1191 loss=2.512, trans_loss=5.577, nll_loss=3.036, w2v_ctc_loss=0.824, task_loss=3.344, task_loss_gen=4.335, contrastive_loss=0, total=6694.8, n_correct=2778.25, ppl=8.2, accuracy=41.499, wps=18330.3, ups=1.37, wpb=13389.6, bsz=444, num_updates=25600, lr=8.83883e-05, gnorm=2.513, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.8, wall=24196
2023-09-06 07:59:18 | INFO | train_inner | epoch 022:    706 / 1191 loss=2.5, trans_loss=5.573, nll_loss=3.032, w2v_ctc_loss=0.806, task_loss=3.219, task_loss_gen=3.988, contrastive_loss=0, total=6721.65, n_correct=2800.33, ppl=8.18, accuracy=41.661, wps=18766, ups=1.4, wpb=13443.3, bsz=460.5, num_updates=25700, lr=8.82162e-05, gnorm=2.753, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.6, wall=24267
2023-09-06 08:00:29 | INFO | train_inner | epoch 022:    806 / 1191 loss=2.501, trans_loss=5.567, nll_loss=3.024, w2v_ctc_loss=0.803, task_loss=3.442, task_loss_gen=4.385, contrastive_loss=0, total=6554.97, n_correct=2725.17, ppl=8.13, accuracy=41.574, wps=18261.8, ups=1.39, wpb=13109.9, bsz=429.5, num_updates=25800, lr=8.80451e-05, gnorm=1.61, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=24339
2023-09-06 08:01:43 | INFO | train_inner | epoch 022:    906 / 1191 loss=2.495, trans_loss=5.566, nll_loss=3.023, w2v_ctc_loss=0.8, task_loss=3.148, task_loss_gen=4.136, contrastive_loss=0, total=6727.29, n_correct=2807.05, ppl=8.13, accuracy=41.726, wps=18244.5, ups=1.36, wpb=13454.6, bsz=458.1, num_updates=25900, lr=8.7875e-05, gnorm=1.211, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.7, wall=24413
2023-09-06 08:02:56 | INFO | train_inner | epoch 022:   1006 / 1191 loss=2.49, trans_loss=5.559, nll_loss=3.014, w2v_ctc_loss=0.797, task_loss=3.032, task_loss_gen=4.046, contrastive_loss=0, total=6823.74, n_correct=2862.79, ppl=8.08, accuracy=41.953, wps=18826.1, ups=1.38, wpb=13647.5, bsz=465.7, num_updates=26000, lr=8.77058e-05, gnorm=1.067, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=24485
2023-09-06 08:02:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
2023-09-06 08:03:32 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.946 | trans_loss 6.694 | nll_loss 4.433 | w2v_ctc_loss 1.362 | task_loss 8.255 | task_loss_gen 12.386 | contrastive_loss 0 | total 6138.43 | n_correct 2571 | ppl 21.6 | accuracy 41.884 | uer 21.475 | wer 23.09 | raw_wer 23.09 | bleu 0.59 | wps 1461.1 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 0.59
2023-09-06 08:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26000 updates
2023-09-06 08:03:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 08:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 08:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt (epoch 22 @ 26000 updates, score 0.59) (writing took 15.908736642915756 seconds)
2023-09-06 08:05:00 | INFO | train_inner | epoch 022:   1106 / 1191 loss=2.491, trans_loss=5.562, nll_loss=3.018, w2v_ctc_loss=0.787, task_loss=3.314, task_loss_gen=4.24, contrastive_loss=0, total=6691.44, n_correct=2800.37, ppl=8.1, accuracy=41.85, wps=10722.6, ups=0.8, wpb=13382.9, bsz=445.8, num_updates=26100, lr=8.75376e-05, gnorm=1.595, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=24610
2023-09-06 08:06:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:06:36 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.93 | trans_loss 6.685 | nll_loss 4.425 | w2v_ctc_loss 1.329 | task_loss 10.24 | task_loss_gen 11.801 | contrastive_loss 0 | total 6138.43 | n_correct 2577.57 | ppl 21.47 | accuracy 41.991 | uer 21.574 | wer 23.083 | raw_wer 23.083 | bleu 0.65 | wps 1689.9 | wpb 6138.4 | bsz 201.1 | num_updates 26185 | best_bleu 0.65
2023-09-06 08:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26185 updates
2023-09-06 08:06:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:06:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 22 @ 26185 updates, score 0.65) (writing took 13.918930566986091 seconds)
2023-09-06 08:06:50 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-06 08:06:50 | INFO | train | epoch 022 | loss 2.504 | trans_loss 5.57 | nll_loss 3.027 | w2v_ctc_loss 0.818 | task_loss 3.27 | task_loss_gen 4.188 | contrastive_loss 0 | total 6703.69 | n_correct 2791.59 | ppl 8.15 | accuracy 41.643 | wps 16431.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 26185 | lr 8.73954e-05 | gnorm 2.184 | clip 0.2 | loss_scale 0.5 | train_wall 855 | gb_free 13.4 | wall 24720
2023-09-06 08:06:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:06:50 | INFO | fairseq.trainer | begin training epoch 23
2023-09-06 08:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:07:09 | INFO | train_inner | epoch 023:     15 / 1191 loss=2.488, trans_loss=5.557, nll_loss=3.011, w2v_ctc_loss=0.782, task_loss=3.304, task_loss_gen=4.363, contrastive_loss=0, total=6687.44, n_correct=2811.08, ppl=8.06, accuracy=42.035, wps=10399.6, ups=0.78, wpb=13374.9, bsz=437.8, num_updates=26200, lr=8.73704e-05, gnorm=1.242, clip=0, loss_scale=0.5, train_wall=72, gb_free=10.6, wall=24739
2023-09-06 08:08:22 | INFO | train_inner | epoch 023:    115 / 1191 loss=2.479, trans_loss=5.543, nll_loss=2.993, w2v_ctc_loss=0.77, task_loss=3.434, task_loss_gen=4.374, contrastive_loss=0, total=6659.81, n_correct=2805.46, ppl=7.96, accuracy=42.125, wps=18352, ups=1.38, wpb=13319.6, bsz=442.7, num_updates=26300, lr=8.72041e-05, gnorm=1.504, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.3, wall=24811
2023-09-06 08:09:35 | INFO | train_inner | epoch 023:    215 / 1191 loss=2.474, trans_loss=5.545, nll_loss=2.995, w2v_ctc_loss=0.773, task_loss=3.026, task_loss_gen=4.058, contrastive_loss=0, total=6794.98, n_correct=2876.57, ppl=7.97, accuracy=42.334, wps=18583.4, ups=1.37, wpb=13590, bsz=467.7, num_updates=26400, lr=8.70388e-05, gnorm=1.21, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.5, wall=24885
2023-09-06 08:10:47 | INFO | train_inner | epoch 023:    315 / 1191 loss=2.467, trans_loss=5.54, nll_loss=2.989, w2v_ctc_loss=0.75, task_loss=3.386, task_loss_gen=4.019, contrastive_loss=0, total=6832.59, n_correct=2894.52, ppl=7.94, accuracy=42.363, wps=18872.6, ups=1.38, wpb=13665.2, bsz=467.2, num_updates=26500, lr=8.68744e-05, gnorm=1.777, clip=0, loss_scale=0.5, train_wall=72, gb_free=15.2, wall=24957
2023-09-06 08:12:00 | INFO | train_inner | epoch 023:    415 / 1191 loss=2.481, trans_loss=5.553, nll_loss=3.005, w2v_ctc_loss=0.764, task_loss=3.481, task_loss_gen=4.452, contrastive_loss=0, total=6670.47, n_correct=2802.58, ppl=8.03, accuracy=42.015, wps=18369.2, ups=1.38, wpb=13340.9, bsz=432, num_updates=26600, lr=8.6711e-05, gnorm=1.659, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.5, wall=25030
2023-09-06 08:13:12 | INFO | train_inner | epoch 023:    515 / 1191 loss=2.464, trans_loss=5.535, nll_loss=2.982, w2v_ctc_loss=0.753, task_loss=3.116, task_loss_gen=4.035, contrastive_loss=0, total=6739.35, n_correct=2871.75, ppl=7.9, accuracy=42.612, wps=18614.6, ups=1.38, wpb=13478.7, bsz=459.7, num_updates=26700, lr=8.65485e-05, gnorm=1.293, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=25102
2023-09-06 08:14:24 | INFO | train_inner | epoch 023:    615 / 1191 loss=2.474, trans_loss=5.548, nll_loss=2.999, w2v_ctc_loss=0.765, task_loss=3.783, task_loss_gen=4.307, contrastive_loss=0, total=6671.11, n_correct=2822.61, ppl=7.99, accuracy=42.311, wps=18619.2, ups=1.4, wpb=13342.2, bsz=452.7, num_updates=26800, lr=8.63868e-05, gnorm=2.72, clip=1, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=25174
2023-09-06 08:15:37 | INFO | train_inner | epoch 023:    715 / 1191 loss=2.47, trans_loss=5.541, nll_loss=2.989, w2v_ctc_loss=0.76, task_loss=3.341, task_loss_gen=4.305, contrastive_loss=0, total=6659.09, n_correct=2828, ppl=7.94, accuracy=42.468, wps=18231.1, ups=1.37, wpb=13318.2, bsz=442.8, num_updates=26900, lr=8.62261e-05, gnorm=1.315, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.9, wall=25247
2023-09-06 08:16:50 | INFO | train_inner | epoch 023:    815 / 1191 loss=2.468, trans_loss=5.539, nll_loss=2.987, w2v_ctc_loss=0.756, task_loss=3.375, task_loss_gen=4.384, contrastive_loss=0, total=6709.17, n_correct=2852.84, ppl=7.93, accuracy=42.522, wps=18335, ups=1.37, wpb=13418.3, bsz=442.6, num_updates=27000, lr=8.60663e-05, gnorm=1.884, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.8, wall=25320
2023-09-06 08:18:02 | INFO | train_inner | epoch 023:    915 / 1191 loss=2.462, trans_loss=5.53, nll_loss=2.975, w2v_ctc_loss=0.758, task_loss=3.368, task_loss_gen=4.032, contrastive_loss=0, total=6731.52, n_correct=2871.55, ppl=7.86, accuracy=42.658, wps=18626.4, ups=1.38, wpb=13463, bsz=468.2, num_updates=27100, lr=8.59074e-05, gnorm=1.97, clip=0, loss_scale=0.5, train_wall=72, gb_free=4, wall=25392
2023-09-06 08:19:15 | INFO | train_inner | epoch 023:   1015 / 1191 loss=2.455, trans_loss=5.523, nll_loss=2.967, w2v_ctc_loss=0.755, task_loss=3.036, task_loss_gen=3.926, contrastive_loss=0, total=6696.93, n_correct=2874.58, ppl=7.82, accuracy=42.924, wps=18541.9, ups=1.38, wpb=13393.9, bsz=472.2, num_updates=27200, lr=8.57493e-05, gnorm=1.448, clip=0, loss_scale=0.5, train_wall=72, gb_free=10.4, wall=25464
2023-09-06 08:20:27 | INFO | train_inner | epoch 023:   1115 / 1191 loss=2.47, trans_loss=5.541, nll_loss=2.99, w2v_ctc_loss=0.758, task_loss=4.197, task_loss_gen=4.692, contrastive_loss=0, total=6610.02, n_correct=2811.06, ppl=7.94, accuracy=42.527, wps=18298.6, ups=1.38, wpb=13220, bsz=432.6, num_updates=27300, lr=8.55921e-05, gnorm=2.728, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.1, wall=25537
2023-09-06 08:21:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:21:57 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.885 | trans_loss 6.64 | nll_loss 4.357 | w2v_ctc_loss 1.28 | task_loss 12.179 | task_loss_gen 11.935 | contrastive_loss 0 | total 6138.43 | n_correct 2609.29 | ppl 20.49 | accuracy 42.507 | uer 20.635 | wer 22.25 | raw_wer 22.25 | bleu 0.8 | wps 1590.3 | wpb 6138.4 | bsz 201.1 | num_updates 27376 | best_bleu 0.8
2023-09-06 08:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27376 updates
2023-09-06 08:21:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 23 @ 27376 updates, score 0.8) (writing took 13.688264800934121 seconds)
2023-09-06 08:22:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-06 08:22:11 | INFO | train | epoch 023 | loss 2.469 | trans_loss 5.54 | nll_loss 2.988 | w2v_ctc_loss 0.76 | task_loss 3.409 | task_loss_gen 4.245 | contrastive_loss 0 | total 6703.69 | n_correct 2846.06 | ppl 7.93 | accuracy 42.455 | wps 17336.7 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 27376 | lr 8.54732e-05 | gnorm 1.775 | clip 0.1 | loss_scale 0.5 | train_wall 857 | gb_free 14.6 | wall 25641
2023-09-06 08:22:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:22:11 | INFO | fairseq.trainer | begin training epoch 24
2023-09-06 08:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:22:36 | INFO | train_inner | epoch 024:     24 / 1191 loss=2.462, trans_loss=5.533, nll_loss=2.978, w2v_ctc_loss=0.751, task_loss=3.421, task_loss_gen=4.407, contrastive_loss=0, total=6683.55, n_correct=2856.56, ppl=7.88, accuracy=42.74, wps=10337.4, ups=0.77, wpb=13367.1, bsz=445.9, num_updates=27400, lr=8.54358e-05, gnorm=1.771, clip=0, loss_scale=0.5, train_wall=72, gb_free=6.7, wall=25666
2023-09-06 08:23:49 | INFO | train_inner | epoch 024:    124 / 1191 loss=2.445, trans_loss=5.519, nll_loss=2.96, w2v_ctc_loss=0.734, task_loss=3.093, task_loss_gen=4.05, contrastive_loss=0, total=6726.65, n_correct=2898.75, ppl=7.78, accuracy=43.094, wps=18595, ups=1.38, wpb=13453.3, bsz=467.3, num_updates=27500, lr=8.52803e-05, gnorm=1.243, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=25738
2023-09-06 08:25:00 | INFO | train_inner | epoch 024:    224 / 1191 loss=2.434, trans_loss=5.508, nll_loss=2.947, w2v_ctc_loss=0.724, task_loss=3.034, task_loss_gen=3.84, contrastive_loss=0, total=6830.09, n_correct=2961.44, ppl=7.71, accuracy=43.359, wps=19064.4, ups=1.4, wpb=13660.2, bsz=485, num_updates=27600, lr=8.51257e-05, gnorm=1.932, clip=0, loss_scale=0.5, train_wall=71, gb_free=12.7, wall=25810
2023-09-06 08:26:13 | INFO | train_inner | epoch 024:    324 / 1191 loss=2.445, trans_loss=5.515, nll_loss=2.955, w2v_ctc_loss=0.731, task_loss=3.473, task_loss_gen=4.233, contrastive_loss=0, total=6738.1, n_correct=2900.1, ppl=7.76, accuracy=43.04, wps=18571.6, ups=1.38, wpb=13476.2, bsz=453.1, num_updates=27700, lr=8.49719e-05, gnorm=2.183, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.2, wall=25883
2023-09-06 08:27:25 | INFO | train_inner | epoch 024:    424 / 1191 loss=2.451, trans_loss=5.517, nll_loss=2.958, w2v_ctc_loss=0.739, task_loss=3.477, task_loss_gen=4.414, contrastive_loss=0, total=6667.84, n_correct=2865.3, ppl=7.77, accuracy=42.972, wps=18564.1, ups=1.39, wpb=13335.7, bsz=436.6, num_updates=27800, lr=8.48189e-05, gnorm=1.212, clip=0, loss_scale=1, train_wall=71, gb_free=13.2, wall=25954
2023-09-06 08:28:38 | INFO | train_inner | epoch 024:    524 / 1191 loss=2.438, trans_loss=5.505, nll_loss=2.943, w2v_ctc_loss=0.729, task_loss=3.279, task_loss_gen=4.355, contrastive_loss=0, total=6644.61, n_correct=2879.43, ppl=7.69, accuracy=43.335, wps=18165.6, ups=1.37, wpb=13289.2, bsz=451.6, num_updates=27900, lr=8.46668e-05, gnorm=0.756, clip=0, loss_scale=1, train_wall=72, gb_free=11.9, wall=26028
2023-09-06 08:29:49 | INFO | train_inner | epoch 024:    624 / 1191 loss=2.453, trans_loss=5.518, nll_loss=2.958, w2v_ctc_loss=0.738, task_loss=3.444, task_loss_gen=4.53, contrastive_loss=0, total=6547.71, n_correct=2811.77, ppl=7.77, accuracy=42.943, wps=18349.7, ups=1.4, wpb=13095.4, bsz=418.8, num_updates=28000, lr=8.45154e-05, gnorm=0.874, clip=0, loss_scale=1, train_wall=71, gb_free=14.1, wall=26099
2023-09-06 08:29:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:30:25 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.858 | trans_loss 6.603 | nll_loss 4.308 | w2v_ctc_loss 1.276 | task_loss 12.452 | task_loss_gen 11.961 | contrastive_loss 0 | total 6138.43 | n_correct 2641.29 | ppl 19.8 | accuracy 43.029 | uer 20.576 | wer 22.228 | raw_wer 22.228 | bleu 1.02 | wps 1476.8 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 1.02
2023-09-06 08:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-09-06 08:30:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 08:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 08:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 1.02) (writing took 13.769007784081623 seconds)
2023-09-06 08:31:52 | INFO | train_inner | epoch 024:    724 / 1191 loss=2.434, trans_loss=5.5, nll_loss=2.937, w2v_ctc_loss=0.732, task_loss=3.304, task_loss_gen=4.07, contrastive_loss=0, total=6732.45, n_correct=2929.62, ppl=7.66, accuracy=43.515, wps=10989.4, ups=0.82, wpb=13464.9, bsz=470.3, num_updates=28100, lr=8.43649e-05, gnorm=1.272, clip=0, loss_scale=1, train_wall=71, gb_free=13.9, wall=26222
2023-09-06 08:33:04 | INFO | train_inner | epoch 024:    824 / 1191 loss=2.44, trans_loss=5.506, nll_loss=2.943, w2v_ctc_loss=0.73, task_loss=3.234, task_loss_gen=4.212, contrastive_loss=0, total=6751.06, n_correct=2923.11, ppl=7.69, accuracy=43.299, wps=18697.7, ups=1.38, wpb=13502.1, bsz=448.7, num_updates=28200, lr=8.42152e-05, gnorm=1.011, clip=0, loss_scale=1, train_wall=72, gb_free=14.1, wall=26294
2023-09-06 08:34:17 | INFO | train_inner | epoch 024:    924 / 1191 loss=2.433, trans_loss=5.504, nll_loss=2.94, w2v_ctc_loss=0.723, task_loss=3.07, task_loss_gen=4.152, contrastive_loss=0, total=6719.91, n_correct=2914.66, ppl=7.68, accuracy=43.373, wps=18393.9, ups=1.37, wpb=13439.8, bsz=459, num_updates=28300, lr=8.40663e-05, gnorm=0.815, clip=0, loss_scale=1, train_wall=72, gb_free=14, wall=26367
2023-09-06 08:35:30 | INFO | train_inner | epoch 024:   1024 / 1191 loss=2.438, trans_loss=5.508, nll_loss=2.946, w2v_ctc_loss=0.725, task_loss=3.715, task_loss_gen=4.67, contrastive_loss=0, total=6578.26, n_correct=2848.76, ppl=7.71, accuracy=43.306, wps=18118.5, ups=1.38, wpb=13156.5, bsz=436.9, num_updates=28400, lr=8.39181e-05, gnorm=1.415, clip=0, loss_scale=1, train_wall=72, gb_free=14.4, wall=26439
2023-09-06 08:36:44 | INFO | train_inner | epoch 024:   1124 / 1191 loss=2.437, trans_loss=5.502, nll_loss=2.938, w2v_ctc_loss=0.725, task_loss=3.367, task_loss_gen=4.389, contrastive_loss=0, total=6714.89, n_correct=2919.61, ppl=7.66, accuracy=43.48, wps=18154.9, ups=1.35, wpb=13429.8, bsz=435.1, num_updates=28500, lr=8.37708e-05, gnorm=0.875, clip=0, loss_scale=1, train_wall=73, gb_free=12.2, wall=26513
2023-09-06 08:37:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:38:08 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.84 | trans_loss 6.578 | nll_loss 4.281 | w2v_ctc_loss 1.27 | task_loss 12.09 | task_loss_gen 12.08 | contrastive_loss 0 | total 6138.43 | n_correct 2653.71 | ppl 19.44 | accuracy 43.231 | uer 19.857 | wer 21.458 | raw_wer 21.458 | bleu 1.17 | wps 1498.2 | wpb 6138.4 | bsz 201.1 | num_updates 28567 | best_bleu 1.17
2023-09-06 08:38:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28567 updates
2023-09-06 08:38:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:38:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 24 @ 28567 updates, score 1.17) (writing took 14.470593063975684 seconds)
2023-09-06 08:38:23 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-06 08:38:23 | INFO | train | epoch 024 | loss 2.44 | trans_loss 5.509 | nll_loss 2.947 | w2v_ctc_loss 0.73 | task_loss 3.304 | task_loss_gen 4.25 | contrastive_loss 0 | total 6703.69 | n_correct 2900.01 | ppl 7.71 | accuracy 43.26 | wps 16435 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 28567 | lr 8.36725e-05 | gnorm 1.214 | clip 0 | loss_scale 1 | train_wall 854 | gb_free 14.9 | wall 26613
2023-09-06 08:38:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:38:23 | INFO | fairseq.trainer | begin training epoch 25
2023-09-06 08:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:38:54 | INFO | train_inner | epoch 025:     33 / 1191 loss=2.433, trans_loss=5.499, nll_loss=2.934, w2v_ctc_loss=0.724, task_loss=3.421, task_loss_gen=4.429, contrastive_loss=0, total=6687.79, n_correct=2911.91, ppl=7.64, accuracy=43.541, wps=10232.4, ups=0.77, wpb=13375.6, bsz=446, num_updates=28600, lr=8.36242e-05, gnorm=0.917, clip=0, loss_scale=1, train_wall=71, gb_free=15.2, wall=26644
2023-09-06 08:40:07 | INFO | train_inner | epoch 025:    133 / 1191 loss=2.419, trans_loss=5.481, nll_loss=2.91, w2v_ctc_loss=0.704, task_loss=3.504, task_loss_gen=4.484, contrastive_loss=0, total=6603.88, n_correct=2897.46, ppl=7.52, accuracy=43.875, wps=18258.3, ups=1.38, wpb=13207.8, bsz=440.3, num_updates=28700, lr=8.34784e-05, gnorm=0.938, clip=0, loss_scale=1, train_wall=72, gb_free=14.3, wall=26716
2023-09-06 08:41:19 | INFO | train_inner | epoch 025:    233 / 1191 loss=2.408, trans_loss=5.48, nll_loss=2.91, w2v_ctc_loss=0.697, task_loss=3.021, task_loss_gen=4.047, contrastive_loss=0, total=6797.98, n_correct=2998.43, ppl=7.51, accuracy=44.108, wps=18778.3, ups=1.38, wpb=13596, bsz=475, num_updates=28800, lr=8.33333e-05, gnorm=0.848, clip=0, loss_scale=1, train_wall=72, gb_free=12.8, wall=26789
2023-09-06 08:42:32 | INFO | train_inner | epoch 025:    333 / 1191 loss=2.43, trans_loss=5.491, nll_loss=2.923, w2v_ctc_loss=0.722, task_loss=3.443, task_loss_gen=4.627, contrastive_loss=0, total=6570.06, n_correct=2871.84, ppl=7.58, accuracy=43.711, wps=17929.8, ups=1.36, wpb=13140.1, bsz=424.5, num_updates=28900, lr=8.3189e-05, gnorm=0.846, clip=0, loss_scale=1, train_wall=73, gb_free=6, wall=26862
2023-09-06 08:43:45 | INFO | train_inner | epoch 025:    433 / 1191 loss=2.422, trans_loss=5.484, nll_loss=2.914, w2v_ctc_loss=0.713, task_loss=3.425, task_loss_gen=4.575, contrastive_loss=0, total=6605.27, n_correct=2895.14, ppl=7.53, accuracy=43.831, wps=18247.4, ups=1.38, wpb=13210.5, bsz=423.9, num_updates=29000, lr=8.30455e-05, gnorm=0.762, clip=0, loss_scale=1, train_wall=72, gb_free=12.7, wall=26935
2023-09-06 08:44:58 | INFO | train_inner | epoch 025:    533 / 1191 loss=2.402, trans_loss=5.469, nll_loss=2.895, w2v_ctc_loss=0.702, task_loss=2.897, task_loss_gen=3.889, contrastive_loss=0, total=6839.61, n_correct=3043.28, ppl=7.44, accuracy=44.495, wps=18754.2, ups=1.37, wpb=13679.2, bsz=482.9, num_updates=29100, lr=8.29027e-05, gnorm=0.79, clip=0, loss_scale=1, train_wall=72, gb_free=12.5, wall=27008
2023-09-06 08:46:09 | INFO | train_inner | epoch 025:    633 / 1191 loss=2.405, trans_loss=5.465, nll_loss=2.89, w2v_ctc_loss=0.703, task_loss=3.082, task_loss_gen=4.086, contrastive_loss=0, total=6773.23, n_correct=3011.69, ppl=7.41, accuracy=44.465, wps=18909.2, ups=1.4, wpb=13546.5, bsz=454.7, num_updates=29200, lr=8.27606e-05, gnorm=0.77, clip=0, loss_scale=1, train_wall=71, gb_free=13.3, wall=27079
2023-09-06 08:47:22 | INFO | train_inner | epoch 025:    733 / 1191 loss=2.407, trans_loss=5.466, nll_loss=2.889, w2v_ctc_loss=0.713, task_loss=3.329, task_loss_gen=4.396, contrastive_loss=0, total=6672.24, n_correct=2962.8, ppl=7.41, accuracy=44.405, wps=18403.7, ups=1.38, wpb=13344.5, bsz=446.8, num_updates=29300, lr=8.26192e-05, gnorm=0.846, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=27152
2023-09-06 08:48:34 | INFO | train_inner | epoch 025:    833 / 1191 loss=2.394, trans_loss=5.454, nll_loss=2.875, w2v_ctc_loss=0.704, task_loss=3.037, task_loss_gen=4.093, contrastive_loss=0, total=6743.82, n_correct=3028.44, ppl=7.33, accuracy=44.907, wps=18716.1, ups=1.39, wpb=13487.6, bsz=462.6, num_updates=29400, lr=8.24786e-05, gnorm=0.739, clip=0, loss_scale=1, train_wall=71, gb_free=11.6, wall=27224
2023-09-06 08:49:46 | INFO | train_inner | epoch 025:    933 / 1191 loss=2.389, trans_loss=5.444, nll_loss=2.861, w2v_ctc_loss=0.709, task_loss=3.069, task_loss_gen=4.063, contrastive_loss=0, total=6769.34, n_correct=3059.37, ppl=7.27, accuracy=45.195, wps=18688, ups=1.38, wpb=13538.7, bsz=467.7, num_updates=29500, lr=8.23387e-05, gnorm=0.826, clip=0, loss_scale=1, train_wall=72, gb_free=13.4, wall=27296
2023-09-06 08:50:58 | INFO | train_inner | epoch 025:   1033 / 1191 loss=2.387, trans_loss=5.446, nll_loss=2.864, w2v_ctc_loss=0.707, task_loss=3.125, task_loss_gen=4.229, contrastive_loss=0, total=6674.8, n_correct=3020.29, ppl=7.28, accuracy=45.249, wps=18583.2, ups=1.39, wpb=13349.6, bsz=454.6, num_updates=29600, lr=8.21995e-05, gnorm=0.806, clip=0, loss_scale=1, train_wall=71, gb_free=13.3, wall=27368
2023-09-06 08:52:11 | INFO | train_inner | epoch 025:   1133 / 1191 loss=2.385, trans_loss=5.431, nll_loss=2.844, w2v_ctc_loss=0.718, task_loss=3.371, task_loss_gen=4.558, contrastive_loss=0, total=6656.31, n_correct=3039.37, ppl=7.18, accuracy=45.661, wps=18311.6, ups=1.38, wpb=13312.6, bsz=439.7, num_updates=29700, lr=8.2061e-05, gnorm=0.874, clip=0, loss_scale=1, train_wall=72, gb_free=11.5, wall=27441
2023-09-06 08:52:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:53:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.657 | trans_loss 6.3 | nll_loss 3.915 | w2v_ctc_loss 1.287 | task_loss 9.618 | task_loss_gen 12.553 | contrastive_loss 0 | total 6138.43 | n_correct 2930.57 | ppl 15.09 | accuracy 47.741 | uer 19.672 | wer 21.041 | raw_wer 21.041 | bleu 3.84 | wps 1430.1 | wpb 6138.4 | bsz 201.1 | num_updates 29758 | best_bleu 3.84
2023-09-06 08:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29758 updates
2023-09-06 08:53:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 25 @ 29758 updates, score 3.84) (writing took 13.31537883693818 seconds)
2023-09-06 08:53:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-06 08:53:44 | INFO | train | epoch 025 | loss 2.403 | trans_loss 5.463 | nll_loss 2.886 | w2v_ctc_loss 0.709 | task_loss 3.193 | task_loss_gen 4.269 | contrastive_loss 0 | total 6703.69 | n_correct 2990.98 | ppl 7.39 | accuracy 44.617 | wps 17334.9 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 29758 | lr 8.1981e-05 | gnorm 0.819 | clip 0 | loss_scale 1 | train_wall 855 | gb_free 11.5 | wall 27534
2023-09-06 08:53:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:53:44 | INFO | fairseq.trainer | begin training epoch 26
2023-09-06 08:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:54:22 | INFO | train_inner | epoch 026:     42 / 1191 loss=2.353, trans_loss=5.395, nll_loss=2.797, w2v_ctc_loss=0.709, task_loss=2.896, task_loss_gen=4.097, contrastive_loss=0, total=6831.33, n_correct=3210.23, ppl=6.95, accuracy=46.993, wps=10427, ups=0.76, wpb=13662.7, bsz=467.1, num_updates=29800, lr=8.19232e-05, gnorm=0.71, clip=0, loss_scale=1, train_wall=72, gb_free=11.4, wall=27572
2023-09-06 08:55:35 | INFO | train_inner | epoch 026:    142 / 1191 loss=2.294, trans_loss=5.306, nll_loss=2.681, w2v_ctc_loss=0.714, task_loss=2.935, task_loss_gen=4.348, contrastive_loss=0, total=6721.54, n_correct=3347.4, ppl=6.41, accuracy=49.801, wps=18423.9, ups=1.37, wpb=13443.1, bsz=458.7, num_updates=29900, lr=8.17861e-05, gnorm=0.591, clip=0, loss_scale=2, train_wall=72, gb_free=12.2, wall=27645
2023-09-06 08:56:47 | INFO | train_inner | epoch 026:    242 / 1191 loss=2.222, trans_loss=5.188, nll_loss=2.529, w2v_ctc_loss=0.732, task_loss=2.736, task_loss_gen=4.34, contrastive_loss=0, total=6683.63, n_correct=3576.5, ppl=5.77, accuracy=53.511, wps=18500.9, ups=1.38, wpb=13367.3, bsz=449.8, num_updates=30000, lr=8.16497e-05, gnorm=0.558, clip=0, loss_scale=2, train_wall=72, gb_free=14, wall=27717
2023-09-06 08:56:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:57:24 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.259 | trans_loss 5.684 | nll_loss 3.126 | w2v_ctc_loss 1.356 | task_loss 8.483 | task_loss_gen 12.601 | contrastive_loss 0 | total 6138.43 | n_correct 3547.57 | ppl 8.73 | accuracy 57.793 | uer 20.969 | wer 22.689 | raw_wer 22.689 | bleu 12.07 | wps 1467.5 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 12.07
2023-09-06 08:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-09-06 08:57:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-06 08:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-06 08:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 12.07) (writing took 15.432711002067663 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 08:58:53 | INFO | train_inner | epoch 026:    342 / 1191 loss=2.167, trans_loss=5.113, nll_loss=2.434, w2v_ctc_loss=0.742, task_loss=2.512, task_loss_gen=3.884, contrastive_loss=0, total=6872.19, n_correct=3869.25, ppl=5.4, accuracy=56.303, wps=10958.6, ups=0.8, wpb=13744.4, bsz=495.7, num_updates=30100, lr=8.15139e-05, gnorm=0.519, clip=0, loss_scale=2, train_wall=72, gb_free=13.8, wall=27842
2023-09-06 09:00:05 | INFO | train_inner | epoch 026:    442 / 1191 loss=2.147, trans_loss=5.072, nll_loss=2.379, w2v_ctc_loss=0.746, task_loss=2.866, task_loss_gen=4.669, contrastive_loss=0, total=6595.24, n_correct=3799.21, ppl=5.2, accuracy=57.605, wps=18089.9, ups=1.37, wpb=13190.5, bsz=428.8, num_updates=30200, lr=8.13788e-05, gnorm=0.562, clip=0, loss_scale=2, train_wall=72, gb_free=14.1, wall=27915
2023-09-06 09:01:19 | INFO | train_inner | epoch 026:    542 / 1191 loss=2.118, trans_loss=5.033, nll_loss=2.331, w2v_ctc_loss=0.741, task_loss=2.842, task_loss_gen=4.549, contrastive_loss=0, total=6665.83, n_correct=3923.94, ppl=5.03, accuracy=58.866, wps=18165.2, ups=1.36, wpb=13331.7, bsz=447.8, num_updates=30300, lr=8.12444e-05, gnorm=0.529, clip=0, loss_scale=2, train_wall=73, gb_free=14.1, wall=27989
2023-09-06 09:02:31 | INFO | train_inner | epoch 026:    642 / 1191 loss=2.104, trans_loss=5.01, nll_loss=2.298, w2v_ctc_loss=0.745, task_loss=3.008, task_loss_gen=4.8, contrastive_loss=0, total=6614.16, n_correct=3950.8, ppl=4.92, accuracy=59.732, wps=18282.6, ups=1.38, wpb=13228.3, bsz=426.8, num_updates=30400, lr=8.11107e-05, gnorm=0.516, clip=0, loss_scale=2, train_wall=72, gb_free=14.3, wall=28061
2023-09-06 09:03:44 | INFO | train_inner | epoch 026:    742 / 1191 loss=2.08, trans_loss=4.981, nll_loss=2.263, w2v_ctc_loss=0.74, task_loss=2.851, task_loss_gen=4.419, contrastive_loss=0, total=6774.24, n_correct=4112.97, ppl=4.8, accuracy=60.715, wps=18564.1, ups=1.37, wpb=13548.5, bsz=446.6, num_updates=30500, lr=8.09776e-05, gnorm=0.506, clip=0, loss_scale=2, train_wall=72, gb_free=11.9, wall=28134
2023-09-06 09:04:57 | INFO | train_inner | epoch 026:    842 / 1191 loss=2.064, trans_loss=4.956, nll_loss=2.233, w2v_ctc_loss=0.736, task_loss=2.777, task_loss_gen=4.442, contrastive_loss=0, total=6656.57, n_correct=4086.44, ppl=4.7, accuracy=61.39, wps=18357.9, ups=1.38, wpb=13313.1, bsz=453.7, num_updates=30600, lr=8.08452e-05, gnorm=0.522, clip=0, loss_scale=2, train_wall=72, gb_free=13.1, wall=28207
2023-09-06 09:06:09 | INFO | train_inner | epoch 026:    942 / 1191 loss=2.06, trans_loss=4.949, nll_loss=2.222, w2v_ctc_loss=0.746, task_loss=2.851, task_loss_gen=4.403, contrastive_loss=0, total=6706.19, n_correct=4145.79, ppl=4.67, accuracy=61.82, wps=18531.9, ups=1.38, wpb=13412.4, bsz=451.6, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=2, train_wall=72, gb_free=12.1, wall=28279
2023-09-06 09:07:22 | INFO | train_inner | epoch 026:   1042 / 1191 loss=2.052, trans_loss=4.935, nll_loss=2.205, w2v_ctc_loss=0.745, task_loss=2.932, task_loss_gen=4.525, contrastive_loss=0, total=6685.17, n_correct=4156.33, ppl=4.61, accuracy=62.172, wps=18421.6, ups=1.38, wpb=13370.3, bsz=443.6, num_updates=30800, lr=8.05823e-05, gnorm=0.525, clip=0, loss_scale=2, train_wall=72, gb_free=13, wall=28352
2023-09-06 09:08:35 | INFO | train_inner | epoch 026:   1142 / 1191 loss=2.032, trans_loss=4.92, nll_loss=2.186, w2v_ctc_loss=0.729, task_loss=2.715, task_loss_gen=4.196, contrastive_loss=0, total=6806.87, n_correct=4274.48, ppl=4.55, accuracy=62.797, wps=18638.7, ups=1.37, wpb=13613.7, bsz=478.9, num_updates=30900, lr=8.04518e-05, gnorm=0.51, clip=0, loss_scale=2, train_wall=72, gb_free=10.1, wall=28425
2023-09-06 09:09:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
2023-09-06 09:09:47 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.197 | nll_loss 2.498 | w2v_ctc_loss 1.325 | task_loss 14.351 | task_loss_gen 12.32 | contrastive_loss 0 | total 6138.43 | n_correct 4033.43 | ppl 5.65 | accuracy 65.708 | uer 19.913 | wer 21.376 | raw_wer 21.376 | bleu 22.34 | wps 1454 | wpb 6138.4 | bsz 201.1 | num_updates 30949 | best_bleu 22.34
2023-09-06 09:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30949 updates
2023-09-06 09:09:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 26 @ 30949 updates, score 22.34) (writing took 13.240448824013583 seconds)
2023-09-06 09:10:01 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-06 09:10:01 | INFO | train | epoch 026 | loss 2.126 | trans_loss 5.049 | nll_loss 2.351 | w2v_ctc_loss 0.737 | task_loss 2.837 | task_loss_gen 4.413 | contrastive_loss 0 | total 6703.69 | n_correct 3913.7 | ppl 5.1 | accuracy 58.381 | wps 16348.2 | ups 1.22 | wpb 13407.4 | bsz 452.1 | num_updates 30949 | lr 8.03881e-05 | gnorm 0.542 | clip 0 | loss_scale 2 | train_wall 858 | gb_free 12.3 | wall 28511
2023-09-06 09:10:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:10:01 | INFO | fairseq.trainer | begin training epoch 27
2023-09-06 09:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:10:46 | INFO | train_inner | epoch 027:     51 / 1191 loss=2.03, trans_loss=4.907, nll_loss=2.169, w2v_ctc_loss=0.736, task_loss=2.931, task_loss_gen=4.517, contrastive_loss=0, total=6618.74, n_correct=4177.2, ppl=4.5, accuracy=63.112, wps=10123.4, ups=0.76, wpb=13237.5, bsz=439.8, num_updates=31000, lr=8.03219e-05, gnorm=0.534, clip=0, loss_scale=2, train_wall=72, gb_free=14.3, wall=28555
2023-09-06 09:11:58 | INFO | train_inner | epoch 027:    151 / 1191 loss=2.02, trans_loss=4.891, nll_loss=2.148, w2v_ctc_loss=0.73, task_loss=2.76, task_loss_gen=4.342, contrastive_loss=0, total=6722.07, n_correct=4267.92, ppl=4.43, accuracy=63.491, wps=18488.8, ups=1.38, wpb=13444.1, bsz=463.7, num_updates=31100, lr=8.01927e-05, gnorm=0.487, clip=0, loss_scale=2, train_wall=72, gb_free=13.2, wall=28628
2023-09-06 09:13:11 | INFO | train_inner | epoch 027:    251 / 1191 loss=2.003, trans_loss=4.878, nll_loss=2.133, w2v_ctc_loss=0.716, task_loss=2.614, task_loss_gen=4.046, contrastive_loss=0, total=6827.01, n_correct=4368.94, ppl=4.39, accuracy=63.995, wps=18842.5, ups=1.38, wpb=13654, bsz=484.7, num_updates=31200, lr=8.00641e-05, gnorm=0.504, clip=0, loss_scale=2, train_wall=72, gb_free=13.2, wall=28701
2023-09-06 09:14:24 | INFO | train_inner | epoch 027:    351 / 1191 loss=2.001, trans_loss=4.873, nll_loss=2.126, w2v_ctc_loss=0.715, task_loss=2.852, task_loss_gen=4.255, contrastive_loss=0, total=6733.4, n_correct=4318.58, ppl=4.37, accuracy=64.137, wps=18449.6, ups=1.37, wpb=13466.8, bsz=465.5, num_updates=31300, lr=7.99361e-05, gnorm=0.561, clip=0, loss_scale=2, train_wall=72, gb_free=10.7, wall=28774
2023-09-06 09:15:37 | INFO | train_inner | epoch 027:    451 / 1191 loss=2.014, trans_loss=4.884, nll_loss=2.14, w2v_ctc_loss=0.736, task_loss=3.189, task_loss_gen=4.656, contrastive_loss=0, total=6623.81, n_correct=4238.57, ppl=4.41, accuracy=63.99, wps=18176.3, ups=1.37, wpb=13247.6, bsz=439.7, num_updates=31400, lr=7.98087e-05, gnorm=0.531, clip=0, loss_scale=2, train_wall=72, gb_free=13.3, wall=28846
2023-09-06 09:16:49 | INFO | train_inner | epoch 027:    551 / 1191 loss=1.997, trans_loss=4.862, nll_loss=2.112, w2v_ctc_loss=0.723, task_loss=2.907, task_loss_gen=4.265, contrastive_loss=0, total=6739.24, n_correct=4348.17, ppl=4.32, accuracy=64.52, wps=18556.9, ups=1.38, wpb=13478.5, bsz=458.5, num_updates=31500, lr=7.96819e-05, gnorm=0.515, clip=0, loss_scale=2, train_wall=72, gb_free=12.2, wall=28919
2023-09-06 09:18:02 | INFO | train_inner | epoch 027:    651 / 1191 loss=1.993, trans_loss=4.859, nll_loss=2.108, w2v_ctc_loss=0.712, task_loss=3.004, task_loss_gen=4.414, contrastive_loss=0, total=6706.8, n_correct=4333.11, ppl=4.31, accuracy=64.608, wps=18536.7, ups=1.38, wpb=13413.6, bsz=447.4, num_updates=31600, lr=7.95557e-05, gnorm=0.521, clip=0, loss_scale=2, train_wall=72, gb_free=13.7, wall=28991
2023-09-06 09:19:14 | INFO | train_inner | epoch 027:    751 / 1191 loss=1.992, trans_loss=4.855, nll_loss=2.104, w2v_ctc_loss=0.721, task_loss=3.083, task_loss_gen=4.541, contrastive_loss=0, total=6683.25, n_correct=4327.73, ppl=4.3, accuracy=64.755, wps=18504.8, ups=1.38, wpb=13366.5, bsz=446.6, num_updates=31700, lr=7.94301e-05, gnorm=0.55, clip=0, loss_scale=2, train_wall=72, gb_free=11.1, wall=29064
2023-09-06 09:20:27 | INFO | train_inner | epoch 027:    851 / 1191 loss=1.996, trans_loss=4.856, nll_loss=2.104, w2v_ctc_loss=0.729, task_loss=3.255, task_loss_gen=4.684, contrastive_loss=0, total=6642.36, n_correct=4298.6, ppl=4.3, accuracy=64.715, wps=18244.1, ups=1.37, wpb=13284.7, bsz=437.2, num_updates=31800, lr=7.93052e-05, gnorm=0.553, clip=0, loss_scale=2, train_wall=72, gb_free=11.9, wall=29136
2023-09-06 09:21:39 | INFO | train_inner | epoch 027:    951 / 1191 loss=1.993, trans_loss=4.854, nll_loss=2.103, w2v_ctc_loss=0.723, task_loss=3.337, task_loss_gen=4.707, contrastive_loss=0, total=6647.74, n_correct=4312.7, ppl=4.29, accuracy=64.875, wps=18360.6, ups=1.38, wpb=13295.5, bsz=427.9, num_updates=31900, lr=7.91808e-05, gnorm=0.538, clip=0, loss_scale=4, train_wall=72, gb_free=13.6, wall=29209
2023-09-06 09:22:51 | INFO | train_inner | epoch 027:   1051 / 1191 loss=1.983, trans_loss=4.847, nll_loss=2.093, w2v_ctc_loss=0.718, task_loss=3.011, task_loss_gen=4.512, contrastive_loss=0, total=6641.77, n_correct=4319.98, ppl=4.27, accuracy=65.043, wps=18370.5, ups=1.38, wpb=13283.5, bsz=447.4, num_updates=32000, lr=7.90569e-05, gnorm=0.436, clip=0, loss_scale=4, train_wall=72, gb_free=14.3, wall=29281
2023-09-06 09:22:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:23:26 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.836 | trans_loss 5.087 | nll_loss 2.355 | w2v_ctc_loss 1.295 | task_loss 14.665 | task_loss_gen 12.608 | contrastive_loss 0 | total 6138.43 | n_correct 4147.14 | ppl 5.11 | accuracy 67.56 | uer 19.3 | wer 20.699 | raw_wer 20.699 | bleu 24.64 | wps 1599.9 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 24.64
2023-09-06 09:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32000 updates
2023-09-06 09:23:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-06 09:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-06 09:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt (epoch 27 @ 32000 updates, score 24.64) (writing took 16.214326540008187 seconds)
2023-09-06 09:24:56 | INFO | train_inner | epoch 027:   1151 / 1191 loss=1.976, trans_loss=4.836, nll_loss=2.08, w2v_ctc_loss=0.71, task_loss=2.898, task_loss_gen=4.392, contrastive_loss=0, total=6761.49, n_correct=4420.06, ppl=4.23, accuracy=65.371, wps=10882.8, ups=0.8, wpb=13523, bsz=454.9, num_updates=32100, lr=7.89337e-05, gnorm=0.431, clip=0, loss_scale=4, train_wall=72, gb_free=13.9, wall=29405
2023-09-06 09:25:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:25:59 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.837 | trans_loss 5.08 | nll_loss 2.344 | w2v_ctc_loss 1.314 | task_loss 10.048 | task_loss_gen 12.584 | contrastive_loss 0 | total 6138.43 | n_correct 4148.57 | ppl 5.08 | accuracy 67.584 | uer 19.068 | wer 20.454 | raw_wer 20.454 | bleu 24.72 | wps 1629.1 | wpb 6138.4 | bsz 201.1 | num_updates 32140 | best_bleu 24.72
2023-09-06 09:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32140 updates
2023-09-06 09:25:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:26:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 27 @ 32140 updates, score 24.72) (writing took 13.905794541002251 seconds)
2023-09-06 09:26:13 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-06 09:26:13 | INFO | train | epoch 027 | loss 1.997 | trans_loss 4.863 | nll_loss 2.114 | w2v_ctc_loss 0.72 | task_loss 2.966 | task_loss_gen 4.425 | contrastive_loss 0 | total 6703.69 | n_correct 4323.29 | ppl 4.33 | accuracy 64.491 | wps 16426.9 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 32140 | lr 7.88846e-05 | gnorm 0.51 | clip 0 | loss_scale 4 | train_wall 857 | gb_free 13.1 | wall 29483
2023-09-06 09:26:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:26:13 | INFO | fairseq.trainer | begin training epoch 28
2023-09-06 09:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:27:04 | INFO | train_inner | epoch 028:     60 / 1191 loss=1.962, trans_loss=4.816, nll_loss=2.055, w2v_ctc_loss=0.699, task_loss=2.775, task_loss_gen=4.487, contrastive_loss=0, total=6694.65, n_correct=4404.54, ppl=4.15, accuracy=65.792, wps=10439.6, ups=0.78, wpb=13389.3, bsz=453.1, num_updates=32200, lr=7.8811e-05, gnorm=0.431, clip=0, loss_scale=4, train_wall=71, gb_free=12.5, wall=29534
2023-09-06 09:28:16 | INFO | train_inner | epoch 028:    160 / 1191 loss=1.97, trans_loss=4.818, nll_loss=2.056, w2v_ctc_loss=0.714, task_loss=2.971, task_loss_gen=4.706, contrastive_loss=0, total=6668.32, n_correct=4384.99, ppl=4.16, accuracy=65.759, wps=18487.7, ups=1.39, wpb=13336.6, bsz=433.5, num_updates=32300, lr=7.86889e-05, gnorm=0.432, clip=0, loss_scale=4, train_wall=72, gb_free=10.9, wall=29606
2023-09-06 09:29:28 | INFO | train_inner | epoch 028:    260 / 1191 loss=1.962, trans_loss=4.814, nll_loss=2.052, w2v_ctc_loss=0.703, task_loss=2.973, task_loss_gen=4.559, contrastive_loss=0, total=6679.49, n_correct=4404.84, ppl=4.15, accuracy=65.946, wps=18571.5, ups=1.39, wpb=13359, bsz=449.8, num_updates=32400, lr=7.85674e-05, gnorm=0.448, clip=0, loss_scale=4, train_wall=71, gb_free=14.6, wall=29678
2023-09-06 09:30:41 | INFO | train_inner | epoch 028:    360 / 1191 loss=1.958, trans_loss=4.807, nll_loss=2.042, w2v_ctc_loss=0.708, task_loss=2.936, task_loss_gen=4.426, contrastive_loss=0, total=6774.84, n_correct=4475.37, ppl=4.12, accuracy=66.059, wps=18576.6, ups=1.37, wpb=13549.7, bsz=468.5, num_updates=32500, lr=7.84465e-05, gnorm=0.462, clip=0, loss_scale=4, train_wall=72, gb_free=12.2, wall=29751
2023-09-06 09:31:55 | INFO | train_inner | epoch 028:    460 / 1191 loss=1.958, trans_loss=4.808, nll_loss=2.044, w2v_ctc_loss=0.704, task_loss=2.876, task_loss_gen=4.358, contrastive_loss=0, total=6746.47, n_correct=4459.03, ppl=4.13, accuracy=66.094, wps=18333.2, ups=1.36, wpb=13492.9, bsz=465.1, num_updates=32600, lr=7.8326e-05, gnorm=0.441, clip=0, loss_scale=4, train_wall=73, gb_free=14.5, wall=29824
2023-09-06 09:33:06 | INFO | train_inner | epoch 028:    560 / 1191 loss=1.954, trans_loss=4.805, nll_loss=2.04, w2v_ctc_loss=0.7, task_loss=2.876, task_loss_gen=4.413, contrastive_loss=0, total=6711.63, n_correct=4442.11, ppl=4.11, accuracy=66.185, wps=18833.7, ups=1.4, wpb=13423.3, bsz=454, num_updates=32700, lr=7.82062e-05, gnorm=0.444, clip=0, loss_scale=4, train_wall=71, gb_free=11.9, wall=29896
2023-09-06 09:34:18 | INFO | train_inner | epoch 028:    660 / 1191 loss=1.951, trans_loss=4.8, nll_loss=2.035, w2v_ctc_loss=0.697, task_loss=2.977, task_loss_gen=4.542, contrastive_loss=0, total=6742.02, n_correct=4473.32, ppl=4.1, accuracy=66.35, wps=18656.7, ups=1.38, wpb=13484, bsz=456, num_updates=32800, lr=7.80869e-05, gnorm=0.448, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=29968
2023-09-06 09:35:31 | INFO | train_inner | epoch 028:    760 / 1191 loss=1.954, trans_loss=4.801, nll_loss=2.036, w2v_ctc_loss=0.706, task_loss=2.929, task_loss_gen=4.528, contrastive_loss=0, total=6702.27, n_correct=4440.3, ppl=4.1, accuracy=66.251, wps=18359.4, ups=1.37, wpb=13404.5, bsz=455.2, num_updates=32900, lr=7.79681e-05, gnorm=0.446, clip=0, loss_scale=4, train_wall=72, gb_free=13.3, wall=30041
2023-09-06 09:36:43 | INFO | train_inner | epoch 028:    860 / 1191 loss=1.949, trans_loss=4.796, nll_loss=2.03, w2v_ctc_loss=0.699, task_loss=2.926, task_loss_gen=4.495, contrastive_loss=0, total=6652.38, n_correct=4418.8, ppl=4.08, accuracy=66.424, wps=18426.1, ups=1.38, wpb=13304.8, bsz=454.3, num_updates=33000, lr=7.78499e-05, gnorm=0.442, clip=0, loss_scale=4, train_wall=71, gb_free=13.4, wall=30113
2023-09-06 09:37:56 | INFO | train_inner | epoch 028:    960 / 1191 loss=1.958, trans_loss=4.803, nll_loss=2.038, w2v_ctc_loss=0.711, task_loss=2.961, task_loss_gen=4.832, contrastive_loss=0, total=6636.39, n_correct=4397.27, ppl=4.11, accuracy=66.26, wps=18270.2, ups=1.38, wpb=13272.8, bsz=433.5, num_updates=33100, lr=7.77322e-05, gnorm=0.423, clip=0, loss_scale=4, train_wall=72, gb_free=13.8, wall=30186
2023-09-06 09:39:09 | INFO | train_inner | epoch 028:   1060 / 1191 loss=1.948, trans_loss=4.798, nll_loss=2.033, w2v_ctc_loss=0.691, task_loss=2.828, task_loss_gen=4.752, contrastive_loss=0, total=6686.82, n_correct=4439.06, ppl=4.09, accuracy=66.385, wps=18354.4, ups=1.37, wpb=13373.6, bsz=442.3, num_updates=33200, lr=7.76151e-05, gnorm=0.429, clip=0, loss_scale=4, train_wall=72, gb_free=14.8, wall=30259
2023-09-06 09:40:22 | INFO | train_inner | epoch 028:   1160 / 1191 loss=1.947, trans_loss=4.795, nll_loss=2.028, w2v_ctc_loss=0.695, task_loss=3.037, task_loss_gen=4.693, contrastive_loss=0, total=6684.12, n_correct=4447.74, ppl=4.08, accuracy=66.542, wps=18305.5, ups=1.37, wpb=13368.2, bsz=446, num_updates=33300, lr=7.74984e-05, gnorm=0.453, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=30332
2023-09-06 09:40:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:41:18 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.789 | trans_loss 5.032 | nll_loss 2.287 | w2v_ctc_loss 1.263 | task_loss 13.391 | task_loss_gen 12.57 | contrastive_loss 0 | total 6138.43 | n_correct 4203.29 | ppl 4.88 | accuracy 68.475 | uer 19.228 | wer 20.439 | raw_wer 20.439 | bleu 25.9 | wps 1696.6 | wpb 6138.4 | bsz 201.1 | num_updates 33331 | best_bleu 25.9
2023-09-06 09:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33331 updates
2023-09-06 09:41:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:41:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 28 @ 33331 updates, score 25.9) (writing took 14.04042054596357 seconds)
2023-09-06 09:41:32 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-06 09:41:32 | INFO | train | epoch 028 | loss 1.955 | trans_loss 4.804 | nll_loss 2.039 | w2v_ctc_loss 0.702 | task_loss 2.911 | task_loss_gen 4.544 | contrastive_loss 0 | total 6703.69 | n_correct 4438.71 | ppl 4.11 | accuracy 66.213 | wps 17367.1 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 33331 | lr 7.74624e-05 | gnorm 0.442 | clip 0 | loss_scale 4 | train_wall 856 | gb_free 13.2 | wall 30402
2023-09-06 09:41:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:41:32 | INFO | fairseq.trainer | begin training epoch 29
2023-09-06 09:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:42:31 | INFO | train_inner | epoch 029:     69 / 1191 loss=1.93, trans_loss=4.772, nll_loss=1.998, w2v_ctc_loss=0.685, task_loss=2.667, task_loss_gen=4.192, contrastive_loss=0, total=6795.78, n_correct=4566.82, ppl=4, accuracy=67.201, wps=10541.9, ups=0.78, wpb=13591.6, bsz=473, num_updates=33400, lr=7.73823e-05, gnorm=0.422, clip=0, loss_scale=4, train_wall=72, gb_free=13.1, wall=30461
2023-09-06 09:43:43 | INFO | train_inner | epoch 029:    169 / 1191 loss=1.936, trans_loss=4.776, nll_loss=2.004, w2v_ctc_loss=0.688, task_loss=2.924, task_loss_gen=4.592, contrastive_loss=0, total=6680.96, n_correct=4474.77, ppl=4.01, accuracy=66.978, wps=18575.2, ups=1.39, wpb=13361.9, bsz=438.8, num_updates=33500, lr=7.72667e-05, gnorm=0.434, clip=0, loss_scale=4, train_wall=71, gb_free=11.7, wall=30533
2023-09-06 09:44:56 | INFO | train_inner | epoch 029:    269 / 1191 loss=1.933, trans_loss=4.778, nll_loss=2.007, w2v_ctc_loss=0.681, task_loss=2.928, task_loss_gen=4.557, contrastive_loss=0, total=6669.15, n_correct=4466.1, ppl=4.02, accuracy=66.967, wps=18113.1, ups=1.36, wpb=13338.3, bsz=454, num_updates=33600, lr=7.71517e-05, gnorm=0.45, clip=0, loss_scale=4, train_wall=73, gb_free=12, wall=30606
2023-09-06 09:46:09 | INFO | train_inner | epoch 029:    369 / 1191 loss=1.936, trans_loss=4.778, nll_loss=2.007, w2v_ctc_loss=0.691, task_loss=2.853, task_loss_gen=4.557, contrastive_loss=0, total=6753.05, n_correct=4521.23, ppl=4.02, accuracy=66.951, wps=18508.1, ups=1.37, wpb=13506.1, bsz=452.3, num_updates=33700, lr=7.70371e-05, gnorm=0.432, clip=0, loss_scale=4, train_wall=72, gb_free=14.1, wall=30679
2023-09-06 09:47:22 | INFO | train_inner | epoch 029:    469 / 1191 loss=1.929, trans_loss=4.773, nll_loss=2.001, w2v_ctc_loss=0.682, task_loss=2.8, task_loss_gen=4.417, contrastive_loss=0, total=6767.55, n_correct=4542.99, ppl=4, accuracy=67.129, wps=18607.6, ups=1.37, wpb=13535.1, bsz=469.6, num_updates=33800, lr=7.69231e-05, gnorm=0.452, clip=0, loss_scale=4, train_wall=72, gb_free=15.1, wall=30752
2023-09-06 09:48:35 | INFO | train_inner | epoch 029:    569 / 1191 loss=1.945, trans_loss=4.78, nll_loss=2.009, w2v_ctc_loss=0.708, task_loss=3.223, task_loss_gen=4.894, contrastive_loss=0, total=6601.9, n_correct=4412.15, ppl=4.03, accuracy=66.832, wps=18071.4, ups=1.37, wpb=13203.8, bsz=422.9, num_updates=33900, lr=7.68095e-05, gnorm=0.46, clip=0, loss_scale=4, train_wall=72, gb_free=13.9, wall=30825
2023-09-06 09:49:47 | INFO | train_inner | epoch 029:    669 / 1191 loss=1.925, trans_loss=4.761, nll_loss=1.985, w2v_ctc_loss=0.685, task_loss=2.713, task_loss_gen=4.431, contrastive_loss=0, total=6730.73, n_correct=4535.37, ppl=3.96, accuracy=67.383, wps=18696.4, ups=1.39, wpb=13461.5, bsz=461.6, num_updates=34000, lr=7.66965e-05, gnorm=0.397, clip=0, loss_scale=8, train_wall=71, gb_free=12.8, wall=30897
2023-09-06 09:49:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:50:21 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.768 | trans_loss 5.009 | nll_loss 2.26 | w2v_ctc_loss 1.243 | task_loss 11.092 | task_loss_gen 12.589 | contrastive_loss 0 | total 6138.43 | n_correct 4231 | ppl 4.79 | accuracy 68.926 | uer 18.798 | wer 20.212 | raw_wer 20.212 | bleu 26.35 | wps 1688.4 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 26.35
2023-09-06 09:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-09-06 09:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-06 09:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-06 09:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 26.35) (writing took 16.268881382071413 seconds)
2023-09-06 09:51:50 | INFO | train_inner | epoch 029:    769 / 1191 loss=1.924, trans_loss=4.762, nll_loss=1.987, w2v_ctc_loss=0.683, task_loss=2.658, task_loss_gen=4.56, contrastive_loss=0, total=6668.92, n_correct=4497.76, ppl=3.96, accuracy=67.444, wps=10885.2, ups=0.82, wpb=13337.8, bsz=453.3, num_updates=34100, lr=7.6584e-05, gnorm=0.393, clip=0, loss_scale=8, train_wall=71, gb_free=13.6, wall=31020
2023-09-06 09:53:03 | INFO | train_inner | epoch 029:    869 / 1191 loss=1.933, trans_loss=4.772, nll_loss=1.999, w2v_ctc_loss=0.692, task_loss=2.713, task_loss_gen=4.985, contrastive_loss=0, total=6644.69, n_correct=4457.26, ppl=4, accuracy=67.08, wps=18224.1, ups=1.37, wpb=13289.4, bsz=431.6, num_updates=34200, lr=7.64719e-05, gnorm=0.4, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=31092
2023-09-06 09:54:16 | INFO | train_inner | epoch 029:    969 / 1191 loss=1.929, trans_loss=4.766, nll_loss=1.993, w2v_ctc_loss=0.692, task_loss=2.469, task_loss_gen=4.771, contrastive_loss=0, total=6741.09, n_correct=4532.78, ppl=3.98, accuracy=67.241, wps=18480.7, ups=1.37, wpb=13482.2, bsz=463.9, num_updates=34300, lr=7.63604e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=31165
2023-09-06 09:55:28 | INFO | train_inner | epoch 029:   1069 / 1191 loss=1.925, trans_loss=4.762, nll_loss=1.988, w2v_ctc_loss=0.686, task_loss=2.739, task_loss_gen=4.675, contrastive_loss=0, total=6710.1, n_correct=4527.2, ppl=3.97, accuracy=67.468, wps=18520.8, ups=1.38, wpb=13420.2, bsz=455.2, num_updates=34400, lr=7.62493e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=13.4, wall=31238
2023-09-06 09:56:41 | INFO | train_inner | epoch 029:   1169 / 1191 loss=1.919, trans_loss=4.761, nll_loss=1.987, w2v_ctc_loss=0.677, task_loss=2.432, task_loss_gen=4.643, contrastive_loss=0, total=6757.48, n_correct=4566.6, ppl=3.96, accuracy=67.578, wps=18486.7, ups=1.37, wpb=13515, bsz=464.2, num_updates=34500, lr=7.61387e-05, gnorm=0.395, clip=0, loss_scale=8, train_wall=73, gb_free=11.9, wall=31311
2023-09-06 09:56:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:57:31 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.757 | trans_loss 4.991 | nll_loss 2.238 | w2v_ctc_loss 1.246 | task_loss 14.886 | task_loss_gen 12.959 | contrastive_loss 0 | total 6138.43 | n_correct 4247.14 | ppl 4.72 | accuracy 69.189 | uer 18.533 | wer 19.955 | raw_wer 19.955 | bleu 26.79 | wps 1686.6 | wpb 6138.4 | bsz 201.1 | num_updates 34522 | best_bleu 26.79
2023-09-06 09:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34522 updates
2023-09-06 09:57:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 29 @ 34522 updates, score 26.79) (writing took 12.81016522902064 seconds)
2023-09-06 09:57:44 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-06 09:57:44 | INFO | train | epoch 029 | loss 1.93 | trans_loss 4.77 | nll_loss 1.997 | w2v_ctc_loss 0.687 | task_loss 2.76 | task_loss_gen 4.629 | contrastive_loss 0 | total 6703.69 | n_correct 4504.72 | ppl 3.99 | accuracy 67.198 | wps 16430 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 34522 | lr 7.61144e-05 | gnorm 0.418 | clip 0 | loss_scale 8 | train_wall 858 | gb_free 13.3 | wall 31374
2023-09-06 09:57:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:57:44 | INFO | fairseq.trainer | begin training epoch 30
2023-09-06 09:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:58:48 | INFO | train_inner | epoch 030:     78 / 1191 loss=1.911, trans_loss=4.747, nll_loss=1.968, w2v_ctc_loss=0.673, task_loss=2.08, task_loss_gen=4.397, contrastive_loss=0, total=6833.03, n_correct=4633.34, ppl=3.91, accuracy=67.808, wps=10750.3, ups=0.79, wpb=13666.1, bsz=481.4, num_updates=34600, lr=7.60286e-05, gnorm=0.381, clip=0, loss_scale=8, train_wall=72, gb_free=11.9, wall=31438
2023-09-06 10:00:00 | INFO | train_inner | epoch 030:    178 / 1191 loss=1.91, trans_loss=4.744, nll_loss=1.965, w2v_ctc_loss=0.669, task_loss=2.394, task_loss_gen=4.81, contrastive_loss=0, total=6687.83, n_correct=4540.64, ppl=3.9, accuracy=67.894, wps=18628.9, ups=1.39, wpb=13375.7, bsz=449, num_updates=34700, lr=7.5919e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=71, gb_free=13.3, wall=31510
2023-09-06 10:01:13 | INFO | train_inner | epoch 030:    278 / 1191 loss=1.911, trans_loss=4.74, nll_loss=1.959, w2v_ctc_loss=0.676, task_loss=2.611, task_loss_gen=4.552, contrastive_loss=0, total=6754.94, n_correct=4588.02, ppl=3.89, accuracy=67.921, wps=18626.3, ups=1.38, wpb=13509.9, bsz=459.9, num_updates=34800, lr=7.58098e-05, gnorm=0.391, clip=0, loss_scale=8, train_wall=72, gb_free=11.4, wall=31582
2023-09-06 10:02:27 | INFO | train_inner | epoch 030:    378 / 1191 loss=1.905, trans_loss=4.742, nll_loss=1.962, w2v_ctc_loss=0.666, task_loss=2.324, task_loss_gen=4.259, contrastive_loss=0, total=6859.61, n_correct=4662, ppl=3.9, accuracy=67.963, wps=18520.3, ups=1.35, wpb=13719.2, bsz=488, num_updates=34900, lr=7.57011e-05, gnorm=0.376, clip=0, loss_scale=8, train_wall=73, gb_free=11.8, wall=31657
2023-09-06 10:03:39 | INFO | train_inner | epoch 030:    478 / 1191 loss=1.916, trans_loss=4.745, nll_loss=1.966, w2v_ctc_loss=0.681, task_loss=2.665, task_loss_gen=4.883, contrastive_loss=0, total=6645.7, n_correct=4503.59, ppl=3.91, accuracy=67.767, wps=18340, ups=1.38, wpb=13291.4, bsz=444.7, num_updates=35000, lr=7.55929e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=31729
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 10:04:52 | INFO | train_inner | epoch 030:    578 / 1191 loss=1.914, trans_loss=4.744, nll_loss=1.965, w2v_ctc_loss=0.678, task_loss=2.615, task_loss_gen=4.838, contrastive_loss=0, total=6672.87, n_correct=4531.08, ppl=3.9, accuracy=67.903, wps=18400.2, ups=1.38, wpb=13345.7, bsz=443.6, num_updates=35100, lr=7.54851e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=31802
2023-09-06 10:06:05 | INFO | train_inner | epoch 030:    678 / 1191 loss=1.917, trans_loss=4.743, nll_loss=1.963, w2v_ctc_loss=0.681, task_loss=2.689, task_loss_gen=5.237, contrastive_loss=0, total=6565.21, n_correct=4451.16, ppl=3.9, accuracy=67.799, wps=18020.9, ups=1.37, wpb=13130.4, bsz=421.9, num_updates=35200, lr=7.53778e-05, gnorm=0.396, clip=0, loss_scale=8, train_wall=72, gb_free=10.9, wall=31874
2023-09-06 10:07:18 | INFO | train_inner | epoch 030:    778 / 1191 loss=1.917, trans_loss=4.745, nll_loss=1.967, w2v_ctc_loss=0.681, task_loss=2.775, task_loss_gen=4.902, contrastive_loss=0, total=6657.47, n_correct=4513.42, ppl=3.91, accuracy=67.795, wps=18128.6, ups=1.36, wpb=13314.9, bsz=440.1, num_updates=35300, lr=7.5271e-05, gnorm=0.395, clip=0, loss_scale=8, train_wall=73, gb_free=13.9, wall=31948
2023-09-06 10:08:31 | INFO | train_inner | epoch 030:    878 / 1191 loss=1.913, trans_loss=4.745, nll_loss=1.967, w2v_ctc_loss=0.675, task_loss=2.611, task_loss_gen=5.005, contrastive_loss=0, total=6666.67, n_correct=4526.6, ppl=3.91, accuracy=67.899, wps=18317, ups=1.37, wpb=13333.3, bsz=443.1, num_updates=35400, lr=7.51646e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=32021
2023-09-06 10:09:44 | INFO | train_inner | epoch 030:    978 / 1191 loss=1.914, trans_loss=4.742, nll_loss=1.963, w2v_ctc_loss=0.682, task_loss=2.741, task_loss_gen=4.855, contrastive_loss=0, total=6645.69, n_correct=4512.27, ppl=3.9, accuracy=67.898, wps=18240.1, ups=1.37, wpb=13291.4, bsz=445.1, num_updates=35500, lr=7.50587e-05, gnorm=0.397, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=32094
2023-09-06 10:10:56 | INFO | train_inner | epoch 030:   1078 / 1191 loss=1.911, trans_loss=4.742, nll_loss=1.963, w2v_ctc_loss=0.679, task_loss=2.629, task_loss_gen=4.555, contrastive_loss=0, total=6766.02, n_correct=4598.83, ppl=3.9, accuracy=67.97, wps=18603.6, ups=1.37, wpb=13532, bsz=457.1, num_updates=35600, lr=7.49532e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=15.1, wall=32166
2023-09-06 10:12:10 | INFO | train_inner | epoch 030:   1178 / 1191 loss=1.912, trans_loss=4.749, nll_loss=1.972, w2v_ctc_loss=0.674, task_loss=2.42, task_loss_gen=4.709, contrastive_loss=0, total=6709.38, n_correct=4548.32, ppl=3.92, accuracy=67.79, wps=18332, ups=1.37, wpb=13418.8, bsz=457, num_updates=35700, lr=7.48481e-05, gnorm=0.389, clip=0, loss_scale=8, train_wall=73, gb_free=10, wall=32239
2023-09-06 10:12:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
2023-09-06 10:12:52 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.751 | trans_loss 4.97 | nll_loss 2.211 | w2v_ctc_loss 1.275 | task_loss 9.238 | task_loss_gen 13.158 | contrastive_loss 0 | total 6138.43 | n_correct 4269.29 | ppl 4.63 | accuracy 69.55 | uer 18.437 | wer 19.706 | raw_wer 19.706 | bleu 27.04 | wps 1748.2 | wpb 6138.4 | bsz 201.1 | num_updates 35713 | best_bleu 27.04
2023-09-06 10:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35713 updates
2023-09-06 10:12:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 30 @ 35713 updates, score 27.04) (writing took 14.340260511031374 seconds)
2023-09-06 10:13:06 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-06 10:13:06 | INFO | train | epoch 030 | loss 1.912 | trans_loss 4.744 | nll_loss 1.965 | w2v_ctc_loss 0.676 | task_loss 2.542 | task_loss_gen 4.745 | contrastive_loss 0 | total 6703.69 | n_correct 4550.13 | ppl 3.9 | accuracy 67.875 | wps 17314 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 35713 | lr 7.48345e-05 | gnorm 0.391 | clip 0 | loss_scale 8 | train_wall 860 | gb_free 14.2 | wall 32296
2023-09-06 10:13:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:13:07 | INFO | fairseq.trainer | begin training epoch 31
2023-09-06 10:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:14:18 | INFO | train_inner | epoch 031:     87 / 1191 loss=1.907, trans_loss=4.729, nll_loss=1.945, w2v_ctc_loss=0.673, task_loss=2.705, task_loss_gen=5.236, contrastive_loss=0, total=6586.06, n_correct=4498.9, ppl=3.85, accuracy=68.309, wps=10267, ups=0.78, wpb=13172.1, bsz=416.6, num_updates=35800, lr=7.47435e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=12.1, wall=32368
2023-09-06 10:15:31 | INFO | train_inner | epoch 031:    187 / 1191 loss=1.893, trans_loss=4.723, nll_loss=1.938, w2v_ctc_loss=0.656, task_loss=2.436, task_loss_gen=4.599, contrastive_loss=0, total=6738.97, n_correct=4611.03, ppl=3.83, accuracy=68.423, wps=18488.6, ups=1.37, wpb=13477.9, bsz=458.5, num_updates=35900, lr=7.46393e-05, gnorm=0.383, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=32441
2023-09-06 10:16:43 | INFO | train_inner | epoch 031:    287 / 1191 loss=1.903, trans_loss=4.724, nll_loss=1.94, w2v_ctc_loss=0.673, task_loss=2.716, task_loss_gen=5.069, contrastive_loss=0, total=6546.21, n_correct=4475.91, ppl=3.84, accuracy=68.374, wps=18048.2, ups=1.38, wpb=13092.4, bsz=430.8, num_updates=36000, lr=7.45356e-05, gnorm=0.392, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=32513
2023-09-06 10:16:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 10:17:17 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.734 | trans_loss 4.964 | nll_loss 2.201 | w2v_ctc_loss 1.231 | task_loss 8.747 | task_loss_gen 13.472 | contrastive_loss 0 | total 6138.43 | n_correct 4268.86 | ppl 4.6 | accuracy 69.543 | uer 18.306 | wer 19.68 | raw_wer 19.68 | bleu 26.92 | wps 1684.6 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 27.04
2023-09-06 10:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-09-06 10:17:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-06 10:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-06 10:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 26.92) (writing took 10.974562954041176 seconds)
--Backword ST Loss tensor(2049.0725, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1170.2964, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 10:18:41 | INFO | train_inner | epoch 031:    387 / 1191 loss=1.898, trans_loss=4.725, nll_loss=1.941, w2v_ctc_loss=0.665, task_loss=2.196, task_loss_gen=4.917, contrastive_loss=0, total=6748.95, n_correct=4614.5, ppl=3.84, accuracy=68.374, wps=11492.2, ups=0.85, wpb=13497.9, bsz=458.1, num_updates=36100, lr=7.44323e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=71, gb_free=14.5, wall=32631
2023-09-06 10:19:54 | INFO | train_inner | epoch 031:    487 / 1191 loss=1.907, trans_loss=4.734, nll_loss=1.952, w2v_ctc_loss=0.673, task_loss=2.416, task_loss_gen=5.391, contrastive_loss=0, total=6661.78, n_correct=4543.6, ppl=3.87, accuracy=68.204, wps=18289.8, ups=1.37, wpb=13323.6, bsz=426.6, num_updates=36200, lr=7.43294e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=32704
2023-09-06 10:21:06 | INFO | train_inner | epoch 031:    587 / 1191 loss=1.898, trans_loss=4.723, nll_loss=1.939, w2v_ctc_loss=0.666, task_loss=2.099, task_loss_gen=5.167, contrastive_loss=0, total=6681.68, n_correct=4566.23, ppl=3.84, accuracy=68.34, wps=18380, ups=1.38, wpb=13363.4, bsz=451.8, num_updates=36300, lr=7.4227e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=32776
2023-09-06 10:22:18 | INFO | train_inner | epoch 031:    687 / 1191 loss=1.89, trans_loss=4.716, nll_loss=1.93, w2v_ctc_loss=0.658, task_loss=2.014, task_loss_gen=4.605, contrastive_loss=0, total=6839.98, n_correct=4692.91, ppl=3.81, accuracy=68.61, wps=18984.9, ups=1.39, wpb=13680, bsz=478.1, num_updates=36400, lr=7.41249e-05, gnorm=0.37, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=32848
2023-09-06 10:23:32 | INFO | train_inner | epoch 031:    787 / 1191 loss=1.893, trans_loss=4.719, nll_loss=1.934, w2v_ctc_loss=0.664, task_loss=2.114, task_loss_gen=4.815, contrastive_loss=0, total=6796.23, n_correct=4659.66, ppl=3.82, accuracy=68.562, wps=18598.7, ups=1.37, wpb=13592.5, bsz=476.2, num_updates=36500, lr=7.40233e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=73, gb_free=12.5, wall=32921
2023-09-06 10:24:44 | INFO | train_inner | epoch 031:    887 / 1191 loss=1.894, trans_loss=4.722, nll_loss=1.938, w2v_ctc_loss=0.658, task_loss=2.275, task_loss_gen=5.181, contrastive_loss=0, total=6613.41, n_correct=4530.56, ppl=3.83, accuracy=68.506, wps=18184, ups=1.37, wpb=13226.8, bsz=445.6, num_updates=36600, lr=7.39221e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=32994
2023-09-06 10:25:56 | INFO | train_inner | epoch 031:    987 / 1191 loss=1.892, trans_loss=4.716, nll_loss=1.93, w2v_ctc_loss=0.66, task_loss=2.22, task_loss_gen=4.942, contrastive_loss=0, total=6712.51, n_correct=4608.77, ppl=3.81, accuracy=68.659, wps=18617.8, ups=1.39, wpb=13425, bsz=455.1, num_updates=36700, lr=7.38213e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=33066
2023-09-06 10:27:09 | INFO | train_inner | epoch 031:   1087 / 1191 loss=1.886, trans_loss=4.716, nll_loss=1.931, w2v_ctc_loss=0.654, task_loss=1.783, task_loss_gen=4.576, contrastive_loss=0, total=6884.21, n_correct=4730.86, ppl=3.81, accuracy=68.72, wps=19038.7, ups=1.38, wpb=13768.4, bsz=489.3, num_updates=36800, lr=7.3721e-05, gnorm=0.373, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=33139
2023-09-06 10:28:22 | INFO | train_inner | epoch 031:   1187 / 1191 loss=1.893, trans_loss=4.718, nll_loss=1.933, w2v_ctc_loss=0.66, task_loss=2.083, task_loss_gen=5.278, contrastive_loss=0, total=6656.88, n_correct=4566.64, ppl=3.82, accuracy=68.6, wps=18279.1, ups=1.37, wpb=13313.8, bsz=445.6, num_updates=36900, lr=7.3621e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=33211
2023-09-06 10:28:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2797.6106, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1707.4456, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1654.6521, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(929.7510, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3310.4385, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(2004.6670, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1780.8369, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1016.0110, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2112.1719, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1140.2004, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1131.2644, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(637.0609, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1175.3707, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(680.6300, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-06 10:28:58 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.708 | trans_loss 4.957 | nll_loss 2.194 | w2v_ctc_loss 1.162 | task_loss 12.988 | task_loss_gen 12.719 | contrastive_loss 0 | total 6138.43 | n_correct 4285.43 | ppl 4.58 | accuracy 69.813 | uer 18.193 | wer 19.543 | raw_wer 19.543 | bleu 27.35 | wps 1737.4 | wpb 6138.4 | bsz 201.1 | num_updates 36904 | best_bleu 27.35
2023-09-06 10:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36904 updates
2023-09-06 10:28:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 31 @ 36904 updates, score 27.35) (writing took 12.602034433977678 seconds)
2023-09-06 10:29:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-06 10:29:11 | INFO | train | epoch 031 | loss 1.896 | trans_loss 4.722 | nll_loss 1.937 | w2v_ctc_loss 0.663 | task_loss 2.248 | task_loss_gen 4.983 | contrastive_loss 0 | total 6703.69 | n_correct 4590.41 | ppl 3.83 | accuracy 68.476 | wps 16555.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 36904 | lr 7.3617e-05 | gnorm 0.382 | clip 0 | loss_scale 16 | train_wall 858 | gb_free 10 | wall 33261
2023-09-06 10:29:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:29:11 | INFO | fairseq.trainer | begin training epoch 32
2023-09-06 10:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:30:28 | INFO | train_inner | epoch 032:     96 / 1191 loss=1.882, trans_loss=4.699, nll_loss=1.909, w2v_ctc_loss=0.651, task_loss=1.998, task_loss_gen=5.054, contrastive_loss=0, total=6689.32, n_correct=4614.09, ppl=3.75, accuracy=68.977, wps=10565.6, ups=0.79, wpb=13378.6, bsz=452.4, num_updates=37000, lr=7.35215e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=12.1, wall=33338
2023-09-06 10:31:41 | INFO | train_inner | epoch 032:    196 / 1191 loss=1.883, trans_loss=4.708, nll_loss=1.919, w2v_ctc_loss=0.648, task_loss=2.07, task_loss_gen=4.89, contrastive_loss=0, total=6806.67, n_correct=4683.37, ppl=3.78, accuracy=68.806, wps=18748.9, ups=1.38, wpb=13613.3, bsz=466.5, num_updates=37100, lr=7.34223e-05, gnorm=0.376, clip=0, loss_scale=16, train_wall=72, gb_free=10.5, wall=33411
2023-09-06 10:32:54 | INFO | train_inner | epoch 032:    296 / 1191 loss=1.887, trans_loss=4.708, nll_loss=1.92, w2v_ctc_loss=0.656, task_loss=2.264, task_loss_gen=5.149, contrastive_loss=0, total=6678.58, n_correct=4593.79, ppl=3.78, accuracy=68.784, wps=18346.3, ups=1.37, wpb=13357.2, bsz=446.2, num_updates=37200, lr=7.33236e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=33483
2023-09-06 10:34:06 | INFO | train_inner | epoch 032:    396 / 1191 loss=1.882, trans_loss=4.699, nll_loss=1.909, w2v_ctc_loss=0.655, task_loss=1.966, task_loss_gen=5.017, contrastive_loss=0, total=6758.65, n_correct=4661.15, ppl=3.75, accuracy=68.966, wps=18595.9, ups=1.38, wpb=13517.3, bsz=458.9, num_updates=37300, lr=7.32252e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=72, gb_free=7.7, wall=33556
2023-09-06 10:35:19 | INFO | train_inner | epoch 032:    496 / 1191 loss=1.886, trans_loss=4.708, nll_loss=1.92, w2v_ctc_loss=0.657, task_loss=2.077, task_loss_gen=5.089, contrastive_loss=0, total=6744.1, n_correct=4643.61, ppl=3.78, accuracy=68.854, wps=18455.8, ups=1.37, wpb=13488.2, bsz=454.9, num_updates=37400, lr=7.31272e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=73, gb_free=14, wall=33629
2023-09-06 10:36:32 | INFO | train_inner | epoch 032:    596 / 1191 loss=1.887, trans_loss=4.708, nll_loss=1.921, w2v_ctc_loss=0.659, task_loss=2.202, task_loss_gen=5.224, contrastive_loss=0, total=6688.42, n_correct=4606.64, ppl=3.79, accuracy=68.875, wps=18331.7, ups=1.37, wpb=13376.8, bsz=444.7, num_updates=37500, lr=7.30297e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=33702
2023-09-06 10:37:46 | INFO | train_inner | epoch 032:    696 / 1191 loss=1.886, trans_loss=4.702, nll_loss=1.912, w2v_ctc_loss=0.655, task_loss=2.258, task_loss_gen=5.465, contrastive_loss=0, total=6670, n_correct=4600.24, ppl=3.76, accuracy=68.969, wps=18081.3, ups=1.36, wpb=13340, bsz=436.6, num_updates=37600, lr=7.29325e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=33776
2023-09-06 10:38:59 | INFO | train_inner | epoch 032:    796 / 1191 loss=1.885, trans_loss=4.705, nll_loss=1.917, w2v_ctc_loss=0.657, task_loss=2.18, task_loss_gen=5.031, contrastive_loss=0, total=6761.99, n_correct=4657.65, ppl=3.78, accuracy=68.88, wps=18623.5, ups=1.38, wpb=13524, bsz=465.5, num_updates=37700, lr=7.28357e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=33849
2023-09-06 10:40:12 | INFO | train_inner | epoch 032:    896 / 1191 loss=1.886, trans_loss=4.706, nll_loss=1.918, w2v_ctc_loss=0.655, task_loss=2.169, task_loss_gen=5.36, contrastive_loss=0, total=6694.46, n_correct=4606.33, ppl=3.78, accuracy=68.808, wps=18314.7, ups=1.37, wpb=13388.9, bsz=444.9, num_updates=37800, lr=7.27393e-05, gnorm=0.38, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=33922
2023-09-06 10:41:24 | INFO | train_inner | epoch 032:    996 / 1191 loss=1.885, trans_loss=4.704, nll_loss=1.915, w2v_ctc_loss=0.66, task_loss=2.158, task_loss_gen=5.303, contrastive_loss=0, total=6610.12, n_correct=4557.45, ppl=3.77, accuracy=68.947, wps=18273, ups=1.38, wpb=13220.2, bsz=440.7, num_updates=37900, lr=7.26433e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=33994
2023-09-06 10:42:37 | INFO | train_inner | epoch 032:   1096 / 1191 loss=1.884, trans_loss=4.704, nll_loss=1.915, w2v_ctc_loss=0.654, task_loss=2.155, task_loss_gen=5.494, contrastive_loss=0, total=6609.06, n_correct=4555.36, ppl=3.77, accuracy=68.926, wps=18114.4, ups=1.37, wpb=13218.1, bsz=431, num_updates=38000, lr=7.25476e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=15, wall=34067
2023-09-06 10:42:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 10:43:10 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.719 | trans_loss 4.942 | nll_loss 2.175 | w2v_ctc_loss 1.233 | task_loss 8.453 | task_loss_gen 13.55 | contrastive_loss 0 | total 6138.43 | n_correct 4292.29 | ppl 4.52 | accuracy 69.925 | uer 18.263 | wer 19.509 | raw_wer 19.509 | bleu 27.62 | wps 1712.9 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 27.62
2023-09-06 10:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38000 updates
2023-09-06 10:43:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-06 10:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-06 10:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt (epoch 32 @ 38000 updates, score 27.62) (writing took 13.705750732915476 seconds)
--Backword ST Loss tensor(2353.1250, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1357.4500, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 10:44:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2240.7683, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1264.2593, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2598.7163, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1521.3013, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1543.4166, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(865.6767, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2027.4688, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1133.1781, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2311.1260, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1364.1544, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1916.9280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1095.4872, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1585.4166, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(861.9168, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-06 10:45:07 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.725 | trans_loss 4.942 | nll_loss 2.178 | w2v_ctc_loss 1.252 | task_loss 6.287 | task_loss_gen 14.577 | contrastive_loss 0 | total 6138.43 | n_correct 4307.86 | ppl 4.52 | accuracy 70.179 | uer 18.172 | wer 19.487 | raw_wer 19.487 | bleu 27.89 | wps 1668.5 | wpb 6138.4 | bsz 201.1 | num_updates 38095 | best_bleu 27.89
2023-09-06 10:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38095 updates
2023-09-06 10:45:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 32 @ 38095 updates, score 27.89) (writing took 13.453006501076743 seconds)
2023-09-06 10:45:21 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-06 10:45:21 | INFO | train | epoch 032 | loss 1.884 | trans_loss 4.705 | nll_loss 1.916 | w2v_ctc_loss 0.655 | task_loss 2.099 | task_loss_gen 5.164 | contrastive_loss 0 | total 6703.69 | n_correct 4618.4 | ppl 3.77 | accuracy 68.893 | wps 16463.5 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 38095 | lr 7.24571e-05 | gnorm 0.38 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 11.4 | wall 34231
2023-09-06 10:45:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:45:21 | INFO | fairseq.trainer | begin training epoch 33
2023-09-06 10:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:45:32 | INFO | train_inner | epoch 033:      5 / 1191 loss=1.88, trans_loss=4.709, nll_loss=1.922, w2v_ctc_loss=0.649, task_loss=1.723, task_loss_gen=5.005, contrastive_loss=0, total=6703.57, n_correct=4618.54, ppl=3.79, accuracy=68.897, wps=7685.9, ups=0.57, wpb=13407.1, bsz=482.5, num_updates=38100, lr=7.24524e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=34241
2023-09-06 10:46:45 | INFO | train_inner | epoch 033:    105 / 1191 loss=1.868, trans_loss=4.688, nll_loss=1.895, w2v_ctc_loss=0.637, task_loss=1.755, task_loss_gen=5.341, contrastive_loss=0, total=6806.82, n_correct=4720.04, ppl=3.72, accuracy=69.343, wps=18538.1, ups=1.36, wpb=13613.6, bsz=467.7, num_updates=38200, lr=7.23575e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=13.9, wall=34315
2023-09-06 10:47:57 | INFO | train_inner | epoch 033:    205 / 1191 loss=1.871, trans_loss=4.686, nll_loss=1.893, w2v_ctc_loss=0.643, task_loss=1.66, task_loss_gen=5.572, contrastive_loss=0, total=6763.38, n_correct=4687.66, ppl=3.71, accuracy=69.309, wps=18738.1, ups=1.39, wpb=13526.8, bsz=455.5, num_updates=38300, lr=7.22629e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=34387
2023-09-06 10:49:11 | INFO | train_inner | epoch 033:    305 / 1191 loss=1.877, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.647, task_loss=1.824, task_loss_gen=6.163, contrastive_loss=0, total=6595.67, n_correct=4567.07, ppl=3.73, accuracy=69.243, wps=17991.7, ups=1.36, wpb=13191.3, bsz=434, num_updates=38400, lr=7.21688e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=12.1, wall=34460
2023-09-06 10:50:23 | INFO | train_inner | epoch 033:    405 / 1191 loss=1.876, trans_loss=4.692, nll_loss=1.899, w2v_ctc_loss=0.645, task_loss=1.879, task_loss_gen=6.094, contrastive_loss=0, total=6592.1, n_correct=4563.24, ppl=3.73, accuracy=69.223, wps=18325.7, ups=1.39, wpb=13184.2, bsz=432.6, num_updates=38500, lr=7.2075e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=71, gb_free=4, wall=34532
2023-09-06 10:51:34 | INFO | train_inner | epoch 033:    505 / 1191 loss=1.87, trans_loss=4.686, nll_loss=1.893, w2v_ctc_loss=0.64, task_loss=1.81, task_loss_gen=5.523, contrastive_loss=0, total=6691.29, n_correct=4640.73, ppl=3.71, accuracy=69.355, wps=18735.2, ups=1.4, wpb=13382.6, bsz=456.4, num_updates=38600, lr=7.19816e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=71, gb_free=14.8, wall=34604
2023-09-06 10:52:47 | INFO | train_inner | epoch 033:    605 / 1191 loss=1.876, trans_loss=4.686, nll_loss=1.892, w2v_ctc_loss=0.654, task_loss=1.843, task_loss_gen=5.966, contrastive_loss=0, total=6673.5, n_correct=4619.75, ppl=3.71, accuracy=69.225, wps=18211.1, ups=1.36, wpb=13347, bsz=446.7, num_updates=38700, lr=7.18885e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=11.3, wall=34677
2023-09-06 10:54:01 | INFO | train_inner | epoch 033:    705 / 1191 loss=1.872, trans_loss=4.688, nll_loss=1.895, w2v_ctc_loss=0.645, task_loss=1.74, task_loss_gen=6.039, contrastive_loss=0, total=6684.47, n_correct=4632.55, ppl=3.72, accuracy=69.303, wps=18241.4, ups=1.36, wpb=13368.9, bsz=443.1, num_updates=38800, lr=7.17958e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=4.2, wall=34750
2023-09-06 10:55:13 | INFO | train_inner | epoch 033:    805 / 1191 loss=1.865, trans_loss=4.684, nll_loss=1.89, w2v_ctc_loss=0.634, task_loss=1.711, task_loss_gen=5.502, contrastive_loss=0, total=6794.84, n_correct=4723.9, ppl=3.71, accuracy=69.522, wps=18771, ups=1.38, wpb=13589.7, bsz=467.9, num_updates=38900, lr=7.17035e-05, gnorm=0.374, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=34823
2023-09-06 10:56:26 | INFO | train_inner | epoch 033:    905 / 1191 loss=1.875, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.651, task_loss=1.686, task_loss_gen=5.705, contrastive_loss=0, total=6754.04, n_correct=4679.74, ppl=3.73, accuracy=69.288, wps=18482.6, ups=1.37, wpb=13508.1, bsz=463.2, num_updates=39000, lr=7.16115e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=34896
2023-09-06 10:57:39 | INFO | train_inner | epoch 033:   1005 / 1191 loss=1.877, trans_loss=4.697, nll_loss=1.907, w2v_ctc_loss=0.646, task_loss=1.827, task_loss_gen=6.163, contrastive_loss=0, total=6679.84, n_correct=4621.41, ppl=3.75, accuracy=69.184, wps=18201.2, ups=1.36, wpb=13359.7, bsz=440.5, num_updates=39100, lr=7.15199e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=73, gb_free=4.3, wall=34969
2023-09-06 10:58:53 | INFO | train_inner | epoch 033:   1105 / 1191 loss=1.875, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.652, task_loss=1.638, task_loss_gen=5.862, contrastive_loss=0, total=6749.49, n_correct=4674.89, ppl=3.73, accuracy=69.263, wps=18429.4, ups=1.37, wpb=13499, bsz=463.2, num_updates=39200, lr=7.14286e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=12.6, wall=35043
2023-09-06 10:59:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:00:29 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.694 | trans_loss 4.926 | nll_loss 2.158 | w2v_ctc_loss 1.183 | task_loss 7.069 | task_loss_gen 14.452 | contrastive_loss 0 | total 6138.43 | n_correct 4309 | ppl 4.46 | accuracy 70.197 | uer 17.993 | wer 19.483 | raw_wer 19.483 | bleu 27.63 | wps 1646.3 | wpb 6138.4 | bsz 201.1 | num_updates 39286 | best_bleu 27.89
2023-09-06 11:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39286 updates
2023-09-06 11:00:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt
2023-09-06 11:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt
2023-09-06 11:00:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt (epoch 33 @ 39286 updates, score 27.63) (writing took 8.112319394014776 seconds)
2023-09-06 11:00:38 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-06 11:00:38 | INFO | train | epoch 033 | loss 1.873 | trans_loss 4.689 | nll_loss 1.896 | w2v_ctc_loss 0.645 | task_loss 1.757 | task_loss_gen 5.804 | contrastive_loss 0 | total 6703.69 | n_correct 4645.9 | ppl 3.72 | accuracy 69.304 | wps 17413.3 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 39286 | lr 7.13503e-05 | gnorm 0.377 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 10.4 | wall 35148
2023-09-06 11:00:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:00:38 | INFO | fairseq.trainer | begin training epoch 34
2023-09-06 11:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:00:56 | INFO | train_inner | epoch 034:     14 / 1191 loss=1.866, trans_loss=4.682, nll_loss=1.888, w2v_ctc_loss=0.642, task_loss=1.676, task_loss_gen=5.599, contrastive_loss=0, total=6714.43, n_correct=4664.77, ppl=3.7, accuracy=69.474, wps=10876.8, ups=0.81, wpb=13428.9, bsz=468.7, num_updates=39300, lr=7.13376e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=35166
2023-09-06 11:02:09 | INFO | train_inner | epoch 034:    114 / 1191 loss=1.856, trans_loss=4.673, nll_loss=1.876, w2v_ctc_loss=0.624, task_loss=1.549, task_loss_gen=5.536, contrastive_loss=0, total=6812.86, n_correct=4750.72, ppl=3.67, accuracy=69.732, wps=18811.8, ups=1.38, wpb=13625.7, bsz=478.9, num_updates=39400, lr=7.1247e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=35238
2023-09-06 11:03:22 | INFO | train_inner | epoch 034:    214 / 1191 loss=1.865, trans_loss=4.677, nll_loss=1.88, w2v_ctc_loss=0.638, task_loss=1.91, task_loss_gen=5.935, contrastive_loss=0, total=6669.32, n_correct=4642.87, ppl=3.68, accuracy=69.615, wps=18262.6, ups=1.37, wpb=13338.6, bsz=448.9, num_updates=39500, lr=7.11568e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=35311
2023-09-06 11:04:34 | INFO | train_inner | epoch 034:    314 / 1191 loss=1.865, trans_loss=4.675, nll_loss=1.878, w2v_ctc_loss=0.637, task_loss=1.757, task_loss_gen=6.57, contrastive_loss=0, total=6597.66, n_correct=4593.44, ppl=3.68, accuracy=69.622, wps=18191.5, ups=1.38, wpb=13195.3, bsz=431.8, num_updates=39600, lr=7.10669e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=35384
2023-09-06 11:05:48 | INFO | train_inner | epoch 034:    414 / 1191 loss=1.866, trans_loss=4.679, nll_loss=1.883, w2v_ctc_loss=0.635, task_loss=1.781, task_loss_gen=6.231, contrastive_loss=0, total=6670.6, n_correct=4639.24, ppl=3.69, accuracy=69.548, wps=18118.8, ups=1.36, wpb=13341.2, bsz=433.1, num_updates=39700, lr=7.09773e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=35458
2023-09-06 11:07:01 | INFO | train_inner | epoch 034:    514 / 1191 loss=1.86, trans_loss=4.673, nll_loss=1.875, w2v_ctc_loss=0.629, task_loss=1.905, task_loss_gen=6.126, contrastive_loss=0, total=6672.9, n_correct=4654.34, ppl=3.67, accuracy=69.75, wps=18275.9, ups=1.37, wpb=13345.8, bsz=440, num_updates=39800, lr=7.08881e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=5.1, wall=35531
2023-09-06 11:08:14 | INFO | train_inner | epoch 034:    614 / 1191 loss=1.863, trans_loss=4.677, nll_loss=1.882, w2v_ctc_loss=0.637, task_loss=1.847, task_loss_gen=5.607, contrastive_loss=0, total=6739.24, n_correct=4689.31, ppl=3.68, accuracy=69.582, wps=18441.3, ups=1.37, wpb=13478.5, bsz=463.2, num_updates=39900, lr=7.07992e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=35604
2023-09-06 11:09:26 | INFO | train_inner | epoch 034:    714 / 1191 loss=1.866, trans_loss=4.678, nll_loss=1.883, w2v_ctc_loss=0.639, task_loss=1.51, task_loss_gen=6.337, contrastive_loss=0, total=6627.68, n_correct=4610.39, ppl=3.69, accuracy=69.563, wps=18403.6, ups=1.39, wpb=13255.4, bsz=441.5, num_updates=40000, lr=7.07107e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=35676
2023-09-06 11:09:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:10:01 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.703 | trans_loss 4.926 | nll_loss 2.159 | w2v_ctc_loss 1.213 | task_loss 6.628 | task_loss_gen 14.668 | contrastive_loss 0 | total 6138.43 | n_correct 4316.14 | ppl 4.47 | accuracy 70.313 | uer 17.979 | wer 19.36 | raw_wer 19.36 | bleu 28.05 | wps 1616.7 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 28.05
2023-09-06 11:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-09-06 11:10:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-06 11:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-06 11:10:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 28.05) (writing took 14.717169138020836 seconds)
--Backword ST Loss tensor(1834.7694, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1111.5298, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 11:11:29 | INFO | train_inner | epoch 034:    814 / 1191 loss=1.864, trans_loss=4.674, nll_loss=1.878, w2v_ctc_loss=0.643, task_loss=1.6, task_loss_gen=6.236, contrastive_loss=0, total=6664.33, n_correct=4642.12, ppl=3.67, accuracy=69.656, wps=10875, ups=0.82, wpb=13328.7, bsz=454.5, num_updates=40100, lr=7.06225e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=35798
2023-09-06 11:12:41 | INFO | train_inner | epoch 034:    914 / 1191 loss=1.867, trans_loss=4.673, nll_loss=1.876, w2v_ctc_loss=0.642, task_loss=1.574, task_loss_gen=7.003, contrastive_loss=0, total=6654.7, n_correct=4635.51, ppl=3.67, accuracy=69.658, wps=18315.6, ups=1.38, wpb=13309.4, bsz=428.5, num_updates=40200, lr=7.05346e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=35871
2023-09-06 11:13:54 | INFO | train_inner | epoch 034:   1014 / 1191 loss=1.866, trans_loss=4.678, nll_loss=1.883, w2v_ctc_loss=0.639, task_loss=1.33, task_loss_gen=7.162, contrastive_loss=0, total=6667.27, n_correct=4643.61, ppl=3.69, accuracy=69.648, wps=18357.5, ups=1.38, wpb=13334.5, bsz=439.7, num_updates=40300, lr=7.0447e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=12.1, wall=35944
2023-09-06 11:15:07 | INFO | train_inner | epoch 034:   1114 / 1191 loss=1.853, trans_loss=4.67, nll_loss=1.873, w2v_ctc_loss=0.624, task_loss=1.091, task_loss_gen=6.653, contrastive_loss=0, total=6861.81, n_correct=4790.88, ppl=3.66, accuracy=69.819, wps=18819.2, ups=1.37, wpb=13723.6, bsz=480.5, num_updates=40400, lr=7.03598e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=72, gb_free=13.3, wall=36017
2023-09-06 11:16:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2803.7712, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1537.4453, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
--Backword ST Loss tensor(2393.0061, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1172.1565, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
--Backword ST Loss tensor(1798.3802, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1000.9257, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
--Backword ST Loss tensor(2507.8379, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1453.2545, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
--Backword ST Loss tensor(1838.6941, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1009.7489, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
--Backword ST Loss tensor(1971.9866, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1184.1243, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
--Backword ST Loss tensor(2231.4927, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1287.1949, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
2023-09-06 11:16:38 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.702 | trans_loss 4.92 | nll_loss 2.151 | w2v_ctc_loss 1.225 | task_loss 5.99 | task_loss_gen 15.859 | contrastive_loss 0 | total 6138.43 | n_correct 4322.43 | ppl 4.44 | accuracy 70.416 | uer 17.666 | wer 18.977 | raw_wer 18.977 | bleu 27.9 | wps 1540.2 | wpb 6138.4 | bsz 201.1 | num_updates 40477 | best_bleu 28.05
2023-09-06 11:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40477 updates
2023-09-06 11:16:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt
2023-09-06 11:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt
2023-09-06 11:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt (epoch 34 @ 40477 updates, score 27.9) (writing took 7.471538525889628 seconds)
2023-09-06 11:16:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-06 11:16:46 | INFO | train | epoch 034 | loss 1.862 | trans_loss 4.675 | nll_loss 1.878 | w2v_ctc_loss 0.635 | task_loss 1.593 | task_loss_gen 6.288 | contrastive_loss 0 | total 6703.69 | n_correct 4670.32 | ppl 3.68 | accuracy 69.668 | wps 16494.9 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 40477 | lr 7.02928e-05 | gnorm 0.378 | clip 0 | loss_scale 64 | train_wall 859 | gb_free 13.8 | wall 36116
2023-09-06 11:16:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:16:46 | INFO | fairseq.trainer | begin training epoch 35
2023-09-06 11:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:17:11 | INFO | train_inner | epoch 035:     23 / 1191 loss=1.855, trans_loss=4.67, nll_loss=1.873, w2v_ctc_loss=0.626, task_loss=1.312, task_loss_gen=6.645, contrastive_loss=0, total=6766.65, n_correct=4725.24, ppl=3.66, accuracy=69.831, wps=10876.7, ups=0.8, wpb=13533.3, bsz=471.5, num_updates=40500, lr=7.02728e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=72, gb_free=10.7, wall=36141
2023-09-06 11:18:24 | INFO | train_inner | epoch 035:    123 / 1191 loss=1.854, trans_loss=4.662, nll_loss=1.861, w2v_ctc_loss=0.631, task_loss=1.211, task_loss_gen=7.343, contrastive_loss=0, total=6708.25, n_correct=4695.48, ppl=3.63, accuracy=69.996, wps=18520.5, ups=1.38, wpb=13416.5, bsz=451.4, num_updates=40600, lr=7.01862e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=36213
2023-09-06 11:19:36 | INFO | train_inner | epoch 035:    223 / 1191 loss=1.851, trans_loss=4.66, nll_loss=1.859, w2v_ctc_loss=0.62, task_loss=1.256, task_loss_gen=7.663, contrastive_loss=0, total=6627.47, n_correct=4643.87, ppl=3.63, accuracy=70.07, wps=18403.4, ups=1.39, wpb=13254.9, bsz=444.5, num_updates=40700, lr=7.01e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=36285
2023-09-06 11:20:48 | INFO | train_inner | epoch 035:    323 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.856, w2v_ctc_loss=0.625, task_loss=1.136, task_loss_gen=7.257, contrastive_loss=0, total=6767.84, n_correct=4747.8, ppl=3.62, accuracy=70.152, wps=18631.6, ups=1.38, wpb=13535.7, bsz=463.2, num_updates=40800, lr=7.0014e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=36358
2023-09-06 11:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 11:22:02 | INFO | train_inner | epoch 035:    424 / 1191 loss=1.86, trans_loss=4.666, nll_loss=1.866, w2v_ctc_loss=0.633, task_loss=1.375, task_loss_gen=8.437, contrastive_loss=0, total=6572.39, n_correct=4598.2, ppl=3.65, accuracy=69.962, wps=17850.2, ups=1.36, wpb=13144.8, bsz=421.2, num_updates=40900, lr=6.99284e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=36432
2023-09-06 11:23:15 | INFO | train_inner | epoch 035:    524 / 1191 loss=1.854, trans_loss=4.661, nll_loss=1.86, w2v_ctc_loss=0.631, task_loss=1.455, task_loss_gen=6.919, contrastive_loss=0, total=6718.03, n_correct=4699.41, ppl=3.63, accuracy=69.952, wps=18469.3, ups=1.37, wpb=13436.1, bsz=456.1, num_updates=41000, lr=6.9843e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=36505
2023-09-06 11:24:28 | INFO | train_inner | epoch 035:    624 / 1191 loss=1.853, trans_loss=4.661, nll_loss=1.861, w2v_ctc_loss=0.626, task_loss=1.601, task_loss_gen=6.653, contrastive_loss=0, total=6702.8, n_correct=4685.06, ppl=3.63, accuracy=69.897, wps=18212.5, ups=1.36, wpb=13405.6, bsz=446.4, num_updates=41100, lr=6.9758e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=73, gb_free=9.3, wall=36578
2023-09-06 11:25:41 | INFO | train_inner | epoch 035:    724 / 1191 loss=1.857, trans_loss=4.669, nll_loss=1.871, w2v_ctc_loss=0.631, task_loss=1.653, task_loss_gen=6.453, contrastive_loss=0, total=6709.59, n_correct=4687.11, ppl=3.66, accuracy=69.857, wps=18453.4, ups=1.38, wpb=13419.2, bsz=453.6, num_updates=41200, lr=6.96733e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=36651
2023-09-06 11:26:54 | INFO | train_inner | epoch 035:    824 / 1191 loss=1.856, trans_loss=4.671, nll_loss=1.874, w2v_ctc_loss=0.625, task_loss=1.588, task_loss_gen=5.959, contrastive_loss=0, total=6756.65, n_correct=4718.22, ppl=3.66, accuracy=69.831, wps=18442.5, ups=1.36, wpb=13513.3, bsz=459.7, num_updates=41300, lr=6.95889e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=36724
2023-09-06 11:28:07 | INFO | train_inner | epoch 035:    924 / 1191 loss=1.849, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.621, task_loss=1.398, task_loss_gen=5.758, contrastive_loss=0, total=6770.43, n_correct=4739.35, ppl=3.64, accuracy=70.001, wps=18679.4, ups=1.38, wpb=13540.9, bsz=473.1, num_updates=41400, lr=6.95048e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=36797
2023-09-06 11:29:19 | INFO | train_inner | epoch 035:   1024 / 1191 loss=1.854, trans_loss=4.659, nll_loss=1.857, w2v_ctc_loss=0.629, task_loss=1.579, task_loss_gen=6.423, contrastive_loss=0, total=6727.5, n_correct=4708.17, ppl=3.62, accuracy=69.984, wps=18658.2, ups=1.39, wpb=13455, bsz=442.9, num_updates=41500, lr=6.9421e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=36869
2023-09-06 11:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 11:30:33 | INFO | train_inner | epoch 035:   1125 / 1191 loss=1.859, trans_loss=4.67, nll_loss=1.872, w2v_ctc_loss=0.635, task_loss=1.422, task_loss_gen=6.64, contrastive_loss=0, total=6635.8, n_correct=4636.34, ppl=3.66, accuracy=69.869, wps=17977.2, ups=1.35, wpb=13271.6, bsz=444.4, num_updates=41600, lr=6.93375e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=73, gb_free=11.4, wall=36943
2023-09-06 11:31:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:31:54 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.697 | trans_loss 4.917 | nll_loss 2.149 | w2v_ctc_loss 1.214 | task_loss 15.598 | task_loss_gen 13.25 | contrastive_loss 0 | total 6138.43 | n_correct 4325.43 | ppl 4.43 | accuracy 70.465 | uer 18.019 | wer 19.275 | raw_wer 19.275 | bleu 28.15 | wps 1724 | wpb 6138.4 | bsz 201.1 | num_updates 41666 | best_bleu 28.15
2023-09-06 11:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41666 updates
2023-09-06 11:31:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 11:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 11:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 35 @ 41666 updates, score 28.15) (writing took 13.84492250403855 seconds)
2023-09-06 11:32:08 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-09-06 11:32:08 | INFO | train | epoch 035 | loss 1.854 | trans_loss 4.664 | nll_loss 1.864 | w2v_ctc_loss 0.628 | task_loss 1.438 | task_loss_gen 6.774 | contrastive_loss 0 | total 6703.22 | n_correct 4689.35 | ppl 3.64 | accuracy 69.957 | wps 17279.9 | ups 1.29 | wpb 13406.4 | bsz 452.2 | num_updates 41666 | lr 6.92826e-05 | gnorm 0.379 | clip 0 | loss_scale 16 | train_wall 860 | gb_free 14.1 | wall 37038
2023-09-06 11:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:32:09 | INFO | fairseq.trainer | begin training epoch 36
2023-09-06 11:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:32:41 | INFO | train_inner | epoch 036:     34 / 1191 loss=1.852, trans_loss=4.663, nll_loss=1.864, w2v_ctc_loss=0.625, task_loss=1.814, task_loss_gen=5.616, contrastive_loss=0, total=6723.46, n_correct=4706.32, ppl=3.64, accuracy=69.998, wps=10498.2, ups=0.78, wpb=13446.9, bsz=466.6, num_updates=41700, lr=6.92543e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=73, gb_free=12.4, wall=37071
2023-09-06 11:33:53 | INFO | train_inner | epoch 036:    134 / 1191 loss=1.847, trans_loss=4.65, nll_loss=1.846, w2v_ctc_loss=0.621, task_loss=2.067, task_loss_gen=5.714, contrastive_loss=0, total=6615.18, n_correct=4644.24, ppl=3.6, accuracy=70.206, wps=18384.5, ups=1.39, wpb=13230.4, bsz=439.7, num_updates=41800, lr=6.91714e-05, gnorm=0.387, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=37143
2023-09-06 11:35:05 | INFO | train_inner | epoch 036:    234 / 1191 loss=1.837, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.61, task_loss=1.773, task_loss_gen=5.255, contrastive_loss=0, total=6741.47, n_correct=4751.61, ppl=3.57, accuracy=70.483, wps=18649.7, ups=1.38, wpb=13482.9, bsz=470.3, num_updates=41900, lr=6.90889e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=8.4, wall=37215
2023-09-06 11:36:17 | INFO | train_inner | epoch 036:    334 / 1191 loss=1.845, trans_loss=4.655, nll_loss=1.853, w2v_ctc_loss=0.619, task_loss=1.892, task_loss_gen=5.153, contrastive_loss=0, total=6788.68, n_correct=4765.72, ppl=3.61, accuracy=70.201, wps=18825.7, ups=1.39, wpb=13577.4, bsz=468.7, num_updates=42000, lr=6.90066e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=71, gb_free=13.9, wall=37287
2023-09-06 11:36:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:36:51 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.699 | trans_loss 4.916 | nll_loss 2.147 | w2v_ctc_loss 1.224 | task_loss 5.77 | task_loss_gen 15.282 | contrastive_loss 0 | total 6138.43 | n_correct 4330.29 | ppl 4.43 | accuracy 70.544 | uer 17.915 | wer 19.16 | raw_wer 19.16 | bleu 28.37 | wps 1703.9 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 28.37
2023-09-06 11:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-09-06 11:36:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-06 11:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-06 11:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 28.37) (writing took 13.892014258075505 seconds)
--Backword ST Loss tensor(2075.8174, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1128.3402, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 11:38:19 | INFO | train_inner | epoch 036:    434 / 1191 loss=1.847, trans_loss=4.655, nll_loss=1.854, w2v_ctc_loss=0.624, task_loss=1.981, task_loss_gen=5.037, contrastive_loss=0, total=6801.05, n_correct=4775.82, ppl=3.61, accuracy=70.222, wps=11212.8, ups=0.82, wpb=13602.1, bsz=473.4, num_updates=42100, lr=6.89246e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=73, gb_free=13.3, wall=37408
2023-09-06 11:39:31 | INFO | train_inner | epoch 036:    534 / 1191 loss=1.848, trans_loss=4.66, nll_loss=1.861, w2v_ctc_loss=0.617, task_loss=1.908, task_loss_gen=5.118, contrastive_loss=0, total=6792.76, n_correct=4758.11, ppl=3.63, accuracy=70.047, wps=18730.8, ups=1.38, wpb=13585.5, bsz=472.4, num_updates=42200, lr=6.88428e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=12.6, wall=37481
2023-09-06 11:40:44 | INFO | train_inner | epoch 036:    634 / 1191 loss=1.85, trans_loss=4.653, nll_loss=1.851, w2v_ctc_loss=0.627, task_loss=2.247, task_loss_gen=5.446, contrastive_loss=0, total=6667.35, n_correct=4681.02, ppl=3.61, accuracy=70.208, wps=18307.9, ups=1.37, wpb=13334.7, bsz=440.8, num_updates=42300, lr=6.87614e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.5, wall=37554
2023-09-06 11:41:57 | INFO | train_inner | epoch 036:    734 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.857, w2v_ctc_loss=0.621, task_loss=2.228, task_loss_gen=5.353, contrastive_loss=0, total=6721.83, n_correct=4711.16, ppl=3.62, accuracy=70.087, wps=18342.8, ups=1.36, wpb=13443.7, bsz=450.1, num_updates=42400, lr=6.86803e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=73, gb_free=13.9, wall=37627
2023-09-06 11:43:10 | INFO | train_inner | epoch 036:    834 / 1191 loss=1.849, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.621, task_loss=2.142, task_loss_gen=5.565, contrastive_loss=0, total=6678.35, n_correct=4679.49, ppl=3.64, accuracy=70.07, wps=18275.8, ups=1.37, wpb=13356.7, bsz=447.4, num_updates=42500, lr=6.85994e-05, gnorm=0.39, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=37700
2023-09-06 11:44:24 | INFO | train_inner | epoch 036:    934 / 1191 loss=1.855, trans_loss=4.66, nll_loss=1.86, w2v_ctc_loss=0.626, task_loss=2.412, task_loss_gen=5.975, contrastive_loss=0, total=6679.59, n_correct=4673.79, ppl=3.63, accuracy=69.971, wps=18204.3, ups=1.36, wpb=13359.2, bsz=429.9, num_updates=42600, lr=6.85189e-05, gnorm=0.392, clip=0, loss_scale=16, train_wall=73, gb_free=13.2, wall=37774
2023-09-06 11:45:36 | INFO | train_inner | epoch 036:   1034 / 1191 loss=1.848, trans_loss=4.66, nll_loss=1.861, w2v_ctc_loss=0.62, task_loss=2.027, task_loss_gen=5.33, contrastive_loss=0, total=6715.41, n_correct=4707.46, ppl=3.63, accuracy=70.099, wps=18579.9, ups=1.38, wpb=13430.8, bsz=465.8, num_updates=42700, lr=6.84386e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.8, wall=37846
2023-09-06 11:46:48 | INFO | train_inner | epoch 036:   1134 / 1191 loss=1.853, trans_loss=4.655, nll_loss=1.853, w2v_ctc_loss=0.631, task_loss=2.308, task_loss_gen=5.672, contrastive_loss=0, total=6605.28, n_correct=4631.84, ppl=3.61, accuracy=70.123, wps=18219, ups=1.38, wpb=13210.6, bsz=432.4, num_updates=42800, lr=6.83586e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=37918
2023-09-06 11:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2577.2063, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1551.1210, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2032.7184, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1166.4968, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2406.9739, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1356.9275, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2207.5479, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1273.7585, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1554.6871, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(850.8668, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1985.6858, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1166.7562, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2246.6257, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1182.2650, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 11:48:03 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.696 | trans_loss 4.907 | nll_loss 2.136 | w2v_ctc_loss 1.231 | task_loss 8.22 | task_loss_gen 14.287 | contrastive_loss 0 | total 6138.43 | n_correct 4327.29 | ppl 4.4 | accuracy 70.495 | uer 17.648 | wer 19.115 | raw_wer 19.115 | bleu 28.12 | wps 1718.5 | wpb 6138.4 | bsz 201.1 | num_updates 42857 | best_bleu 28.37
2023-09-06 11:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42857 updates
2023-09-06 11:48:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt
2023-09-06 11:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt
2023-09-06 11:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt (epoch 36 @ 42857 updates, score 28.12) (writing took 7.892403287929483 seconds)
2023-09-06 11:48:11 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-09-06 11:48:11 | INFO | train | epoch 036 | loss 1.848 | trans_loss 4.656 | nll_loss 1.855 | w2v_ctc_loss 0.622 | task_loss 2.1 | task_loss_gen 5.438 | contrastive_loss 0 | total 6703.69 | n_correct 4701.92 | ppl 3.62 | accuracy 70.139 | wps 16587.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 42857 | lr 6.83131e-05 | gnorm 0.385 | clip 0 | loss_scale 16 | train_wall 858 | gb_free 12.7 | wall 38001
2023-09-06 11:48:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:48:11 | INFO | fairseq.trainer | begin training epoch 37
2023-09-06 11:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:48:50 | INFO | train_inner | epoch 037:     43 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.855, w2v_ctc_loss=0.623, task_loss=2.287, task_loss_gen=5.569, contrastive_loss=0, total=6672.81, n_correct=4678.39, ppl=3.62, accuracy=70.111, wps=10946.1, ups=0.82, wpb=13345.6, bsz=440.3, num_updates=42900, lr=6.82789e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=15.1, wall=38040
2023-09-06 11:50:03 | INFO | train_inner | epoch 037:    143 / 1191 loss=1.841, trans_loss=4.647, nll_loss=1.843, w2v_ctc_loss=0.611, task_loss=2.026, task_loss_gen=5.128, contrastive_loss=0, total=6762.6, n_correct=4757.04, ppl=3.59, accuracy=70.343, wps=18607.3, ups=1.38, wpb=13525.2, bsz=464, num_updates=43000, lr=6.81994e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=12.7, wall=38113
2023-09-06 11:51:16 | INFO | train_inner | epoch 037:    243 / 1191 loss=1.842, trans_loss=4.643, nll_loss=1.838, w2v_ctc_loss=0.617, task_loss=2.244, task_loss_gen=5.399, contrastive_loss=0, total=6696.92, n_correct=4715.29, ppl=3.58, accuracy=70.41, wps=18477.3, ups=1.38, wpb=13393.8, bsz=449.2, num_updates=43100, lr=6.81203e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=11.6, wall=38185
2023-09-06 11:52:28 | INFO | train_inner | epoch 037:    343 / 1191 loss=1.844, trans_loss=4.648, nll_loss=1.844, w2v_ctc_loss=0.617, task_loss=2.277, task_loss_gen=5.534, contrastive_loss=0, total=6637.72, n_correct=4666.73, ppl=3.59, accuracy=70.306, wps=18395, ups=1.39, wpb=13275.4, bsz=440.5, num_updates=43200, lr=6.80414e-05, gnorm=0.391, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=38258
2023-09-06 11:53:40 | INFO | train_inner | epoch 037:    443 / 1191 loss=1.839, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.612, task_loss=2.307, task_loss_gen=5.449, contrastive_loss=0, total=6703.75, n_correct=4721.84, ppl=3.57, accuracy=70.436, wps=18466.5, ups=1.38, wpb=13407.5, bsz=446.8, num_updates=43300, lr=6.79628e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=38330
2023-09-06 11:54:54 | INFO | train_inner | epoch 037:    543 / 1191 loss=1.839, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.615, task_loss=2.3, task_loss_gen=5.43, contrastive_loss=0, total=6639.95, n_correct=4681.1, ppl=3.57, accuracy=70.499, wps=18050.8, ups=1.36, wpb=13279.9, bsz=449.3, num_updates=43400, lr=6.78844e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=73, gb_free=13.4, wall=38404
2023-09-06 11:56:07 | INFO | train_inner | epoch 037:    643 / 1191 loss=1.842, trans_loss=4.648, nll_loss=1.845, w2v_ctc_loss=0.608, task_loss=2.282, task_loss_gen=5.794, contrastive_loss=0, total=6631.82, n_correct=4664.94, ppl=3.59, accuracy=70.342, wps=18248.8, ups=1.38, wpb=13263.6, bsz=428.1, num_updates=43500, lr=6.78064e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=72, gb_free=12.2, wall=38476
2023-09-06 11:57:19 | INFO | train_inner | epoch 037:    743 / 1191 loss=1.844, trans_loss=4.646, nll_loss=1.842, w2v_ctc_loss=0.62, task_loss=2.322, task_loss_gen=5.367, contrastive_loss=0, total=6719.07, n_correct=4726.43, ppl=3.58, accuracy=70.344, wps=18523.3, ups=1.38, wpb=13438.1, bsz=451.8, num_updates=43600, lr=6.77285e-05, gnorm=0.389, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=38549
2023-09-06 11:58:32 | INFO | train_inner | epoch 037:    843 / 1191 loss=1.839, trans_loss=4.651, nll_loss=1.849, w2v_ctc_loss=0.61, task_loss=2.232, task_loss_gen=5.192, contrastive_loss=0, total=6808.88, n_correct=4787.97, ppl=3.6, accuracy=70.319, wps=18604.1, ups=1.37, wpb=13617.8, bsz=466.8, num_updates=43700, lr=6.7651e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=38622
2023-09-06 11:59:46 | INFO | train_inner | epoch 037:    943 / 1191 loss=1.831, trans_loss=4.642, nll_loss=1.838, w2v_ctc_loss=0.604, task_loss=1.85, task_loss_gen=5.033, contrastive_loss=0, total=6855.49, n_correct=4838.14, ppl=3.57, accuracy=70.573, wps=18739.3, ups=1.37, wpb=13711, bsz=499.9, num_updates=43800, lr=6.75737e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=38695
2023-09-06 12:00:59 | INFO | train_inner | epoch 037:   1043 / 1191 loss=1.841, trans_loss=4.643, nll_loss=1.839, w2v_ctc_loss=0.616, task_loss=2.101, task_loss_gen=6.079, contrastive_loss=0, total=6689.96, n_correct=4713.04, ppl=3.58, accuracy=70.449, wps=18241.7, ups=1.36, wpb=13379.9, bsz=441.4, num_updates=43900, lr=6.74967e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=38769
2023-09-06 12:02:12 | INFO | train_inner | epoch 037:   1143 / 1191 loss=1.845, trans_loss=4.652, nll_loss=1.85, w2v_ctc_loss=0.618, task_loss=1.774, task_loss_gen=6.389, contrastive_loss=0, total=6631.9, n_correct=4663.73, ppl=3.6, accuracy=70.323, wps=18270.3, ups=1.38, wpb=13263.8, bsz=443.6, num_updates=44000, lr=6.742e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=38841
2023-09-06 12:02:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:02:45 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.9 | nll_loss 2.126 | w2v_ctc_loss 1.182 | task_loss 10.978 | task_loss_gen 14.144 | contrastive_loss 0 | total 6138.43 | n_correct 4332.57 | ppl 4.37 | accuracy 70.581 | uer 17.578 | wer 19.011 | raw_wer 19.011 | bleu 28.19 | wps 1642.1 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 28.37
2023-09-06 12:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44000 updates
2023-09-06 12:02:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-06 12:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-06 12:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt (epoch 37 @ 44000 updates, score 28.19) (writing took 8.800060661975294 seconds)
--Backword ST Loss tensor(2808.5962, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1697.1611, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:03:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2411.4268, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1402.1918, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1608.7341, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(919.2394, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2234.9009, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1283.4520, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1411.5433, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(826.7528, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2498.3572, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1368.0658, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1891.8773, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1088.8613, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1239.6111, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(652.8146, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-06 12:04:02 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.69 | trans_loss 4.905 | nll_loss 2.131 | w2v_ctc_loss 1.218 | task_loss 7.318 | task_loss_gen 15.168 | contrastive_loss 0 | total 6138.43 | n_correct 4332 | ppl 4.38 | accuracy 70.572 | uer 17.592 | wer 18.929 | raw_wer 18.929 | bleu 28.48 | wps 1723.9 | wpb 6138.4 | bsz 201.1 | num_updates 44048 | best_bleu 28.48
2023-09-06 12:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44048 updates
2023-09-06 12:04:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 12:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 12:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 37 @ 44048 updates, score 28.48) (writing took 14.73071038397029 seconds)
2023-09-06 12:04:17 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-09-06 12:04:17 | INFO | train | epoch 037 | loss 1.841 | trans_loss 4.646 | nll_loss 1.842 | w2v_ctc_loss 0.614 | task_loss 2.143 | task_loss_gen 5.549 | contrastive_loss 0 | total 6703.69 | n_correct 4719.02 | ppl 3.59 | accuracy 70.394 | wps 16528.1 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 44048 | lr 6.73832e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 13.5 | wall 38967
2023-09-06 12:04:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:04:17 | INFO | fairseq.trainer | begin training epoch 38
2023-09-06 12:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:05:03 | INFO | train_inner | epoch 038:     52 / 1191 loss=1.842, trans_loss=4.648, nll_loss=1.844, w2v_ctc_loss=0.615, task_loss=1.91, task_loss_gen=6.55, contrastive_loss=0, total=6590.11, n_correct=4639.72, ppl=3.59, accuracy=70.404, wps=7681.7, ups=0.58, wpb=13180.2, bsz=432.1, num_updates=44100, lr=6.73435e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=39013
2023-09-06 12:06:16 | INFO | train_inner | epoch 038:    152 / 1191 loss=1.831, trans_loss=4.63, nll_loss=1.823, w2v_ctc_loss=0.605, task_loss=2.064, task_loss_gen=5.924, contrastive_loss=0, total=6707.39, n_correct=4748.29, ppl=3.54, accuracy=70.792, wps=18399.6, ups=1.37, wpb=13414.8, bsz=449.4, num_updates=44200, lr=6.72673e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=8, wall=39086
2023-09-06 12:07:29 | INFO | train_inner | epoch 038:    252 / 1191 loss=1.837, trans_loss=4.638, nll_loss=1.832, w2v_ctc_loss=0.611, task_loss=1.824, task_loss_gen=6.069, contrastive_loss=0, total=6683.44, n_correct=4714.2, ppl=3.56, accuracy=70.536, wps=18406.8, ups=1.38, wpb=13366.9, bsz=456.5, num_updates=44300, lr=6.71913e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=39158
2023-09-06 12:08:42 | INFO | train_inner | epoch 038:    352 / 1191 loss=1.834, trans_loss=4.63, nll_loss=1.822, w2v_ctc_loss=0.61, task_loss=1.786, task_loss_gen=6.468, contrastive_loss=0, total=6695.6, n_correct=4736.58, ppl=3.54, accuracy=70.742, wps=18131.6, ups=1.35, wpb=13391.2, bsz=443, num_updates=44400, lr=6.71156e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=39232
2023-09-06 12:09:55 | INFO | train_inner | epoch 038:    452 / 1191 loss=1.831, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.604, task_loss=1.715, task_loss_gen=6.031, contrastive_loss=0, total=6755.69, n_correct=4774.44, ppl=3.56, accuracy=70.673, wps=18506.6, ups=1.37, wpb=13511.4, bsz=476.3, num_updates=44500, lr=6.70402e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=39305
2023-09-06 12:11:08 | INFO | train_inner | epoch 038:    552 / 1191 loss=1.83, trans_loss=4.633, nll_loss=1.825, w2v_ctc_loss=0.603, task_loss=1.792, task_loss_gen=6.158, contrastive_loss=0, total=6799.96, n_correct=4815.04, ppl=3.54, accuracy=70.81, wps=18705.4, ups=1.38, wpb=13599.9, bsz=463.7, num_updates=44600, lr=6.6965e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=72, gb_free=11.7, wall=39378
2023-09-06 12:12:21 | INFO | train_inner | epoch 038:    652 / 1191 loss=1.835, trans_loss=4.643, nll_loss=1.839, w2v_ctc_loss=0.608, task_loss=1.85, task_loss_gen=5.674, contrastive_loss=0, total=6826.7, n_correct=4815.87, ppl=3.58, accuracy=70.545, wps=18702.9, ups=1.37, wpb=13653.4, bsz=474.6, num_updates=44700, lr=6.689e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=39451
2023-09-06 12:13:34 | INFO | train_inner | epoch 038:    752 / 1191 loss=1.832, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.606, task_loss=1.943, task_loss_gen=5.958, contrastive_loss=0, total=6730.12, n_correct=4754.98, ppl=3.56, accuracy=70.652, wps=18453.1, ups=1.37, wpb=13460.2, bsz=464.2, num_updates=44800, lr=6.68153e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=39524
2023-09-06 12:14:47 | INFO | train_inner | epoch 038:    852 / 1191 loss=1.835, trans_loss=4.636, nll_loss=1.829, w2v_ctc_loss=0.607, task_loss=2.106, task_loss_gen=6.514, contrastive_loss=0, total=6687.39, n_correct=4721.33, ppl=3.55, accuracy=70.6, wps=18343.8, ups=1.37, wpb=13374.8, bsz=435.4, num_updates=44900, lr=6.67409e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=11.5, wall=39597
2023-09-06 12:16:00 | INFO | train_inner | epoch 038:    952 / 1191 loss=1.837, trans_loss=4.64, nll_loss=1.834, w2v_ctc_loss=0.61, task_loss=2.16, task_loss_gen=6.137, contrastive_loss=0, total=6685.88, n_correct=4719.35, ppl=3.57, accuracy=70.587, wps=18310, ups=1.37, wpb=13371.8, bsz=446, num_updates=45000, lr=6.66667e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=10.6, wall=39670
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 12:17:12 | INFO | train_inner | epoch 038:   1052 / 1191 loss=1.837, trans_loss=4.636, nll_loss=1.83, w2v_ctc_loss=0.613, task_loss=2.19, task_loss_gen=6.311, contrastive_loss=0, total=6622.97, n_correct=4672.42, ppl=3.56, accuracy=70.549, wps=18313, ups=1.38, wpb=13245.9, bsz=440.1, num_updates=45100, lr=6.65927e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=39742
2023-09-06 12:18:25 | INFO | train_inner | epoch 038:   1152 / 1191 loss=1.833, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.605, task_loss=2.004, task_loss_gen=6.225, contrastive_loss=0, total=6688.64, n_correct=4724.66, ppl=3.56, accuracy=70.637, wps=18531.6, ups=1.39, wpb=13377.3, bsz=448.4, num_updates=45200, lr=6.6519e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=39814
2023-09-06 12:18:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
2023-09-06 12:19:26 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.687 | trans_loss 4.899 | nll_loss 2.123 | w2v_ctc_loss 1.222 | task_loss 11.828 | task_loss_gen 14.459 | contrastive_loss 0 | total 6138.43 | n_correct 4343.29 | ppl 4.36 | accuracy 70.756 | uer 17.348 | wer 18.84 | raw_wer 18.84 | bleu 28.42 | wps 1780 | wpb 6138.4 | bsz 201.1 | num_updates 45239 | best_bleu 28.48
2023-09-06 12:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45239 updates
2023-09-06 12:19:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt
2023-09-06 12:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt
2023-09-06 12:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt (epoch 38 @ 45239 updates, score 28.42) (writing took 8.190815735957585 seconds)
2023-09-06 12:19:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-09-06 12:19:35 | INFO | train | epoch 038 | loss 1.834 | trans_loss 4.636 | nll_loss 1.83 | w2v_ctc_loss 0.607 | task_loss 1.956 | task_loss_gen 6.172 | contrastive_loss 0 | total 6703.69 | n_correct 4735.87 | ppl 3.56 | accuracy 70.646 | wps 17400.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 45239 | lr 6.64903e-05 | gnorm 0.383 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 13.8 | wall 39885
2023-09-06 12:19:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:19:35 | INFO | fairseq.trainer | begin training epoch 39
2023-09-06 12:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:20:28 | INFO | train_inner | epoch 039:     61 / 1191 loss=1.833, trans_loss=4.633, nll_loss=1.826, w2v_ctc_loss=0.605, task_loss=2.293, task_loss_gen=6.889, contrastive_loss=0, total=6527.07, n_correct=4618.88, ppl=3.54, accuracy=70.765, wps=10601, ups=0.81, wpb=13054.1, bsz=420.4, num_updates=45300, lr=6.64455e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=10.1, wall=39938
2023-09-06 12:21:40 | INFO | train_inner | epoch 039:    161 / 1191 loss=1.825, trans_loss=4.621, nll_loss=1.81, w2v_ctc_loss=0.598, task_loss=2.072, task_loss_gen=6.39, contrastive_loss=0, total=6683.06, n_correct=4746.07, ppl=3.51, accuracy=71.016, wps=18419.1, ups=1.38, wpb=13366.1, bsz=440.5, num_updates=45400, lr=6.63723e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=40010
2023-09-06 12:22:53 | INFO | train_inner | epoch 039:    261 / 1191 loss=1.832, trans_loss=4.634, nll_loss=1.827, w2v_ctc_loss=0.604, task_loss=2.601, task_loss_gen=6.339, contrastive_loss=0, total=6673.47, n_correct=4717.58, ppl=3.55, accuracy=70.692, wps=18335.4, ups=1.37, wpb=13346.9, bsz=445, num_updates=45500, lr=6.62994e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=40083
2023-09-06 12:24:07 | INFO | train_inner | epoch 039:    361 / 1191 loss=1.833, trans_loss=4.629, nll_loss=1.821, w2v_ctc_loss=0.609, task_loss=2.581, task_loss_gen=6.325, contrastive_loss=0, total=6602.39, n_correct=4677.77, ppl=3.53, accuracy=70.85, wps=17968.3, ups=1.36, wpb=13204.8, bsz=427.5, num_updates=45600, lr=6.62266e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=40156
2023-09-06 12:25:19 | INFO | train_inner | epoch 039:    461 / 1191 loss=1.824, trans_loss=4.625, nll_loss=1.816, w2v_ctc_loss=0.594, task_loss=2.124, task_loss_gen=6.163, contrastive_loss=0, total=6752.25, n_correct=4789.08, ppl=3.52, accuracy=70.926, wps=18584.5, ups=1.38, wpb=13504.5, bsz=462.8, num_updates=45700, lr=6.61541e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=40229
2023-09-06 12:26:32 | INFO | train_inner | epoch 039:    561 / 1191 loss=1.826, trans_loss=4.623, nll_loss=1.814, w2v_ctc_loss=0.598, task_loss=2.067, task_loss_gen=6.386, contrastive_loss=0, total=6699.88, n_correct=4752.56, ppl=3.52, accuracy=70.935, wps=18401.2, ups=1.37, wpb=13399.8, bsz=450.3, num_updates=45800, lr=6.60819e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=40302
2023-09-06 12:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 12:27:46 | INFO | train_inner | epoch 039:    662 / 1191 loss=1.829, trans_loss=4.632, nll_loss=1.824, w2v_ctc_loss=0.603, task_loss=1.98, task_loss_gen=6.393, contrastive_loss=0, total=6707.94, n_correct=4744.18, ppl=3.54, accuracy=70.725, wps=18186.4, ups=1.36, wpb=13415.9, bsz=462.7, num_updates=45900, lr=6.60098e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=73, gb_free=6.1, wall=40376
2023-09-06 12:28:59 | INFO | train_inner | epoch 039:    762 / 1191 loss=1.83, trans_loss=4.632, nll_loss=1.824, w2v_ctc_loss=0.605, task_loss=2.059, task_loss_gen=6.301, contrastive_loss=0, total=6736.15, n_correct=4766.53, ppl=3.54, accuracy=70.76, wps=18384, ups=1.36, wpb=13472.3, bsz=455.3, num_updates=46000, lr=6.5938e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=12.7, wall=40449
2023-09-06 12:28:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:29:32 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.892 | nll_loss 2.114 | w2v_ctc_loss 1.189 | task_loss 11.979 | task_loss_gen 14.682 | contrastive_loss 0 | total 6138.43 | n_correct 4347 | ppl 4.33 | accuracy 70.816 | uer 17.26 | wer 18.661 | raw_wer 18.661 | bleu 28.72 | wps 1739.8 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 28.72
2023-09-06 12:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-09-06 12:29:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-06 12:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-06 12:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 28.72) (writing took 14.484925823984668 seconds)
--Backword ST Loss tensor(2797.3718, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1596.1881, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:30:59 | INFO | train_inner | epoch 039:    862 / 1191 loss=1.827, trans_loss=4.631, nll_loss=1.824, w2v_ctc_loss=0.599, task_loss=1.763, task_loss_gen=6.143, contrastive_loss=0, total=6798.2, n_correct=4814.61, ppl=3.54, accuracy=70.822, wps=11299.8, ups=0.83, wpb=13596.4, bsz=472.1, num_updates=46100, lr=6.58665e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=40569
2023-09-06 12:32:12 | INFO | train_inner | epoch 039:    962 / 1191 loss=1.821, trans_loss=4.622, nll_loss=1.812, w2v_ctc_loss=0.595, task_loss=1.862, task_loss_gen=5.887, contrastive_loss=0, total=6835.31, n_correct=4850.18, ppl=3.51, accuracy=70.958, wps=18729.2, ups=1.37, wpb=13670.6, bsz=480.9, num_updates=46200, lr=6.57952e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=40642
2023-09-06 12:33:25 | INFO | train_inner | epoch 039:   1062 / 1191 loss=1.822, trans_loss=4.624, nll_loss=1.815, w2v_ctc_loss=0.592, task_loss=2.006, task_loss_gen=6.05, contrastive_loss=0, total=6757.98, n_correct=4794.51, ppl=3.52, accuracy=70.946, wps=18672.8, ups=1.38, wpb=13516, bsz=459.7, num_updates=46300, lr=6.57241e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=40715
2023-09-06 12:34:37 | INFO | train_inner | epoch 039:   1162 / 1191 loss=1.837, trans_loss=4.633, nll_loss=1.825, w2v_ctc_loss=0.615, task_loss=2.267, task_loss_gen=6.709, contrastive_loss=0, total=6582.59, n_correct=4653.19, ppl=3.54, accuracy=70.689, wps=18160.7, ups=1.38, wpb=13165.2, bsz=428.8, num_updates=46400, lr=6.56532e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=40787
2023-09-06 12:34:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2541.7473, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1418.5901, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2095.0024, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1310.1160, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2316.9895, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1461.6812, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2651.2571, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1556.9844, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2435.6958, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1438.0281, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2181.4453, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1172.4755, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1851.2646, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1067.9636, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 12:35:31 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.895 | nll_loss 2.118 | w2v_ctc_loss 1.192 | task_loss 32.414 | task_loss_gen 19.448 | contrastive_loss 0 | total 6138.43 | n_correct 4345.57 | ppl 4.34 | accuracy 70.793 | uer 17.18 | wer 18.672 | raw_wer 18.672 | bleu 28.31 | wps 1726.4 | wpb 6138.4 | bsz 201.1 | num_updates 46429 | best_bleu 28.72
2023-09-06 12:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46429 updates
2023-09-06 12:35:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt
2023-09-06 12:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt
2023-09-06 12:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt (epoch 39 @ 46429 updates, score 28.31) (writing took 8.6472507850267 seconds)
2023-09-06 12:35:40 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-09-06 12:35:40 | INFO | train | epoch 039 | loss 1.828 | trans_loss 4.628 | nll_loss 1.819 | w2v_ctc_loss 0.601 | task_loss 2.128 | task_loss_gen 6.284 | contrastive_loss 0 | total 6703.27 | n_correct 4749.3 | ppl 3.53 | accuracy 70.851 | wps 16522.4 | ups 1.23 | wpb 13406.5 | bsz 452.1 | num_updates 46429 | lr 6.56327e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 13.1 | wall 40850
2023-09-06 12:35:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:35:41 | INFO | fairseq.trainer | begin training epoch 40
2023-09-06 12:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:36:40 | INFO | train_inner | epoch 040:     71 / 1191 loss=1.817, trans_loss=4.614, nll_loss=1.802, w2v_ctc_loss=0.591, task_loss=2.072, task_loss_gen=5.935, contrastive_loss=0, total=6767.38, n_correct=4812.29, ppl=3.49, accuracy=71.11, wps=11057.1, ups=0.82, wpb=13534.8, bsz=468.9, num_updates=46500, lr=6.55826e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=40910
2023-09-06 12:37:52 | INFO | train_inner | epoch 040:    171 / 1191 loss=1.822, trans_loss=4.617, nll_loss=1.805, w2v_ctc_loss=0.599, task_loss=2.388, task_loss_gen=6.035, contrastive_loss=0, total=6723.92, n_correct=4786.7, ppl=3.49, accuracy=71.189, wps=18725.2, ups=1.39, wpb=13447.8, bsz=450.2, num_updates=46600, lr=6.55122e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=40981
2023-09-06 12:39:04 | INFO | train_inner | epoch 040:    271 / 1191 loss=1.816, trans_loss=4.615, nll_loss=1.803, w2v_ctc_loss=0.589, task_loss=2.065, task_loss_gen=5.806, contrastive_loss=0, total=6753.31, n_correct=4802.28, ppl=3.49, accuracy=71.11, wps=18652.6, ups=1.38, wpb=13506.6, bsz=465.8, num_updates=46700, lr=6.5442e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=41054
2023-09-06 12:40:17 | INFO | train_inner | epoch 040:    371 / 1191 loss=1.826, trans_loss=4.62, nll_loss=1.81, w2v_ctc_loss=0.6, task_loss=2.259, task_loss_gen=6.625, contrastive_loss=0, total=6618.47, n_correct=4698.37, ppl=3.51, accuracy=70.989, wps=18062.8, ups=1.36, wpb=13236.9, bsz=438.2, num_updates=46800, lr=6.5372e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=41127
2023-09-06 12:41:30 | INFO | train_inner | epoch 040:    471 / 1191 loss=1.818, trans_loss=4.617, nll_loss=1.805, w2v_ctc_loss=0.591, task_loss=2.268, task_loss_gen=6.182, contrastive_loss=0, total=6719.05, n_correct=4781.41, ppl=3.5, accuracy=71.162, wps=18471, ups=1.37, wpb=13438.1, bsz=454.8, num_updates=46900, lr=6.53023e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=41200
2023-09-06 12:42:42 | INFO | train_inner | epoch 040:    571 / 1191 loss=1.818, trans_loss=4.618, nll_loss=1.807, w2v_ctc_loss=0.587, task_loss=2.249, task_loss_gen=5.869, contrastive_loss=0, total=6684.61, n_correct=4750.58, ppl=3.5, accuracy=71.067, wps=18462.9, ups=1.38, wpb=13369.2, bsz=455.8, num_updates=47000, lr=6.52328e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=41272
2023-09-06 12:43:56 | INFO | train_inner | epoch 040:    671 / 1191 loss=1.823, trans_loss=4.621, nll_loss=1.81, w2v_ctc_loss=0.595, task_loss=2.256, task_loss_gen=6.344, contrastive_loss=0, total=6699.46, n_correct=4755.32, ppl=3.51, accuracy=70.981, wps=18220.4, ups=1.36, wpb=13398.9, bsz=447.6, num_updates=47100, lr=6.51635e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=7.6, wall=41346
2023-09-06 12:45:09 | INFO | train_inner | epoch 040:    771 / 1191 loss=1.826, trans_loss=4.621, nll_loss=1.811, w2v_ctc_loss=0.602, task_loss=2.491, task_loss_gen=6.285, contrastive_loss=0, total=6659.73, n_correct=4729.33, ppl=3.51, accuracy=71.014, wps=18275.2, ups=1.37, wpb=13319.5, bsz=443.6, num_updates=47200, lr=6.50945e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=41419
2023-09-06 12:46:22 | INFO | train_inner | epoch 040:    871 / 1191 loss=1.827, trans_loss=4.624, nll_loss=1.815, w2v_ctc_loss=0.6, task_loss=2.559, task_loss_gen=6.113, contrastive_loss=0, total=6696.57, n_correct=4749.88, ppl=3.52, accuracy=70.93, wps=18223, ups=1.36, wpb=13393.1, bsz=441.7, num_updates=47300, lr=6.50256e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=41492
2023-09-06 12:47:35 | INFO | train_inner | epoch 040:    971 / 1191 loss=1.825, trans_loss=4.628, nll_loss=1.82, w2v_ctc_loss=0.594, task_loss=2.207, task_loss_gen=5.948, contrastive_loss=0, total=6694.1, n_correct=4747.47, ppl=3.53, accuracy=70.92, wps=18528.2, ups=1.38, wpb=13388.2, bsz=455.1, num_updates=47400, lr=6.4957e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=41565
2023-09-06 12:48:48 | INFO | train_inner | epoch 040:   1071 / 1191 loss=1.823, trans_loss=4.619, nll_loss=1.809, w2v_ctc_loss=0.601, task_loss=2.404, task_loss_gen=5.983, contrastive_loss=0, total=6744.49, n_correct=4790.34, ppl=3.5, accuracy=71.026, wps=18434.2, ups=1.37, wpb=13489, bsz=455.8, num_updates=47500, lr=6.48886e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=41638
2023-09-06 12:50:01 | INFO | train_inner | epoch 040:   1171 / 1191 loss=1.817, trans_loss=4.619, nll_loss=1.809, w2v_ctc_loss=0.586, task_loss=2.131, task_loss_gen=6.017, contrastive_loss=0, total=6706.26, n_correct=4768.15, ppl=3.5, accuracy=71.1, wps=18444.4, ups=1.38, wpb=13412.5, bsz=463.1, num_updates=47600, lr=6.48204e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=41710
2023-09-06 12:50:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:50:48 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.888 | nll_loss 2.11 | w2v_ctc_loss 1.157 | task_loss 15.74 | task_loss_gen 15.158 | contrastive_loss 0 | total 6138.43 | n_correct 4347.14 | ppl 4.32 | accuracy 70.818 | uer 17.132 | wer 18.657 | raw_wer 18.657 | bleu 28.38 | wps 1745.9 | wpb 6138.4 | bsz 201.1 | num_updates 47620 | best_bleu 28.72
2023-09-06 12:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47620 updates
2023-09-06 12:50:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt
2023-09-06 12:50:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt
2023-09-06 12:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt (epoch 40 @ 47620 updates, score 28.38) (writing took 7.713489155983552 seconds)
2023-09-06 12:50:56 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-09-06 12:50:56 | INFO | train | epoch 040 | loss 1.822 | trans_loss 4.62 | nll_loss 1.809 | w2v_ctc_loss 0.594 | task_loss 2.281 | task_loss_gen 6.118 | contrastive_loss 0 | total 6703.69 | n_correct 4762.69 | ppl 3.5 | accuracy 71.046 | wps 17436.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 47620 | lr 6.48068e-05 | gnorm 0.386 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 11.9 | wall 41766
2023-09-06 12:50:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:50:56 | INFO | fairseq.trainer | begin training epoch 41
2023-09-06 12:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:52:02 | INFO | train_inner | epoch 041:     80 / 1191 loss=1.816, trans_loss=4.615, nll_loss=1.803, w2v_ctc_loss=0.588, task_loss=2.405, task_loss_gen=5.995, contrastive_loss=0, total=6708.43, n_correct=4776.38, ppl=3.49, accuracy=71.2, wps=11014.6, ups=0.82, wpb=13416.9, bsz=461.1, num_updates=47700, lr=6.47524e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=41832
2023-09-06 12:53:15 | INFO | train_inner | epoch 041:    180 / 1191 loss=1.821, trans_loss=4.614, nll_loss=1.801, w2v_ctc_loss=0.594, task_loss=2.172, task_loss_gen=6.323, contrastive_loss=0, total=6679.28, n_correct=4747.32, ppl=3.49, accuracy=71.075, wps=18511.1, ups=1.39, wpb=13358.6, bsz=446.1, num_updates=47800, lr=6.46846e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=41904
2023-09-06 12:54:28 | INFO | train_inner | epoch 041:    280 / 1191 loss=1.81, trans_loss=4.609, nll_loss=1.796, w2v_ctc_loss=0.582, task_loss=1.956, task_loss_gen=5.848, contrastive_loss=0, total=6799.31, n_correct=4851.95, ppl=3.47, accuracy=71.359, wps=18512.7, ups=1.36, wpb=13598.6, bsz=478, num_updates=47900, lr=6.46171e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=73, gb_free=13.6, wall=41978
2023-09-06 12:55:41 | INFO | train_inner | epoch 041:    380 / 1191 loss=1.813, trans_loss=4.61, nll_loss=1.797, w2v_ctc_loss=0.587, task_loss=1.611, task_loss_gen=6.663, contrastive_loss=0, total=6787.95, n_correct=4843.29, ppl=3.48, accuracy=71.351, wps=18575.7, ups=1.37, wpb=13575.9, bsz=460.8, num_updates=48000, lr=6.45497e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=42051
2023-09-06 12:55:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:56:14 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.668 | trans_loss 4.893 | nll_loss 2.116 | w2v_ctc_loss 1.174 | task_loss 22.324 | task_loss_gen 15.948 | contrastive_loss 0 | total 6138.43 | n_correct 4352.71 | ppl 4.34 | accuracy 70.909 | uer 17.279 | wer 18.736 | raw_wer 18.736 | bleu 28.64 | wps 1747.9 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 28.72
2023-09-06 12:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-09-06 12:56:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-06 12:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-06 12:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 28.64) (writing took 9.281694228993729 seconds)
--Backword ST Loss tensor(1687.9701, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(985.9595, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:57:36 | INFO | train_inner | epoch 041:    480 / 1191 loss=1.816, trans_loss=4.611, nll_loss=1.798, w2v_ctc_loss=0.593, task_loss=1.67, task_loss_gen=6.795, contrastive_loss=0, total=6778.68, n_correct=4837.4, ppl=3.48, accuracy=71.362, wps=11756.1, ups=0.87, wpb=13557.4, bsz=458.9, num_updates=48100, lr=6.44826e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=42166
2023-09-06 12:58:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 12:58:50 | INFO | train_inner | epoch 041:    581 / 1191 loss=1.809, trans_loss=4.605, nll_loss=1.79, w2v_ctc_loss=0.579, task_loss=1.533, task_loss_gen=7.01, contrastive_loss=0, total=6791.35, n_correct=4850.65, ppl=3.46, accuracy=71.424, wps=18568.6, ups=1.37, wpb=13582.7, bsz=462.3, num_updates=48200, lr=6.44157e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=72, gb_free=10.9, wall=42239
2023-09-06 13:00:02 | INFO | train_inner | epoch 041:    681 / 1191 loss=1.817, trans_loss=4.612, nll_loss=1.799, w2v_ctc_loss=0.593, task_loss=2.048, task_loss_gen=6.568, contrastive_loss=0, total=6677.75, n_correct=4756.62, ppl=3.48, accuracy=71.231, wps=18447.9, ups=1.38, wpb=13355.5, bsz=448.7, num_updates=48300, lr=6.43489e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=10.3, wall=42312
2023-09-06 13:01:15 | INFO | train_inner | epoch 041:    781 / 1191 loss=1.821, trans_loss=4.612, nll_loss=1.799, w2v_ctc_loss=0.597, task_loss=2.349, task_loss_gen=6.69, contrastive_loss=0, total=6547.43, n_correct=4660.12, ppl=3.48, accuracy=71.175, wps=18003.4, ups=1.37, wpb=13094.9, bsz=422.4, num_updates=48400, lr=6.42824e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=42385
2023-09-06 13:02:28 | INFO | train_inner | epoch 041:    881 / 1191 loss=1.818, trans_loss=4.61, nll_loss=1.796, w2v_ctc_loss=0.591, task_loss=2.441, task_loss_gen=6.465, contrastive_loss=0, total=6581.95, n_correct=4688.7, ppl=3.47, accuracy=71.236, wps=17973.4, ups=1.37, wpb=13163.9, bsz=427.6, num_updates=48500, lr=6.42161e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=10.4, wall=42458
2023-09-06 13:03:41 | INFO | train_inner | epoch 041:    981 / 1191 loss=1.823, trans_loss=4.62, nll_loss=1.811, w2v_ctc_loss=0.596, task_loss=2.514, task_loss_gen=6.483, contrastive_loss=0, total=6677.96, n_correct=4740.62, ppl=3.51, accuracy=70.989, wps=18236.7, ups=1.37, wpb=13355.9, bsz=444.6, num_updates=48600, lr=6.415e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=73, gb_free=13.8, wall=42531
2023-09-06 13:04:55 | INFO | train_inner | epoch 041:   1081 / 1191 loss=1.815, trans_loss=4.616, nll_loss=1.805, w2v_ctc_loss=0.588, task_loss=2.438, task_loss_gen=5.829, contrastive_loss=0, total=6841.34, n_correct=4874.27, ppl=3.49, accuracy=71.247, wps=18657.7, ups=1.36, wpb=13682.7, bsz=478.7, num_updates=48700, lr=6.40841e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=42604
2023-09-06 13:06:07 | INFO | train_inner | epoch 041:   1181 / 1191 loss=1.819, trans_loss=4.615, nll_loss=1.804, w2v_ctc_loss=0.589, task_loss=2.443, task_loss_gen=6.651, contrastive_loss=0, total=6589.42, n_correct=4689.07, ppl=3.49, accuracy=71.161, wps=18243.6, ups=1.38, wpb=13178.8, bsz=431.4, num_updates=48800, lr=6.40184e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=42677
2023-09-06 13:06:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1781.7280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1082.5361, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1912.5507, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1139.8356, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3617.3083, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(2218.8662, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1320.2130, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(737.5485, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2227.6731, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1271.6799, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2076.0674, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1156.4071, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2408.7302, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1482.7592, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 13:06:47 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.674 | trans_loss 4.893 | nll_loss 2.116 | w2v_ctc_loss 1.194 | task_loss 30.392 | task_loss_gen 18.337 | contrastive_loss 0 | total 6138.43 | n_correct 4347 | ppl 4.34 | accuracy 70.816 | uer 17.239 | wer 18.873 | raw_wer 18.873 | bleu 28.66 | wps 1750.1 | wpb 6138.4 | bsz 201.1 | num_updates 48810 | best_bleu 28.72
2023-09-06 13:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48810 updates
2023-09-06 13:06:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt
2023-09-06 13:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt
2023-09-06 13:06:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt (epoch 41 @ 48810 updates, score 28.66) (writing took 8.731995202950202 seconds)
2023-09-06 13:06:56 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-09-06 13:06:56 | INFO | train | epoch 041 | loss 1.816 | trans_loss 4.612 | nll_loss 1.8 | w2v_ctc_loss 0.589 | task_loss 2.123 | task_loss_gen 6.434 | contrastive_loss 0 | total 6704.36 | n_correct 4776.42 | ppl 3.48 | accuracy 71.244 | wps 16625.1 | ups 1.24 | wpb 13408.7 | bsz 452.2 | num_updates 48810 | lr 6.40119e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 11.3 | wall 42726
2023-09-06 13:06:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:06:56 | INFO | fairseq.trainer | begin training epoch 42
2023-09-06 13:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:08:09 | INFO | train_inner | epoch 042:     90 / 1191 loss=1.803, trans_loss=4.6, nll_loss=1.784, w2v_ctc_loss=0.574, task_loss=2.218, task_loss_gen=5.522, contrastive_loss=0, total=6824.86, n_correct=4884.58, ppl=3.44, accuracy=71.57, wps=11208.1, ups=0.82, wpb=13649.7, bsz=483.3, num_updates=48900, lr=6.39529e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=42798
2023-09-06 13:09:22 | INFO | train_inner | epoch 042:    190 / 1191 loss=1.814, trans_loss=4.607, nll_loss=1.793, w2v_ctc_loss=0.583, task_loss=2.361, task_loss_gen=6.215, contrastive_loss=0, total=6671.53, n_correct=4756.64, ppl=3.46, accuracy=71.298, wps=18181.7, ups=1.36, wpb=13343.1, bsz=441.1, num_updates=49000, lr=6.38877e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=42872
2023-09-06 13:10:35 | INFO | train_inner | epoch 042:    290 / 1191 loss=1.812, trans_loss=4.6, nll_loss=1.784, w2v_ctc_loss=0.589, task_loss=2.639, task_loss_gen=6.328, contrastive_loss=0, total=6650.86, n_correct=4753.68, ppl=3.44, accuracy=71.475, wps=18173.8, ups=1.37, wpb=13301.7, bsz=445.5, num_updates=49100, lr=6.38226e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=42945
2023-09-06 13:11:48 | INFO | train_inner | epoch 042:    390 / 1191 loss=1.809, trans_loss=4.601, nll_loss=1.786, w2v_ctc_loss=0.583, task_loss=2.782, task_loss_gen=6.291, contrastive_loss=0, total=6626.36, n_correct=4735.76, ppl=3.45, accuracy=71.468, wps=18173.5, ups=1.37, wpb=13252.7, bsz=447.3, num_updates=49200, lr=6.37577e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=43018
2023-09-06 13:13:01 | INFO | train_inner | epoch 042:    490 / 1191 loss=1.816, trans_loss=4.608, nll_loss=1.794, w2v_ctc_loss=0.587, task_loss=3.033, task_loss_gen=6.483, contrastive_loss=0, total=6622.87, n_correct=4724.41, ppl=3.47, accuracy=71.335, wps=18110.6, ups=1.37, wpb=13245.7, bsz=418.4, num_updates=49300, lr=6.3693e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=43091
2023-09-06 13:14:14 | INFO | train_inner | epoch 042:    590 / 1191 loss=1.821, trans_loss=4.611, nll_loss=1.799, w2v_ctc_loss=0.598, task_loss=2.747, task_loss_gen=6.362, contrastive_loss=0, total=6598.24, n_correct=4697.99, ppl=3.48, accuracy=71.201, wps=18233.3, ups=1.38, wpb=13196.5, bsz=431.9, num_updates=49400, lr=6.36285e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=12, wall=43163
2023-09-06 13:15:26 | INFO | train_inner | epoch 042:    690 / 1191 loss=1.808, trans_loss=4.606, nll_loss=1.792, w2v_ctc_loss=0.58, task_loss=2.248, task_loss_gen=5.606, contrastive_loss=0, total=6827.49, n_correct=4881.49, ppl=3.46, accuracy=71.498, wps=18787.4, ups=1.38, wpb=13655, bsz=480.8, num_updates=49500, lr=6.35642e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=8.4, wall=43236
2023-09-06 13:16:39 | INFO | train_inner | epoch 042:    790 / 1191 loss=1.814, trans_loss=4.611, nll_loss=1.798, w2v_ctc_loss=0.59, task_loss=2.301, task_loss_gen=5.936, contrastive_loss=0, total=6715.54, n_correct=4789.81, ppl=3.48, accuracy=71.324, wps=18503.2, ups=1.38, wpb=13431.1, bsz=463.9, num_updates=49600, lr=6.35001e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=43309
2023-09-06 13:17:51 | INFO | train_inner | epoch 042:    890 / 1191 loss=1.81, trans_loss=4.601, nll_loss=1.785, w2v_ctc_loss=0.583, task_loss=2.313, task_loss_gen=6.419, contrastive_loss=0, total=6567.62, n_correct=4694.3, ppl=3.45, accuracy=71.476, wps=18244.8, ups=1.39, wpb=13135.2, bsz=440.7, num_updates=49700, lr=6.34361e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=43381
2023-09-06 13:19:04 | INFO | train_inner | epoch 042:    990 / 1191 loss=1.805, trans_loss=4.603, nll_loss=1.79, w2v_ctc_loss=0.576, task_loss=2.036, task_loss_gen=5.685, contrastive_loss=0, total=6827.16, n_correct=4876.74, ppl=3.46, accuracy=71.431, wps=18678.1, ups=1.37, wpb=13654.3, bsz=484, num_updates=49800, lr=6.33724e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=43454
2023-09-06 13:20:16 | INFO | train_inner | epoch 042:   1090 / 1191 loss=1.815, trans_loss=4.608, nll_loss=1.794, w2v_ctc_loss=0.586, task_loss=2.398, task_loss_gen=6.87, contrastive_loss=0, total=6664.62, n_correct=4753.72, ppl=3.47, accuracy=71.328, wps=18430.5, ups=1.38, wpb=13329.2, bsz=421.6, num_updates=49900, lr=6.33089e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=43526
2023-09-06 13:21:29 | INFO | train_inner | epoch 042:   1190 / 1191 loss=1.81, trans_loss=4.604, nll_loss=1.79, w2v_ctc_loss=0.585, task_loss=1.884, task_loss_gen=6.429, contrastive_loss=0, total=6824.38, n_correct=4878.68, ppl=3.46, accuracy=71.489, wps=18686.8, ups=1.37, wpb=13648.8, bsz=463.9, num_updates=50000, lr=6.32456e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=43599
2023-09-06 13:21:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-06 13:21:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 13:22:02 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.666 | trans_loss 4.883 | nll_loss 2.105 | w2v_ctc_loss 1.188 | task_loss 17.003 | task_loss_gen 15.493 | contrastive_loss 0 | total 6138.43 | n_correct 4353 | ppl 4.3 | accuracy 70.914 | uer 17.158 | wer 18.643 | raw_wer 18.643 | bleu 28.65 | wps 1728.4 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 28.72
2023-09-06 13:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50000 updates
2023-09-06 13:22:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt
2023-09-06 13:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt
2023-09-06 13:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt (epoch 42 @ 50000 updates, score 28.65) (writing took 9.404174275929108 seconds)
2023-09-06 13:22:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-09-06 13:22:13 | INFO | train | epoch 042 | loss 1.811 | trans_loss 4.605 | nll_loss 1.791 | w2v_ctc_loss 0.584 | task_loss 2.4 | task_loss_gen 6.153 | contrastive_loss 0 | total 6705.54 | n_correct 4788.29 | ppl 3.46 | accuracy 71.408 | wps 17412.5 | ups 1.3 | wpb 13411.1 | bsz 452.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 14.2 | wall 43642
2023-09-06 13:22:13 | INFO | fairseq_cli.train | done training in 43587.3 seconds
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1728 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-06 13:36:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16744', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-06 13:36:24 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 13:36:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-06 13:36:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-06 13:36:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-06 13:36:30 | INFO | root | load pretrained hubert
2023-09-06 13:36:38 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 13:36:41 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 13:36:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 13:36:48 | INFO | root | share the sematic adapter and textual encoder
2023-09-06 13:36:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-06 13:36:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-06 13:36:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-06 13:36:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-06 13:36:48 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-09-06 13:36:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-06 13:36:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 13:36:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:36:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:36:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 13:37:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-06 13:37:04 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 13:37:04 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-06 13:37:04 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-09-06 13:37:04 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 13:37:07 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
2023-09-06 13:37:23 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-06 13:37:24 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt (epoch 42 @ 50000 updates)
2023-09-06 13:37:24 | INFO | fairseq.trainer | loading train data for epoch 42
2023-09-06 13:37:24 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 13:37:24 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:37:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:37:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 13:37:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
2023-09-06 13:38:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:38:24 | INFO | fairseq.trainer | begin training epoch 42
2023-09-06 13:38:24 | INFO | fairseq_cli.train | Start iterating over samples
--Backword ST Loss tensor(1718.1373, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1021.0747, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 13:38:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1544.7151, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(901.5706, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(0., device='cuda:7', grad_fn=<MulBackward0>) 	MT Loss tensor(1474.5765, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(1379.3282, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(788.9484, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(2725.9148, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1605.6843, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(0., device='cuda:6', grad_fn=<MulBackward0>) 	MT Loss tensor(1474.5765, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(2211.3982, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1313.1876, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(1982.1458, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1240.6178, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-06 13:39:07 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.666 | trans_loss 4.884 | nll_loss 2.106 | w2v_ctc_loss 1.186 | task_loss 16.727 | task_loss_gen 15.505 | contrastive_loss 0 | total 6138.43 | n_correct 4351.29 | ppl 4.31 | accuracy 70.886 | uer 17.164 | wer 18.646 | raw_wer 18.646 | bleu 28.61 | wps 1720.4 | wpb 6138.4 | bsz 201.1 | num_updates 50001 | best_bleu 28.72
2023-09-06 13:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50001 updates
2023-09-06 13:39:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt
2023-09-06 13:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt
2023-09-06 13:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt (epoch 42 @ 50001 updates, score 28.61) (writing took 8.464933410985395 seconds)
2023-09-06 13:39:16 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-09-06 13:39:16 | INFO | train | epoch 042 | loss 1.811 | trans_loss 4.605 | nll_loss 1.791 | w2v_ctc_loss 0.584 | task_loss 2.4 | task_loss_gen 6.156 | contrastive_loss 0 | total 6703.69 | n_correct 4787 | ppl 3.46 | accuracy 71.408 | wps 15682.3 | ups 1.17 | wpb 13407.4 | bsz 452.1 | num_updates 50001 | lr 6.32449e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 11.1 | wall 0
2023-09-06 13:39:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:39:16 | INFO | fairseq.trainer | begin training epoch 43
2023-09-06 13:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:40:38 | INFO | train_inner | epoch 043:     99 / 1191 loss=1.804, trans_loss=4.594, nll_loss=1.777, w2v_ctc_loss=0.576, task_loss=2.523, task_loss_gen=6.5, contrastive_loss=0, total=6732.96, n_correct=4827.73, ppl=3.43, accuracy=71.703, wps=5933, ups=0.44, wpb=13465.9, bsz=453.1, num_updates=50100, lr=6.31824e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=77, gb_free=11.3, wall=0
2023-09-06 13:41:53 | INFO | train_inner | epoch 043:    199 / 1191 loss=1.81, trans_loss=4.599, nll_loss=1.783, w2v_ctc_loss=0.583, task_loss=2.802, task_loss_gen=6.737, contrastive_loss=0, total=6600.22, n_correct=4721.61, ppl=3.44, accuracy=71.537, wps=17703.5, ups=1.34, wpb=13200.4, bsz=424.1, num_updates=50200, lr=6.31194e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=74, gb_free=13.9, wall=0
2023-09-06 13:43:08 | INFO | train_inner | epoch 043:    299 / 1191 loss=1.804, trans_loss=4.601, nll_loss=1.786, w2v_ctc_loss=0.575, task_loss=2.458, task_loss_gen=5.85, contrastive_loss=0, total=6773.88, n_correct=4845.19, ppl=3.45, accuracy=71.528, wps=18003.5, ups=1.33, wpb=13547.8, bsz=472.8, num_updates=50300, lr=6.30567e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=75, gb_free=13.7, wall=0
2023-09-06 13:44:23 | INFO | train_inner | epoch 043:    399 / 1191 loss=1.812, trans_loss=4.605, nll_loss=1.79, w2v_ctc_loss=0.587, task_loss=2.895, task_loss_gen=5.889, contrastive_loss=0, total=6701.97, n_correct=4789.29, ppl=3.46, accuracy=71.461, wps=17895.7, ups=1.34, wpb=13403.9, bsz=453.3, num_updates=50400, lr=6.29941e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=74, gb_free=12.6, wall=0
2023-09-06 13:45:37 | INFO | train_inner | epoch 043:    499 / 1191 loss=1.806, trans_loss=4.597, nll_loss=1.78, w2v_ctc_loss=0.578, task_loss=2.665, task_loss_gen=6.032, contrastive_loss=0, total=6702.87, n_correct=4802.7, ppl=3.43, accuracy=71.651, wps=18078.4, ups=1.35, wpb=13405.7, bsz=449.6, num_updates=50500, lr=6.29317e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=74, gb_free=14.1, wall=0
2023-09-06 13:46:52 | INFO | train_inner | epoch 043:    599 / 1191 loss=1.815, trans_loss=4.603, nll_loss=1.788, w2v_ctc_loss=0.591, task_loss=2.962, task_loss_gen=6.562, contrastive_loss=0, total=6674.04, n_correct=4764.55, ppl=3.45, accuracy=71.389, wps=17784.8, ups=1.33, wpb=13348.1, bsz=434.8, num_updates=50600, lr=6.28695e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=74, gb_free=14.2, wall=0
2023-09-06 13:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 13:48:06 | INFO | train_inner | epoch 043:    700 / 1191 loss=1.806, trans_loss=4.592, nll_loss=1.774, w2v_ctc_loss=0.581, task_loss=3.168, task_loss_gen=6.116, contrastive_loss=0, total=6623.68, n_correct=4742.6, ppl=3.42, accuracy=71.601, wps=17804.9, ups=1.34, wpb=13247.4, bsz=436.9, num_updates=50700, lr=6.28074e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=74, gb_free=13.7, wall=0
2023-09-06 13:49:22 | INFO | train_inner | epoch 043:    800 / 1191 loss=1.802, trans_loss=4.596, nll_loss=1.78, w2v_ctc_loss=0.571, task_loss=3.592, task_loss_gen=5.721, contrastive_loss=0, total=6741.48, n_correct=4827.03, ppl=3.43, accuracy=71.602, wps=17775.9, ups=1.32, wpb=13483, bsz=460.1, num_updates=50800, lr=6.27456e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=75, gb_free=9, wall=0
2023-09-06 13:50:36 | INFO | train_inner | epoch 043:    900 / 1191 loss=1.812, trans_loss=4.6, nll_loss=1.785, w2v_ctc_loss=0.588, task_loss=3.86, task_loss_gen=6.023, contrastive_loss=0, total=6579.57, n_correct=4701.36, ppl=3.45, accuracy=71.454, wps=17887.5, ups=1.36, wpb=13159.1, bsz=431.2, num_updates=50900, lr=6.26839e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=73, gb_free=11.6, wall=0
2023-09-06 13:51:49 | INFO | train_inner | epoch 043:   1000 / 1191 loss=1.806, trans_loss=4.602, nll_loss=1.788, w2v_ctc_loss=0.576, task_loss=3.458, task_loss_gen=5.569, contrastive_loss=0, total=6711.09, n_correct=4801.86, ppl=3.45, accuracy=71.551, wps=18259.4, ups=1.36, wpb=13422.2, bsz=452.8, num_updates=51000, lr=6.26224e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=73, gb_free=14.4, wall=0
2023-09-06 13:53:02 | INFO | train_inner | epoch 043:   1100 / 1191 loss=1.806, trans_loss=4.603, nll_loss=1.789, w2v_ctc_loss=0.573, task_loss=3.328, task_loss_gen=5.399, contrastive_loss=0, total=6760.41, n_correct=4829.72, ppl=3.46, accuracy=71.441, wps=18526.6, ups=1.37, wpb=13520.8, bsz=471.8, num_updates=51100, lr=6.25611e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=0
2023-09-06 13:54:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 13:54:41 | INFO | dev_st | epoch 043 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.885 | nll_loss 2.103 | w2v_ctc_loss 1.203 | task_loss 25.667 | task_loss_gen 16.834 | contrastive_loss 0 | total 6138.43 | n_correct 4356.86 | ppl 4.3 | accuracy 70.977 | uer 16.982 | wer 18.397 | raw_wer 18.397 | bleu 28.64 | wps 1740.2 | wpb 6138.4 | bsz 201.1 | num_updates 51191 | best_bleu 28.72
2023-09-06 13:54:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 51191 updates
2023-09-06 13:54:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt
2023-09-06 13:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt
2023-09-06 13:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt (epoch 43 @ 51191 updates, score 28.64) (writing took 7.690105653018691 seconds)
2023-09-06 13:54:49 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-09-06 13:54:49 | INFO | train | epoch 043 | loss 1.807 | trans_loss 4.599 | nll_loss 1.784 | w2v_ctc_loss 0.58 | task_loss 3.076 | task_loss_gen 5.952 | contrastive_loss 0 | total 6703.66 | n_correct 4795.71 | ppl 3.44 | accuracy 71.539 | wps 17092.8 | ups 1.27 | wpb 13407.3 | bsz 452.2 | num_updates 51191 | lr 6.25055e-05 | gnorm 0.41 | clip 0 | loss_scale 16 | train_wall 876 | gb_free 12.4 | wall 0
2023-09-06 13:54:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:54:50 | INFO | fairseq.trainer | begin training epoch 44
2023-09-06 13:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:55:04 | INFO | train_inner | epoch 044:      9 / 1191 loss=1.806, trans_loss=4.602, nll_loss=1.787, w2v_ctc_loss=0.58, task_loss=3.282, task_loss_gen=5.271, contrastive_loss=0, total=6797.32, n_correct=4862.85, ppl=3.45, accuracy=71.541, wps=11174.8, ups=0.82, wpb=13594.6, bsz=477.7, num_updates=51200, lr=6.25e-05, gnorm=0.431, clip=0, loss_scale=16, train_wall=71, gb_free=13.2, wall=0
2023-09-06 13:56:17 | INFO | train_inner | epoch 044:    109 / 1191 loss=1.8, trans_loss=4.587, nll_loss=1.768, w2v_ctc_loss=0.569, task_loss=3.516, task_loss_gen=5.722, contrastive_loss=0, total=6679.82, n_correct=4795.68, ppl=3.41, accuracy=71.794, wps=18187.6, ups=1.36, wpb=13359.6, bsz=441.2, num_updates=51300, lr=6.24391e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=14.3, wall=0
2023-09-06 13:57:32 | INFO | train_inner | epoch 044:    209 / 1191 loss=1.802, trans_loss=4.599, nll_loss=1.784, w2v_ctc_loss=0.568, task_loss=3.503, task_loss_gen=5.629, contrastive_loss=0, total=6695.29, n_correct=4794.74, ppl=3.44, accuracy=71.614, wps=18089.3, ups=1.35, wpb=13390.6, bsz=456.1, num_updates=51400, lr=6.23783e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=13, wall=0
2023-09-06 13:58:44 | INFO | train_inner | epoch 044:    309 / 1191 loss=1.804, trans_loss=4.597, nll_loss=1.78, w2v_ctc_loss=0.573, task_loss=3.537, task_loss_gen=5.456, contrastive_loss=0, total=6700.97, n_correct=4797.14, ppl=3.43, accuracy=71.589, wps=18464.3, ups=1.38, wpb=13401.9, bsz=452.6, num_updates=51500, lr=6.23177e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=0
2023-09-06 13:59:57 | INFO | train_inner | epoch 044:    409 / 1191 loss=1.796, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.568, task_loss=3.457, task_loss_gen=5.368, contrastive_loss=0, total=6804.45, n_correct=4885.83, ppl=3.41, accuracy=71.803, wps=18713.9, ups=1.38, wpb=13608.9, bsz=473.3, num_updates=51600, lr=6.22573e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=11.2, wall=0
2023-09-06 14:01:10 | INFO | train_inner | epoch 044:    509 / 1191 loss=1.807, trans_loss=4.601, nll_loss=1.785, w2v_ctc_loss=0.577, task_loss=3.477, task_loss_gen=5.648, contrastive_loss=0, total=6655.25, n_correct=4759.73, ppl=3.45, accuracy=71.518, wps=18159.2, ups=1.36, wpb=13310.5, bsz=441.2, num_updates=51700, lr=6.2197e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=0
2023-09-06 14:02:24 | INFO | train_inner | epoch 044:    609 / 1191 loss=1.802, trans_loss=4.598, nll_loss=1.781, w2v_ctc_loss=0.57, task_loss=3.406, task_loss_gen=5.154, contrastive_loss=0, total=6833.75, n_correct=4894.87, ppl=3.44, accuracy=71.628, wps=18427.3, ups=1.35, wpb=13667.5, bsz=466, num_updates=51800, lr=6.2137e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=0
2023-09-06 14:03:38 | INFO | train_inner | epoch 044:    709 / 1191 loss=1.807, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.582, task_loss=3.642, task_loss_gen=5.391, contrastive_loss=0, total=6684.9, n_correct=4788.82, ppl=3.44, accuracy=71.636, wps=18195, ups=1.36, wpb=13369.8, bsz=447.5, num_updates=51900, lr=6.20771e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=0
2023-09-06 14:04:52 | INFO | train_inner | epoch 044:    809 / 1191 loss=1.804, trans_loss=4.593, nll_loss=1.776, w2v_ctc_loss=0.576, task_loss=3.552, task_loss_gen=5.445, contrastive_loss=0, total=6656.84, n_correct=4773.51, ppl=3.42, accuracy=71.708, wps=18011, ups=1.35, wpb=13313.7, bsz=442.1, num_updates=52000, lr=6.20174e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=73, gb_free=15.2, wall=0
2023-09-06 14:04:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:05:24 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 3.665 | trans_loss 4.883 | nll_loss 2.1 | w2v_ctc_loss 1.187 | task_loss 35.107 | task_loss_gen 19.791 | contrastive_loss 0 | total 6138.43 | n_correct 4360.71 | ppl 4.29 | accuracy 71.04 | uer 17.038 | wer 18.49 | raw_wer 18.49 | bleu 28.65 | wps 1738.4 | wpb 6138.4 | bsz 201.1 | num_updates 52000 | best_bleu 28.72
2023-09-06 14:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 52000 updates
2023-09-06 14:05:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt
2023-09-06 14:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt
2023-09-06 14:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt (epoch 44 @ 52000 updates, score 28.65) (writing took 8.818902858998626 seconds)
--Backword ST Loss tensor(1682.9839, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1005.3674, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 14:06:47 | INFO | train_inner | epoch 044:    909 / 1191 loss=1.805, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.577, task_loss=3.165, task_loss_gen=5.069, contrastive_loss=0, total=6781.41, n_correct=4860.43, ppl=3.44, accuracy=71.673, wps=11722.3, ups=0.86, wpb=13562.8, bsz=468.3, num_updates=52100, lr=6.19578e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=6.2, wall=0
2023-09-06 14:08:00 | INFO | train_inner | epoch 044:   1009 / 1191 loss=1.808, trans_loss=4.595, nll_loss=1.778, w2v_ctc_loss=0.583, task_loss=3.361, task_loss_gen=5.517, contrastive_loss=0, total=6659.98, n_correct=4764.49, ppl=3.43, accuracy=71.539, wps=18373.7, ups=1.38, wpb=13320, bsz=448.8, num_updates=52200, lr=6.18984e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=71, gb_free=12.5, wall=0
2023-09-06 14:09:12 | INFO | train_inner | epoch 044:   1109 / 1191 loss=1.802, trans_loss=4.591, nll_loss=1.773, w2v_ctc_loss=0.573, task_loss=3.433, task_loss_gen=5.618, contrastive_loss=0, total=6660.47, n_correct=4776.52, ppl=3.42, accuracy=71.714, wps=18453.1, ups=1.39, wpb=13320.9, bsz=444.5, num_updates=52300, lr=6.18392e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=71, gb_free=13.4, wall=0
2023-09-06 14:10:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2158.2170, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1306.8412, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1995.7280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1179.7162, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2415.6912, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1534.7655, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1881.2483, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1080.7881, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2609.7634, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1619.9615, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2306.8945, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1374.9971, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2928.0994, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1799.6743, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-06 14:10:46 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.885 | nll_loss 2.104 | w2v_ctc_loss 1.218 | task_loss 28.066 | task_loss_gen 18.005 | contrastive_loss 0 | total 6138.43 | n_correct 4355.57 | ppl 4.3 | accuracy 70.956 | uer 16.998 | wer 18.449 | raw_wer 18.449 | bleu 28.89 | wps 1625.1 | wpb 6138.4 | bsz 201.1 | num_updates 52382 | best_bleu 28.89
2023-09-06 14:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 52382 updates
2023-09-06 14:10:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 44 @ 52382 updates, score 28.89) (writing took 13.500149061903358 seconds)
2023-09-06 14:11:00 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-09-06 14:11:00 | INFO | train | epoch 044 | loss 1.804 | trans_loss 4.595 | nll_loss 1.779 | w2v_ctc_loss 0.575 | task_loss 3.448 | task_loss_gen 5.461 | contrastive_loss 0 | total 6703.69 | n_correct 4803.42 | ppl 3.43 | accuracy 71.653 | wps 16449.3 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 52382 | lr 6.17908e-05 | gnorm 0.43 | clip 0 | loss_scale 16 | train_wall 862 | gb_free 13.3 | wall 0
2023-09-06 14:11:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:11:00 | INFO | fairseq.trainer | begin training epoch 45
2023-09-06 14:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:11:22 | INFO | train_inner | epoch 045:     18 / 1191 loss=1.806, trans_loss=4.599, nll_loss=1.783, w2v_ctc_loss=0.583, task_loss=3.288, task_loss_gen=5.555, contrastive_loss=0, total=6632.04, n_correct=4749.21, ppl=3.44, accuracy=71.61, wps=10239.4, ups=0.77, wpb=13264.1, bsz=448.2, num_updates=52400, lr=6.17802e-05, gnorm=0.437, clip=0, loss_scale=16, train_wall=73, gb_free=9, wall=0
2023-09-06 14:12:35 | INFO | train_inner | epoch 045:    118 / 1191 loss=1.802, trans_loss=4.592, nll_loss=1.774, w2v_ctc_loss=0.568, task_loss=3.466, task_loss_gen=5.838, contrastive_loss=0, total=6670.4, n_correct=4785.24, ppl=3.42, accuracy=71.738, wps=18258.4, ups=1.37, wpb=13340.8, bsz=433.5, num_updates=52500, lr=6.17213e-05, gnorm=0.436, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:13:47 | INFO | train_inner | epoch 045:    218 / 1191 loss=1.798, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.569, task_loss=3.163, task_loss_gen=5.312, contrastive_loss=0, total=6727.47, n_correct=4835.67, ppl=3.4, accuracy=71.879, wps=18526.8, ups=1.38, wpb=13454.9, bsz=448.7, num_updates=52600, lr=6.16626e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=0
2023-09-06 14:15:00 | INFO | train_inner | epoch 045:    318 / 1191 loss=1.793, trans_loss=4.582, nll_loss=1.761, w2v_ctc_loss=0.562, task_loss=2.914, task_loss_gen=5.104, contrastive_loss=0, total=6780.65, n_correct=4875.75, ppl=3.39, accuracy=71.907, wps=18578.6, ups=1.37, wpb=13561.3, bsz=469, num_updates=52700, lr=6.16041e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=0
2023-09-06 14:16:13 | INFO | train_inner | epoch 045:    418 / 1191 loss=1.801, trans_loss=4.586, nll_loss=1.767, w2v_ctc_loss=0.573, task_loss=2.92, task_loss_gen=5.884, contrastive_loss=0, total=6562.23, n_correct=4714.52, ppl=3.4, accuracy=71.843, wps=18114.5, ups=1.38, wpb=13124.5, bsz=429.5, num_updates=52800, lr=6.15457e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=0
2023-09-06 14:17:26 | INFO | train_inner | epoch 045:    518 / 1191 loss=1.8, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.574, task_loss=2.73, task_loss_gen=5.492, contrastive_loss=0, total=6731.19, n_correct=4839.78, ppl=3.41, accuracy=71.901, wps=18375.2, ups=1.36, wpb=13462.4, bsz=449.9, num_updates=52900, lr=6.14875e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=14.4, wall=0
2023-09-06 14:18:40 | INFO | train_inner | epoch 045:    618 / 1191 loss=1.798, trans_loss=4.591, nll_loss=1.773, w2v_ctc_loss=0.571, task_loss=2.396, task_loss_gen=5.243, contrastive_loss=0, total=6800.14, n_correct=4881.13, ppl=3.42, accuracy=71.78, wps=18469.5, ups=1.36, wpb=13600.3, bsz=479.9, num_updates=53000, lr=6.14295e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=73, gb_free=14, wall=0
2023-09-06 14:19:52 | INFO | train_inner | epoch 045:    718 / 1191 loss=1.8, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.574, task_loss=2.392, task_loss_gen=6.045, contrastive_loss=0, total=6648.02, n_correct=4774.7, ppl=3.4, accuracy=71.821, wps=18345.9, ups=1.38, wpb=13296, bsz=435, num_updates=53100, lr=6.13716e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=0
2023-09-06 14:21:05 | INFO | train_inner | epoch 045:    818 / 1191 loss=1.796, trans_loss=4.584, nll_loss=1.764, w2v_ctc_loss=0.57, task_loss=2.451, task_loss_gen=5.681, contrastive_loss=0, total=6743.87, n_correct=4849.57, ppl=3.4, accuracy=71.911, wps=18487.7, ups=1.37, wpb=13487.7, bsz=463.9, num_updates=53200, lr=6.13139e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=0
2023-09-06 14:22:17 | INFO | train_inner | epoch 045:    918 / 1191 loss=1.798, trans_loss=4.587, nll_loss=1.768, w2v_ctc_loss=0.568, task_loss=2.691, task_loss_gen=6.064, contrastive_loss=0, total=6624.82, n_correct=4760.69, ppl=3.41, accuracy=71.861, wps=18335.5, ups=1.38, wpb=13249.6, bsz=437.6, num_updates=53300, lr=6.12564e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:23:31 | INFO | train_inner | epoch 045:   1018 / 1191 loss=1.798, trans_loss=4.589, nll_loss=1.77, w2v_ctc_loss=0.569, task_loss=2.591, task_loss_gen=5.557, contrastive_loss=0, total=6761.87, n_correct=4850.04, ppl=3.41, accuracy=71.726, wps=18474.6, ups=1.37, wpb=13523.7, bsz=475.5, num_updates=53400, lr=6.1199e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=73, gb_free=13.3, wall=0
2023-09-06 14:24:45 | INFO | train_inner | epoch 045:   1118 / 1191 loss=1.801, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.568, task_loss=2.687, task_loss_gen=5.62, contrastive_loss=0, total=6739.03, n_correct=4826.14, ppl=3.44, accuracy=71.615, wps=18224.2, ups=1.35, wpb=13478.1, bsz=456.6, num_updates=53500, lr=6.11418e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=0
2023-09-06 14:25:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:26:11 | INFO | dev_st | epoch 045 | valid on 'dev_st' subset | loss 3.657 | trans_loss 4.874 | nll_loss 2.09 | w2v_ctc_loss 1.177 | task_loss 21.59 | task_loss_gen 15.798 | contrastive_loss 0 | total 6138.43 | n_correct 4365.43 | ppl 4.26 | accuracy 71.116 | uer 16.704 | wer 18.274 | raw_wer 18.274 | bleu 29.25 | wps 1770.2 | wpb 6138.4 | bsz 201.1 | num_updates 53573 | best_bleu 29.25
2023-09-06 14:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 53573 updates
2023-09-06 14:26:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 45 @ 53573 updates, score 29.25) (writing took 13.300631770980544 seconds)
2023-09-06 14:26:24 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-09-06 14:26:24 | INFO | train | epoch 045 | loss 1.799 | trans_loss 4.589 | nll_loss 1.77 | w2v_ctc_loss 0.57 | task_loss 2.77 | task_loss_gen 5.637 | contrastive_loss 0 | total 6703.69 | n_correct 4813.43 | ppl 3.41 | accuracy 71.803 | wps 17276.1 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 53573 | lr 6.11001e-05 | gnorm 0.403 | clip 0 | loss_scale 32 | train_wall 862 | gb_free 13.2 | wall 0
2023-09-06 14:26:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:26:25 | INFO | fairseq.trainer | begin training epoch 46
2023-09-06 14:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:26:52 | INFO | train_inner | epoch 046:     27 / 1191 loss=1.795, trans_loss=4.585, nll_loss=1.765, w2v_ctc_loss=0.566, task_loss=2.723, task_loss_gen=5.702, contrastive_loss=0, total=6718.04, n_correct=4830.12, ppl=3.4, accuracy=71.898, wps=10581.2, ups=0.79, wpb=13436.1, bsz=454.9, num_updates=53600, lr=6.10847e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:28:04 | INFO | train_inner | epoch 046:    127 / 1191 loss=1.792, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.563, task_loss=2.786, task_loss_gen=6.082, contrastive_loss=0, total=6663.69, n_correct=4803.02, ppl=3.37, accuracy=72.077, wps=18420.7, ups=1.38, wpb=13327.4, bsz=437.6, num_updates=53700, lr=6.10278e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=0
2023-09-06 14:29:17 | INFO | train_inner | epoch 046:    227 / 1191 loss=1.792, trans_loss=4.58, nll_loss=1.759, w2v_ctc_loss=0.559, task_loss=2.464, task_loss_gen=5.674, contrastive_loss=0, total=6762.2, n_correct=4864.82, ppl=3.38, accuracy=71.941, wps=18609.1, ups=1.38, wpb=13524.4, bsz=463.9, num_updates=53800, lr=6.09711e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=0
2023-09-06 14:30:29 | INFO | train_inner | epoch 046:    327 / 1191 loss=1.791, trans_loss=4.579, nll_loss=1.758, w2v_ctc_loss=0.562, task_loss=2.411, task_loss_gen=5.562, contrastive_loss=0, total=6829.04, n_correct=4918.52, ppl=3.38, accuracy=72.024, wps=18769.7, ups=1.37, wpb=13658.1, bsz=469.8, num_updates=53900, lr=6.09145e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=0
2023-09-06 14:31:44 | INFO | train_inner | epoch 046:    427 / 1191 loss=1.792, trans_loss=4.582, nll_loss=1.762, w2v_ctc_loss=0.564, task_loss=2.642, task_loss_gen=5.877, contrastive_loss=0, total=6722.66, n_correct=4842.51, ppl=3.39, accuracy=72.033, wps=18139.4, ups=1.35, wpb=13445.3, bsz=461.7, num_updates=54000, lr=6.08581e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=0
2023-09-06 14:31:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:32:17 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 3.677 | trans_loss 4.88 | nll_loss 2.097 | w2v_ctc_loss 1.231 | task_loss 38.247 | task_loss_gen 21.142 | contrastive_loss 0 | total 6138.43 | n_correct 4367.29 | ppl 4.28 | accuracy 71.147 | uer 17.15 | wer 18.643 | raw_wer 18.643 | bleu 28.62 | wps 1691.4 | wpb 6138.4 | bsz 201.1 | num_updates 54000 | best_bleu 29.25
2023-09-06 14:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 54000 updates
2023-09-06 14:32:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt
2023-09-06 14:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt
2023-09-06 14:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt (epoch 46 @ 54000 updates, score 28.62) (writing took 9.978976218029857 seconds)
--Backword ST Loss tensor(3481.8765, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(2023.9858, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 14:33:40 | INFO | train_inner | epoch 046:    527 / 1191 loss=1.792, trans_loss=4.582, nll_loss=1.761, w2v_ctc_loss=0.561, task_loss=2.953, task_loss_gen=6.052, contrastive_loss=0, total=6766.53, n_correct=4871.62, ppl=3.39, accuracy=71.996, wps=11662.4, ups=0.86, wpb=13533.1, bsz=463.2, num_updates=54100, lr=6.08018e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=0
2023-09-06 14:34:53 | INFO | train_inner | epoch 046:    627 / 1191 loss=1.793, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.563, task_loss=3.091, task_loss_gen=5.983, contrastive_loss=0, total=6658.17, n_correct=4793.99, ppl=3.38, accuracy=72.002, wps=18265, ups=1.37, wpb=13316.3, bsz=452.1, num_updates=54200, lr=6.07457e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=0
2023-09-06 14:36:05 | INFO | train_inner | epoch 046:    727 / 1191 loss=1.79, trans_loss=4.578, nll_loss=1.757, w2v_ctc_loss=0.559, task_loss=2.736, task_loss_gen=5.683, contrastive_loss=0, total=6763.57, n_correct=4875.39, ppl=3.38, accuracy=72.083, wps=18692, ups=1.38, wpb=13527.1, bsz=458.9, num_updates=54300, lr=6.06897e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=11.7, wall=0
2023-09-06 14:37:18 | INFO | train_inner | epoch 046:    827 / 1191 loss=1.797, trans_loss=4.589, nll_loss=1.771, w2v_ctc_loss=0.567, task_loss=2.836, task_loss_gen=5.761, contrastive_loss=0, total=6721.64, n_correct=4829.34, ppl=3.41, accuracy=71.848, wps=18320.6, ups=1.36, wpb=13443.3, bsz=455.9, num_updates=54400, lr=6.06339e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=0
2023-09-06 14:38:31 | INFO | train_inner | epoch 046:    927 / 1191 loss=1.796, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.57, task_loss=2.646, task_loss_gen=5.542, contrastive_loss=0, total=6811.3, n_correct=4897.54, ppl=3.4, accuracy=71.903, wps=18669.5, ups=1.37, wpb=13622.6, bsz=468.4, num_updates=54500, lr=6.05783e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=0
2023-09-06 14:39:45 | INFO | train_inner | epoch 046:   1027 / 1191 loss=1.802, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.577, task_loss=2.799, task_loss_gen=6.396, contrastive_loss=0, total=6588.76, n_correct=4737.95, ppl=3.41, accuracy=71.91, wps=17895.4, ups=1.36, wpb=13177.5, bsz=423.3, num_updates=54600, lr=6.05228e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=0
2023-09-06 14:40:57 | INFO | train_inner | epoch 046:   1127 / 1191 loss=1.798, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.573, task_loss=2.831, task_loss_gen=6.546, contrastive_loss=0, total=6492.04, n_correct=4670.87, ppl=3.38, accuracy=71.948, wps=18014.4, ups=1.39, wpb=12984.1, bsz=419.7, num_updates=54700, lr=6.04674e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=0
2023-09-06 14:41:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1707.3628, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1057.1147, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1481.7738, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(868.3412, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1138.5153, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(718.0974, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2201.6121, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1289.4028, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2248.2708, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1311.4828, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2465.6396, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1487.9614, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1773.3262, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1023.3325, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-06 14:42:17 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 3.65 | trans_loss 4.878 | nll_loss 2.095 | w2v_ctc_loss 1.146 | task_loss 34.169 | task_loss_gen 19.438 | contrastive_loss 0 | total 6138.43 | n_correct 4365.43 | ppl 4.27 | accuracy 71.116 | uer 16.875 | wer 18.453 | raw_wer 18.453 | bleu 29.05 | wps 1704.7 | wpb 6138.4 | bsz 201.1 | num_updates 54764 | best_bleu 29.25
2023-09-06 14:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 54764 updates
2023-09-06 14:42:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt
2023-09-06 14:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt
2023-09-06 14:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt (epoch 46 @ 54764 updates, score 29.05) (writing took 9.657549981959164 seconds)
2023-09-06 14:42:27 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-09-06 14:42:27 | INFO | train | epoch 046 | loss 1.794 | trans_loss 4.581 | nll_loss 1.761 | w2v_ctc_loss 0.565 | task_loss 2.732 | task_loss_gen 5.918 | contrastive_loss 0 | total 6703.69 | n_correct 4825.94 | ppl 3.39 | accuracy 71.989 | wps 16587 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 54764 | lr 6.04321e-05 | gnorm 0.4 | clip 0 | loss_scale 64 | train_wall 858 | gb_free 14.3 | wall 0
2023-09-06 14:42:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:42:27 | INFO | fairseq.trainer | begin training epoch 47
2023-09-06 14:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:43:01 | INFO | train_inner | epoch 047:     36 / 1191 loss=1.795, trans_loss=4.581, nll_loss=1.76, w2v_ctc_loss=0.568, task_loss=2.598, task_loss_gen=6.203, contrastive_loss=0, total=6621.19, n_correct=4766.48, ppl=3.39, accuracy=71.988, wps=10659, ups=0.8, wpb=13242.4, bsz=446.8, num_updates=54800, lr=6.04122e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:44:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 14:44:15 | INFO | train_inner | epoch 047:    137 / 1191 loss=1.784, trans_loss=4.568, nll_loss=1.743, w2v_ctc_loss=0.555, task_loss=2.174, task_loss_gen=6.138, contrastive_loss=0, total=6721.79, n_correct=4860.32, ppl=3.35, accuracy=72.307, wps=18151, ups=1.35, wpb=13443.6, bsz=459.4, num_updates=54900, lr=6.03572e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=0
2023-09-06 14:45:28 | INFO | train_inner | epoch 047:    237 / 1191 loss=1.786, trans_loss=4.57, nll_loss=1.746, w2v_ctc_loss=0.556, task_loss=2.462, task_loss_gen=6.155, contrastive_loss=0, total=6718.37, n_correct=4853.18, ppl=3.35, accuracy=72.237, wps=18427, ups=1.37, wpb=13436.7, bsz=453.6, num_updates=55000, lr=6.03023e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=0
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 14:46:42 | INFO | train_inner | epoch 047:    337 / 1191 loss=1.795, trans_loss=4.578, nll_loss=1.756, w2v_ctc_loss=0.568, task_loss=2.896, task_loss_gen=6.253, contrastive_loss=0, total=6617.22, n_correct=4766.15, ppl=3.38, accuracy=72.026, wps=17919.5, ups=1.35, wpb=13234.4, bsz=438.4, num_updates=55100, lr=6.02475e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=73, gb_free=10.8, wall=0
2023-09-06 14:47:55 | INFO | train_inner | epoch 047:    437 / 1191 loss=1.789, trans_loss=4.568, nll_loss=1.744, w2v_ctc_loss=0.558, task_loss=2.913, task_loss_gen=6.245, contrastive_loss=0, total=6600.85, n_correct=4765.64, ppl=3.35, accuracy=72.197, wps=18007.5, ups=1.36, wpb=13201.7, bsz=436.7, num_updates=55200, lr=6.01929e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=10.7, wall=0
2023-09-06 14:49:08 | INFO | train_inner | epoch 047:    537 / 1191 loss=1.789, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.564, task_loss=2.624, task_loss_gen=5.665, contrastive_loss=0, total=6749.44, n_correct=4867.62, ppl=3.37, accuracy=72.119, wps=18641.2, ups=1.38, wpb=13498.9, bsz=466, num_updates=55300, lr=6.01385e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=0
2023-09-06 14:50:21 | INFO | train_inner | epoch 047:    637 / 1191 loss=1.792, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.568, task_loss=2.76, task_loss_gen=5.746, contrastive_loss=0, total=6757.57, n_correct=4875.85, ppl=3.37, accuracy=72.154, wps=18540, ups=1.37, wpb=13515.1, bsz=464.1, num_updates=55400, lr=6.00842e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=0
2023-09-06 14:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 14:51:34 | INFO | train_inner | epoch 047:    738 / 1191 loss=1.796, trans_loss=4.583, nll_loss=1.763, w2v_ctc_loss=0.568, task_loss=2.983, task_loss_gen=6.015, contrastive_loss=0, total=6661.83, n_correct=4794.69, ppl=3.39, accuracy=71.973, wps=18234.9, ups=1.37, wpb=13323.7, bsz=440.3, num_updates=55500, lr=6.003e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=0
2023-09-06 14:52:47 | INFO | train_inner | epoch 047:    838 / 1191 loss=1.783, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.552, task_loss=3.196, task_loss_gen=5.254, contrastive_loss=0, total=6828.86, n_correct=4933.26, ppl=3.36, accuracy=72.241, wps=18630.4, ups=1.36, wpb=13657.7, bsz=468.6, num_updates=55600, lr=5.9976e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=0
2023-09-06 14:54:00 | INFO | train_inner | epoch 047:    938 / 1191 loss=1.789, trans_loss=4.578, nll_loss=1.756, w2v_ctc_loss=0.556, task_loss=3.179, task_loss_gen=5.454, contrastive_loss=0, total=6700.11, n_correct=4826.43, ppl=3.38, accuracy=72.035, wps=18417.4, ups=1.37, wpb=13400.2, bsz=450.2, num_updates=55700, lr=5.99222e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:55:13 | INFO | train_inner | epoch 047:   1038 / 1191 loss=1.794, trans_loss=4.581, nll_loss=1.76, w2v_ctc_loss=0.565, task_loss=3.273, task_loss_gen=5.429, contrastive_loss=0, total=6711.84, n_correct=4834.47, ppl=3.39, accuracy=72.029, wps=18281.4, ups=1.36, wpb=13423.7, bsz=450.4, num_updates=55800, lr=5.98684e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=73, gb_free=11.7, wall=0
2023-09-06 14:55:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 14:56:26 | INFO | train_inner | epoch 047:   1139 / 1191 loss=1.796, trans_loss=4.584, nll_loss=1.764, w2v_ctc_loss=0.565, task_loss=3.582, task_loss_gen=5.573, contrastive_loss=0, total=6626.4, n_correct=4766.25, ppl=3.4, accuracy=71.928, wps=18253.6, ups=1.38, wpb=13252.8, bsz=433.7, num_updates=55900, lr=5.98149e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:57:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 14:57:37 | INFO | dev_st | epoch 047 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.872 | nll_loss 2.088 | w2v_ctc_loss 1.195 | task_loss 50.577 | task_loss_gen 26.338 | contrastive_loss 0 | total 6138.43 | n_correct 4370.71 | ppl 4.25 | accuracy 71.202 | uer 16.621 | wer 18.219 | raw_wer 18.219 | bleu 28.67 | wps 1688.6 | wpb 6138.4 | bsz 201.1 | num_updates 55952 | best_bleu 29.25
2023-09-06 14:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 55952 updates
2023-09-06 14:57:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt
2023-09-06 14:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt
2023-09-06 14:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt (epoch 47 @ 55952 updates, score 28.67) (writing took 7.97138655197341 seconds)
2023-09-06 14:57:46 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-09-06 14:57:46 | INFO | train | epoch 047 | loss 1.79 | trans_loss 4.576 | nll_loss 1.754 | w2v_ctc_loss 0.562 | task_loss 2.92 | task_loss_gen 5.776 | contrastive_loss 0 | total 6703.56 | n_correct 4834.4 | ppl 3.37 | accuracy 72.117 | wps 17343.1 | ups 1.29 | wpb 13407.1 | bsz 452.1 | num_updates 55952 | lr 5.97871e-05 | gnorm 0.429 | clip 0 | loss_scale 8 | train_wall 860 | gb_free 13.7 | wall 0
2023-09-06 14:57:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:57:46 | INFO | fairseq.trainer | begin training epoch 48
2023-09-06 14:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:58:29 | INFO | train_inner | epoch 048:     48 / 1191 loss=1.789, trans_loss=4.577, nll_loss=1.755, w2v_ctc_loss=0.56, task_loss=3.564, task_loss_gen=5.008, contrastive_loss=0, total=6755.92, n_correct=4875.99, ppl=3.38, accuracy=72.174, wps=11004.7, ups=0.81, wpb=13511.8, bsz=465.5, num_updates=56000, lr=5.97614e-05, gnorm=0.576, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=0
2023-09-06 14:58:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:59:02 | INFO | dev_st | epoch 048 | valid on 'dev_st' subset | loss 3.67 | trans_loss 4.876 | nll_loss 2.091 | w2v_ctc_loss 1.218 | task_loss 34.95 | task_loss_gen 20.11 | contrastive_loss 0 | total 6138.43 | n_correct 4367.57 | ppl 4.26 | accuracy 71.151 | uer 16.757 | wer 18.219 | raw_wer 18.219 | bleu 28.84 | wps 1678.6 | wpb 6138.4 | bsz 201.1 | num_updates 56000 | best_bleu 29.25
2023-09-06 14:59:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 56000 updates
2023-09-06 14:59:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt
2023-09-06 14:59:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt
2023-09-06 14:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt (epoch 48 @ 56000 updates, score 28.84) (writing took 10.312104300945066 seconds)
--Backword ST Loss tensor(2573.0110, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1487.2593, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 15:00:26 | INFO | train_inner | epoch 048:    148 / 1191 loss=1.788, trans_loss=4.576, nll_loss=1.753, w2v_ctc_loss=0.557, task_loss=3.658, task_loss_gen=5.146, contrastive_loss=0, total=6761.65, n_correct=4876.25, ppl=3.37, accuracy=72.116, wps=11504.9, ups=0.85, wpb=13523.3, bsz=465.9, num_updates=56100, lr=5.97081e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=0
2023-09-06 15:01:39 | INFO | train_inner | epoch 048:    248 / 1191 loss=1.786, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.55, task_loss=3.842, task_loss_gen=5.215, contrastive_loss=0, total=6673.84, n_correct=4811.49, ppl=3.37, accuracy=72.095, wps=18362.9, ups=1.38, wpb=13347.7, bsz=451.5, num_updates=56200, lr=5.9655e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=0
2023-09-06 15:02:51 | INFO | train_inner | epoch 048:    348 / 1191 loss=1.784, trans_loss=4.571, nll_loss=1.748, w2v_ctc_loss=0.556, task_loss=3.395, task_loss_gen=4.87, contrastive_loss=0, total=6764.05, n_correct=4888.96, ppl=3.36, accuracy=72.279, wps=18668.5, ups=1.38, wpb=13528.1, bsz=468.9, num_updates=56300, lr=5.9602e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=0
2023-09-06 15:04:04 | INFO | train_inner | epoch 048:    448 / 1191 loss=1.788, trans_loss=4.572, nll_loss=1.748, w2v_ctc_loss=0.556, task_loss=3.696, task_loss_gen=5.188, contrastive_loss=0, total=6606.75, n_correct=4768.83, ppl=3.36, accuracy=72.181, wps=18241.5, ups=1.38, wpb=13213.5, bsz=444, num_updates=56400, lr=5.95491e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=72, gb_free=11.2, wall=0
2023-09-06 15:05:16 | INFO | train_inner | epoch 048:    548 / 1191 loss=1.784, trans_loss=4.57, nll_loss=1.746, w2v_ctc_loss=0.555, task_loss=3.513, task_loss_gen=4.954, contrastive_loss=0, total=6781.21, n_correct=4899.74, ppl=3.35, accuracy=72.255, wps=18752.6, ups=1.38, wpb=13562.4, bsz=471.7, num_updates=56500, lr=5.94964e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:06:28 | INFO | train_inner | epoch 048:    648 / 1191 loss=1.788, trans_loss=4.568, nll_loss=1.743, w2v_ctc_loss=0.557, task_loss=4.071, task_loss_gen=5.516, contrastive_loss=0, total=6643.62, n_correct=4800.77, ppl=3.35, accuracy=72.261, wps=18383.6, ups=1.38, wpb=13287.2, bsz=428.9, num_updates=56600, lr=5.94438e-05, gnorm=0.624, clip=0, loss_scale=8, train_wall=71, gb_free=13.1, wall=0
2023-09-06 15:07:41 | INFO | train_inner | epoch 048:    748 / 1191 loss=1.795, trans_loss=4.58, nll_loss=1.758, w2v_ctc_loss=0.565, task_loss=3.869, task_loss_gen=5.547, contrastive_loss=0, total=6579.2, n_correct=4739.13, ppl=3.38, accuracy=72.032, wps=18044.7, ups=1.37, wpb=13158.4, bsz=423, num_updates=56700, lr=5.93914e-05, gnorm=0.589, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=0
2023-09-06 15:08:54 | INFO | train_inner | epoch 048:    848 / 1191 loss=1.784, trans_loss=4.572, nll_loss=1.75, w2v_ctc_loss=0.554, task_loss=3.401, task_loss_gen=4.831, contrastive_loss=0, total=6756.73, n_correct=4881.84, ppl=3.36, accuracy=72.252, wps=18601.4, ups=1.38, wpb=13513.5, bsz=466.3, num_updates=56800, lr=5.93391e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=72, gb_free=12.4, wall=0
2023-09-06 15:10:06 | INFO | train_inner | epoch 048:    948 / 1191 loss=1.789, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.558, task_loss=3.978, task_loss_gen=5.483, contrastive_loss=0, total=6678.5, n_correct=4817.58, ppl=3.37, accuracy=72.136, wps=18476.1, ups=1.38, wpb=13357, bsz=438.4, num_updates=56900, lr=5.92869e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=0
2023-09-06 15:11:19 | INFO | train_inner | epoch 048:   1048 / 1191 loss=1.787, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.554, task_loss=3.92, task_loss_gen=5.128, contrastive_loss=0, total=6849.67, n_correct=4939.53, ppl=3.38, accuracy=72.113, wps=18778.1, ups=1.37, wpb=13699.3, bsz=473.3, num_updates=57000, lr=5.92349e-05, gnorm=0.622, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=0
2023-09-06 15:12:33 | INFO | train_inner | epoch 048:   1148 / 1191 loss=1.792, trans_loss=4.581, nll_loss=1.759, w2v_ctc_loss=0.56, task_loss=3.728, task_loss_gen=5.18, contrastive_loss=0, total=6719.48, n_correct=4837.73, ppl=3.38, accuracy=71.996, wps=18267.1, ups=1.36, wpb=13439, bsz=447.9, num_updates=57100, lr=5.9183e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=73, gb_free=14.9, wall=0
2023-09-06 15:13:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(3237.3193, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1964.2389, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1470.1304, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(897.3575, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1136.5033, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(671.9695, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1734.4319, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(989.7063, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1933.6711, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1144.8184, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2047.3541, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1203.7058, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1514.3202, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(849.9476, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 15:13:36 | INFO | dev_st | epoch 048 | valid on 'dev_st' subset | loss 3.671 | trans_loss 4.878 | nll_loss 2.095 | w2v_ctc_loss 1.215 | task_loss 20.257 | task_loss_gen 15.241 | contrastive_loss 0 | total 6138.43 | n_correct 4366.86 | ppl 4.27 | accuracy 71.14 | uer 17.027 | wer 18.579 | raw_wer 18.579 | bleu 28.75 | wps 1755 | wpb 6138.4 | bsz 201.1 | num_updates 57143 | best_bleu 29.25
2023-09-06 15:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 57143 updates
2023-09-06 15:13:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt
2023-09-06 15:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt
2023-09-06 15:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt (epoch 48 @ 57143 updates, score 28.75) (writing took 7.5665960350306705 seconds)
2023-09-06 15:13:44 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-09-06 15:13:44 | INFO | train | epoch 048 | loss 1.788 | trans_loss 4.574 | nll_loss 1.752 | w2v_ctc_loss 0.557 | task_loss 3.73 | task_loss_gen 5.173 | contrastive_loss 0 | total 6703.69 | n_correct 4837.24 | ppl 3.37 | accuracy 72.158 | wps 16656.7 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 57143 | lr 5.91607e-05 | gnorm 0.58 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 13.2 | wall 0
2023-09-06 15:13:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:13:44 | INFO | fairseq.trainer | begin training epoch 49
2023-09-06 15:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:14:33 | INFO | train_inner | epoch 049:     57 / 1191 loss=1.781, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.549, task_loss=3.647, task_loss_gen=4.953, contrastive_loss=0, total=6679.78, n_correct=4834.63, ppl=3.34, accuracy=72.377, wps=11077, ups=0.83, wpb=13359.6, bsz=456.1, num_updates=57200, lr=5.91312e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=71, gb_free=13.5, wall=0
2023-09-06 15:15:46 | INFO | train_inner | epoch 049:    157 / 1191 loss=1.787, trans_loss=4.567, nll_loss=1.741, w2v_ctc_loss=0.554, task_loss=3.838, task_loss_gen=5.418, contrastive_loss=0, total=6612.2, n_correct=4781.45, ppl=3.34, accuracy=72.313, wps=18220.3, ups=1.38, wpb=13224.4, bsz=422.4, num_updates=57300, lr=5.90796e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=0
2023-09-06 15:16:58 | INFO | train_inner | epoch 049:    257 / 1191 loss=1.782, trans_loss=4.564, nll_loss=1.738, w2v_ctc_loss=0.553, task_loss=3.672, task_loss_gen=4.959, contrastive_loss=0, total=6685.78, n_correct=4839.98, ppl=3.34, accuracy=72.392, wps=18445, ups=1.38, wpb=13371.6, bsz=456.3, num_updates=57400, lr=5.90281e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=72, gb_free=12.9, wall=0
2023-09-06 15:18:11 | INFO | train_inner | epoch 049:    357 / 1191 loss=1.784, trans_loss=4.568, nll_loss=1.744, w2v_ctc_loss=0.555, task_loss=3.615, task_loss_gen=4.949, contrastive_loss=0, total=6723.83, n_correct=4863.11, ppl=3.35, accuracy=72.326, wps=18609.8, ups=1.38, wpb=13447.7, bsz=459.3, num_updates=57500, lr=5.89768e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=72, gb_free=15.3, wall=0
2023-09-06 15:19:23 | INFO | train_inner | epoch 049:    457 / 1191 loss=1.789, trans_loss=4.576, nll_loss=1.753, w2v_ctc_loss=0.557, task_loss=3.736, task_loss_gen=5.209, contrastive_loss=0, total=6648.78, n_correct=4791.83, ppl=3.37, accuracy=72.071, wps=18352.9, ups=1.38, wpb=13297.6, bsz=452.1, num_updates=57600, lr=5.89256e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=72, gb_free=9.9, wall=0
2023-09-06 15:20:36 | INFO | train_inner | epoch 049:    557 / 1191 loss=1.791, trans_loss=4.575, nll_loss=1.751, w2v_ctc_loss=0.559, task_loss=3.747, task_loss_gen=5.176, contrastive_loss=0, total=6687.89, n_correct=4819.23, ppl=3.37, accuracy=72.059, wps=18478.6, ups=1.38, wpb=13375.8, bsz=438.2, num_updates=57700, lr=5.88745e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=0
2023-09-06 15:21:49 | INFO | train_inner | epoch 049:    657 / 1191 loss=1.787, trans_loss=4.574, nll_loss=1.75, w2v_ctc_loss=0.556, task_loss=3.83, task_loss_gen=5.245, contrastive_loss=0, total=6670.64, n_correct=4817.54, ppl=3.36, accuracy=72.22, wps=18076.5, ups=1.35, wpb=13341.3, bsz=443.9, num_updates=57800, lr=5.88235e-05, gnorm=0.571, clip=0, loss_scale=8, train_wall=73, gb_free=14.2, wall=0
2023-09-06 15:23:01 | INFO | train_inner | epoch 049:    757 / 1191 loss=1.785, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.551, task_loss=3.711, task_loss_gen=5.026, contrastive_loss=0, total=6753.54, n_correct=4878.54, ppl=3.37, accuracy=72.237, wps=18772.8, ups=1.39, wpb=13507.1, bsz=465, num_updates=57900, lr=5.87727e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=71, gb_free=13.6, wall=0
2023-09-06 15:24:14 | INFO | train_inner | epoch 049:    857 / 1191 loss=1.787, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.557, task_loss=3.076, task_loss_gen=4.962, contrastive_loss=0, total=6770.54, n_correct=4887.61, ppl=3.36, accuracy=72.189, wps=18655.6, ups=1.38, wpb=13541.1, bsz=466.9, num_updates=58000, lr=5.8722e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=0
2023-09-06 15:24:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:24:47 | INFO | dev_st | epoch 049 | valid on 'dev_st' subset | loss 3.661 | trans_loss 4.874 | nll_loss 2.089 | w2v_ctc_loss 1.192 | task_loss 28.37 | task_loss_gen 17.202 | contrastive_loss 0 | total 6138.43 | n_correct 4377.14 | ppl 4.25 | accuracy 71.307 | uer 16.589 | wer 18.133 | raw_wer 18.133 | bleu 28.59 | wps 1734.8 | wpb 6138.4 | bsz 201.1 | num_updates 58000 | best_bleu 29.25
2023-09-06 15:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 58000 updates
2023-09-06 15:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt
2023-09-06 15:24:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt
2023-09-06 15:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt (epoch 49 @ 58000 updates, score 28.59) (writing took 6.9795685049612075 seconds)
--Backword ST Loss tensor(2259.4529, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1271.5597, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 15:26:06 | INFO | train_inner | epoch 049:    957 / 1191 loss=1.784, trans_loss=4.573, nll_loss=1.749, w2v_ctc_loss=0.553, task_loss=3.144, task_loss_gen=4.817, contrastive_loss=0, total=6761.92, n_correct=4883.79, ppl=3.36, accuracy=72.225, wps=12042.5, ups=0.89, wpb=13523.8, bsz=467.2, num_updates=58100, lr=5.86715e-05, gnorm=0.437, clip=0, loss_scale=16, train_wall=71, gb_free=11.9, wall=0
2023-09-06 15:27:20 | INFO | train_inner | epoch 049:   1057 / 1191 loss=1.784, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.551, task_loss=3.153, task_loss_gen=5.301, contrastive_loss=0, total=6705.5, n_correct=4850.33, ppl=3.36, accuracy=72.334, wps=18278.2, ups=1.36, wpb=13411, bsz=447.5, num_updates=58200, lr=5.8621e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=11.1, wall=0
2023-09-06 15:28:33 | INFO | train_inner | epoch 049:   1157 / 1191 loss=1.787, trans_loss=4.572, nll_loss=1.749, w2v_ctc_loss=0.553, task_loss=3.384, task_loss_gen=5.385, contrastive_loss=0, total=6652.04, n_correct=4803.87, ppl=3.36, accuracy=72.216, wps=18207.7, ups=1.37, wpb=13304.1, bsz=436.4, num_updates=58300, lr=5.85707e-05, gnorm=0.453, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=0
2023-09-06 15:28:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2049.5686, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1088.6987, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3155.9907, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1955.5491, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2143.3647, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1082.7660, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3638.3079, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(2152.2073, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1152.7844, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(690.7031, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1469.7068, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(865.5139, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2844.4546, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1675.8196, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-06 15:29:30 | INFO | dev_st | epoch 049 | valid on 'dev_st' subset | loss 3.649 | trans_loss 4.873 | nll_loss 2.089 | w2v_ctc_loss 1.153 | task_loss 30.537 | task_loss_gen 17.778 | contrastive_loss 0 | total 6138.43 | n_correct 4373.14 | ppl 4.25 | accuracy 71.242 | uer 16.431 | wer 18.062 | raw_wer 18.062 | bleu 28.71 | wps 1756.7 | wpb 6138.4 | bsz 201.1 | num_updates 58334 | best_bleu 29.25
2023-09-06 15:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 58334 updates
2023-09-06 15:29:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt
2023-09-06 15:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt
2023-09-06 15:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt (epoch 49 @ 58334 updates, score 28.71) (writing took 7.675531419925392 seconds)
2023-09-06 15:29:38 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-09-06 15:29:38 | INFO | train | epoch 049 | loss 1.785 | trans_loss 4.571 | nll_loss 1.747 | w2v_ctc_loss 0.554 | task_loss 3.515 | task_loss_gen 5.103 | contrastive_loss 0 | total 6703.69 | n_correct 4843.69 | ppl 3.36 | accuracy 72.254 | wps 16743 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 58334 | lr 5.85537e-05 | gnorm 0.516 | clip 0 | loss_scale 16 | train_wall 856 | gb_free 13.7 | wall 0
2023-09-06 15:29:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:29:38 | INFO | fairseq.trainer | begin training epoch 50
2023-09-06 15:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:30:34 | INFO | train_inner | epoch 050:     66 / 1191 loss=1.779, trans_loss=4.564, nll_loss=1.739, w2v_ctc_loss=0.548, task_loss=3.176, task_loss_gen=5.089, contrastive_loss=0, total=6708.17, n_correct=4862.95, ppl=3.34, accuracy=72.493, wps=11065.7, ups=0.82, wpb=13416.3, bsz=455.7, num_updates=58400, lr=5.85206e-05, gnorm=0.435, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=0
2023-09-06 15:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 15:31:48 | INFO | train_inner | epoch 050:    167 / 1191 loss=1.775, trans_loss=4.558, nll_loss=1.731, w2v_ctc_loss=0.539, task_loss=3.048, task_loss_gen=5, contrastive_loss=0, total=6753.39, n_correct=4897.72, ppl=3.32, accuracy=72.522, wps=18355.4, ups=1.36, wpb=13506.8, bsz=460.9, num_updates=58500, lr=5.84705e-05, gnorm=0.459, clip=0, loss_scale=8, train_wall=73, gb_free=14.9, wall=0
2023-09-06 15:33:00 | INFO | train_inner | epoch 050:    267 / 1191 loss=1.785, trans_loss=4.565, nll_loss=1.738, w2v_ctc_loss=0.555, task_loss=3.712, task_loss_gen=5.359, contrastive_loss=0, total=6571.43, n_correct=4754.96, ppl=3.34, accuracy=72.358, wps=18190.8, ups=1.38, wpb=13142.9, bsz=420.8, num_updates=58600, lr=5.84206e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=0
2023-09-06 15:34:12 | INFO | train_inner | epoch 050:    367 / 1191 loss=1.783, trans_loss=4.565, nll_loss=1.739, w2v_ctc_loss=0.554, task_loss=3.755, task_loss_gen=5.018, contrastive_loss=0, total=6736.79, n_correct=4876.72, ppl=3.34, accuracy=72.389, wps=18560, ups=1.38, wpb=13473.6, bsz=451.1, num_updates=58700, lr=5.83708e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:35:25 | INFO | train_inner | epoch 050:    467 / 1191 loss=1.778, trans_loss=4.565, nll_loss=1.739, w2v_ctc_loss=0.544, task_loss=3.564, task_loss_gen=4.845, contrastive_loss=0, total=6713.38, n_correct=4857.57, ppl=3.34, accuracy=72.357, wps=18454.4, ups=1.37, wpb=13426.8, bsz=467.5, num_updates=58800, lr=5.83212e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=72, gb_free=9.2, wall=0
2023-09-06 15:36:38 | INFO | train_inner | epoch 050:    567 / 1191 loss=1.778, trans_loss=4.564, nll_loss=1.739, w2v_ctc_loss=0.548, task_loss=3.483, task_loss_gen=4.797, contrastive_loss=0, total=6785.13, n_correct=4918.2, ppl=3.34, accuracy=72.485, wps=18637.9, ups=1.37, wpb=13570.3, bsz=469, num_updates=58900, lr=5.82717e-05, gnorm=0.571, clip=0, loss_scale=8, train_wall=72, gb_free=13.4, wall=0
2023-09-06 15:37:50 | INFO | train_inner | epoch 050:    667 / 1191 loss=1.784, trans_loss=4.561, nll_loss=1.735, w2v_ctc_loss=0.557, task_loss=3.933, task_loss_gen=5.341, contrastive_loss=0, total=6658.77, n_correct=4823.48, ppl=3.33, accuracy=72.438, wps=18385.4, ups=1.38, wpb=13317.5, bsz=435.7, num_updates=59000, lr=5.82223e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=0
2023-09-06 15:39:03 | INFO | train_inner | epoch 050:    767 / 1191 loss=1.776, trans_loss=4.562, nll_loss=1.735, w2v_ctc_loss=0.541, task_loss=3.659, task_loss_gen=5.023, contrastive_loss=0, total=6708.2, n_correct=4861.72, ppl=3.33, accuracy=72.474, wps=18539, ups=1.38, wpb=13416.4, bsz=447.6, num_updates=59100, lr=5.8173e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=72, gb_free=10.2, wall=0
2023-09-06 15:40:15 | INFO | train_inner | epoch 050:    867 / 1191 loss=1.788, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.557, task_loss=3.688, task_loss_gen=5.081, contrastive_loss=0, total=6627.13, n_correct=4784.82, ppl=3.36, accuracy=72.2, wps=18360.4, ups=1.39, wpb=13254.3, bsz=441.5, num_updates=59200, lr=5.81238e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=71, gb_free=11.4, wall=0
2023-09-06 15:41:28 | INFO | train_inner | epoch 050:    967 / 1191 loss=1.783, trans_loss=4.569, nll_loss=1.745, w2v_ctc_loss=0.552, task_loss=3.808, task_loss_gen=5.227, contrastive_loss=0, total=6653.63, n_correct=4811.72, ppl=3.35, accuracy=72.317, wps=18278.6, ups=1.37, wpb=13307.3, bsz=443.3, num_updates=59300, lr=5.80748e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:42:40 | INFO | train_inner | epoch 050:   1067 / 1191 loss=1.775, trans_loss=4.561, nll_loss=1.735, w2v_ctc_loss=0.542, task_loss=3.566, task_loss_gen=4.718, contrastive_loss=0, total=6789.63, n_correct=4924.81, ppl=3.33, accuracy=72.534, wps=18774, ups=1.38, wpb=13579.3, bsz=466.6, num_updates=59400, lr=5.80259e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=72, gb_free=12.5, wall=0
2023-09-06 15:43:52 | INFO | train_inner | epoch 050:   1167 / 1191 loss=1.779, trans_loss=4.567, nll_loss=1.742, w2v_ctc_loss=0.543, task_loss=3.379, task_loss_gen=4.731, contrastive_loss=0, total=6761.3, n_correct=4892.46, ppl=3.35, accuracy=72.36, wps=18792.7, ups=1.39, wpb=13522.6, bsz=467.9, num_updates=59500, lr=5.79771e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=71, gb_free=14.3, wall=0
2023-09-06 15:44:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:44:43 | INFO | dev_st | epoch 050 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.873 | nll_loss 2.091 | w2v_ctc_loss 1.192 | task_loss 28.958 | task_loss_gen 17.21 | contrastive_loss 0 | total 6138.43 | n_correct 4369.71 | ppl 4.26 | accuracy 71.186 | uer 17.124 | wer 18.754 | raw_wer 18.754 | bleu 28.85 | wps 1750.3 | wpb 6138.4 | bsz 201.1 | num_updates 59524 | best_bleu 29.25
2023-09-06 15:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 59524 updates
2023-09-06 15:44:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt
2023-09-06 15:44:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt
2023-09-06 15:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt (epoch 50 @ 59524 updates, score 28.85) (writing took 8.160001026000828 seconds)
2023-09-06 15:44:51 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-09-06 15:44:51 | INFO | train | epoch 050 | loss 1.78 | trans_loss 4.565 | nll_loss 1.739 | w2v_ctc_loss 0.548 | task_loss 3.574 | task_loss_gen 5.013 | contrastive_loss 0 | total 6704.13 | n_correct 4854.39 | ppl 3.34 | accuracy 72.409 | wps 17467 | ups 1.3 | wpb 13408.3 | bsz 452.1 | num_updates 59524 | lr 5.79654e-05 | gnorm 0.54 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 13.8 | wall 0
2023-09-06 15:44:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:44:52 | INFO | fairseq.trainer | begin training epoch 51
2023-09-06 15:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:45:54 | INFO | train_inner | epoch 051:     76 / 1191 loss=1.772, trans_loss=4.551, nll_loss=1.722, w2v_ctc_loss=0.541, task_loss=3.41, task_loss_gen=4.944, contrastive_loss=0, total=6696.16, n_correct=4871.23, ppl=3.3, accuracy=72.747, wps=11025.9, ups=0.82, wpb=13392.3, bsz=452.5, num_updates=59600, lr=5.79284e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=72, gb_free=13.1, wall=0
2023-09-06 15:47:05 | INFO | train_inner | epoch 051:    176 / 1191 loss=1.784, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.551, task_loss=3.878, task_loss_gen=5.324, contrastive_loss=0, total=6626.19, n_correct=4792.29, ppl=3.34, accuracy=72.323, wps=18419.1, ups=1.39, wpb=13252.4, bsz=435.1, num_updates=59700, lr=5.78799e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=71, gb_free=13.5, wall=0
2023-09-06 15:48:19 | INFO | train_inner | epoch 051:    276 / 1191 loss=1.782, trans_loss=4.559, nll_loss=1.732, w2v_ctc_loss=0.553, task_loss=4.049, task_loss_gen=5.536, contrastive_loss=0, total=6666.05, n_correct=4833.29, ppl=3.32, accuracy=72.506, wps=18235.1, ups=1.37, wpb=13332.1, bsz=432.4, num_updates=59800, lr=5.78315e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=72, gb_free=9.8, wall=0
2023-09-06 15:49:32 | INFO | train_inner | epoch 051:    376 / 1191 loss=1.777, trans_loss=4.56, nll_loss=1.733, w2v_ctc_loss=0.546, task_loss=3.723, task_loss_gen=5.123, contrastive_loss=0, total=6770.7, n_correct=4912.89, ppl=3.32, accuracy=72.561, wps=18446.6, ups=1.36, wpb=13541.4, bsz=469.4, num_updates=59900, lr=5.77832e-05, gnorm=0.583, clip=0, loss_scale=8, train_wall=73, gb_free=10.4, wall=0
2023-09-06 15:50:44 | INFO | train_inner | epoch 051:    476 / 1191 loss=1.779, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.545, task_loss=3.541, task_loss_gen=4.985, contrastive_loss=0, total=6767.23, n_correct=4897.87, ppl=3.34, accuracy=72.376, wps=18699.5, ups=1.38, wpb=13534.5, bsz=463.7, num_updates=60000, lr=5.7735e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=72, gb_free=14.9, wall=0
2023-09-06 15:50:44 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-09-06 15:50:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:51:17 | INFO | dev_st | epoch 051 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.873 | nll_loss 2.09 | w2v_ctc_loss 1.231 | task_loss 44.877 | task_loss_gen 23.786 | contrastive_loss 0 | total 6138.43 | n_correct 4372.86 | ppl 4.26 | accuracy 71.237 | uer 16.915 | wer 18.382 | raw_wer 18.382 | bleu 29.04 | wps 1761.3 | wpb 6138.4 | bsz 201.1 | num_updates 60000 | best_bleu 29.25
2023-09-06 15:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 60000 updates
2023-09-06 15:51:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt
2023-09-06 15:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt
2023-09-06 15:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt (epoch 51 @ 60000 updates, score 29.04) (writing took 9.170054742018692 seconds)
2023-09-06 15:51:27 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-09-06 15:51:27 | INFO | train | epoch 051 | loss 1.778 | trans_loss 4.56 | nll_loss 1.733 | w2v_ctc_loss 0.547 | task_loss 3.739 | task_loss_gen 5.196 | contrastive_loss 0 | total 6706.48 | n_correct 4862.68 | ppl 3.32 | accuracy 72.507 | wps 16141.8 | ups 1.2 | wpb 13413 | bsz 449.9 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.563 | clip 0 | loss_scale 8 | train_wall 342 | gb_free 14.9 | wall 0
2023-09-06 15:51:27 | INFO | fairseq_cli.train | done training in 7983.4 seconds
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 384 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
