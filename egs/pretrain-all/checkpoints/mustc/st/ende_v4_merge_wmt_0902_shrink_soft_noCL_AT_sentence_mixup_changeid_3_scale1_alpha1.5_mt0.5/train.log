2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18700
2023-09-03 09:29:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-03 09:29:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-03 09:29:52 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 09:29:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-03 09:29:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18700', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-03 09:29:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-03 09:29:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-03 09:29:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-03 09:29:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-03 09:29:55 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 09:29:59 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-03 09:29:59 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-03 09:29:59 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-03 09:30:01 | INFO | root | load pretrained hubert
2023-09-03 09:30:09 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 09:30:11 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 09:30:18 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 09:30:18 | INFO | root | share the sematic adapter and textual encoder
2023-09-03 09:30:18 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-03 09:30:18 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-03 09:30:18 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-03 09:30:18 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-03 09:30:18 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-03 09:30:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-03 09:30:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 09:30:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 09:30:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 09:30:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 09:30:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-03 09:30:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-03 09:30:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-03 09:30:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 09:30:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 09:30:36 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-03 09:30:36 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-03 09:30:36 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 09:30:36 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 09:30:36 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-03 09:30:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 09:30:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 09:30:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 09:30:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 09:30:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 09:31:20 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-03 09:31:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 09:31:20 | INFO | fairseq.trainer | begin training epoch 1
2023-09-03 09:31:20 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 09:31:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-03 09:32:30 | INFO | train_inner | epoch 001:    101 / 1474 loss=17.384, trans_loss=5.873, nll_loss=4.681, w2v_ctc_loss=22.309, task_loss=1.373, task_loss_gen=1.395, contrastive_loss=0, total=4212.33, n_correct=124.68, ppl=25.65, accuracy=2.96, wps=21383.6, ups=1.71, wpb=12566.1, bsz=472.9, num_updates=100, lr=4.098e-06, gnorm=2.695, clip=0, loss_scale=64, train_wall=63, gb_free=18.8, wall=114
2023-09-03 09:32:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-03 09:33:29 | INFO | train_inner | epoch 001:    202 / 1474 loss=13.471, trans_loss=5.85, nll_loss=4.681, w2v_ctc_loss=16.303, task_loss=1.123, task_loss_gen=1.428, contrastive_loss=0, total=4127.88, n_correct=127.41, ppl=25.65, accuracy=3.087, wps=20876.4, ups=1.69, wpb=12326, bsz=463, num_updates=200, lr=8.096e-06, gnorm=7.325, clip=15, loss_scale=32, train_wall=58, gb_free=18.7, wall=173
2023-09-03 09:34:29 | INFO | train_inner | epoch 001:    302 / 1474 loss=7.225, trans_loss=5.785, nll_loss=4.64, w2v_ctc_loss=6.746, task_loss=0.832, task_loss_gen=1.78, contrastive_loss=0, total=4077.62, n_correct=133.45, ppl=24.93, accuracy=3.273, wps=20346.2, ups=1.67, wpb=12179.5, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=1.408, clip=0, loss_scale=32, train_wall=59, gb_free=19.3, wall=233
2023-09-03 09:35:27 | INFO | train_inner | epoch 001:    402 / 1474 loss=6.702, trans_loss=5.721, nll_loss=4.585, w2v_ctc_loss=6.01, task_loss=0.413, task_loss_gen=2.255, contrastive_loss=0, total=4177.45, n_correct=119.25, ppl=24, accuracy=2.855, wps=21435.7, ups=1.72, wpb=12474.2, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=58, gb_free=18.7, wall=291
2023-09-03 09:36:25 | INFO | train_inner | epoch 001:    502 / 1474 loss=6.525, trans_loss=5.766, nll_loss=4.65, w2v_ctc_loss=5.688, task_loss=0.157, task_loss_gen=3.082, contrastive_loss=0, total=4202.06, n_correct=98.33, ppl=25.1, accuracy=2.34, wps=21650.9, ups=1.72, wpb=12556.3, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=57, gb_free=14.6, wall=349
2023-09-03 09:37:23 | INFO | train_inner | epoch 001:    602 / 1474 loss=6.467, trans_loss=5.899, nll_loss=4.81, w2v_ctc_loss=5.461, task_loss=0.047, task_loss_gen=4.458, contrastive_loss=0, total=4124.52, n_correct=78.42, ppl=28.05, accuracy=1.901, wps=21306.2, ups=1.73, wpb=12301.1, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=57, gb_free=18.8, wall=407
2023-09-03 09:38:21 | INFO | train_inner | epoch 001:    702 / 1474 loss=6.284, trans_loss=5.96, nll_loss=4.889, w2v_ctc_loss=5.11, task_loss=0.013, task_loss_gen=6.066, contrastive_loss=0, total=4147.01, n_correct=48.97, ppl=29.63, accuracy=1.181, wps=21460.9, ups=1.73, wpb=12381.3, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.456, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=465
2023-09-03 09:39:18 | INFO | train_inner | epoch 001:    802 / 1474 loss=6.013, trans_loss=5.992, nll_loss=4.926, w2v_ctc_loss=4.662, task_loss=0.004, task_loss_gen=7.185, contrastive_loss=0, total=4121.11, n_correct=46.23, ppl=30.39, accuracy=1.122, wps=21288, ups=1.73, wpb=12298.3, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.765, clip=0, loss_scale=32, train_wall=57, gb_free=19.1, wall=523
2023-09-03 09:40:17 | INFO | train_inner | epoch 001:    902 / 1474 loss=5.841, trans_loss=6.033, nll_loss=4.973, w2v_ctc_loss=4.352, task_loss=0.001, task_loss_gen=8.438, contrastive_loss=0, total=4167.98, n_correct=67.71, ppl=31.41, accuracy=1.625, wps=21137.9, ups=1.7, wpb=12446.6, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.796, clip=0, loss_scale=32, train_wall=58, gb_free=19, wall=582
2023-09-03 09:41:15 | INFO | train_inner | epoch 001:   1002 / 1474 loss=5.702, trans_loss=6.069, nll_loss=5.015, w2v_ctc_loss=4.097, task_loss=0, task_loss_gen=9.454, contrastive_loss=0, total=4136.38, n_correct=115.65, ppl=32.33, accuracy=2.796, wps=21302.9, ups=1.72, wpb=12354.6, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=0.993, clip=0, loss_scale=32, train_wall=57, gb_free=19.2, wall=640
2023-09-03 09:42:13 | INFO | train_inner | epoch 001:   1102 / 1474 loss=5.605, trans_loss=6.095, nll_loss=5.044, w2v_ctc_loss=3.923, task_loss=0, task_loss_gen=10.628, contrastive_loss=0, total=4148.31, n_correct=139.61, ppl=32.98, accuracy=3.365, wps=21341, ups=1.72, wpb=12371.7, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=1, clip=0, loss_scale=32, train_wall=57, gb_free=18.6, wall=698
2023-09-03 09:42:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 09:43:12 | INFO | train_inner | epoch 001:   1203 / 1474 loss=5.525, trans_loss=6.093, nll_loss=5.043, w2v_ctc_loss=3.795, task_loss=0, task_loss_gen=12.505, contrastive_loss=0, total=4116.39, n_correct=151.59, ppl=32.98, accuracy=3.683, wps=20939.1, ups=1.7, wpb=12295.1, bsz=430, num_updates=1200, lr=4.8076e-05, gnorm=1.085, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=756
2023-09-03 09:44:10 | INFO | train_inner | epoch 001:   1303 / 1474 loss=5.422, trans_loss=6.085, nll_loss=5.033, w2v_ctc_loss=3.649, task_loss=0, task_loss_gen=12.69, contrastive_loss=0, total=4055.88, n_correct=146.6, ppl=32.74, accuracy=3.615, wps=21027.8, ups=1.74, wpb=12109.1, bsz=443.9, num_updates=1300, lr=5.2074e-05, gnorm=1.087, clip=0, loss_scale=16, train_wall=57, gb_free=19.2, wall=814
2023-09-03 09:45:09 | INFO | train_inner | epoch 001:   1403 / 1474 loss=5.328, trans_loss=6.069, nll_loss=5.015, w2v_ctc_loss=3.524, task_loss=0, task_loss_gen=13.637, contrastive_loss=0, total=4127.47, n_correct=151.8, ppl=32.34, accuracy=3.678, wps=20824.1, ups=1.69, wpb=12332.8, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.099, clip=0, loss_scale=16, train_wall=59, gb_free=19.1, wall=873
2023-09-03 09:45:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-03 09:46:37 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.295 | trans_loss 13.244 | nll_loss 12.854 | w2v_ctc_loss 4.471 | task_loss 0 | task_loss_gen 86.353 | contrastive_loss 0 | total 4003.4 | n_correct 239.9 | ppl 7402.98 | accuracy 5.992 | uer 60.125 | wer 58.76 | raw_wer 58.76 | bleu 0 | wps 1037.2 | wpb 4003.4 | bsz 141.8 | num_updates 1471
2023-09-03 09:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1471 updates
2023-09-03 09:46:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 09:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 09:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1471 updates, score 0.0) (writing took 4.426133009023033 seconds)
2023-09-03 09:46:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-03 09:46:41 | INFO | train | epoch 001 | loss 7.303 | trans_loss 5.954 | nll_loss 4.863 | w2v_ctc_loss 6.688 | task_loss 0.272 | task_loss_gen 7.048 | contrastive_loss 0 | total 4138.13 | n_correct 112.755 | ppl 29.09 | accuracy 2.725 | wps 19974 | ups 1.62 | wpb 12354.2 | bsz 458.2 | num_updates 1471 | lr 5.89106e-05 | gnorm 1.432 | clip 1 | loss_scale 16 | train_wall 854 | gb_free 18.9 | wall 965
2023-09-03 09:46:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 09:46:41 | INFO | fairseq.trainer | begin training epoch 2
2023-09-03 09:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 09:47:05 | INFO | train_inner | epoch 002:     29 / 1474 loss=5.255, trans_loss=6.067, nll_loss=5.009, w2v_ctc_loss=3.413, task_loss=0, task_loss_gen=13.521, contrastive_loss=0, total=4165.52, n_correct=153.4, ppl=32.19, accuracy=3.683, wps=10713.3, ups=0.86, wpb=12425.3, bsz=471.4, num_updates=1500, lr=6.007e-05, gnorm=1.361, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=989
2023-09-03 09:48:03 | INFO | train_inner | epoch 002:    129 / 1474 loss=5.205, trans_loss=6.059, nll_loss=4.999, w2v_ctc_loss=3.34, task_loss=0, task_loss_gen=15.016, contrastive_loss=0, total=4149.27, n_correct=153.61, ppl=31.98, accuracy=3.702, wps=21408.9, ups=1.73, wpb=12375.1, bsz=451.7, num_updates=1600, lr=6.4068e-05, gnorm=1.089, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1047
2023-09-03 09:49:00 | INFO | train_inner | epoch 002:    229 / 1474 loss=5.111, trans_loss=6.036, nll_loss=4.975, w2v_ctc_loss=3.223, task_loss=0, task_loss_gen=13.281, contrastive_loss=0, total=4199.2, n_correct=155, ppl=31.44, accuracy=3.691, wps=21768.4, ups=1.74, wpb=12541.6, bsz=494.4, num_updates=1700, lr=6.8066e-05, gnorm=1.132, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1104
2023-09-03 09:49:58 | INFO | train_inner | epoch 002:    329 / 1474 loss=5.09, trans_loss=6.031, nll_loss=4.966, w2v_ctc_loss=3.186, task_loss=0, task_loss_gen=16.302, contrastive_loss=0, total=4130.92, n_correct=158.84, ppl=31.26, accuracy=3.845, wps=21422.6, ups=1.74, wpb=12331.6, bsz=442.3, num_updates=1800, lr=7.2064e-05, gnorm=1.144, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1162
2023-09-03 09:50:56 | INFO | train_inner | epoch 002:    429 / 1474 loss=5.054, trans_loss=6.024, nll_loss=4.962, w2v_ctc_loss=3.137, task_loss=0, task_loss_gen=18.077, contrastive_loss=0, total=4036.18, n_correct=158.02, ppl=31.16, accuracy=3.915, wps=20619.5, ups=1.71, wpb=12064.4, bsz=416.3, num_updates=1900, lr=7.6062e-05, gnorm=0.984, clip=0, loss_scale=16, train_wall=58, gb_free=18.9, wall=1221
2023-09-03 09:51:54 | INFO | train_inner | epoch 002:    529 / 1474 loss=4.988, trans_loss=6.034, nll_loss=4.969, w2v_ctc_loss=3.032, task_loss=0, task_loss_gen=15.991, contrastive_loss=0, total=4185.63, n_correct=154.87, ppl=31.32, accuracy=3.7, wps=21538.9, ups=1.72, wpb=12487.7, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=0.994, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1279
2023-09-03 09:51:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 09:52:41 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.034 | trans_loss 13.11 | nll_loss 12.686 | w2v_ctc_loss 3.902 | task_loss 0 | task_loss_gen 99.951 | contrastive_loss 0 | total 4003.4 | n_correct 239.8 | ppl 6590.04 | accuracy 5.99 | uer 54.373 | wer 53.622 | raw_wer 53.622 | bleu 0 | wps 1043 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-09-03 09:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-03 09:52:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-03 09:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-03 09:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.804786571010482 seconds)
2023-09-03 09:53:51 | INFO | train_inner | epoch 002:    629 / 1474 loss=4.947, trans_loss=6.032, nll_loss=4.968, w2v_ctc_loss=2.968, task_loss=0, task_loss_gen=16.99, contrastive_loss=0, total=4116.05, n_correct=153.02, ppl=31.3, accuracy=3.718, wps=10531.8, ups=0.86, wpb=12285, bsz=443.4, num_updates=2100, lr=8.4058e-05, gnorm=1.053, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1395
2023-09-03 09:54:48 | INFO | train_inner | epoch 002:    729 / 1474 loss=4.92, trans_loss=6.034, nll_loss=4.971, w2v_ctc_loss=2.93, task_loss=0, task_loss_gen=16.935, contrastive_loss=0, total=4152.4, n_correct=155.63, ppl=31.37, accuracy=3.748, wps=21592.9, ups=1.74, wpb=12393.8, bsz=463.6, num_updates=2200, lr=8.8056e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1453
2023-09-03 09:55:46 | INFO | train_inner | epoch 002:    829 / 1474 loss=4.892, trans_loss=6.025, nll_loss=4.963, w2v_ctc_loss=2.894, task_loss=0, task_loss_gen=17.534, contrastive_loss=0, total=4168.87, n_correct=151.51, ppl=31.2, accuracy=3.634, wps=21622.7, ups=1.74, wpb=12453.5, bsz=461.2, num_updates=2300, lr=9.2054e-05, gnorm=0.86, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1510
2023-09-03 09:56:43 | INFO | train_inner | epoch 002:    929 / 1474 loss=4.848, trans_loss=6.019, nll_loss=4.955, w2v_ctc_loss=2.831, task_loss=0, task_loss_gen=18.03, contrastive_loss=0, total=4104.79, n_correct=149.92, ppl=31.01, accuracy=3.652, wps=21397, ups=1.75, wpb=12254.8, bsz=445.6, num_updates=2400, lr=9.6052e-05, gnorm=0.878, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1567
2023-09-03 09:57:42 | INFO | train_inner | epoch 002:   1029 / 1474 loss=4.823, trans_loss=6.018, nll_loss=4.955, w2v_ctc_loss=2.791, task_loss=0, task_loss_gen=17.961, contrastive_loss=0, total=4100.85, n_correct=139.05, ppl=31.02, accuracy=3.391, wps=20783, ups=1.7, wpb=12245.2, bsz=455.2, num_updates=2500, lr=0.00010005, gnorm=0.823, clip=0, loss_scale=16, train_wall=58, gb_free=19.2, wall=1626
2023-09-03 09:58:40 | INFO | train_inner | epoch 002:   1129 / 1474 loss=4.775, trans_loss=6.019, nll_loss=4.955, w2v_ctc_loss=2.726, task_loss=0, task_loss_gen=16.193, contrastive_loss=0, total=4195.47, n_correct=138.64, ppl=31.02, accuracy=3.305, wps=21635.4, ups=1.73, wpb=12522.7, bsz=489.6, num_updates=2600, lr=0.000104048, gnorm=0.759, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1684
2023-09-03 09:59:38 | INFO | train_inner | epoch 002:   1229 / 1474 loss=4.763, trans_loss=6.02, nll_loss=4.955, w2v_ctc_loss=2.705, task_loss=0, task_loss_gen=16.609, contrastive_loss=0, total=4220.45, n_correct=148.27, ppl=31.02, accuracy=3.513, wps=21771.1, ups=1.73, wpb=12591.7, bsz=492, num_updates=2700, lr=0.000108046, gnorm=0.714, clip=0, loss_scale=16, train_wall=57, gb_free=19.6, wall=1742
2023-09-03 10:00:35 | INFO | train_inner | epoch 002:   1329 / 1474 loss=4.746, trans_loss=6.01, nll_loss=4.947, w2v_ctc_loss=2.68, task_loss=0, task_loss_gen=17.493, contrastive_loss=0, total=4159.97, n_correct=141.12, ppl=30.84, accuracy=3.392, wps=21684.5, ups=1.74, wpb=12433.6, bsz=462.1, num_updates=2800, lr=0.000112044, gnorm=0.673, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1799
2023-09-03 10:01:33 | INFO | train_inner | epoch 002:   1429 / 1474 loss=4.737, trans_loss=6.019, nll_loss=4.957, w2v_ctc_loss=2.66, task_loss=0, task_loss_gen=19.824, contrastive_loss=0, total=4050.6, n_correct=141.16, ppl=31.05, accuracy=3.485, wps=21099.4, ups=1.74, wpb=12095, bsz=438.3, num_updates=2900, lr=0.000116042, gnorm=0.773, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1857
2023-09-03 10:01:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 10:02:45 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.837 | trans_loss 13.045 | nll_loss 12.615 | w2v_ctc_loss 3.393 | task_loss 0 | task_loss_gen 110.69 | contrastive_loss 0 | total 4003.4 | n_correct 229.2 | ppl 6274.22 | accuracy 5.725 | uer 48.486 | wer 47.336 | raw_wer 47.336 | bleu 0 | wps 1033.2 | wpb 4003.4 | bsz 141.8 | num_updates 2945 | best_bleu 0
2023-09-03 10:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2945 updates
2023-09-03 10:02:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 10:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 10:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2945 updates, score 0.0) (writing took 13.277103626984172 seconds)
2023-09-03 10:02:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-03 10:02:59 | INFO | train | epoch 002 | loss 4.921 | trans_loss 6.028 | nll_loss 4.965 | w2v_ctc_loss 2.936 | task_loss 0 | task_loss_gen 16.824 | contrastive_loss 0 | total 4138.65 | n_correct 149.607 | ppl 31.23 | accuracy 3.615 | wps 18623.5 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 2945 | lr 0.000117841 | gnorm 0.918 | clip 0 | loss_scale 16 | train_wall 842 | gb_free 19 | wall 1943
2023-09-03 10:02:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 10:02:59 | INFO | fairseq.trainer | begin training epoch 3
2023-09-03 10:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 10:03:38 | INFO | train_inner | epoch 003:     55 / 1474 loss=4.703, trans_loss=6.008, nll_loss=4.942, w2v_ctc_loss=2.61, task_loss=0, task_loss_gen=18.843, contrastive_loss=0, total=4066.57, n_correct=141.45, ppl=30.73, accuracy=3.478, wps=9646, ups=0.79, wpb=12139.2, bsz=441.1, num_updates=3000, lr=0.00012004, gnorm=0.708, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1983
2023-09-03 10:03:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 10:03:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-03 10:04:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-03 10:05:05 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.996, trans_loss=5.275, nll_loss=4.041, w2v_ctc_loss=2.297, task_loss=0.483, task_loss_gen=4.599, contrastive_loss=0, total=4134.93, n_correct=300.01, ppl=16.46, accuracy=7.256, wps=14234.9, ups=1.15, wpb=12348.4, bsz=457.2, num_updates=3100, lr=0.000124038, gnorm=1.59, clip=0, loss_scale=2, train_wall=86, gb_free=16.3, wall=2069
2023-09-03 10:06:31 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.482, trans_loss=4.766, nll_loss=3.359, w2v_ctc_loss=2.047, task_loss=0.428, task_loss_gen=1.86, contrastive_loss=0, total=4161.13, n_correct=677.23, ppl=10.26, accuracy=16.275, wps=14504, ups=1.17, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.102, clip=0, loss_scale=2, train_wall=85, gb_free=16.8, wall=2155
2023-09-03 10:07:56 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.072, trans_loss=4.273, nll_loss=2.703, w2v_ctc_loss=1.952, task_loss=0.311, task_loss_gen=2.145, contrastive_loss=0, total=4150.02, n_correct=1188.51, ppl=6.51, accuracy=28.639, wps=14593.8, ups=1.18, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.102, clip=0, loss_scale=2, train_wall=84, gb_free=16.8, wall=2240
2023-09-03 10:09:21 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.004, trans_loss=4.251, nll_loss=2.676, w2v_ctc_loss=1.877, task_loss=0.291, task_loss_gen=2.41, contrastive_loss=0, total=4209.57, n_correct=1250.13, ppl=6.39, accuracy=29.697, wps=14718.6, ups=1.17, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.015, clip=0, loss_scale=2, train_wall=85, gb_free=15.7, wall=2325
2023-09-03 10:10:46 | INFO | train_inner | epoch 003:    558 / 1474 loss=2.976, trans_loss=4.28, nll_loss=2.713, w2v_ctc_loss=1.811, task_loss=0.4, task_loss_gen=3.103, contrastive_loss=0, total=4088.48, n_correct=1182.27, ppl=6.56, accuracy=28.917, wps=14325.1, ups=1.17, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.082, clip=0, loss_scale=2, train_wall=85, gb_free=17.4, wall=2411
2023-09-03 10:12:13 | INFO | train_inner | epoch 003:    658 / 1474 loss=2.907, trans_loss=4.254, nll_loss=2.675, w2v_ctc_loss=1.744, task_loss=0.273, task_loss_gen=2.556, contrastive_loss=0, total=4221.58, n_correct=1281.55, ppl=6.39, accuracy=30.357, wps=14553.7, ups=1.16, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.946, clip=0, loss_scale=2, train_wall=86, gb_free=16.1, wall=2497
2023-09-03 10:13:37 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.879, trans_loss=4.237, nll_loss=2.658, w2v_ctc_loss=1.717, task_loss=0.378, task_loss_gen=2.524, contrastive_loss=0, total=4167.41, n_correct=1277.58, ppl=6.31, accuracy=30.656, wps=14707.6, ups=1.18, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.031, clip=0, loss_scale=2, train_wall=84, gb_free=16.1, wall=2582
2023-09-03 10:15:02 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.856, trans_loss=4.246, nll_loss=2.668, w2v_ctc_loss=1.675, task_loss=0.355, task_loss_gen=2.957, contrastive_loss=0, total=4165.53, n_correct=1269.34, ppl=6.35, accuracy=30.472, wps=14636.6, ups=1.18, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.934, clip=0, loss_scale=2, train_wall=84, gb_free=16.7, wall=2667
2023-09-03 10:16:28 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.833, trans_loss=4.23, nll_loss=2.646, w2v_ctc_loss=1.659, task_loss=0.343, task_loss_gen=2.68, contrastive_loss=0, total=4162.3, n_correct=1302.45, ppl=6.26, accuracy=31.292, wps=14561.8, ups=1.17, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.982, clip=0, loss_scale=2, train_wall=85, gb_free=16.5, wall=2752
2023-09-03 10:17:52 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.835, trans_loss=4.238, nll_loss=2.658, w2v_ctc_loss=1.649, task_loss=0.432, task_loss_gen=2.758, contrastive_loss=0, total=4069.95, n_correct=1255.26, ppl=6.31, accuracy=30.842, wps=14378.9, ups=1.18, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.066, clip=0, loss_scale=2, train_wall=84, gb_free=16.1, wall=2837
2023-09-03 10:17:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 10:18:24 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.625 | trans_loss 7.483 | nll_loss 5.422 | w2v_ctc_loss 1.886 | task_loss 0.156 | task_loss_gen 12.485 | contrastive_loss 0 | total 4003.4 | n_correct 1329.2 | ppl 42.87 | accuracy 33.202 | uer 28.344 | wer 29.563 | raw_wer 29.563 | bleu 0.25 | wps 1714.7 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 0.25
2023-09-03 10:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-09-03 10:18:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-03 10:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-03 10:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.25) (writing took 14.638862403051462 seconds)
2023-09-03 10:20:03 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.826, trans_loss=4.275, nll_loss=2.702, w2v_ctc_loss=1.608, task_loss=0.581, task_loss_gen=2.81, contrastive_loss=0, total=4038.49, n_correct=1210.15, ppl=6.51, accuracy=29.965, wps=9201.9, ups=0.76, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.15, clip=0, loss_scale=2, train_wall=84, gb_free=16.1, wall=2968
2023-09-03 10:21:28 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.786, trans_loss=4.245, nll_loss=2.666, w2v_ctc_loss=1.579, task_loss=0.488, task_loss_gen=2.266, contrastive_loss=0, total=4064.31, n_correct=1256.77, ppl=6.35, accuracy=30.922, wps=14386.9, ups=1.19, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.182, clip=0, loss_scale=2, train_wall=84, gb_free=17, wall=3052
2023-09-03 10:22:53 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.768, trans_loss=4.238, nll_loss=2.657, w2v_ctc_loss=1.547, task_loss=0.634, task_loss_gen=2.269, contrastive_loss=0, total=4134.58, n_correct=1279.98, ppl=6.31, accuracy=30.958, wps=14457.6, ups=1.17, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1.279, clip=0, loss_scale=2, train_wall=85, gb_free=17.5, wall=3137
2023-09-03 10:24:18 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.759, trans_loss=4.242, nll_loss=2.663, w2v_ctc_loss=1.531, task_loss=0.612, task_loss_gen=1.94, contrastive_loss=0, total=4209.94, n_correct=1293.43, ppl=6.33, accuracy=30.723, wps=14751, ups=1.17, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=1.26, clip=0, loss_scale=2, train_wall=85, gb_free=16.8, wall=3223
2023-09-03 10:24:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 10:25:03 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.571 | trans_loss 7.474 | nll_loss 5.41 | w2v_ctc_loss 1.725 | task_loss 2.224 | task_loss_gen 5.179 | contrastive_loss 0 | total 4003.4 | n_correct 1341.9 | ppl 42.51 | accuracy 33.519 | uer 27.208 | wer 28.288 | raw_wer 28.288 | bleu 0.18 | wps 1736.4 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 0.25
2023-09-03 10:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-09-03 10:25:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_0.1804.pt
2023-09-03 10:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_0.1804.pt
2023-09-03 10:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_0.1804.pt (epoch 3 @ 4416 updates, score 0.18) (writing took 8.97838884498924 seconds)
2023-09-03 10:25:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-03 10:25:12 | INFO | train | epoch 003 | loss 3.059 | trans_loss 4.421 | nll_loss 2.898 | w2v_ctc_loss 1.793 | task_loss 0.414 | task_loss_gen 3.215 | contrastive_loss 0 | total 4138.84 | n_correct 1108.27 | ppl 7.45 | accuracy 26.777 | wps 13637.1 | ups 1.1 | wpb 12356.5 | bsz 458.7 | num_updates 4416 | lr 0.000176652 | gnorm 1.109 | clip 0 | loss_scale 2 | train_wall 1229 | gb_free 16.1 | wall 3276
2023-09-03 10:25:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 10:25:12 | INFO | fairseq.trainer | begin training epoch 4
2023-09-03 10:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 10:26:30 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.705, trans_loss=4.203, nll_loss=2.613, w2v_ctc_loss=1.48, task_loss=0.64, task_loss_gen=1.819, contrastive_loss=0, total=4099.41, n_correct=1307.54, ppl=6.12, accuracy=31.896, wps=9264.5, ups=0.76, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=1.169, clip=0, loss_scale=2, train_wall=84, gb_free=16, wall=3355
2023-09-03 10:27:55 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.703, trans_loss=4.206, nll_loss=2.617, w2v_ctc_loss=1.469, task_loss=0.687, task_loss_gen=1.874, contrastive_loss=0, total=4175.15, n_correct=1313.57, ppl=6.13, accuracy=31.462, wps=14724.6, ups=1.18, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=1.229, clip=0, loss_scale=2, train_wall=84, gb_free=16.3, wall=3439
2023-09-03 10:29:20 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.708, trans_loss=4.217, nll_loss=2.632, w2v_ctc_loss=1.464, task_loss=0.802, task_loss_gen=2.248, contrastive_loss=0, total=4145.23, n_correct=1284.45, ppl=6.2, accuracy=30.986, wps=14582.3, ups=1.18, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=1.313, clip=0, loss_scale=2, train_wall=84, gb_free=15.7, wall=3524
2023-09-03 10:30:44 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.7, trans_loss=4.235, nll_loss=2.651, w2v_ctc_loss=1.455, task_loss=0.544, task_loss_gen=2.212, contrastive_loss=0, total=4127.66, n_correct=1297.05, ppl=6.28, accuracy=31.423, wps=14627.5, ups=1.19, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=1.1, clip=0, loss_scale=2, train_wall=84, gb_free=17.1, wall=3608
2023-09-03 10:32:09 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.669, trans_loss=4.255, nll_loss=2.675, w2v_ctc_loss=1.42, task_loss=0.443, task_loss_gen=2.335, contrastive_loss=0, total=4218.78, n_correct=1333.17, ppl=6.39, accuracy=31.601, wps=14756.5, ups=1.17, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=1.18, clip=0, loss_scale=2, train_wall=85, gb_free=16.2, wall=3694
2023-09-03 10:33:35 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.67, trans_loss=4.202, nll_loss=2.611, w2v_ctc_loss=1.44, task_loss=0.51, task_loss_gen=1.935, contrastive_loss=0, total=4217.52, n_correct=1356.49, ppl=6.11, accuracy=32.163, wps=14791.5, ups=1.17, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=1.042, clip=0, loss_scale=2, train_wall=85, gb_free=15.8, wall=3779
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:0')
2023-09-03 10:35:01 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.654, trans_loss=4.223, nll_loss=2.635, w2v_ctc_loss=1.394, task_loss=0.767, task_loss_gen=2.145, contrastive_loss=0, total=4176.39, n_correct=1322.72, ppl=6.21, accuracy=31.671, wps=14394.1, ups=1.16, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=1.195, clip=0, loss_scale=2, train_wall=86, gb_free=16.8, wall=3865
2023-09-03 10:36:26 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.64, trans_loss=4.166, nll_loss=2.569, w2v_ctc_loss=1.408, task_loss=0.839, task_loss_gen=1.857, contrastive_loss=0, total=4026.63, n_correct=1322.68, ppl=5.93, accuracy=32.848, wps=14197.5, ups=1.18, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.66, clip=0, loss_scale=4, train_wall=84, gb_free=12.9, wall=3950
2023-09-03 10:37:51 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.623, trans_loss=4.143, nll_loss=2.54, w2v_ctc_loss=1.402, task_loss=0.427, task_loss_gen=1.959, contrastive_loss=0, total=4186.04, n_correct=1398.41, ppl=5.82, accuracy=33.407, wps=14647.7, ups=1.17, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.473, clip=0, loss_scale=4, train_wall=85, gb_free=17.4, wall=4035
2023-09-03 10:39:16 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.605, trans_loss=4.134, nll_loss=2.527, w2v_ctc_loss=1.385, task_loss=0.518, task_loss_gen=2.048, contrastive_loss=0, total=4125.02, n_correct=1396.76, ppl=5.77, accuracy=33.861, wps=14456.5, ups=1.17, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.513, clip=0, loss_scale=4, train_wall=85, gb_free=12.4, wall=4121
2023-09-03 10:40:42 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.608, trans_loss=4.131, nll_loss=2.523, w2v_ctc_loss=1.389, task_loss=0.406, task_loss_gen=2.325, contrastive_loss=0, total=4075.6, n_correct=1385.53, ppl=5.75, accuracy=33.996, wps=14190.3, ups=1.17, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.465, clip=0, loss_scale=4, train_wall=85, gb_free=15.6, wall=4206
2023-09-03 10:42:08 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.586, trans_loss=4.12, nll_loss=2.511, w2v_ctc_loss=1.379, task_loss=0.393, task_loss_gen=2.134, contrastive_loss=0, total=4161.18, n_correct=1437.98, ppl=5.7, accuracy=34.557, wps=14517.9, ups=1.17, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.49, clip=0, loss_scale=4, train_wall=85, gb_free=16.4, wall=4292
2023-09-03 10:43:33 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.579, trans_loss=4.122, nll_loss=2.513, w2v_ctc_loss=1.363, task_loss=0.384, task_loss_gen=2.508, contrastive_loss=0, total=4156.53, n_correct=1440.92, ppl=5.71, accuracy=34.666, wps=14633.6, ups=1.18, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.5, clip=0, loss_scale=4, train_wall=84, gb_free=15.6, wall=4377
2023-09-03 10:44:56 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.597, trans_loss=4.153, nll_loss=2.55, w2v_ctc_loss=1.366, task_loss=0.398, task_loss_gen=3.24, contrastive_loss=0, total=4101.23, n_correct=1385.81, ppl=5.86, accuracy=33.79, wps=14621.8, ups=1.19, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.532, clip=0, loss_scale=4, train_wall=83, gb_free=15.3, wall=4461
2023-09-03 10:46:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2967, device='cuda:1')
2023-09-03 10:46:46 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.372 | trans_loss 7.289 | nll_loss 5.172 | w2v_ctc_loss 1.482 | task_loss 0.457 | task_loss_gen 10.362 | contrastive_loss 0 | total 4003.4 | n_correct 1444.4 | ppl 36.06 | accuracy 36.079 | uer 22.759 | wer 24.373 | raw_wer 24.373 | bleu 0.65 | wps 1526.8 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 0.65
2023-09-03 10:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-09-03 10:46:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 10:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 10:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5890 updates, score 0.65) (writing took 12.688284075004049 seconds)
2023-09-03 10:46:59 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-03 10:46:59 | INFO | train | epoch 004 | loss 2.641 | trans_loss 4.178 | nll_loss 2.581 | w2v_ctc_loss 1.41 | task_loss 0.535 | task_loss_gen 2.254 | contrastive_loss 0 | total 4138.65 | n_correct 1359.01 | ppl 5.98 | accuracy 32.837 | wps 13933.5 | ups 1.13 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.82 | clip 0 | loss_scale 4 | train_wall 1243 | gb_free 14.4 | wall 4583
2023-09-03 10:46:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 10:46:59 | INFO | fairseq.trainer | begin training epoch 5
2023-09-03 10:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 10:47:14 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.57, trans_loss=4.152, nll_loss=2.547, w2v_ctc_loss=1.337, task_loss=0.29, task_loss_gen=3.302, contrastive_loss=0, total=4037.7, n_correct=1383.9, ppl=5.84, accuracy=34.274, wps=8730.7, ups=0.72, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.471, clip=0, loss_scale=4, train_wall=83, gb_free=16.6, wall=4599
2023-09-03 10:48:39 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.502, trans_loss=4.116, nll_loss=2.501, w2v_ctc_loss=1.258, task_loss=0.423, task_loss_gen=2.86, contrastive_loss=0, total=4247.37, n_correct=1496.63, ppl=5.66, accuracy=35.237, wps=14989.7, ups=1.18, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.577, clip=0, loss_scale=4, train_wall=84, gb_free=16.4, wall=4683
2023-09-03 10:48:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 10:49:12 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.344 | trans_loss 7.253 | nll_loss 5.117 | w2v_ctc_loss 1.47 | task_loss 0.223 | task_loss_gen 13.266 | contrastive_loss 0 | total 4003.4 | n_correct 1459.1 | ppl 34.7 | accuracy 36.447 | uer 22.523 | wer 24.063 | raw_wer 24.063 | bleu 0.7 | wps 1598.2 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 0.7
2023-09-03 10:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-09-03 10:49:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-03 10:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-03 10:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 0.7) (writing took 13.362467286002357 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0080, -0.0009, -0.0012,  0.0001, -0.0013], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4067,  0.6387,  0.2781,  ..., -0.1077,  0.2668, -0.2974],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0033,  0.1610,  0.1576,  ...,  0.1006,  0.0221,  0.0181]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0080, -0.0009, -0.0012,  0.0001, -0.0013], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-03 10:50:50 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.51, trans_loss=4.12, nll_loss=2.503, w2v_ctc_loss=1.274, task_loss=0.269, task_loss_gen=3.096, contrastive_loss=0, total=4189.85, n_correct=1479.56, ppl=5.67, accuracy=35.313, wps=9564, ups=0.77, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.453, clip=0, loss_scale=4, train_wall=83, gb_free=17.5, wall=4814
2023-09-03 10:52:14 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.522, trans_loss=4.116, nll_loss=2.505, w2v_ctc_loss=1.288, task_loss=0.44, task_loss_gen=2.999, contrastive_loss=0, total=4090.1, n_correct=1430.79, ppl=5.68, accuracy=34.982, wps=14593.6, ups=1.19, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.687, clip=0, loss_scale=4, train_wall=83, gb_free=15.9, wall=4898
2023-09-03 10:53:39 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.488, trans_loss=4.095, nll_loss=2.475, w2v_ctc_loss=1.263, task_loss=0.47, task_loss_gen=2.62, contrastive_loss=0, total=4147.17, n_correct=1492.69, ppl=5.56, accuracy=35.993, wps=14566.2, ups=1.18, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.629, clip=0, loss_scale=4, train_wall=84, gb_free=14.5, wall=4983
2023-09-03 10:55:03 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.501, trans_loss=4.096, nll_loss=2.476, w2v_ctc_loss=1.274, task_loss=0.787, task_loss_gen=3.401, contrastive_loss=0, total=4026.81, n_correct=1439.96, ppl=5.56, accuracy=35.759, wps=14311.7, ups=1.19, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.647, clip=0, loss_scale=4, train_wall=83, gb_free=17.1, wall=5067
2023-09-03 10:56:27 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.495, trans_loss=4.079, nll_loss=2.454, w2v_ctc_loss=1.28, task_loss=1.071, task_loss_gen=2.747, contrastive_loss=0, total=4107.75, n_correct=1495.19, ppl=5.48, accuracy=36.399, wps=14491.3, ups=1.18, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.728, clip=0, loss_scale=4, train_wall=84, gb_free=15.9, wall=5152
2023-09-03 10:57:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-03 10:57:53 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.51, trans_loss=4.049, nll_loss=2.419, w2v_ctc_loss=1.33, task_loss=1.372, task_loss_gen=2.166, contrastive_loss=0, total=4173.98, n_correct=1550.64, ppl=5.35, accuracy=37.15, wps=14553, ups=1.17, wpb=12458.6, bsz=481.2, num_updates=6600, lr=0.000174078, gnorm=1.175, clip=1, loss_scale=2, train_wall=85, gb_free=16.8, wall=5237
2023-09-03 10:59:18 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.519, trans_loss=4.038, nll_loss=2.405, w2v_ctc_loss=1.34, task_loss=1.104, task_loss_gen=1.79, contrastive_loss=0, total=4127.9, n_correct=1540.02, ppl=5.3, accuracy=37.308, wps=14421.9, ups=1.17, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.847, clip=0, loss_scale=2, train_wall=85, gb_free=15.4, wall=5323
2023-09-03 11:00:43 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.502, trans_loss=4.023, nll_loss=2.387, w2v_ctc_loss=1.329, task_loss=0.992, task_loss_gen=1.745, contrastive_loss=0, total=4101.19, n_correct=1545.27, ppl=5.23, accuracy=37.679, wps=14545.7, ups=1.19, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.689, clip=0, loss_scale=2, train_wall=84, gb_free=16.9, wall=5407
2023-09-03 11:02:07 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.507, trans_loss=4.017, nll_loss=2.379, w2v_ctc_loss=1.343, task_loss=0.713, task_loss_gen=1.585, contrastive_loss=0, total=4164.27, n_correct=1576.66, ppl=5.2, accuracy=37.862, wps=14798.8, ups=1.19, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.782, clip=0, loss_scale=2, train_wall=83, gb_free=14.6, wall=5491
2023-09-03 11:03:32 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.534, trans_loss=4.007, nll_loss=2.364, w2v_ctc_loss=1.39, task_loss=0.534, task_loss_gen=1.655, contrastive_loss=0, total=4168.94, n_correct=1594.87, ppl=5.15, accuracy=38.256, wps=14507.8, ups=1.17, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.703, clip=0, loss_scale=2, train_wall=85, gb_free=16.3, wall=5576
2023-09-03 11:04:57 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.497, trans_loss=4.007, nll_loss=2.365, w2v_ctc_loss=1.334, task_loss=0.542, task_loss_gen=1.64, contrastive_loss=0, total=4171.16, n_correct=1599.52, ppl=5.15, accuracy=38.347, wps=14601.3, ups=1.17, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.678, clip=0, loss_scale=2, train_wall=85, gb_free=15.5, wall=5662
2023-09-03 11:06:23 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.513, trans_loss=3.999, nll_loss=2.356, w2v_ctc_loss=1.363, task_loss=0.545, task_loss_gen=1.701, contrastive_loss=0, total=4126.97, n_correct=1594.72, ppl=5.12, accuracy=38.641, wps=14426.7, ups=1.17, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.782, clip=0, loss_scale=2, train_wall=85, gb_free=15.1, wall=5747
2023-09-03 11:07:47 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.54, trans_loss=3.993, nll_loss=2.35, w2v_ctc_loss=1.413, task_loss=0.48, task_loss_gen=1.724, contrastive_loss=0, total=4138.54, n_correct=1615.39, ppl=5.1, accuracy=39.033, wps=14651.5, ups=1.19, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=1.012, clip=1, loss_scale=2, train_wall=84, gb_free=16.4, wall=5831
2023-09-03 11:08:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0701, -0.0061, -0.0086,  0.0109, -0.0145], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3628,  0.2678, -0.4644,  ..., -0.2661,  0.1637, -0.3804],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0626,  0.1121,  1.0684,  ...,  0.5586,  0.0291, -0.0524]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0701, -0.0061, -0.0086,  0.0109, -0.0145], device='cuda:5',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0568, -0.0076, -0.0077,  0.0041, -0.0102], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4949,  0.4646,  0.2732,  ..., -0.1913,  0.1870, -0.3040],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0486,  0.0179,  0.7622,  ...,  0.4155,  0.3010, -0.0389]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0568, -0.0076, -0.0077,  0.0041, -0.0102], device='cuda:4',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-7.1859e-04, -2.1982e-04,  1.4901e-06, -3.0851e-04, -5.4061e-05],
       device='cuda:7', dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1907,  0.3594,  0.2375,  ..., -0.0151,  0.0615, -0.1172],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0163, -0.1324, -0.0706,  ...,  0.0091,  0.0179,  0.0014]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-7.1859e-04, -2.1982e-04,  1.4901e-06, -3.0851e-04, -5.4061e-05],
       device='cuda:7', dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0768, -0.0035, -0.0062, -0.0179, -0.0046], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3591, -0.1991,  0.4590,  ..., -0.3042,  0.2042, -0.3708],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0463,  0.8354,  1.7188,  ...,  0.0947,  0.3550,  0.0476]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0768, -0.0035, -0.0062, -0.0179, -0.0046], device='cuda:2',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.1643, -0.0260, -0.0185, -0.0691,  0.0023], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2410,  0.5918, -0.5859,  ..., -0.3667,  0.1599, -0.6118],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0256,  0.1357,  2.1133,  ...,  0.2256, -0.0446,  0.0836]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.1643, -0.0260, -0.0185, -0.0691,  0.0023], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.1199, -0.0211, -0.0138,  0.0030, -0.0174], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.4500,  1.2617,  0.2219,  ..., -0.3779,  0.0144, -0.3115],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2267, -1.2422,  0.5498,  ...,  0.4983,  0.3943, -0.0349]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.1199, -0.0211, -0.0138,  0.0030, -0.0174], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.0703, -0.0054, -0.0064, -0.0027, -0.0105], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.9336, -0.0702, -0.5483,  ..., -0.3076,  0.2161, -0.4521],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2463,  2.0254,  4.7266,  ...,  0.5571,  0.5659, -0.1234]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.0703, -0.0054, -0.0064, -0.0027, -0.0105], device='cuda:3',
       dtype=torch.float16)
--------------------
2023-09-03 11:09:17 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.102 | trans_loss 6.878 | nll_loss 4.655 | w2v_ctc_loss 1.509 | task_loss 0.997 | task_loss_gen 9.146 | contrastive_loss 0 | total 4003.4 | n_correct 1666.7 | ppl 25.2 | accuracy 41.632 | uer 23.518 | wer 25.234 | raw_wer 25.234 | bleu 3.19 | wps 1373.3 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 3.19
2023-09-03 11:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-09-03 11:09:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7363 updates, score 3.19) (writing took 12.186603772977833 seconds)
2023-09-03 11:09:30 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-03 11:09:30 | INFO | train | epoch 005 | loss 2.512 | trans_loss 4.051 | nll_loss 2.421 | w2v_ctc_loss 1.324 | task_loss 0.681 | task_loss_gen 2.254 | contrastive_loss 0 | total 4138.4 | n_correct 1534.25 | ppl 5.36 | accuracy 37.074 | wps 13473.4 | ups 1.09 | wpb 12355.1 | bsz 458.4 | num_updates 7363 | lr 0.000164812 | gnorm 0.747 | clip 0.1 | loss_scale 2 | train_wall 1238 | gb_free 15.8 | wall 5934
2023-09-03 11:09:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 11:09:30 | INFO | fairseq.trainer | begin training epoch 6
2023-09-03 11:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 11:10:09 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.526, trans_loss=3.976, nll_loss=2.327, w2v_ctc_loss=1.405, task_loss=0.452, task_loss_gen=1.801, contrastive_loss=0, total=4113.87, n_correct=1619.03, ppl=5.02, accuracy=39.355, wps=8670, ups=0.71, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.891, clip=0, loss_scale=2, train_wall=84, gb_free=17.5, wall=5973
2023-09-03 11:11:33 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.485, trans_loss=3.949, nll_loss=2.292, w2v_ctc_loss=1.364, task_loss=0.386, task_loss_gen=1.937, contrastive_loss=0, total=4161.2, n_correct=1671.37, ppl=4.9, accuracy=40.166, wps=14704.6, ups=1.18, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.88, clip=1, loss_scale=2, train_wall=84, gb_free=16.6, wall=6058
2023-09-03 11:12:58 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.48, trans_loss=3.941, nll_loss=2.284, w2v_ctc_loss=1.37, task_loss=0.491, task_loss_gen=1.923, contrastive_loss=0, total=4110.12, n_correct=1671.96, ppl=4.87, accuracy=40.679, wps=14466.8, ups=1.18, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.78, clip=0, loss_scale=2, train_wall=84, gb_free=16.8, wall=6142
2023-09-03 11:14:26 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.449, trans_loss=3.911, nll_loss=2.242, w2v_ctc_loss=1.354, task_loss=0.4, task_loss_gen=1.683, contrastive_loss=0, total=4170.52, n_correct=1744.59, ppl=4.73, accuracy=41.831, wps=14244, ups=1.14, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.923, clip=0, loss_scale=2, train_wall=87, gb_free=15.3, wall=6230
2023-09-03 11:15:50 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.437, trans_loss=3.9, nll_loss=2.228, w2v_ctc_loss=1.348, task_loss=0.404, task_loss_gen=1.663, contrastive_loss=0, total=4154.89, n_correct=1766.55, ppl=4.68, accuracy=42.517, wps=14765.2, ups=1.19, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.776, clip=0, loss_scale=2, train_wall=83, gb_free=16, wall=6314
2023-09-03 11:17:14 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.408, trans_loss=3.875, nll_loss=2.194, w2v_ctc_loss=1.332, task_loss=0.394, task_loss_gen=1.799, contrastive_loss=0, total=4174.46, n_correct=1824.86, ppl=4.58, accuracy=43.715, wps=14743.9, ups=1.18, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.642, clip=0, loss_scale=2, train_wall=84, gb_free=16.9, wall=6398
2023-09-03 11:18:38 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.392, trans_loss=3.86, nll_loss=2.173, w2v_ctc_loss=1.328, task_loss=0.369, task_loss_gen=1.789, contrastive_loss=0, total=4145.19, n_correct=1841.9, ppl=4.51, accuracy=44.435, wps=14729.1, ups=1.19, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.728, clip=0, loss_scale=2, train_wall=83, gb_free=15.5, wall=6482
2023-09-03 11:18:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 11:19:14 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.737 | trans_loss 6.323 | nll_loss 3.913 | w2v_ctc_loss 1.542 | task_loss 0.94 | task_loss_gen 9.093 | contrastive_loss 0 | total 4003.4 | n_correct 1969.9 | ppl 15.06 | accuracy 49.206 | uer 22.759 | wer 24.723 | raw_wer 24.723 | bleu 8.32 | wps 1452.9 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 8.32
2023-09-03 11:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-09-03 11:19:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-03 11:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-03 11:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 8.32) (writing took 12.976314833038487 seconds)
2023-09-03 11:20:52 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.408, trans_loss=3.844, nll_loss=2.155, w2v_ctc_loss=1.369, task_loss=0.445, task_loss_gen=1.856, contrastive_loss=0, total=4151.01, n_correct=1872.16, ppl=4.45, accuracy=45.101, wps=9259.2, ups=0.75, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.879, clip=0, loss_scale=2, train_wall=84, gb_free=12.6, wall=6616
2023-09-03 11:22:18 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.379, trans_loss=3.826, nll_loss=2.13, w2v_ctc_loss=1.342, task_loss=0.485, task_loss_gen=1.794, contrastive_loss=0, total=4108.83, n_correct=1883.2, ppl=4.38, accuracy=45.833, wps=14324.8, ups=1.17, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.703, clip=0, loss_scale=2, train_wall=85, gb_free=16.8, wall=6702
2023-09-03 11:23:42 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.368, trans_loss=3.805, nll_loss=2.101, w2v_ctc_loss=1.35, task_loss=0.492, task_loss_gen=1.827, contrastive_loss=0, total=4076.46, n_correct=1905.01, ppl=4.29, accuracy=46.732, wps=14345, ups=1.18, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.728, clip=0, loss_scale=2, train_wall=84, gb_free=12.3, wall=6787
2023-09-03 11:25:06 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.345, trans_loss=3.774, nll_loss=2.062, w2v_ctc_loss=1.348, task_loss=0.401, task_loss_gen=1.668, contrastive_loss=0, total=4175.9, n_correct=1993.34, ppl=4.18, accuracy=47.734, wps=14839, ups=1.19, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.846, clip=0, loss_scale=2, train_wall=83, gb_free=13.8, wall=6871
2023-09-03 11:26:31 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.349, trans_loss=3.766, nll_loss=2.052, w2v_ctc_loss=1.354, task_loss=0.414, task_loss_gen=2.056, contrastive_loss=0, total=4077.2, n_correct=1962.83, ppl=4.15, accuracy=48.142, wps=14406.2, ups=1.18, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.753, clip=0, loss_scale=2, train_wall=84, gb_free=16, wall=6955
2023-09-03 11:27:56 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.317, trans_loss=3.743, nll_loss=2.021, w2v_ctc_loss=1.336, task_loss=0.394, task_loss_gen=1.802, contrastive_loss=0, total=4133.46, n_correct=2032.48, ppl=4.06, accuracy=49.171, wps=14501.2, ups=1.17, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.734, clip=0, loss_scale=4, train_wall=84, gb_free=11.9, wall=7040
2023-09-03 11:29:21 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.303, trans_loss=3.73, nll_loss=2.003, w2v_ctc_loss=1.331, task_loss=0.31, task_loss_gen=2.19, contrastive_loss=0, total=4127.77, n_correct=2060.02, ppl=4.01, accuracy=49.906, wps=14571.8, ups=1.18, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.783, clip=0, loss_scale=4, train_wall=84, gb_free=16.7, wall=7125
2023-09-03 11:30:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-03 11:30:47 | INFO | train_inner | epoch 006:   1438 / 1474 loss=2.306, trans_loss=3.719, nll_loss=1.99, w2v_ctc_loss=1.342, task_loss=0.295, task_loss_gen=2.257, contrastive_loss=0, total=4195.85, n_correct=2108.66, ppl=3.97, accuracy=50.256, wps=14529.9, ups=1.16, wpb=12525, bsz=463.3, num_updates=8800, lr=0.000150756, gnorm=0.871, clip=0, loss_scale=2, train_wall=85, gb_free=16.1, wall=7211
2023-09-03 11:31:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 11:31:52 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.44 | trans_loss 5.891 | nll_loss 3.356 | w2v_ctc_loss 1.524 | task_loss 5.628 | task_loss_gen 6.176 | contrastive_loss 0 | total 4003.4 | n_correct 2221.2 | ppl 10.24 | accuracy 55.483 | uer 23.136 | wer 24.988 | raw_wer 24.988 | bleu 13.03 | wps 1446.2 | wpb 4003.4 | bsz 141.8 | num_updates 8836 | best_bleu 13.03
2023-09-03 11:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8836 updates
2023-09-03 11:31:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:31:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8836 updates, score 13.03) (writing took 13.924471719015855 seconds)
2023-09-03 11:32:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-03 11:32:06 | INFO | train | epoch 006 | loss 2.388 | trans_loss 3.832 | nll_loss 2.138 | w2v_ctc_loss 1.347 | task_loss 0.404 | task_loss_gen 1.869 | contrastive_loss 0 | total 4138.73 | n_correct 1879.86 | ppl 4.4 | accuracy 45.421 | wps 13418.5 | ups 1.09 | wpb 12356 | bsz 458.6 | num_updates 8836 | lr 0.000150448 | gnorm 0.788 | clip 0.1 | loss_scale 2 | train_wall 1241 | gb_free 14.8 | wall 7290
2023-09-03 11:32:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 11:32:06 | INFO | fairseq.trainer | begin training epoch 7
2023-09-03 11:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 11:33:08 | INFO | train_inner | epoch 007:     64 / 1474 loss=2.281, trans_loss=3.709, nll_loss=1.977, w2v_ctc_loss=1.32, task_loss=0.453, task_loss_gen=1.82, contrastive_loss=0, total=4105.94, n_correct=2078.74, ppl=3.94, accuracy=50.628, wps=8674.8, ups=0.71, wpb=12258, bsz=460.8, num_updates=8900, lr=0.000149906, gnorm=0.849, clip=0, loss_scale=2, train_wall=84, gb_free=14.6, wall=7352
2023-09-03 11:34:32 | INFO | train_inner | epoch 007:    164 / 1474 loss=2.276, trans_loss=3.696, nll_loss=1.96, w2v_ctc_loss=1.317, task_loss=0.496, task_loss_gen=1.717, contrastive_loss=0, total=4101.13, n_correct=2090.1, ppl=3.89, accuracy=50.964, wps=14593.6, ups=1.19, wpb=12245.3, bsz=452.9, num_updates=9000, lr=0.000149071, gnorm=0.822, clip=0, loss_scale=2, train_wall=83, gb_free=16.6, wall=7436
2023-09-03 11:35:57 | INFO | train_inner | epoch 007:    264 / 1474 loss=2.252, trans_loss=3.673, nll_loss=1.929, w2v_ctc_loss=1.305, task_loss=0.507, task_loss_gen=1.641, contrastive_loss=0, total=4143.65, n_correct=2148.51, ppl=3.81, accuracy=51.851, wps=14629.8, ups=1.18, wpb=12365.3, bsz=458, num_updates=9100, lr=0.00014825, gnorm=0.701, clip=0, loss_scale=2, train_wall=84, gb_free=15.8, wall=7521
2023-09-03 11:37:22 | INFO | train_inner | epoch 007:    364 / 1474 loss=2.243, trans_loss=3.669, nll_loss=1.924, w2v_ctc_loss=1.296, task_loss=0.502, task_loss_gen=1.595, contrastive_loss=0, total=4190.59, n_correct=2177.5, ppl=3.79, accuracy=51.962, wps=14618.1, ups=1.17, wpb=12506.9, bsz=477.2, num_updates=9200, lr=0.000147442, gnorm=0.743, clip=0, loss_scale=2, train_wall=85, gb_free=16.4, wall=7606
2023-09-03 11:38:47 | INFO | train_inner | epoch 007:    464 / 1474 loss=2.223, trans_loss=3.655, nll_loss=1.909, w2v_ctc_loss=1.278, task_loss=0.56, task_loss_gen=1.525, contrastive_loss=0, total=4154.13, n_correct=2185.15, ppl=3.75, accuracy=52.602, wps=14703.6, ups=1.19, wpb=12405.4, bsz=461.6, num_updates=9300, lr=0.000146647, gnorm=0.643, clip=0, loss_scale=2, train_wall=84, gb_free=16, wall=7691
2023-09-03 11:40:10 | INFO | train_inner | epoch 007:    564 / 1474 loss=2.229, trans_loss=3.646, nll_loss=1.894, w2v_ctc_loss=1.297, task_loss=0.462, task_loss_gen=1.595, contrastive_loss=0, total=4171.52, n_correct=2214.53, ppl=3.72, accuracy=53.087, wps=14849.1, ups=1.19, wpb=12446, bsz=461, num_updates=9400, lr=0.000145865, gnorm=0.736, clip=0, loss_scale=2, train_wall=83, gb_free=16.7, wall=7775
2023-09-03 11:41:35 | INFO | train_inner | epoch 007:    664 / 1474 loss=2.224, trans_loss=3.64, nll_loss=1.887, w2v_ctc_loss=1.296, task_loss=0.474, task_loss_gen=1.661, contrastive_loss=0, total=4151.13, n_correct=2217.12, ppl=3.7, accuracy=53.41, wps=14613.7, ups=1.18, wpb=12385.9, bsz=454, num_updates=9500, lr=0.000145095, gnorm=0.75, clip=0, loss_scale=2, train_wall=84, gb_free=12.3, wall=7859
2023-09-03 11:43:00 | INFO | train_inner | epoch 007:    764 / 1474 loss=2.208, trans_loss=3.624, nll_loss=1.868, w2v_ctc_loss=1.281, task_loss=0.543, task_loss_gen=1.631, contrastive_loss=0, total=4124.23, n_correct=2215.13, ppl=3.65, accuracy=53.71, wps=14472.3, ups=1.18, wpb=12314.5, bsz=446.8, num_updates=9600, lr=0.000144338, gnorm=0.738, clip=0, loss_scale=2, train_wall=84, gb_free=13.8, wall=7945
2023-09-03 11:44:26 | INFO | train_inner | epoch 007:    864 / 1474 loss=2.219, trans_loss=3.633, nll_loss=1.878, w2v_ctc_loss=1.299, task_loss=0.505, task_loss_gen=1.563, contrastive_loss=0, total=4148.43, n_correct=2221.89, ppl=3.68, accuracy=53.56, wps=14457.6, ups=1.17, wpb=12380.2, bsz=461.8, num_updates=9700, lr=0.000143592, gnorm=0.819, clip=0, loss_scale=2, train_wall=85, gb_free=16.1, wall=8030
2023-09-03 11:45:51 | INFO | train_inner | epoch 007:    964 / 1474 loss=2.185, trans_loss=3.612, nll_loss=1.853, w2v_ctc_loss=1.267, task_loss=0.513, task_loss_gen=1.511, contrastive_loss=0, total=4141.1, n_correct=2245.29, ppl=3.61, accuracy=54.22, wps=14463.3, ups=1.17, wpb=12362.4, bsz=473.7, num_updates=9800, lr=0.000142857, gnorm=0.72, clip=0, loss_scale=2, train_wall=85, gb_free=13.4, wall=8116
2023-09-03 11:47:16 | INFO | train_inner | epoch 007:   1064 / 1474 loss=2.207, trans_loss=3.618, nll_loss=1.861, w2v_ctc_loss=1.295, task_loss=0.589, task_loss_gen=1.601, contrastive_loss=0, total=4100.93, n_correct=2225.31, ppl=3.63, accuracy=54.264, wps=14475.7, ups=1.18, wpb=12243.4, bsz=437.6, num_updates=9900, lr=0.000142134, gnorm=0.807, clip=0, loss_scale=2, train_wall=84, gb_free=14.4, wall=8200
2023-09-03 11:48:41 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.18, trans_loss=3.593, nll_loss=1.831, w2v_ctc_loss=1.273, task_loss=0.503, task_loss_gen=1.474, contrastive_loss=0, total=4139.88, n_correct=2275.15, ppl=3.56, accuracy=54.957, wps=14541.1, ups=1.18, wpb=12369.6, bsz=471.4, num_updates=10000, lr=0.000141421, gnorm=0.71, clip=0, loss_scale=2, train_wall=84, gb_free=16.3, wall=8285
2023-09-03 11:48:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 11:49:16 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.246 | trans_loss 5.622 | nll_loss 3.018 | w2v_ctc_loss 1.485 | task_loss 2.474 | task_loss_gen 6.546 | contrastive_loss 0 | total 4003.4 | n_correct 2376.2 | ppl 8.1 | accuracy 59.355 | uer 22.382 | wer 24.112 | raw_wer 24.112 | bleu 16.21 | wps 1470.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 16.21
2023-09-03 11:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-09-03 11:49:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-03 11:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-03 11:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 16.21) (writing took 14.907688414969016 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 11:50:56 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.183, trans_loss=3.6, nll_loss=1.838, w2v_ctc_loss=1.272, task_loss=0.555, task_loss_gen=1.528, contrastive_loss=0, total=4129.16, n_correct=2259.13, ppl=3.58, accuracy=54.712, wps=9155.6, ups=0.74, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.687, clip=0, loss_scale=2, train_wall=84, gb_free=16.5, wall=8420
2023-09-03 11:52:20 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.18, trans_loss=3.584, nll_loss=1.818, w2v_ctc_loss=1.285, task_loss=0.523, task_loss_gen=1.405, contrastive_loss=0, total=4177.71, n_correct=2312.25, ppl=3.53, accuracy=55.347, wps=14752.1, ups=1.18, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.666, clip=0, loss_scale=2, train_wall=84, gb_free=16.3, wall=8505
2023-09-03 11:53:47 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.168, trans_loss=3.579, nll_loss=1.813, w2v_ctc_loss=1.267, task_loss=0.655, task_loss_gen=1.572, contrastive_loss=0, total=4107.01, n_correct=2283.11, ppl=3.51, accuracy=55.591, wps=14212.4, ups=1.16, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.631, clip=0, loss_scale=2, train_wall=86, gb_free=12.8, wall=8591
2023-09-03 11:53:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
2023-09-03 11:54:31 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.547 | nll_loss 2.918 | w2v_ctc_loss 1.523 | task_loss 2.038 | task_loss_gen 6.575 | contrastive_loss 0 | total 4003.4 | n_correct 2413 | ppl 7.56 | accuracy 60.274 | uer 21.211 | wer 22.732 | raw_wer 22.732 | bleu 16.49 | wps 1419.1 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 16.49
2023-09-03 11:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-09-03 11:54:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 11:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10310 updates, score 16.49) (writing took 14.619760539964773 seconds)
2023-09-03 11:54:46 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-03 11:54:46 | INFO | train | epoch 007 | loss 2.215 | trans_loss 3.633 | nll_loss 1.879 | w2v_ctc_loss 1.289 | task_loss 0.527 | task_loss_gen 1.582 | contrastive_loss 0 | total 4138.65 | n_correct 2213.21 | ppl 3.68 | accuracy 53.477 | wps 13394.8 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 10310 | lr 0.000139279 | gnorm 0.735 | clip 0 | loss_scale 2 | train_wall 1241 | gb_free 12.8 | wall 8650
2023-09-03 11:54:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 11:54:46 | INFO | fairseq.trainer | begin training epoch 8
2023-09-03 11:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 11:56:10 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.161, trans_loss=3.575, nll_loss=1.802, w2v_ctc_loss=1.263, task_loss=0.637, task_loss_gen=1.551, contrastive_loss=0, total=4106.01, n_correct=2292.8, ppl=3.49, accuracy=55.84, wps=8560.4, ups=0.7, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.727, clip=0, loss_scale=2, train_wall=84, gb_free=16.8, wall=8734
2023-09-03 11:57:34 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.141, trans_loss=3.558, nll_loss=1.78, w2v_ctc_loss=1.242, task_loss=0.74, task_loss_gen=1.507, contrastive_loss=0, total=4043.12, n_correct=2276.26, ppl=3.43, accuracy=56.3, wps=14307.7, ups=1.19, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.666, clip=0, loss_scale=2, train_wall=84, gb_free=12.8, wall=8818
2023-09-03 11:58:58 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.116, trans_loss=3.541, nll_loss=1.761, w2v_ctc_loss=1.225, task_loss=0.675, task_loss_gen=1.261, contrastive_loss=0, total=4207.9, n_correct=2395.79, ppl=3.39, accuracy=56.936, wps=14913.9, ups=1.19, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.565, clip=0, loss_scale=2, train_wall=84, gb_free=13.6, wall=8902
2023-09-03 12:00:24 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.127, trans_loss=3.544, nll_loss=1.764, w2v_ctc_loss=1.236, task_loss=0.719, task_loss_gen=1.416, contrastive_loss=0, total=4134.6, n_correct=2352.79, ppl=3.4, accuracy=56.905, wps=14379.6, ups=1.17, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.58, clip=0, loss_scale=2, train_wall=85, gb_free=17, wall=8988
2023-09-03 12:01:49 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.101, trans_loss=3.535, nll_loss=1.754, w2v_ctc_loss=1.208, task_loss=0.67, task_loss_gen=1.202, contrastive_loss=0, total=4196.6, n_correct=2397.76, ppl=3.37, accuracy=57.136, wps=14676.7, ups=1.17, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.594, clip=0, loss_scale=2, train_wall=85, gb_free=12.4, wall=9074
2023-09-03 12:03:14 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.11, trans_loss=3.524, nll_loss=1.744, w2v_ctc_loss=1.223, task_loss=0.763, task_loss_gen=1.452, contrastive_loss=0, total=4065.55, n_correct=2332.79, ppl=3.35, accuracy=57.379, wps=14304.9, ups=1.18, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.418, clip=0, loss_scale=4, train_wall=84, gb_free=15.8, wall=9158
2023-09-03 12:04:39 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.093, trans_loss=3.515, nll_loss=1.729, w2v_ctc_loss=1.208, task_loss=0.728, task_loss_gen=1.419, contrastive_loss=0, total=4135.41, n_correct=2397.22, ppl=3.31, accuracy=57.968, wps=14514.9, ups=1.18, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.404, clip=0, loss_scale=4, train_wall=84, gb_free=15.6, wall=9244
2023-09-03 12:06:04 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.081, trans_loss=3.508, nll_loss=1.723, w2v_ctc_loss=1.197, task_loss=0.687, task_loss_gen=1.378, contrastive_loss=0, total=4128.86, n_correct=2397.27, ppl=3.3, accuracy=58.061, wps=14617.3, ups=1.18, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.398, clip=0, loss_scale=4, train_wall=84, gb_free=16, wall=9328
2023-09-03 12:07:29 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.068, trans_loss=3.506, nll_loss=1.72, w2v_ctc_loss=1.183, task_loss=0.673, task_loss_gen=1.308, contrastive_loss=0, total=4166.92, n_correct=2430.36, ppl=3.29, accuracy=58.325, wps=14615.2, ups=1.17, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.396, clip=0, loss_scale=4, train_wall=85, gb_free=14.1, wall=9413
2023-09-03 12:08:54 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.064, trans_loss=3.502, nll_loss=1.713, w2v_ctc_loss=1.18, task_loss=0.597, task_loss_gen=1.354, contrastive_loss=0, total=4150.39, n_correct=2435.36, ppl=3.28, accuracy=58.678, wps=14557.9, ups=1.17, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.391, clip=0, loss_scale=4, train_wall=84, gb_free=16.9, wall=9498
2023-09-03 12:10:19 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.059, trans_loss=3.502, nll_loss=1.713, w2v_ctc_loss=1.174, task_loss=0.567, task_loss_gen=1.462, contrastive_loss=0, total=4197.39, n_correct=2454.25, ppl=3.28, accuracy=58.471, wps=14704.8, ups=1.17, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.386, clip=0, loss_scale=4, train_wall=85, gb_free=16.5, wall=9583
2023-09-03 12:11:43 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.059, trans_loss=3.49, nll_loss=1.7, w2v_ctc_loss=1.181, task_loss=0.542, task_loss_gen=1.401, contrastive_loss=0, total=4180.55, n_correct=2460.52, ppl=3.25, accuracy=58.856, wps=14901.1, ups=1.19, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.386, clip=0, loss_scale=4, train_wall=83, gb_free=16.9, wall=9667
2023-09-03 12:13:07 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.064, trans_loss=3.493, nll_loss=1.703, w2v_ctc_loss=1.186, task_loss=0.607, task_loss_gen=1.53, contrastive_loss=0, total=4062.6, n_correct=2379.78, ppl=3.26, accuracy=58.578, wps=14513.7, ups=1.2, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.393, clip=0, loss_scale=4, train_wall=83, gb_free=12.6, wall=9751
2023-09-03 12:14:31 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.051, trans_loss=3.493, nll_loss=1.703, w2v_ctc_loss=1.169, task_loss=0.492, task_loss_gen=1.498, contrastive_loss=0, total=4159.11, n_correct=2453.07, ppl=3.25, accuracy=58.981, wps=14704.2, ups=1.18, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.388, clip=0, loss_scale=4, train_wall=84, gb_free=12.9, wall=9835
2023-09-03 12:15:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 12:16:15 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.069 | trans_loss 5.384 | nll_loss 2.715 | w2v_ctc_loss 1.43 | task_loss 2.312 | task_loss_gen 6.387 | contrastive_loss 0 | total 4003.4 | n_correct 2518.7 | ppl 6.57 | accuracy 62.914 | uer 20.389 | wer 22.095 | raw_wer 22.095 | bleu 18.56 | wps 1619.4 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 18.56
2023-09-03 12:16:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-09-03 12:16:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 12:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 12:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 18.56) (writing took 12.59213267499581 seconds)
2023-09-03 12:16:28 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-03 12:16:28 | INFO | train | epoch 008 | loss 2.089 | trans_loss 3.519 | nll_loss 1.734 | w2v_ctc_loss 1.202 | task_loss 0.64 | task_loss_gen 1.416 | contrastive_loss 0 | total 4138.65 | n_correct 2393.52 | ppl 3.33 | accuracy 57.833 | wps 13983.9 | ups 1.13 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.472 | clip 0 | loss_scale 4 | train_wall 1238 | gb_free 16.6 | wall 9952
2023-09-03 12:16:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 12:16:28 | INFO | fairseq.trainer | begin training epoch 9
2023-09-03 12:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 12:16:49 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.04, trans_loss=3.487, nll_loss=1.693, w2v_ctc_loss=1.158, task_loss=0.498, task_loss_gen=1.567, contrastive_loss=0, total=4121.25, n_correct=2439.5, ppl=3.23, accuracy=59.193, wps=8895.2, ups=0.72, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.414, clip=0, loss_scale=4, train_wall=84, gb_free=17.5, wall=9974
2023-09-03 12:18:13 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.011, trans_loss=3.46, nll_loss=1.66, w2v_ctc_loss=1.132, task_loss=0.485, task_loss_gen=1.432, contrastive_loss=0, total=4191.82, n_correct=2511.66, ppl=3.16, accuracy=59.918, wps=14908.4, ups=1.19, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.376, clip=0, loss_scale=4, train_wall=83, gb_free=15.6, wall=10058
2023-09-03 12:19:38 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.017, trans_loss=3.465, nll_loss=1.665, w2v_ctc_loss=1.133, task_loss=0.58, task_loss_gen=1.638, contrastive_loss=0, total=4061.27, n_correct=2427.7, ppl=3.17, accuracy=59.777, wps=14300.9, ups=1.18, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.391, clip=0, loss_scale=4, train_wall=84, gb_free=17.3, wall=10142
2023-09-03 12:19:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 12:20:12 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.06 | trans_loss 5.402 | nll_loss 2.736 | w2v_ctc_loss 1.361 | task_loss 2.383 | task_loss_gen 6.282 | contrastive_loss 0 | total 4003.4 | n_correct 2509.8 | ppl 6.66 | accuracy 62.692 | uer 20.118 | wer 21.77 | raw_wer 21.77 | bleu 18.88 | wps 1570.7 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.88
2023-09-03 12:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-09-03 12:20:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-03 12:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-03 12:20:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.88) (writing took 12.873279742023442 seconds)
2023-09-03 12:21:50 | INFO | train_inner | epoch 009:    316 / 1474 loss=1.997, trans_loss=3.45, nll_loss=1.649, w2v_ctc_loss=1.119, task_loss=0.482, task_loss_gen=1.47, contrastive_loss=0, total=4146.43, n_correct=2495.38, ppl=3.14, accuracy=60.181, wps=9427.2, ups=0.76, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.381, clip=0, loss_scale=4, train_wall=83, gb_free=16, wall=10274
2023-09-03 12:23:15 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.008, trans_loss=3.464, nll_loss=1.665, w2v_ctc_loss=1.127, task_loss=0.497, task_loss_gen=1.539, contrastive_loss=0, total=4194.84, n_correct=2511.69, ppl=3.17, accuracy=59.876, wps=14705.8, ups=1.17, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.384, clip=0, loss_scale=4, train_wall=85, gb_free=15.8, wall=10359
2023-09-03 12:24:39 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.025, trans_loss=3.463, nll_loss=1.663, w2v_ctc_loss=1.149, task_loss=0.521, task_loss_gen=1.623, contrastive_loss=0, total=4124.3, n_correct=2470.02, ppl=3.17, accuracy=59.889, wps=14519.8, ups=1.18, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.387, clip=0, loss_scale=4, train_wall=84, gb_free=11.1, wall=10444
2023-09-03 12:26:05 | INFO | train_inner | epoch 009:    616 / 1474 loss=1.997, trans_loss=3.452, nll_loss=1.652, w2v_ctc_loss=1.119, task_loss=0.534, task_loss_gen=1.569, contrastive_loss=0, total=4120.96, n_correct=2482.09, ppl=3.14, accuracy=60.231, wps=14438.3, ups=1.17, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.386, clip=0, loss_scale=4, train_wall=85, gb_free=15.8, wall=10529
2023-09-03 12:27:29 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.016, trans_loss=3.459, nll_loss=1.66, w2v_ctc_loss=1.143, task_loss=0.533, task_loss_gen=1.571, contrastive_loss=0, total=4088.53, n_correct=2454.9, ppl=3.16, accuracy=60.044, wps=14565.9, ups=1.19, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.397, clip=0, loss_scale=4, train_wall=83, gb_free=16.6, wall=10613
2023-09-03 12:28:54 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.002, trans_loss=3.45, nll_loss=1.65, w2v_ctc_loss=1.129, task_loss=0.47, task_loss_gen=1.384, contrastive_loss=0, total=4220.43, n_correct=2545.92, ppl=3.14, accuracy=60.324, wps=14783.1, ups=1.17, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.379, clip=0, loss_scale=4, train_wall=84, gb_free=14, wall=10698
2023-09-03 12:30:20 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.005, trans_loss=3.455, nll_loss=1.652, w2v_ctc_loss=1.129, task_loss=0.531, task_loss_gen=1.55, contrastive_loss=0, total=4146.05, n_correct=2496.27, ppl=3.14, accuracy=60.208, wps=14421, ups=1.17, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.388, clip=0, loss_scale=4, train_wall=85, gb_free=17.4, wall=10784
2023-09-03 12:31:44 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.014, trans_loss=3.463, nll_loss=1.663, w2v_ctc_loss=1.134, task_loss=0.609, task_loss_gen=1.663, contrastive_loss=0, total=4101.48, n_correct=2462.67, ppl=3.17, accuracy=60.043, wps=14511.6, ups=1.19, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.399, clip=0, loss_scale=4, train_wall=84, gb_free=15.6, wall=10868
2023-09-03 12:33:08 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.001, trans_loss=3.457, nll_loss=1.652, w2v_ctc_loss=1.124, task_loss=0.514, task_loss_gen=1.414, contrastive_loss=0, total=4179.09, n_correct=2528.03, ppl=3.14, accuracy=60.492, wps=14789.5, ups=1.19, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.37, clip=0, loss_scale=8, train_wall=84, gb_free=14.8, wall=10953
2023-09-03 12:34:34 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.008, trans_loss=3.451, nll_loss=1.649, w2v_ctc_loss=1.136, task_loss=0.45, task_loss_gen=1.723, contrastive_loss=0, total=4140.66, n_correct=2499.74, ppl=3.14, accuracy=60.371, wps=14472.1, ups=1.17, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.373, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=11038
2023-09-03 12:35:58 | INFO | train_inner | epoch 009:   1316 / 1474 loss=1.983, trans_loss=3.441, nll_loss=1.635, w2v_ctc_loss=1.111, task_loss=0.336, task_loss_gen=1.64, contrastive_loss=0, total=4204.43, n_correct=2556, ppl=3.11, accuracy=60.793, wps=14843.9, ups=1.18, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.365, clip=0, loss_scale=8, train_wall=84, gb_free=17.4, wall=11123
2023-09-03 12:37:22 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.005, trans_loss=3.454, nll_loss=1.652, w2v_ctc_loss=1.13, task_loss=0.417, task_loss_gen=1.966, contrastive_loss=0, total=4069.19, n_correct=2462.37, ppl=3.14, accuracy=60.513, wps=14427.8, ups=1.19, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.377, clip=0, loss_scale=8, train_wall=83, gb_free=16.2, wall=11207
2023-09-03 12:38:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 12:38:44 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.002 | trans_loss 5.322 | nll_loss 2.637 | w2v_ctc_loss 1.346 | task_loss 4.406 | task_loss_gen 5.831 | contrastive_loss 0 | total 4003.4 | n_correct 2551.8 | ppl 6.22 | accuracy 63.741 | uer 19.287 | wer 20.879 | raw_wer 20.879 | bleu 19.56 | wps 1572.3 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19.56
2023-09-03 12:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-09-03 12:38:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 12:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 12:38:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 19.56) (writing took 14.221549382025842 seconds)
2023-09-03 12:38:59 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-03 12:38:59 | INFO | train | epoch 009 | loss 2.006 | trans_loss 3.456 | nll_loss 1.654 | w2v_ctc_loss 1.129 | task_loss 0.494 | task_loss_gen 1.586 | contrastive_loss 0 | total 4138.65 | n_correct 2491.91 | ppl 3.15 | accuracy 60.211 | wps 13485.6 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.383 | clip 0 | loss_scale 8 | train_wall 1237 | gb_free 11.1 | wall 11303
2023-09-03 12:38:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 12:38:59 | INFO | fairseq.trainer | begin training epoch 10
2023-09-03 12:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 12:39:42 | INFO | train_inner | epoch 010:     42 / 1474 loss=1.974, trans_loss=3.436, nll_loss=1.628, w2v_ctc_loss=1.101, task_loss=0.417, task_loss_gen=1.764, contrastive_loss=0, total=4100.8, n_correct=2505.2, ppl=3.09, accuracy=61.091, wps=8775.5, ups=0.72, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.378, clip=0, loss_scale=8, train_wall=83, gb_free=15.9, wall=11346
2023-09-03 12:41:07 | INFO | train_inner | epoch 010:    142 / 1474 loss=1.948, trans_loss=3.417, nll_loss=1.606, w2v_ctc_loss=1.072, task_loss=0.397, task_loss_gen=1.735, contrastive_loss=0, total=4247.35, n_correct=2617, ppl=3.04, accuracy=61.615, wps=14925.7, ups=1.18, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.37, clip=0, loss_scale=8, train_wall=84, gb_free=11.2, wall=11431
2023-09-03 12:42:31 | INFO | train_inner | epoch 010:    242 / 1474 loss=1.956, trans_loss=3.415, nll_loss=1.601, w2v_ctc_loss=1.084, task_loss=0.443, task_loss_gen=1.762, contrastive_loss=0, total=4122.82, n_correct=2538.48, ppl=3.03, accuracy=61.571, wps=14642.4, ups=1.19, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.375, clip=0, loss_scale=8, train_wall=83, gb_free=16, wall=11515
2023-09-03 12:43:56 | INFO | train_inner | epoch 010:    342 / 1474 loss=1.951, trans_loss=3.414, nll_loss=1.604, w2v_ctc_loss=1.077, task_loss=0.408, task_loss_gen=1.84, contrastive_loss=0, total=4138.27, n_correct=2545.97, ppl=3.04, accuracy=61.523, wps=14540.3, ups=1.18, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.371, clip=0, loss_scale=8, train_wall=84, gb_free=16, wall=11600
2023-09-03 12:45:22 | INFO | train_inner | epoch 010:    442 / 1474 loss=1.94, trans_loss=3.418, nll_loss=1.606, w2v_ctc_loss=1.061, task_loss=0.449, task_loss_gen=1.732, contrastive_loss=0, total=4196.37, n_correct=2585.71, ppl=3.04, accuracy=61.618, wps=14655.2, ups=1.17, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.372, clip=0, loss_scale=8, train_wall=85, gb_free=15.7, wall=11686
2023-09-03 12:46:47 | INFO | train_inner | epoch 010:    542 / 1474 loss=1.97, trans_loss=3.428, nll_loss=1.615, w2v_ctc_loss=1.098, task_loss=0.511, task_loss_gen=1.862, contrastive_loss=0, total=4102.8, n_correct=2516.59, ppl=3.06, accuracy=61.338, wps=14304.9, ups=1.17, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.381, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=11771
2023-09-03 12:48:12 | INFO | train_inner | epoch 010:    642 / 1474 loss=1.959, trans_loss=3.424, nll_loss=1.613, w2v_ctc_loss=1.086, task_loss=0.439, task_loss_gen=1.625, contrastive_loss=0, total=4176.56, n_correct=2568.13, ppl=3.06, accuracy=61.489, wps=14619.7, ups=1.17, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.376, clip=0, loss_scale=8, train_wall=85, gb_free=15.8, wall=11857
2023-09-03 12:49:36 | INFO | train_inner | epoch 010:    742 / 1474 loss=1.97, trans_loss=3.42, nll_loss=1.608, w2v_ctc_loss=1.103, task_loss=0.398, task_loss_gen=1.808, contrastive_loss=0, total=4125.87, n_correct=2538.09, ppl=3.05, accuracy=61.516, wps=14637.1, ups=1.19, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.374, clip=0, loss_scale=8, train_wall=84, gb_free=14, wall=11941
2023-09-03 12:49:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 12:50:10 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.003 | trans_loss 5.304 | nll_loss 2.615 | w2v_ctc_loss 1.39 | task_loss 2.295 | task_loss_gen 7.061 | contrastive_loss 0 | total 4003.4 | n_correct 2562.7 | ppl 6.13 | accuracy 64.013 | uer 19.829 | wer 21.539 | raw_wer 21.539 | bleu 19.61 | wps 1545.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.61
2023-09-03 12:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-09-03 12:50:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-03 12:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-03 12:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.61) (writing took 14.160575263027567 seconds)
2023-09-03 12:51:49 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.946, trans_loss=3.415, nll_loss=1.603, w2v_ctc_loss=1.072, task_loss=0.403, task_loss_gen=1.845, contrastive_loss=0, total=4128.44, n_correct=2548.47, ppl=3.04, accuracy=61.73, wps=9268.3, ups=0.75, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.367, clip=0, loss_scale=8, train_wall=84, gb_free=14.4, wall=12074
2023-09-03 12:53:13 | INFO | train_inner | epoch 010:    942 / 1474 loss=1.953, trans_loss=3.415, nll_loss=1.6, w2v_ctc_loss=1.083, task_loss=0.401, task_loss_gen=1.753, contrastive_loss=0, total=4160.94, n_correct=2570.41, ppl=3.03, accuracy=61.775, wps=14849.7, ups=1.2, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.371, clip=0, loss_scale=8, train_wall=83, gb_free=15.1, wall=12157
2023-09-03 12:54:38 | INFO | train_inner | epoch 010:   1042 / 1474 loss=1.958, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.086, task_loss=0.491, task_loss_gen=1.916, contrastive_loss=0, total=4067.53, n_correct=2503.01, ppl=3.04, accuracy=61.536, wps=14334.6, ups=1.18, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.382, clip=0, loss_scale=8, train_wall=84, gb_free=16.5, wall=12242
2023-09-03 12:56:02 | INFO | train_inner | epoch 010:   1142 / 1474 loss=1.967, trans_loss=3.423, nll_loss=1.612, w2v_ctc_loss=1.096, task_loss=0.65, task_loss_gen=1.828, contrastive_loss=0, total=4044.03, n_correct=2483.37, ppl=3.06, accuracy=61.408, wps=14295.7, ups=1.18, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.388, clip=0, loss_scale=8, train_wall=84, gb_free=17, wall=12327
2023-09-03 12:57:27 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.956, trans_loss=3.407, nll_loss=1.597, w2v_ctc_loss=1.09, task_loss=0.502, task_loss_gen=1.677, contrastive_loss=0, total=4110.41, n_correct=2538.85, ppl=3.03, accuracy=61.766, wps=14550.3, ups=1.18, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.372, clip=0, loss_scale=8, train_wall=84, gb_free=16.2, wall=12411
2023-09-03 12:58:51 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.952, trans_loss=3.412, nll_loss=1.6, w2v_ctc_loss=1.085, task_loss=0.412, task_loss_gen=1.785, contrastive_loss=0, total=4121.38, n_correct=2549.94, ppl=3.03, accuracy=61.871, wps=14558.8, ups=1.18, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.369, clip=0, loss_scale=8, train_wall=84, gb_free=13.6, wall=12496
2023-09-03 13:00:17 | INFO | train_inner | epoch 010:   1442 / 1474 loss=1.943, trans_loss=3.421, nll_loss=1.609, w2v_ctc_loss=1.066, task_loss=0.4, task_loss_gen=1.71, contrastive_loss=0, total=4192.39, n_correct=2585.62, ppl=3.05, accuracy=61.674, wps=14605.3, ups=1.17, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.368, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=12581
2023-09-03 13:00:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 13:01:18 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.988 | trans_loss 5.285 | nll_loss 2.586 | w2v_ctc_loss 1.383 | task_loss 3.877 | task_loss_gen 7.28 | contrastive_loss 0 | total 4003.4 | n_correct 2588.6 | ppl 6 | accuracy 64.66 | uer 19.138 | wer 20.834 | raw_wer 20.834 | bleu 20.22 | wps 1517.9 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 20.22
2023-09-03 13:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-09-03 13:01:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14732 updates, score 20.22) (writing took 12.00228433299344 seconds)
2023-09-03 13:01:31 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-03 13:01:31 | INFO | train | epoch 010 | loss 1.954 | trans_loss 3.417 | nll_loss 1.606 | w2v_ctc_loss 1.081 | task_loss 0.447 | task_loss_gen 1.771 | contrastive_loss 0 | total 4138.65 | n_correct 2549.85 | ppl 3.04 | accuracy 61.611 | wps 13472.3 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.374 | clip 0 | loss_scale 8 | train_wall 1238 | gb_free 17 | wall 12655
2023-09-03 13:01:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 13:01:31 | INFO | fairseq.trainer | begin training epoch 11
2023-09-03 13:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 13:02:35 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.92, trans_loss=3.392, nll_loss=1.573, w2v_ctc_loss=1.048, task_loss=0.477, task_loss_gen=1.52, contrastive_loss=0, total=4175.24, n_correct=2609.44, ppl=2.98, accuracy=62.498, wps=9035.5, ups=0.72, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.366, clip=0, loss_scale=8, train_wall=82, gb_free=16.4, wall=12719
2023-09-03 13:04:00 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.923, trans_loss=3.392, nll_loss=1.575, w2v_ctc_loss=1.052, task_loss=0.513, task_loss_gen=1.674, contrastive_loss=0, total=4087.78, n_correct=2553.68, ppl=2.98, accuracy=62.471, wps=14367.9, ups=1.18, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.374, clip=0, loss_scale=16, train_wall=84, gb_free=16, wall=12804
2023-09-03 13:05:24 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.914, trans_loss=3.389, nll_loss=1.57, w2v_ctc_loss=1.043, task_loss=0.431, task_loss_gen=1.831, contrastive_loss=0, total=4118.77, n_correct=2578.46, ppl=2.97, accuracy=62.603, wps=14596.5, ups=1.19, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.365, clip=0, loss_scale=16, train_wall=83, gb_free=11.9, wall=12888
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 13:06:25 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.057, trans_loss=5.031, nll_loss=2.33, w2v_ctc_loss=0.783, task_loss=0.535, task_loss_gen=3.016, contrastive_loss=0, total=4097.83, n_correct=2563.48, ppl=5.03, accuracy=62.557, wps=13504.7, ups=1.64, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.497, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=12949
2023-09-03 13:07:27 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.063, trans_loss=5.067, nll_loss=2.354, w2v_ctc_loss=0.776, task_loss=0.591, task_loss_gen=3.144, contrastive_loss=0, total=4110.64, n_correct=2564.19, ppl=5.11, accuracy=62.379, wps=13230.4, ups=1.61, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.504, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=13012
2023-09-03 13:08:29 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.066, trans_loss=5.066, nll_loss=2.352, w2v_ctc_loss=0.788, task_loss=0.552, task_loss_gen=3.338, contrastive_loss=0, total=4071.69, n_correct=2539.7, ppl=5.11, accuracy=62.375, wps=13186.9, ups=1.62, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.519, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=13073
2023-09-03 13:09:31 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.061, trans_loss=5.058, nll_loss=2.342, w2v_ctc_loss=0.784, task_loss=0.449, task_loss_gen=3.312, contrastive_loss=0, total=4157.2, n_correct=2598.31, ppl=5.07, accuracy=62.501, wps=13389.2, ups=1.61, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.499, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=13135
2023-09-03 13:10:33 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.069, trans_loss=5.07, nll_loss=2.357, w2v_ctc_loss=0.797, task_loss=0.546, task_loss_gen=3.168, contrastive_loss=0, total=4174.91, n_correct=2605.74, ppl=5.12, accuracy=62.414, wps=13538.7, ups=1.62, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=13197
2023-09-03 13:11:34 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.067, trans_loss=5.067, nll_loss=2.354, w2v_ctc_loss=0.792, task_loss=0.595, task_loss_gen=3.193, contrastive_loss=0, total=4118.44, n_correct=2568.79, ppl=5.11, accuracy=62.373, wps=13471.7, ups=1.64, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.516, clip=0, loss_scale=16, train_wall=60, gb_free=10.3, wall=13258
2023-09-03 13:12:35 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.064, trans_loss=5.064, nll_loss=2.35, w2v_ctc_loss=0.795, task_loss=0.516, task_loss_gen=3.246, contrastive_loss=0, total=4140.92, n_correct=2587.98, ppl=5.1, accuracy=62.498, wps=13483.6, ups=1.63, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.504, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=13320
2023-09-03 13:13:36 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.059, trans_loss=5.058, nll_loss=2.342, w2v_ctc_loss=0.791, task_loss=0.539, task_loss_gen=3.116, contrastive_loss=0, total=4136.99, n_correct=2594.5, ppl=5.07, accuracy=62.715, wps=13609.9, ups=1.64, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.497, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=13380
2023-09-03 13:14:38 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.062, trans_loss=5.064, nll_loss=2.35, w2v_ctc_loss=0.793, task_loss=0.488, task_loss_gen=3.262, contrastive_loss=0, total=4185.65, n_correct=2618.34, ppl=5.1, accuracy=62.555, wps=13549.1, ups=1.62, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=13.6, wall=13442
2023-09-03 13:15:40 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.061, trans_loss=5.057, nll_loss=2.342, w2v_ctc_loss=0.795, task_loss=0.527, task_loss_gen=3.25, contrastive_loss=0, total=4171.89, n_correct=2609.84, ppl=5.07, accuracy=62.558, wps=13429.7, ups=1.61, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=13504
2023-09-03 13:15:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
2023-09-03 13:16:13 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.978 | trans_loss 5.272 | nll_loss 2.57 | w2v_ctc_loss 1.379 | task_loss 1.537 | task_loss_gen 8.211 | contrastive_loss 0 | total 4003.4 | n_correct 2585.8 | ppl 5.94 | accuracy 64.59 | uer 18.984 | wer 20.633 | raw_wer 20.633 | bleu 20.4 | wps 1634.3 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 20.4
2023-09-03 13:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-09-03 13:16:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-03 13:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-03 13:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.4) (writing took 15.38357177801663 seconds)
2023-09-03 13:17:31 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.052, trans_loss=5.054, nll_loss=2.339, w2v_ctc_loss=0.778, task_loss=0.451, task_loss_gen=3.09, contrastive_loss=0, total=4190.34, n_correct=2626.35, ppl=5.06, accuracy=62.676, wps=7566.6, ups=0.9, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=13615
2023-09-03 13:18:32 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.055, trans_loss=5.057, nll_loss=2.342, w2v_ctc_loss=0.783, task_loss=0.38, task_loss_gen=3.496, contrastive_loss=0, total=4158.39, n_correct=2607.46, ppl=5.07, accuracy=62.704, wps=13521.6, ups=1.63, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=13677
2023-09-03 13:18:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 13:19:10 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.251 | nll_loss 2.541 | w2v_ctc_loss 1.346 | task_loss 1.986 | task_loss_gen 8.077 | contrastive_loss 0 | total 4003.4 | n_correct 2600.2 | ppl 5.82 | accuracy 64.95 | uer 18.746 | wer 20.581 | raw_wer 20.581 | bleu 20.58 | wps 1545.1 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 20.58
2023-09-03 13:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-09-03 13:19:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16206 updates, score 20.58) (writing took 13.557314538978972 seconds)
2023-09-03 13:19:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-03 13:19:24 | INFO | train | epoch 011 | loss 2.026 | trans_loss 4.644 | nll_loss 2.154 | w2v_ctc_loss 0.852 | task_loss 0.502 | task_loss_gen 2.838 | contrastive_loss 0 | total 4138.65 | n_correct 2588.03 | ppl 4.45 | accuracy 62.533 | wps 12389.2 | ups 1.37 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.481 | clip 0 | loss_scale 16 | train_wall 957 | gb_free 16.9 | wall 13728
2023-09-03 13:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 13:19:24 | INFO | fairseq.trainer | begin training epoch 12
2023-09-03 13:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 13:20:29 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.035, trans_loss=5.021, nll_loss=2.294, w2v_ctc_loss=0.767, task_loss=0.433, task_loss_gen=3.324, contrastive_loss=0, total=4146.82, n_correct=2630.65, ppl=4.9, accuracy=63.438, wps=7127.1, ups=0.86, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.504, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=13793
2023-09-03 13:21:31 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.043, trans_loss=5.024, nll_loss=2.298, w2v_ctc_loss=0.777, task_loss=0.501, task_loss_gen=3.578, contrastive_loss=0, total=4120.68, n_correct=2602.59, ppl=4.92, accuracy=63.159, wps=13348.8, ups=1.62, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.51, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=13855
2023-09-03 13:22:32 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.036, trans_loss=5.027, nll_loss=2.302, w2v_ctc_loss=0.764, task_loss=0.432, task_loss_gen=3.201, contrastive_loss=0, total=4199.46, n_correct=2658.05, ppl=4.93, accuracy=63.295, wps=13629.5, ups=1.62, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.494, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=13916
2023-09-03 13:23:34 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.039, trans_loss=5.025, nll_loss=2.299, w2v_ctc_loss=0.773, task_loss=0.481, task_loss_gen=3.199, contrastive_loss=0, total=4151.14, n_correct=2626.04, ppl=4.92, accuracy=63.261, wps=13499.2, ups=1.63, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=13978
2023-09-03 13:24:35 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.049, trans_loss=5.041, nll_loss=2.32, w2v_ctc_loss=0.783, task_loss=0.536, task_loss_gen=3.196, contrastive_loss=0, total=4110.49, n_correct=2592.94, ppl=4.99, accuracy=63.081, wps=13450.8, ups=1.64, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.502, clip=0, loss_scale=16, train_wall=60, gb_free=13.4, wall=14039
2023-09-03 13:25:37 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.041, trans_loss=5.028, nll_loss=2.304, w2v_ctc_loss=0.776, task_loss=0.537, task_loss_gen=2.948, contrastive_loss=0, total=4189.92, n_correct=2647.8, ppl=4.94, accuracy=63.195, wps=13544, ups=1.62, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=14.5, wall=14101
2023-09-03 13:26:38 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.028, trans_loss=5.024, nll_loss=2.3, w2v_ctc_loss=0.753, task_loss=0.467, task_loss_gen=3.007, contrastive_loss=0, total=4206.3, n_correct=2668.05, ppl=4.92, accuracy=63.43, wps=13722.7, ups=1.63, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.494, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=14162
2023-09-03 13:27:40 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.04, trans_loss=5.021, nll_loss=2.295, w2v_ctc_loss=0.777, task_loss=0.517, task_loss_gen=3.393, contrastive_loss=0, total=4085.96, n_correct=2588.61, ppl=4.91, accuracy=63.354, wps=13244.5, ups=1.62, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.512, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=14224
2023-09-03 13:28:41 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.041, trans_loss=5.025, nll_loss=2.3, w2v_ctc_loss=0.775, task_loss=0.462, task_loss_gen=3.568, contrastive_loss=0, total=4169.74, n_correct=2638.34, ppl=4.92, accuracy=63.273, wps=13539.7, ups=1.62, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.498, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=14286
2023-09-03 13:29:43 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.043, trans_loss=5.029, nll_loss=2.306, w2v_ctc_loss=0.776, task_loss=0.458, task_loss_gen=3.709, contrastive_loss=0, total=4117.67, n_correct=2603.74, ppl=4.94, accuracy=63.233, wps=13439.4, ups=1.63, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=14347
2023-09-03 13:30:44 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.047, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.782, task_loss=0.545, task_loss_gen=3.627, contrastive_loss=0, total=4047.61, n_correct=2558.57, ppl=4.95, accuracy=63.212, wps=13158.5, ups=1.63, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.512, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=14408
2023-09-03 13:31:46 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.052, trans_loss=5.048, nll_loss=2.33, w2v_ctc_loss=0.787, task_loss=0.406, task_loss_gen=3.629, contrastive_loss=0, total=4184.55, n_correct=2632.49, ppl=5.03, accuracy=62.91, wps=13479.6, ups=1.61, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.493, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=14470
2023-09-03 13:32:48 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.051, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.794, task_loss=0.481, task_loss_gen=4.178, contrastive_loss=0, total=4086.33, n_correct=2578.69, ppl=4.95, accuracy=63.105, wps=13226.9, ups=1.62, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=14532
2023-09-03 13:33:50 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.038, trans_loss=5.033, nll_loss=2.311, w2v_ctc_loss=0.765, task_loss=0.359, task_loss_gen=4.281, contrastive_loss=0, total=4134.89, n_correct=2615.9, ppl=4.96, accuracy=63.264, wps=13409.7, ups=1.62, wpb=8269.8, bsz=304.4, num_updates=17600, lr=0.0001066, gnorm=0.498, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=14594
2023-09-03 13:34:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 13:35:12 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.233 | nll_loss 2.521 | w2v_ctc_loss 1.38 | task_loss 1.005 | task_loss_gen 10.213 | contrastive_loss 0 | total 4003.4 | n_correct 2612.6 | ppl 5.74 | accuracy 65.26 | uer 18.894 | wer 20.566 | raw_wer 20.566 | bleu 20.76 | wps 1583.6 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 20.76
2023-09-03 13:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-09-03 13:35:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:35:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17680 updates, score 20.76) (writing took 14.097149234032258 seconds)
2023-09-03 13:35:26 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-03 13:35:26 | INFO | train | epoch 012 | loss 2.042 | trans_loss 5.029 | nll_loss 2.306 | w2v_ctc_loss 0.775 | task_loss 0.466 | task_loss_gen 3.517 | contrastive_loss 0 | total 4138.65 | n_correct 2616.86 | ppl 4.94 | accuracy 63.23 | wps 12674.6 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 17680 | lr 0.000106359 | gnorm 0.503 | clip 0 | loss_scale 32 | train_wall 896 | gb_free 12.3 | wall 14691
2023-09-03 13:35:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 13:35:27 | INFO | fairseq.trainer | begin training epoch 13
2023-09-03 13:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 13:35:46 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.045, trans_loss=5.033, nll_loss=2.31, w2v_ctc_loss=0.782, task_loss=0.335, task_loss_gen=4.226, contrastive_loss=0, total=4104.86, n_correct=2593.89, ppl=4.96, accuracy=63.191, wps=7043.9, ups=0.86, wpb=8209.7, bsz=296.8, num_updates=17700, lr=0.000106299, gnorm=0.506, clip=0, loss_scale=32, train_wall=61, gb_free=14.3, wall=14710
2023-09-03 13:36:48 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.023, trans_loss=4.999, nll_loss=2.266, w2v_ctc_loss=0.758, task_loss=0.47, task_loss_gen=3.956, contrastive_loss=0, total=4161.2, n_correct=2658.85, ppl=4.81, accuracy=63.896, wps=13524.7, ups=1.63, wpb=8322.4, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.495, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=14772
2023-09-03 13:37:50 | INFO | train_inner | epoch 013:    220 / 1474 loss=2.021, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.753, task_loss=0.416, task_loss_gen=3.578, contrastive_loss=0, total=4202.62, n_correct=2680.4, ppl=4.85, accuracy=63.779, wps=13542.7, ups=1.61, wpb=8405.2, bsz=328.3, num_updates=17900, lr=0.000105703, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=14834
2023-09-03 13:38:52 | INFO | train_inner | epoch 013:    320 / 1474 loss=2.018, trans_loss=4.99, nll_loss=2.255, w2v_ctc_loss=0.75, task_loss=0.402, task_loss_gen=4.333, contrastive_loss=0, total=4112.8, n_correct=2638.36, ppl=4.77, accuracy=64.15, wps=13270.1, ups=1.61, wpb=8225.6, bsz=296, num_updates=18000, lr=0.000105409, gnorm=0.503, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=14896
2023-09-03 13:38:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 13:39:25 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.238 | nll_loss 2.525 | w2v_ctc_loss 1.357 | task_loss 2.301 | task_loss_gen 7.884 | contrastive_loss 0 | total 4003.4 | n_correct 2612.2 | ppl 5.76 | accuracy 65.25 | uer 18.884 | wer 20.514 | raw_wer 20.514 | bleu 20.49 | wps 1627.6 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 20.76
2023-09-03 13:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-09-03 13:39:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-03 13:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-03 13:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 20.49) (writing took 8.474193727015518 seconds)
2023-09-03 13:40:35 | INFO | train_inner | epoch 013:    420 / 1474 loss=2.02, trans_loss=4.997, nll_loss=2.264, w2v_ctc_loss=0.762, task_loss=0.392, task_loss_gen=3.948, contrastive_loss=0, total=4176.06, n_correct=2671.35, ppl=4.8, accuracy=63.968, wps=8100.6, ups=0.97, wpb=8352.1, bsz=317.5, num_updates=18100, lr=0.000105118, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=14999
2023-09-03 13:41:37 | INFO | train_inner | epoch 013:    520 / 1474 loss=2.026, trans_loss=5.007, nll_loss=2.277, w2v_ctc_loss=0.763, task_loss=0.348, task_loss_gen=4.265, contrastive_loss=0, total=4197.57, n_correct=2673.52, ppl=4.85, accuracy=63.692, wps=13560.2, ups=1.62, wpb=8395.1, bsz=318.1, num_updates=18200, lr=0.000104828, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=15, wall=15061
2023-09-03 13:42:38 | INFO | train_inner | epoch 013:    620 / 1474 loss=2.018, trans_loss=4.996, nll_loss=2.264, w2v_ctc_loss=0.757, task_loss=0.373, task_loss_gen=4.028, contrastive_loss=0, total=4160.12, n_correct=2663.55, ppl=4.8, accuracy=64.026, wps=13565.9, ups=1.63, wpb=8320.2, bsz=308.7, num_updates=18300, lr=0.000104542, gnorm=0.489, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=15122
2023-09-03 13:43:41 | INFO | train_inner | epoch 013:    720 / 1474 loss=2.037, trans_loss=5.007, nll_loss=2.276, w2v_ctc_loss=0.78, task_loss=0.478, task_loss_gen=4.485, contrastive_loss=0, total=4101.54, n_correct=2609.44, ppl=4.84, accuracy=63.621, wps=13066.1, ups=1.59, wpb=8203.1, bsz=285.7, num_updates=18400, lr=0.000104257, gnorm=0.506, clip=0, loss_scale=32, train_wall=62, gb_free=15.4, wall=15185
2023-09-03 13:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 13:44:47 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.028, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.762, task_loss=0.458, task_loss_gen=4.222, contrastive_loss=0, total=4115.39, n_correct=2617.82, ppl=4.85, accuracy=63.61, wps=12474.5, ups=1.52, wpb=8230.8, bsz=303.5, num_updates=18500, lr=0.000103975, gnorm=0.532, clip=0, loss_scale=16, train_wall=65, gb_free=14.5, wall=15251
2023-09-03 13:45:50 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.028, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.765, task_loss=0.521, task_loss_gen=3.618, contrastive_loss=0, total=4107.01, n_correct=2621.23, ppl=4.84, accuracy=63.823, wps=13039.8, ups=1.59, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.496, clip=0, loss_scale=16, train_wall=62, gb_free=15.6, wall=15314
2023-09-03 13:46:51 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.031, trans_loss=5.01, nll_loss=2.28, w2v_ctc_loss=0.767, task_loss=0.559, task_loss_gen=3.511, contrastive_loss=0, total=4081.02, n_correct=2596.19, ppl=4.86, accuracy=63.616, wps=13280.8, ups=1.63, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.511, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=15376
2023-09-03 13:47:53 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.019, trans_loss=4.997, nll_loss=2.265, w2v_ctc_loss=0.757, task_loss=0.553, task_loss_gen=3.257, contrastive_loss=0, total=4105.62, n_correct=2625.81, ppl=4.81, accuracy=63.956, wps=13434.3, ups=1.64, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.503, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=15437
2023-09-03 13:48:54 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.03, trans_loss=5.008, nll_loss=2.279, w2v_ctc_loss=0.768, task_loss=0.585, task_loss_gen=3.419, contrastive_loss=0, total=4110.35, n_correct=2618.88, ppl=4.85, accuracy=63.714, wps=13360.9, ups=1.63, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.517, clip=0, loss_scale=16, train_wall=61, gb_free=14.5, wall=15498
2023-09-03 13:49:56 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.019, trans_loss=4.995, nll_loss=2.262, w2v_ctc_loss=0.757, task_loss=0.515, task_loss_gen=3.227, contrastive_loss=0, total=4112.2, n_correct=2634.97, ppl=4.8, accuracy=64.077, wps=13389.2, ups=1.63, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=15560
2023-09-03 13:50:59 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.023, trans_loss=5.006, nll_loss=2.277, w2v_ctc_loss=0.756, task_loss=0.531, task_loss_gen=3.114, contrastive_loss=0, total=4180.88, n_correct=2668.01, ppl=4.85, accuracy=63.815, wps=13109.5, ups=1.57, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.501, clip=0, loss_scale=16, train_wall=63, gb_free=14.9, wall=15624
2023-09-03 13:51:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 13:52:09 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.236 | nll_loss 2.523 | w2v_ctc_loss 1.387 | task_loss 7.769 | task_loss_gen 6.598 | contrastive_loss 0 | total 4003.4 | n_correct 2611 | ppl 5.75 | accuracy 65.22 | uer 19.444 | wer 21.174 | raw_wer 21.174 | bleu 21.04 | wps 1502.2 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 21.04
2023-09-03 13:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-09-03 13:52:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:52:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 13:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 13 @ 19153 updates, score 21.04) (writing took 13.279766228981316 seconds)
2023-09-03 13:52:23 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-03 13:52:23 | INFO | train | epoch 013 | loss 2.024 | trans_loss 5.002 | nll_loss 2.271 | w2v_ctc_loss 0.761 | task_loss 0.471 | task_loss_gen 3.751 | contrastive_loss 0 | total 4138.47 | n_correct 2642.25 | ppl 4.83 | accuracy 63.846 | wps 11996.2 | ups 1.45 | wpb 8276.9 | bsz 305.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.506 | clip 0 | loss_scale 16 | train_wall 906 | gb_free 17.4 | wall 15707
2023-09-03 13:52:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 13:52:23 | INFO | fairseq.trainer | begin training epoch 14
2023-09-03 13:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 13:53:01 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.005, trans_loss=4.973, nll_loss=2.234, w2v_ctc_loss=0.749, task_loss=0.56, task_loss_gen=2.784, contrastive_loss=0, total=4176.2, n_correct=2692.83, ppl=4.71, accuracy=64.48, wps=6846.8, ups=0.82, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.512, clip=0, loss_scale=16, train_wall=65, gb_free=10.2, wall=15746
2023-09-03 13:54:06 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.006, trans_loss=4.968, nll_loss=2.226, w2v_ctc_loss=0.75, task_loss=0.675, task_loss_gen=3.017, contrastive_loss=0, total=4080.86, n_correct=2637.45, ppl=4.68, accuracy=64.63, wps=12682.5, ups=1.55, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.502, clip=0, loss_scale=16, train_wall=64, gb_free=16.7, wall=15810
2023-09-03 13:55:08 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.013, trans_loss=4.982, nll_loss=2.244, w2v_ctc_loss=0.75, task_loss=0.665, task_loss_gen=3.061, contrastive_loss=0, total=4106.97, n_correct=2640.04, ppl=4.74, accuracy=64.282, wps=13069.4, ups=1.59, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.499, clip=0, loss_scale=16, train_wall=62, gb_free=11.9, wall=15873
2023-09-03 13:56:10 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.004, trans_loss=4.977, nll_loss=2.239, w2v_ctc_loss=0.744, task_loss=0.556, task_loss_gen=2.805, contrastive_loss=0, total=4179.8, n_correct=2695.72, ppl=4.72, accuracy=64.494, wps=13637.4, ups=1.63, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=15934
2023-09-03 13:57:11 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.01, trans_loss=4.983, nll_loss=2.246, w2v_ctc_loss=0.745, task_loss=0.642, task_loss_gen=3.093, contrastive_loss=0, total=4120.38, n_correct=2651.58, ppl=4.74, accuracy=64.353, wps=13414.1, ups=1.63, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.499, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=15996
2023-09-03 13:58:13 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.022, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.769, task_loss=0.613, task_loss_gen=3.276, contrastive_loss=0, total=4089.86, n_correct=2622.59, ppl=4.76, accuracy=64.124, wps=13167.2, ups=1.61, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.513, clip=0, loss_scale=16, train_wall=61, gb_free=11.6, wall=16058
2023-09-03 13:59:15 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.011, trans_loss=4.982, nll_loss=2.245, w2v_ctc_loss=0.75, task_loss=0.656, task_loss_gen=3.073, contrastive_loss=0, total=4158.94, n_correct=2671.92, ppl=4.74, accuracy=64.245, wps=13532.6, ups=1.63, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=16119
2023-09-03 14:00:16 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.002, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.743, task_loss=0.607, task_loss_gen=2.968, contrastive_loss=0, total=4150.03, n_correct=2682.28, ppl=4.69, accuracy=64.633, wps=13571.9, ups=1.64, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.489, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=16180
2023-09-03 14:01:17 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.003, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.743, task_loss=0.653, task_loss_gen=2.809, contrastive_loss=0, total=4162.8, n_correct=2688.45, ppl=4.69, accuracy=64.583, wps=13538.1, ups=1.63, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.5, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=16242
2023-09-03 14:01:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 14:01:51 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.214 | nll_loss 2.493 | w2v_ctc_loss 1.371 | task_loss 2.614 | task_loss_gen 7.45 | contrastive_loss 0 | total 4003.4 | n_correct 2627.7 | ppl 5.63 | accuracy 65.637 | uer 18.499 | wer 20.286 | raw_wer 20.286 | bleu 21.34 | wps 1616.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.34
2023-09-03 14:01:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-09-03 14:01:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-03 14:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-03 14:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.34) (writing took 16.13343869498931 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 14:03:09 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.01, trans_loss=4.979, nll_loss=2.241, w2v_ctc_loss=0.752, task_loss=0.62, task_loss_gen=3.025, contrastive_loss=0, total=4159.46, n_correct=2672.29, ppl=4.73, accuracy=64.246, wps=7444.1, ups=0.89, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=16354
2023-09-03 14:04:11 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.008, trans_loss=4.979, nll_loss=2.243, w2v_ctc_loss=0.743, task_loss=0.494, task_loss_gen=3.289, contrastive_loss=0, total=4155.93, n_correct=2677.86, ppl=4.73, accuracy=64.435, wps=13362.9, ups=1.61, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=16416
2023-09-03 14:05:13 | INFO | train_inner | epoch 014:   1147 / 1474 loss=2.011, trans_loss=4.981, nll_loss=2.245, w2v_ctc_loss=0.753, task_loss=0.502, task_loss_gen=3.154, contrastive_loss=0, total=4228.09, n_correct=2714.71, ppl=4.74, accuracy=64.207, wps=13688, ups=1.62, wpb=8456.2, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.491, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=16478
2023-09-03 14:06:14 | INFO | train_inner | epoch 014:   1247 / 1474 loss=2.023, trans_loss=4.987, nll_loss=2.252, w2v_ctc_loss=0.767, task_loss=0.591, task_loss_gen=3.777, contrastive_loss=0, total=4027.71, n_correct=2584.8, ppl=4.76, accuracy=64.175, wps=13187.2, ups=1.64, wpb=8055.4, bsz=273.6, num_updates=20400, lr=9.90148e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=16539
2023-09-03 14:07:16 | INFO | train_inner | epoch 014:   1347 / 1474 loss=2.006, trans_loss=4.981, nll_loss=2.244, w2v_ctc_loss=0.745, task_loss=0.466, task_loss_gen=3.351, contrastive_loss=0, total=4198.71, n_correct=2703.55, ppl=4.74, accuracy=64.39, wps=13680.4, ups=1.63, wpb=8397.4, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=0.497, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=16600
2023-09-03 14:08:17 | INFO | train_inner | epoch 014:   1447 / 1474 loss=2.011, trans_loss=4.985, nll_loss=2.25, w2v_ctc_loss=0.749, task_loss=0.499, task_loss_gen=3.645, contrastive_loss=0, total=4140.5, n_correct=2663.53, ppl=4.76, accuracy=64.329, wps=13429.5, ups=1.62, wpb=8281, bsz=307.1, num_updates=20600, lr=9.85329e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=16662
2023-09-03 14:08:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
2023-09-03 14:09:07 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.934 | trans_loss 5.211 | nll_loss 2.493 | w2v_ctc_loss 1.369 | task_loss 1.963 | task_loss_gen 8.269 | contrastive_loss 0 | total 4003.4 | n_correct 2631.9 | ppl 5.63 | accuracy 65.742 | uer 18.642 | wer 20.271 | raw_wer 20.271 | bleu 21.24 | wps 1649.8 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 21.34
2023-09-03 14:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-09-03 14:09:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.2403.pt
2023-09-03 14:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.2403.pt
2023-09-03 14:09:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.2403.pt (epoch 14 @ 20627 updates, score 21.24) (writing took 8.15660718100844 seconds)
2023-09-03 14:09:15 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-03 14:09:15 | INFO | train | epoch 014 | loss 2.01 | trans_loss 4.979 | nll_loss 2.242 | w2v_ctc_loss 0.75 | task_loss 0.587 | task_loss_gen 3.163 | contrastive_loss 0 | total 4138.65 | n_correct 2663.95 | ppl 4.73 | accuracy 64.368 | wps 12050.4 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.499 | clip 0 | loss_scale 32 | train_wall 902 | gb_free 16.1 | wall 16720
2023-09-03 14:09:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 14:09:15 | INFO | fairseq.trainer | begin training epoch 15
2023-09-03 14:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 14:10:08 | INFO | train_inner | epoch 015:     73 / 1474 loss=2.002, trans_loss=4.967, nll_loss=2.225, w2v_ctc_loss=0.741, task_loss=0.427, task_loss_gen=3.893, contrastive_loss=0, total=4083.93, n_correct=2640.84, ppl=4.68, accuracy=64.664, wps=7403.3, ups=0.91, wpb=8167.9, bsz=300.1, num_updates=20700, lr=9.82946e-05, gnorm=0.497, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=16772
2023-09-03 14:11:09 | INFO | train_inner | epoch 015:    173 / 1474 loss=2, trans_loss=4.958, nll_loss=2.213, w2v_ctc_loss=0.747, task_loss=0.348, task_loss_gen=4.203, contrastive_loss=0, total=4122.67, n_correct=2675.09, ppl=4.64, accuracy=64.887, wps=13464.3, ups=1.63, wpb=8245.3, bsz=299.1, num_updates=20800, lr=9.80581e-05, gnorm=0.498, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=16833
2023-09-03 14:12:10 | INFO | train_inner | epoch 015:    273 / 1474 loss=1.991, trans_loss=4.955, nll_loss=2.21, w2v_ctc_loss=0.732, task_loss=0.421, task_loss_gen=3.72, contrastive_loss=0, total=4190.11, n_correct=2724.73, ppl=4.63, accuracy=65.028, wps=13765.9, ups=1.64, wpb=8380.2, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.488, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=16894
2023-09-03 14:12:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 14:13:12 | INFO | train_inner | epoch 015:    374 / 1474 loss=1.993, trans_loss=4.95, nll_loss=2.204, w2v_ctc_loss=0.735, task_loss=0.443, task_loss_gen=3.868, contrastive_loss=0, total=4163.9, n_correct=2703.52, ppl=4.61, accuracy=64.928, wps=13412.8, ups=1.61, wpb=8327.8, bsz=305.2, num_updates=21000, lr=9.759e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=16956
2023-09-03 14:14:14 | INFO | train_inner | epoch 015:    474 / 1474 loss=1.995, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.727, task_loss=0.388, task_loss_gen=3.888, contrastive_loss=0, total=4074.53, n_correct=2636.63, ppl=4.64, accuracy=64.71, wps=13153.1, ups=1.61, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=17018
2023-09-03 14:15:15 | INFO | train_inner | epoch 015:    574 / 1474 loss=1.996, trans_loss=4.954, nll_loss=2.209, w2v_ctc_loss=0.741, task_loss=0.442, task_loss_gen=3.79, contrastive_loss=0, total=4140.59, n_correct=2689.6, ppl=4.62, accuracy=64.957, wps=13459.3, ups=1.63, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=11.7, wall=17080
2023-09-03 14:16:17 | INFO | train_inner | epoch 015:    674 / 1474 loss=2, trans_loss=4.958, nll_loss=2.214, w2v_ctc_loss=0.744, task_loss=0.505, task_loss_gen=3.461, contrastive_loss=0, total=4134.99, n_correct=2677.08, ppl=4.64, accuracy=64.742, wps=13495.5, ups=1.63, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=60, gb_free=10.1, wall=17141
2023-09-03 14:17:18 | INFO | train_inner | epoch 015:    774 / 1474 loss=2, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.743, task_loss=0.411, task_loss_gen=3.637, contrastive_loss=0, total=4173.66, n_correct=2702.71, ppl=4.66, accuracy=64.756, wps=13618.2, ups=1.63, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=17202
2023-09-03 14:18:19 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.005, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.748, task_loss=0.619, task_loss_gen=3.536, contrastive_loss=0, total=4059.35, n_correct=2620.43, ppl=4.67, accuracy=64.553, wps=13311.3, ups=1.64, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=17263
2023-09-03 14:19:20 | INFO | train_inner | epoch 015:    974 / 1474 loss=1.997, trans_loss=4.96, nll_loss=2.217, w2v_ctc_loss=0.735, task_loss=0.563, task_loss_gen=3.297, contrastive_loss=0, total=4122.87, n_correct=2672.48, ppl=4.65, accuracy=64.821, wps=13418.6, ups=1.63, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=17325
2023-09-03 14:20:22 | INFO | train_inner | epoch 015:   1074 / 1474 loss=1.998, trans_loss=4.968, nll_loss=2.227, w2v_ctc_loss=0.739, task_loss=0.501, task_loss_gen=3.109, contrastive_loss=0, total=4192.24, n_correct=2711.78, ppl=4.68, accuracy=64.686, wps=13549.6, ups=1.62, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=17387
2023-09-03 14:21:23 | INFO | train_inner | epoch 015:   1174 / 1474 loss=1.982, trans_loss=4.954, nll_loss=2.21, w2v_ctc_loss=0.72, task_loss=0.428, task_loss_gen=3.176, contrastive_loss=0, total=4185, n_correct=2726.16, ppl=4.63, accuracy=65.141, wps=13704.2, ups=1.64, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.495, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=17448
2023-09-03 14:22:25 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2, trans_loss=4.956, nll_loss=2.212, w2v_ctc_loss=0.747, task_loss=0.455, task_loss_gen=3.722, contrastive_loss=0, total=4152.04, n_correct=2688.65, ppl=4.63, accuracy=64.755, wps=13580, ups=1.64, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=17509
2023-09-03 14:23:26 | INFO | train_inner | epoch 015:   1374 / 1474 loss=1.994, trans_loss=4.955, nll_loss=2.21, w2v_ctc_loss=0.734, task_loss=0.516, task_loss_gen=3.674, contrastive_loss=0, total=4100.21, n_correct=2660.71, ppl=4.63, accuracy=64.892, wps=13344.4, ups=1.63, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=17570
2023-09-03 14:23:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 14:24:02 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.905 | trans_loss 5.2 | nll_loss 2.477 | w2v_ctc_loss 1.3 | task_loss 10.333 | task_loss_gen 7.102 | contrastive_loss 0 | total 4003.4 | n_correct 2637.5 | ppl 5.57 | accuracy 65.882 | uer 18.082 | wer 19.776 | raw_wer 19.776 | bleu 21.39 | wps 1477.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.39
2023-09-03 14:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-09-03 14:24:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-03 14:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-03 14:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.39) (writing took 14.453801624011248 seconds)
2023-09-03 14:25:19 | INFO | train_inner | epoch 015:   1474 / 1474 loss=1.997, trans_loss=4.965, nll_loss=2.225, w2v_ctc_loss=0.739, task_loss=0.605, task_loss_gen=3.093, contrastive_loss=0, total=4141.17, n_correct=2681.79, ppl=4.68, accuracy=64.759, wps=7347.2, ups=0.89, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=17683
2023-09-03 14:25:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 14:25:56 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.924 | trans_loss 5.198 | nll_loss 2.476 | w2v_ctc_loss 1.366 | task_loss 1.885 | task_loss_gen 8.264 | contrastive_loss 0 | total 4003.4 | n_correct 2636.8 | ppl 5.56 | accuracy 65.864 | uer 18.342 | wer 20.133 | raw_wer 20.133 | bleu 21.46 | wps 1444.4 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 21.46
2023-09-03 14:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-09-03 14:25:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 14:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 14:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 15 @ 22100 updates, score 21.46) (writing took 13.845376254001167 seconds)
2023-09-03 14:26:10 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-03 14:26:10 | INFO | train | epoch 015 | loss 1.996 | trans_loss 4.958 | nll_loss 2.215 | w2v_ctc_loss 0.737 | task_loss 0.47 | task_loss_gen 3.589 | contrastive_loss 0 | total 4138.64 | n_correct 2683.45 | ppl 4.64 | accuracy 64.839 | wps 12016.2 | ups 1.45 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.503 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 16.5 | wall 17734
2023-09-03 14:26:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 14:26:10 | INFO | fairseq.trainer | begin training epoch 16
2023-09-03 14:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 14:27:18 | INFO | train_inner | epoch 016:    100 / 1474 loss=1.98, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.724, task_loss=0.52, task_loss_gen=3.192, contrastive_loss=0, total=4126.22, n_correct=2694.68, ppl=4.56, accuracy=65.306, wps=6929.8, ups=0.84, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=17802
2023-09-03 14:28:19 | INFO | train_inner | epoch 016:    200 / 1474 loss=1.978, trans_loss=4.929, nll_loss=2.176, w2v_ctc_loss=0.717, task_loss=0.557, task_loss_gen=3.502, contrastive_loss=0, total=4100.6, n_correct=2685.38, ppl=4.52, accuracy=65.487, wps=13390.8, ups=1.63, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=60, gb_free=12.3, wall=17863
2023-09-03 14:29:20 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.987, trans_loss=4.941, nll_loss=2.192, w2v_ctc_loss=0.731, task_loss=0.542, task_loss_gen=3.316, contrastive_loss=0, total=4166.94, n_correct=2716.05, ppl=4.57, accuracy=65.181, wps=13582.9, ups=1.63, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=17925
2023-09-03 14:30:22 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.989, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.733, task_loss=0.462, task_loss_gen=3.729, contrastive_loss=0, total=4073.3, n_correct=2658.53, ppl=4.55, accuracy=65.267, wps=13333.9, ups=1.64, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=17986
2023-09-03 14:31:24 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.982, trans_loss=4.942, nll_loss=2.195, w2v_ctc_loss=0.724, task_loss=0.616, task_loss_gen=3.087, contrastive_loss=0, total=4174.67, n_correct=2725.69, ppl=4.58, accuracy=65.291, wps=13447.9, ups=1.61, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=18048
2023-09-03 14:32:25 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.983, trans_loss=4.939, nll_loss=2.189, w2v_ctc_loss=0.725, task_loss=0.504, task_loss_gen=3.415, contrastive_loss=0, total=4124.65, n_correct=2695.09, ppl=4.56, accuracy=65.341, wps=13509.4, ups=1.64, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=18109
2023-09-03 14:33:26 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.985, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.729, task_loss=0.525, task_loss_gen=3.571, contrastive_loss=0, total=4095.49, n_correct=2674.04, ppl=4.56, accuracy=65.292, wps=13482.6, ups=1.65, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=18170
2023-09-03 14:34:27 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.981, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.721, task_loss=0.512, task_loss_gen=3.303, contrastive_loss=0, total=4174.94, n_correct=2726.62, ppl=4.56, accuracy=65.309, wps=13631, ups=1.63, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=18231
2023-09-03 14:35:28 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.982, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.724, task_loss=0.574, task_loss_gen=3.325, contrastive_loss=0, total=4163.19, n_correct=2719.74, ppl=4.56, accuracy=65.328, wps=13621.2, ups=1.64, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=18292
2023-09-03 14:36:30 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.992, trans_loss=4.946, nll_loss=2.198, w2v_ctc_loss=0.739, task_loss=0.457, task_loss_gen=3.709, contrastive_loss=0, total=4103.45, n_correct=2668.65, ppl=4.59, accuracy=65.034, wps=13233.4, ups=1.61, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=61, gb_free=14.4, wall=18354
2023-09-03 14:37:32 | INFO | train_inner | epoch 016:   1100 / 1474 loss=1.996, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.743, task_loss=0.52, task_loss_gen=3.818, contrastive_loss=0, total=4119.27, n_correct=2674.19, ppl=4.61, accuracy=64.919, wps=13258.2, ups=1.61, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=18416
2023-09-03 14:38:34 | INFO | train_inner | epoch 016:   1200 / 1474 loss=1.983, trans_loss=4.945, nll_loss=2.198, w2v_ctc_loss=0.717, task_loss=0.439, task_loss_gen=3.875, contrastive_loss=0, total=4165.11, n_correct=2712.98, ppl=4.59, accuracy=65.136, wps=13413.2, ups=1.61, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=18478
2023-09-03 14:39:35 | INFO | train_inner | epoch 016:   1300 / 1474 loss=1.986, trans_loss=4.94, nll_loss=2.192, w2v_ctc_loss=0.733, task_loss=0.411, task_loss_gen=4.006, contrastive_loss=0, total=4134.61, n_correct=2696.67, ppl=4.57, accuracy=65.222, wps=13486.1, ups=1.63, wpb=8269.2, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=18540
2023-09-03 14:40:37 | INFO | train_inner | epoch 016:   1400 / 1474 loss=1.983, trans_loss=4.94, nll_loss=2.192, w2v_ctc_loss=0.734, task_loss=0.42, task_loss_gen=3.936, contrastive_loss=0, total=4206.33, n_correct=2746, ppl=4.57, accuracy=65.283, wps=13745.8, ups=1.63, wpb=8412.7, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=18601
2023-09-03 14:41:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 14:41:55 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.192 | nll_loss 2.465 | w2v_ctc_loss 1.308 | task_loss 1.208 | task_loss_gen 9.521 | contrastive_loss 0 | total 4003.4 | n_correct 2646.3 | ppl 5.52 | accuracy 66.101 | uer 17.994 | wer 19.649 | raw_wer 19.649 | bleu 21.45 | wps 1624.1 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 21.46
2023-09-03 14:41:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-09-03 14:41:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.4502.pt
2023-09-03 14:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.4502.pt
2023-09-03 14:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.4502.pt (epoch 16 @ 23574 updates, score 21.45) (writing took 8.152650470961817 seconds)
2023-09-03 14:42:04 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-03 14:42:04 | INFO | train | epoch 016 | loss 1.985 | trans_loss 4.94 | nll_loss 2.192 | w2v_ctc_loss 0.728 | task_loss 0.498 | task_loss_gen 3.591 | contrastive_loss 0 | total 4138.65 | n_correct 2700.21 | ppl 4.57 | accuracy 65.244 | wps 12786.9 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.507 | clip 0 | loss_scale 32 | train_wall 893 | gb_free 15.1 | wall 18688
2023-09-03 14:42:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 14:42:04 | INFO | fairseq.trainer | begin training epoch 17
2023-09-03 14:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 14:42:28 | INFO | train_inner | epoch 017:     26 / 1474 loss=1.979, trans_loss=4.928, nll_loss=2.176, w2v_ctc_loss=0.719, task_loss=0.401, task_loss_gen=4.31, contrastive_loss=0, total=4152.31, n_correct=2716.78, ppl=4.52, accuracy=65.428, wps=7481.9, ups=0.9, wpb=8304.6, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=13.4, wall=18712
2023-09-03 14:43:29 | INFO | train_inner | epoch 017:    126 / 1474 loss=1.976, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.724, task_loss=0.33, task_loss_gen=4.594, contrastive_loss=0, total=4118.91, n_correct=2705.89, ppl=4.48, accuracy=65.694, wps=13353.2, ups=1.62, wpb=8237.8, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=18774
2023-09-03 14:44:31 | INFO | train_inner | epoch 017:    226 / 1474 loss=1.966, trans_loss=4.915, nll_loss=2.158, w2v_ctc_loss=0.706, task_loss=0.382, task_loss_gen=4.123, contrastive_loss=0, total=4145.15, n_correct=2724.8, ppl=4.46, accuracy=65.735, wps=13561.6, ups=1.64, wpb=8290.3, bsz=315, num_updates=23800, lr=9.16698e-05, gnorm=0.49, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=18835
2023-09-03 14:45:32 | INFO | train_inner | epoch 017:    326 / 1474 loss=1.97, trans_loss=4.919, nll_loss=2.164, w2v_ctc_loss=0.71, task_loss=0.454, task_loss_gen=4.197, contrastive_loss=0, total=4169.51, n_correct=2739.63, ppl=4.48, accuracy=65.706, wps=13676.1, ups=1.64, wpb=8339, bsz=308.1, num_updates=23900, lr=9.14779e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=18896
2023-09-03 14:46:33 | INFO | train_inner | epoch 017:    426 / 1474 loss=1.969, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.713, task_loss=0.403, task_loss_gen=4.341, contrastive_loss=0, total=4140.49, n_correct=2722.46, ppl=4.48, accuracy=65.752, wps=13439.9, ups=1.62, wpb=8281, bsz=306.9, num_updates=24000, lr=9.12871e-05, gnorm=0.495, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=18957
2023-09-03 14:46:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 14:47:07 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.908 | trans_loss 5.192 | nll_loss 2.465 | w2v_ctc_loss 1.326 | task_loss 2.771 | task_loss_gen 7.715 | contrastive_loss 0 | total 4003.4 | n_correct 2640.9 | ppl 5.52 | accuracy 65.966 | uer 18.024 | wer 19.746 | raw_wer 19.746 | bleu 21.67 | wps 1575 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.67
2023-09-03 14:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-09-03 14:47:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-03 14:47:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-03 14:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.67) (writing took 14.809902838955168 seconds)
2023-09-03 14:48:24 | INFO | train_inner | epoch 017:    526 / 1474 loss=1.976, trans_loss=4.925, nll_loss=2.171, w2v_ctc_loss=0.722, task_loss=0.355, task_loss_gen=4.696, contrastive_loss=0, total=4184.16, n_correct=2741.01, ppl=4.5, accuracy=65.509, wps=7518.7, ups=0.9, wpb=8368.3, bsz=307.1, num_updates=24100, lr=9.10975e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=19069
2023-09-03 14:49:26 | INFO | train_inner | epoch 017:    626 / 1474 loss=1.972, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.715, task_loss=0.453, task_loss_gen=4.44, contrastive_loss=0, total=4166.61, n_correct=2736.15, ppl=4.5, accuracy=65.668, wps=13500, ups=1.62, wpb=8333.2, bsz=303.3, num_updates=24200, lr=9.09091e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=19130
2023-09-03 14:50:28 | INFO | train_inner | epoch 017:    726 / 1474 loss=1.981, trans_loss=4.928, nll_loss=2.176, w2v_ctc_loss=0.73, task_loss=0.404, task_loss_gen=4.392, contrastive_loss=0, total=4167.85, n_correct=2729.5, ppl=4.52, accuracy=65.489, wps=13539.9, ups=1.62, wpb=8335.7, bsz=308.3, num_updates=24300, lr=9.07218e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=14.8, wall=19192
2023-09-03 14:51:29 | INFO | train_inner | epoch 017:    826 / 1474 loss=1.975, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.72, task_loss=0.411, task_loss_gen=4.582, contrastive_loss=0, total=4093.22, n_correct=2688.21, ppl=4.5, accuracy=65.675, wps=13459.9, ups=1.64, wpb=8186.4, bsz=296.3, num_updates=24400, lr=9.05357e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=19253
2023-09-03 14:52:29 | INFO | train_inner | epoch 017:    926 / 1474 loss=1.972, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.714, task_loss=0.341, task_loss_gen=4.497, contrastive_loss=0, total=4099.33, n_correct=2691.84, ppl=4.5, accuracy=65.665, wps=13611.8, ups=1.66, wpb=8198.7, bsz=301.8, num_updates=24500, lr=9.03508e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=59, gb_free=16, wall=19313
2023-09-03 14:53:30 | INFO | train_inner | epoch 017:   1026 / 1474 loss=1.971, trans_loss=4.92, nll_loss=2.166, w2v_ctc_loss=0.72, task_loss=0.417, task_loss_gen=4.318, contrastive_loss=0, total=4123.22, n_correct=2707.03, ppl=4.49, accuracy=65.653, wps=13471.3, ups=1.63, wpb=8246.4, bsz=307.7, num_updates=24600, lr=9.0167e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=19374
2023-09-03 14:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 14:54:32 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.972, trans_loss=4.92, nll_loss=2.166, w2v_ctc_loss=0.712, task_loss=0.483, task_loss_gen=4.29, contrastive_loss=0, total=4073.68, n_correct=2675.69, ppl=4.49, accuracy=65.682, wps=13206.1, ups=1.62, wpb=8147.4, bsz=292.9, num_updates=24700, lr=8.99843e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=19436
2023-09-03 14:55:34 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.974, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.712, task_loss=0.522, task_loss_gen=3.694, contrastive_loss=0, total=4173.49, n_correct=2727.37, ppl=4.53, accuracy=65.35, wps=13437.6, ups=1.61, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=19498
2023-09-03 14:56:35 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.97, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.705, task_loss=0.491, task_loss_gen=3.505, contrastive_loss=0, total=4156.28, n_correct=2725.67, ppl=4.5, accuracy=65.58, wps=13511.6, ups=1.63, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=19560
2023-09-03 14:57:37 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.972, trans_loss=4.925, nll_loss=2.171, w2v_ctc_loss=0.715, task_loss=0.519, task_loss_gen=3.51, contrastive_loss=0, total=4112.95, n_correct=2700.44, ppl=4.5, accuracy=65.657, wps=13376.7, ups=1.63, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=19621
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 14:58:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
2023-09-03 14:58:39 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.183 | nll_loss 2.457 | w2v_ctc_loss 1.302 | task_loss 2.031 | task_loss_gen 8.148 | contrastive_loss 0 | total 4003.4 | n_correct 2657.2 | ppl 5.49 | accuracy 66.374 | uer 17.737 | wer 19.455 | raw_wer 19.455 | bleu 21.64 | wps 1626.6 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 21.67
2023-09-03 14:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-09-03 14:58:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6405.pt
2023-09-03 14:58:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6405.pt
2023-09-03 14:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6405.pt (epoch 17 @ 25047 updates, score 21.64) (writing took 9.340114900027402 seconds)
2023-09-03 14:58:48 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-03 14:58:48 | INFO | train | epoch 017 | loss 1.973 | trans_loss 4.922 | nll_loss 2.168 | w2v_ctc_loss 0.716 | task_loss 0.43 | task_loss_gen 4.203 | contrastive_loss 0 | total 4138.53 | n_correct 2716.22 | ppl 4.49 | accuracy 65.632 | wps 12141.7 | ups 1.47 | wpb 8277.1 | bsz 305.6 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.502 | clip 0 | loss_scale 16 | train_wall 894 | gb_free 16.1 | wall 19693
2023-09-03 14:58:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 14:58:48 | INFO | fairseq.trainer | begin training epoch 18
2023-09-03 14:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 14:59:29 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.974, trans_loss=4.92, nll_loss=2.165, w2v_ctc_loss=0.723, task_loss=0.553, task_loss_gen=3.645, contrastive_loss=0, total=4139.04, n_correct=2720.35, ppl=4.49, accuracy=65.724, wps=7403.1, ups=0.89, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=19733
2023-09-03 15:00:30 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.954, trans_loss=4.898, nll_loss=2.136, w2v_ctc_loss=0.691, task_loss=0.414, task_loss_gen=3.67, contrastive_loss=0, total=4154.85, n_correct=2746.92, ppl=4.4, accuracy=66.114, wps=13546.2, ups=1.63, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=19794
2023-09-03 15:01:32 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.955, trans_loss=4.899, nll_loss=2.137, w2v_ctc_loss=0.699, task_loss=0.496, task_loss_gen=3.59, contrastive_loss=0, total=4162.72, n_correct=2756.35, ppl=4.4, accuracy=66.215, wps=13508.4, ups=1.62, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=19856
2023-09-03 15:02:33 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.963, trans_loss=4.907, nll_loss=2.147, w2v_ctc_loss=0.706, task_loss=0.535, task_loss_gen=3.558, contrastive_loss=0, total=4161.22, n_correct=2745.25, ppl=4.43, accuracy=65.972, wps=13556.8, ups=1.63, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=61, gb_free=14, wall=19917
2023-09-03 15:03:35 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.967, trans_loss=4.911, nll_loss=2.153, w2v_ctc_loss=0.706, task_loss=0.582, task_loss_gen=3.666, contrastive_loss=0, total=4092.36, n_correct=2693.71, ppl=4.45, accuracy=65.823, wps=13227, ups=1.62, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=19979
2023-09-03 15:04:36 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.952, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.698, task_loss=0.46, task_loss_gen=3.163, contrastive_loss=0, total=4206.45, n_correct=2783.66, ppl=4.4, accuracy=66.176, wps=13727.6, ups=1.63, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=20041
2023-09-03 15:05:38 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.968, trans_loss=4.914, nll_loss=2.158, w2v_ctc_loss=0.709, task_loss=0.611, task_loss_gen=3.43, contrastive_loss=0, total=4097.96, n_correct=2698.77, ppl=4.46, accuracy=65.856, wps=13332.7, ups=1.63, wpb=8195.9, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=61, gb_free=11.8, wall=20102
2023-09-03 15:06:39 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.969, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.717, task_loss=0.607, task_loss_gen=3.095, contrastive_loss=0, total=4208.5, n_correct=2766.64, ppl=4.47, accuracy=65.739, wps=13661.3, ups=1.62, wpb=8417, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=20164
2023-09-03 15:07:41 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.963, trans_loss=4.91, nll_loss=2.152, w2v_ctc_loss=0.704, task_loss=0.589, task_loss_gen=3.417, contrastive_loss=0, total=4166.07, n_correct=2746.7, ppl=4.44, accuracy=65.93, wps=13542.7, ups=1.63, wpb=8332.1, bsz=302.4, num_updates=25900, lr=8.7875e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=20225
2023-09-03 15:08:41 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.955, trans_loss=4.904, nll_loss=2.145, w2v_ctc_loss=0.696, task_loss=0.506, task_loss_gen=3.155, contrastive_loss=0, total=4141.27, n_correct=2737, ppl=4.42, accuracy=66.091, wps=13754.9, ups=1.66, wpb=8282.5, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=20285
2023-09-03 15:08:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:09:15 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.908 | trans_loss 5.183 | nll_loss 2.451 | w2v_ctc_loss 1.346 | task_loss 5.971 | task_loss_gen 6.902 | contrastive_loss 0 | total 4003.4 | n_correct 2656.4 | ppl 5.47 | accuracy 66.354 | uer 17.721 | wer 19.496 | raw_wer 19.496 | bleu 21.9 | wps 1599.9 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 21.9
2023-09-03 15:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-09-03 15:09:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-03 15:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-03 15:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.9) (writing took 13.644851062970702 seconds)
2023-09-03 15:10:30 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.961, trans_loss=4.906, nll_loss=2.147, w2v_ctc_loss=0.699, task_loss=0.563, task_loss_gen=3.446, contrastive_loss=0, total=4134.55, n_correct=2729.72, ppl=4.43, accuracy=66.022, wps=7566.3, ups=0.92, wpb=8269.1, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=20395
2023-09-03 15:11:32 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.957, trans_loss=4.898, nll_loss=2.138, w2v_ctc_loss=0.703, task_loss=0.424, task_loss_gen=3.448, contrastive_loss=0, total=4157.63, n_correct=2747.55, ppl=4.4, accuracy=66.085, wps=13537.8, ups=1.63, wpb=8315.3, bsz=314, num_updates=26200, lr=8.73704e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=20456
2023-09-03 15:12:33 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.968, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.707, task_loss=0.51, task_loss_gen=3.845, contrastive_loss=0, total=4085.66, n_correct=2687.71, ppl=4.48, accuracy=65.784, wps=13328.7, ups=1.63, wpb=8171.3, bsz=286.6, num_updates=26300, lr=8.72041e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=20517
2023-09-03 15:13:34 | INFO | train_inner | epoch 018:   1353 / 1474 loss=1.975, trans_loss=4.917, nll_loss=2.161, w2v_ctc_loss=0.724, task_loss=0.528, task_loss_gen=3.748, contrastive_loss=0, total=4065.6, n_correct=2672.85, ppl=4.47, accuracy=65.743, wps=13325, ups=1.64, wpb=8131.2, bsz=291.1, num_updates=26400, lr=8.70388e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=60, gb_free=12.8, wall=20578
2023-09-03 15:14:36 | INFO | train_inner | epoch 018:   1453 / 1474 loss=1.967, trans_loss=4.913, nll_loss=2.157, w2v_ctc_loss=0.71, task_loss=0.556, task_loss_gen=3.658, contrastive_loss=0, total=4122.48, n_correct=2714.99, ppl=4.46, accuracy=65.858, wps=13402.5, ups=1.63, wpb=8245, bsz=299.5, num_updates=26500, lr=8.68744e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=20640
2023-09-03 15:14:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:15:22 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.912 | trans_loss 5.182 | nll_loss 2.455 | w2v_ctc_loss 1.362 | task_loss 3.071 | task_loss_gen 7.287 | contrastive_loss 0 | total 4003.4 | n_correct 2653.7 | ppl 5.48 | accuracy 66.286 | uer 17.615 | wer 19.358 | raw_wer 19.358 | bleu 22 | wps 1616.7 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 22
2023-09-03 15:15:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-09-03 15:15:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 15:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 15:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26521 updates, score 22.0) (writing took 13.791990074969362 seconds)
2023-09-03 15:15:36 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-03 15:15:36 | INFO | train | epoch 018 | loss 1.963 | trans_loss 4.908 | nll_loss 2.15 | w2v_ctc_loss 0.705 | task_loss 0.527 | task_loss_gen 3.493 | contrastive_loss 0 | total 4138.65 | n_correct 2729.5 | ppl 4.44 | accuracy 65.952 | wps 12111.1 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 26521 | lr 8.684e-05 | gnorm 0.506 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 15.5 | wall 20700
2023-09-03 15:15:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 15:15:36 | INFO | fairseq.trainer | begin training epoch 19
2023-09-03 15:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 15:16:31 | INFO | train_inner | epoch 019:     79 / 1474 loss=1.953, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.696, task_loss=0.437, task_loss_gen=3.662, contrastive_loss=0, total=4101.48, n_correct=2722.47, ppl=4.36, accuracy=66.378, wps=7126.7, ups=0.87, wpb=8203, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=20755
2023-09-03 15:17:33 | INFO | train_inner | epoch 019:    179 / 1474 loss=1.954, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.708, task_loss=0.373, task_loss_gen=3.563, contrastive_loss=0, total=4227.39, n_correct=2802.6, ppl=4.37, accuracy=66.296, wps=13596.3, ups=1.61, wpb=8454.8, bsz=324.7, num_updates=26700, lr=8.65485e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=20817
2023-09-03 15:18:34 | INFO | train_inner | epoch 019:    279 / 1474 loss=1.947, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.695, task_loss=0.348, task_loss_gen=4.126, contrastive_loss=0, total=4186.65, n_correct=2787.53, ppl=4.33, accuracy=66.581, wps=13669.6, ups=1.63, wpb=8373.3, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.49, clip=0, loss_scale=32, train_wall=60, gb_free=13.3, wall=20879
2023-09-03 15:19:36 | INFO | train_inner | epoch 019:    379 / 1474 loss=1.949, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.69, task_loss=0.428, task_loss_gen=4.078, contrastive_loss=0, total=4165.84, n_correct=2765.68, ppl=4.36, accuracy=66.389, wps=13599.5, ups=1.63, wpb=8331.7, bsz=310, num_updates=26900, lr=8.62261e-05, gnorm=0.495, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=20940
2023-09-03 15:20:36 | INFO | train_inner | epoch 019:    479 / 1474 loss=1.955, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.702, task_loss=0.415, task_loss_gen=4.318, contrastive_loss=0, total=4122.98, n_correct=2734.31, ppl=4.37, accuracy=66.319, wps=13535.2, ups=1.64, wpb=8246, bsz=302.7, num_updates=27000, lr=8.60663e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=21001
2023-09-03 15:21:37 | INFO | train_inner | epoch 019:    579 / 1474 loss=1.95, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.695, task_loss=0.416, task_loss_gen=4.102, contrastive_loss=0, total=4121.66, n_correct=2736.12, ppl=4.36, accuracy=66.384, wps=13513.9, ups=1.64, wpb=8243.3, bsz=304.4, num_updates=27100, lr=8.59074e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=21062
2023-09-03 15:22:39 | INFO | train_inner | epoch 019:    679 / 1474 loss=1.942, trans_loss=4.892, nll_loss=2.129, w2v_ctc_loss=0.679, task_loss=0.396, task_loss_gen=3.873, contrastive_loss=0, total=4205.65, n_correct=2793.29, ppl=4.38, accuracy=66.418, wps=13733.1, ups=1.63, wpb=8411.3, bsz=322.9, num_updates=27200, lr=8.57493e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=21123
2023-09-03 15:23:41 | INFO | train_inner | epoch 019:    779 / 1474 loss=1.955, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.702, task_loss=0.364, task_loss_gen=4.698, contrastive_loss=0, total=4120.36, n_correct=2734.04, ppl=4.37, accuracy=66.354, wps=13260.8, ups=1.61, wpb=8240.7, bsz=298.5, num_updates=27300, lr=8.55921e-05, gnorm=0.497, clip=0, loss_scale=32, train_wall=61, gb_free=13.5, wall=21185
2023-09-03 15:24:42 | INFO | train_inner | epoch 019:    879 / 1474 loss=1.957, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.701, task_loss=0.394, task_loss_gen=4.252, contrastive_loss=0, total=4176.52, n_correct=2765.96, ppl=4.4, accuracy=66.226, wps=13630.5, ups=1.63, wpb=8353, bsz=309.8, num_updates=27400, lr=8.54358e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=21246
2023-09-03 15:25:44 | INFO | train_inner | epoch 019:    979 / 1474 loss=1.959, trans_loss=4.904, nll_loss=2.145, w2v_ctc_loss=0.701, task_loss=0.398, task_loss_gen=4.471, contrastive_loss=0, total=4079.93, n_correct=2691.7, ppl=4.42, accuracy=65.974, wps=13129.5, ups=1.61, wpb=8159.9, bsz=305, num_updates=27500, lr=8.52803e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=21309
2023-09-03 15:26:46 | INFO | train_inner | epoch 019:   1079 / 1474 loss=1.957, trans_loss=4.9, nll_loss=2.139, w2v_ctc_loss=0.698, task_loss=0.47, task_loss_gen=4.541, contrastive_loss=0, total=4041.08, n_correct=2674.97, ppl=4.41, accuracy=66.194, wps=13177.2, ups=1.63, wpb=8082.2, bsz=292.3, num_updates=27600, lr=8.51257e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=21370
2023-09-03 15:27:48 | INFO | train_inner | epoch 019:   1179 / 1474 loss=1.959, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.703, task_loss=0.321, task_loss_gen=4.78, contrastive_loss=0, total=4146.59, n_correct=2739.55, ppl=4.41, accuracy=66.068, wps=13354.4, ups=1.61, wpb=8293.2, bsz=310.1, num_updates=27700, lr=8.49719e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=11.8, wall=21432
2023-09-03 15:28:49 | INFO | train_inner | epoch 019:   1279 / 1474 loss=1.954, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.692, task_loss=0.422, task_loss_gen=4.428, contrastive_loss=0, total=4142.96, n_correct=2742.85, ppl=4.4, accuracy=66.205, wps=13446.9, ups=1.62, wpb=8285.9, bsz=300.3, num_updates=27800, lr=8.48189e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=21494
2023-09-03 15:29:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 15:29:51 | INFO | train_inner | epoch 019:   1380 / 1474 loss=1.958, trans_loss=4.898, nll_loss=2.138, w2v_ctc_loss=0.702, task_loss=0.417, task_loss_gen=4.247, contrastive_loss=0, total=4130.55, n_correct=2729.42, ppl=4.4, accuracy=66.079, wps=13311.4, ups=1.61, wpb=8261.1, bsz=300.5, num_updates=27900, lr=8.46668e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=21556
2023-09-03 15:30:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:31:24 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.897 | trans_loss 5.178 | nll_loss 2.446 | w2v_ctc_loss 1.323 | task_loss 1.753 | task_loss_gen 9.178 | contrastive_loss 0 | total 4003.4 | n_correct 2650.1 | ppl 5.45 | accuracy 66.196 | uer 17.729 | wer 19.429 | raw_wer 19.429 | bleu 21.65 | wps 1522.9 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 22
2023-09-03 15:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-09-03 15:31:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6502.pt
2023-09-03 15:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6502.pt
2023-09-03 15:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.6502.pt (epoch 19 @ 27994 updates, score 21.65) (writing took 8.073877802002244 seconds)
2023-09-03 15:31:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-03 15:31:32 | INFO | train | epoch 019 | loss 1.953 | trans_loss 4.893 | nll_loss 2.131 | w2v_ctc_loss 0.697 | task_loss 0.407 | task_loss_gen 4.207 | contrastive_loss 0 | total 4138.58 | n_correct 2743.34 | ppl 4.38 | accuracy 66.287 | wps 12744.4 | ups 1.54 | wpb 8277.2 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.504 | clip 0 | loss_scale 16 | train_wall 894 | gb_free 17 | wall 21657
2023-09-03 15:31:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 15:31:33 | INFO | fairseq.trainer | begin training epoch 20
2023-09-03 15:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 15:31:44 | INFO | train_inner | epoch 020:      6 / 1474 loss=1.95, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.691, task_loss=0.51, task_loss_gen=3.837, contrastive_loss=0, total=4117.61, n_correct=2731.44, ppl=4.37, accuracy=66.336, wps=7323.7, ups=0.89, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=21668
2023-09-03 15:31:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:32:18 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.892 | trans_loss 5.175 | nll_loss 2.442 | w2v_ctc_loss 1.313 | task_loss 1.824 | task_loss_gen 9.087 | contrastive_loss 0 | total 4003.4 | n_correct 2654.9 | ppl 5.43 | accuracy 66.316 | uer 17.676 | wer 19.425 | raw_wer 19.425 | bleu 21.83 | wps 1556.3 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22
2023-09-03 15:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-09-03 15:32:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-03 15:32:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-03 15:32:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.83) (writing took 8.305550316988956 seconds)
2023-09-03 15:33:28 | INFO | train_inner | epoch 020:    106 / 1474 loss=1.939, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.682, task_loss=0.516, task_loss_gen=3.564, contrastive_loss=0, total=4192.82, n_correct=2794.77, ppl=4.3, accuracy=66.656, wps=8065.6, ups=0.96, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=21772
2023-09-03 15:34:30 | INFO | train_inner | epoch 020:    206 / 1474 loss=1.944, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.687, task_loss=0.519, task_loss_gen=3.609, contrastive_loss=0, total=4155.9, n_correct=2768.33, ppl=4.31, accuracy=66.612, wps=13403.9, ups=1.61, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=11.3, wall=21834
2023-09-03 15:35:31 | INFO | train_inner | epoch 020:    306 / 1474 loss=1.937, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.688, task_loss=0.419, task_loss_gen=3.275, contrastive_loss=0, total=4192.69, n_correct=2797.94, ppl=4.3, accuracy=66.734, wps=13639.3, ups=1.63, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=21896
2023-09-03 15:36:33 | INFO | train_inner | epoch 020:    406 / 1474 loss=1.94, trans_loss=4.87, nll_loss=2.101, w2v_ctc_loss=0.68, task_loss=0.563, task_loss_gen=3.552, contrastive_loss=0, total=4116.96, n_correct=2747.78, ppl=4.29, accuracy=66.743, wps=13443.2, ups=1.63, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=60, gb_free=12.3, wall=21957
2023-09-03 15:37:34 | INFO | train_inner | epoch 020:    506 / 1474 loss=1.947, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.686, task_loss=0.592, task_loss_gen=3.634, contrastive_loss=0, total=4100.73, n_correct=2726.21, ppl=4.34, accuracy=66.481, wps=13437.3, ups=1.64, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=22018
2023-09-03 15:38:35 | INFO | train_inner | epoch 020:    606 / 1474 loss=1.949, trans_loss=4.882, nll_loss=2.116, w2v_ctc_loss=0.69, task_loss=0.557, task_loss_gen=3.593, contrastive_loss=0, total=4101.99, n_correct=2725.65, ppl=4.34, accuracy=66.447, wps=13456.7, ups=1.64, wpb=8204, bsz=298.3, num_updates=28600, lr=8.36242e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=60, gb_free=13.2, wall=22079
2023-09-03 15:39:36 | INFO | train_inner | epoch 020:    706 / 1474 loss=1.949, trans_loss=4.886, nll_loss=2.121, w2v_ctc_loss=0.692, task_loss=0.63, task_loss_gen=3.448, contrastive_loss=0, total=4124.25, n_correct=2737.59, ppl=4.35, accuracy=66.378, wps=13468.2, ups=1.63, wpb=8248.5, bsz=297.2, num_updates=28700, lr=8.34784e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=22140
2023-09-03 15:40:37 | INFO | train_inner | epoch 020:    806 / 1474 loss=1.949, trans_loss=4.885, nll_loss=2.12, w2v_ctc_loss=0.697, task_loss=0.517, task_loss_gen=3.521, contrastive_loss=0, total=4153.23, n_correct=2761.86, ppl=4.35, accuracy=66.499, wps=13526.1, ups=1.63, wpb=8306.5, bsz=308.5, num_updates=28800, lr=8.33333e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=22202
2023-09-03 15:41:39 | INFO | train_inner | epoch 020:    906 / 1474 loss=1.951, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.692, task_loss=0.567, task_loss_gen=3.372, contrastive_loss=0, total=4153.72, n_correct=2751.54, ppl=4.38, accuracy=66.243, wps=13402.6, ups=1.61, wpb=8307.4, bsz=320.7, num_updates=28900, lr=8.3189e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=22264
2023-09-03 15:42:41 | INFO | train_inner | epoch 020:   1006 / 1474 loss=1.946, trans_loss=4.886, nll_loss=2.121, w2v_ctc_loss=0.683, task_loss=0.745, task_loss_gen=3.24, contrastive_loss=0, total=4156.05, n_correct=2760.65, ppl=4.35, accuracy=66.425, wps=13426.8, ups=1.62, wpb=8312.1, bsz=305.3, num_updates=29000, lr=8.30455e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=22325
2023-09-03 15:43:42 | INFO | train_inner | epoch 020:   1106 / 1474 loss=1.945, trans_loss=4.885, nll_loss=2.12, w2v_ctc_loss=0.687, task_loss=0.622, task_loss_gen=3.031, contrastive_loss=0, total=4181.53, n_correct=2779.62, ppl=4.35, accuracy=66.474, wps=13651.1, ups=1.63, wpb=8363.1, bsz=320.2, num_updates=29100, lr=8.29027e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=22387
2023-09-03 15:44:44 | INFO | train_inner | epoch 020:   1206 / 1474 loss=1.953, trans_loss=4.877, nll_loss=2.109, w2v_ctc_loss=0.704, task_loss=0.775, task_loss_gen=3.437, contrastive_loss=0, total=4029.26, n_correct=2678.63, ppl=4.31, accuracy=66.479, wps=13195.9, ups=1.64, wpb=8058.5, bsz=282.4, num_updates=29200, lr=8.27606e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=22448
2023-09-03 15:45:46 | INFO | train_inner | epoch 020:   1306 / 1474 loss=1.947, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.688, task_loss=0.815, task_loss_gen=3.297, contrastive_loss=0, total=4127.21, n_correct=2744.51, ppl=4.35, accuracy=66.498, wps=13274.4, ups=1.61, wpb=8254.4, bsz=299.9, num_updates=29300, lr=8.26192e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=14.3, wall=22510
2023-09-03 15:46:47 | INFO | train_inner | epoch 020:   1406 / 1474 loss=1.951, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.692, task_loss=0.823, task_loss_gen=3.479, contrastive_loss=0, total=4110.89, n_correct=2730.81, ppl=4.36, accuracy=66.429, wps=13355.3, ups=1.62, wpb=8221.8, bsz=291.6, num_updates=29400, lr=8.24786e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=12.8, wall=22572
2023-09-03 15:47:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:48:03 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.881 | trans_loss 5.182 | nll_loss 2.449 | w2v_ctc_loss 1.261 | task_loss 7.984 | task_loss_gen 7.358 | contrastive_loss 0 | total 4003.4 | n_correct 2657.7 | ppl 5.46 | accuracy 66.386 | uer 17.835 | wer 19.817 | raw_wer 19.817 | bleu 21.99 | wps 1506.9 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 22
2023-09-03 15:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-09-03 15:48:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.9905.pt
2023-09-03 15:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.9905.pt
2023-09-03 15:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.9905.pt (epoch 20 @ 29468 updates, score 21.99) (writing took 9.176637677999679 seconds)
2023-09-03 15:48:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-03 15:48:13 | INFO | train | epoch 020 | loss 1.946 | trans_loss 4.881 | nll_loss 2.116 | w2v_ctc_loss 0.689 | task_loss 0.615 | task_loss_gen 3.411 | contrastive_loss 0 | total 4138.65 | n_correct 2752.72 | ppl 4.33 | accuracy 66.512 | wps 12198.5 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.51 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 15.9 | wall 22657
2023-09-03 15:48:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 15:48:13 | INFO | fairseq.trainer | begin training epoch 21
2023-09-03 15:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 15:48:40 | INFO | train_inner | epoch 021:     32 / 1474 loss=1.941, trans_loss=4.878, nll_loss=2.113, w2v_ctc_loss=0.686, task_loss=0.713, task_loss_gen=3.119, contrastive_loss=0, total=4166.35, n_correct=2775.43, ppl=4.33, accuracy=66.615, wps=7406.7, ups=0.89, wpb=8332.7, bsz=319.4, num_updates=29500, lr=8.23387e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=60, gb_free=10.7, wall=22684
2023-09-03 15:49:41 | INFO | train_inner | epoch 021:    132 / 1474 loss=1.931, trans_loss=4.859, nll_loss=2.088, w2v_ctc_loss=0.676, task_loss=0.777, task_loss_gen=3.111, contrastive_loss=0, total=4181.45, n_correct=2800.71, ppl=4.25, accuracy=66.979, wps=13630.4, ups=1.63, wpb=8362.9, bsz=317.6, num_updates=29600, lr=8.21995e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=22745
2023-09-03 15:50:42 | INFO | train_inner | epoch 021:    232 / 1474 loss=1.928, trans_loss=4.864, nll_loss=2.092, w2v_ctc_loss=0.668, task_loss=0.842, task_loss_gen=2.971, contrastive_loss=0, total=4167.12, n_correct=2790.2, ppl=4.26, accuracy=66.958, wps=13728.2, ups=1.65, wpb=8334.2, bsz=315.1, num_updates=29700, lr=8.2061e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=60, gb_free=11.4, wall=22806
2023-09-03 15:51:44 | INFO | train_inner | epoch 021:    332 / 1474 loss=1.939, trans_loss=4.868, nll_loss=2.098, w2v_ctc_loss=0.686, task_loss=0.863, task_loss_gen=3.251, contrastive_loss=0, total=4130.24, n_correct=2758.51, ppl=4.28, accuracy=66.788, wps=13293.2, ups=1.61, wpb=8260.5, bsz=303.6, num_updates=29800, lr=8.19232e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=22868
2023-09-03 15:52:45 | INFO | train_inner | epoch 021:    432 / 1474 loss=1.93, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.672, task_loss=0.781, task_loss_gen=3.132, contrastive_loss=0, total=4186.28, n_correct=2806.45, ppl=4.25, accuracy=67.039, wps=13699, ups=1.64, wpb=8372.6, bsz=310.3, num_updates=29900, lr=8.17861e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=22929
2023-09-03 15:53:46 | INFO | train_inner | epoch 021:    532 / 1474 loss=1.93, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.677, task_loss=0.673, task_loss_gen=3.59, contrastive_loss=0, total=4096.33, n_correct=2749.65, ppl=4.22, accuracy=67.125, wps=13387.5, ups=1.63, wpb=8192.7, bsz=298, num_updates=30000, lr=8.16497e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=22991
2023-09-03 15:53:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 15:54:20 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.894 | trans_loss 5.179 | nll_loss 2.443 | w2v_ctc_loss 1.31 | task_loss 6.051 | task_loss_gen 7.555 | contrastive_loss 0 | total 4003.4 | n_correct 2653.5 | ppl 5.44 | accuracy 66.281 | uer 17.67 | wer 19.459 | raw_wer 19.459 | bleu 21.88 | wps 1553.2 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22
2023-09-03 15:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-09-03 15:54:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-09-03 15:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-09-03 15:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 21.88) (writing took 9.847130096983165 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 15:55:32 | INFO | train_inner | epoch 021:    632 / 1474 loss=1.933, trans_loss=4.863, nll_loss=2.093, w2v_ctc_loss=0.674, task_loss=0.653, task_loss_gen=3.54, contrastive_loss=0, total=4215.02, n_correct=2819.48, ppl=4.27, accuracy=66.891, wps=7987, ups=0.95, wpb=8430, bsz=314.6, num_updates=30100, lr=8.15139e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=23096
2023-09-03 15:56:33 | INFO | train_inner | epoch 021:    732 / 1474 loss=1.938, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.68, task_loss=0.582, task_loss_gen=3.711, contrastive_loss=0, total=4147.25, n_correct=2772.69, ppl=4.3, accuracy=66.856, wps=13535.1, ups=1.63, wpb=8294.5, bsz=308.5, num_updates=30200, lr=8.13788e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=23157
2023-09-03 15:57:35 | INFO | train_inner | epoch 021:    832 / 1474 loss=1.941, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.68, task_loss=0.552, task_loss_gen=4.02, contrastive_loss=0, total=4071.46, n_correct=2713.73, ppl=4.31, accuracy=66.653, wps=13185.7, ups=1.62, wpb=8142.9, bsz=294.2, num_updates=30300, lr=8.12444e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=23219
2023-09-03 15:58:36 | INFO | train_inner | epoch 021:    932 / 1474 loss=1.932, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.677, task_loss=0.507, task_loss_gen=3.907, contrastive_loss=0, total=4098.4, n_correct=2742.17, ppl=4.26, accuracy=66.908, wps=13404.6, ups=1.64, wpb=8196.8, bsz=301.3, num_updates=30400, lr=8.11107e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=23280
2023-09-03 15:59:37 | INFO | train_inner | epoch 021:   1032 / 1474 loss=1.941, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.684, task_loss=0.584, task_loss_gen=3.815, contrastive_loss=0, total=4099.06, n_correct=2737.27, ppl=4.31, accuracy=66.778, wps=13467.3, ups=1.64, wpb=8198.1, bsz=297.6, num_updates=30500, lr=8.09776e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=23341
2023-09-03 16:00:38 | INFO | train_inner | epoch 021:   1132 / 1474 loss=1.937, trans_loss=4.863, nll_loss=2.092, w2v_ctc_loss=0.681, task_loss=0.566, task_loss_gen=4.061, contrastive_loss=0, total=4127.16, n_correct=2761.73, ppl=4.26, accuracy=66.916, wps=13544.4, ups=1.64, wpb=8254.3, bsz=295.6, num_updates=30600, lr=8.08452e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=23402
2023-09-03 16:01:39 | INFO | train_inner | epoch 021:   1232 / 1474 loss=1.936, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.678, task_loss=0.434, task_loss_gen=3.762, contrastive_loss=0, total=4159.29, n_correct=2776.86, ppl=4.29, accuracy=66.763, wps=13608.7, ups=1.64, wpb=8318.6, bsz=312.4, num_updates=30700, lr=8.07134e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=23463
2023-09-03 16:02:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 16:02:41 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.937, trans_loss=4.867, nll_loss=2.099, w2v_ctc_loss=0.683, task_loss=0.516, task_loss_gen=3.648, contrastive_loss=0, total=4139.02, n_correct=2770.12, ppl=4.28, accuracy=66.927, wps=13301.6, ups=1.61, wpb=8278, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=17.1, wall=23526
2023-09-03 16:03:44 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.95, trans_loss=4.877, nll_loss=2.11, w2v_ctc_loss=0.7, task_loss=0.664, task_loss_gen=3.499, contrastive_loss=0, total=4127.02, n_correct=2744.53, ppl=4.32, accuracy=66.501, wps=13243.4, ups=1.6, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=62, gb_free=16.1, wall=23588
2023-09-03 16:04:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
2023-09-03 16:04:42 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.9 | trans_loss 5.182 | nll_loss 2.451 | w2v_ctc_loss 1.322 | task_loss 4.21 | task_loss_gen 10.256 | contrastive_loss 0 | total 4003.4 | n_correct 2658.4 | ppl 5.47 | accuracy 66.404 | uer 18.034 | wer 19.921 | raw_wer 19.921 | bleu 21.78 | wps 1610.1 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 22
2023-09-03 16:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-09-03 16:04:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.7809.pt
2023-09-03 16:04:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.7809.pt
2023-09-03 16:04:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_21.7809.pt (epoch 21 @ 30941 updates, score 21.78) (writing took 9.065794423979241 seconds)
2023-09-03 16:04:52 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-03 16:04:52 | INFO | train | epoch 021 | loss 1.936 | trans_loss 4.866 | nll_loss 2.097 | w2v_ctc_loss 0.68 | task_loss 0.65 | task_loss_gen 3.554 | contrastive_loss 0 | total 4138.76 | n_correct 2767.15 | ppl 4.28 | accuracy 66.859 | wps 12201.3 | ups 1.47 | wpb 8277.5 | bsz 305.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.507 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 15.1 | wall 23656
2023-09-03 16:04:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 16:04:52 | INFO | fairseq.trainer | begin training epoch 22
2023-09-03 16:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 16:05:36 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.931, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.679, task_loss=0.68, task_loss_gen=3.336, contrastive_loss=0, total=4140.16, n_correct=2779.82, ppl=4.23, accuracy=67.143, wps=7393.6, ups=0.89, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=23700
2023-09-03 16:06:37 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.927, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.671, task_loss=0.576, task_loss_gen=3.621, contrastive_loss=0, total=4115.86, n_correct=2764.84, ppl=4.22, accuracy=67.175, wps=13405.3, ups=1.63, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=23761
2023-09-03 16:07:39 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.918, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.66, task_loss=0.571, task_loss_gen=3.219, contrastive_loss=0, total=4247.73, n_correct=2858.69, ppl=4.2, accuracy=67.299, wps=13784.3, ups=1.62, wpb=8495.5, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.495, clip=0, loss_scale=16, train_wall=61, gb_free=13.5, wall=23823
2023-09-03 16:08:41 | INFO | train_inner | epoch 022:    359 / 1474 loss=1.932, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.675, task_loss=0.726, task_loss_gen=3.186, contrastive_loss=0, total=4212.22, n_correct=2820.66, ppl=4.25, accuracy=66.964, wps=13459.4, ups=1.6, wpb=8424.4, bsz=317.9, num_updates=31300, lr=7.99361e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=62, gb_free=15.2, wall=23886
2023-09-03 16:09:43 | INFO | train_inner | epoch 022:    459 / 1474 loss=1.934, trans_loss=4.857, nll_loss=2.083, w2v_ctc_loss=0.679, task_loss=0.67, task_loss_gen=3.302, contrastive_loss=0, total=4131.12, n_correct=2768.65, ppl=4.24, accuracy=67.019, wps=13340, ups=1.61, wpb=8262.2, bsz=297.3, num_updates=31400, lr=7.98087e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=23947
2023-09-03 16:10:45 | INFO | train_inner | epoch 022:    559 / 1474 loss=1.927, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.674, task_loss=0.648, task_loss_gen=3.244, contrastive_loss=0, total=4153.54, n_correct=2791.91, ppl=4.22, accuracy=67.218, wps=13442.2, ups=1.62, wpb=8307.1, bsz=307.1, num_updates=31500, lr=7.96819e-05, gnorm=0.499, clip=0, loss_scale=16, train_wall=61, gb_free=14.5, wall=24009
2023-09-03 16:11:46 | INFO | train_inner | epoch 022:    659 / 1474 loss=1.918, trans_loss=4.845, nll_loss=2.069, w2v_ctc_loss=0.659, task_loss=0.582, task_loss_gen=3.159, contrastive_loss=0, total=4143.91, n_correct=2792.69, ppl=4.19, accuracy=67.393, wps=13675.4, ups=1.65, wpb=8287.8, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=24070
2023-09-03 16:12:47 | INFO | train_inner | epoch 022:    759 / 1474 loss=1.928, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.676, task_loss=0.632, task_loss_gen=3.288, contrastive_loss=0, total=4168.91, n_correct=2801.12, ppl=4.2, accuracy=67.191, wps=13578.5, ups=1.63, wpb=8337.8, bsz=303.5, num_updates=31700, lr=7.94301e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=24131
2023-09-03 16:13:48 | INFO | train_inner | epoch 022:    859 / 1474 loss=1.938, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.68, task_loss=0.651, task_loss_gen=3.609, contrastive_loss=0, total=4079.59, n_correct=2720.93, ppl=4.27, accuracy=66.696, wps=13293, ups=1.63, wpb=8159.2, bsz=288.7, num_updates=31800, lr=7.93052e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=24193
2023-09-03 16:14:50 | INFO | train_inner | epoch 022:    959 / 1474 loss=1.923, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.666, task_loss=0.665, task_loss_gen=3.29, contrastive_loss=0, total=4129.75, n_correct=2778.21, ppl=4.2, accuracy=67.273, wps=13319, ups=1.61, wpb=8259.5, bsz=303.9, num_updates=31900, lr=7.91808e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=24255
2023-09-03 16:15:51 | INFO | train_inner | epoch 022:   1059 / 1474 loss=1.922, trans_loss=4.848, nll_loss=2.074, w2v_ctc_loss=0.663, task_loss=0.629, task_loss_gen=3.136, contrastive_loss=0, total=4155.56, n_correct=2795.13, ppl=4.21, accuracy=67.262, wps=13681.7, ups=1.65, wpb=8311.1, bsz=315.3, num_updates=32000, lr=7.90569e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=24315
2023-09-03 16:15:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 16:16:25 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.9 | trans_loss 5.184 | nll_loss 2.455 | w2v_ctc_loss 1.318 | task_loss 6.17 | task_loss_gen 6.949 | contrastive_loss 0 | total 4003.4 | n_correct 2661.3 | ppl 5.48 | accuracy 66.476 | uer 17.806 | wer 19.63 | raw_wer 19.63 | bleu 22 | wps 1579.4 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22
2023-09-03 16:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-09-03 16:16:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-09-03 16:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-09-03 16:16:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.0) (writing took 16.152897396998014 seconds)
2023-09-03 16:17:43 | INFO | train_inner | epoch 022:   1159 / 1474 loss=1.942, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.685, task_loss=0.628, task_loss_gen=3.529, contrastive_loss=0, total=4089.92, n_correct=2727.32, ppl=4.3, accuracy=66.684, wps=7316.6, ups=0.89, wpb=8179.8, bsz=292.2, num_updates=32100, lr=7.89337e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=24427
2023-09-03 16:18:44 | INFO | train_inner | epoch 022:   1259 / 1474 loss=1.933, trans_loss=4.869, nll_loss=2.101, w2v_ctc_loss=0.678, task_loss=0.653, task_loss_gen=2.913, contrastive_loss=0, total=4179.82, n_correct=2792.48, ppl=4.29, accuracy=66.809, wps=13585.9, ups=1.63, wpb=8359.6, bsz=322.5, num_updates=32200, lr=7.8811e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=24489
2023-09-03 16:19:45 | INFO | train_inner | epoch 022:   1359 / 1474 loss=1.924, trans_loss=4.851, nll_loss=2.077, w2v_ctc_loss=0.665, task_loss=0.671, task_loss_gen=3, contrastive_loss=0, total=4076.98, n_correct=2739.62, ppl=4.22, accuracy=67.197, wps=13430.4, ups=1.65, wpb=8154, bsz=303.1, num_updates=32300, lr=7.86889e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=60, gb_free=10.1, wall=24549
2023-09-03 16:20:47 | INFO | train_inner | epoch 022:   1459 / 1474 loss=1.94, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.685, task_loss=0.63, task_loss_gen=3.491, contrastive_loss=0, total=4070.93, n_correct=2720.06, ppl=4.28, accuracy=66.817, wps=13270.5, ups=1.63, wpb=8141.9, bsz=286.5, num_updates=32400, lr=7.85674e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=24611
2023-09-03 16:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 16:21:30 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.174 | nll_loss 2.44 | w2v_ctc_loss 1.289 | task_loss 2.167 | task_loss_gen 7.791 | contrastive_loss 0 | total 4003.4 | n_correct 2663.5 | ppl 5.43 | accuracy 66.531 | uer 17.864 | wer 19.593 | raw_wer 19.593 | bleu 22.33 | wps 1530.6 | wpb 4003.4 | bsz 141.8 | num_updates 32415 | best_bleu 22.33
2023-09-03 16:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32415 updates
2023-09-03 16:21:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 16:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 16:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 22 @ 32415 updates, score 22.33) (writing took 13.522103895025793 seconds)
2023-09-03 16:21:44 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-03 16:21:44 | INFO | train | epoch 022 | loss 1.929 | trans_loss 4.855 | nll_loss 2.082 | w2v_ctc_loss 0.673 | task_loss 0.638 | task_loss_gen 3.285 | contrastive_loss 0 | total 4138.65 | n_correct 2776.33 | ppl 4.23 | accuracy 67.083 | wps 12053 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 32415 | lr 7.85492e-05 | gnorm 0.508 | clip 0 | loss_scale 16 | train_wall 894 | gb_free 11.3 | wall 24668
2023-09-03 16:21:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 16:21:44 | INFO | fairseq.trainer | begin training epoch 23
2023-09-03 16:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 16:22:44 | INFO | train_inner | epoch 023:     85 / 1474 loss=1.922, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.674, task_loss=0.57, task_loss_gen=3.467, contrastive_loss=0, total=4094.01, n_correct=2762.67, ppl=4.17, accuracy=67.481, wps=6982.9, ups=0.85, wpb=8188, bsz=301, num_updates=32500, lr=7.84465e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=24728
2023-09-03 16:23:45 | INFO | train_inner | epoch 023:    185 / 1474 loss=1.915, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.658, task_loss=0.516, task_loss_gen=3.693, contrastive_loss=0, total=4118.15, n_correct=2787.61, ppl=4.13, accuracy=67.691, wps=13402.5, ups=1.63, wpb=8236.3, bsz=296.2, num_updates=32600, lr=7.8326e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=61, gb_free=15.1, wall=24790
2023-09-03 16:24:47 | INFO | train_inner | epoch 023:    285 / 1474 loss=1.917, trans_loss=4.843, nll_loss=2.066, w2v_ctc_loss=0.654, task_loss=0.483, task_loss_gen=3.708, contrastive_loss=0, total=4156.76, n_correct=2799.86, ppl=4.19, accuracy=67.357, wps=13444.2, ups=1.62, wpb=8313.5, bsz=305.6, num_updates=32700, lr=7.82062e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=24851
2023-09-03 16:25:48 | INFO | train_inner | epoch 023:    385 / 1474 loss=1.917, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.661, task_loss=0.454, task_loss_gen=3.875, contrastive_loss=0, total=4114.42, n_correct=2781.56, ppl=4.14, accuracy=67.605, wps=13518.2, ups=1.64, wpb=8228.8, bsz=295.1, num_updates=32800, lr=7.80869e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=60, gb_free=12.7, wall=24912
2023-09-03 16:26:49 | INFO | train_inner | epoch 023:    485 / 1474 loss=1.922, trans_loss=4.844, nll_loss=2.068, w2v_ctc_loss=0.666, task_loss=0.375, task_loss_gen=3.707, contrastive_loss=0, total=4156.07, n_correct=2794.27, ppl=4.19, accuracy=67.233, wps=13553.8, ups=1.63, wpb=8312.1, bsz=312.6, num_updates=32900, lr=7.79681e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=24974
2023-09-03 16:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 16:27:51 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.911, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.657, task_loss=0.464, task_loss_gen=3.618, contrastive_loss=0, total=4167.47, n_correct=2820.72, ppl=4.14, accuracy=67.684, wps=13472.7, ups=1.62, wpb=8334.9, bsz=314.1, num_updates=33000, lr=7.78499e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=25035
2023-09-03 16:28:52 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.919, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.661, task_loss=0.442, task_loss_gen=3.702, contrastive_loss=0, total=4136.6, n_correct=2790.5, ppl=4.18, accuracy=67.459, wps=13529.6, ups=1.64, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=60, gb_free=17.4, wall=25097
2023-09-03 16:29:54 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.923, trans_loss=4.845, nll_loss=2.068, w2v_ctc_loss=0.668, task_loss=0.455, task_loss_gen=3.665, contrastive_loss=0, total=4147.22, n_correct=2791.4, ppl=4.19, accuracy=67.308, wps=13516, ups=1.63, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=25158
2023-09-03 16:30:55 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.915, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.663, task_loss=0.417, task_loss_gen=3.422, contrastive_loss=0, total=4193.16, n_correct=2832.51, ppl=4.17, accuracy=67.551, wps=13717.3, ups=1.64, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.491, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=25219
2023-09-03 16:31:57 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.915, trans_loss=4.838, nll_loss=2.061, w2v_ctc_loss=0.652, task_loss=0.554, task_loss_gen=3.553, contrastive_loss=0, total=4164.33, n_correct=2807.03, ppl=4.17, accuracy=67.407, wps=13398.2, ups=1.61, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=25281
2023-09-03 16:32:59 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.929, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.676, task_loss=0.505, task_loss_gen=3.974, contrastive_loss=0, total=4088.37, n_correct=2750.36, ppl=4.2, accuracy=67.273, wps=13225.3, ups=1.62, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=61, gb_free=15.1, wall=25343
2023-09-03 16:34:01 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.921, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.667, task_loss=0.461, task_loss_gen=3.755, contrastive_loss=0, total=4162.3, n_correct=2799.65, ppl=4.2, accuracy=67.262, wps=13425.7, ups=1.61, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=25405
2023-09-03 16:35:02 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.917, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.661, task_loss=0.421, task_loss_gen=3.811, contrastive_loss=0, total=4131.74, n_correct=2783.14, ppl=4.18, accuracy=67.36, wps=13510.2, ups=1.63, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=25466
2023-09-03 16:36:03 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.927, trans_loss=4.855, nll_loss=2.081, w2v_ctc_loss=0.669, task_loss=0.437, task_loss_gen=3.963, contrastive_loss=0, total=4141.25, n_correct=2779.19, ppl=4.23, accuracy=67.11, wps=13529.8, ups=1.63, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=25528
2023-09-03 16:36:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 16:37:31 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.891 | trans_loss 5.16 | nll_loss 2.421 | w2v_ctc_loss 1.341 | task_loss 1.171 | task_loss_gen 10.783 | contrastive_loss 0 | total 4003.4 | n_correct 2672.3 | ppl 5.36 | accuracy 66.751 | uer 17.299 | wer 19.007 | raw_wer 19.007 | bleu 22.42 | wps 1616.4 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 22.42
2023-09-03 16:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-09-03 16:37:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 16:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 16:37:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 23 @ 33888 updates, score 22.42) (writing took 18.342428393953014 seconds)
2023-09-03 16:37:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-03 16:37:49 | INFO | train | epoch 023 | loss 1.92 | trans_loss 4.841 | nll_loss 2.064 | w2v_ctc_loss 0.663 | task_loss 0.465 | task_loss_gen 3.728 | contrastive_loss 0 | total 4138.38 | n_correct 2789.04 | ppl 4.18 | accuracy 67.394 | wps 12633 | ups 1.53 | wpb 8276.8 | bsz 305.6 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.504 | clip 0 | loss_scale 16 | train_wall 895 | gb_free 13.3 | wall 25633
2023-09-03 16:37:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 16:37:49 | INFO | fairseq.trainer | begin training epoch 24
2023-09-03 16:37:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 16:38:04 | INFO | train_inner | epoch 024:     12 / 1474 loss=1.925, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.663, task_loss=0.446, task_loss_gen=3.971, contrastive_loss=0, total=4095.53, n_correct=2749.65, ppl=4.23, accuracy=67.138, wps=6793, ups=0.83, wpb=8191.1, bsz=306.3, num_updates=33900, lr=7.68095e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=25648
2023-09-03 16:39:05 | INFO | train_inner | epoch 024:    112 / 1474 loss=1.906, trans_loss=4.822, nll_loss=2.038, w2v_ctc_loss=0.65, task_loss=0.437, task_loss_gen=3.68, contrastive_loss=0, total=4167.42, n_correct=2824.28, ppl=4.11, accuracy=67.77, wps=13537.2, ups=1.62, wpb=8334.8, bsz=323, num_updates=34000, lr=7.66965e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=25710
2023-09-03 16:39:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 16:39:39 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.887 | trans_loss 5.169 | nll_loss 2.43 | w2v_ctc_loss 1.309 | task_loss 2.055 | task_loss_gen 8.8 | contrastive_loss 0 | total 4003.4 | n_correct 2668.1 | ppl 5.39 | accuracy 66.646 | uer 17.384 | wer 19.205 | raw_wer 19.205 | bleu 22.15 | wps 1561 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.42
2023-09-03 16:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-09-03 16:39:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-09-03 16:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-09-03 16:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.15) (writing took 10.203657410980668 seconds)
2023-09-03 16:40:51 | INFO | train_inner | epoch 024:    212 / 1474 loss=1.903, trans_loss=4.827, nll_loss=2.046, w2v_ctc_loss=0.643, task_loss=0.434, task_loss_gen=3.392, contrastive_loss=0, total=4247.08, n_correct=2877.21, ppl=4.13, accuracy=67.746, wps=8014.4, ups=0.94, wpb=8494.2, bsz=339.5, num_updates=34100, lr=7.6584e-05, gnorm=0.49, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=25816
2023-09-03 16:41:53 | INFO | train_inner | epoch 024:    312 / 1474 loss=1.908, trans_loss=4.824, nll_loss=2.041, w2v_ctc_loss=0.652, task_loss=0.412, task_loss_gen=3.828, contrastive_loss=0, total=4139.31, n_correct=2805.49, ppl=4.12, accuracy=67.777, wps=13527.9, ups=1.63, wpb=8278.6, bsz=308.4, num_updates=34200, lr=7.64719e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=25877
2023-09-03 16:42:54 | INFO | train_inner | epoch 024:    412 / 1474 loss=1.92, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.665, task_loss=0.335, task_loss_gen=4.327, contrastive_loss=0, total=4157.07, n_correct=2805.38, ppl=4.13, accuracy=67.485, wps=13495.1, ups=1.62, wpb=8314.1, bsz=299.9, num_updates=34300, lr=7.63604e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=25939
2023-09-03 16:43:56 | INFO | train_inner | epoch 024:    512 / 1474 loss=1.915, trans_loss=4.827, nll_loss=2.046, w2v_ctc_loss=0.662, task_loss=0.468, task_loss_gen=4.016, contrastive_loss=0, total=4138.82, n_correct=2797.74, ppl=4.13, accuracy=67.598, wps=13337.8, ups=1.61, wpb=8277.6, bsz=301.6, num_updates=34400, lr=7.62493e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=26001
2023-09-03 16:44:58 | INFO | train_inner | epoch 024:    612 / 1474 loss=1.908, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.648, task_loss=0.426, task_loss_gen=3.975, contrastive_loss=0, total=4164.75, n_correct=2821.64, ppl=4.13, accuracy=67.751, wps=13577.4, ups=1.63, wpb=8329.5, bsz=309.1, num_updates=34500, lr=7.61387e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=26062
2023-09-03 16:45:59 | INFO | train_inner | epoch 024:    712 / 1474 loss=1.92, trans_loss=4.839, nll_loss=2.06, w2v_ctc_loss=0.659, task_loss=0.414, task_loss_gen=4.156, contrastive_loss=0, total=4103.92, n_correct=2765.18, ppl=4.17, accuracy=67.379, wps=13417.4, ups=1.63, wpb=8207.8, bsz=294, num_updates=34600, lr=7.60286e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=60, gb_free=11.6, wall=26123
2023-09-03 16:47:01 | INFO | train_inner | epoch 024:    812 / 1474 loss=1.914, trans_loss=4.836, nll_loss=2.058, w2v_ctc_loss=0.658, task_loss=0.379, task_loss_gen=4.082, contrastive_loss=0, total=4109.8, n_correct=2775.93, ppl=4.17, accuracy=67.544, wps=13279.1, ups=1.62, wpb=8219.6, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=26185
2023-09-03 16:48:02 | INFO | train_inner | epoch 024:    912 / 1474 loss=1.922, trans_loss=4.835, nll_loss=2.055, w2v_ctc_loss=0.667, task_loss=0.507, task_loss_gen=4.273, contrastive_loss=0, total=4042.08, n_correct=2729.32, ppl=4.16, accuracy=67.523, wps=13235.2, ups=1.64, wpb=8084.2, bsz=280.6, num_updates=34800, lr=7.58098e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=26246
2023-09-03 16:49:04 | INFO | train_inner | epoch 024:   1012 / 1474 loss=1.916, trans_loss=4.838, nll_loss=2.059, w2v_ctc_loss=0.655, task_loss=0.496, task_loss_gen=3.946, contrastive_loss=0, total=4140.44, n_correct=2797.22, ppl=4.17, accuracy=67.559, wps=13385.7, ups=1.62, wpb=8280.9, bsz=298.7, num_updates=34900, lr=7.57011e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=11.3, wall=26308
2023-09-03 16:50:05 | INFO | train_inner | epoch 024:   1112 / 1474 loss=1.911, trans_loss=4.824, nll_loss=2.043, w2v_ctc_loss=0.661, task_loss=0.462, task_loss_gen=3.751, contrastive_loss=0, total=4134.93, n_correct=2797.86, ppl=4.12, accuracy=67.664, wps=13526.7, ups=1.64, wpb=8269.9, bsz=309.4, num_updates=35000, lr=7.55929e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=26369
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 16:51:06 | INFO | train_inner | epoch 024:   1212 / 1474 loss=1.911, trans_loss=4.831, nll_loss=2.051, w2v_ctc_loss=0.654, task_loss=0.439, task_loss_gen=4.07, contrastive_loss=0, total=4144.49, n_correct=2805.48, ppl=4.14, accuracy=67.692, wps=13491.4, ups=1.63, wpb=8289, bsz=309.8, num_updates=35100, lr=7.54851e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=26431
2023-09-03 16:52:08 | INFO | train_inner | epoch 024:   1312 / 1474 loss=1.919, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.668, task_loss=0.434, task_loss_gen=4.758, contrastive_loss=0, total=4110.93, n_correct=2778.69, ppl=4.15, accuracy=67.593, wps=13295.9, ups=1.62, wpb=8221.9, bsz=293, num_updates=35200, lr=7.53778e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=61, gb_free=13.2, wall=26492
2023-09-03 16:53:09 | INFO | train_inner | epoch 024:   1412 / 1474 loss=1.922, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.673, task_loss=0.388, task_loss_gen=4.755, contrastive_loss=0, total=4088.73, n_correct=2758.68, ppl=4.17, accuracy=67.47, wps=13366.4, ups=1.63, wpb=8177.5, bsz=294.1, num_updates=35300, lr=7.5271e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=26554
2023-09-03 16:53:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
2023-09-03 16:54:21 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.898 | trans_loss 5.169 | nll_loss 2.434 | w2v_ctc_loss 1.344 | task_loss 1.274 | task_loss_gen 10.051 | contrastive_loss 0 | total 4003.4 | n_correct 2671.9 | ppl 5.4 | accuracy 66.741 | uer 17.811 | wer 19.63 | raw_wer 19.63 | bleu 22.21 | wps 1561.6 | wpb 4003.4 | bsz 141.8 | num_updates 35362 | best_bleu 22.42
2023-09-03 16:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35362 updates
2023-09-03 16:54:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2108.pt
2023-09-03 16:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2108.pt
2023-09-03 16:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2108.pt (epoch 24 @ 35362 updates, score 22.21) (writing took 10.744520987034775 seconds)
2023-09-03 16:54:32 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-03 16:54:32 | INFO | train | epoch 024 | loss 1.913 | trans_loss 4.831 | nll_loss 2.05 | w2v_ctc_loss 0.658 | task_loss 0.424 | task_loss_gen 4.067 | contrastive_loss 0 | total 4138.65 | n_correct 2798.63 | ppl 4.14 | accuracy 67.622 | wps 12170.6 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 35362 | lr 7.5205e-05 | gnorm 0.505 | clip 0 | loss_scale 32 | train_wall 895 | gb_free 15.8 | wall 26636
2023-09-03 16:54:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 16:54:32 | INFO | fairseq.trainer | begin training epoch 25
2023-09-03 16:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 16:55:02 | INFO | train_inner | epoch 025:     38 / 1474 loss=1.904, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.65, task_loss=0.312, task_loss_gen=4.509, contrastive_loss=0, total=4170.36, n_correct=2832.58, ppl=4.12, accuracy=67.922, wps=7396.2, ups=0.89, wpb=8340.7, bsz=313, num_updates=35400, lr=7.51646e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=26666
2023-09-03 16:56:03 | INFO | train_inner | epoch 025:    138 / 1474 loss=1.9, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.646, task_loss=0.352, task_loss_gen=4.512, contrastive_loss=0, total=4133.56, n_correct=2812.1, ppl=4.06, accuracy=68.031, wps=13462.1, ups=1.63, wpb=8267.1, bsz=306.4, num_updates=35500, lr=7.50587e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=26728
2023-09-03 16:57:05 | INFO | train_inner | epoch 025:    238 / 1474 loss=1.901, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.645, task_loss=0.463, task_loss_gen=4.378, contrastive_loss=0, total=4112.46, n_correct=2797.83, ppl=4.07, accuracy=68.033, wps=13341.8, ups=1.62, wpb=8224.9, bsz=303.4, num_updates=35600, lr=7.49532e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=26789
2023-09-03 16:58:07 | INFO | train_inner | epoch 025:    338 / 1474 loss=1.908, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.652, task_loss=0.416, task_loss_gen=4.913, contrastive_loss=0, total=4139.11, n_correct=2809.83, ppl=4.07, accuracy=67.885, wps=13296.9, ups=1.61, wpb=8278.2, bsz=291.7, num_updates=35700, lr=7.48481e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=62, gb_free=14.7, wall=26852
2023-09-03 16:59:09 | INFO | train_inner | epoch 025:    438 / 1474 loss=1.91, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.66, task_loss=0.285, task_loss_gen=4.836, contrastive_loss=0, total=4181.96, n_correct=2839.55, ppl=4.08, accuracy=67.9, wps=13620.5, ups=1.63, wpb=8363.9, bsz=303, num_updates=35800, lr=7.47435e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=26913
2023-09-03 17:00:10 | INFO | train_inner | epoch 025:    538 / 1474 loss=1.909, trans_loss=4.827, nll_loss=2.046, w2v_ctc_loss=0.654, task_loss=0.447, task_loss_gen=4.278, contrastive_loss=0, total=4162.59, n_correct=2818.68, ppl=4.13, accuracy=67.715, wps=13670.4, ups=1.64, wpb=8325.2, bsz=312.9, num_updates=35900, lr=7.46393e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=11.5, wall=26974
2023-09-03 17:01:11 | INFO | train_inner | epoch 025:    638 / 1474 loss=1.906, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.656, task_loss=0.401, task_loss_gen=4.522, contrastive_loss=0, total=4142.58, n_correct=2814.73, ppl=4.07, accuracy=67.946, wps=13420.2, ups=1.62, wpb=8285.2, bsz=308.3, num_updates=36000, lr=7.45356e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=61, gb_free=14.4, wall=27036
2023-09-03 17:01:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 17:01:45 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.897 | trans_loss 5.171 | nll_loss 2.434 | w2v_ctc_loss 1.337 | task_loss 0.633 | task_loss_gen 12.724 | contrastive_loss 0 | total 4003.4 | n_correct 2671.3 | ppl 5.4 | accuracy 66.726 | uer 17.538 | wer 19.515 | raw_wer 19.515 | bleu 22 | wps 1597.6 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.42
2023-09-03 17:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-09-03 17:01:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-09-03 17:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-09-03 17:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.0) (writing took 12.013517479994334 seconds)
--Backword ST Loss tensor(1223.4437, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(707.0323, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 17:02:58 | INFO | train_inner | epoch 025:    738 / 1474 loss=1.907, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.653, task_loss=0.367, task_loss_gen=4.849, contrastive_loss=0, total=4126.89, n_correct=2802.61, ppl=4.08, accuracy=67.911, wps=7717.1, ups=0.93, wpb=8253.8, bsz=300.9, num_updates=36100, lr=7.44323e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=27143
2023-09-03 17:04:00 | INFO | train_inner | epoch 025:    838 / 1474 loss=1.899, trans_loss=4.816, nll_loss=2.032, w2v_ctc_loss=0.646, task_loss=0.341, task_loss_gen=4.312, contrastive_loss=0, total=4199.63, n_correct=2857.96, ppl=4.09, accuracy=68.053, wps=13730.1, ups=1.63, wpb=8399.3, bsz=329, num_updates=36200, lr=7.43294e-05, gnorm=0.498, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=27204
2023-09-03 17:05:01 | INFO | train_inner | epoch 025:    938 / 1474 loss=1.906, trans_loss=4.82, nll_loss=2.038, w2v_ctc_loss=0.656, task_loss=0.324, task_loss_gen=4.744, contrastive_loss=0, total=4134.29, n_correct=2808.13, ppl=4.11, accuracy=67.923, wps=13484.9, ups=1.63, wpb=8268.6, bsz=312.8, num_updates=36300, lr=7.4227e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=27265
2023-09-03 17:06:03 | INFO | train_inner | epoch 025:   1038 / 1474 loss=1.907, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.645, task_loss=0.372, task_loss_gen=4.512, contrastive_loss=0, total=4184.54, n_correct=2832.46, ppl=4.13, accuracy=67.689, wps=13591.6, ups=1.62, wpb=8369.1, bsz=311.2, num_updates=36400, lr=7.41249e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=27327
2023-09-03 17:07:04 | INFO | train_inner | epoch 025:   1138 / 1474 loss=1.905, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.644, task_loss=0.402, task_loss_gen=4.991, contrastive_loss=0, total=4042.38, n_correct=2748.47, ppl=4.09, accuracy=67.991, wps=13142.4, ups=1.63, wpb=8084.8, bsz=286.2, num_updates=36500, lr=7.40233e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=27388
2023-09-03 17:08:05 | INFO | train_inner | epoch 025:   1238 / 1474 loss=1.909, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.65, task_loss=0.367, task_loss_gen=4.892, contrastive_loss=0, total=4077.76, n_correct=2764.62, ppl=4.12, accuracy=67.798, wps=13446.1, ups=1.65, wpb=8155.5, bsz=291.8, num_updates=36600, lr=7.39221e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=27449
2023-09-03 17:09:06 | INFO | train_inner | epoch 025:   1338 / 1474 loss=1.909, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.654, task_loss=0.421, task_loss_gen=4.499, contrastive_loss=0, total=4169.44, n_correct=2824.76, ppl=4.11, accuracy=67.749, wps=13520.5, ups=1.62, wpb=8338.9, bsz=311.7, num_updates=36700, lr=7.38213e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=27511
2023-09-03 17:10:08 | INFO | train_inner | epoch 025:   1438 / 1474 loss=1.916, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.659, task_loss=0.31, task_loss_gen=4.963, contrastive_loss=0, total=4100.7, n_correct=2766.12, ppl=4.16, accuracy=67.455, wps=13332.8, ups=1.63, wpb=8201.4, bsz=300.2, num_updates=36800, lr=7.3721e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=61, gb_free=12.4, wall=27572
2023-09-03 17:10:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1706.7443, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1026.1014, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2154.3501, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1241.8027, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1340.0308, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(750.8038, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1125.7152, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(605.8729, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1405.7446, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(836.3966, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1606.6106, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(965.2423, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1292.8700, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(748.7758, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-03 17:11:03 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.16 | nll_loss 2.423 | w2v_ctc_loss 1.323 | task_loss 1.214 | task_loss_gen 10.643 | contrastive_loss 0 | total 4003.4 | n_correct 2672.5 | ppl 5.36 | accuracy 66.756 | uer 17.251 | wer 19.138 | raw_wer 19.138 | bleu 22.56 | wps 1613.6 | wpb 4003.4 | bsz 141.8 | num_updates 36836 | best_bleu 22.56
2023-09-03 17:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36836 updates
2023-09-03 17:11:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 17:11:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 17:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 25 @ 36836 updates, score 22.56) (writing took 15.790430152963381 seconds)
2023-09-03 17:11:20 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-03 17:11:20 | INFO | train | epoch 025 | loss 1.906 | trans_loss 4.819 | nll_loss 2.036 | w2v_ctc_loss 0.651 | task_loss 0.372 | task_loss_gen 4.641 | contrastive_loss 0 | total 4138.65 | n_correct 2808.49 | ppl 4.1 | accuracy 67.86 | wps 12102.6 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 36836 | lr 7.36849e-05 | gnorm 0.505 | clip 0 | loss_scale 32 | train_wall 895 | gb_free 13.9 | wall 27644
2023-09-03 17:11:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 17:11:20 | INFO | fairseq.trainer | begin training epoch 26
2023-09-03 17:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 17:12:07 | INFO | train_inner | epoch 026:     64 / 1474 loss=1.895, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.639, task_loss=0.309, task_loss_gen=4.532, contrastive_loss=0, total=4185.54, n_correct=2851.39, ppl=4.05, accuracy=68.125, wps=7040, ups=0.84, wpb=8371.1, bsz=318.6, num_updates=36900, lr=7.3621e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=27691
2023-09-03 17:13:09 | INFO | train_inner | epoch 026:    164 / 1474 loss=1.889, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.629, task_loss=0.336, task_loss_gen=4.17, contrastive_loss=0, total=4272.09, n_correct=2916.44, ppl=4.05, accuracy=68.267, wps=13711.4, ups=1.6, wpb=8544.2, bsz=341.7, num_updates=37000, lr=7.35215e-05, gnorm=0.494, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=27753
2023-09-03 17:14:11 | INFO | train_inner | epoch 026:    264 / 1474 loss=1.899, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.649, task_loss=0.407, task_loss_gen=4.642, contrastive_loss=0, total=4124.77, n_correct=2812.62, ppl=4.03, accuracy=68.189, wps=13298.6, ups=1.61, wpb=8249.5, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=27815
2023-09-03 17:15:12 | INFO | train_inner | epoch 026:    364 / 1474 loss=1.899, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.647, task_loss=0.427, task_loss_gen=4.627, contrastive_loss=0, total=4170.99, n_correct=2843.08, ppl=4.05, accuracy=68.163, wps=13659.8, ups=1.64, wpb=8342, bsz=315.6, num_updates=37200, lr=7.33236e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=27876
2023-09-03 17:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-03 17:16:14 | INFO | train_inner | epoch 026:    465 / 1474 loss=1.894, trans_loss=4.796, nll_loss=2.006, w2v_ctc_loss=0.641, task_loss=0.333, task_loss_gen=4.901, contrastive_loss=0, total=4165.83, n_correct=2846.21, ppl=4.02, accuracy=68.323, wps=13560.2, ups=1.63, wpb=8331.7, bsz=313.8, num_updates=37300, lr=7.32252e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=27938
2023-09-03 17:17:15 | INFO | train_inner | epoch 026:    565 / 1474 loss=1.906, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.658, task_loss=0.346, task_loss_gen=5.037, contrastive_loss=0, total=4139.82, n_correct=2815.94, ppl=4.06, accuracy=68.021, wps=13468.2, ups=1.63, wpb=8279.6, bsz=300, num_updates=37400, lr=7.31272e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=61, gb_free=14.7, wall=27999
2023-09-03 17:18:17 | INFO | train_inner | epoch 026:    665 / 1474 loss=1.899, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.64, task_loss=0.454, task_loss_gen=4.666, contrastive_loss=0, total=4146.72, n_correct=2823.45, ppl=4.06, accuracy=68.089, wps=13478.6, ups=1.63, wpb=8293.4, bsz=302.7, num_updates=37500, lr=7.30297e-05, gnorm=0.498, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=28061
2023-09-03 17:19:18 | INFO | train_inner | epoch 026:    765 / 1474 loss=1.904, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.646, task_loss=0.402, task_loss_gen=4.787, contrastive_loss=0, total=4084.89, n_correct=2776.42, ppl=4.08, accuracy=67.968, wps=13348.3, ups=1.63, wpb=8169.8, bsz=297.2, num_updates=37600, lr=7.29325e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=28122
2023-09-03 17:20:19 | INFO | train_inner | epoch 026:    865 / 1474 loss=1.9, trans_loss=4.807, nll_loss=2.019, w2v_ctc_loss=0.647, task_loss=0.408, task_loss_gen=4.655, contrastive_loss=0, total=4180.78, n_correct=2842.97, ppl=4.05, accuracy=68.001, wps=13619.5, ups=1.63, wpb=8361.6, bsz=309.6, num_updates=37700, lr=7.28357e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=28184
2023-09-03 17:21:21 | INFO | train_inner | epoch 026:    965 / 1474 loss=1.901, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.637, task_loss=0.391, task_loss_gen=4.855, contrastive_loss=0, total=4147.79, n_correct=2819.82, ppl=4.08, accuracy=67.984, wps=13517.8, ups=1.63, wpb=8295.6, bsz=299.5, num_updates=37800, lr=7.27393e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=61, gb_free=12, wall=28245
2023-09-03 17:22:22 | INFO | train_inner | epoch 026:   1065 / 1474 loss=1.9, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.644, task_loss=0.434, task_loss_gen=4.792, contrastive_loss=0, total=4118.07, n_correct=2807.81, ppl=4.06, accuracy=68.183, wps=13401.1, ups=1.63, wpb=8236.1, bsz=293.6, num_updates=37900, lr=7.26433e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=28306
2023-09-03 17:23:24 | INFO | train_inner | epoch 026:   1165 / 1474 loss=1.905, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.646, task_loss=0.388, task_loss_gen=4.933, contrastive_loss=0, total=4108.48, n_correct=2790.21, ppl=4.1, accuracy=67.913, wps=13332.3, ups=1.62, wpb=8217, bsz=297.9, num_updates=38000, lr=7.25476e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=28368
2023-09-03 17:23:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 17:23:59 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.888 | trans_loss 5.166 | nll_loss 2.427 | w2v_ctc_loss 1.317 | task_loss 2.151 | task_loss_gen 8.693 | contrastive_loss 0 | total 4003.4 | n_correct 2673.1 | ppl 5.38 | accuracy 66.771 | uer 17.118 | wer 18.959 | raw_wer 18.959 | bleu 22.3 | wps 1477.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.56
2023-09-03 17:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-09-03 17:23:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-09-03 17:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-09-03 17:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.3) (writing took 10.41887706099078 seconds)
--Backword ST Loss tensor(1593.0627, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(938.7529, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 17:25:11 | INFO | train_inner | epoch 026:   1265 / 1474 loss=1.915, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.662, task_loss=0.324, task_loss_gen=5.422, contrastive_loss=0, total=4005.94, n_correct=2713.43, ppl=4.12, accuracy=67.735, wps=7471.8, ups=0.93, wpb=8011.9, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=28475
2023-09-03 17:26:13 | INFO | train_inner | epoch 026:   1365 / 1474 loss=1.901, trans_loss=4.818, nll_loss=2.035, w2v_ctc_loss=0.64, task_loss=0.384, task_loss_gen=4.719, contrastive_loss=0, total=4146.34, n_correct=2820.94, ppl=4.1, accuracy=68.034, wps=13355.6, ups=1.61, wpb=8292.7, bsz=307.7, num_updates=38200, lr=7.23575e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=28537
2023-09-03 17:27:14 | INFO | train_inner | epoch 026:   1465 / 1474 loss=1.894, trans_loss=4.81, nll_loss=2.025, w2v_ctc_loss=0.636, task_loss=0.297, task_loss_gen=4.588, contrastive_loss=0, total=4172.4, n_correct=2843.47, ppl=4.07, accuracy=68.15, wps=13654.9, ups=1.64, wpb=8344.8, bsz=320, num_updates=38300, lr=7.22629e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=28598
2023-09-03 17:27:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1862.3188, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1144.8381, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1997.3757, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1086.1187, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1400.7836, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(747.0559, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1022.4321, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(600.3433, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1102.5819, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(638.7012, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1310.6561, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(667.5463, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1368.2446, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(831.7610, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-03 17:27:53 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.877 | trans_loss 5.167 | nll_loss 2.431 | w2v_ctc_loss 1.282 | task_loss 1.139 | task_loss_gen 11.284 | contrastive_loss 0 | total 4003.4 | n_correct 2672.4 | ppl 5.39 | accuracy 66.753 | uer 17.434 | wer 19.347 | raw_wer 19.347 | bleu 22.61 | wps 1576.1 | wpb 4003.4 | bsz 141.8 | num_updates 38309 | best_bleu 22.61
2023-09-03 17:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38309 updates
2023-09-03 17:27:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 17:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 17:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 26 @ 38309 updates, score 22.61) (writing took 13.429755066055804 seconds)
2023-09-03 17:28:07 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-03 17:28:07 | INFO | train | epoch 026 | loss 1.9 | trans_loss 4.809 | nll_loss 2.023 | w2v_ctc_loss 0.644 | task_loss 0.38 | task_loss_gen 4.768 | contrastive_loss 0 | total 4138.5 | n_correct 2817.91 | ppl 4.06 | accuracy 68.09 | wps 12106 | ups 1.46 | wpb 8277 | bsz 305.6 | num_updates 38309 | lr 7.22544e-05 | gnorm 0.503 | clip 0 | loss_scale 32 | train_wall 895 | gb_free 15.7 | wall 28651
2023-09-03 17:28:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 17:28:07 | INFO | fairseq.trainer | begin training epoch 27
2023-09-03 17:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 17:29:10 | INFO | train_inner | epoch 027:     91 / 1474 loss=1.888, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.63, task_loss=0.383, task_loss_gen=5.174, contrastive_loss=0, total=4051.87, n_correct=2778.92, ppl=3.96, accuracy=68.584, wps=7011.3, ups=0.87, wpb=8103.7, bsz=281.2, num_updates=38400, lr=7.21688e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=28714
2023-09-03 17:30:11 | INFO | train_inner | epoch 027:    191 / 1474 loss=1.885, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.633, task_loss=0.389, task_loss_gen=4.333, contrastive_loss=0, total=4197.99, n_correct=2875.45, ppl=3.99, accuracy=68.496, wps=13665.4, ups=1.63, wpb=8396, bsz=324.3, num_updates=38500, lr=7.2075e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=28776
2023-09-03 17:31:13 | INFO | train_inner | epoch 027:    291 / 1474 loss=1.89, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.634, task_loss=0.453, task_loss_gen=4.458, contrastive_loss=0, total=4161.57, n_correct=2849.93, ppl=4.01, accuracy=68.482, wps=13443.1, ups=1.62, wpb=8323.1, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=28837
2023-09-03 17:32:15 | INFO | train_inner | epoch 027:    391 / 1474 loss=1.894, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.633, task_loss=0.445, task_loss_gen=4.602, contrastive_loss=0, total=4085.81, n_correct=2788.12, ppl=4.03, accuracy=68.239, wps=13186.9, ups=1.61, wpb=8171.6, bsz=298.1, num_updates=38700, lr=7.18885e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15.1, wall=28899
2023-09-03 17:33:17 | INFO | train_inner | epoch 027:    491 / 1474 loss=1.893, trans_loss=4.805, nll_loss=2.018, w2v_ctc_loss=0.638, task_loss=0.362, task_loss_gen=4.236, contrastive_loss=0, total=4241.27, n_correct=2892.61, ppl=4.05, accuracy=68.202, wps=13741.5, ups=1.62, wpb=8482.5, bsz=330.9, num_updates=38800, lr=7.17958e-05, gnorm=0.495, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=28961
2023-09-03 17:34:18 | INFO | train_inner | epoch 027:    591 / 1474 loss=1.893, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.642, task_loss=0.446, task_loss_gen=4.48, contrastive_loss=0, total=4133.35, n_correct=2822.78, ppl=4.02, accuracy=68.293, wps=13591.1, ups=1.64, wpb=8266.7, bsz=312.8, num_updates=38900, lr=7.17035e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=12.4, wall=29022
2023-09-03 17:35:19 | INFO | train_inner | epoch 027:    691 / 1474 loss=1.899, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.646, task_loss=0.442, task_loss_gen=4.715, contrastive_loss=0, total=4151.08, n_correct=2829.37, ppl=4.05, accuracy=68.16, wps=13445.4, ups=1.62, wpb=8302.2, bsz=302.6, num_updates=39000, lr=7.16115e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=29084
2023-09-03 17:36:20 | INFO | train_inner | epoch 027:    791 / 1474 loss=1.898, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.643, task_loss=0.422, task_loss_gen=4.862, contrastive_loss=0, total=4106.27, n_correct=2804.54, ppl=4.02, accuracy=68.299, wps=13499.5, ups=1.64, wpb=8212.5, bsz=293, num_updates=39100, lr=7.15199e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=29145
2023-09-03 17:37:22 | INFO | train_inner | epoch 027:    891 / 1474 loss=1.893, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.631, task_loss=0.382, task_loss_gen=4.941, contrastive_loss=0, total=4112.64, n_correct=2812.46, ppl=4.04, accuracy=68.386, wps=13436.3, ups=1.63, wpb=8225.3, bsz=294.8, num_updates=39200, lr=7.14286e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=29206
2023-09-03 17:37:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 17:38:24 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.894, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.635, task_loss=0.4, task_loss_gen=4.626, contrastive_loss=0, total=4186.97, n_correct=2857.6, ppl=4.05, accuracy=68.25, wps=13370.4, ups=1.6, wpb=8373.9, bsz=314.8, num_updates=39300, lr=7.13376e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=62, gb_free=14, wall=29268
2023-09-03 17:39:25 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.889, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.631, task_loss=0.449, task_loss_gen=4.433, contrastive_loss=0, total=4160.42, n_correct=2843.12, ppl=4.02, accuracy=68.337, wps=13591.7, ups=1.63, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=29330
2023-09-03 17:40:27 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.9, trans_loss=4.805, nll_loss=2.016, w2v_ctc_loss=0.65, task_loss=0.542, task_loss_gen=4.25, contrastive_loss=0, total=4103.72, n_correct=2796.61, ppl=4.04, accuracy=68.148, wps=13387.6, ups=1.63, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=29391
2023-09-03 17:41:28 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.904, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.645, task_loss=0.442, task_loss_gen=4.682, contrastive_loss=0, total=4065.94, n_correct=2762.34, ppl=4.07, accuracy=67.939, wps=13299, ups=1.64, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=29452
2023-09-03 17:42:29 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.891, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.631, task_loss=0.469, task_loss_gen=3.868, contrastive_loss=0, total=4149.21, n_correct=2832.75, ppl=4.05, accuracy=68.272, wps=13565, ups=1.63, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=29513
2023-09-03 17:43:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 17:43:54 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.868 | trans_loss 5.159 | nll_loss 2.419 | w2v_ctc_loss 1.267 | task_loss 2.887 | task_loss_gen 8.509 | contrastive_loss 0 | total 4003.4 | n_correct 2676.4 | ppl 5.35 | accuracy 66.853 | uer 16.933 | wer 18.836 | raw_wer 18.836 | bleu 22.28 | wps 1489.4 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 22.61
2023-09-03 17:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-09-03 17:43:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2805.pt
2023-09-03 17:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2805.pt
2023-09-03 17:44:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.2805.pt (epoch 27 @ 39782 updates, score 22.28) (writing took 8.109414917998947 seconds)
2023-09-03 17:44:02 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-03 17:44:02 | INFO | train | epoch 027 | loss 1.893 | trans_loss 4.8 | nll_loss 2.01 | w2v_ctc_loss 0.637 | task_loss 0.438 | task_loss_gen 4.492 | contrastive_loss 0 | total 4138.49 | n_correct 2826.28 | ppl 4.03 | accuracy 68.292 | wps 12758.7 | ups 1.54 | wpb 8277 | bsz 305.6 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.51 | clip 0 | loss_scale 16 | train_wall 894 | gb_free 17.5 | wall 29607
2023-09-03 17:44:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 17:44:03 | INFO | fairseq.trainer | begin training epoch 28
2023-09-03 17:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 17:44:21 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.889, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.631, task_loss=0.583, task_loss_gen=3.872, contrastive_loss=0, total=4106.72, n_correct=2807.34, ppl=4.02, accuracy=68.36, wps=7350.8, ups=0.89, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=29625
2023-09-03 17:45:22 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.883, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.627, task_loss=0.641, task_loss_gen=3.935, contrastive_loss=0, total=4103.42, n_correct=2825.98, ppl=3.94, accuracy=68.869, wps=13437.8, ups=1.64, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=29686
2023-09-03 17:46:23 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.881, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.627, task_loss=0.339, task_loss_gen=4.004, contrastive_loss=0, total=4200.12, n_correct=2883.83, ppl=3.98, accuracy=68.661, wps=13746.8, ups=1.64, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=60, gb_free=10.6, wall=29747
2023-09-03 17:46:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 17:46:57 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.169 | nll_loss 2.431 | w2v_ctc_loss 1.347 | task_loss 2.626 | task_loss_gen 8.612 | contrastive_loss 0 | total 4003.4 | n_correct 2667.8 | ppl 5.39 | accuracy 66.638 | uer 17.307 | wer 19.052 | raw_wer 19.052 | bleu 21.91 | wps 1568.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.61
2023-09-03 17:46:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-09-03 17:46:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-09-03 17:46:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-09-03 17:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 21.91) (writing took 7.432256817992311 seconds)
--Backword ST Loss tensor(1683.0735, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(982.8508, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:0')
2023-09-03 17:48:06 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.888, trans_loss=4.796, nll_loss=2.005, w2v_ctc_loss=0.623, task_loss=0.45, task_loss_gen=4.083, contrastive_loss=0, total=4147.36, n_correct=2828.38, ppl=4.01, accuracy=68.197, wps=8021.2, ups=0.97, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=62, gb_free=16.3, wall=29851
2023-09-03 17:49:08 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.89, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.637, task_loss=0.521, task_loss_gen=4.165, contrastive_loss=0, total=4087.34, n_correct=2804.41, ppl=3.98, accuracy=68.612, wps=13324, ups=1.63, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=29912
2023-09-03 17:50:08 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.887, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.628, task_loss=0.489, task_loss_gen=4.238, contrastive_loss=0, total=4099.71, n_correct=2809.1, ppl=3.99, accuracy=68.519, wps=13495.9, ups=1.65, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=29973
2023-09-03 17:51:10 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.893, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.636, task_loss=0.478, task_loss_gen=3.992, contrastive_loss=0, total=4177.06, n_correct=2853.4, ppl=4.03, accuracy=68.311, wps=13621.3, ups=1.63, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=30034
2023-09-03 17:52:11 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.886, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.628, task_loss=0.527, task_loss_gen=3.365, contrastive_loss=0, total=4190.74, n_correct=2865.62, ppl=4.03, accuracy=68.38, wps=13671, ups=1.63, wpb=8381.5, bsz=328.5, num_updates=40500, lr=7.02728e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=30095
2023-09-03 17:53:12 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.886, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.628, task_loss=0.565, task_loss_gen=3.64, contrastive_loss=0, total=4091.75, n_correct=2804.89, ppl=4.01, accuracy=68.55, wps=13438.9, ups=1.64, wpb=8183.5, bsz=306, num_updates=40600, lr=7.01862e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=30156
2023-09-03 17:54:14 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.895, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.638, task_loss=0.618, task_loss_gen=3.615, contrastive_loss=0, total=4123.89, n_correct=2811.93, ppl=4.03, accuracy=68.186, wps=13214.6, ups=1.6, wpb=8247.8, bsz=301, num_updates=40700, lr=7.01e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=62, gb_free=16.8, wall=30219
2023-09-03 17:55:16 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.896, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.641, task_loss=0.646, task_loss_gen=3.395, contrastive_loss=0, total=4176.06, n_correct=2848.47, ppl=4.03, accuracy=68.21, wps=13629, ups=1.63, wpb=8352.1, bsz=311.4, num_updates=40800, lr=7.0014e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=30280
2023-09-03 17:56:17 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.885, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.628, task_loss=0.725, task_loss_gen=3.189, contrastive_loss=0, total=4206.08, n_correct=2878.11, ppl=4, accuracy=68.427, wps=13692.6, ups=1.63, wpb=8412.2, bsz=317.3, num_updates=40900, lr=6.99284e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=30341
2023-09-03 17:57:18 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.888, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.627, task_loss=0.684, task_loss_gen=3.135, contrastive_loss=0, total=4109.72, n_correct=2811.29, ppl=4.03, accuracy=68.406, wps=13494.1, ups=1.64, wpb=8219.4, bsz=306.9, num_updates=41000, lr=6.9843e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=30402
2023-09-03 17:58:20 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.9, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.646, task_loss=0.794, task_loss_gen=3.321, contrastive_loss=0, total=4085.44, n_correct=2788.18, ppl=4.03, accuracy=68.247, wps=13193.9, ups=1.61, wpb=8170.9, bsz=285.6, num_updates=41100, lr=6.9758e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=30464
2023-09-03 17:59:22 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.894, trans_loss=4.799, nll_loss=2.008, w2v_ctc_loss=0.635, task_loss=0.86, task_loss_gen=3.157, contrastive_loss=0, total=4137.47, n_correct=2826.6, ppl=4.02, accuracy=68.317, wps=13375.3, ups=1.62, wpb=8274.9, bsz=294.8, num_updates=41200, lr=6.96733e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=30526
2023-09-03 17:59:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1505.3258, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(881.2892, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:5')
--Backword ST Loss tensor(1467.6082, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(882.7528, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:6')
--Backword ST Loss tensor(1330.4592, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(758.1769, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:4')
--Backword ST Loss tensor(1340.9901, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(739.3486, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:7')
--Backword ST Loss tensor(1387.1519, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(828.7657, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:3')
--Backword ST Loss tensor(1196.4116, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(764.3578, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:1')
--Backword ST Loss tensor(1241.2728, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(705.2568, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122, device='cuda:2')
2023-09-03 18:00:31 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.88 | trans_loss 5.17 | nll_loss 2.432 | w2v_ctc_loss 1.284 | task_loss 4.97 | task_loss_gen 6.31 | contrastive_loss 0 | total 4003.4 | n_correct 2671.5 | ppl 5.4 | accuracy 66.731 | uer 17.487 | wer 19.336 | raw_wer 19.336 | bleu 22.32 | wps 1486.5 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 22.61
2023-09-03 18:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-09-03 18:00:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3200.pt
2023-09-03 18:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3200.pt
2023-09-03 18:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3200.pt (epoch 28 @ 41256 updates, score 22.32) (writing took 8.223608234024141 seconds)
2023-09-03 18:00:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-03 18:00:40 | INFO | train | epoch 028 | loss 1.889 | trans_loss 4.794 | nll_loss 2.002 | w2v_ctc_loss 0.632 | task_loss 0.598 | task_loss_gen 3.623 | contrastive_loss 0 | total 4138.65 | n_correct 2832.06 | ppl 4.01 | accuracy 68.43 | wps 12233.4 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.516 | clip 0 | loss_scale 16 | train_wall 895 | gb_free 16.2 | wall 30604
2023-09-03 18:00:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 18:00:40 | INFO | fairseq.trainer | begin training epoch 29
2023-09-03 18:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 18:01:14 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.886, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.634, task_loss=0.804, task_loss_gen=2.842, contrastive_loss=0, total=4168.25, n_correct=2860.08, ppl=3.98, accuracy=68.616, wps=7422.5, ups=0.89, wpb=8336.5, bsz=315.7, num_updates=41300, lr=6.95889e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=30638
2023-09-03 18:02:16 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.884, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.629, task_loss=0.772, task_loss_gen=2.876, contrastive_loss=0, total=4117.66, n_correct=2828.03, ppl=3.97, accuracy=68.681, wps=13429.7, ups=1.63, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=30700
2023-09-03 18:03:17 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.873, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.614, task_loss=0.597, task_loss_gen=2.937, contrastive_loss=0, total=4198.99, n_correct=2889.43, ppl=3.95, accuracy=68.813, wps=13619.9, ups=1.62, wpb=8398, bsz=330.7, num_updates=41500, lr=6.9421e-05, gnorm=0.49, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=30761
2023-09-03 18:04:18 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.893, trans_loss=4.794, nll_loss=2.001, w2v_ctc_loss=0.638, task_loss=0.564, task_loss_gen=3.773, contrastive_loss=0, total=4091.28, n_correct=2801.71, ppl=4, accuracy=68.48, wps=13389.2, ups=1.64, wpb=8182.6, bsz=290.4, num_updates=41600, lr=6.93375e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=30823
2023-09-03 18:05:20 | INFO | train_inner | epoch 029:    444 / 1474 loss=1.875, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.622, task_loss=0.603, task_loss_gen=3.484, contrastive_loss=0, total=4158.09, n_correct=2869.32, ppl=3.91, accuracy=69.006, wps=13509.5, ups=1.62, wpb=8316.2, bsz=307.2, num_updates=41700, lr=6.92543e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=30884
2023-09-03 18:06:22 | INFO | train_inner | epoch 029:    544 / 1474 loss=1.889, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.625, task_loss=0.711, task_loss_gen=3.421, contrastive_loss=0, total=4156.12, n_correct=2841.12, ppl=4, accuracy=68.36, wps=13488.5, ups=1.62, wpb=8312.2, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=61, gb_free=11.8, wall=30946
2023-09-03 18:07:23 | INFO | train_inner | epoch 029:    644 / 1474 loss=1.877, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.619, task_loss=0.553, task_loss_gen=3.069, contrastive_loss=0, total=4153.45, n_correct=2852.32, ppl=3.96, accuracy=68.674, wps=13611.5, ups=1.64, wpb=8306.9, bsz=320.5, num_updates=41900, lr=6.90889e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=31007
2023-09-03 18:08:24 | INFO | train_inner | epoch 029:    744 / 1474 loss=1.876, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.617, task_loss=0.571, task_loss_gen=3.116, contrastive_loss=0, total=4232.02, n_correct=2910.01, ppl=3.95, accuracy=68.762, wps=13777.2, ups=1.63, wpb=8464, bsz=328, num_updates=42000, lr=6.90066e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=61, gb_free=11, wall=31068
2023-09-03 18:08:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 18:08:57 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.881 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.308 | task_loss 3.373 | task_loss_gen 6.657 | contrastive_loss 0 | total 4003.4 | n_correct 2679.2 | ppl 5.35 | accuracy 66.923 | uer 16.951 | wer 18.717 | raw_wer 18.717 | bleu 22.42 | wps 1638.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.61
2023-09-03 18:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-09-03 18:08:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-09-03 18:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 427, in validate_and_save
    checkpoint_utils.save_checkpoint(
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 125, in save_checkpoint
    assert PathManager.copy(
  File "/mnt/zhangyh/fairseq-AT/fairseq/file_io.py", line 76, in copy
    return shutil.copyfile(src_path, dst_path)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 275, in copyfile
    _fastcopy_sendfile(fsrc, fdst)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 166, in _fastcopy_sendfile
    raise err from None
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 152, in _fastcopy_sendfile
    sent = os.sendfile(outfd, infd, offset, blocksize)
OSError: [Errno 28] No space left on device: './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt' -> './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4201.pt'

/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1346 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19808
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-03 18:11:54 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-03 18:11:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-03 18:11:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19808', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-03 18:11:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-03 18:11:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-03 18:11:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-03 18:11:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-03 18:11:57 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 18:12:02 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-03 18:12:02 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-03 18:12:02 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-03 18:12:03 | INFO | root | load pretrained hubert
2023-09-03 18:12:11 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-03 18:12:14 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 18:12:21 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-03 18:12:21 | INFO | root | share the sematic adapter and textual encoder
2023-09-03 18:12:21 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-03 18:12:21 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-03 18:12:21 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-03 18:12:21 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-03 18:12:21 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-03 18:12:21 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-03 18:12:21 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 18:12:21 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 18:12:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 18:12:22 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 18:12:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-03 18:12:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-03 18:12:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-03 18:12:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-03 18:12:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-03 18:12:37 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-03 18:12:37 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-03 18:12:37 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-03 18:12:40 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
2023-09-03 18:12:58 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-03 18:12:59 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_last.pt (epoch 29 @ 41256 updates)
2023-09-03 18:12:59 | INFO | fairseq.trainer | loading train data for epoch 29
2023-09-03 18:12:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-03 18:12:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 18:12:59 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-03 18:13:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-03 18:13:03 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
2023-09-03 18:13:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 18:13:45 | INFO | fairseq.trainer | begin training epoch 29
2023-09-03 18:13:45 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
2023-09-03 18:14:27 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.88, trans_loss=4.777, nll_loss=1.981, w2v_ctc_loss=0.624, task_loss=0.927, task_loss_gen=3.008, contrastive_loss=0, total=4157.14, n_correct=2859.02, ppl=3.95, accuracy=68.774, wps=13182.7, ups=1.58, wpb=8314.3, bsz=302.7, num_updates=41300, lr=6.95889e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=35, gb_free=17.4, wall=109
2023-09-03 18:15:30 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.884, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.626, task_loss=0.858, task_loss_gen=2.727, contrastive_loss=0, total=4117.66, n_correct=2827.24, ppl=3.98, accuracy=68.661, wps=13152, ups=1.6, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=62, gb_free=16.9, wall=172
2023-09-03 18:16:34 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.877, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.622, task_loss=0.741, task_loss_gen=2.687, contrastive_loss=0, total=4198.99, n_correct=2885.43, ppl=3.96, accuracy=68.717, wps=13103.7, ups=1.56, wpb=8398, bsz=330.7, num_updates=41500, lr=6.9421e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=63, gb_free=14.9, wall=236
2023-09-03 18:17:36 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.892, trans_loss=4.794, nll_loss=2.001, w2v_ctc_loss=0.636, task_loss=1.012, task_loss_gen=3.058, contrastive_loss=0, total=4091.28, n_correct=2801.59, ppl=4, accuracy=68.477, wps=13127, ups=1.6, wpb=8182.6, bsz=290.4, num_updates=41600, lr=6.93375e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=298
2023-09-03 18:18:39 | INFO | train_inner | epoch 029:    444 / 1474 loss=1.877, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.624, task_loss=1.148, task_loss_gen=2.66, contrastive_loss=0, total=4158.09, n_correct=2867.98, ppl=3.91, accuracy=68.973, wps=13269.3, ups=1.6, wpb=8316.2, bsz=307.2, num_updates=41700, lr=6.92543e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=62, gb_free=15.6, wall=361
2023-09-03 18:19:42 | INFO | train_inner | epoch 029:    544 / 1474 loss=1.891, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.627, task_loss=1.292, task_loss_gen=2.836, contrastive_loss=0, total=4156.12, n_correct=2842.24, ppl=4.01, accuracy=68.387, wps=13227.5, ups=1.59, wpb=8312.2, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=62, gb_free=11.8, wall=424
2023-09-03 18:20:44 | INFO | train_inner | epoch 029:    644 / 1474 loss=1.885, trans_loss=4.789, nll_loss=1.997, w2v_ctc_loss=0.628, task_loss=1.018, task_loss_gen=2.555, contrastive_loss=0, total=4153.45, n_correct=2843.22, ppl=3.99, accuracy=68.454, wps=13354, ups=1.61, wpb=8306.9, bsz=320.5, num_updates=41900, lr=6.90889e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=486
2023-09-03 18:21:46 | INFO | train_inner | epoch 029:    744 / 1474 loss=1.882, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.629, task_loss=0.855, task_loss_gen=2.646, contrastive_loss=0, total=4232.02, n_correct=2905.27, ppl=3.97, accuracy=68.65, wps=13505.2, ups=1.6, wpb=8464, bsz=328, num_updates=42000, lr=6.90066e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=62, gb_free=11, wall=549
2023-09-03 18:21:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-03 18:22:20 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.883 | trans_loss 5.159 | nll_loss 2.418 | w2v_ctc_loss 1.316 | task_loss 7.604 | task_loss_gen 6.508 | contrastive_loss 0 | total 4003.4 | n_correct 2675.7 | ppl 5.34 | accuracy 66.836 | uer 17.102 | wer 18.732 | raw_wer 18.732 | bleu 22.43 | wps 1540.3 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.61
2023-09-03 18:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-09-03 18:22:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-09-03 18:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-09-03 18:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.43) (writing took 12.036463683005422 seconds)
--Backword ST Loss tensor(1448.5341, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(847.5851, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 18:23:35 | INFO | train_inner | epoch 029:    844 / 1474 loss=1.894, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.632, task_loss=1.017, task_loss_gen=3.068, contrastive_loss=0, total=4033.38, n_correct=2756.03, ppl=4.02, accuracy=68.331, wps=7430.3, ups=0.92, wpb=8066.8, bsz=280.8, num_updates=42100, lr=6.89246e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=657
2023-09-03 18:24:37 | INFO | train_inner | epoch 029:    944 / 1474 loss=1.891, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.636, task_loss=0.917, task_loss_gen=2.728, contrastive_loss=0, total=4082.33, n_correct=2794.67, ppl=4.01, accuracy=68.458, wps=13247.7, ups=1.62, wpb=8164.7, bsz=297.1, num_updates=42200, lr=6.88428e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=719
2023-09-03 18:25:39 | INFO | train_inner | epoch 029:   1044 / 1474 loss=1.881, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.622, task_loss=0.926, task_loss_gen=2.637, contrastive_loss=0, total=4146.28, n_correct=2846.03, ppl=3.96, accuracy=68.641, wps=13345.2, ups=1.61, wpb=8292.6, bsz=307.7, num_updates=42300, lr=6.87614e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=13.4, wall=781
2023-09-03 18:26:41 | INFO | train_inner | epoch 029:   1144 / 1474 loss=1.891, trans_loss=4.795, nll_loss=2.003, w2v_ctc_loss=0.633, task_loss=0.944, task_loss_gen=2.941, contrastive_loss=0, total=4068.72, n_correct=2786.09, ppl=4.01, accuracy=68.476, wps=13175.8, ups=1.62, wpb=8137.4, bsz=284, num_updates=42400, lr=6.86803e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=10.2, wall=843
2023-09-03 18:27:43 | INFO | train_inner | epoch 029:   1244 / 1474 loss=1.891, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.634, task_loss=0.842, task_loss_gen=2.83, contrastive_loss=0, total=4152.35, n_correct=2840.16, ppl=4.02, accuracy=68.399, wps=13326.9, ups=1.6, wpb=8304.7, bsz=298.8, num_updates=42500, lr=6.85994e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=62, gb_free=15.8, wall=905
2023-09-03 18:28:46 | INFO | train_inner | epoch 029:   1344 / 1474 loss=1.88, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.621, task_loss=0.85, task_loss_gen=2.656, contrastive_loss=0, total=4168.19, n_correct=2862.97, ppl=3.96, accuracy=68.686, wps=13168.3, ups=1.58, wpb=8336.4, bsz=312.8, num_updates=42600, lr=6.85189e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=63, gb_free=16.2, wall=969
2023-09-03 18:29:48 | INFO | train_inner | epoch 029:   1444 / 1474 loss=1.884, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.628, task_loss=0.78, task_loss_gen=2.728, contrastive_loss=0, total=4165.62, n_correct=2857.71, ppl=3.98, accuracy=68.602, wps=13501.9, ups=1.62, wpb=8331.2, bsz=311.1, num_updates=42700, lr=6.84386e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=61, gb_free=11.7, wall=1030
2023-09-03 18:30:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1379.6592, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(731.6091, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1264.9950, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(690.8210, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(896.0581, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(505.3869, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1794.8196, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1048.8320, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1854.3485, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1135.1785, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1074.6156, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(615.1874, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1517.8120, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(875.6140, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-03 18:30:39 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.169 | nll_loss 2.435 | w2v_ctc_loss 1.327 | task_loss 4.284 | task_loss_gen 6.093 | contrastive_loss 0 | total 4003.4 | n_correct 2670.7 | ppl 5.41 | accuracy 66.711 | uer 17.681 | wer 19.63 | raw_wer 19.63 | bleu 22.44 | wps 1611.9 | wpb 4003.4 | bsz 141.8 | num_updates 42730 | best_bleu 22.61
2023-09-03 18:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42730 updates
2023-09-03 18:30:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4405.pt
2023-09-03 18:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4405.pt
2023-09-03 18:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4405.pt (epoch 29 @ 42730 updates, score 22.44) (writing took 8.016380132001359 seconds)
2023-09-03 18:30:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-03 18:30:47 | INFO | train | epoch 029 | loss 1.885 | trans_loss 4.787 | nll_loss 1.994 | w2v_ctc_loss 0.628 | task_loss 0.935 | task_loss_gen 2.76 | contrastive_loss 0 | total 4138.65 | n_correct 2838.36 | ppl 3.98 | accuracy 68.582 | wps 12101.8 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 42730 | lr 6.84146e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 917 | gb_free 15.8 | wall 1090
2023-09-03 18:30:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 18:30:48 | INFO | fairseq.trainer | begin training epoch 30
2023-09-03 18:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 18:31:37 | INFO | train_inner | epoch 030:     70 / 1474 loss=1.873, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.612, task_loss=0.748, task_loss_gen=2.536, contrastive_loss=0, total=4184.78, n_correct=2881.57, ppl=3.94, accuracy=68.858, wps=7638.9, ups=0.91, wpb=8369.6, bsz=320.1, num_updates=42800, lr=6.83586e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=1140
2023-09-03 18:32:39 | INFO | train_inner | epoch 030:    170 / 1474 loss=1.871, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.618, task_loss=0.766, task_loss_gen=2.542, contrastive_loss=0, total=4202.52, n_correct=2903.85, ppl=3.89, accuracy=69.098, wps=13617.5, ups=1.62, wpb=8405, bsz=318.8, num_updates=42900, lr=6.82789e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=1202
2023-09-03 18:33:41 | INFO | train_inner | epoch 030:    270 / 1474 loss=1.881, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.626, task_loss=0.867, task_loss_gen=2.735, contrastive_loss=0, total=4116.51, n_correct=2836.76, ppl=3.95, accuracy=68.912, wps=13345.9, ups=1.62, wpb=8233, bsz=296.1, num_updates=43000, lr=6.81994e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=1263
2023-09-03 18:34:44 | INFO | train_inner | epoch 030:    370 / 1474 loss=1.873, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.616, task_loss=0.852, task_loss_gen=2.642, contrastive_loss=0, total=4173, n_correct=2879.33, ppl=3.92, accuracy=68.999, wps=13158.2, ups=1.58, wpb=8346, bsz=305.9, num_updates=43100, lr=6.81203e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=63, gb_free=11.7, wall=1327
2023-09-03 18:35:46 | INFO | train_inner | epoch 030:    470 / 1474 loss=1.876, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.618, task_loss=0.856, task_loss_gen=2.524, contrastive_loss=0, total=4126.49, n_correct=2838.23, ppl=3.94, accuracy=68.781, wps=13331.5, ups=1.62, wpb=8253, bsz=311, num_updates=43200, lr=6.80414e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=1389
2023-09-03 18:36:48 | INFO | train_inner | epoch 030:    570 / 1474 loss=1.879, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.623, task_loss=0.792, task_loss_gen=2.576, contrastive_loss=0, total=4171.17, n_correct=2870.41, ppl=3.95, accuracy=68.815, wps=13486.4, ups=1.62, wpb=8342.3, bsz=313.5, num_updates=43300, lr=6.79628e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=1451
2023-09-03 18:37:50 | INFO | train_inner | epoch 030:    670 / 1474 loss=1.878, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.624, task_loss=0.723, task_loss_gen=2.718, contrastive_loss=0, total=4194.82, n_correct=2884.72, ppl=3.94, accuracy=68.769, wps=13442.2, ups=1.6, wpb=8389.6, bsz=316.8, num_updates=43400, lr=6.78844e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=62, gb_free=14.7, wall=1513
2023-09-03 18:38:53 | INFO | train_inner | epoch 030:    770 / 1474 loss=1.885, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.629, task_loss=0.634, task_loss_gen=3.247, contrastive_loss=0, total=4089.14, n_correct=2805.92, ppl=3.96, accuracy=68.619, wps=13125.3, ups=1.6, wpb=8178.3, bsz=298.9, num_updates=43500, lr=6.78064e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=62, gb_free=17.4, wall=1575
2023-09-03 18:39:55 | INFO | train_inner | epoch 030:    870 / 1474 loss=1.881, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.621, task_loss=0.656, task_loss_gen=3.435, contrastive_loss=0, total=4096.41, n_correct=2816.55, ppl=3.95, accuracy=68.757, wps=13075.7, ups=1.6, wpb=8192.8, bsz=291.9, num_updates=43600, lr=6.77285e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=62, gb_free=16.4, wall=1638
2023-09-03 18:40:57 | INFO | train_inner | epoch 030:    970 / 1474 loss=1.882, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.628, task_loss=0.654, task_loss_gen=3.175, contrastive_loss=0, total=4149.69, n_correct=2851.87, ppl=3.96, accuracy=68.725, wps=13418.5, ups=1.62, wpb=8299.4, bsz=307.3, num_updates=43700, lr=6.7651e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=1700
2023-09-03 18:42:00 | INFO | train_inner | epoch 030:   1070 / 1474 loss=1.89, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.627, task_loss=0.733, task_loss_gen=3.499, contrastive_loss=0, total=4099.16, n_correct=2808.28, ppl=3.98, accuracy=68.509, wps=13097.8, ups=1.6, wpb=8198.3, bsz=281.9, num_updates=43800, lr=6.75737e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=62, gb_free=14.2, wall=1762
2023-09-03 18:43:02 | INFO | train_inner | epoch 030:   1170 / 1474 loss=1.878, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.622, task_loss=0.628, task_loss_gen=3.072, contrastive_loss=0, total=4168.48, n_correct=2866.32, ppl=3.95, accuracy=68.762, wps=13469.6, ups=1.62, wpb=8337, bsz=314.7, num_updates=43900, lr=6.74967e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=1824
2023-09-03 18:44:04 | INFO | train_inner | epoch 030:   1270 / 1474 loss=1.889, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.635, task_loss=0.64, task_loss_gen=3.634, contrastive_loss=0, total=4021.73, n_correct=2760.51, ppl=3.96, accuracy=68.64, wps=12915.6, ups=1.61, wpb=8043.5, bsz=280.6, num_updates=44000, lr=6.742e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=62, gb_free=14.4, wall=1887
2023-09-03 18:44:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 18:44:37 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.165 | nll_loss 2.423 | w2v_ctc_loss 1.314 | task_loss 5.198 | task_loss_gen 6.272 | contrastive_loss 0 | total 4003.4 | n_correct 2676.8 | ppl 5.36 | accuracy 66.863 | uer 17.028 | wer 18.799 | raw_wer 18.799 | bleu 22.48 | wps 1606.8 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.61
2023-09-03 18:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-09-03 18:44:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-09-03 18:44:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-09-03 18:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.48) (writing took 10.03796547598904 seconds)
--Backword ST Loss tensor(1013.4023, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(574.2368, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 18:45:50 | INFO | train_inner | epoch 030:   1370 / 1474 loss=1.872, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.613, task_loss=0.552, task_loss_gen=3.081, contrastive_loss=0, total=4164.94, n_correct=2871.16, ppl=3.95, accuracy=68.936, wps=7845.1, ups=0.94, wpb=8329.9, bsz=320.3, num_updates=44100, lr=6.73435e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=1993
2023-09-03 18:46:52 | INFO | train_inner | epoch 030:   1470 / 1474 loss=1.879, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.617, task_loss=0.593, task_loss_gen=3.161, contrastive_loss=0, total=4128.4, n_correct=2836.25, ppl=3.97, accuracy=68.701, wps=13428.8, ups=1.63, wpb=8256.8, bsz=311.6, num_updates=44200, lr=6.72673e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=2054
2023-09-03 18:46:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1810.8180, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1078.4268, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1114.2871, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(694.3904, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1257.7107, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(797.6182, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1224.2916, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(590.9529, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1707.7026, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1033.1437, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1755.8547, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1019.3049, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1692.8394, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1032.9698, device='cuda:6', grad_fn=<MulBackward0>)
2023-09-03 18:47:27 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.872 | trans_loss 5.159 | nll_loss 2.416 | w2v_ctc_loss 1.281 | task_loss 3.903 | task_loss_gen 6.471 | contrastive_loss 0 | total 4003.4 | n_correct 2680.1 | ppl 5.34 | accuracy 66.946 | uer 17.049 | wer 18.806 | raw_wer 18.806 | bleu 22.38 | wps 1632.8 | wpb 4003.4 | bsz 141.8 | num_updates 44204 | best_bleu 22.61
2023-09-03 18:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44204 updates
2023-09-03 18:47:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt
2023-09-03 18:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt
2023-09-03 18:47:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt (epoch 30 @ 44204 updates, score 22.38) (writing took 9.268279461015482 seconds)
2023-09-03 18:47:36 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-03 18:47:36 | INFO | train | epoch 030 | loss 1.879 | trans_loss 4.777 | nll_loss 1.981 | w2v_ctc_loss 0.622 | task_loss 0.712 | task_loss_gen 2.97 | contrastive_loss 0 | total 4138.65 | n_correct 2846.93 | ppl 3.95 | accuracy 68.789 | wps 12094.1 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 44204 | lr 6.72642e-05 | gnorm 0.518 | clip 0 | loss_scale 32 | train_wall 906 | gb_free 16.8 | wall 2099
2023-09-03 18:47:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 18:47:36 | INFO | fairseq.trainer | begin training epoch 31
2023-09-03 18:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 18:47:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-03 18:48:43 | INFO | train_inner | epoch 031:     97 / 1474 loss=1.876, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.622, task_loss=0.643, task_loss_gen=3.221, contrastive_loss=0, total=4080.96, n_correct=2819.59, ppl=3.91, accuracy=69.091, wps=7346.3, ups=0.9, wpb=8161.9, bsz=295.1, num_updates=44300, lr=6.71913e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=61, gb_free=13.1, wall=2165
2023-09-03 18:49:45 | INFO | train_inner | epoch 031:    197 / 1474 loss=1.872, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.615, task_loss=0.674, task_loss_gen=3.067, contrastive_loss=0, total=4143.18, n_correct=2863.18, ppl=3.9, accuracy=69.106, wps=13378.4, ups=1.61, wpb=8286.4, bsz=301.1, num_updates=44400, lr=6.71156e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=2227
2023-09-03 18:50:47 | INFO | train_inner | epoch 031:    297 / 1474 loss=1.873, trans_loss=4.763, nll_loss=1.961, w2v_ctc_loss=0.616, task_loss=0.672, task_loss_gen=3.019, contrastive_loss=0, total=4154.03, n_correct=2869.33, ppl=3.89, accuracy=69.073, wps=13289.7, ups=1.6, wpb=8308.1, bsz=301.5, num_updates=44500, lr=6.70402e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=62, gb_free=16, wall=2290
2023-09-03 18:51:50 | INFO | train_inner | epoch 031:    397 / 1474 loss=1.881, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.622, task_loss=0.71, task_loss_gen=3.248, contrastive_loss=0, total=4079.78, n_correct=2808.27, ppl=3.94, accuracy=68.834, wps=13049.6, ups=1.6, wpb=8159.6, bsz=284.9, num_updates=44600, lr=6.6965e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=62, gb_free=15.4, wall=2352
2023-09-03 18:52:52 | INFO | train_inner | epoch 031:    497 / 1474 loss=1.875, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.624, task_loss=0.788, task_loss_gen=2.942, contrastive_loss=0, total=4122.36, n_correct=2846.99, ppl=3.91, accuracy=69.062, wps=13236.8, ups=1.61, wpb=8244.7, bsz=302, num_updates=44700, lr=6.689e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=62, gb_free=16.3, wall=2415
2023-09-03 18:53:54 | INFO | train_inner | epoch 031:    597 / 1474 loss=1.871, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.611, task_loss=0.768, task_loss_gen=2.987, contrastive_loss=0, total=4082.24, n_correct=2818.41, ppl=3.9, accuracy=69.041, wps=13241, ups=1.62, wpb=8164.5, bsz=294.3, num_updates=44800, lr=6.68153e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=2476
2023-09-03 18:54:55 | INFO | train_inner | epoch 031:    697 / 1474 loss=1.866, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.607, task_loss=0.704, task_loss_gen=2.764, contrastive_loss=0, total=4207.46, n_correct=2911.38, ppl=3.9, accuracy=69.196, wps=13758.1, ups=1.63, wpb=8414.9, bsz=313.6, num_updates=44900, lr=6.67409e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=2537
2023-09-03 18:55:57 | INFO | train_inner | epoch 031:    797 / 1474 loss=1.873, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.612, task_loss=0.841, task_loss_gen=2.888, contrastive_loss=0, total=4102.27, n_correct=2827.12, ppl=3.92, accuracy=68.916, wps=13182.7, ups=1.61, wpb=8204.5, bsz=297.2, num_updates=45000, lr=6.66667e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=62, gb_free=15.5, wall=2600
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
2023-09-03 18:56:59 | INFO | train_inner | epoch 031:    897 / 1474 loss=1.873, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.618, task_loss=0.796, task_loss_gen=2.961, contrastive_loss=0, total=4102.53, n_correct=2832.76, ppl=3.89, accuracy=69.049, wps=13313.7, ups=1.62, wpb=8205.1, bsz=297, num_updates=45100, lr=6.65927e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=2661
2023-09-03 18:57:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 18:58:02 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.873, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.613, task_loss=0.69, task_loss_gen=2.704, contrastive_loss=0, total=4183.08, n_correct=2884.47, ppl=3.94, accuracy=68.956, wps=13248.8, ups=1.58, wpb=8366.2, bsz=317.5, num_updates=45200, lr=6.6519e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=63, gb_free=16, wall=2724
2023-09-03 18:59:04 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.874, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.616, task_loss=0.879, task_loss_gen=2.574, contrastive_loss=0, total=4147.34, n_correct=2859.49, ppl=3.93, accuracy=68.948, wps=13472.5, ups=1.62, wpb=8294.7, bsz=314.6, num_updates=45300, lr=6.64455e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=61, gb_free=16.9, wall=2786
2023-09-03 19:00:05 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.872, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.613, task_loss=0.809, task_loss_gen=2.359, contrastive_loss=0, total=4185.34, n_correct=2880.49, ppl=3.94, accuracy=68.823, wps=13698.5, ups=1.64, wpb=8370.7, bsz=321.6, num_updates=45400, lr=6.63723e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=2847
2023-09-03 19:01:06 | INFO | train_inner | epoch 031:   1298 / 1474 loss=1.874, trans_loss=4.778, nll_loss=1.983, w2v_ctc_loss=0.617, task_loss=0.85, task_loss_gen=2.34, contrastive_loss=0, total=4223.54, n_correct=2909.9, ppl=3.95, accuracy=68.897, wps=13802.8, ups=1.63, wpb=8447.1, bsz=325, num_updates=45500, lr=6.62994e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=60, gb_free=13.2, wall=2908
2023-09-03 19:02:08 | INFO | train_inner | epoch 031:   1398 / 1474 loss=1.874, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.613, task_loss=0.897, task_loss_gen=2.299, contrastive_loss=0, total=4195.76, n_correct=2887.66, ppl=3.94, accuracy=68.823, wps=13454.7, ups=1.6, wpb=8391.5, bsz=328.2, num_updates=45600, lr=6.62266e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=62, gb_free=16.2, wall=2971
2023-09-03 19:02:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
mt_weight tensor(0.5000)
asr_weight tensor(0.2122)
2023-09-03 19:03:28 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.882 | trans_loss 5.166 | nll_loss 2.422 | w2v_ctc_loss 1.299 | task_loss 12.835 | task_loss_gen 7.744 | contrastive_loss 0 | total 4003.4 | n_correct 2677.5 | ppl 5.36 | accuracy 66.881 | uer 16.895 | wer 18.784 | raw_wer 18.784 | bleu 22.38 | wps 1645.6 | wpb 4003.4 | bsz 141.8 | num_updates 45676 | best_bleu 22.61
2023-09-03 19:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45676 updates
2023-09-03 19:03:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt
2023-09-03 19:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt
2023-09-03 19:03:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.3804.pt (epoch 31 @ 45676 updates, score 22.38) (writing took 13.014730176015291 seconds)
2023-09-03 19:03:41 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-03 19:03:41 | INFO | train | epoch 031 | loss 1.873 | trans_loss 4.769 | nll_loss 1.97 | w2v_ctc_loss 0.616 | task_loss 0.786 | task_loss_gen 2.797 | contrastive_loss 0 | total 4138.38 | n_correct 2854.86 | ppl 3.92 | accuracy 68.985 | wps 12627.3 | ups 1.53 | wpb 8276.8 | bsz 305.6 | num_updates 45676 | lr 6.61715e-05 | gnorm 0.532 | clip 0 | loss_scale 8 | train_wall 903 | gb_free 11.7 | wall 3063
2023-09-03 19:03:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 19:03:41 | INFO | fairseq.trainer | begin training epoch 32
2023-09-03 19:03:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 19:04:03 | INFO | train_inner | epoch 032:     24 / 1474 loss=1.872, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.613, task_loss=1.137, task_loss_gen=2.671, contrastive_loss=0, total=4039.04, n_correct=2790.42, ppl=3.9, accuracy=69.086, wps=7069.3, ups=0.88, wpb=8078.1, bsz=287.3, num_updates=45700, lr=6.61541e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=61, gb_free=17.4, wall=3085
2023-09-03 19:05:04 | INFO | train_inner | epoch 032:    124 / 1474 loss=1.855, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.596, task_loss=1.035, task_loss_gen=2.298, contrastive_loss=0, total=4224.84, n_correct=2934.54, ppl=3.84, accuracy=69.459, wps=13790.3, ups=1.63, wpb=8449.7, bsz=322.5, num_updates=45800, lr=6.60819e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=3146
2023-09-03 19:06:06 | INFO | train_inner | epoch 032:    224 / 1474 loss=1.865, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.608, task_loss=0.965, task_loss_gen=2.338, contrastive_loss=0, total=4163.01, n_correct=2878.66, ppl=3.9, accuracy=69.149, wps=13480.3, ups=1.62, wpb=8326, bsz=322.2, num_updates=45900, lr=6.60098e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=16.9, wall=3208
2023-09-03 19:07:07 | INFO | train_inner | epoch 032:    324 / 1474 loss=1.861, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.603, task_loss=1.066, task_loss_gen=2.34, contrastive_loss=0, total=4185.21, n_correct=2904.23, ppl=3.86, accuracy=69.393, wps=13717.3, ups=1.64, wpb=8370.4, bsz=315.1, num_updates=46000, lr=6.5938e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=60, gb_free=16, wall=3269
2023-09-03 19:07:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 19:07:40 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.165 | nll_loss 2.425 | w2v_ctc_loss 1.336 | task_loss 9.189 | task_loss_gen 6.777 | contrastive_loss 0 | total 4003.4 | n_correct 2678.2 | ppl 5.37 | accuracy 66.898 | uer 16.858 | wer 18.638 | raw_wer 18.638 | bleu 22.59 | wps 1592.1 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.61
2023-09-03 19:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-09-03 19:07:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-09-03 19:07:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-09-03 19:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.59) (writing took 10.314203586953226 seconds)
--Backword ST Loss tensor(843.1224, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(477.4152, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 19:08:53 | INFO | train_inner | epoch 032:    424 / 1474 loss=1.863, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.604, task_loss=1.077, task_loss_gen=2.536, contrastive_loss=0, total=4156.71, n_correct=2881.76, ppl=3.86, accuracy=69.328, wps=7784.2, ups=0.94, wpb=8313.4, bsz=305.7, num_updates=46100, lr=6.58665e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=61, gb_free=10.3, wall=3376
2023-09-03 19:09:56 | INFO | train_inner | epoch 032:    524 / 1474 loss=1.875, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.619, task_loss=1.195, task_loss_gen=2.336, contrastive_loss=0, total=4195.32, n_correct=2891.82, ppl=3.92, accuracy=68.93, wps=13339.4, ups=1.59, wpb=8390.6, bsz=318.2, num_updates=46200, lr=6.57952e-05, gnorm=0.576, clip=0, loss_scale=8, train_wall=62, gb_free=16.2, wall=3439
2023-09-03 19:10:58 | INFO | train_inner | epoch 032:    624 / 1474 loss=1.876, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.617, task_loss=1.226, task_loss_gen=2.447, contrastive_loss=0, total=4141.99, n_correct=2853.75, ppl=3.92, accuracy=68.898, wps=13373.9, ups=1.61, wpb=8284, bsz=300.9, num_updates=46300, lr=6.57241e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=3501
2023-09-03 19:12:00 | INFO | train_inner | epoch 032:    724 / 1474 loss=1.877, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.623, task_loss=1.135, task_loss_gen=2.492, contrastive_loss=0, total=4153.97, n_correct=2865.59, ppl=3.92, accuracy=68.984, wps=13448, ups=1.62, wpb=8307.9, bsz=301.5, num_updates=46400, lr=6.56532e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=16.8, wall=3563
2023-09-03 19:13:01 | INFO | train_inner | epoch 032:    824 / 1474 loss=1.869, trans_loss=4.764, nll_loss=1.962, w2v_ctc_loss=0.608, task_loss=1.131, task_loss_gen=2.5, contrastive_loss=0, total=4119.08, n_correct=2845.24, ppl=3.9, accuracy=69.075, wps=13512.5, ups=1.64, wpb=8238.2, bsz=295.1, num_updates=46500, lr=6.55826e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=60, gb_free=16.5, wall=3624
2023-09-03 19:14:03 | INFO | train_inner | epoch 032:    924 / 1474 loss=1.869, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.608, task_loss=1.117, task_loss_gen=2.42, contrastive_loss=0, total=4142.37, n_correct=2864.01, ppl=3.9, accuracy=69.139, wps=13454.1, ups=1.62, wpb=8284.7, bsz=299.1, num_updates=46600, lr=6.55122e-05, gnorm=0.576, clip=0, loss_scale=8, train_wall=61, gb_free=15.2, wall=3685
2023-09-03 19:15:05 | INFO | train_inner | epoch 032:   1024 / 1474 loss=1.873, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.613, task_loss=0.986, task_loss_gen=2.494, contrastive_loss=0, total=4112.12, n_correct=2835.54, ppl=3.92, accuracy=68.956, wps=13262.3, ups=1.61, wpb=8224.2, bsz=302.5, num_updates=46700, lr=6.5442e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=61, gb_free=16.4, wall=3747
2023-09-03 19:16:07 | INFO | train_inner | epoch 032:   1124 / 1474 loss=1.883, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.624, task_loss=1.23, task_loss_gen=2.871, contrastive_loss=0, total=4022.64, n_correct=2765.93, ppl=3.92, accuracy=68.759, wps=12993.6, ups=1.62, wpb=8045.3, bsz=273.1, num_updates=46800, lr=6.5372e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=61, gb_free=10.8, wall=3809
2023-09-03 19:17:09 | INFO | train_inner | epoch 032:   1224 / 1474 loss=1.882, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.623, task_loss=1.167, task_loss_gen=2.54, contrastive_loss=0, total=4145.44, n_correct=2846.18, ppl=3.96, accuracy=68.658, wps=13299.9, ups=1.6, wpb=8290.9, bsz=308.7, num_updates=46900, lr=6.53023e-05, gnorm=0.577, clip=0, loss_scale=8, train_wall=62, gb_free=16.9, wall=3871
2023-09-03 19:18:10 | INFO | train_inner | epoch 032:   1324 / 1474 loss=1.872, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.614, task_loss=1.119, task_loss_gen=2.363, contrastive_loss=0, total=4083.72, n_correct=2817.77, ppl=3.9, accuracy=69, wps=13388.6, ups=1.64, wpb=8167.4, bsz=297.1, num_updates=47000, lr=6.52328e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=60, gb_free=15.4, wall=3932
2023-09-03 19:19:11 | INFO | train_inner | epoch 032:   1424 / 1474 loss=1.875, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.616, task_loss=1.005, task_loss_gen=2.427, contrastive_loss=0, total=4105.33, n_correct=2833.84, ppl=3.92, accuracy=69.028, wps=13414.7, ups=1.63, wpb=8210.7, bsz=305.7, num_updates=47100, lr=6.51635e-05, gnorm=0.564, clip=0, loss_scale=8, train_wall=61, gb_free=16.1, wall=3994
2023-09-03 19:19:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(826.3332, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(480.2854, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1210.0983, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(747.1971, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1435.7939, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(792.6884, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1355.9395, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(768.5167, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1345.3542, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(804.0662, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1001.7502, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(592.9568, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1882.7588, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1128.1919, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-03 19:20:15 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.889 | trans_loss 5.163 | nll_loss 2.42 | w2v_ctc_loss 1.329 | task_loss 9.656 | task_loss_gen 7.119 | contrastive_loss 0 | total 4003.4 | n_correct 2678.4 | ppl 5.35 | accuracy 66.903 | uer 16.978 | wer 18.814 | raw_wer 18.814 | bleu 22.62 | wps 1582.1 | wpb 4003.4 | bsz 141.8 | num_updates 47150 | best_bleu 22.62
2023-09-03 19:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47150 updates
2023-09-03 19:20:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 19:20:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-03 19:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_best.pt (epoch 32 @ 47150 updates, score 22.62) (writing took 11.89845856098691 seconds)
2023-09-03 19:20:27 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-03 19:20:27 | INFO | train | epoch 032 | loss 1.871 | trans_loss 4.765 | nll_loss 1.965 | w2v_ctc_loss 0.612 | task_loss 1.096 | task_loss_gen 2.442 | contrastive_loss 0 | total 4138.65 | n_correct 2857.98 | ppl 3.9 | accuracy 69.056 | wps 12123.5 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 47150 | lr 6.5129e-05 | gnorm 0.56 | clip 0 | loss_scale 8 | train_wall 898 | gb_free 16 | wall 4070
2023-09-03 19:20:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 19:20:28 | INFO | fairseq.trainer | begin training epoch 33
2023-09-03 19:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 19:21:06 | INFO | train_inner | epoch 033:     50 / 1474 loss=1.872, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.615, task_loss=0.993, task_loss_gen=2.278, contrastive_loss=0, total=4161.67, n_correct=2871.83, ppl=3.92, accuracy=69.007, wps=7220.4, ups=0.87, wpb=8323.3, bsz=322.6, num_updates=47200, lr=6.50945e-05, gnorm=0.573, clip=0, loss_scale=8, train_wall=62, gb_free=17.5, wall=4109
2023-09-03 19:22:08 | INFO | train_inner | epoch 033:    150 / 1474 loss=1.859, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.594, task_loss=1.261, task_loss_gen=2.53, contrastive_loss=0, total=4067.33, n_correct=2822.04, ppl=3.83, accuracy=69.383, wps=13290.7, ups=1.63, wpb=8134.7, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=4170
2023-09-03 19:22:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-03 19:23:10 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.857, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.604, task_loss=0.951, task_loss_gen=2.154, contrastive_loss=0, total=4257.02, n_correct=2958.66, ppl=3.83, accuracy=69.501, wps=13664.3, ups=1.6, wpb=8514, bsz=337.3, num_updates=47400, lr=6.4957e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=62, gb_free=16.1, wall=4232
2023-09-03 19:24:11 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.868, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.609, task_loss=1.252, task_loss_gen=2.438, contrastive_loss=0, total=4111.69, n_correct=2849.57, ppl=3.87, accuracy=69.304, wps=13437, ups=1.63, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=4294
2023-09-03 19:25:12 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.856, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.598, task_loss=1.125, task_loss_gen=2.243, contrastive_loss=0, total=4147.28, n_correct=2883.71, ppl=3.84, accuracy=69.533, wps=13695, ups=1.65, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=4354
2023-09-03 19:26:13 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.873, trans_loss=4.761, nll_loss=1.958, w2v_ctc_loss=0.616, task_loss=1.238, task_loss_gen=2.433, contrastive_loss=0, total=4127.68, n_correct=2851.32, ppl=3.88, accuracy=69.078, wps=13367.8, ups=1.62, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=61, gb_free=15.2, wall=4416
2023-09-03 19:27:16 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.869, trans_loss=4.767, nll_loss=1.966, w2v_ctc_loss=0.605, task_loss=1.174, task_loss_gen=2.391, contrastive_loss=0, total=4164.1, n_correct=2879.3, ppl=3.91, accuracy=69.146, wps=13339.1, ups=1.6, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=62, gb_free=15, wall=4478
2023-09-03 19:28:18 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.88, trans_loss=4.765, nll_loss=1.964, w2v_ctc_loss=0.627, task_loss=1.287, task_loss_gen=2.466, contrastive_loss=0, total=4064.29, n_correct=2801.55, ppl=3.9, accuracy=68.931, wps=13166, ups=1.62, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=4540
2023-09-03 19:29:19 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.857, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.596, task_loss=0.944, task_loss_gen=2.259, contrastive_loss=0, total=4141.12, n_correct=2874.69, ppl=3.86, accuracy=69.418, wps=13490.8, ups=1.63, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=61, gb_free=16.2, wall=4601
2023-09-03 19:29:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 19:29:53 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.169 | nll_loss 2.426 | w2v_ctc_loss 1.347 | task_loss 10.95 | task_loss_gen 6.848 | contrastive_loss 0 | total 4003.4 | n_correct 2676 | ppl 5.37 | accuracy 66.843 | uer 17.225 | wer 18.959 | raw_wer 18.959 | bleu 22.35 | wps 1577.2 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.62
2023-09-03 19:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-09-03 19:29:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-09-03 19:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-09-03 19:30:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.35) (writing took 8.131690483016428 seconds)
--Backword ST Loss tensor(1267.9963, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(800.3627, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-03 19:31:02 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.87, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.614, task_loss=0.983, task_loss_gen=2.409, contrastive_loss=0, total=4147.76, n_correct=2869.54, ppl=3.89, accuracy=69.183, wps=8050.9, ups=0.97, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=60, gb_free=17.3, wall=4705
2023-09-03 19:32:04 | INFO | train_inner | epoch 033:   1051 / 1474 loss=1.872, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.615, task_loss=0.889, task_loss_gen=2.462, contrastive_loss=0, total=4137.41, n_correct=2856.83, ppl=3.89, accuracy=69.049, wps=13320.6, ups=1.61, wpb=8274.8, bsz=307.9, num_updates=48200, lr=6.44157e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=62, gb_free=15.5, wall=4767
2023-09-03 19:33:07 | INFO | train_inner | epoch 033:   1151 / 1474 loss=1.867, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.602, task_loss=0.93, task_loss_gen=2.411, contrastive_loss=0, total=4182.88, n_correct=2888.65, ppl=3.9, accuracy=69.059, wps=13418.7, ups=1.6, wpb=8365.8, bsz=308.6, num_updates=48300, lr=6.43489e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=62, gb_free=16, wall=4829
2023-09-03 19:34:08 | INFO | train_inner | epoch 033:   1251 / 1474 loss=1.873, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.616, task_loss=0.98, task_loss_gen=2.513, contrastive_loss=0, total=4102.27, n_correct=2834.07, ppl=3.88, accuracy=69.085, wps=13385.5, ups=1.63, wpb=8204.5, bsz=291.8, num_updates=48400, lr=6.42824e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=61, gb_free=15.4, wall=4890
2023-09-03 19:35:10 | INFO | train_inner | epoch 033:   1351 / 1474 loss=1.864, trans_loss=4.759, nll_loss=1.957, w2v_ctc_loss=0.61, task_loss=0.862, task_loss_gen=2.329, contrastive_loss=0, total=4131.08, n_correct=2860.54, ppl=3.88, accuracy=69.244, wps=13351.4, ups=1.62, wpb=8262.2, bsz=313.9, num_updates=48500, lr=6.42161e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=61, gb_free=16.9, wall=4952
2023-09-03 19:36:11 | INFO | train_inner | epoch 033:   1451 / 1474 loss=1.868, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.606, task_loss=0.917, task_loss_gen=2.354, contrastive_loss=0, total=4135.49, n_correct=2852.77, ppl=3.9, accuracy=68.983, wps=13405.6, ups=1.62, wpb=8271, bsz=310.7, num_updates=48600, lr=6.415e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=61, gb_free=15.8, wall=5014
2023-09-03 19:36:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(925.8334, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(574.8387, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1011.9528, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(582.4977, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(833.9850, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(513.5209, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1258.0005, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(764.1013, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1335.1835, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(747.4631, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(904.0477, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(542.4778, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1516.5345, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(944.9993, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-03 19:36:59 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.883 | trans_loss 5.165 | nll_loss 2.422 | w2v_ctc_loss 1.303 | task_loss 9.699 | task_loss_gen 6.401 | contrastive_loss 0 | total 4003.4 | n_correct 2677.3 | ppl 5.36 | accuracy 66.876 | uer 16.887 | wer 18.646 | raw_wer 18.646 | bleu 22.47 | wps 1528.3 | wpb 4003.4 | bsz 141.8 | num_updates 48623 | best_bleu 22.62
2023-09-03 19:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48623 updates
2023-09-03 19:36:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4707.pt
2023-09-03 19:37:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4707.pt
2023-09-03 19:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint.best_bleu_22.4707.pt (epoch 33 @ 48623 updates, score 22.47) (writing took 7.43602971296059 seconds)
2023-09-03 19:37:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-03 19:37:07 | INFO | train | epoch 033 | loss 1.867 | trans_loss 4.758 | nll_loss 1.955 | w2v_ctc_loss 0.608 | task_loss 1.051 | task_loss_gen 2.385 | contrastive_loss 0 | total 4136.82 | n_correct 2863 | ppl 3.88 | accuracy 69.208 | wps 12190.5 | ups 1.47 | wpb 8273.6 | bsz 305 | num_updates 48623 | lr 6.41349e-05 | gnorm 0.55 | clip 0 | loss_scale 8 | train_wall 899 | gb_free 17.5 | wall 5070
2023-09-03 19:37:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-03 19:37:07 | INFO | fairseq.trainer | begin training epoch 34
2023-09-03 19:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-03 19:38:02 | INFO | train_inner | epoch 034:     77 / 1474 loss=1.861, trans_loss=4.747, nll_loss=1.94, w2v_ctc_loss=0.605, task_loss=0.981, task_loss_gen=2.363, contrastive_loss=0, total=4122.67, n_correct=2863.44, ppl=3.84, accuracy=69.456, wps=7438.1, ups=0.9, wpb=8245.3, bsz=301.4, num_updates=48700, lr=6.40841e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=61, gb_free=17.3, wall=5125
2023-09-03 19:39:04 | INFO | train_inner | epoch 034:    177 / 1474 loss=1.86, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.607, task_loss=0.969, task_loss_gen=2.534, contrastive_loss=0, total=4074.94, n_correct=2836.97, ppl=3.81, accuracy=69.62, wps=13119.2, ups=1.61, wpb=8149.9, bsz=295.4, num_updates=48800, lr=6.40184e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=62, gb_free=16.7, wall=5187
2023-09-03 19:40:07 | INFO | train_inner | epoch 034:    277 / 1474 loss=1.861, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.598, task_loss=0.83, task_loss_gen=2.309, contrastive_loss=0, total=4228.22, n_correct=2928.79, ppl=3.86, accuracy=69.268, wps=13611.6, ups=1.61, wpb=8456.4, bsz=324.6, num_updates=48900, lr=6.39529e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=5249
2023-09-03 19:41:08 | INFO | train_inner | epoch 034:    377 / 1474 loss=1.853, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.597, task_loss=0.854, task_loss_gen=2.213, contrastive_loss=0, total=4173.35, n_correct=2903.93, ppl=3.82, accuracy=69.583, wps=13562, ups=1.62, wpb=8346.7, bsz=320.5, num_updates=49000, lr=6.38877e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=61, gb_free=16, wall=5311
2023-09-03 19:42:09 | INFO | train_inner | epoch 034:    477 / 1474 loss=1.866, trans_loss=4.748, nll_loss=1.942, w2v_ctc_loss=0.61, task_loss=1.009, task_loss_gen=2.669, contrastive_loss=0, total=4066.67, n_correct=2823.67, ppl=3.84, accuracy=69.434, wps=13246.9, ups=1.63, wpb=8133.3, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=5372
2023-09-03 19:43:10 | INFO | train_inner | epoch 034:    577 / 1474 loss=1.854, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.596, task_loss=0.933, task_loss_gen=2.45, contrastive_loss=0, total=4115.49, n_correct=2867.42, ppl=3.8, accuracy=69.674, wps=13535.6, ups=1.64, wpb=8231, bsz=299.4, num_updates=49200, lr=6.37577e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=60, gb_free=14.5, wall=5433
2023-09-03 19:44:12 | INFO | train_inner | epoch 034:    677 / 1474 loss=1.86, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.602, task_loss=0.932, task_loss_gen=2.399, contrastive_loss=0, total=4124.78, n_correct=2865.72, ppl=3.84, accuracy=69.476, wps=13369.9, ups=1.62, wpb=8249.6, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=61, gb_free=11.2, wall=5494
2023-09-03 19:45:13 | INFO | train_inner | epoch 034:    777 / 1474 loss=1.861, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.592, task_loss=0.921, task_loss_gen=2.467, contrastive_loss=0, total=4082.25, n_correct=2828.03, ppl=3.89, accuracy=69.276, wps=13315, ups=1.63, wpb=8164.5, bsz=296, num_updates=49400, lr=6.36285e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=5556
2023-09-03 19:46:15 | INFO | train_inner | epoch 034:    877 / 1474 loss=1.866, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.606, task_loss=0.847, task_loss_gen=2.63, contrastive_loss=0, total=4110.66, n_correct=2850.5, ppl=3.87, accuracy=69.344, wps=13322.8, ups=1.62, wpb=8221.3, bsz=296.1, num_updates=49500, lr=6.35642e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=5618
2023-09-03 19:47:16 | INFO | train_inner | epoch 034:    977 / 1474 loss=1.865, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.612, task_loss=0.746, task_loss_gen=2.605, contrastive_loss=0, total=4162.47, n_correct=2883.9, ppl=3.87, accuracy=69.283, wps=13543.7, ups=1.63, wpb=8324.9, bsz=312.5, num_updates=49600, lr=6.35001e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=61, gb_free=12.8, wall=5679
2023-09-03 19:48:17 | INFO | train_inner | epoch 034:   1077 / 1474 loss=1.862, trans_loss=4.749, nll_loss=1.943, w2v_ctc_loss=0.609, task_loss=0.714, task_loss_gen=2.628, contrastive_loss=0, total=4151.58, n_correct=2881.35, ppl=3.85, accuracy=69.404, wps=13648, ups=1.64, wpb=8303.2, bsz=308, num_updates=49700, lr=6.34361e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=5740
2023-09-03 19:49:20 | INFO | train_inner | epoch 034:   1177 / 1474 loss=1.86, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.603, task_loss=0.755, task_loss_gen=2.725, contrastive_loss=0, total=4091.98, n_correct=2842.31, ppl=3.85, accuracy=69.461, wps=13108.1, ups=1.6, wpb=8184, bsz=297.4, num_updates=49800, lr=6.33724e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=62, gb_free=16.9, wall=5802
2023-09-03 19:50:21 | INFO | train_inner | epoch 034:   1277 / 1474 loss=1.857, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.597, task_loss=0.734, task_loss_gen=2.685, contrastive_loss=0, total=4162.83, n_correct=2893.32, ppl=3.83, accuracy=69.504, wps=13601.4, ups=1.63, wpb=8325.7, bsz=301.1, num_updates=49900, lr=6.33089e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=5863
2023-09-03 19:51:23 | INFO | train_inner | epoch 034:   1377 / 1474 loss=1.865, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.612, task_loss=0.592, task_loss_gen=2.74, contrastive_loss=0, total=4187.24, n_correct=2897.02, ppl=3.87, accuracy=69.187, wps=13524.5, ups=1.61, wpb=8374.5, bsz=320.2, num_updates=50000, lr=6.32456e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=5925
2023-09-03 19:51:23 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-03 19:51:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-03 19:51:56 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.879 | trans_loss 5.169 | nll_loss 2.424 | w2v_ctc_loss 1.281 | task_loss 5.408 | task_loss_gen 5.466 | contrastive_loss 0 | total 4003.4 | n_correct 2670.9 | ppl 5.37 | accuracy 66.716 | uer 17.068 | wer 18.866 | raw_wer 18.866 | bleu 22.24 | wps 1595.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.62
2023-09-03 19:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-09-03 19:51:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-09-03 19:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-09-03 19:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v4_merge_wmt_0902_shrink_soft_noCL_AT_sentence_mixup_changeid_3_scale1_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.24) (writing took 7.442693910968956 seconds)
2023-09-03 19:52:04 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-03 19:52:04 | INFO | train | epoch 034 | loss 1.861 | trans_loss 4.748 | nll_loss 1.943 | w2v_ctc_loss 0.603 | task_loss 0.84 | task_loss_gen 2.531 | contrastive_loss 0 | total 4133.06 | n_correct 2869.48 | ppl 3.84 | accuracy 69.427 | wps 12692.3 | ups 1.54 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 839 | gb_free 16.8 | wall 5967
2023-09-03 19:52:04 | INFO | fairseq_cli.train | done training in 5899.4 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-9:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 256 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
