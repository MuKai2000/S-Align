sleep_train.sh: line 3: 51315 Terminated              sleep 3h
stage 1: ST Network Training
dev=0,1,2,3,4,5,6,7 data=data_all_ende_lcrm model=./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py data_all_ende_lcrm --config-yaml config_st.yaml --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml --task joint_triple_pretraining_merge --max-tokens 15000 --skip-invalid-size-inputs-valid-test --update-freq 1 --log-interval 100 --save-dir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5 --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5 --distributed-world-size 8 --ddp-backend no_c10d --fp16 --eval-bleu --eval-tokenized-bleu --eval-bleu-remove-bpe sentencepiece --best-checkpoint-metric bleu --keep-best-checkpoints 10 --maximize-best-checkpoint-metric
[34mRun command: 
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py
        data_all_ende_lcrm
        --config-yaml config_st.yaml
        --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml
        --task joint_triple_pretraining_merge
        --max-tokens 15000
        --skip-invalid-size-inputs-valid-test
        --update-freq 1
        --log-interval 100
        --save-dir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5
        --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5
        
        --distributed-world-size 8
        --ddp-backend no_c10d
        --fp16
        --eval-bleu
        --eval-tokenized-bleu
        --eval-bleu-remove-bpe sentencepiece
        --best-checkpoint-metric bleu
        --keep-best-checkpoints 10
        --maximize-best-checkpoint-metric
        --no-epoch-checkpoints
        --validate-interval 1 
        --save-interval 1 
        --keep-last-epochs 2 
        --save-interval-updates 2000
        --keep-interval-updates 5
        --share-decoder-input-output-embed
        --use-w2v-ctc [0m
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11353
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-15 01:26:44 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-15 01:26:44 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-15 01:26:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11353', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=True, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-15 01:26:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-15 01:26:48 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-15 01:26:53 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-15 01:26:53 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-15 01:26:53 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-15 01:26:56 | INFO | root | load pretrained hubert
2023-08-15 01:26:58 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-15 01:26:58 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-15 01:27:01 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-15 01:27:02 | INFO | root | share the sematic adapter and textual encoder
2023-08-15 01:27:02 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-15 01:27:02 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-15 01:27:02 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-15 01:27:02 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-15 01:27:02 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-15 01:27:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-15 01:27:02 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-15 01:27:02 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:27:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-15 01:27:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-15 01:27:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-15 01:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-15 01:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-15 01:27:08 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-15 01:27:08 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-15 01:27:08 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 01:27:08 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 01:27:08 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-15 01:27:08 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-15 01:27:08 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:08 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-15 01:27:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:27:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-15 01:28:00 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-15 01:28:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 01:28:00 | INFO | fairseq.trainer | begin training epoch 1
2023-08-15 01:28:00 | INFO | fairseq_cli.train | Start iterating over samples
None None None
2023-08-15 01:28:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
None None None
2023-08-15 01:28:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
None None None
2023-08-15 01:28:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 01:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
None None None
None None None
None None None
2023-08-15 01:29:22 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.046, trans_loss=5.871, nll_loss=4.679, w2v_ctc_loss=22.329, task_loss=1.768, contrastive_loss=3.272, total=4215.43, n_correct=123.12, ppl=25.61, accuracy=2.921, wps=18495.5, ups=1.47, wpb=12576.1, bsz=475.2, num_updates=100, lr=4.098e-06, gnorm=2.858, clip=0, loss_scale=8, train_wall=74, gb_free=18.6, wall=134
2023-08-15 01:29:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-15 01:30:28 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.574, trans_loss=5.85, nll_loss=4.678, w2v_ctc_loss=17.067, task_loss=1.713, contrastive_loss=3.233, total=4109.72, n_correct=115.54, ppl=25.59, accuracy=2.811, wps=18473.1, ups=1.51, wpb=12272.1, bsz=456.9, num_updates=200, lr=8.096e-06, gnorm=7.252, clip=18, loss_scale=4, train_wall=66, gb_free=19.4, wall=200
2023-08-15 01:31:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-15 01:31:33 | INFO | train_inner | epoch 001:    306 / 1474 loss=9.91, trans_loss=5.828, nll_loss=4.689, w2v_ctc_loss=6.887, task_loss=1.66, contrastive_loss=3.18, total=4081.87, n_correct=110.77, ppl=25.79, accuracy=2.714, wps=18688.3, ups=1.53, wpb=12194.5, bsz=440.2, num_updates=300, lr=1.2094e-05, gnorm=2.295, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=265
2023-08-15 01:32:38 | INFO | train_inner | epoch 001:    406 / 1474 loss=9.414, trans_loss=5.8, nll_loss=4.688, w2v_ctc_loss=6.118, task_loss=1.415, contrastive_loss=3.205, total=4172.39, n_correct=98.29, ppl=25.78, accuracy=2.356, wps=19258, ups=1.55, wpb=12458.9, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.495, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=330
2023-08-15 01:33:44 | INFO | train_inner | epoch 001:    506 / 1474 loss=9.259, trans_loss=5.797, nll_loss=4.707, w2v_ctc_loss=5.828, task_loss=1.27, contrastive_loss=3.302, total=4181.66, n_correct=93, ppl=26.11, accuracy=2.224, wps=19018.1, ups=1.52, wpb=12495.1, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.47, clip=0, loss_scale=2, train_wall=65, gb_free=19.2, wall=396
2023-08-15 01:34:50 | INFO | train_inner | epoch 001:    606 / 1474 loss=9.124, trans_loss=5.789, nll_loss=4.692, w2v_ctc_loss=5.677, task_loss=1.242, contrastive_loss=3.255, total=4137.35, n_correct=98.09, ppl=25.85, accuracy=2.371, wps=18629.3, ups=1.51, wpb=12337.2, bsz=474.5, num_updates=600, lr=2.4088e-05, gnorm=1.823, clip=3, loss_scale=2, train_wall=66, gb_free=18.7, wall=462
2023-08-15 01:35:54 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.045, trans_loss=5.772, nll_loss=4.674, w2v_ctc_loss=5.634, task_loss=1.312, contrastive_loss=3.139, total=4145.85, n_correct=94.41, ppl=25.52, accuracy=2.277, wps=19215.2, ups=1.55, wpb=12381.9, bsz=454.4, num_updates=700, lr=2.8086e-05, gnorm=1.145, clip=0, loss_scale=2, train_wall=64, gb_free=19.5, wall=526
2023-08-15 01:36:59 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.947, trans_loss=5.839, nll_loss=4.75, w2v_ctc_loss=5.466, task_loss=1.271, contrastive_loss=3.154, total=4129.2, n_correct=76.96, ppl=26.91, accuracy=1.864, wps=19054.1, ups=1.55, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.155, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=591
2023-08-15 01:38:03 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.836, trans_loss=5.936, nll_loss=4.871, w2v_ctc_loss=5.273, task_loss=1.291, contrastive_loss=3.057, total=4167.97, n_correct=68.7, ppl=29.26, accuracy=1.648, wps=19455.1, ups=1.56, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.492, clip=0, loss_scale=2, train_wall=63, gb_free=18.6, wall=655
2023-08-15 01:39:09 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.699, trans_loss=6.021, nll_loss=4.975, w2v_ctc_loss=5.007, task_loss=1.292, contrastive_loss=3.054, total=4137.5, n_correct=64.05, ppl=31.45, accuracy=1.548, wps=18717.7, ups=1.51, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.703, clip=0, loss_scale=2, train_wall=66, gb_free=19.3, wall=721
2023-08-15 01:40:14 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.501, trans_loss=6.094, nll_loss=5.06, w2v_ctc_loss=4.756, task_loss=1.327, contrastive_loss=2.956, total=4151.84, n_correct=55.05, ppl=33.36, accuracy=1.326, wps=19099.4, ups=1.54, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=1.729, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=786
2023-08-15 01:41:19 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.296, trans_loss=6.082, nll_loss=5.042, w2v_ctc_loss=4.565, task_loss=1.383, contrastive_loss=2.847, total=4123.25, n_correct=66.02, ppl=32.96, accuracy=1.601, wps=19037.7, ups=1.55, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.276, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=851
2023-08-15 01:42:23 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.149, trans_loss=6.084, nll_loss=5.045, w2v_ctc_loss=4.383, task_loss=1.302, contrastive_loss=2.803, total=4066.16, n_correct=64.56, ppl=33.01, accuracy=1.588, wps=18878.5, ups=1.56, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.542, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=915
2023-08-15 01:43:28 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8.037, trans_loss=6.133, nll_loss=5.114, w2v_ctc_loss=4.223, task_loss=1.324, contrastive_loss=2.869, total=4119.98, n_correct=57.3, ppl=34.62, accuracy=1.391, wps=18872.1, ups=1.53, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.409, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=980
2023-08-15 01:44:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
2023-08-15 01:44:53 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.395 | trans_loss 13.751 | nll_loss 13.558 | w2v_ctc_loss 5.482 | task_loss 7.545 | contrastive_loss 4.078 | total 4003.4 | n_correct 48.5 | ppl 12056.7 | accuracy 1.211 | uer 69.96 | wer 68.025 | raw_wer 68.025 | bleu 0 | wps 1149.1 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-15 01:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-15 01:44:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 01:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 01:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.962518582120538 seconds)
2023-08-15 01:45:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-15 01:45:00 | INFO | train | epoch 001 | loss 10.108 | trans_loss 5.929 | nll_loss 4.844 | w2v_ctc_loss 7.238 | task_loss 1.391 | contrastive_loss 3.085 | total 4138.38 | n_correct 83.6948 | ppl 28.72 | accuracy 2.022 | wps 18013.2 | ups 1.46 | wpb 12355.2 | bsz 458.6 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.27 | clip 1.4 | loss_scale 2 | train_wall 959 | gb_free 18.9 | wall 1072
2023-08-15 01:45:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 01:45:01 | INFO | fairseq.trainer | begin training epoch 2
2023-08-15 01:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 01:45:30 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.895, trans_loss=6.103, nll_loss=5.072, w2v_ctc_loss=4.067, task_loss=1.253, contrastive_loss=2.835, total=4165.61, n_correct=63.39, ppl=33.65, accuracy=1.522, wps=10203.8, ups=0.82, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.585, clip=0, loss_scale=2, train_wall=66, gb_free=18.7, wall=1102
2023-08-15 01:46:35 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.775, trans_loss=6.121, nll_loss=5.099, w2v_ctc_loss=3.976, task_loss=1.31, contrastive_loss=2.687, total=4153.7, n_correct=58.79, ppl=34.28, accuracy=1.415, wps=19125.8, ups=1.54, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.417, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1167
2023-08-15 01:47:39 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.675, trans_loss=6.103, nll_loss=5.08, w2v_ctc_loss=3.821, task_loss=1.144, contrastive_loss=2.75, total=4201.44, n_correct=64.75, ppl=33.83, accuracy=1.541, wps=19413, ups=1.55, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.449, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1231
2023-08-15 01:48:44 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.492, trans_loss=6.095, nll_loss=5.071, w2v_ctc_loss=3.765, task_loss=1.337, contrastive_loss=2.515, total=4130.13, n_correct=65.52, ppl=33.61, accuracy=1.586, wps=19194.3, ups=1.56, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.6, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1295
2023-08-15 01:49:49 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.351, trans_loss=6.089, nll_loss=5.067, w2v_ctc_loss=3.703, task_loss=1.468, contrastive_loss=2.334, total=4035.12, n_correct=62.66, ppl=33.52, accuracy=1.553, wps=18402.6, ups=1.53, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.637, clip=0, loss_scale=2, train_wall=65, gb_free=19, wall=1361
2023-08-15 01:50:53 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.268, trans_loss=6.052, nll_loss=5.016, w2v_ctc_loss=3.567, task_loss=1.268, contrastive_loss=2.476, total=4183.09, n_correct=77.21, ppl=32.37, accuracy=1.846, wps=19413.5, ups=1.56, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.554, clip=0, loss_scale=2, train_wall=64, gb_free=18.5, wall=1425
2023-08-15 01:50:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 01:51:35 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.696 | trans_loss 13.399 | nll_loss 13.12 | w2v_ctc_loss 4.631 | task_loss 7.545 | contrastive_loss 3.542 | total 4003.4 | n_correct 60.2 | ppl 8900.64 | accuracy 1.504 | uer 61.986 | wer 60.434 | raw_wer 60.434 | bleu 0 | wps 1134.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-15 01:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-15 01:51:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-15 01:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-15 01:52:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 58.091513980180025 seconds)
2023-08-15 01:53:37 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.129, trans_loss=6.055, nll_loss=5.018, w2v_ctc_loss=3.476, task_loss=1.301, contrastive_loss=2.29, total=4123.85, n_correct=69.79, ppl=32.41, accuracy=1.692, wps=7523.4, ups=0.61, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.498, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1589
2023-08-15 01:54:41 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.054, trans_loss=6.046, nll_loss=5.008, w2v_ctc_loss=3.412, task_loss=1.288, contrastive_loss=2.359, total=4148.13, n_correct=73.63, ppl=32.18, accuracy=1.775, wps=19327.2, ups=1.56, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.54, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1653
2023-08-15 01:55:46 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.957, trans_loss=6.024, nll_loss=4.982, w2v_ctc_loss=3.361, task_loss=1.301, contrastive_loss=2.311, total=4172.27, n_correct=75.88, ppl=31.61, accuracy=1.819, wps=19183.1, ups=1.54, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.408, clip=0, loss_scale=2, train_wall=65, gb_free=18.8, wall=1718
2023-08-15 01:56:51 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.819, trans_loss=6.025, nll_loss=4.981, w2v_ctc_loss=3.273, task_loss=1.362, contrastive_loss=2.225, total=4101.67, n_correct=70.05, ppl=31.59, accuracy=1.708, wps=18843.3, ups=1.54, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.301, clip=0, loss_scale=4, train_wall=65, gb_free=18.9, wall=1783
2023-08-15 01:57:55 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.724, trans_loss=6.011, nll_loss=4.963, w2v_ctc_loss=3.212, task_loss=1.324, contrastive_loss=2.114, total=4091.09, n_correct=71.7, ppl=31.19, accuracy=1.753, wps=18966.6, ups=1.55, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.163, clip=0, loss_scale=4, train_wall=64, gb_free=19.2, wall=1847
2023-08-15 01:59:01 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.7, trans_loss=6.01, nll_loss=4.962, w2v_ctc_loss=3.113, task_loss=1.149, contrastive_loss=2.336, total=4219.19, n_correct=74.89, ppl=31.17, accuracy=1.775, wps=19276.2, ups=1.53, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.142, clip=0, loss_scale=4, train_wall=65, gb_free=19, wall=1913
2023-08-15 02:00:05 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.592, trans_loss=5.994, nll_loss=4.94, w2v_ctc_loss=3.081, task_loss=1.21, contrastive_loss=2.146, total=4212.91, n_correct=75.64, ppl=30.7, accuracy=1.795, wps=19419.4, ups=1.54, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.094, clip=0, loss_scale=4, train_wall=64, gb_free=19.1, wall=1977
2023-08-15 02:01:11 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.486, trans_loss=5.988, nll_loss=4.938, w2v_ctc_loss=3.045, task_loss=1.271, contrastive_loss=1.928, total=4142.48, n_correct=77.37, ppl=30.64, accuracy=1.868, wps=18867.9, ups=1.52, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.116, clip=0, loss_scale=4, train_wall=65, gb_free=18.9, wall=2043
2023-08-15 02:02:16 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.394, trans_loss=5.981, nll_loss=4.927, w2v_ctc_loss=2.998, task_loss=1.386, contrastive_loss=1.988, total=4063.28, n_correct=73.8, ppl=30.41, accuracy=1.816, wps=18676.1, ups=1.54, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=2.063, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2108
2023-08-15 02:02:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:03:23 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.884 | trans_loss 13.06 | nll_loss 12.661 | w2v_ctc_loss 3.805 | task_loss 7.545 | contrastive_loss 2.693 | total 4003.4 | n_correct 84.5 | ppl 6474.55 | accuracy 2.111 | uer 53.449 | wer 52.541 | raw_wer 52.541 | bleu 0 | wps 1161.5 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-15 02:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-15 02:03:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:03:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 31.05997110903263 seconds)
2023-08-15 02:03:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-15 02:03:54 | INFO | train | epoch 002 | loss 7.029 | trans_loss 6.042 | nll_loss 5.003 | w2v_ctc_loss 3.416 | task_loss 1.292 | contrastive_loss 2.319 | total 4138.65 | n_correct 70.8351 | ppl 32.07 | accuracy 1.712 | wps 16069.6 | ups 1.3 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.353 | clip 0 | loss_scale 4 | train_wall 948 | gb_free 19 | wall 2206
2023-08-15 02:03:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:03:54 | INFO | fairseq.trainer | begin training epoch 3
2023-08-15 02:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:04:40 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.298, trans_loss=5.968, nll_loss=4.91, w2v_ctc_loss=2.947, task_loss=1.362, contrastive_loss=1.843, total=4048.67, n_correct=77.87, ppl=30.06, accuracy=1.923, wps=8401.7, ups=0.7, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.902, clip=0, loss_scale=4, train_wall=64, gb_free=18.8, wall=2252
2023-08-15 02:04:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-15 02:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-15 02:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-08-15 02:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-08-15 02:06:15 | INFO | train_inner | epoch 003:    162 / 1474 loss=5.708, trans_loss=5.054, nll_loss=3.729, w2v_ctc_loss=2.849, task_loss=0.896, contrastive_loss=1.936, total=4165.74, n_correct=479.89, ppl=13.26, accuracy=11.52, wps=13079.5, ups=1.05, wpb=12437.4, bsz=466, num_updates=3100, lr=0.000124038, gnorm=7.734, clip=22, loss_scale=0.25, train_wall=95, gb_free=16.7, wall=2347
2023-08-15 02:07:50 | INFO | train_inner | epoch 003:    262 / 1474 loss=4.941, trans_loss=4.352, nll_loss=2.807, w2v_ctc_loss=2.674, task_loss=0.93, contrastive_loss=1.77, total=4149.55, n_correct=1099.64, ppl=7, accuracy=26.5, wps=13095.9, ups=1.06, wpb=12397.1, bsz=463.2, num_updates=3200, lr=0.000128036, gnorm=8.109, clip=17, loss_scale=0.25, train_wall=94, gb_free=16.3, wall=2442
2023-08-15 02:09:23 | INFO | train_inner | epoch 003:    362 / 1474 loss=4.644, trans_loss=4.247, nll_loss=2.672, w2v_ctc_loss=2.552, task_loss=0.905, contrastive_loss=1.699, total=4175.96, n_correct=1253.99, ppl=6.37, accuracy=30.029, wps=13386.8, ups=1.07, wpb=12461.5, bsz=474.2, num_updates=3300, lr=0.000132034, gnorm=4.088, clip=6, loss_scale=0.25, train_wall=93, gb_free=16.3, wall=2535
2023-08-15 02:10:55 | INFO | train_inner | epoch 003:    462 / 1474 loss=4.336, trans_loss=4.176, nll_loss=2.581, w2v_ctc_loss=2.398, task_loss=0.923, contrastive_loss=1.386, total=4187.52, n_correct=1345.84, ppl=5.98, accuracy=32.139, wps=13484.2, ups=1.08, wpb=12498.8, bsz=463.6, num_updates=3400, lr=0.000136032, gnorm=2.803, clip=2, loss_scale=0.25, train_wall=92, gb_free=14, wall=2627
2023-08-15 02:12:28 | INFO | train_inner | epoch 003:    562 / 1474 loss=4.151, trans_loss=4.155, nll_loss=2.557, w2v_ctc_loss=2.282, task_loss=0.998, contrastive_loss=1.302, total=4083.21, n_correct=1342.2, ppl=5.89, accuracy=32.871, wps=13169.7, ups=1.08, wpb=12199, bsz=437.9, num_updates=3500, lr=0.00014003, gnorm=2.95, clip=1, loss_scale=0.25, train_wall=92, gb_free=15.6, wall=2720
2023-08-15 02:14:03 | INFO | train_inner | epoch 003:    662 / 1474 loss=4.06, trans_loss=4.137, nll_loss=2.529, w2v_ctc_loss=2.18, task_loss=0.866, contrastive_loss=1.365, total=4232.39, n_correct=1440.22, ppl=5.77, accuracy=34.029, wps=13319.2, ups=1.06, wpb=12618.9, bsz=487.6, num_updates=3600, lr=0.000144028, gnorm=2.388, clip=1, loss_scale=0.25, train_wall=94, gb_free=16.1, wall=2815
2023-08-15 02:15:35 | INFO | train_inner | epoch 003:    762 / 1474 loss=3.915, trans_loss=4.101, nll_loss=2.489, w2v_ctc_loss=2.133, task_loss=0.898, contrastive_loss=1.096, total=4155.31, n_correct=1450.07, ppl=5.61, accuracy=34.897, wps=13442, ups=1.08, wpb=12412.9, bsz=465.8, num_updates=3700, lr=0.000148026, gnorm=2.284, clip=0, loss_scale=0.25, train_wall=92, gb_free=16.1, wall=2907
2023-08-15 02:17:08 | INFO | train_inner | epoch 003:    862 / 1474 loss=3.821, trans_loss=4.095, nll_loss=2.479, w2v_ctc_loss=2.085, task_loss=0.93, contrastive_loss=1.026, total=4170.95, n_correct=1471.56, ppl=5.57, accuracy=35.281, wps=13395.5, ups=1.08, wpb=12453.7, bsz=458.1, num_updates=3800, lr=0.000152024, gnorm=2.448, clip=2, loss_scale=0.25, train_wall=92, gb_free=17.1, wall=3000
2023-08-15 02:18:41 | INFO | train_inner | epoch 003:    962 / 1474 loss=3.765, trans_loss=4.075, nll_loss=2.451, w2v_ctc_loss=2.052, task_loss=0.884, contrastive_loss=1.039, total=4174.19, n_correct=1518.81, ppl=5.47, accuracy=36.386, wps=13408, ups=1.08, wpb=12449.2, bsz=475.7, num_updates=3900, lr=0.000156022, gnorm=2.387, clip=1, loss_scale=0.25, train_wall=92, gb_free=13.4, wall=3093
2023-08-15 02:20:14 | INFO | train_inner | epoch 003:   1062 / 1474 loss=3.673, trans_loss=4.059, nll_loss=2.433, w2v_ctc_loss=2.04, task_loss=1.003, contrastive_loss=0.907, total=4049.41, n_correct=1484.14, ppl=5.4, accuracy=36.651, wps=12992.1, ups=1.07, wpb=12096, bsz=436.3, num_updates=4000, lr=0.00016002, gnorm=2.005, clip=1, loss_scale=0.25, train_wall=93, gb_free=16.1, wall=3186
2023-08-15 02:20:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:20:46 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.959 | trans_loss 7.093 | nll_loss 4.92 | w2v_ctc_loss 2.553 | task_loss 4.155 | contrastive_loss 1.245 | total 4003.4 | n_correct 1559.3 | ppl 30.28 | accuracy 38.949 | uer 35.45 | wer 35.051 | raw_wer 35.051 | bleu 1.9 | wps 1504.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 1.9
2023-08-15 02:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-15 02:20:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-15 02:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-15 02:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 1.9) (writing took 42.583586329594254 seconds)
2023-08-15 02:23:00 | INFO | train_inner | epoch 003:   1162 / 1474 loss=3.565, trans_loss=4.048, nll_loss=2.417, w2v_ctc_loss=1.964, task_loss=0.989, contrastive_loss=0.844, total=4044.1, n_correct=1509.82, ppl=5.34, accuracy=37.334, wps=7260.5, ups=0.6, wpb=12070.2, bsz=433.6, num_updates=4100, lr=0.000164018, gnorm=1.859, clip=0, loss_scale=0.25, train_wall=91, gb_free=15.4, wall=3352
2023-08-15 02:24:32 | INFO | train_inner | epoch 003:   1262 / 1474 loss=3.489, trans_loss=4.02, nll_loss=2.382, w2v_ctc_loss=1.918, task_loss=0.985, contrastive_loss=0.794, total=4065.1, n_correct=1550.21, ppl=5.21, accuracy=38.135, wps=13213.2, ups=1.09, wpb=12140.5, bsz=432.3, num_updates=4200, lr=0.000168016, gnorm=1.825, clip=0, loss_scale=0.25, train_wall=91, gb_free=16.9, wall=3444
2023-08-15 02:26:05 | INFO | train_inner | epoch 003:   1362 / 1474 loss=3.461, trans_loss=4.002, nll_loss=2.358, w2v_ctc_loss=1.882, task_loss=0.93, contrastive_loss=0.884, total=4132.35, n_correct=1615.33, ppl=5.13, accuracy=39.09, wps=13245.9, ups=1.07, wpb=12335.6, bsz=462.1, num_updates=4300, lr=0.000172014, gnorm=1.797, clip=0, loss_scale=0.25, train_wall=93, gb_free=17.4, wall=3537
2023-08-15 02:27:39 | INFO | train_inner | epoch 003:   1462 / 1474 loss=3.401, trans_loss=3.979, nll_loss=2.329, w2v_ctc_loss=1.854, task_loss=0.887, contrastive_loss=0.835, total=4206.88, n_correct=1685.65, ppl=5.02, accuracy=40.069, wps=13458.1, ups=1.07, wpb=12566, bsz=476, num_updates=4400, lr=0.000176012, gnorm=1.732, clip=0, loss_scale=0.25, train_wall=93, gb_free=14.7, wall=3631
2023-08-15 02:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:28:18 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.557 | trans_loss 6.728 | nll_loss 4.439 | w2v_ctc_loss 2.275 | task_loss 4.122 | contrastive_loss 1.026 | total 4003.4 | n_correct 1760 | ppl 21.69 | accuracy 43.963 | uer 32.931 | wer 32.579 | raw_wer 32.579 | bleu 5.04 | wps 1632.7 | wpb 4003.4 | bsz 141.8 | num_updates 4412 | best_bleu 5.04
2023-08-15 02:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4412 updates
2023-08-15 02:28:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4412 updates, score 5.04) (writing took 30.616793431341648 seconds)
2023-08-15 02:28:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-15 02:28:49 | INFO | train | epoch 003 | loss 4.15 | trans_loss 4.247 | nll_loss 2.676 | w2v_ctc_loss 2.231 | task_loss 0.945 | contrastive_loss 1.234 | total 4138.85 | n_correct 1325.37 | ppl 6.39 | accuracy 32.023 | wps 12150.7 | ups 0.98 | wpb 12356.3 | bsz 458.6 | num_updates 4412 | lr 0.000176492 | gnorm 3.109 | clip 3.6 | loss_scale 0.25 | train_wall 1345 | gb_free 16.2 | wall 3701
2023-08-15 02:28:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:28:49 | INFO | fairseq.trainer | begin training epoch 4
2023-08-15 02:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:30:18 | INFO | train_inner | epoch 004:     88 / 1474 loss=3.281, trans_loss=3.954, nll_loss=2.293, w2v_ctc_loss=1.823, task_loss=0.976, contrastive_loss=0.644, total=4082.27, n_correct=1674.94, ppl=4.9, accuracy=41.03, wps=7667.7, ups=0.63, wpb=12182.1, bsz=434.2, num_updates=4500, lr=0.00018001, gnorm=1.793, clip=2, loss_scale=0.25, train_wall=91, gb_free=17.6, wall=3790
2023-08-15 02:31:49 | INFO | train_inner | epoch 004:    188 / 1474 loss=3.215, trans_loss=3.917, nll_loss=2.247, w2v_ctc_loss=1.773, task_loss=0.882, contrastive_loss=0.653, total=4184.92, n_correct=1768.23, ppl=4.75, accuracy=42.252, wps=13604.6, ups=1.09, wpb=12496.9, bsz=470.3, num_updates=4600, lr=0.000184008, gnorm=1.396, clip=0, loss_scale=0.25, train_wall=91, gb_free=12.8, wall=3881
2023-08-15 02:33:22 | INFO | train_inner | epoch 004:    288 / 1474 loss=3.199, trans_loss=3.91, nll_loss=2.239, w2v_ctc_loss=1.761, task_loss=0.924, contrastive_loss=0.745, total=4150, n_correct=1771.38, ppl=4.72, accuracy=42.684, wps=13356.6, ups=1.08, wpb=12397.9, bsz=465.2, num_updates=4700, lr=0.000188006, gnorm=1.479, clip=0, loss_scale=0.25, train_wall=92, gb_free=16.6, wall=3974
2023-08-15 02:34:54 | INFO | train_inner | epoch 004:    388 / 1474 loss=3.137, trans_loss=3.896, nll_loss=2.218, w2v_ctc_loss=1.759, task_loss=0.973, contrastive_loss=0.57, total=4114.32, n_correct=1783.34, ppl=4.65, accuracy=43.345, wps=13321.5, ups=1.09, wpb=12277.1, bsz=440, num_updates=4800, lr=0.000192004, gnorm=2.176, clip=2, loss_scale=0.25, train_wall=92, gb_free=11.7, wall=4066
2023-08-15 02:36:28 | INFO | train_inner | epoch 004:    488 / 1474 loss=3.155, trans_loss=3.868, nll_loss=2.182, w2v_ctc_loss=1.693, task_loss=0.826, contrastive_loss=0.96, total=4239.74, n_correct=1883.99, ppl=4.54, accuracy=44.436, wps=13592.3, ups=1.07, wpb=12652.2, bsz=506.4, num_updates=4900, lr=0.000196002, gnorm=1.384, clip=0, loss_scale=0.25, train_wall=93, gb_free=16.7, wall=4160
2023-08-15 02:38:00 | INFO | train_inner | epoch 004:    588 / 1474 loss=3.065, trans_loss=3.846, nll_loss=2.154, w2v_ctc_loss=1.712, task_loss=0.876, contrastive_loss=0.601, total=4219.26, n_correct=1912.19, ppl=4.45, accuracy=45.321, wps=13643.4, ups=1.08, wpb=12596.5, bsz=483.8, num_updates=5000, lr=0.0002, gnorm=1.484, clip=0, loss_scale=0.25, train_wall=92, gb_free=15.9, wall=4252
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:0')
2023-08-15 02:39:34 | INFO | train_inner | epoch 004:    688 / 1474 loss=3.037, trans_loss=3.845, nll_loss=2.149, w2v_ctc_loss=1.7, task_loss=0.966, contrastive_loss=0.642, total=4171.93, n_correct=1907.01, ppl=4.44, accuracy=45.71, wps=13183.3, ups=1.06, wpb=12436.9, bsz=453.3, num_updates=5100, lr=0.00019803, gnorm=1.126, clip=1, loss_scale=0.25, train_wall=94, gb_free=15.3, wall=4346
2023-08-15 02:41:07 | INFO | train_inner | epoch 004:    788 / 1474 loss=2.989, trans_loss=3.822, nll_loss=2.123, w2v_ctc_loss=1.705, task_loss=1.012, contrastive_loss=0.501, total=4029.4, n_correct=1865.59, ppl=4.36, accuracy=46.299, wps=12989.8, ups=1.08, wpb=12032.2, bsz=423.7, num_updates=5200, lr=0.000196116, gnorm=1.037, clip=0, loss_scale=0.5, train_wall=92, gb_free=16, wall=4439
2023-08-15 02:42:39 | INFO | train_inner | epoch 004:    888 / 1474 loss=3.028, trans_loss=3.807, nll_loss=2.105, w2v_ctc_loss=1.704, task_loss=0.934, contrastive_loss=0.68, total=4175.28, n_correct=1950.66, ppl=4.3, accuracy=46.719, wps=13466.4, ups=1.08, wpb=12468.9, bsz=463.7, num_updates=5300, lr=0.000194257, gnorm=1.108, clip=1, loss_scale=0.5, train_wall=92, gb_free=15.3, wall=4531
2023-08-15 02:44:12 | INFO | train_inner | epoch 004:    988 / 1474 loss=2.945, trans_loss=3.787, nll_loss=2.079, w2v_ctc_loss=1.668, task_loss=0.949, contrastive_loss=0.538, total=4132.46, n_correct=1970.66, ppl=4.22, accuracy=47.687, wps=13280, ups=1.08, wpb=12343.2, bsz=455.3, num_updates=5400, lr=0.00019245, gnorm=0.965, clip=1, loss_scale=0.5, train_wall=92, gb_free=10.3, wall=4624
2023-08-15 02:45:45 | INFO | train_inner | epoch 004:   1088 / 1474 loss=2.905, trans_loss=3.781, nll_loss=2.07, w2v_ctc_loss=1.65, task_loss=0.996, contrastive_loss=0.498, total=4073.98, n_correct=1958.38, ppl=4.2, accuracy=48.07, wps=13090.1, ups=1.08, wpb=12161.7, bsz=437.9, num_updates=5500, lr=0.000190693, gnorm=0.866, clip=0, loss_scale=0.5, train_wall=92, gb_free=15.6, wall=4717
2023-08-15 02:47:18 | INFO | train_inner | epoch 004:   1188 / 1474 loss=2.905, trans_loss=3.763, nll_loss=2.049, w2v_ctc_loss=1.632, task_loss=0.862, contrastive_loss=0.597, total=4172.46, n_correct=2036.08, ppl=4.14, accuracy=48.798, wps=13439.7, ups=1.08, wpb=12459.8, bsz=487.1, num_updates=5600, lr=0.000188982, gnorm=0.863, clip=0, loss_scale=0.5, train_wall=92, gb_free=10.9, wall=4810
2023-08-15 02:48:50 | INFO | train_inner | epoch 004:   1288 / 1474 loss=2.866, trans_loss=3.745, nll_loss=2.026, w2v_ctc_loss=1.62, task_loss=0.899, contrastive_loss=0.55, total=4140.32, n_correct=2045.82, ppl=4.07, accuracy=49.412, wps=13420.1, ups=1.09, wpb=12365.2, bsz=467.7, num_updates=5700, lr=0.000187317, gnorm=0.823, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=4902
2023-08-15 02:50:22 | INFO | train_inner | epoch 004:   1388 / 1474 loss=2.808, trans_loss=3.732, nll_loss=2.008, w2v_ctc_loss=1.609, task_loss=0.963, contrastive_loss=0.416, total=4092.66, n_correct=2038.81, ppl=4.02, accuracy=49.816, wps=13377.3, ups=1.09, wpb=12224.9, bsz=436.3, num_updates=5800, lr=0.000185695, gnorm=0.832, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.2, wall=4994
2023-08-15 02:51:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5391, device='cuda:3')
2023-08-15 02:52:06 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.7 | trans_loss 5.865 | nll_loss 3.318 | w2v_ctc_loss 1.842 | task_loss 4.336 | contrastive_loss 0.615 | total 4003.4 | n_correct 2230.9 | ppl 9.97 | accuracy 55.725 | uer 27.444 | wer 28.47 | raw_wer 28.47 | bleu 13.7 | wps 1928.9 | wpb 4003.4 | bsz 141.8 | num_updates 5886 | best_bleu 13.7
2023-08-15 02:52:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5886 updates
2023-08-15 02:52:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 02:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5886 updates, score 13.7) (writing took 29.734384087845683 seconds)
2023-08-15 02:52:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-15 02:52:36 | INFO | train | epoch 004 | loss 3.021 | trans_loss 3.826 | nll_loss 2.129 | w2v_ctc_loss 1.692 | task_loss 0.93 | contrastive_loss 0.608 | total 4138.65 | n_correct 1908.78 | ppl 4.38 | accuracy 46.121 | wps 12758.9 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5886 | lr 0.000184334 | gnorm 1.207 | clip 0.5 | loss_scale 0.5 | train_wall 1356 | gb_free 14.5 | wall 5128
2023-08-15 02:52:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 02:52:36 | INFO | fairseq.trainer | begin training epoch 5
2023-08-15 02:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 02:52:57 | INFO | train_inner | epoch 005:     14 / 1474 loss=2.77, trans_loss=3.717, nll_loss=1.987, w2v_ctc_loss=1.556, task_loss=0.934, contrastive_loss=0.455, total=4073.09, n_correct=2058.18, ppl=3.96, accuracy=50.531, wps=7826.5, ups=0.64, wpb=12158.4, bsz=451.4, num_updates=5900, lr=0.000184115, gnorm=0.749, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.1, wall=5149
2023-08-15 02:54:30 | INFO | train_inner | epoch 005:    114 / 1474 loss=2.701, trans_loss=3.679, nll_loss=1.94, w2v_ctc_loss=1.5, task_loss=0.853, contrastive_loss=0.422, total=4233.69, n_correct=2197.94, ppl=3.84, accuracy=51.915, wps=13551.2, ups=1.07, wpb=12643.8, bsz=488.6, num_updates=6000, lr=0.000182574, gnorm=0.732, clip=0, loss_scale=0.5, train_wall=93, gb_free=15.5, wall=5242
2023-08-15 02:54:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 02:54:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.67 | trans_loss 5.85 | nll_loss 3.293 | w2v_ctc_loss 1.788 | task_loss 4.291 | contrastive_loss 0.6 | total 4003.4 | n_correct 2240.8 | ppl 9.8 | accuracy 55.972 | uer 27.325 | wer 28.28 | raw_wer 28.28 | bleu 13.76 | wps 2083 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 13.76
2023-08-15 02:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-15 02:54:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-15 02:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-15 02:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 13.76) (writing took 52.42412124015391 seconds)
2023-08-15 02:57:20 | INFO | train_inner | epoch 005:    214 / 1474 loss=2.731, trans_loss=3.681, nll_loss=1.94, w2v_ctc_loss=1.504, task_loss=0.868, contrastive_loss=0.627, total=4185.02, n_correct=2178.01, ppl=3.84, accuracy=52.043, wps=7364.3, ups=0.59, wpb=12486.5, bsz=485.7, num_updates=6100, lr=0.000181071, gnorm=0.704, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.4, wall=5412
2023-08-15 02:58:52 | INFO | train_inner | epoch 005:    314 / 1474 loss=2.698, trans_loss=3.664, nll_loss=1.924, w2v_ctc_loss=1.514, task_loss=0.948, contrastive_loss=0.482, total=4097.42, n_correct=2135.14, ppl=3.79, accuracy=52.109, wps=13331.5, ups=1.09, wpb=12251.6, bsz=448, num_updates=6200, lr=0.000179605, gnorm=0.742, clip=0, loss_scale=0.5, train_wall=91, gb_free=13.8, wall=5504
2023-08-15 03:00:25 | INFO | train_inner | epoch 005:    414 / 1474 loss=2.685, trans_loss=3.658, nll_loss=1.915, w2v_ctc_loss=1.479, task_loss=0.918, contrastive_loss=0.555, total=4135.49, n_correct=2171.18, ppl=3.77, accuracy=52.501, wps=13231, ups=1.07, wpb=12359.1, bsz=465.9, num_updates=6300, lr=0.000178174, gnorm=0.738, clip=0, loss_scale=0.5, train_wall=93, gb_free=17.2, wall=5597
2023-08-15 03:01:58 | INFO | train_inner | epoch 005:    514 / 1474 loss=2.646, trans_loss=3.657, nll_loss=1.911, w2v_ctc_loss=1.473, task_loss=1.01, contrastive_loss=0.485, total=4035.21, n_correct=2125.49, ppl=3.76, accuracy=52.674, wps=13037.8, ups=1.08, wpb=12051.5, bsz=427.7, num_updates=6400, lr=0.000176777, gnorm=0.7, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=5689
2023-08-15 03:03:30 | INFO | train_inner | epoch 005:    614 / 1474 loss=2.626, trans_loss=3.657, nll_loss=1.909, w2v_ctc_loss=1.472, task_loss=0.977, contrastive_loss=0.383, total=4117.64, n_correct=2180.22, ppl=3.76, accuracy=52.948, wps=13340.5, ups=1.09, wpb=12284.8, bsz=443.7, num_updates=6500, lr=0.000175412, gnorm=0.704, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.9, wall=5782
2023-08-15 03:05:02 | INFO | train_inner | epoch 005:    714 / 1474 loss=2.64, trans_loss=3.648, nll_loss=1.899, w2v_ctc_loss=1.459, task_loss=0.896, contrastive_loss=0.492, total=4153.99, n_correct=2214.43, ppl=3.73, accuracy=53.309, wps=13408.2, ups=1.08, wpb=12400.6, bsz=476.1, num_updates=6600, lr=0.000174078, gnorm=0.681, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.4, wall=5874
2023-08-15 03:06:36 | INFO | train_inner | epoch 005:    814 / 1474 loss=2.6, trans_loss=3.634, nll_loss=1.88, w2v_ctc_loss=1.444, task_loss=0.939, contrastive_loss=0.416, total=4131.08, n_correct=2218.02, ppl=3.68, accuracy=53.691, wps=13195.6, ups=1.07, wpb=12332.3, bsz=455.1, num_updates=6700, lr=0.000172774, gnorm=0.664, clip=0, loss_scale=0.5, train_wall=93, gb_free=17.5, wall=5968
2023-08-15 03:08:08 | INFO | train_inner | epoch 005:    914 / 1474 loss=2.569, trans_loss=3.629, nll_loss=1.875, w2v_ctc_loss=1.436, task_loss=0.969, contrastive_loss=0.363, total=4109.29, n_correct=2217.13, ppl=3.67, accuracy=53.954, wps=13251.2, ups=1.08, wpb=12268.1, bsz=445.5, num_updates=6800, lr=0.000171499, gnorm=0.657, clip=0, loss_scale=0.5, train_wall=92, gb_free=11.6, wall=6060
2023-08-15 03:09:40 | INFO | train_inner | epoch 005:   1014 / 1474 loss=2.574, trans_loss=3.626, nll_loss=1.871, w2v_ctc_loss=1.43, task_loss=0.919, contrastive_loss=0.435, total=4163.73, n_correct=2255.75, ppl=3.66, accuracy=54.176, wps=13531.3, ups=1.09, wpb=12429.6, bsz=462.1, num_updates=6900, lr=0.000170251, gnorm=0.706, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.1, wall=6152
2023-08-15 03:11:14 | INFO | train_inner | epoch 005:   1114 / 1474 loss=2.592, trans_loss=3.622, nll_loss=1.864, w2v_ctc_loss=1.442, task_loss=0.932, contrastive_loss=0.449, total=4172.75, n_correct=2270.75, ppl=3.64, accuracy=54.419, wps=13201.3, ups=1.06, wpb=12448.4, bsz=464, num_updates=7000, lr=0.000169031, gnorm=0.686, clip=0, loss_scale=0.5, train_wall=94, gb_free=12.5, wall=6246
2023-08-15 03:12:48 | INFO | train_inner | epoch 005:   1214 / 1474 loss=2.528, trans_loss=3.613, nll_loss=1.852, w2v_ctc_loss=1.408, task_loss=0.941, contrastive_loss=0.339, total=4164.91, n_correct=2282.42, ppl=3.61, accuracy=54.801, wps=13281.4, ups=1.07, wpb=12422.5, bsz=455.7, num_updates=7100, lr=0.000167836, gnorm=0.66, clip=0, loss_scale=0.5, train_wall=93, gb_free=14.6, wall=6340
2023-08-15 03:14:21 | INFO | train_inner | epoch 005:   1314 / 1474 loss=2.507, trans_loss=3.608, nll_loss=1.848, w2v_ctc_loss=1.397, task_loss=0.951, contrastive_loss=0.31, total=4127.88, n_correct=2265.74, ppl=3.6, accuracy=54.889, wps=13248.7, ups=1.08, wpb=12320.7, bsz=445.3, num_updates=7200, lr=0.000166667, gnorm=0.642, clip=0, loss_scale=1, train_wall=93, gb_free=16, wall=6433
2023-08-15 03:15:53 | INFO | train_inner | epoch 005:   1414 / 1474 loss=2.508, trans_loss=3.604, nll_loss=1.844, w2v_ctc_loss=1.385, task_loss=0.941, contrastive_loss=0.359, total=4135.9, n_correct=2277.99, ppl=3.59, accuracy=55.078, wps=13392.7, ups=1.08, wpb=12351.8, bsz=456.9, num_updates=7300, lr=0.000165521, gnorm=0.631, clip=0, loss_scale=1, train_wall=92, gb_free=16.6, wall=6525
2023-08-15 03:16:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:17:15 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.441 | trans_loss 5.633 | nll_loss 3.024 | w2v_ctc_loss 1.594 | task_loss 4.429 | contrastive_loss 0.52 | total 4003.4 | n_correct 2373.1 | ppl 8.13 | accuracy 59.277 | uer 25.496 | wer 27.042 | raw_wer 27.042 | bleu 16.56 | wps 1831 | wpb 4003.4 | bsz 141.8 | num_updates 7360 | best_bleu 16.56
2023-08-15 03:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7360 updates
2023-08-15 03:17:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:17:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7360 updates, score 16.56) (writing took 32.769794806838036 seconds)
2023-08-15 03:17:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-15 03:17:48 | INFO | train | epoch 005 | loss 2.613 | trans_loss 3.64 | nll_loss 1.889 | w2v_ctc_loss 1.452 | task_loss 0.931 | contrastive_loss 0.438 | total 4138.65 | n_correct 2214.94 | ppl 3.7 | accuracy 53.518 | wps 12049.2 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 7360 | lr 0.000164845 | gnorm 0.688 | clip 0 | loss_scale 1 | train_wall 1359 | gb_free 16 | wall 6640
2023-08-15 03:17:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 03:17:48 | INFO | fairseq.trainer | begin training epoch 6
2023-08-15 03:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 03:18:34 | INFO | train_inner | epoch 006:     40 / 1474 loss=2.496, trans_loss=3.587, nll_loss=1.819, w2v_ctc_loss=1.385, task_loss=0.961, contrastive_loss=0.359, total=4114.92, n_correct=2285.83, ppl=3.53, accuracy=55.55, wps=7653.1, ups=0.62, wpb=12278.2, bsz=446.4, num_updates=7400, lr=0.000164399, gnorm=0.642, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=6685
2023-08-15 03:20:06 | INFO | train_inner | epoch 006:    140 / 1474 loss=2.45, trans_loss=3.561, nll_loss=1.789, w2v_ctc_loss=1.331, task_loss=0.929, contrastive_loss=0.397, total=4157.03, n_correct=2341.06, ppl=3.46, accuracy=56.316, wps=13362.6, ups=1.08, wpb=12418.5, bsz=455.9, num_updates=7500, lr=0.000163299, gnorm=0.611, clip=0, loss_scale=1, train_wall=92, gb_free=14.7, wall=6778
2023-08-15 03:21:40 | INFO | train_inner | epoch 006:    240 / 1474 loss=2.451, trans_loss=3.569, nll_loss=1.799, w2v_ctc_loss=1.358, task_loss=0.976, contrastive_loss=0.317, total=4121.73, n_correct=2310.22, ppl=3.48, accuracy=56.05, wps=13237.6, ups=1.08, wpb=12312.8, bsz=446.5, num_updates=7600, lr=0.000162221, gnorm=0.625, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=6871
2023-08-15 03:23:14 | INFO | train_inner | epoch 006:    340 / 1474 loss=2.476, trans_loss=3.559, nll_loss=1.786, w2v_ctc_loss=1.307, task_loss=0.879, contrastive_loss=0.59, total=4170.63, n_correct=2356.75, ppl=3.45, accuracy=56.508, wps=13197.8, ups=1.06, wpb=12451, bsz=486.5, num_updates=7700, lr=0.000161165, gnorm=0.64, clip=0, loss_scale=1, train_wall=94, gb_free=12.5, wall=6966
2023-08-15 03:24:46 | INFO | train_inner | epoch 006:    440 / 1474 loss=2.403, trans_loss=3.55, nll_loss=1.775, w2v_ctc_loss=1.314, task_loss=0.903, contrastive_loss=0.304, total=4147.89, n_correct=2359.66, ppl=3.42, accuracy=56.888, wps=13512.4, ups=1.09, wpb=12386.2, bsz=467, num_updates=7800, lr=0.000160128, gnorm=0.612, clip=0, loss_scale=1, train_wall=91, gb_free=16.8, wall=7057
2023-08-15 03:26:18 | INFO | train_inner | epoch 006:    540 / 1474 loss=2.409, trans_loss=3.555, nll_loss=1.78, w2v_ctc_loss=1.325, task_loss=0.936, contrastive_loss=0.297, total=4170.36, n_correct=2372.34, ppl=3.43, accuracy=56.886, wps=13406.1, ups=1.08, wpb=12447.9, bsz=455.9, num_updates=7900, lr=0.000159111, gnorm=0.602, clip=0, loss_scale=1, train_wall=92, gb_free=15.3, wall=7150
2023-08-15 03:27:50 | INFO | train_inner | epoch 006:    640 / 1474 loss=2.404, trans_loss=3.552, nll_loss=1.778, w2v_ctc_loss=1.303, task_loss=0.89, contrastive_loss=0.348, total=4144.5, n_correct=2361.91, ppl=3.43, accuracy=56.989, wps=13479.9, ups=1.09, wpb=12372.4, bsz=470, num_updates=8000, lr=0.000158114, gnorm=0.609, clip=0, loss_scale=1, train_wall=91, gb_free=17, wall=7242
2023-08-15 03:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:28:16 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.311 | trans_loss 5.503 | nll_loss 2.856 | w2v_ctc_loss 1.532 | task_loss 4.513 | contrastive_loss 0.468 | total 4003.4 | n_correct 2445.9 | ppl 7.24 | accuracy 61.096 | uer 23.42 | wer 24.995 | raw_wer 24.995 | bleu 17.99 | wps 2028.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.99
2023-08-15 03:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-15 03:28:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-15 03:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-15 03:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.99) (writing took 61.554183047264814 seconds)
2023-08-15 03:30:50 | INFO | train_inner | epoch 006:    740 / 1474 loss=2.397, trans_loss=3.551, nll_loss=1.776, w2v_ctc_loss=1.319, task_loss=0.948, contrastive_loss=0.3, total=4145.29, n_correct=2364.72, ppl=3.42, accuracy=57.046, wps=6883.6, ups=0.56, wpb=12375, bsz=454.7, num_updates=8100, lr=0.000157135, gnorm=0.598, clip=0, loss_scale=1, train_wall=92, gb_free=17.5, wall=7422
2023-08-15 03:32:23 | INFO | train_inner | epoch 006:    840 / 1474 loss=2.384, trans_loss=3.55, nll_loss=1.775, w2v_ctc_loss=1.311, task_loss=0.965, contrastive_loss=0.278, total=4131.83, n_correct=2358.74, ppl=3.42, accuracy=57.087, wps=13310.2, ups=1.08, wpb=12335.3, bsz=446.9, num_updates=8200, lr=0.000156174, gnorm=0.61, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=7515
2023-08-15 03:33:57 | INFO | train_inner | epoch 006:    940 / 1474 loss=2.415, trans_loss=3.556, nll_loss=1.782, w2v_ctc_loss=1.32, task_loss=1.003, contrastive_loss=0.377, total=4068.88, n_correct=2314.2, ppl=3.44, accuracy=56.876, wps=12916.1, ups=1.06, wpb=12145.6, bsz=436.9, num_updates=8300, lr=0.00015523, gnorm=0.606, clip=0, loss_scale=1, train_wall=94, gb_free=15.9, wall=7609
2023-08-15 03:35:28 | INFO | train_inner | epoch 006:   1040 / 1474 loss=2.408, trans_loss=3.541, nll_loss=1.763, w2v_ctc_loss=1.291, task_loss=0.875, contrastive_loss=0.452, total=4176.69, n_correct=2396.35, ppl=3.39, accuracy=57.374, wps=13585.2, ups=1.09, wpb=12465.8, bsz=480, num_updates=8400, lr=0.000154303, gnorm=0.652, clip=0, loss_scale=1, train_wall=91, gb_free=16.3, wall=7700
2023-08-15 03:37:00 | INFO | train_inner | epoch 006:   1140 / 1474 loss=2.375, trans_loss=3.538, nll_loss=1.76, w2v_ctc_loss=1.301, task_loss=1.013, contrastive_loss=0.303, total=4078.12, n_correct=2337.1, ppl=3.39, accuracy=57.308, wps=13232.2, ups=1.09, wpb=12175.4, bsz=435.5, num_updates=8500, lr=0.000153393, gnorm=0.596, clip=0, loss_scale=1, train_wall=91, gb_free=14.7, wall=7792
2023-08-15 03:38:33 | INFO | train_inner | epoch 006:   1240 / 1474 loss=2.409, trans_loss=3.53, nll_loss=1.752, w2v_ctc_loss=1.28, task_loss=0.931, contrastive_loss=0.567, total=4126.61, n_correct=2376.89, ppl=3.37, accuracy=57.599, wps=13299.5, ups=1.08, wpb=12325.4, bsz=463.4, num_updates=8600, lr=0.000152499, gnorm=0.6, clip=0, loss_scale=1, train_wall=92, gb_free=13.3, wall=7885
2023-08-15 03:40:05 | INFO | train_inner | epoch 006:   1340 / 1474 loss=2.336, trans_loss=3.529, nll_loss=1.747, w2v_ctc_loss=1.276, task_loss=0.921, contrastive_loss=0.256, total=4127.1, n_correct=2390.82, ppl=3.36, accuracy=57.93, wps=13441.4, ups=1.09, wpb=12313, bsz=454.8, num_updates=8700, lr=0.00015162, gnorm=0.595, clip=0, loss_scale=1, train_wall=91, gb_free=16.5, wall=7977
2023-08-15 03:41:37 | INFO | train_inner | epoch 006:   1440 / 1474 loss=2.337, trans_loss=3.522, nll_loss=1.74, w2v_ctc_loss=1.277, task_loss=0.925, contrastive_loss=0.262, total=4197.14, n_correct=2437.32, ppl=3.34, accuracy=58.071, wps=13539.9, ups=1.08, wpb=12529.7, bsz=463.5, num_updates=8800, lr=0.000150756, gnorm=0.58, clip=0, loss_scale=1, train_wall=92, gb_free=15.2, wall=8069
2023-08-15 03:42:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 03:42:33 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.242 | trans_loss 5.445 | nll_loss 2.788 | w2v_ctc_loss 1.461 | task_loss 4.496 | contrastive_loss 0.437 | total 4003.4 | n_correct 2474.8 | ppl 6.91 | accuracy 61.817 | uer 21.992 | wer 23.47 | raw_wer 23.47 | bleu 18.62 | wps 2006.2 | wpb 4003.4 | bsz 141.8 | num_updates 8834 | best_bleu 18.62
2023-08-15 03:42:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8834 updates
2023-08-15 03:42:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 03:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8834 updates, score 18.62) (writing took 34.4519123211503 seconds)
2023-08-15 03:43:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-15 03:43:08 | INFO | train | epoch 006 | loss 2.403 | trans_loss 3.547 | nll_loss 1.771 | w2v_ctc_loss 1.308 | task_loss 0.933 | contrastive_loss 0.359 | total 4138.65 | n_correct 2361.98 | ppl 3.41 | accuracy 57.071 | wps 11980.5 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 8834 | lr 0.000150465 | gnorm 0.609 | clip 0 | loss_scale 1 | train_wall 1357 | gb_free 14.8 | wall 8160
2023-08-15 03:43:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 03:43:08 | INFO | fairseq.trainer | begin training epoch 7
2023-08-15 03:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 03:44:17 | INFO | train_inner | epoch 007:     66 / 1474 loss=2.304, trans_loss=3.51, nll_loss=1.723, w2v_ctc_loss=1.246, task_loss=0.918, contrastive_loss=0.273, total=4099.48, n_correct=2399.59, ppl=3.3, accuracy=58.534, wps=7640.2, ups=0.62, wpb=12236.9, bsz=460.3, num_updates=8900, lr=0.000149906, gnorm=0.593, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=8229
2023-08-15 03:45:49 | INFO | train_inner | epoch 007:    166 / 1474 loss=2.307, trans_loss=3.503, nll_loss=1.714, w2v_ctc_loss=1.235, task_loss=0.942, contrastive_loss=0.343, total=4107.4, n_correct=2407.25, ppl=3.28, accuracy=58.608, wps=13431.9, ups=1.1, wpb=12263.9, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.595, clip=0, loss_scale=1, train_wall=91, gb_free=16.6, wall=8321
2023-08-15 03:47:21 | INFO | train_inner | epoch 007:    266 / 1474 loss=2.279, trans_loss=3.499, nll_loss=1.708, w2v_ctc_loss=1.23, task_loss=0.937, contrastive_loss=0.249, total=4137.13, n_correct=2434.34, ppl=3.27, accuracy=58.841, wps=13319.2, ups=1.08, wpb=12346.5, bsz=454.9, num_updates=9100, lr=0.00014825, gnorm=0.57, clip=0, loss_scale=1, train_wall=92, gb_free=16.2, wall=8413
2023-08-15 03:48:54 | INFO | train_inner | epoch 007:    366 / 1474 loss=2.328, trans_loss=3.5, nll_loss=1.71, w2v_ctc_loss=1.223, task_loss=0.9, contrastive_loss=0.507, total=4199.72, n_correct=2470.48, ppl=3.27, accuracy=58.825, wps=13492.4, ups=1.08, wpb=12534, bsz=480.8, num_updates=9200, lr=0.000147442, gnorm=0.57, clip=0, loss_scale=1, train_wall=92, gb_free=17.3, wall=8506
2023-08-15 03:50:26 | INFO | train_inner | epoch 007:    466 / 1474 loss=2.307, trans_loss=3.498, nll_loss=1.709, w2v_ctc_loss=1.219, task_loss=0.932, contrastive_loss=0.424, total=4149.08, n_correct=2439.73, ppl=3.27, accuracy=58.802, wps=13477.2, ups=1.09, wpb=12391, bsz=459, num_updates=9300, lr=0.000146647, gnorm=0.583, clip=0, loss_scale=2, train_wall=91, gb_free=16.8, wall=8598
2023-08-15 03:51:58 | INFO | train_inner | epoch 007:    566 / 1474 loss=2.267, trans_loss=3.495, nll_loss=1.703, w2v_ctc_loss=1.218, task_loss=0.917, contrastive_loss=0.253, total=4168.84, n_correct=2464.55, ppl=3.26, accuracy=59.118, wps=13514.8, ups=1.09, wpb=12436.4, bsz=460, num_updates=9400, lr=0.000145865, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=8690
2023-08-15 03:53:31 | INFO | train_inner | epoch 007:    666 / 1474 loss=2.257, trans_loss=3.489, nll_loss=1.696, w2v_ctc_loss=1.214, task_loss=0.923, contrastive_loss=0.239, total=4164.13, n_correct=2472.15, ppl=3.24, accuracy=59.368, wps=13348.3, ups=1.07, wpb=12427.2, bsz=458.5, num_updates=9500, lr=0.000145095, gnorm=0.573, clip=0, loss_scale=2, train_wall=93, gb_free=15.3, wall=8783
2023-08-15 03:55:04 | INFO | train_inner | epoch 007:    766 / 1474 loss=2.256, trans_loss=3.487, nll_loss=1.694, w2v_ctc_loss=1.215, task_loss=0.971, contrastive_loss=0.239, total=4126.5, n_correct=2441.72, ppl=3.24, accuracy=59.172, wps=13331.1, ups=1.08, wpb=12320.2, bsz=450.3, num_updates=9600, lr=0.000144338, gnorm=0.564, clip=0, loss_scale=2, train_wall=92, gb_free=15, wall=8876
2023-08-15 03:56:36 | INFO | train_inner | epoch 007:    866 / 1474 loss=2.251, trans_loss=3.492, nll_loss=1.7, w2v_ctc_loss=1.211, task_loss=0.958, contrastive_loss=0.244, total=4133.53, n_correct=2448.6, ppl=3.25, accuracy=59.238, wps=13328.1, ups=1.08, wpb=12333.5, bsz=453.5, num_updates=9700, lr=0.000143592, gnorm=0.567, clip=0, loss_scale=2, train_wall=92, gb_free=12.4, wall=8968
2023-08-15 03:58:09 | INFO | train_inner | epoch 007:    966 / 1474 loss=2.262, trans_loss=3.48, nll_loss=1.686, w2v_ctc_loss=1.197, task_loss=0.886, contrastive_loss=0.345, total=4144.45, n_correct=2469.54, ppl=3.22, accuracy=59.587, wps=13380, ups=1.08, wpb=12374.7, bsz=476.9, num_updates=9800, lr=0.000142857, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=15.8, wall=9061
2023-08-15 03:59:41 | INFO | train_inner | epoch 007:   1066 / 1474 loss=2.247, trans_loss=3.492, nll_loss=1.702, w2v_ctc_loss=1.215, task_loss=0.983, contrastive_loss=0.216, total=4100.65, n_correct=2431.08, ppl=3.25, accuracy=59.285, wps=13267.2, ups=1.08, wpb=12242.5, bsz=435.4, num_updates=9900, lr=0.000142134, gnorm=0.563, clip=0, loss_scale=2, train_wall=92, gb_free=15.5, wall=9153
2023-08-15 04:01:14 | INFO | train_inner | epoch 007:   1166 / 1474 loss=2.296, trans_loss=3.475, nll_loss=1.682, w2v_ctc_loss=1.199, task_loss=0.907, contrastive_loss=0.481, total=4138.96, n_correct=2469.95, ppl=3.21, accuracy=59.676, wps=13365.2, ups=1.08, wpb=12367.7, bsz=471.9, num_updates=10000, lr=0.000141421, gnorm=0.581, clip=0, loss_scale=2, train_wall=92, gb_free=16.4, wall=9246
2023-08-15 04:01:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:01:43 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.17 | trans_loss 5.374 | nll_loss 2.699 | w2v_ctc_loss 1.409 | task_loss 4.551 | contrastive_loss 0.418 | total 4003.4 | n_correct 2522.3 | ppl 6.49 | accuracy 63.004 | uer 21.315 | wer 23.049 | raw_wer 23.049 | bleu 19.24 | wps 1701.9 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.24
2023-08-15 04:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-15 04:01:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-15 04:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-15 04:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.24) (writing took 58.23552869819105 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 04:04:13 | INFO | train_inner | epoch 007:   1266 / 1474 loss=2.234, trans_loss=3.478, nll_loss=1.684, w2v_ctc_loss=1.196, task_loss=0.956, contrastive_loss=0.243, total=4120.42, n_correct=2455.52, ppl=3.21, accuracy=59.594, wps=6870.2, ups=0.56, wpb=12304.2, bsz=446.6, num_updates=10100, lr=0.00014072, gnorm=0.459, clip=0, loss_scale=2, train_wall=91, gb_free=15.2, wall=9425
2023-08-15 04:05:45 | INFO | train_inner | epoch 007:   1366 / 1474 loss=2.249, trans_loss=3.473, nll_loss=1.678, w2v_ctc_loss=1.203, task_loss=0.875, contrastive_loss=0.281, total=4186.45, n_correct=2505.4, ppl=3.2, accuracy=59.845, wps=13561.1, ups=1.08, wpb=12499.3, bsz=479.7, num_updates=10200, lr=0.000140028, gnorm=0.437, clip=0, loss_scale=2, train_wall=92, gb_free=11.7, wall=9517
2023-08-15 04:07:20 | INFO | train_inner | epoch 007:   1466 / 1474 loss=2.253, trans_loss=3.476, nll_loss=1.684, w2v_ctc_loss=1.197, task_loss=0.989, contrastive_loss=0.339, total=4117.01, n_correct=2457.17, ppl=3.21, accuracy=59.683, wps=13008.1, ups=1.06, wpb=12300.4, bsz=448.4, num_updates=10300, lr=0.000139347, gnorm=0.437, clip=0, loss_scale=2, train_wall=94, gb_free=15.8, wall=9611
2023-08-15 04:07:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
2023-08-15 04:07:50 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.154 | trans_loss 5.35 | nll_loss 2.668 | w2v_ctc_loss 1.425 | task_loss 4.56 | contrastive_loss 0.403 | total 4003.4 | n_correct 2541 | ppl 6.35 | accuracy 63.471 | uer 21.336 | wer 23.101 | raw_wer 23.101 | bleu 19.58 | wps 2237.6 | wpb 4003.4 | bsz 141.8 | num_updates 10308 | best_bleu 19.58
2023-08-15 04:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10308 updates
2023-08-15 04:07:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10308 updates, score 19.58) (writing took 30.374376825988293 seconds)
2023-08-15 04:08:20 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-15 04:08:20 | INFO | train | epoch 007 | loss 2.272 | trans_loss 3.489 | nll_loss 1.697 | w2v_ctc_loss 1.213 | task_loss 0.935 | contrastive_loss 0.313 | total 4138.65 | n_correct 2451.44 | ppl 3.24 | accuracy 59.233 | wps 12043.5 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 10308 | lr 0.000139293 | gnorm 0.549 | clip 0 | loss_scale 2 | train_wall 1356 | gb_free 12.8 | wall 9672
2023-08-15 04:08:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:08:20 | INFO | fairseq.trainer | begin training epoch 8
2023-08-15 04:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:09:54 | INFO | train_inner | epoch 008:     92 / 1474 loss=2.198, trans_loss=3.465, nll_loss=1.662, w2v_ctc_loss=1.165, task_loss=1.002, contrastive_loss=0.232, total=4097.76, n_correct=2473, ppl=3.17, accuracy=60.35, wps=7918.8, ups=0.65, wpb=12216.9, bsz=437, num_updates=10400, lr=0.000138675, gnorm=0.444, clip=0, loss_scale=2, train_wall=92, gb_free=15.6, wall=9766
2023-08-15 04:11:26 | INFO | train_inner | epoch 008:    192 / 1474 loss=2.196, trans_loss=3.455, nll_loss=1.651, w2v_ctc_loss=1.158, task_loss=1.017, contrastive_loss=0.255, total=4039, n_correct=2441.28, ppl=3.14, accuracy=60.443, wps=13103.7, ups=1.09, wpb=12046.3, bsz=428.9, num_updates=10500, lr=0.000138013, gnorm=0.437, clip=0, loss_scale=2, train_wall=91, gb_free=14.5, wall=9858
2023-08-15 04:12:58 | INFO | train_inner | epoch 008:    292 / 1474 loss=2.196, trans_loss=3.449, nll_loss=1.645, w2v_ctc_loss=1.161, task_loss=0.879, contrastive_loss=0.251, total=4210.6, n_correct=2552.45, ppl=3.13, accuracy=60.62, wps=13594.6, ups=1.08, wpb=12566.5, bsz=486.9, num_updates=10600, lr=0.000137361, gnorm=0.431, clip=0, loss_scale=2, train_wall=92, gb_free=15.7, wall=9950
2023-08-15 04:14:32 | INFO | train_inner | epoch 008:    392 / 1474 loss=2.203, trans_loss=3.452, nll_loss=1.648, w2v_ctc_loss=1.166, task_loss=0.973, contrastive_loss=0.272, total=4139.64, n_correct=2505.65, ppl=3.13, accuracy=60.528, wps=13133.8, ups=1.06, wpb=12350.6, bsz=447.4, num_updates=10700, lr=0.000136717, gnorm=0.429, clip=0, loss_scale=2, train_wall=93, gb_free=14.8, wall=10044
2023-08-15 04:16:05 | INFO | train_inner | epoch 008:    492 / 1474 loss=2.259, trans_loss=3.451, nll_loss=1.649, w2v_ctc_loss=1.153, task_loss=0.853, contrastive_loss=0.532, total=4189.5, n_correct=2532.54, ppl=3.14, accuracy=60.45, wps=13441.7, ups=1.07, wpb=12508.9, bsz=499.4, num_updates=10800, lr=0.000136083, gnorm=0.439, clip=0, loss_scale=2, train_wall=93, gb_free=12.3, wall=10137
2023-08-15 04:17:38 | INFO | train_inner | epoch 008:    592 / 1474 loss=2.189, trans_loss=3.446, nll_loss=1.646, w2v_ctc_loss=1.171, task_loss=1.018, contrastive_loss=0.205, total=4061.09, n_correct=2456.01, ppl=3.13, accuracy=60.477, wps=13130.4, ups=1.08, wpb=12140.1, bsz=427.7, num_updates=10900, lr=0.000135457, gnorm=0.434, clip=0, loss_scale=2, train_wall=92, gb_free=16.2, wall=10230
2023-08-15 04:19:10 | INFO | train_inner | epoch 008:    692 / 1474 loss=2.18, trans_loss=3.442, nll_loss=1.637, w2v_ctc_loss=1.163, task_loss=0.956, contrastive_loss=0.217, total=4144.17, n_correct=2523, ppl=3.11, accuracy=60.881, wps=13351, ups=1.08, wpb=12370.7, bsz=450.4, num_updates=11000, lr=0.00013484, gnorm=0.429, clip=0, loss_scale=2, train_wall=92, gb_free=13, wall=10322
2023-08-15 04:20:43 | INFO | train_inner | epoch 008:    792 / 1474 loss=2.195, trans_loss=3.438, nll_loss=1.636, w2v_ctc_loss=1.158, task_loss=0.958, contrastive_loss=0.302, total=4117.36, n_correct=2503.82, ppl=3.11, accuracy=60.811, wps=13333.4, ups=1.08, wpb=12305.6, bsz=448.1, num_updates=11100, lr=0.000134231, gnorm=0.437, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=10415
2023-08-15 04:22:15 | INFO | train_inner | epoch 008:    892 / 1474 loss=2.185, trans_loss=3.441, nll_loss=1.637, w2v_ctc_loss=1.138, task_loss=0.884, contrastive_loss=0.308, total=4182.5, n_correct=2550.91, ppl=3.11, accuracy=60.99, wps=13524.7, ups=1.08, wpb=12489.6, bsz=478.7, num_updates=11200, lr=0.000133631, gnorm=0.433, clip=0, loss_scale=2, train_wall=92, gb_free=17.2, wall=10507
2023-08-15 04:23:47 | INFO | train_inner | epoch 008:    992 / 1474 loss=2.161, trans_loss=3.44, nll_loss=1.635, w2v_ctc_loss=1.143, task_loss=0.897, contrastive_loss=0.211, total=4155.49, n_correct=2536.57, ppl=3.11, accuracy=61.041, wps=13513.9, ups=1.09, wpb=12408.4, bsz=464, num_updates=11300, lr=0.000133038, gnorm=0.423, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=10599
2023-08-15 04:25:20 | INFO | train_inner | epoch 008:   1092 / 1474 loss=2.203, trans_loss=3.443, nll_loss=1.637, w2v_ctc_loss=1.14, task_loss=0.939, contrastive_loss=0.428, total=4186.39, n_correct=2548.38, ppl=3.11, accuracy=60.873, wps=13427.1, ups=1.07, wpb=12493.6, bsz=461.7, num_updates=11400, lr=0.000132453, gnorm=0.424, clip=0, loss_scale=4, train_wall=93, gb_free=14.9, wall=10692
2023-08-15 04:26:52 | INFO | train_inner | epoch 008:   1192 / 1474 loss=2.168, trans_loss=3.435, nll_loss=1.631, w2v_ctc_loss=1.149, task_loss=0.889, contrastive_loss=0.22, total=4178.48, n_correct=2553.29, ppl=3.1, accuracy=61.106, wps=13567.4, ups=1.09, wpb=12482, bsz=472.1, num_updates=11500, lr=0.000131876, gnorm=0.422, clip=0, loss_scale=4, train_wall=91, gb_free=15.5, wall=10784
2023-08-15 04:28:23 | INFO | train_inner | epoch 008:   1292 / 1474 loss=2.171, trans_loss=3.438, nll_loss=1.634, w2v_ctc_loss=1.151, task_loss=0.984, contrastive_loss=0.238, total=4064.4, n_correct=2476.85, ppl=3.1, accuracy=60.94, wps=13288.5, ups=1.09, wpb=12140.7, bsz=436, num_updates=11600, lr=0.000131306, gnorm=0.426, clip=0, loss_scale=4, train_wall=91, gb_free=15.7, wall=10875
2023-08-15 04:29:55 | INFO | train_inner | epoch 008:   1392 / 1474 loss=2.18, trans_loss=3.438, nll_loss=1.634, w2v_ctc_loss=1.139, task_loss=0.894, contrastive_loss=0.303, total=4163.91, n_correct=2546.72, ppl=3.1, accuracy=61.162, wps=13537.5, ups=1.09, wpb=12433, bsz=472.8, num_updates=11700, lr=0.000130744, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=16.2, wall=10967
2023-08-15 04:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:31:34 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.087 | trans_loss 5.283 | nll_loss 2.58 | w2v_ctc_loss 1.379 | task_loss 4.628 | contrastive_loss 0.38 | total 4003.4 | n_correct 2582.2 | ppl 5.98 | accuracy 64.5 | uer 19.866 | wer 21.658 | raw_wer 21.658 | bleu 19.93 | wps 2155.7 | wpb 4003.4 | bsz 141.8 | num_updates 11782 | best_bleu 19.93
2023-08-15 04:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11782 updates
2023-08-15 04:31:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11782 updates, score 19.93) (writing took 30.62983792461455 seconds)
2023-08-15 04:32:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-15 04:32:05 | INFO | train | epoch 008 | loss 2.19 | trans_loss 3.445 | nll_loss 1.641 | w2v_ctc_loss 1.153 | task_loss 0.935 | contrastive_loss 0.289 | total 4138.65 | n_correct 2516.08 | ppl 3.12 | accuracy 60.795 | wps 12778.5 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11782 | lr 0.000130288 | gnorm 0.43 | clip 0 | loss_scale 4 | train_wall 1355 | gb_free 16.6 | wall 11097
2023-08-15 04:32:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:32:06 | INFO | fairseq.trainer | begin training epoch 9
2023-08-15 04:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:32:31 | INFO | train_inner | epoch 009:     18 / 1474 loss=2.176, trans_loss=3.435, nll_loss=1.628, w2v_ctc_loss=1.125, task_loss=0.93, contrastive_loss=0.396, total=4111.15, n_correct=2520.34, ppl=3.09, accuracy=61.305, wps=7895.7, ups=0.64, wpb=12269.8, bsz=460.9, num_updates=11800, lr=0.000130189, gnorm=0.419, clip=0, loss_scale=4, train_wall=92, gb_free=16.7, wall=11123
2023-08-15 04:34:03 | INFO | train_inner | epoch 009:    118 / 1474 loss=2.12, trans_loss=3.408, nll_loss=1.594, w2v_ctc_loss=1.101, task_loss=0.874, contrastive_loss=0.232, total=4186.63, n_correct=2599, ppl=3.02, accuracy=62.079, wps=13511.2, ups=1.08, wpb=12503, bsz=481.5, num_updates=11900, lr=0.000129641, gnorm=0.417, clip=0, loss_scale=4, train_wall=92, gb_free=16.2, wall=11215
2023-08-15 04:35:36 | INFO | train_inner | epoch 009:    218 / 1474 loss=2.106, trans_loss=3.411, nll_loss=1.597, w2v_ctc_loss=1.1, task_loss=1.012, contrastive_loss=0.186, total=4071.82, n_correct=2522.54, ppl=3.03, accuracy=61.951, wps=13125.7, ups=1.08, wpb=12157.1, bsz=430.9, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=4, train_wall=92, gb_free=16.3, wall=11308
2023-08-15 04:35:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:36:00 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.289 | nll_loss 2.585 | w2v_ctc_loss 1.363 | task_loss 4.583 | contrastive_loss 0.375 | total 4003.4 | n_correct 2581.2 | ppl 6 | accuracy 64.475 | uer 19.924 | wer 21.852 | raw_wer 21.852 | bleu 19.96 | wps 2147.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.96
2023-08-15 04:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-15 04:36:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-15 04:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-15 04:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 19.96) (writing took 55.65827392973006 seconds)
2023-08-15 04:38:29 | INFO | train_inner | epoch 009:    318 / 1474 loss=2.106, trans_loss=3.401, nll_loss=1.588, w2v_ctc_loss=1.086, task_loss=0.86, contrastive_loss=0.24, total=4167.06, n_correct=2595.17, ppl=3.01, accuracy=62.278, wps=7198.5, ups=0.58, wpb=12450.2, bsz=485.4, num_updates=12100, lr=0.000128565, gnorm=0.416, clip=0, loss_scale=4, train_wall=92, gb_free=14.6, wall=11481
2023-08-15 04:40:02 | INFO | train_inner | epoch 009:    418 / 1474 loss=2.111, trans_loss=3.417, nll_loss=1.605, w2v_ctc_loss=1.102, task_loss=0.94, contrastive_loss=0.197, total=4175.09, n_correct=2581.8, ppl=3.04, accuracy=61.838, wps=13307.8, ups=1.07, wpb=12466.4, bsz=457.5, num_updates=12200, lr=0.000128037, gnorm=0.417, clip=0, loss_scale=4, train_wall=93, gb_free=17, wall=11574
2023-08-15 04:41:35 | INFO | train_inner | epoch 009:    518 / 1474 loss=2.137, trans_loss=3.414, nll_loss=1.601, w2v_ctc_loss=1.12, task_loss=0.982, contrastive_loss=0.252, total=4118.47, n_correct=2547.22, ppl=3.03, accuracy=61.849, wps=13332.3, ups=1.08, wpb=12292.7, bsz=439.7, num_updates=12300, lr=0.000127515, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=17.2, wall=11667
2023-08-15 04:43:07 | INFO | train_inner | epoch 009:    618 / 1474 loss=2.128, trans_loss=3.407, nll_loss=1.596, w2v_ctc_loss=1.095, task_loss=0.939, contrastive_loss=0.31, total=4141.76, n_correct=2568.19, ppl=3.02, accuracy=62.007, wps=13373.2, ups=1.08, wpb=12378.7, bsz=462.3, num_updates=12400, lr=0.000127, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=16.7, wall=11759
2023-08-15 04:44:38 | INFO | train_inner | epoch 009:    718 / 1474 loss=2.118, trans_loss=3.413, nll_loss=1.603, w2v_ctc_loss=1.119, task_loss=0.972, contrastive_loss=0.196, total=4075.02, n_correct=2518.77, ppl=3.04, accuracy=61.81, wps=13337.2, ups=1.1, wpb=12176, bsz=443.4, num_updates=12500, lr=0.000126491, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=17.2, wall=11850
2023-08-15 04:46:12 | INFO | train_inner | epoch 009:    818 / 1474 loss=2.172, trans_loss=3.408, nll_loss=1.597, w2v_ctc_loss=1.105, task_loss=0.851, contrastive_loss=0.438, total=4214.28, n_correct=2607.52, ppl=3.03, accuracy=61.873, wps=13491.4, ups=1.07, wpb=12593.1, bsz=499.2, num_updates=12600, lr=0.000125988, gnorm=0.436, clip=0, loss_scale=4, train_wall=93, gb_free=16.5, wall=11944
2023-08-15 04:47:46 | INFO | train_inner | epoch 009:    918 / 1474 loss=2.148, trans_loss=3.413, nll_loss=1.597, w2v_ctc_loss=1.106, task_loss=0.959, contrastive_loss=0.412, total=4157.54, n_correct=2575.78, ppl=3.03, accuracy=61.954, wps=13153.5, ups=1.06, wpb=12400.4, bsz=452, num_updates=12700, lr=0.000125491, gnorm=0.414, clip=0, loss_scale=4, train_wall=94, gb_free=16, wall=12038
2023-08-15 04:49:18 | INFO | train_inner | epoch 009:   1018 / 1474 loss=2.107, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.107, task_loss=1.046, contrastive_loss=0.193, total=4093.77, n_correct=2533.16, ppl=3.04, accuracy=61.878, wps=13286, ups=1.09, wpb=12221, bsz=423.7, num_updates=12800, lr=0.000125, gnorm=0.421, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=12130
2023-08-15 04:50:50 | INFO | train_inner | epoch 009:   1118 / 1474 loss=2.11, trans_loss=3.417, nll_loss=1.602, w2v_ctc_loss=1.098, task_loss=0.892, contrastive_loss=0.219, total=4173.97, n_correct=2588.53, ppl=3.03, accuracy=62.016, wps=13480.9, ups=1.08, wpb=12442.6, bsz=471.4, num_updates=12900, lr=0.000124515, gnorm=0.425, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=12222
2023-08-15 04:52:24 | INFO | train_inner | epoch 009:   1218 / 1474 loss=2.114, trans_loss=3.412, nll_loss=1.6, w2v_ctc_loss=1.115, task_loss=0.983, contrastive_loss=0.199, total=4144.88, n_correct=2569, ppl=3.03, accuracy=61.98, wps=13264.3, ups=1.07, wpb=12376.1, bsz=450, num_updates=13000, lr=0.000124035, gnorm=0.423, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=12316
2023-08-15 04:53:56 | INFO | train_inner | epoch 009:   1318 / 1474 loss=2.136, trans_loss=3.404, nll_loss=1.589, w2v_ctc_loss=1.089, task_loss=0.854, contrastive_loss=0.388, total=4200.61, n_correct=2618.38, ppl=3.01, accuracy=62.333, wps=13553.8, ups=1.08, wpb=12534.4, bsz=490.7, num_updates=13100, lr=0.00012356, gnorm=0.42, clip=0, loss_scale=4, train_wall=92, gb_free=15.3, wall=12408
2023-08-15 04:55:28 | INFO | train_inner | epoch 009:   1418 / 1474 loss=2.103, trans_loss=3.419, nll_loss=1.607, w2v_ctc_loss=1.106, task_loss=1.004, contrastive_loss=0.178, total=4075.96, n_correct=2520.68, ppl=3.05, accuracy=61.843, wps=13288.8, ups=1.09, wpb=12161.1, bsz=430.6, num_updates=13200, lr=0.000123091, gnorm=0.415, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=12500
2023-08-15 04:56:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 04:56:42 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.047 | trans_loss 5.253 | nll_loss 2.548 | w2v_ctc_loss 1.334 | task_loss 4.57 | contrastive_loss 0.368 | total 4003.4 | n_correct 2599 | ppl 5.85 | accuracy 64.92 | uer 19.168 | wer 21.017 | raw_wer 21.017 | bleu 20.72 | wps 2102.5 | wpb 4003.4 | bsz 141.8 | num_updates 13256 | best_bleu 20.72
2023-08-15 04:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13256 updates
2023-08-15 04:56:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 04:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13256 updates, score 20.72) (writing took 29.309386936947703 seconds)
2023-08-15 04:57:12 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-15 04:57:12 | INFO | train | epoch 009 | loss 2.123 | trans_loss 3.411 | nll_loss 1.598 | w2v_ctc_loss 1.103 | task_loss 0.936 | contrastive_loss 0.266 | total 4138.65 | n_correct 2565.36 | ppl 3.03 | accuracy 61.986 | wps 12086.5 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 13256 | lr 0.000122831 | gnorm 0.421 | clip 0 | loss_scale 4 | train_wall 1357 | gb_free 11.2 | wall 12604
2023-08-15 04:57:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 04:57:13 | INFO | fairseq.trainer | begin training epoch 10
2023-08-15 04:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 04:58:01 | INFO | train_inner | epoch 010:     44 / 1474 loss=2.095, trans_loss=3.4, nll_loss=1.583, w2v_ctc_loss=1.075, task_loss=0.874, contrastive_loss=0.27, total=4112.83, n_correct=2571.19, ppl=3, accuracy=62.516, wps=8012.7, ups=0.65, wpb=12275.4, bsz=475.1, num_updates=13300, lr=0.000122628, gnorm=0.411, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=12653
2023-08-15 04:59:34 | INFO | train_inner | epoch 010:    144 / 1474 loss=2.052, trans_loss=3.384, nll_loss=1.564, w2v_ctc_loss=1.05, task_loss=0.903, contrastive_loss=0.192, total=4230.29, n_correct=2661.03, ppl=2.96, accuracy=62.904, wps=13596.3, ups=1.08, wpb=12634.2, bsz=472.7, num_updates=13400, lr=0.000122169, gnorm=0.406, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=12746
2023-08-15 05:01:06 | INFO | train_inner | epoch 010:    244 / 1474 loss=2.08, trans_loss=3.381, nll_loss=1.559, w2v_ctc_loss=1.058, task_loss=0.92, contrastive_loss=0.313, total=4131.59, n_correct=2602.35, ppl=2.95, accuracy=62.987, wps=13410.3, ups=1.09, wpb=12331.3, bsz=463.6, num_updates=13500, lr=0.000121716, gnorm=0.409, clip=0, loss_scale=8, train_wall=91, gb_free=9.6, wall=12838
2023-08-15 05:02:38 | INFO | train_inner | epoch 010:    344 / 1474 loss=2.06, trans_loss=3.381, nll_loss=1.562, w2v_ctc_loss=1.055, task_loss=0.943, contrastive_loss=0.228, total=4135.23, n_correct=2602.23, ppl=2.95, accuracy=62.928, wps=13355.2, ups=1.08, wpb=12360.3, bsz=454.8, num_updates=13600, lr=0.000121268, gnorm=0.41, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=12930
2023-08-15 05:04:12 | INFO | train_inner | epoch 010:    444 / 1474 loss=2.085, trans_loss=3.385, nll_loss=1.565, w2v_ctc_loss=1.045, task_loss=0.899, contrastive_loss=0.394, total=4197.95, n_correct=2642.1, ppl=2.96, accuracy=62.938, wps=13421.7, ups=1.07, wpb=12531.8, bsz=481.2, num_updates=13700, lr=0.000120824, gnorm=0.402, clip=0, loss_scale=8, train_wall=93, gb_free=15.2, wall=13024
2023-08-15 05:05:45 | INFO | train_inner | epoch 010:    544 / 1474 loss=2.069, trans_loss=3.397, nll_loss=1.577, w2v_ctc_loss=1.078, task_loss=1.017, contrastive_loss=0.179, total=4097.61, n_correct=2565.62, ppl=2.98, accuracy=62.613, wps=13107.6, ups=1.07, wpb=12219.2, bsz=434.6, num_updates=13800, lr=0.000120386, gnorm=0.412, clip=0, loss_scale=8, train_wall=93, gb_free=17.6, wall=13117
2023-08-15 05:07:18 | INFO | train_inner | epoch 010:    644 / 1474 loss=2.089, trans_loss=3.39, nll_loss=1.571, w2v_ctc_loss=1.067, task_loss=0.872, contrastive_loss=0.298, total=4187.04, n_correct=2628.14, ppl=2.97, accuracy=62.768, wps=13471.2, ups=1.08, wpb=12494.9, bsz=483.5, num_updates=13900, lr=0.000119952, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=16.2, wall=13210
2023-08-15 05:08:49 | INFO | train_inner | epoch 010:    744 / 1474 loss=2.07, trans_loss=3.388, nll_loss=1.568, w2v_ctc_loss=1.084, task_loss=0.951, contrastive_loss=0.175, total=4112.31, n_correct=2580.36, ppl=2.97, accuracy=62.747, wps=13394.9, ups=1.09, wpb=12277.4, bsz=448.4, num_updates=14000, lr=0.000119523, gnorm=0.425, clip=0, loss_scale=8, train_wall=91, gb_free=12, wall=13301
2023-08-15 05:08:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:09:13 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.05 | trans_loss 5.244 | nll_loss 2.53 | w2v_ctc_loss 1.377 | task_loss 4.65 | contrastive_loss 0.354 | total 4003.4 | n_correct 2600.7 | ppl 5.78 | accuracy 64.962 | uer 19.85 | wer 21.767 | raw_wer 21.767 | bleu 20.54 | wps 2154.4 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 20.72
2023-08-15 05:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-15 05:09:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-15 05:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-15 05:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 20.54) (writing took 42.75176669098437 seconds)
2023-08-15 05:11:31 | INFO | train_inner | epoch 010:    844 / 1474 loss=2.054, trans_loss=3.389, nll_loss=1.569, w2v_ctc_loss=1.061, task_loss=0.927, contrastive_loss=0.181, total=4135.95, n_correct=2596.12, ppl=2.97, accuracy=62.77, wps=7644.1, ups=0.62, wpb=12346.8, bsz=456.9, num_updates=14100, lr=0.000119098, gnorm=0.467, clip=0, loss_scale=8, train_wall=92, gb_free=15.5, wall=13463
2023-08-15 05:13:04 | INFO | train_inner | epoch 010:    944 / 1474 loss=2.061, trans_loss=3.384, nll_loss=1.562, w2v_ctc_loss=1.06, task_loss=0.892, contrastive_loss=0.219, total=4169.57, n_correct=2627.18, ppl=2.95, accuracy=63.008, wps=13411.4, ups=1.08, wpb=12439, bsz=473.3, num_updates=14200, lr=0.000118678, gnorm=0.407, clip=0, loss_scale=8, train_wall=92, gb_free=13.2, wall=13556
2023-08-15 05:14:36 | INFO | train_inner | epoch 010:   1044 / 1474 loss=2.056, trans_loss=3.386, nll_loss=1.565, w2v_ctc_loss=1.065, task_loss=1.024, contrastive_loss=0.186, total=4058.1, n_correct=2548.81, ppl=2.96, accuracy=62.808, wps=13182.9, ups=1.09, wpb=12115.2, bsz=430.4, num_updates=14300, lr=0.000118262, gnorm=0.417, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=13647
2023-08-15 05:16:07 | INFO | train_inner | epoch 010:   1144 / 1474 loss=2.067, trans_loss=3.392, nll_loss=1.574, w2v_ctc_loss=1.082, task_loss=1.052, contrastive_loss=0.17, total=4034.12, n_correct=2525.3, ppl=2.98, accuracy=62.599, wps=13148.2, ups=1.09, wpb=12044.8, bsz=418.2, num_updates=14400, lr=0.000117851, gnorm=0.416, clip=0, loss_scale=8, train_wall=91, gb_free=15.3, wall=13739
2023-08-15 05:17:40 | INFO | train_inner | epoch 010:   1244 / 1474 loss=2.053, trans_loss=3.378, nll_loss=1.56, w2v_ctc_loss=1.071, task_loss=0.955, contrastive_loss=0.168, total=4107.11, n_correct=2581.69, ppl=2.95, accuracy=62.859, wps=13273.1, ups=1.08, wpb=12283.5, bsz=446.4, num_updates=14500, lr=0.000117444, gnorm=0.415, clip=0, loss_scale=8, train_wall=92, gb_free=14.8, wall=13832
2023-08-15 05:19:12 | INFO | train_inner | epoch 010:   1344 / 1474 loss=2.056, trans_loss=3.385, nll_loss=1.566, w2v_ctc_loss=1.069, task_loss=0.94, contrastive_loss=0.18, total=4143.63, n_correct=2610.67, ppl=2.96, accuracy=63.004, wps=13351.3, ups=1.08, wpb=12373.1, bsz=457, num_updates=14600, lr=0.000117041, gnorm=0.413, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13924
2023-08-15 05:20:46 | INFO | train_inner | epoch 010:   1444 / 1474 loss=2.11, trans_loss=3.393, nll_loss=1.574, w2v_ctc_loss=1.049, task_loss=0.884, contrastive_loss=0.432, total=4183.87, n_correct=2624.11, ppl=2.98, accuracy=62.72, wps=13318.2, ups=1.07, wpb=12480.2, bsz=480.8, num_updates=14700, lr=0.000116642, gnorm=0.419, clip=0, loss_scale=8, train_wall=93, gb_free=12.9, wall=14018
2023-08-15 05:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:21:37 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.031 | trans_loss 5.23 | nll_loss 2.516 | w2v_ctc_loss 1.352 | task_loss 4.599 | contrastive_loss 0.35 | total 4003.4 | n_correct 2617.5 | ppl 5.72 | accuracy 65.382 | uer 18.799 | wer 20.715 | raw_wer 20.715 | bleu 21.2 | wps 2170.5 | wpb 4003.4 | bsz 141.8 | num_updates 14730 | best_bleu 21.2
2023-08-15 05:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14730 updates
2023-08-15 05:21:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 05:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 05:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14730 updates, score 21.2) (writing took 31.978072565048933 seconds)
2023-08-15 05:22:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-15 05:22:10 | INFO | train | epoch 010 | loss 2.07 | trans_loss 3.386 | nll_loss 1.567 | w2v_ctc_loss 1.062 | task_loss 0.936 | contrastive_loss 0.248 | total 4138.65 | n_correct 2600.62 | ppl 2.96 | accuracy 62.837 | wps 12163.7 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14730 | lr 0.000116524 | gnorm 0.416 | clip 0 | loss_scale 8 | train_wall 1356 | gb_free 17 | wall 14102
2023-08-15 05:22:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 05:22:10 | INFO | fairseq.trainer | begin training epoch 11
2023-08-15 05:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 05:23:21 | INFO | train_inner | epoch 011:     70 / 1474 loss=2.037, trans_loss=3.364, nll_loss=1.538, w2v_ctc_loss=1.034, task_loss=0.879, contrastive_loss=0.255, total=4162.14, n_correct=2647.73, ppl=2.9, accuracy=63.615, wps=8005.1, ups=0.64, wpb=12425.4, bsz=474.3, num_updates=14800, lr=0.000116248, gnorm=0.4, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=14173
2023-08-15 05:24:54 | INFO | train_inner | epoch 011:    170 / 1474 loss=2.019, trans_loss=3.364, nll_loss=1.54, w2v_ctc_loss=1.033, task_loss=0.958, contrastive_loss=0.175, total=4103.74, n_correct=2605.78, ppl=2.91, accuracy=63.498, wps=13246.8, ups=1.08, wpb=12261.3, bsz=450.5, num_updates=14900, lr=0.000115857, gnorm=0.413, clip=0, loss_scale=8, train_wall=92, gb_free=16.5, wall=14266
2023-08-15 05:26:26 | INFO | train_inner | epoch 011:    270 / 1474 loss=2.009, trans_loss=3.365, nll_loss=1.539, w2v_ctc_loss=1.026, task_loss=0.972, contrastive_loss=0.161, total=4114.56, n_correct=2612.41, ppl=2.91, accuracy=63.492, wps=13338.4, ups=1.09, wpb=12288.3, bsz=443.1, num_updates=15000, lr=0.00011547, gnorm=0.404, clip=0, loss_scale=8, train_wall=92, gb_free=15.3, wall=14358
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 05:27:35 | INFO | train_inner | epoch 011:    370 / 1474 loss=2.075, trans_loss=5, nll_loss=2.285, w2v_ctc_loss=0.768, task_loss=1.439, contrastive_loss=0.131, total=4094.93, n_correct=2602.06, ppl=4.87, accuracy=63.543, wps=11997.1, ups=1.46, wpb=8223.5, bsz=297, num_updates=15100, lr=0.000115087, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=11.8, wall=14427
2023-08-15 05:28:44 | INFO | train_inner | epoch 011:    470 / 1474 loss=2.099, trans_loss=5.038, nll_loss=2.316, w2v_ctc_loss=0.766, task_loss=1.458, contrastive_loss=0.249, total=4113.98, n_correct=2596.24, ppl=4.98, accuracy=63.108, wps=11777.4, ups=1.43, wpb=8228, bsz=302.3, num_updates=15200, lr=0.000114708, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=9.7, wall=14496
2023-08-15 05:29:54 | INFO | train_inner | epoch 011:    570 / 1474 loss=2.1, trans_loss=5.034, nll_loss=2.311, w2v_ctc_loss=0.781, task_loss=1.507, contrastive_loss=0.243, total=4074.83, n_correct=2575.1, ppl=4.96, accuracy=63.195, wps=11638.4, ups=1.43, wpb=8149.7, bsz=293.3, num_updates=15300, lr=0.000114332, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=15, wall=14566
2023-08-15 05:31:04 | INFO | train_inner | epoch 011:    670 / 1474 loss=2.097, trans_loss=5.021, nll_loss=2.295, w2v_ctc_loss=0.775, task_loss=1.362, contrastive_loss=0.304, total=4161.4, n_correct=2637.87, ppl=4.91, accuracy=63.389, wps=11898.9, ups=1.43, wpb=8322.8, bsz=311.9, num_updates=15400, lr=0.000113961, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=14636
2023-08-15 05:32:14 | INFO | train_inner | epoch 011:    770 / 1474 loss=2.089, trans_loss=5.034, nll_loss=2.312, w2v_ctc_loss=0.784, task_loss=1.442, contrastive_loss=0.129, total=4153.23, n_correct=2630.14, ppl=4.97, accuracy=63.328, wps=11974.1, ups=1.44, wpb=8306.5, bsz=301.5, num_updates=15500, lr=0.000113592, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=14706
2023-08-15 05:33:23 | INFO | train_inner | epoch 011:    870 / 1474 loss=2.09, trans_loss=5.036, nll_loss=2.315, w2v_ctc_loss=0.782, task_loss=1.468, contrastive_loss=0.12, total=4122.58, n_correct=2603.2, ppl=4.97, accuracy=63.145, wps=11941.9, ups=1.45, wpb=8245.2, bsz=293.8, num_updates=15600, lr=0.000113228, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=14775
2023-08-15 05:34:33 | INFO | train_inner | epoch 011:    970 / 1474 loss=2.084, trans_loss=5.029, nll_loss=2.305, w2v_ctc_loss=0.779, task_loss=1.415, contrastive_loss=0.133, total=4150.11, n_correct=2629.07, ppl=4.94, accuracy=63.349, wps=11905.2, ups=1.43, wpb=8300.2, bsz=304.8, num_updates=15700, lr=0.000112867, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=14845
2023-08-15 05:35:42 | INFO | train_inner | epoch 011:   1070 / 1474 loss=2.084, trans_loss=5.027, nll_loss=2.304, w2v_ctc_loss=0.776, task_loss=1.378, contrastive_loss=0.15, total=4146.14, n_correct=2630.65, ppl=4.94, accuracy=63.448, wps=11973.1, ups=1.44, wpb=8292.3, bsz=309.8, num_updates=15800, lr=0.000112509, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=14914
2023-08-15 05:36:51 | INFO | train_inner | epoch 011:   1170 / 1474 loss=2.084, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.776, task_loss=1.384, contrastive_loss=0.144, total=4182.57, n_correct=2651.36, ppl=4.95, accuracy=63.391, wps=12066.8, ups=1.44, wpb=8365.1, bsz=311.4, num_updates=15900, lr=0.000112154, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=14983
2023-08-15 05:38:01 | INFO | train_inner | epoch 011:   1270 / 1474 loss=2.095, trans_loss=5.029, nll_loss=2.307, w2v_ctc_loss=0.783, task_loss=1.382, contrastive_loss=0.197, total=4157.11, n_correct=2629.69, ppl=4.95, accuracy=63.258, wps=11945.6, ups=1.44, wpb=8314.2, bsz=308.6, num_updates=16000, lr=0.000111803, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=15053
2023-08-15 05:38:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 05:38:24 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.028 | trans_loss 5.223 | nll_loss 2.508 | w2v_ctc_loss 1.363 | task_loss 4.62 | contrastive_loss 0.345 | total 4003.4 | n_correct 2622.4 | ppl 5.69 | accuracy 65.504 | uer 18.791 | wer 20.704 | raw_wer 20.704 | bleu 20.84 | wps 2257.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.2
2023-08-15 05:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-15 05:38:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-15 05:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-15 05:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.84) (writing took 41.220497814938426 seconds)
2023-08-15 05:40:16 | INFO | train_inner | epoch 011:   1370 / 1474 loss=2.101, trans_loss=5.027, nll_loss=2.305, w2v_ctc_loss=0.769, task_loss=1.293, contrastive_loss=0.363, total=4192.31, n_correct=2655.84, ppl=4.94, accuracy=63.35, wps=6192.4, ups=0.74, wpb=8384.6, bsz=328.3, num_updates=16100, lr=0.000111456, gnorm=0.521, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=15188
2023-08-15 05:41:26 | INFO | train_inner | epoch 011:   1470 / 1474 loss=2.077, trans_loss=5.025, nll_loss=2.301, w2v_ctc_loss=0.773, task_loss=1.352, contrastive_loss=0.137, total=4162.97, n_correct=2645.19, ppl=4.93, accuracy=63.541, wps=11914.1, ups=1.43, wpb=8325.9, bsz=313, num_updates=16200, lr=0.000111111, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=15258
2023-08-15 05:41:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:41:52 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.016 | trans_loss 5.216 | nll_loss 2.494 | w2v_ctc_loss 1.338 | task_loss 4.627 | contrastive_loss 0.344 | total 4003.4 | n_correct 2629.4 | ppl 5.63 | accuracy 65.679 | uer 19.003 | wer 20.902 | raw_wer 20.902 | bleu 20.85 | wps 2267.5 | wpb 4003.4 | bsz 141.8 | num_updates 16204 | best_bleu 21.2
2023-08-15 05:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16204 updates
2023-08-15 05:41:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt
2023-08-15 05:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt
2023-08-15 05:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_20.8504.pt (epoch 11 @ 16204 updates, score 20.85) (writing took 20.98008725605905 seconds)
2023-08-15 05:42:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-15 05:42:13 | INFO | train | epoch 011 | loss 2.071 | trans_loss 4.611 | nll_loss 2.113 | w2v_ctc_loss 0.839 | task_loss 1.287 | contrastive_loss 0.187 | total 4138.65 | n_correct 2623.22 | ppl 4.33 | accuracy 63.383 | wps 11056.4 | ups 1.22 | wpb 9025.9 | bsz 333.5 | num_updates 16204 | lr 0.000111097 | gnorm 0.503 | clip 0 | loss_scale 16 | train_wall 1079 | gb_free 16.9 | wall 15305
2023-08-15 05:42:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 05:42:13 | INFO | fairseq.trainer | begin training epoch 12
2023-08-15 05:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 05:43:27 | INFO | train_inner | epoch 012:     96 / 1474 loss=2.061, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.758, task_loss=1.347, contrastive_loss=0.167, total=4145.21, n_correct=2663, ppl=4.76, accuracy=64.243, wps=6846.1, ups=0.83, wpb=8290.4, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=15379
2023-08-15 05:44:36 | INFO | train_inner | epoch 012:    196 / 1474 loss=2.063, trans_loss=4.994, nll_loss=2.259, w2v_ctc_loss=0.761, task_loss=1.441, contrastive_loss=0.122, total=4124.1, n_correct=2639.02, ppl=4.79, accuracy=63.99, wps=11906.9, ups=1.44, wpb=8248.2, bsz=296.1, num_updates=16400, lr=0.000110432, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=15448
2023-08-15 05:45:46 | INFO | train_inner | epoch 012:    296 / 1474 loss=2.059, trans_loss=4.994, nll_loss=2.261, w2v_ctc_loss=0.749, task_loss=1.312, contrastive_loss=0.152, total=4208.07, n_correct=2699.42, ppl=4.79, accuracy=64.149, wps=12119.7, ups=1.44, wpb=8416.1, bsz=321.7, num_updates=16500, lr=0.000110096, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=11.9, wall=15518
2023-08-15 05:46:56 | INFO | train_inner | epoch 012:    396 / 1474 loss=2.065, trans_loss=5, nll_loss=2.267, w2v_ctc_loss=0.764, task_loss=1.384, contrastive_loss=0.135, total=4144.42, n_correct=2651.45, ppl=4.81, accuracy=63.976, wps=11872.4, ups=1.43, wpb=8288.8, bsz=305.3, num_updates=16600, lr=0.000109764, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=15588
2023-08-15 05:48:04 | INFO | train_inner | epoch 012:    496 / 1474 loss=2.072, trans_loss=5.01, nll_loss=2.282, w2v_ctc_loss=0.768, task_loss=1.429, contrastive_loss=0.142, total=4095.26, n_correct=2617.26, ppl=4.86, accuracy=63.909, wps=11907.9, ups=1.45, wpb=8190.5, bsz=299.8, num_updates=16700, lr=0.000109435, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=15656
2023-08-15 05:49:14 | INFO | train_inner | epoch 012:    596 / 1474 loss=2.076, trans_loss=5.003, nll_loss=2.272, w2v_ctc_loss=0.768, task_loss=1.327, contrastive_loss=0.209, total=4204.6, n_correct=2682.73, ppl=4.83, accuracy=63.805, wps=12024.6, ups=1.43, wpb=8409.2, bsz=319.2, num_updates=16800, lr=0.000109109, gnorm=0.56, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=15726
2023-08-15 05:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 05:50:24 | INFO | train_inner | epoch 012:    697 / 1474 loss=2.06, trans_loss=4.999, nll_loss=2.267, w2v_ctc_loss=0.756, task_loss=1.346, contrastive_loss=0.135, total=4175.27, n_correct=2675.61, ppl=4.81, accuracy=64.082, wps=12010.4, ups=1.44, wpb=8350.5, bsz=312.5, num_updates=16900, lr=0.000108786, gnorm=0.514, clip=0, loss_scale=8, train_wall=69, gb_free=15.1, wall=15796
2023-08-15 05:51:34 | INFO | train_inner | epoch 012:    797 / 1474 loss=2.067, trans_loss=4.997, nll_loss=2.264, w2v_ctc_loss=0.77, task_loss=1.438, contrastive_loss=0.13, total=4083.9, n_correct=2613.62, ppl=4.8, accuracy=63.998, wps=11726, ups=1.44, wpb=8167.8, bsz=296.3, num_updates=17000, lr=0.000108465, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=12.5, wall=15866
2023-08-15 05:52:43 | INFO | train_inner | epoch 012:    897 / 1474 loss=2.069, trans_loss=4.998, nll_loss=2.266, w2v_ctc_loss=0.761, task_loss=1.433, contrastive_loss=0.181, total=4168.41, n_correct=2670.14, ppl=4.81, accuracy=64.057, wps=12031.6, ups=1.44, wpb=8336.8, bsz=306.2, num_updates=17100, lr=0.000108148, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=15.3, wall=15935
2023-08-15 05:53:52 | INFO | train_inner | epoch 012:    997 / 1474 loss=2.072, trans_loss=5.003, nll_loss=2.272, w2v_ctc_loss=0.77, task_loss=1.433, contrastive_loss=0.191, total=4121.91, n_correct=2636.05, ppl=4.83, accuracy=63.952, wps=11905.8, ups=1.44, wpb=8243.8, bsz=301.5, num_updates=17200, lr=0.000107833, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=16004
2023-08-15 05:55:02 | INFO | train_inner | epoch 012:   1097 / 1474 loss=2.084, trans_loss=5.009, nll_loss=2.28, w2v_ctc_loss=0.773, task_loss=1.466, contrastive_loss=0.233, total=4055.97, n_correct=2588.37, ppl=4.86, accuracy=63.816, wps=11653.9, ups=1.44, wpb=8111.9, bsz=291.2, num_updates=17300, lr=0.000107521, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=11.8, wall=16074
2023-08-15 05:56:11 | INFO | train_inner | epoch 012:   1197 / 1474 loss=2.089, trans_loss=5.024, nll_loss=2.299, w2v_ctc_loss=0.785, task_loss=1.376, contrastive_loss=0.203, total=4187.55, n_correct=2660.14, ppl=4.92, accuracy=63.525, wps=12009.4, ups=1.43, wpb=8375.1, bsz=317.5, num_updates=17400, lr=0.000107211, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=16143
2023-08-15 05:57:20 | INFO | train_inner | epoch 012:   1297 / 1474 loss=2.072, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.776, task_loss=1.559, contrastive_loss=0.116, total=4075.32, n_correct=2599.26, ppl=4.84, accuracy=63.781, wps=11816.8, ups=1.45, wpb=8150.6, bsz=287, num_updates=17500, lr=0.000106904, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=16.9, wall=16212
2023-08-15 05:58:30 | INFO | train_inner | epoch 012:   1397 / 1474 loss=2.074, trans_loss=5.012, nll_loss=2.284, w2v_ctc_loss=0.761, task_loss=1.42, contrastive_loss=0.219, total=4137.07, n_correct=2637.14, ppl=4.87, accuracy=63.744, wps=11851.9, ups=1.43, wpb=8274.1, bsz=305.6, num_updates=17600, lr=0.0001066, gnorm=0.548, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=16282
2023-08-15 05:59:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 05:59:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.023 | trans_loss 5.21 | nll_loss 2.487 | w2v_ctc_loss 1.383 | task_loss 4.633 | contrastive_loss 0.345 | total 4003.4 | n_correct 2625.7 | ppl 5.6 | accuracy 65.587 | uer 18.682 | wer 20.54 | raw_wer 20.54 | bleu 21.18 | wps 2228.3 | wpb 4003.4 | bsz 141.8 | num_updates 17677 | best_bleu 21.2
2023-08-15 05:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17677 updates
2023-08-15 05:59:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt
2023-08-15 05:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt
2023-08-15 06:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.1804.pt (epoch 12 @ 17677 updates, score 21.18) (writing took 22.721838489174843 seconds)
2023-08-15 06:00:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-15 06:00:10 | INFO | train | epoch 012 | loss 2.07 | trans_loss 5.003 | nll_loss 2.272 | w2v_ctc_loss 0.766 | task_loss 1.408 | contrastive_loss 0.165 | total 4136.79 | n_correct 2644.53 | ppl 4.83 | accuracy 63.927 | wps 11311.1 | ups 1.37 | wpb 8273.6 | bsz 304.9 | num_updates 17677 | lr 0.000106368 | gnorm 0.53 | clip 0 | loss_scale 8 | train_wall 1016 | gb_free 12.5 | wall 16382
2023-08-15 06:00:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:00:11 | INFO | fairseq.trainer | begin training epoch 13
2023-08-15 06:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:00:34 | INFO | train_inner | epoch 013:     23 / 1474 loss=2.069, trans_loss=5.005, nll_loss=2.275, w2v_ctc_loss=0.775, task_loss=1.446, contrastive_loss=0.124, total=4092.72, n_correct=2616.12, ppl=4.84, accuracy=63.921, wps=6626.7, ups=0.81, wpb=8185.4, bsz=296.2, num_updates=17700, lr=0.000106299, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=16406
2023-08-15 06:01:43 | INFO | train_inner | epoch 013:    123 / 1474 loss=2.053, trans_loss=4.978, nll_loss=2.239, w2v_ctc_loss=0.753, task_loss=1.401, contrastive_loss=0.139, total=4178.31, n_correct=2690.43, ppl=4.72, accuracy=64.39, wps=12004.5, ups=1.44, wpb=8356.6, bsz=304, num_updates=17800, lr=0.000106, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=16475
2023-08-15 06:02:53 | INFO | train_inner | epoch 013:    223 / 1474 loss=2.073, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.746, task_loss=1.315, contrastive_loss=0.353, total=4188.38, n_correct=2689.46, ppl=4.76, accuracy=64.212, wps=12007.2, ups=1.43, wpb=8376.8, bsz=326.5, num_updates=17900, lr=0.000105703, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=14.2, wall=16545
2023-08-15 06:04:03 | INFO | train_inner | epoch 013:    323 / 1474 loss=2.046, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.751, task_loss=1.464, contrastive_loss=0.118, total=4101.73, n_correct=2651.28, ppl=4.69, accuracy=64.638, wps=11824.1, ups=1.44, wpb=8203.5, bsz=293.4, num_updates=18000, lr=0.000105409, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=16615
2023-08-15 06:04:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:04:26 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.006 | trans_loss 5.215 | nll_loss 2.493 | w2v_ctc_loss 1.311 | task_loss 4.654 | contrastive_loss 0.351 | total 4003.4 | n_correct 2630.8 | ppl 5.63 | accuracy 65.714 | uer 18.86 | wer 20.976 | raw_wer 20.976 | bleu 21.42 | wps 2168.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.42
2023-08-15 06:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-15 06:04:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-15 06:04:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-15 06:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.42) (writing took 44.70576670207083 seconds)
2023-08-15 06:06:21 | INFO | train_inner | epoch 013:    423 / 1474 loss=2.051, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.752, task_loss=1.293, contrastive_loss=0.167, total=4205.54, n_correct=2712.05, ppl=4.72, accuracy=64.488, wps=6078.3, ups=0.72, wpb=8411.1, bsz=323.5, num_updates=18100, lr=0.000105118, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=16753
2023-08-15 06:07:31 | INFO | train_inner | epoch 013:    523 / 1474 loss=2.058, trans_loss=4.984, nll_loss=2.247, w2v_ctc_loss=0.754, task_loss=1.365, contrastive_loss=0.202, total=4185.31, n_correct=2690.2, ppl=4.75, accuracy=64.277, wps=11974.1, ups=1.43, wpb=8370.6, bsz=316.7, num_updates=18200, lr=0.000104828, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=16823
2023-08-15 06:08:40 | INFO | train_inner | epoch 013:    623 / 1474 loss=2.045, trans_loss=4.977, nll_loss=2.239, w2v_ctc_loss=0.752, task_loss=1.385, contrastive_loss=0.113, total=4157.86, n_correct=2686.78, ppl=4.72, accuracy=64.619, wps=12057.1, ups=1.45, wpb=8315.7, bsz=306.4, num_updates=18300, lr=0.000104542, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=16892
2023-08-15 06:09:49 | INFO | train_inner | epoch 013:    723 / 1474 loss=2.059, trans_loss=4.984, nll_loss=2.248, w2v_ctc_loss=0.765, task_loss=1.548, contrastive_loss=0.116, total=4099, n_correct=2633.57, ppl=4.75, accuracy=64.249, wps=11818.6, ups=1.44, wpb=8198, bsz=286.3, num_updates=18400, lr=0.000104257, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=16961
2023-08-15 06:10:59 | INFO | train_inner | epoch 013:    823 / 1474 loss=2.063, trans_loss=4.988, nll_loss=2.253, w2v_ctc_loss=0.764, task_loss=1.427, contrastive_loss=0.165, total=4122.84, n_correct=2643.16, ppl=4.77, accuracy=64.11, wps=11763.5, ups=1.43, wpb=8245.7, bsz=305.7, num_updates=18500, lr=0.000103975, gnorm=0.532, clip=0, loss_scale=8, train_wall=70, gb_free=16.8, wall=17031
2023-08-15 06:12:09 | INFO | train_inner | epoch 013:    923 / 1474 loss=2.051, trans_loss=4.981, nll_loss=2.245, w2v_ctc_loss=0.753, task_loss=1.435, contrastive_loss=0.124, total=4100.74, n_correct=2640.8, ppl=4.74, accuracy=64.398, wps=11825.6, ups=1.44, wpb=8201.5, bsz=296.8, num_updates=18600, lr=0.000103695, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=17101
2023-08-15 06:13:18 | INFO | train_inner | epoch 013:   1023 / 1474 loss=2.066, trans_loss=4.989, nll_loss=2.254, w2v_ctc_loss=0.765, task_loss=1.494, contrastive_loss=0.178, total=4080.72, n_correct=2616.02, ppl=4.77, accuracy=64.107, wps=11779.7, ups=1.44, wpb=8161.4, bsz=292.3, num_updates=18700, lr=0.000103418, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=17.2, wall=17170
2023-08-15 06:14:27 | INFO | train_inner | epoch 013:   1123 / 1474 loss=2.048, trans_loss=4.975, nll_loss=2.236, w2v_ctc_loss=0.748, task_loss=1.38, contrastive_loss=0.157, total=4103.17, n_correct=2647.6, ppl=4.71, accuracy=64.526, wps=11907.8, ups=1.45, wpb=8206.3, bsz=305.6, num_updates=18800, lr=0.000103142, gnorm=0.52, clip=0, loss_scale=8, train_wall=68, gb_free=17.4, wall=17239
2023-08-15 06:15:37 | INFO | train_inner | epoch 013:   1223 / 1474 loss=2.056, trans_loss=4.985, nll_loss=2.249, w2v_ctc_loss=0.764, task_loss=1.486, contrastive_loss=0.117, total=4124.88, n_correct=2653.92, ppl=4.75, accuracy=64.339, wps=11847.9, ups=1.44, wpb=8249.8, bsz=296.7, num_updates=18900, lr=0.000102869, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=17308
2023-08-15 06:16:46 | INFO | train_inner | epoch 013:   1323 / 1474 loss=2.055, trans_loss=4.975, nll_loss=2.237, w2v_ctc_loss=0.755, task_loss=1.386, contrastive_loss=0.212, total=4108.18, n_correct=2652.05, ppl=4.71, accuracy=64.555, wps=11799.3, ups=1.44, wpb=8216.4, bsz=308.4, num_updates=19000, lr=0.000102598, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=17378
2023-08-15 06:17:55 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.06, trans_loss=4.983, nll_loss=2.248, w2v_ctc_loss=0.746, task_loss=1.388, contrastive_loss=0.228, total=4171.47, n_correct=2685.09, ppl=4.75, accuracy=64.368, wps=12077.8, ups=1.45, wpb=8342.9, bsz=310.5, num_updates=19100, lr=0.000102329, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=17447
2023-08-15 06:18:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:18:54 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.994 | trans_loss 5.196 | nll_loss 2.466 | w2v_ctc_loss 1.328 | task_loss 4.635 | contrastive_loss 0.334 | total 4003.4 | n_correct 2647.8 | ppl 5.52 | accuracy 66.139 | uer 18.438 | wer 20.376 | raw_wer 20.376 | bleu 21.6 | wps 2129.8 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 21.6
2023-08-15 06:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-08-15 06:18:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 06:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 06:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 13 @ 19151 updates, score 21.6) (writing took 29.30767272040248 seconds)
2023-08-15 06:19:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-15 06:19:24 | INFO | train | epoch 013 | loss 2.055 | trans_loss 4.98 | nll_loss 2.243 | w2v_ctc_loss 0.755 | task_loss 1.405 | contrastive_loss 0.171 | total 4138.65 | n_correct 2665.2 | ppl 4.73 | accuracy 64.398 | wps 10579.3 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 19151 | lr 0.000102193 | gnorm 0.522 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 17.4 | wall 17536
2023-08-15 06:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:19:24 | INFO | fairseq.trainer | begin training epoch 14
2023-08-15 06:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:20:06 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.029, trans_loss=4.949, nll_loss=2.204, w2v_ctc_loss=0.739, task_loss=1.292, contrastive_loss=0.127, total=4182.69, n_correct=2723, ppl=4.61, accuracy=65.102, wps=6415.3, ups=0.77, wpb=8365.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=17578
2023-08-15 06:21:14 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.028, trans_loss=4.945, nll_loss=2.198, w2v_ctc_loss=0.74, task_loss=1.4, contrastive_loss=0.109, total=4086.4, n_correct=2662.63, ppl=4.59, accuracy=65.158, wps=11931.4, ups=1.46, wpb=8172.8, bsz=301.5, num_updates=19300, lr=0.000101797, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=17646
2023-08-15 06:22:24 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.043, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.74, task_loss=1.469, contrastive_loss=0.21, total=4103.37, n_correct=2661.74, ppl=4.64, accuracy=64.867, wps=11802.3, ups=1.44, wpb=8206.7, bsz=294, num_updates=19400, lr=0.000101535, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=17716
2023-08-15 06:23:33 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.031, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.732, task_loss=1.319, contrastive_loss=0.145, total=4168.35, n_correct=2710.74, ppl=4.64, accuracy=65.031, wps=12034.5, ups=1.44, wpb=8336.7, bsz=318.7, num_updates=19500, lr=0.000101274, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=17785
2023-08-15 06:24:43 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.033, trans_loss=4.961, nll_loss=2.218, w2v_ctc_loss=0.734, task_loss=1.383, contrastive_loss=0.127, total=4155.83, n_correct=2695.08, ppl=4.65, accuracy=64.851, wps=11939.2, ups=1.44, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=17855
2023-08-15 06:25:52 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.049, trans_loss=4.965, nll_loss=2.222, w2v_ctc_loss=0.762, task_loss=1.526, contrastive_loss=0.123, total=4064.87, n_correct=2629.91, ppl=4.67, accuracy=64.699, wps=11657.4, ups=1.43, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=17924
2023-08-15 06:27:02 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.045, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.742, task_loss=1.4, contrastive_loss=0.186, total=4167.34, n_correct=2696.94, ppl=4.67, accuracy=64.716, wps=11931.8, ups=1.43, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=17994
2023-08-15 06:28:11 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.036, trans_loss=4.952, nll_loss=2.208, w2v_ctc_loss=0.75, task_loss=1.377, contrastive_loss=0.119, total=4142.94, n_correct=2694.08, ppl=4.62, accuracy=65.028, wps=12050, ups=1.45, wpb=8285.9, bsz=308.6, num_updates=19900, lr=0.000100251, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=18063
2023-08-15 06:29:21 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.044, trans_loss=4.954, nll_loss=2.21, w2v_ctc_loss=0.74, task_loss=1.341, contrastive_loss=0.227, total=4173.06, n_correct=2708.65, ppl=4.63, accuracy=64.908, wps=11923.4, ups=1.43, wpb=8346.1, bsz=319.1, num_updates=20000, lr=0.0001, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=18133
2023-08-15 06:29:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:29:45 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.992 | trans_loss 5.187 | nll_loss 2.457 | w2v_ctc_loss 1.346 | task_loss 4.645 | contrastive_loss 0.327 | total 4003.4 | n_correct 2649.8 | ppl 5.49 | accuracy 66.189 | uer 18.095 | wer 19.988 | raw_wer 19.988 | bleu 21.35 | wps 2105.8 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.6
2023-08-15 06:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-15 06:29:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-15 06:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-15 06:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.35) (writing took 35.2795620765537 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 06:31:31 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.038, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.739, task_loss=1.402, contrastive_loss=0.161, total=4166.71, n_correct=2697.99, ppl=4.65, accuracy=64.751, wps=6407.9, ups=0.77, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=18263
2023-08-15 06:32:41 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.036, trans_loss=4.958, nll_loss=2.214, w2v_ctc_loss=0.74, task_loss=1.425, contrastive_loss=0.139, total=4145.57, n_correct=2694.32, ppl=4.64, accuracy=64.993, wps=11828.2, ups=1.43, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=18333
2023-08-15 06:33:51 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.067, trans_loss=4.963, nll_loss=2.222, w2v_ctc_loss=0.748, task_loss=1.326, contrastive_loss=0.412, total=4219.9, n_correct=2729.67, ppl=4.67, accuracy=64.686, wps=12102.8, ups=1.43, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=18403
2023-08-15 06:35:00 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.043, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.755, task_loss=1.629, contrastive_loss=0.1, total=4032.06, n_correct=2609.93, ppl=4.67, accuracy=64.729, wps=11642.6, ups=1.44, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=18472
2023-08-15 06:36:10 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.029, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.734, task_loss=1.332, contrastive_loss=0.117, total=4205.07, n_correct=2730.55, ppl=4.65, accuracy=64.935, wps=12089.6, ups=1.44, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18542
2023-08-15 06:37:19 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.041, trans_loss=4.965, nll_loss=2.225, w2v_ctc_loss=0.742, task_loss=1.403, contrastive_loss=0.155, total=4126.44, n_correct=2672.47, ppl=4.67, accuracy=64.765, wps=11947.6, ups=1.45, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=18611
2023-08-15 06:37:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 06:37:59 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.004 | trans_loss 5.185 | nll_loss 2.454 | w2v_ctc_loss 1.39 | task_loss 4.666 | contrastive_loss 0.337 | total 4003.4 | n_correct 2650.2 | ppl 5.48 | accuracy 66.199 | uer 18.86 | wer 20.76 | raw_wer 20.76 | bleu 21.51 | wps 2194.9 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.6
2023-08-15 06:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-15 06:37:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt
2023-08-15 06:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt
2023-08-15 06:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5104.pt (epoch 14 @ 20625 updates, score 21.51) (writing took 22.15944396518171 seconds)
2023-08-15 06:38:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-15 06:38:22 | INFO | train | epoch 014 | loss 2.04 | trans_loss 4.959 | nll_loss 2.216 | w2v_ctc_loss 0.743 | task_loss 1.405 | contrastive_loss 0.166 | total 4138.65 | n_correct 2684.66 | ppl 4.65 | accuracy 64.868 | wps 10719.4 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 16.1 | wall 18674
2023-08-15 06:38:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:38:22 | INFO | fairseq.trainer | begin training epoch 15
2023-08-15 06:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:39:21 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.035, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.734, task_loss=1.409, contrastive_loss=0.202, total=4090.99, n_correct=2662.89, ppl=4.6, accuracy=65.092, wps=6709.9, ups=0.82, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=18733
2023-08-15 06:40:30 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.02, trans_loss=4.935, nll_loss=2.184, w2v_ctc_loss=0.734, task_loss=1.452, contrastive_loss=0.11, total=4115.56, n_correct=2695.1, ppl=4.54, accuracy=65.486, wps=11864.6, ups=1.44, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=18802
2023-08-15 06:41:39 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.016, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.723, task_loss=1.366, contrastive_loss=0.104, total=4182.19, n_correct=2734.56, ppl=4.56, accuracy=65.386, wps=12119, ups=1.45, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.51, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=18871
2023-08-15 06:42:48 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.019, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.724, task_loss=1.402, contrastive_loss=0.128, total=4172.52, n_correct=2732.45, ppl=4.53, accuracy=65.487, wps=12050.8, ups=1.44, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=18940
2023-08-15 06:43:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 06:43:58 | INFO | train_inner | epoch 015:    476 / 1474 loss=2.013, trans_loss=4.932, nll_loss=2.179, w2v_ctc_loss=0.722, task_loss=1.521, contrastive_loss=0.095, total=4047.69, n_correct=2649.36, ppl=4.53, accuracy=65.454, wps=11593, ups=1.43, wpb=8095.4, bsz=284.6, num_updates=21100, lr=9.73585e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=19010
2023-08-15 06:45:07 | INFO | train_inner | epoch 015:    576 / 1474 loss=2.023, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.732, task_loss=1.44, contrastive_loss=0.131, total=4151.89, n_correct=2710.25, ppl=4.56, accuracy=65.278, wps=11998, ups=1.45, wpb=8303.8, bsz=302, num_updates=21200, lr=9.71286e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=13.2, wall=19079
2023-08-15 06:46:17 | INFO | train_inner | epoch 015:    676 / 1474 loss=2.031, trans_loss=4.935, nll_loss=2.184, w2v_ctc_loss=0.735, task_loss=1.435, contrastive_loss=0.177, total=4122.17, n_correct=2690.83, ppl=4.54, accuracy=65.277, wps=11860.9, ups=1.44, wpb=8244.3, bsz=304, num_updates=21300, lr=9.69003e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=19149
2023-08-15 06:47:26 | INFO | train_inner | epoch 015:    776 / 1474 loss=2.026, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.74, task_loss=1.404, contrastive_loss=0.115, total=4181.07, n_correct=2724.72, ppl=4.58, accuracy=65.168, wps=12039.8, ups=1.44, wpb=8362.1, bsz=307.1, num_updates=21400, lr=9.66736e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=19218
2023-08-15 06:48:35 | INFO | train_inner | epoch 015:    876 / 1474 loss=2.027, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.738, task_loss=1.521, contrastive_loss=0.106, total=4052.17, n_correct=2643.14, ppl=4.59, accuracy=65.228, wps=11785.9, ups=1.45, wpb=8104.3, bsz=286.4, num_updates=21500, lr=9.64486e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=19287
2023-08-15 06:49:44 | INFO | train_inner | epoch 015:    976 / 1474 loss=2.029, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.729, task_loss=1.4, contrastive_loss=0.195, total=4135.95, n_correct=2697.61, ppl=4.58, accuracy=65.223, wps=12023.5, ups=1.45, wpb=8271.9, bsz=304.3, num_updates=21600, lr=9.6225e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=19356
2023-08-15 06:50:55 | INFO | train_inner | epoch 015:   1076 / 1474 loss=2.046, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.728, task_loss=1.322, contrastive_loss=0.354, total=4187.18, n_correct=2722.33, ppl=4.6, accuracy=65.016, wps=11871.1, ups=1.42, wpb=8374.4, bsz=324.7, num_updates=21700, lr=9.60031e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=13.6, wall=19426
2023-08-15 06:52:04 | INFO | train_inner | epoch 015:   1176 / 1474 loss=2.015, trans_loss=4.938, nll_loss=2.19, w2v_ctc_loss=0.717, task_loss=1.266, contrastive_loss=0.156, total=4184.18, n_correct=2742.84, ppl=4.56, accuracy=65.553, wps=12134.2, ups=1.45, wpb=8368.4, bsz=328.4, num_updates=21800, lr=9.57826e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=19495
2023-08-15 06:53:13 | INFO | train_inner | epoch 015:   1276 / 1474 loss=2.026, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.744, task_loss=1.437, contrastive_loss=0.111, total=4141.39, n_correct=2704.13, ppl=4.55, accuracy=65.295, wps=11909, ups=1.44, wpb=8282.8, bsz=302.1, num_updates=21900, lr=9.55637e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=19565
2023-08-15 06:54:22 | INFO | train_inner | epoch 015:   1376 / 1474 loss=2.019, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.734, task_loss=1.451, contrastive_loss=0.099, total=4106.11, n_correct=2685.55, ppl=4.55, accuracy=65.404, wps=11837.1, ups=1.44, wpb=8212.2, bsz=294.2, num_updates=22000, lr=9.53463e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=19634
2023-08-15 06:54:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:54:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.185 | nll_loss 2.453 | w2v_ctc_loss 1.314 | task_loss 4.622 | contrastive_loss 0.322 | total 4003.4 | n_correct 2653.4 | ppl 5.47 | accuracy 66.279 | uer 18.262 | wer 20.223 | raw_wer 20.223 | bleu 21.76 | wps 2081.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.76
2023-08-15 06:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-15 06:54:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-15 06:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-15 06:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.76) (writing took 54.27956608496606 seconds)
2023-08-15 06:55:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 06:56:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 06:57:14 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.978 | trans_loss 5.184 | nll_loss 2.457 | w2v_ctc_loss 1.305 | task_loss 4.634 | contrastive_loss 0.333 | total 4003.4 | n_correct 2649.8 | ppl 5.49 | accuracy 66.189 | uer 18.286 | wer 20.141 | raw_wer 20.141 | bleu 21.54 | wps 2148.3 | wpb 4003.4 | bsz 141.8 | num_updates 22097 | best_bleu 21.76
2023-08-15 06:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22097 updates
2023-08-15 06:57:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt
2023-08-15 06:57:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt
2023-08-15 06:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.5405.pt (epoch 15 @ 22097 updates, score 21.54) (writing took 23.58774878643453 seconds)
2023-08-15 06:57:38 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-15 06:57:39 | INFO | train | epoch 015 | loss 2.024 | trans_loss 4.939 | nll_loss 2.19 | w2v_ctc_loss 0.73 | task_loss 1.407 | contrastive_loss 0.154 | total 4136.64 | n_correct 2701.82 | ppl 4.56 | accuracy 65.314 | wps 10529.8 | ups 1.27 | wpb 8273.3 | bsz 305 | num_updates 22097 | lr 9.51368e-05 | gnorm 0.523 | clip 0 | loss_scale 8 | train_wall 1013 | gb_free 16.6 | wall 19830
2023-08-15 06:57:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 06:57:39 | INFO | fairseq.trainer | begin training epoch 16
2023-08-15 06:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 06:57:49 | INFO | train_inner | epoch 016:      3 / 1474 loss=2.03, trans_loss=4.947, nll_loss=2.201, w2v_ctc_loss=0.729, task_loss=1.348, contrastive_loss=0.189, total=4147.48, n_correct=2702.65, ppl=4.6, accuracy=65.164, wps=4021.6, ups=0.48, wpb=8295, bsz=314.7, num_updates=22100, lr=9.51303e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=19841
2023-08-15 06:58:57 | INFO | train_inner | epoch 016:    103 / 1474 loss=2.006, trans_loss=4.919, nll_loss=2.163, w2v_ctc_loss=0.716, task_loss=1.346, contrastive_loss=0.127, total=4116.45, n_correct=2704.65, ppl=4.48, accuracy=65.703, wps=11982.6, ups=1.46, wpb=8232.9, bsz=314.3, num_updates=22200, lr=9.49158e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=19909
2023-08-15 07:00:07 | INFO | train_inner | epoch 016:    203 / 1474 loss=1.999, trans_loss=4.91, nll_loss=2.153, w2v_ctc_loss=0.706, task_loss=1.443, contrastive_loss=0.102, total=4112.07, n_correct=2711.73, ppl=4.45, accuracy=65.946, wps=11801.5, ups=1.43, wpb=8224.1, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=19979
2023-08-15 07:01:17 | INFO | train_inner | epoch 016:    303 / 1474 loss=2.021, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.727, task_loss=1.399, contrastive_loss=0.178, total=4160.84, n_correct=2728.3, ppl=4.51, accuracy=65.571, wps=11852.2, ups=1.42, wpb=8321.7, bsz=308.1, num_updates=22400, lr=9.44911e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=70, gb_free=16.7, wall=20049
2023-08-15 07:02:27 | INFO | train_inner | epoch 016:    403 / 1474 loss=2.015, trans_loss=4.916, nll_loss=2.159, w2v_ctc_loss=0.721, task_loss=1.502, contrastive_loss=0.19, total=4066.97, n_correct=2673.49, ppl=4.47, accuracy=65.737, wps=11710.1, ups=1.44, wpb=8133.9, bsz=287, num_updates=22500, lr=9.42809e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=14.6, wall=20119
2023-08-15 07:03:37 | INFO | train_inner | epoch 016:    503 / 1474 loss=2.013, trans_loss=4.927, nll_loss=2.175, w2v_ctc_loss=0.717, task_loss=1.353, contrastive_loss=0.139, total=4168.86, n_correct=2733.09, ppl=4.52, accuracy=65.56, wps=11960.5, ups=1.43, wpb=8337.7, bsz=318.4, num_updates=22600, lr=9.40721e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=20188
2023-08-15 07:04:46 | INFO | train_inner | epoch 016:    603 / 1474 loss=2.008, trans_loss=4.924, nll_loss=2.17, w2v_ctc_loss=0.718, task_loss=1.394, contrastive_loss=0.099, total=4132.12, n_correct=2714.17, ppl=4.5, accuracy=65.685, wps=11950.3, ups=1.45, wpb=8264.2, bsz=300.3, num_updates=22700, lr=9.38647e-05, gnorm=0.516, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=20258
2023-08-15 07:05:54 | INFO | train_inner | epoch 016:    703 / 1474 loss=2.008, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.722, task_loss=1.43, contrastive_loss=0.1, total=4102.33, n_correct=2693.4, ppl=4.49, accuracy=65.655, wps=11926.5, ups=1.45, wpb=8204.7, bsz=298.1, num_updates=22800, lr=9.36586e-05, gnorm=0.514, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=20326
2023-08-15 07:07:04 | INFO | train_inner | epoch 016:    803 / 1474 loss=2.008, trans_loss=4.92, nll_loss=2.165, w2v_ctc_loss=0.708, task_loss=1.344, contrastive_loss=0.161, total=4176.5, n_correct=2746, ppl=4.48, accuracy=65.749, wps=12052.8, ups=1.44, wpb=8353, bsz=311.3, num_updates=22900, lr=9.34539e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=20396
2023-08-15 07:08:13 | INFO | train_inner | epoch 016:    903 / 1474 loss=2.013, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.715, task_loss=1.39, contrastive_loss=0.154, total=4150.45, n_correct=2722.92, ppl=4.5, accuracy=65.605, wps=12042, ups=1.45, wpb=8300.9, bsz=305.8, num_updates=23000, lr=9.32505e-05, gnorm=0.517, clip=0, loss_scale=8, train_wall=68, gb_free=11.3, wall=20465
2023-08-15 07:09:22 | INFO | train_inner | epoch 016:   1003 / 1474 loss=2.019, trans_loss=4.927, nll_loss=2.175, w2v_ctc_loss=0.732, task_loss=1.439, contrastive_loss=0.151, total=4118.26, n_correct=2697.93, ppl=4.52, accuracy=65.511, wps=11814.8, ups=1.43, wpb=8236.5, bsz=301.7, num_updates=23100, lr=9.30484e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=20534
2023-08-15 07:10:32 | INFO | train_inner | epoch 016:   1103 / 1474 loss=2.018, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.727, task_loss=1.486, contrastive_loss=0.127, total=4113.57, n_correct=2691.6, ppl=4.53, accuracy=65.432, wps=11784.4, ups=1.43, wpb=8227.1, bsz=296.2, num_updates=23200, lr=9.28477e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=20604
2023-08-15 07:11:43 | INFO | train_inner | epoch 016:   1203 / 1474 loss=2.025, trans_loss=4.932, nll_loss=2.181, w2v_ctc_loss=0.716, task_loss=1.433, contrastive_loss=0.225, total=4157.18, n_correct=2716.5, ppl=4.54, accuracy=65.345, wps=11752, ups=1.41, wpb=8314.4, bsz=306.3, num_updates=23300, lr=9.26482e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=20675
2023-08-15 07:12:53 | INFO | train_inner | epoch 016:   1303 / 1474 loss=2.025, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.733, task_loss=1.376, contrastive_loss=0.203, total=4150.54, n_correct=2718.29, ppl=4.52, accuracy=65.492, wps=11913.4, ups=1.44, wpb=8301.1, bsz=312.3, num_updates=23400, lr=9.245e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=12.5, wall=20745
2023-08-15 07:14:03 | INFO | train_inner | epoch 016:   1403 / 1474 loss=2.009, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.721, task_loss=1.33, contrastive_loss=0.13, total=4198.78, n_correct=2758.17, ppl=4.5, accuracy=65.69, wps=11996.1, ups=1.43, wpb=8397.6, bsz=322.4, num_updates=23500, lr=9.22531e-05, gnorm=0.515, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=20815
2023-08-15 07:14:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:15:17 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.982 | trans_loss 5.171 | nll_loss 2.436 | w2v_ctc_loss 1.354 | task_loss 4.669 | contrastive_loss 0.331 | total 4003.4 | n_correct 2659.1 | ppl 5.41 | accuracy 66.421 | uer 18.196 | wer 19.966 | raw_wer 19.966 | bleu 21.97 | wps 2057.1 | wpb 4003.4 | bsz 141.8 | num_updates 23571 | best_bleu 21.97
2023-08-15 07:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23571 updates
2023-08-15 07:15:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23571 updates, score 21.97) (writing took 31.604974687099457 seconds)
2023-08-15 07:15:49 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-15 07:15:49 | INFO | train | epoch 016 | loss 2.014 | trans_loss 4.923 | nll_loss 2.17 | w2v_ctc_loss 0.719 | task_loss 1.403 | contrastive_loss 0.158 | total 4138.65 | n_correct 2715.96 | ppl 4.5 | accuracy 65.624 | wps 11185.5 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 23571 | lr 9.21141e-05 | gnorm 0.52 | clip 0 | loss_scale 8 | train_wall 1018 | gb_free 15.1 | wall 20921
2023-08-15 07:15:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:15:50 | INFO | fairseq.trainer | begin training epoch 17
2023-08-15 07:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:16:18 | INFO | train_inner | epoch 017:     29 / 1474 loss=2.015, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.709, task_loss=1.448, contrastive_loss=0.269, total=4138.06, n_correct=2724.76, ppl=4.45, accuracy=65.846, wps=6124.5, ups=0.74, wpb=8276.1, bsz=300.4, num_updates=23600, lr=9.20575e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=70, gb_free=17.4, wall=20950
2023-08-15 07:17:27 | INFO | train_inner | epoch 017:    129 / 1474 loss=1.995, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.712, task_loss=1.443, contrastive_loss=0.1, total=4110.37, n_correct=2718.15, ppl=4.39, accuracy=66.129, wps=11858.8, ups=1.44, wpb=8220.7, bsz=295.6, num_updates=23700, lr=9.1863e-05, gnorm=0.516, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=21019
2023-08-15 07:18:36 | INFO | train_inner | epoch 017:    229 / 1474 loss=2.008, trans_loss=4.899, nll_loss=2.138, w2v_ctc_loss=0.698, task_loss=1.31, contrastive_loss=0.266, total=4181.59, n_correct=2763.02, ppl=4.4, accuracy=66.076, wps=12093.2, ups=1.45, wpb=8363.2, bsz=322.2, num_updates=23800, lr=9.16698e-05, gnorm=0.51, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=21088
2023-08-15 07:19:46 | INFO | train_inner | epoch 017:    329 / 1474 loss=2.013, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.707, task_loss=1.411, contrastive_loss=0.271, total=4157.97, n_correct=2740.1, ppl=4.44, accuracy=65.9, wps=11918.8, ups=1.43, wpb=8315.9, bsz=304, num_updates=23900, lr=9.14779e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=21158
2023-08-15 07:20:56 | INFO | train_inner | epoch 017:    429 / 1474 loss=1.99, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.702, task_loss=1.403, contrastive_loss=0.099, total=4135.12, n_correct=2738.51, ppl=4.41, accuracy=66.226, wps=11881.7, ups=1.44, wpb=8270.2, bsz=306.1, num_updates=24000, lr=9.12871e-05, gnorm=0.511, clip=0, loss_scale=8, train_wall=69, gb_free=12.4, wall=21228
2023-08-15 07:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:21:20 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.981 | trans_loss 5.178 | nll_loss 2.445 | w2v_ctc_loss 1.339 | task_loss 4.618 | contrastive_loss 0.321 | total 4003.4 | n_correct 2654.8 | ppl 5.44 | accuracy 66.314 | uer 18.318 | wer 20.253 | raw_wer 20.253 | bleu 21.55 | wps 2117.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.97
2023-08-15 07:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-15 07:21:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-15 07:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-15 07:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.55) (writing took 43.65551965683699 seconds)
2023-08-15 07:23:15 | INFO | train_inner | epoch 017:    529 / 1474 loss=2.005, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.715, task_loss=1.454, contrastive_loss=0.145, total=4185.81, n_correct=2757.39, ppl=4.45, accuracy=65.875, wps=6028.6, ups=0.72, wpb=8371.6, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=15.8, wall=21367
2023-08-15 07:24:24 | INFO | train_inner | epoch 017:    629 / 1474 loss=1.996, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.706, task_loss=1.407, contrastive_loss=0.097, total=4168.62, n_correct=2754.42, ppl=4.44, accuracy=66.075, wps=12078.9, ups=1.45, wpb=8337.2, bsz=303.2, num_updates=24200, lr=9.09091e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=69, gb_free=13.9, wall=21436
2023-08-15 07:25:33 | INFO | train_inner | epoch 017:    729 / 1474 loss=2.011, trans_loss=4.912, nll_loss=2.154, w2v_ctc_loss=0.726, task_loss=1.397, contrastive_loss=0.145, total=4167.34, n_correct=2743.27, ppl=4.45, accuracy=65.828, wps=11999.8, ups=1.44, wpb=8334.7, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=9.6, wall=21505
2023-08-15 07:26:42 | INFO | train_inner | epoch 017:    829 / 1474 loss=2, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.716, task_loss=1.42, contrastive_loss=0.108, total=4092.64, n_correct=2699.83, ppl=4.44, accuracy=65.968, wps=11862.2, ups=1.45, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=21574
2023-08-15 07:27:50 | INFO | train_inner | epoch 017:    929 / 1474 loss=1.993, trans_loss=4.904, nll_loss=2.146, w2v_ctc_loss=0.707, task_loss=1.377, contrastive_loss=0.103, total=4109.5, n_correct=2714.4, ppl=4.42, accuracy=66.052, wps=12024.1, ups=1.46, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=21642
2023-08-15 07:29:00 | INFO | train_inner | epoch 017:   1029 / 1474 loss=2, trans_loss=4.908, nll_loss=2.151, w2v_ctc_loss=0.716, task_loss=1.416, contrastive_loss=0.108, total=4098.36, n_correct=2703.56, ppl=4.44, accuracy=65.967, wps=11814.3, ups=1.44, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=21712
2023-08-15 07:30:09 | INFO | train_inner | epoch 017:   1129 / 1474 loss=1.994, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.702, task_loss=1.426, contrastive_loss=0.102, total=4100.14, n_correct=2706.73, ppl=4.43, accuracy=66.016, wps=11878.4, ups=1.45, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=21781
2023-08-15 07:31:19 | INFO | train_inner | epoch 017:   1229 / 1474 loss=2.03, trans_loss=4.917, nll_loss=2.163, w2v_ctc_loss=0.704, task_loss=1.351, contrastive_loss=0.405, total=4173.98, n_correct=2741.94, ppl=4.48, accuracy=65.691, wps=11860.8, ups=1.42, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=15.7, wall=21851
2023-08-15 07:32:28 | INFO | train_inner | epoch 017:   1329 / 1474 loss=1.995, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.702, task_loss=1.414, contrastive_loss=0.111, total=4146.07, n_correct=2739.27, ppl=4.44, accuracy=66.069, wps=11980.1, ups=1.44, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=21920
2023-08-15 07:33:38 | INFO | train_inner | epoch 017:   1429 / 1474 loss=1.996, trans_loss=4.909, nll_loss=2.151, w2v_ctc_loss=0.708, task_loss=1.423, contrastive_loss=0.101, total=4119.23, n_correct=2721.41, ppl=4.44, accuracy=66.066, wps=11851.7, ups=1.44, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=12.8, wall=21990
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 07:34:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
2023-08-15 07:34:33 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.98 | trans_loss 5.167 | nll_loss 2.431 | w2v_ctc_loss 1.359 | task_loss 4.664 | contrastive_loss 0.33 | total 4003.4 | n_correct 2657.2 | ppl 5.39 | accuracy 66.374 | uer 17.689 | wer 19.608 | raw_wer 19.608 | bleu 22.01 | wps 2122.7 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 22.01
2023-08-15 07:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-08-15 07:34:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 17 @ 25045 updates, score 22.01) (writing took 29.43081351555884 seconds)
2023-08-15 07:35:03 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-15 07:35:03 | INFO | train | epoch 017 | loss 2.002 | trans_loss 4.906 | nll_loss 2.148 | w2v_ctc_loss 0.709 | task_loss 1.405 | contrastive_loss 0.154 | total 4138.65 | n_correct 2731.29 | ppl 4.43 | accuracy 65.995 | wps 10572.9 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.518 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 16.1 | wall 22075
2023-08-15 07:35:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:35:04 | INFO | fairseq.trainer | begin training epoch 18
2023-08-15 07:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:35:50 | INFO | train_inner | epoch 018:     55 / 1474 loss=1.999, trans_loss=4.902, nll_loss=2.143, w2v_ctc_loss=0.718, task_loss=1.435, contrastive_loss=0.11, total=4128.93, n_correct=2728.33, ppl=4.42, accuracy=66.078, wps=6242.4, ups=0.76, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=22122
2023-08-15 07:36:59 | INFO | train_inner | epoch 018:    155 / 1474 loss=1.991, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.688, task_loss=1.333, contrastive_loss=0.23, total=4158.38, n_correct=2766.57, ppl=4.33, accuracy=66.53, wps=12037.1, ups=1.45, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=22191
2023-08-15 07:38:08 | INFO | train_inner | epoch 018:    255 / 1474 loss=1.983, trans_loss=4.885, nll_loss=2.12, w2v_ctc_loss=0.701, task_loss=1.361, contrastive_loss=0.1, total=4161.92, n_correct=2765.28, ppl=4.35, accuracy=66.442, wps=12043.7, ups=1.45, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=22260
2023-08-15 07:39:18 | INFO | train_inner | epoch 018:    355 / 1474 loss=1.987, trans_loss=4.891, nll_loss=2.127, w2v_ctc_loss=0.695, task_loss=1.431, contrastive_loss=0.115, total=4167.42, n_correct=2763.46, ppl=4.37, accuracy=66.311, wps=12038.1, ups=1.44, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=22330
2023-08-15 07:40:27 | INFO | train_inner | epoch 018:    455 / 1474 loss=1.999, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.7, task_loss=1.509, contrastive_loss=0.205, total=4075.78, n_correct=2699.25, ppl=4.38, accuracy=66.227, wps=11683.4, ups=1.43, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=22399
2023-08-15 07:41:37 | INFO | train_inner | epoch 018:    555 / 1474 loss=1.975, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.686, task_loss=1.255, contrastive_loss=0.112, total=4218.07, n_correct=2812.41, ppl=4.33, accuracy=66.675, wps=12145.9, ups=1.44, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=22469
2023-08-15 07:42:46 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.001, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.707, task_loss=1.452, contrastive_loss=0.184, total=4093.44, n_correct=2706.93, ppl=4.41, accuracy=66.128, wps=11877.9, ups=1.45, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=22538
2023-08-15 07:43:56 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.006, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.706, task_loss=1.338, contrastive_loss=0.275, total=4202.99, n_correct=2784.86, ppl=4.39, accuracy=66.259, wps=12042.4, ups=1.43, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=22608
2023-08-15 07:45:05 | INFO | train_inner | epoch 018:    855 / 1474 loss=1.988, trans_loss=4.894, nll_loss=2.131, w2v_ctc_loss=0.7, task_loss=1.412, contrastive_loss=0.1, total=4177.43, n_correct=2767.46, ppl=4.38, accuracy=66.248, wps=12032.9, ups=1.44, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=22677
2023-08-15 07:46:14 | INFO | train_inner | epoch 018:    955 / 1474 loss=1.982, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.695, task_loss=1.309, contrastive_loss=0.105, total=4138.23, n_correct=2746.95, ppl=4.36, accuracy=66.38, wps=12075, ups=1.46, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=22746
2023-08-15 07:46:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:46:37 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.173 | nll_loss 2.436 | w2v_ctc_loss 1.319 | task_loss 4.666 | contrastive_loss 0.321 | total 4003.4 | n_correct 2666.7 | ppl 5.41 | accuracy 66.611 | uer 18.207 | wer 20.119 | raw_wer 20.119 | bleu 21.82 | wps 2098.1 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.01
2023-08-15 07:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-15 07:46:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-15 07:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-15 07:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.82) (writing took 34.82252572849393 seconds)
2023-08-15 07:48:22 | INFO | train_inner | epoch 018:   1055 / 1474 loss=1.989, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.701, task_loss=1.479, contrastive_loss=0.1, total=4133.59, n_correct=2740.29, ppl=4.38, accuracy=66.293, wps=6426, ups=0.78, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=22874
2023-08-15 07:49:32 | INFO | train_inner | epoch 018:   1155 / 1474 loss=1.996, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.703, task_loss=1.326, contrastive_loss=0.207, total=4154.22, n_correct=2756.25, ppl=4.36, accuracy=66.348, wps=12011, ups=1.45, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=22943
2023-08-15 07:50:40 | INFO | train_inner | epoch 018:   1255 / 1474 loss=1.99, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.701, task_loss=1.504, contrastive_loss=0.094, total=4089.17, n_correct=2703.42, ppl=4.41, accuracy=66.112, wps=11876.5, ups=1.45, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=23012
2023-08-15 07:51:50 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.001, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.719, task_loss=1.503, contrastive_loss=0.123, total=4068.84, n_correct=2686.48, ppl=4.41, accuracy=66.026, wps=11754.3, ups=1.44, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=23082
2023-08-15 07:52:58 | INFO | train_inner | epoch 018:   1455 / 1474 loss=1.994, trans_loss=4.899, nll_loss=2.138, w2v_ctc_loss=0.71, task_loss=1.494, contrastive_loss=0.106, total=4113.23, n_correct=2723.38, ppl=4.4, accuracy=66.21, wps=11953.7, ups=1.45, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=23150
2023-08-15 07:53:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 07:53:35 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.978 | trans_loss 5.17 | nll_loss 2.434 | w2v_ctc_loss 1.359 | task_loss 4.661 | contrastive_loss 0.312 | total 4003.4 | n_correct 2666.1 | ppl 5.4 | accuracy 66.596 | uer 17.663 | wer 19.619 | raw_wer 19.619 | bleu 22.02 | wps 2119.5 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.02
2023-08-15 07:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-15 07:53:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 07:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26519 updates, score 22.02) (writing took 32.82808456942439 seconds)
2023-08-15 07:54:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-15 07:54:09 | INFO | train | epoch 018 | loss 1.992 | trans_loss 4.892 | nll_loss 2.13 | w2v_ctc_loss 0.701 | task_loss 1.405 | contrastive_loss 0.15 | total 4138.65 | n_correct 2743.74 | ppl 4.38 | accuracy 66.296 | wps 10653 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 15.7 | wall 23221
2023-08-15 07:54:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 07:54:09 | INFO | fairseq.trainer | begin training epoch 19
2023-08-15 07:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 07:55:12 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.983, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.693, task_loss=1.401, contrastive_loss=0.155, total=4107.26, n_correct=2736.88, ppl=4.31, accuracy=66.635, wps=6158.5, ups=0.75, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=12.4, wall=23284
2023-08-15 07:56:22 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.982, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.698, task_loss=1.313, contrastive_loss=0.147, total=4222.18, n_correct=2815.49, ppl=4.31, accuracy=66.683, wps=12077.8, ups=1.43, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=11.3, wall=23354
2023-08-15 07:57:31 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.973, trans_loss=4.87, nll_loss=2.1, w2v_ctc_loss=0.694, task_loss=1.377, contrastive_loss=0.09, total=4187.37, n_correct=2796.21, ppl=4.29, accuracy=66.777, wps=12016.9, ups=1.43, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=23423
2023-08-15 07:58:40 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.984, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.685, task_loss=1.386, contrastive_loss=0.197, total=4170.67, n_correct=2777.08, ppl=4.3, accuracy=66.586, wps=12096.3, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=23492
2023-08-15 07:59:49 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.983, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.702, task_loss=1.438, contrastive_loss=0.106, total=4115.22, n_correct=2735.2, ppl=4.33, accuracy=66.465, wps=11921.1, ups=1.45, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=23561
2023-08-15 08:00:58 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.976, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.682, task_loss=1.378, contrastive_loss=0.17, total=4129.22, n_correct=2756.19, ppl=4.29, accuracy=66.748, wps=11995.2, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=23630
2023-08-15 08:02:07 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.969, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.676, task_loss=1.279, contrastive_loss=0.096, total=4197.2, n_correct=2797.38, ppl=4.33, accuracy=66.649, wps=12146.4, ups=1.45, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=69, gb_free=14.3, wall=23699
2023-08-15 08:03:17 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.979, trans_loss=4.876, nll_loss=2.108, w2v_ctc_loss=0.698, task_loss=1.413, contrastive_loss=0.11, total=4142.6, n_correct=2759.92, ppl=4.31, accuracy=66.623, wps=11896.1, ups=1.44, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=23769
2023-08-15 08:04:26 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.98, trans_loss=4.883, nll_loss=2.117, w2v_ctc_loss=0.697, task_loss=1.434, contrastive_loss=0.093, total=4153.47, n_correct=2763.16, ppl=4.34, accuracy=66.527, wps=12012.3, ups=1.45, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=23838
2023-08-15 08:05:36 | INFO | train_inner | epoch 019:    981 / 1474 loss=2, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.688, task_loss=1.402, contrastive_loss=0.328, total=4101.29, n_correct=2723.29, ppl=4.36, accuracy=66.401, wps=11677.4, ups=1.42, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=23908
2023-08-15 08:05:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 08:06:46 | INFO | train_inner | epoch 019:   1082 / 1474 loss=1.985, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.691, task_loss=1.497, contrastive_loss=0.136, total=4039.69, n_correct=2683.71, ppl=4.36, accuracy=66.434, wps=11543.9, ups=1.43, wpb=8079.4, bsz=291.5, num_updates=27600, lr=8.51257e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=23978
2023-08-15 08:07:56 | INFO | train_inner | epoch 019:   1182 / 1474 loss=1.997, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.699, task_loss=1.44, contrastive_loss=0.22, total=4129.82, n_correct=2738.04, ppl=4.36, accuracy=66.299, wps=11884, ups=1.44, wpb=8259.6, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=24048
2023-08-15 08:09:05 | INFO | train_inner | epoch 019:   1282 / 1474 loss=1.982, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.69, task_loss=1.41, contrastive_loss=0.118, total=4147.96, n_correct=2757.48, ppl=4.35, accuracy=66.478, wps=11987.7, ups=1.45, wpb=8295.9, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=24117
2023-08-15 08:10:14 | INFO | train_inner | epoch 019:   1382 / 1474 loss=1.98, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.697, task_loss=1.435, contrastive_loss=0.102, total=4125.32, n_correct=2746.97, ppl=4.33, accuracy=66.588, wps=11960.4, ups=1.45, wpb=8250.6, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24186
2023-08-15 08:11:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:11:42 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.162 | nll_loss 2.424 | w2v_ctc_loss 1.392 | task_loss 4.614 | contrastive_loss 0.312 | total 4003.4 | n_correct 2666.7 | ppl 5.37 | accuracy 66.611 | uer 18.111 | wer 20.104 | raw_wer 20.104 | bleu 21.99 | wps 1954.3 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 22.02
2023-08-15 08:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-08-15 08:11:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt
2023-08-15 08:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt
2023-08-15 08:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_21.9901.pt (epoch 19 @ 27992 updates, score 21.99) (writing took 20.373123195022345 seconds)
2023-08-15 08:12:03 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-15 08:12:03 | INFO | train | epoch 019 | loss 1.982 | trans_loss 4.878 | nll_loss 2.112 | w2v_ctc_loss 0.692 | task_loss 1.403 | contrastive_loss 0.148 | total 4138.65 | n_correct 2755.34 | ppl 4.32 | accuracy 66.576 | wps 11347.7 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.52 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 17.1 | wall 24295
2023-08-15 08:12:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:12:03 | INFO | fairseq.trainer | begin training epoch 20
2023-08-15 08:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:12:16 | INFO | train_inner | epoch 020:      8 / 1474 loss=1.98, trans_loss=4.872, nll_loss=2.105, w2v_ctc_loss=0.685, task_loss=1.41, contrastive_loss=0.188, total=4124.63, n_correct=2749.95, ppl=4.3, accuracy=66.671, wps=6757.9, ups=0.82, wpb=8249.3, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=24308
2023-08-15 08:12:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:12:40 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.165 | nll_loss 2.427 | w2v_ctc_loss 1.327 | task_loss 4.626 | contrastive_loss 0.313 | total 4003.4 | n_correct 2669.2 | ppl 5.38 | accuracy 66.673 | uer 18.045 | wer 20.178 | raw_wer 20.178 | bleu 21.98 | wps 2170.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.02
2023-08-15 08:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-15 08:12:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-15 08:12:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-15 08:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.98) (writing took 40.79153152927756 seconds)
2023-08-15 08:14:31 | INFO | train_inner | epoch 020:    108 / 1474 loss=1.96, trans_loss=4.856, nll_loss=2.082, w2v_ctc_loss=0.669, task_loss=1.354, contrastive_loss=0.109, total=4199.19, n_correct=2816.17, ppl=4.23, accuracy=67.065, wps=6246.9, ups=0.74, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=24443
2023-08-15 08:15:41 | INFO | train_inner | epoch 020:    208 / 1474 loss=1.97, trans_loss=4.861, nll_loss=2.089, w2v_ctc_loss=0.68, task_loss=1.459, contrastive_loss=0.161, total=4148.29, n_correct=2776.88, ppl=4.25, accuracy=66.94, wps=11857.3, ups=1.43, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=70, gb_free=15.3, wall=24513
2023-08-15 08:16:49 | INFO | train_inner | epoch 020:    308 / 1474 loss=1.956, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.674, task_loss=1.266, contrastive_loss=0.098, total=4191.34, n_correct=2816.57, ppl=4.23, accuracy=67.2, wps=12190.5, ups=1.45, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=24581
2023-08-15 08:17:59 | INFO | train_inner | epoch 020:    408 / 1474 loss=1.96, trans_loss=4.852, nll_loss=2.077, w2v_ctc_loss=0.675, task_loss=1.421, contrastive_loss=0.098, total=4114.19, n_correct=2763.94, ppl=4.22, accuracy=67.181, wps=11837.2, ups=1.44, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=24651
2023-08-15 08:19:08 | INFO | train_inner | epoch 020:    508 / 1474 loss=1.974, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.673, task_loss=1.445, contrastive_loss=0.184, total=4108.2, n_correct=2745.06, ppl=4.28, accuracy=66.819, wps=11833.5, ups=1.44, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=24720
2023-08-15 08:20:17 | INFO | train_inner | epoch 020:    608 / 1474 loss=1.98, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.685, task_loss=1.475, contrastive_loss=0.19, total=4092.44, n_correct=2735.68, ppl=4.27, accuracy=66.847, wps=11871.8, ups=1.45, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=24789
2023-08-15 08:21:26 | INFO | train_inner | epoch 020:    708 / 1474 loss=1.971, trans_loss=4.868, nll_loss=2.098, w2v_ctc_loss=0.691, task_loss=1.406, contrastive_loss=0.092, total=4137.06, n_correct=2762.15, ppl=4.28, accuracy=66.766, wps=12098.9, ups=1.46, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24858
2023-08-15 08:22:35 | INFO | train_inner | epoch 020:    808 / 1474 loss=1.969, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.688, task_loss=1.388, contrastive_loss=0.093, total=4146.78, n_correct=2772.3, ppl=4.28, accuracy=66.854, wps=11984.2, ups=1.45, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=24927
2023-08-15 08:23:46 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.002, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.682, task_loss=1.336, contrastive_loss=0.396, total=4161, n_correct=2770.74, ppl=4.31, accuracy=66.588, wps=11749.2, ups=1.41, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=24998
2023-08-15 08:24:55 | INFO | train_inner | epoch 020:   1008 / 1474 loss=1.966, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.675, task_loss=1.399, contrastive_loss=0.1, total=4168.14, n_correct=2787.23, ppl=4.29, accuracy=66.87, wps=12001.1, ups=1.44, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=25067
2023-08-15 08:26:04 | INFO | train_inner | epoch 020:   1108 / 1474 loss=1.989, trans_loss=4.873, nll_loss=2.105, w2v_ctc_loss=0.687, task_loss=1.351, contrastive_loss=0.242, total=4166.49, n_correct=2776.56, ppl=4.3, accuracy=66.64, wps=12031.4, ups=1.44, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=25136
2023-08-15 08:27:14 | INFO | train_inner | epoch 020:   1208 / 1474 loss=1.977, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.702, task_loss=1.55, contrastive_loss=0.087, total=4029.18, n_correct=2686.62, ppl=4.27, accuracy=66.679, wps=11674.9, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=11.4, wall=25205
2023-08-15 08:28:23 | INFO | train_inner | epoch 020:   1308 / 1474 loss=1.973, trans_loss=4.873, nll_loss=2.106, w2v_ctc_loss=0.687, task_loss=1.477, contrastive_loss=0.093, total=4123.21, n_correct=2750.1, ppl=4.3, accuracy=66.698, wps=11858.5, ups=1.44, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=25275
2023-08-15 08:29:32 | INFO | train_inner | epoch 020:   1408 / 1474 loss=1.974, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.69, task_loss=1.478, contrastive_loss=0.092, total=4116.28, n_correct=2745.71, ppl=4.3, accuracy=66.704, wps=11873, ups=1.44, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=25344
2023-08-15 08:30:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:30:41 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.163 | nll_loss 2.421 | w2v_ctc_loss 1.318 | task_loss 4.628 | contrastive_loss 0.308 | total 4003.4 | n_correct 2670 | ppl 5.35 | accuracy 66.693 | uer 17.681 | wer 19.582 | raw_wer 19.582 | bleu 22.27 | wps 2131.5 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 22.27
2023-08-15 08:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-15 08:30:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 29466 updates, score 22.27) (writing took 31.56113838031888 seconds)
2023-08-15 08:31:14 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-15 08:31:14 | INFO | train | epoch 020 | loss 1.973 | trans_loss 4.866 | nll_loss 2.095 | w2v_ctc_loss 0.682 | task_loss 1.404 | contrastive_loss 0.146 | total 4138.65 | n_correct 2766.73 | ppl 4.27 | accuracy 66.851 | wps 10604.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.517 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 15.9 | wall 25446
2023-08-15 08:31:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:31:14 | INFO | fairseq.trainer | begin training epoch 21
2023-08-15 08:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:31:46 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.975, trans_loss=4.865, nll_loss=2.095, w2v_ctc_loss=0.673, task_loss=1.337, contrastive_loss=0.213, total=4152.26, n_correct=2778.38, ppl=4.27, accuracy=66.912, wps=6236.5, ups=0.75, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=25478
2023-08-15 08:32:55 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.967, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.674, task_loss=1.311, contrastive_loss=0.201, total=4195.08, n_correct=2819.67, ppl=4.2, accuracy=67.214, wps=12103.2, ups=1.44, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=25547
2023-08-15 08:33:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 08:34:04 | INFO | train_inner | epoch 021:    235 / 1474 loss=1.956, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.661, task_loss=1.346, contrastive_loss=0.157, total=4154.29, n_correct=2792.57, ppl=4.21, accuracy=67.221, wps=11949.2, ups=1.44, wpb=8308.6, bsz=312.2, num_updates=29700, lr=8.2061e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=25616
2023-08-15 08:35:14 | INFO | train_inner | epoch 021:    335 / 1474 loss=1.969, trans_loss=4.855, nll_loss=2.081, w2v_ctc_loss=0.683, task_loss=1.395, contrastive_loss=0.162, total=4157.2, n_correct=2784.25, ppl=4.23, accuracy=66.974, wps=11912.7, ups=1.43, wpb=8314.4, bsz=311.1, num_updates=29800, lr=8.19232e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=25686
2023-08-15 08:36:23 | INFO | train_inner | epoch 021:    435 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.672, task_loss=1.347, contrastive_loss=0.085, total=4181.07, n_correct=2814.25, ppl=4.21, accuracy=67.309, wps=12107.4, ups=1.45, wpb=8362.1, bsz=308.2, num_updates=29900, lr=8.17861e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=25755
2023-08-15 08:37:32 | INFO | train_inner | epoch 021:    535 / 1474 loss=1.956, trans_loss=4.843, nll_loss=2.065, w2v_ctc_loss=0.679, task_loss=1.456, contrastive_loss=0.084, total=4089.72, n_correct=2754.81, ppl=4.19, accuracy=67.359, wps=11831.4, ups=1.45, wpb=8179.4, bsz=295.7, num_updates=30000, lr=8.16497e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=25824
2023-08-15 08:37:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 08:37:55 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.969 | trans_loss 5.175 | nll_loss 2.437 | w2v_ctc_loss 1.325 | task_loss 4.634 | contrastive_loss 0.308 | total 4003.4 | n_correct 2671.7 | ppl 5.42 | accuracy 66.736 | uer 17.7 | wer 19.507 | raw_wer 19.507 | bleu 22.07 | wps 2257.4 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.27
2023-08-15 08:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-15 08:37:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-15 08:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-15 08:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.07) (writing took 25.492328878492117 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 08:39:32 | INFO | train_inner | epoch 021:    635 / 1474 loss=1.97, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.668, task_loss=1.388, contrastive_loss=0.255, total=4210.28, n_correct=2828.92, ppl=4.21, accuracy=67.191, wps=7060.7, ups=0.84, wpb=8420.6, bsz=315.7, num_updates=30100, lr=8.15139e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=25944
2023-08-15 08:40:41 | INFO | train_inner | epoch 021:    735 / 1474 loss=1.963, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.674, task_loss=1.404, contrastive_loss=0.116, total=4149.01, n_correct=2783.68, ppl=4.24, accuracy=67.093, wps=11998.2, ups=1.45, wpb=8298, bsz=307.4, num_updates=30200, lr=8.13788e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=26013
2023-08-15 08:41:50 | INFO | train_inner | epoch 021:    835 / 1474 loss=1.972, trans_loss=4.866, nll_loss=2.095, w2v_ctc_loss=0.681, task_loss=1.477, contrastive_loss=0.131, total=4075.99, n_correct=2724.19, ppl=4.27, accuracy=66.835, wps=11734.8, ups=1.44, wpb=8152, bsz=295.7, num_updates=30300, lr=8.12444e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=26082
2023-08-15 08:42:59 | INFO | train_inner | epoch 021:    935 / 1474 loss=1.962, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.679, task_loss=1.412, contrastive_loss=0.103, total=4091.88, n_correct=2743.39, ppl=4.23, accuracy=67.045, wps=11942.1, ups=1.46, wpb=8183.8, bsz=300, num_updates=30400, lr=8.11107e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=26151
2023-08-15 08:44:08 | INFO | train_inner | epoch 021:   1035 / 1474 loss=1.964, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.68, task_loss=1.427, contrastive_loss=0.1, total=4107.66, n_correct=2753.27, ppl=4.25, accuracy=67.028, wps=11919.6, ups=1.45, wpb=8215.3, bsz=299.5, num_updates=30500, lr=8.09776e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=14.3, wall=26220
2023-08-15 08:45:17 | INFO | train_inner | epoch 021:   1135 / 1474 loss=1.964, trans_loss=4.853, nll_loss=2.078, w2v_ctc_loss=0.683, task_loss=1.501, contrastive_loss=0.104, total=4118.94, n_correct=2765.82, ppl=4.22, accuracy=67.149, wps=11931.5, ups=1.45, wpb=8237.9, bsz=294.9, num_updates=30600, lr=8.08452e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=26289
2023-08-15 08:46:26 | INFO | train_inner | epoch 021:   1235 / 1474 loss=1.967, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.675, task_loss=1.347, contrastive_loss=0.155, total=4151.84, n_correct=2784.33, ppl=4.24, accuracy=67.063, wps=12021.1, ups=1.45, wpb=8303.7, bsz=309.1, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=26358
2023-08-15 08:47:35 | INFO | train_inner | epoch 021:   1335 / 1474 loss=1.96, trans_loss=4.853, nll_loss=2.081, w2v_ctc_loss=0.672, task_loss=1.362, contrastive_loss=0.117, total=4145.91, n_correct=2789.8, ppl=4.23, accuracy=67.29, wps=11923.4, ups=1.44, wpb=8291.8, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=26427
2023-08-15 08:48:45 | INFO | train_inner | epoch 021:   1435 / 1474 loss=1.982, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.698, task_loss=1.471, contrastive_loss=0.165, total=4136.27, n_correct=2764.38, ppl=4.27, accuracy=66.833, wps=11819.1, ups=1.43, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=26497
2023-08-15 08:49:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
2023-08-15 08:49:35 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.162 | nll_loss 2.422 | w2v_ctc_loss 1.319 | task_loss 4.651 | contrastive_loss 0.308 | total 4003.4 | n_correct 2677.5 | ppl 5.36 | accuracy 66.881 | uer 17.822 | wer 19.634 | raw_wer 19.634 | bleu 22.33 | wps 2288 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 22.33
2023-08-15 08:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-15 08:49:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 08:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 21 @ 30939 updates, score 22.33) (writing took 30.37798308953643 seconds)
2023-08-15 08:50:06 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-15 08:50:06 | INFO | train | epoch 021 | loss 1.965 | trans_loss 4.854 | nll_loss 2.08 | w2v_ctc_loss 0.677 | task_loss 1.404 | contrastive_loss 0.143 | total 4138.9 | n_correct 2777.71 | ppl 4.23 | accuracy 67.112 | wps 10765.7 | ups 1.3 | wpb 8277.8 | bsz 305.7 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.524 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 15.1 | wall 26578
2023-08-15 08:50:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 08:50:06 | INFO | fairseq.trainer | begin training epoch 22
2023-08-15 08:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 08:50:56 | INFO | train_inner | epoch 022:     61 / 1474 loss=1.956, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.679, task_loss=1.414, contrastive_loss=0.086, total=4133.81, n_correct=2786.51, ppl=4.19, accuracy=67.408, wps=6321.4, ups=0.76, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=26628
2023-08-15 08:52:06 | INFO | train_inner | epoch 022:    161 / 1474 loss=1.961, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.673, task_loss=1.431, contrastive_loss=0.165, total=4116.11, n_correct=2770.56, ppl=4.17, accuracy=67.31, wps=11760.2, ups=1.43, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=26698
2023-08-15 08:53:15 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.941, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.655, task_loss=1.227, contrastive_loss=0.107, total=4272.11, n_correct=2892.95, ppl=4.14, accuracy=67.717, wps=12398, ups=1.45, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=26767
2023-08-15 08:54:26 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.978, trans_loss=4.849, nll_loss=2.074, w2v_ctc_loss=0.676, task_loss=1.427, contrastive_loss=0.264, total=4178.4, n_correct=2804.44, ppl=4.21, accuracy=67.118, wps=11852.2, ups=1.42, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=26838
2023-08-15 08:55:35 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.963, trans_loss=4.844, nll_loss=2.067, w2v_ctc_loss=0.673, task_loss=1.476, contrastive_loss=0.148, total=4132.96, n_correct=2779.08, ppl=4.19, accuracy=67.242, wps=11953.1, ups=1.45, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=26907
2023-08-15 08:55:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 08:56:46 | INFO | train_inner | epoch 022:    562 / 1474 loss=1.951, trans_loss=4.839, nll_loss=2.06, w2v_ctc_loss=0.668, task_loss=1.414, contrastive_loss=0.094, total=4150.92, n_correct=2799.25, ppl=4.17, accuracy=67.437, wps=11710.1, ups=1.41, wpb=8301.8, bsz=306.9, num_updates=31500, lr=7.96819e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=26978
2023-08-15 08:57:55 | INFO | train_inner | epoch 022:    662 / 1474 loss=1.95, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.655, task_loss=1.334, contrastive_loss=0.181, total=4146.54, n_correct=2801.49, ppl=4.15, accuracy=67.562, wps=12046.7, ups=1.45, wpb=8293.1, bsz=311.9, num_updates=31600, lr=7.95557e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=12.9, wall=27047
2023-08-15 08:59:05 | INFO | train_inner | epoch 022:    762 / 1474 loss=1.952, trans_loss=4.838, nll_loss=2.059, w2v_ctc_loss=0.67, task_loss=1.443, contrastive_loss=0.095, total=4170.82, n_correct=2810.6, ppl=4.17, accuracy=67.387, wps=11934, ups=1.43, wpb=8341.6, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=11.5, wall=27116
2023-08-15 09:00:14 | INFO | train_inner | epoch 022:    862 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.672, task_loss=1.508, contrastive_loss=0.083, total=4077.65, n_correct=2739.29, ppl=4.2, accuracy=67.178, wps=11784.2, ups=1.44, wpb=8155.3, bsz=290.5, num_updates=31800, lr=7.93052e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=27186
2023-08-15 09:01:24 | INFO | train_inner | epoch 022:    962 / 1474 loss=1.95, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.664, task_loss=1.412, contrastive_loss=0.094, total=4136.66, n_correct=2787.54, ppl=4.17, accuracy=67.386, wps=11827.6, ups=1.43, wpb=8273.3, bsz=304.7, num_updates=31900, lr=7.91808e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=14.4, wall=27256
2023-08-15 09:02:32 | INFO | train_inner | epoch 022:   1062 / 1474 loss=1.955, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.653, task_loss=1.347, contrastive_loss=0.246, total=4152.13, n_correct=2804.78, ppl=4.16, accuracy=67.55, wps=12103.3, ups=1.46, wpb=8304.3, bsz=313.8, num_updates=32000, lr=7.90569e-05, gnorm=0.503, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=27324
2023-08-15 09:02:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:02:55 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.16 | nll_loss 2.422 | w2v_ctc_loss 1.32 | task_loss 4.623 | contrastive_loss 0.308 | total 4003.4 | n_correct 2675 | ppl 5.36 | accuracy 66.818 | uer 17.482 | wer 19.321 | raw_wer 19.321 | bleu 22.3 | wps 2232.9 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.33
2023-08-15 09:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-15 09:02:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-15 09:02:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-15 09:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.3) (writing took 42.399332424625754 seconds)
2023-08-15 09:04:48 | INFO | train_inner | epoch 022:   1162 / 1474 loss=1.968, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.679, task_loss=1.458, contrastive_loss=0.138, total=4102.27, n_correct=2749.47, ppl=4.25, accuracy=67.023, wps=6063.9, ups=0.74, wpb=8204.5, bsz=296.1, num_updates=32100, lr=7.89337e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=27460
2023-08-15 09:05:57 | INFO | train_inner | epoch 022:   1262 / 1474 loss=1.96, trans_loss=4.855, nll_loss=2.083, w2v_ctc_loss=0.67, task_loss=1.304, contrastive_loss=0.131, total=4179.1, n_correct=2807.7, ppl=4.24, accuracy=67.184, wps=12102.8, ups=1.45, wpb=8358.2, bsz=321.7, num_updates=32200, lr=7.8811e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=16.9, wall=27529
2023-08-15 09:07:06 | INFO | train_inner | epoch 022:   1362 / 1474 loss=1.957, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.664, task_loss=1.409, contrastive_loss=0.154, total=4061.14, n_correct=2733.14, ppl=4.19, accuracy=67.3, wps=11786.6, ups=1.45, wpb=8122.3, bsz=299.1, num_updates=32300, lr=7.86889e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=27598
2023-08-15 09:08:15 | INFO | train_inner | epoch 022:   1462 / 1474 loss=1.965, trans_loss=4.857, nll_loss=2.083, w2v_ctc_loss=0.683, task_loss=1.503, contrastive_loss=0.101, total=4083.08, n_correct=2740.28, ppl=4.24, accuracy=67.113, wps=11827.4, ups=1.45, wpb=8166.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=69, gb_free=16, wall=27667
2023-08-15 09:08:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:08:47 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.942 | trans_loss 5.157 | nll_loss 2.416 | w2v_ctc_loss 1.276 | task_loss 4.608 | contrastive_loss 0.306 | total 4003.4 | n_correct 2676.5 | ppl 5.34 | accuracy 66.856 | uer 17.328 | wer 19.235 | raw_wer 19.235 | bleu 21.73 | wps 2153.1 | wpb 4003.4 | bsz 141.8 | num_updates 32412 | best_bleu 22.33
2023-08-15 09:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-08-15 09:08:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 09:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 09:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt (epoch 22 @ 32412 updates, score 21.73) (writing took 15.687888592481613 seconds)
2023-08-15 09:09:03 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-15 09:09:03 | INFO | train | epoch 022 | loss 1.957 | trans_loss 4.843 | nll_loss 2.066 | w2v_ctc_loss 0.669 | task_loss 1.405 | contrastive_loss 0.141 | total 4138.62 | n_correct 2786.74 | ppl 4.19 | accuracy 67.335 | wps 10730.1 | ups 1.3 | wpb 8277.2 | bsz 305.7 | num_updates 32412 | lr 7.85529e-05 | gnorm 0.525 | clip 0 | loss_scale 8 | train_wall 1015 | gb_free 11.3 | wall 27714
2023-08-15 09:09:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:09:03 | INFO | fairseq.trainer | begin training epoch 23
2023-08-15 09:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:10:10 | INFO | train_inner | epoch 023:     88 / 1474 loss=1.943, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.664, task_loss=1.427, contrastive_loss=0.088, total=4093.3, n_correct=2772.57, ppl=4.12, accuracy=67.734, wps=7080.8, ups=0.86, wpb=8186.6, bsz=301.3, num_updates=32500, lr=7.84465e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=68, gb_free=15.9, wall=27782
2023-08-15 09:11:20 | INFO | train_inner | epoch 023:    188 / 1474 loss=1.94, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.658, task_loss=1.492, contrastive_loss=0.089, total=4116.26, n_correct=2792.72, ppl=4.1, accuracy=67.846, wps=11863.8, ups=1.44, wpb=8232.5, bsz=294.4, num_updates=32600, lr=7.8326e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=27852
2023-08-15 09:12:29 | INFO | train_inner | epoch 023:    288 / 1474 loss=1.953, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.657, task_loss=1.41, contrastive_loss=0.167, total=4148.03, n_correct=2799.69, ppl=4.16, accuracy=67.494, wps=11886.2, ups=1.43, wpb=8296.1, bsz=305.7, num_updates=32700, lr=7.82062e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=69, gb_free=17.1, wall=27921
2023-08-15 09:13:39 | INFO | train_inner | epoch 023:    388 / 1474 loss=1.936, trans_loss=4.818, nll_loss=2.033, w2v_ctc_loss=0.655, task_loss=1.454, contrastive_loss=0.079, total=4115.99, n_correct=2793.23, ppl=4.09, accuracy=67.863, wps=11912.8, ups=1.45, wpb=8232, bsz=294.1, num_updates=32800, lr=7.80869e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=27990
2023-08-15 09:14:48 | INFO | train_inner | epoch 023:    488 / 1474 loss=1.944, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.655, task_loss=1.374, contrastive_loss=0.136, total=4156.5, n_correct=2814.62, ppl=4.13, accuracy=67.716, wps=12026, ups=1.45, wpb=8313, bsz=312.2, num_updates=32900, lr=7.79681e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=28060
2023-08-15 09:15:56 | INFO | train_inner | epoch 023:    588 / 1474 loss=1.94, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.659, task_loss=1.322, contrastive_loss=0.086, total=4174.84, n_correct=2827.63, ppl=4.13, accuracy=67.73, wps=12148.2, ups=1.45, wpb=8349.7, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=28128
2023-08-15 09:17:06 | INFO | train_inner | epoch 023:    688 / 1474 loss=1.949, trans_loss=4.832, nll_loss=2.053, w2v_ctc_loss=0.662, task_loss=1.407, contrastive_loss=0.124, total=4139.68, n_correct=2800.47, ppl=4.15, accuracy=67.649, wps=11972.1, ups=1.45, wpb=8279.4, bsz=302.2, num_updates=33100, lr=7.77322e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=16.4, wall=28198
2023-08-15 09:18:14 | INFO | train_inner | epoch 023:    788 / 1474 loss=1.947, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.664, task_loss=1.414, contrastive_loss=0.104, total=4147.97, n_correct=2801.98, ppl=4.15, accuracy=67.551, wps=12049.3, ups=1.45, wpb=8295.9, bsz=305.8, num_updates=33200, lr=7.76151e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=28266
2023-08-15 09:19:24 | INFO | train_inner | epoch 023:    888 / 1474 loss=1.95, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.658, task_loss=1.281, contrastive_loss=0.186, total=4182.69, n_correct=2831.01, ppl=4.13, accuracy=67.684, wps=12092.4, ups=1.45, wpb=8365.4, bsz=325, num_updates=33300, lr=7.74984e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=28336
2023-08-15 09:20:33 | INFO | train_inner | epoch 023:    988 / 1474 loss=1.973, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.663, task_loss=1.405, contrastive_loss=0.346, total=4165.01, n_correct=2802.3, ppl=4.16, accuracy=67.282, wps=11992.9, ups=1.44, wpb=8330, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=17.4, wall=28405
2023-08-15 09:21:43 | INFO | train_inner | epoch 023:   1088 / 1474 loss=1.952, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.671, task_loss=1.494, contrastive_loss=0.092, total=4092.37, n_correct=2760.86, ppl=4.17, accuracy=67.464, wps=11736.8, ups=1.43, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=28475
2023-08-15 09:22:53 | INFO | train_inner | epoch 023:   1188 / 1474 loss=1.949, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.671, task_loss=1.398, contrastive_loss=0.085, total=4164.9, n_correct=2811.78, ppl=4.17, accuracy=67.511, wps=11902.5, ups=1.43, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=13.4, wall=28545
2023-08-15 09:24:02 | INFO | train_inner | epoch 023:   1288 / 1474 loss=1.943, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.66, task_loss=1.368, contrastive_loss=0.096, total=4136.96, n_correct=2793.99, ppl=4.15, accuracy=67.537, wps=11967.1, ups=1.45, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=28614
2023-08-15 09:25:11 | INFO | train_inner | epoch 023:   1388 / 1474 loss=1.959, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.665, task_loss=1.419, contrastive_loss=0.156, total=4142.84, n_correct=2789.47, ppl=4.2, accuracy=67.332, wps=11930.6, ups=1.44, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=28683
2023-08-15 09:26:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:26:35 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.156 | nll_loss 2.414 | w2v_ctc_loss 1.305 | task_loss 4.675 | contrastive_loss 0.305 | total 4003.4 | n_correct 2674.4 | ppl 5.33 | accuracy 66.803 | uer 17.384 | wer 19.235 | raw_wer 19.235 | bleu 22.08 | wps 2199.3 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 22.33
2023-08-15 09:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-15 09:26:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt
2023-08-15 09:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt
2023-08-15 09:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0808.pt (epoch 23 @ 33886 updates, score 22.08) (writing took 26.592188460752368 seconds)
2023-08-15 09:27:02 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-15 09:27:02 | INFO | train | epoch 023 | loss 1.95 | trans_loss 4.832 | nll_loss 2.052 | w2v_ctc_loss 0.661 | task_loss 1.404 | contrastive_loss 0.139 | total 4138.65 | n_correct 2796.92 | ppl 4.15 | accuracy 67.581 | wps 11303.7 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 13.4 | wall 28794
2023-08-15 09:27:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:27:02 | INFO | fairseq.trainer | begin training epoch 24
2023-08-15 09:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:27:20 | INFO | train_inner | epoch 024:     14 / 1474 loss=1.964, trans_loss=4.841, nll_loss=2.065, w2v_ctc_loss=0.658, task_loss=1.421, contrastive_loss=0.236, total=4084.21, n_correct=2749.85, ppl=4.18, accuracy=67.329, wps=6348.9, ups=0.78, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=28812
2023-08-15 09:28:30 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.942, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.64, task_loss=1.297, contrastive_loss=0.247, total=4168.61, n_correct=2833.02, ppl=4.07, accuracy=67.961, wps=11951.8, ups=1.43, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=11, wall=28882
2023-08-15 09:28:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:28:53 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.163 | nll_loss 2.42 | w2v_ctc_loss 1.31 | task_loss 4.666 | contrastive_loss 0.305 | total 4003.4 | n_correct 2666.5 | ppl 5.35 | accuracy 66.606 | uer 17.45 | wer 19.28 | raw_wer 19.28 | bleu 22.46 | wps 2239.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.46
2023-08-15 09:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-15 09:28:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-15 09:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-15 09:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.46) (writing took 53.71330666169524 seconds)
2023-08-15 09:30:58 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.95, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.639, task_loss=1.224, contrastive_loss=0.301, total=4252.53, n_correct=2887.72, ppl=4.1, accuracy=67.906, wps=5754.8, ups=0.68, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=29030
2023-08-15 09:32:07 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.931, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.648, task_loss=1.367, contrastive_loss=0.081, total=4138.44, n_correct=2813.93, ppl=4.08, accuracy=67.995, wps=11980.1, ups=1.45, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=29099
2023-08-15 09:33:17 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.959, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.666, task_loss=1.483, contrastive_loss=0.223, total=4153.83, n_correct=2811.64, ppl=4.09, accuracy=67.688, wps=11848.1, ups=1.43, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=70, gb_free=15.9, wall=29169
2023-08-15 09:34:26 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.943, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.656, task_loss=1.428, contrastive_loss=0.152, total=4141.88, n_correct=2810.02, ppl=4.09, accuracy=67.844, wps=11921.7, ups=1.44, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=29238
2023-08-15 09:35:36 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.937, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.649, task_loss=1.412, contrastive_loss=0.112, total=4162.06, n_correct=2821.44, ppl=4.1, accuracy=67.79, wps=12018, ups=1.44, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=29308
2023-08-15 09:36:45 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.942, trans_loss=4.824, nll_loss=2.041, w2v_ctc_loss=0.652, task_loss=1.453, contrastive_loss=0.127, total=4097.35, n_correct=2776.54, ppl=4.11, accuracy=67.764, wps=11822.9, ups=1.44, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=29377
2023-08-15 09:37:55 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.941, trans_loss=4.828, nll_loss=2.048, w2v_ctc_loss=0.657, task_loss=1.404, contrastive_loss=0.102, total=4124.25, n_correct=2793.12, ppl=4.13, accuracy=67.724, wps=11797.4, ups=1.43, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=29447
2023-08-15 09:39:03 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.946, trans_loss=4.827, nll_loss=2.044, w2v_ctc_loss=0.665, task_loss=1.562, contrastive_loss=0.079, total=4041.44, n_correct=2731.99, ppl=4.12, accuracy=67.599, wps=11779, ups=1.46, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=29515
2023-08-15 09:40:13 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.938, trans_loss=4.825, nll_loss=2.042, w2v_ctc_loss=0.652, task_loss=1.466, contrastive_loss=0.082, total=4128.8, n_correct=2799.61, ppl=4.12, accuracy=67.807, wps=11910.1, ups=1.44, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=29585
2023-08-15 09:41:22 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.942, trans_loss=4.816, nll_loss=2.032, w2v_ctc_loss=0.661, task_loss=1.354, contrastive_loss=0.126, total=4130.49, n_correct=2800.26, ppl=4.09, accuracy=67.795, wps=11919.7, ups=1.44, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=29654
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 09:42:32 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.94, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.651, task_loss=1.389, contrastive_loss=0.113, total=4157.47, n_correct=2814.75, ppl=4.12, accuracy=67.703, wps=11894.9, ups=1.43, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=29724
2023-08-15 09:43:41 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.946, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.668, task_loss=1.493, contrastive_loss=0.085, total=4107.23, n_correct=2779.07, ppl=4.13, accuracy=67.663, wps=11916, ups=1.45, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=29793
2023-08-15 09:44:50 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.943, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.666, task_loss=1.468, contrastive_loss=0.084, total=4094.39, n_correct=2773.88, ppl=4.13, accuracy=67.748, wps=11929.2, ups=1.46, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=29862
2023-08-15 09:45:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
2023-08-15 09:45:54 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.161 | nll_loss 2.422 | w2v_ctc_loss 1.302 | task_loss 4.662 | contrastive_loss 0.306 | total 4003.4 | n_correct 2679.8 | ppl 5.36 | accuracy 66.938 | uer 17.495 | wer 19.328 | raw_wer 19.328 | bleu 22.08 | wps 2256.2 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 22.46
2023-08-15 09:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-15 09:45:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt
2023-08-15 09:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt
2023-08-15 09:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.0809.pt (epoch 24 @ 35360 updates, score 22.08) (writing took 23.378317130729556 seconds)
2023-08-15 09:46:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-15 09:46:17 | INFO | train | epoch 024 | loss 1.942 | trans_loss 4.821 | nll_loss 2.038 | w2v_ctc_loss 0.654 | task_loss 1.405 | contrastive_loss 0.137 | total 4138.65 | n_correct 2805.79 | ppl 4.11 | accuracy 67.795 | wps 10559.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.9 | wall 29949
2023-08-15 09:46:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 09:46:18 | INFO | fairseq.trainer | begin training epoch 25
2023-08-15 09:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 09:46:52 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.927, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.645, task_loss=1.355, contrastive_loss=0.09, total=4165.57, n_correct=2840.85, ppl=4.07, accuracy=68.198, wps=6779, ups=0.81, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=69, gb_free=12.8, wall=29984
2023-08-15 09:48:02 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.921, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.64, task_loss=1.365, contrastive_loss=0.087, total=4135.43, n_correct=2822.59, ppl=4.02, accuracy=68.254, wps=11904.5, ups=1.44, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=30054
2023-08-15 09:49:12 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.931, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.65, task_loss=1.441, contrastive_loss=0.093, total=4116.13, n_correct=2796.2, ppl=4.06, accuracy=67.933, wps=11787.1, ups=1.43, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=30124
2023-08-15 09:50:21 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.93, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.643, task_loss=1.5, contrastive_loss=0.119, total=4141.49, n_correct=2820.6, ppl=4.04, accuracy=68.106, wps=11905.7, ups=1.44, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=30193
2023-08-15 09:51:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 09:51:32 | INFO | train_inner | epoch 025:    441 / 1474 loss=1.938, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.667, task_loss=1.505, contrastive_loss=0.081, total=4149.36, n_correct=2823.31, ppl=4.05, accuracy=68.042, wps=11744.9, ups=1.42, wpb=8298.7, bsz=290.1, num_updates=35800, lr=7.47435e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=30264
2023-08-15 09:52:41 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.934, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.649, task_loss=1.371, contrastive_loss=0.093, total=4154.79, n_correct=2820.91, ppl=4.1, accuracy=67.895, wps=11988.5, ups=1.44, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=30333
2023-08-15 09:53:51 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.936, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.648, task_loss=1.395, contrastive_loss=0.161, total=4156.33, n_correct=2824.16, ppl=4.05, accuracy=67.948, wps=11977.1, ups=1.44, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=30403
2023-08-15 09:53:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 09:54:15 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.16 | nll_loss 2.417 | w2v_ctc_loss 1.302 | task_loss 4.642 | contrastive_loss 0.308 | total 4003.4 | n_correct 2678.4 | ppl 5.34 | accuracy 66.903 | uer 17.368 | wer 19.082 | raw_wer 19.082 | bleu 22.47 | wps 1850.6 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.47
2023-08-15 09:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-15 09:54:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-15 09:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-15 09:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.47) (writing took 57.3581663146615 seconds)
2023-08-15 09:56:22 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.938, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.648, task_loss=1.416, contrastive_loss=0.155, total=4133.94, n_correct=2811.28, ppl=4.06, accuracy=68.005, wps=5455.2, ups=0.66, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=30554
2023-08-15 09:57:32 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.928, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.647, task_loss=1.303, contrastive_loss=0.098, total=4174.24, n_correct=2843.4, ppl=4.07, accuracy=68.118, wps=12001.8, ups=1.44, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=30624
2023-08-15 09:58:41 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.936, trans_loss=4.811, nll_loss=2.026, w2v_ctc_loss=0.649, task_loss=1.337, contrastive_loss=0.16, total=4154.13, n_correct=2826.87, ppl=4.07, accuracy=68.05, wps=11974, ups=1.44, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=10.5, wall=30693
2023-08-15 09:59:51 | INFO | train_inner | epoch 025:   1041 / 1474 loss=1.951, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.646, task_loss=1.396, contrastive_loss=0.269, total=4178.3, n_correct=2832.28, ppl=4.11, accuracy=67.785, wps=11950, ups=1.43, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=30763
2023-08-15 10:01:00 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.933, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.651, task_loss=1.51, contrastive_loss=0.075, total=4042.33, n_correct=2746.02, ppl=4.08, accuracy=67.932, wps=11752, ups=1.45, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=30832
2023-08-15 10:02:09 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.933, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.646, task_loss=1.43, contrastive_loss=0.085, total=4087.78, n_correct=2777.79, ppl=4.1, accuracy=67.954, wps=11829.3, ups=1.45, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=30901
2023-08-15 10:03:18 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.941, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.65, task_loss=1.373, contrastive_loss=0.178, total=4166.64, n_correct=2829.28, ppl=4.08, accuracy=67.903, wps=12041.4, ups=1.44, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=30970
2023-08-15 10:04:28 | INFO | train_inner | epoch 025:   1441 / 1474 loss=1.947, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.654, task_loss=1.429, contrastive_loss=0.148, total=4114.64, n_correct=2781.25, ppl=4.13, accuracy=67.594, wps=11755.7, ups=1.43, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=31040
2023-08-15 10:04:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:05:15 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.27 | task_loss 4.621 | contrastive_loss 0.299 | total 4003.4 | n_correct 2682.9 | ppl 5.33 | accuracy 67.016 | uer 17.272 | wer 19.272 | raw_wer 19.272 | bleu 22.46 | wps 2242.1 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 22.47
2023-08-15 10:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-15 10:05:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt
2023-08-15 10:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt
2023-08-15 10:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4609.pt (epoch 25 @ 36833 updates, score 22.46) (writing took 29.225748728960752 seconds)
2023-08-15 10:05:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-15 10:05:44 | INFO | train | epoch 025 | loss 1.935 | trans_loss 4.812 | nll_loss 2.026 | w2v_ctc_loss 0.649 | task_loss 1.407 | contrastive_loss 0.127 | total 4137.25 | n_correct 2812.26 | ppl 4.07 | accuracy 67.974 | wps 10445.3 | ups 1.26 | wpb 8274.5 | bsz 305.1 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.527 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 14 | wall 31116
2023-08-15 10:05:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:05:45 | INFO | fairseq.trainer | begin training epoch 26
2023-08-15 10:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:06:39 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.924, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.64, task_loss=1.328, contrastive_loss=0.112, total=4172.16, n_correct=2844.88, ppl=4.02, accuracy=68.187, wps=6399.4, ups=0.77, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=31171
2023-08-15 10:07:49 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.93, trans_loss=4.795, nll_loss=2.005, w2v_ctc_loss=0.622, task_loss=1.237, contrastive_loss=0.285, total=4265.22, n_correct=2919.59, ppl=4.01, accuracy=68.451, wps=12210.7, ups=1.43, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=31241
2023-08-15 10:08:58 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.935, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.646, task_loss=1.396, contrastive_loss=0.175, total=4123.94, n_correct=2811.75, ppl=4.02, accuracy=68.181, wps=11845.6, ups=1.44, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=31310
2023-08-15 10:10:07 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.927, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.639, task_loss=1.34, contrastive_loss=0.13, total=4168.11, n_correct=2843.9, ppl=4.03, accuracy=68.23, wps=12085.4, ups=1.45, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=31379
2023-08-15 10:11:16 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.931, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.648, task_loss=1.346, contrastive_loss=0.175, total=4167.53, n_correct=2848.77, ppl=4, accuracy=68.356, wps=12109.7, ups=1.45, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=13.7, wall=31448
2023-08-15 10:12:26 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.927, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.65, task_loss=1.414, contrastive_loss=0.095, total=4158.48, n_correct=2839.42, ppl=4.03, accuracy=68.28, wps=11889.7, ups=1.43, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=12.5, wall=31518
2023-08-15 10:13:35 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.922, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.635, task_loss=1.439, contrastive_loss=0.081, total=4129.11, n_correct=2815.99, ppl=4.03, accuracy=68.198, wps=11911.7, ups=1.44, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=13.5, wall=31587
2023-08-15 10:14:45 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.939, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.645, task_loss=1.413, contrastive_loss=0.196, total=4096.84, n_correct=2791.13, ppl=4.05, accuracy=68.129, wps=11818.9, ups=1.44, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=31657
2023-08-15 10:15:54 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.928, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.648, task_loss=1.399, contrastive_loss=0.097, total=4176.27, n_correct=2846.31, ppl=4.03, accuracy=68.154, wps=12109.9, ups=1.45, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=31726
2023-08-15 10:17:03 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.928, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.632, task_loss=1.447, contrastive_loss=0.148, total=4141.01, n_correct=2823.94, ppl=4.04, accuracy=68.194, wps=11888.7, ups=1.44, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=31795
2023-08-15 10:18:13 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.927, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.647, task_loss=1.483, contrastive_loss=0.082, total=4113.69, n_correct=2803.77, ppl=4.04, accuracy=68.157, wps=11853.6, ups=1.44, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=31865
2023-08-15 10:19:22 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.933, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.646, task_loss=1.464, contrastive_loss=0.12, total=4116.78, n_correct=2799.07, ppl=4.07, accuracy=67.992, wps=11826.7, ups=1.44, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31934
2023-08-15 10:19:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:19:46 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.16 | nll_loss 2.417 | w2v_ctc_loss 1.373 | task_loss 4.647 | contrastive_loss 0.294 | total 4003.4 | n_correct 2681.6 | ppl 5.34 | accuracy 66.983 | uer 17.477 | wer 19.414 | raw_wer 19.414 | bleu 22.55 | wps 2201.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.55
2023-08-15 10:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-15 10:19:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-15 10:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-15 10:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.55) (writing took 49.746575059369206 seconds)
2023-08-15 10:21:47 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.936, trans_loss=4.816, nll_loss=2.029, w2v_ctc_loss=0.659, task_loss=1.554, contrastive_loss=0.082, total=4001.06, n_correct=2718.19, ppl=4.08, accuracy=67.937, wps=5523.9, ups=0.69, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=32079
2023-08-15 10:22:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 10:22:58 | INFO | train_inner | epoch 026:   1368 / 1474 loss=1.924, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.634, task_loss=1.405, contrastive_loss=0.095, total=4157.05, n_correct=2832.57, ppl=4.06, accuracy=68.139, wps=11731, ups=1.41, wpb=8314.1, bsz=310.7, num_updates=38200, lr=7.23575e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=70, gb_free=13.4, wall=32150
2023-08-15 10:24:07 | INFO | train_inner | epoch 026:   1468 / 1474 loss=1.916, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.633, task_loss=1.342, contrastive_loss=0.089, total=4151.66, n_correct=2838.73, ppl=4.03, accuracy=68.376, wps=12032.2, ups=1.45, wpb=8303.3, bsz=315.5, num_updates=38300, lr=7.22629e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=32219
2023-08-15 10:24:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:24:35 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.26 | task_loss 4.611 | contrastive_loss 0.297 | total 4003.4 | n_correct 2675 | ppl 5.35 | accuracy 66.818 | uer 17.309 | wer 19.216 | raw_wer 19.216 | bleu 22.22 | wps 2128 | wpb 4003.4 | bsz 141.8 | num_updates 38306 | best_bleu 22.55
2023-08-15 10:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38306 updates
2023-08-15 10:24:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-15 10:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-15 10:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt (epoch 26 @ 38306 updates, score 22.22) (writing took 20.961894690990448 seconds)
2023-08-15 10:24:56 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-15 10:24:56 | INFO | train | epoch 026 | loss 1.929 | trans_loss 4.802 | nll_loss 2.012 | w2v_ctc_loss 0.642 | task_loss 1.404 | contrastive_loss 0.133 | total 4138.42 | n_correct 2822.66 | ppl 4.03 | accuracy 68.206 | wps 10583.3 | ups 1.28 | wpb 8276.8 | bsz 305.6 | num_updates 38306 | lr 7.22573e-05 | gnorm 0.524 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.7 | wall 32268
2023-08-15 10:24:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:24:57 | INFO | fairseq.trainer | begin training epoch 27
2023-08-15 10:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:26:08 | INFO | train_inner | epoch 027:     94 / 1474 loss=1.906, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.626, task_loss=1.501, contrastive_loss=0.069, total=4072.63, n_correct=2805.54, ppl=3.92, accuracy=68.888, wps=6715, ups=0.82, wpb=8145.3, bsz=284.2, num_updates=38400, lr=7.21688e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=32340
2023-08-15 10:27:18 | INFO | train_inner | epoch 027:    194 / 1474 loss=1.909, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.625, task_loss=1.345, contrastive_loss=0.095, total=4179.66, n_correct=2870.04, ppl=3.97, accuracy=68.667, wps=12077.5, ups=1.44, wpb=8359.3, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=32410
2023-08-15 10:28:28 | INFO | train_inner | epoch 027:    294 / 1474 loss=1.919, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.636, task_loss=1.4, contrastive_loss=0.082, total=4173.27, n_correct=2858.76, ppl=4, accuracy=68.502, wps=11915.8, ups=1.43, wpb=8346.5, bsz=307, num_updates=38600, lr=7.19816e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=32480
2023-08-15 10:29:38 | INFO | train_inner | epoch 027:    394 / 1474 loss=1.944, trans_loss=4.798, nll_loss=2.007, w2v_ctc_loss=0.642, task_loss=1.465, contrastive_loss=0.272, total=4078.73, n_correct=2780.79, ppl=4.02, accuracy=68.178, wps=11678, ups=1.43, wpb=8157.5, bsz=297.5, num_updates=38700, lr=7.18885e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=32550
2023-08-15 10:30:47 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.931, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.634, task_loss=1.285, contrastive_loss=0.202, total=4245.37, n_correct=2898.9, ppl=4.03, accuracy=68.284, wps=12176.8, ups=1.43, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=32619
2023-08-15 10:31:57 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.927, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.643, task_loss=1.381, contrastive_loss=0.142, total=4134.93, n_correct=2825.57, ppl=4, accuracy=68.334, wps=11946.7, ups=1.44, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=32688
2023-08-15 10:33:06 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.925, trans_loss=4.796, nll_loss=2.004, w2v_ctc_loss=0.64, task_loss=1.401, contrastive_loss=0.119, total=4162.17, n_correct=2840.69, ppl=4.01, accuracy=68.25, wps=11928.4, ups=1.43, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=32758
2023-08-15 10:34:15 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.924, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.646, task_loss=1.475, contrastive_loss=0.082, total=4107.17, n_correct=2803.99, ppl=4.01, accuracy=68.271, wps=11922.8, ups=1.45, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=11.2, wall=32827
2023-08-15 10:35:24 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.919, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.633, task_loss=1.456, contrastive_loss=0.075, total=4101.4, n_correct=2802.86, ppl=4.03, accuracy=68.339, wps=11885.5, ups=1.45, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=32896
2023-08-15 10:36:34 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.934, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.633, task_loss=1.361, contrastive_loss=0.26, total=4195.5, n_correct=2866.55, ppl=4.02, accuracy=68.324, wps=11977.4, ups=1.43, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=32966
2023-08-15 10:37:44 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.92, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.637, task_loss=1.409, contrastive_loss=0.092, total=4147.99, n_correct=2832, ppl=4.01, accuracy=68.274, wps=11937.2, ups=1.44, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=33036
2023-08-15 10:38:53 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.929, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.647, task_loss=1.471, contrastive_loss=0.096, total=4104.84, n_correct=2797.08, ppl=4.04, accuracy=68.141, wps=11867.7, ups=1.45, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=11.9, wall=33105
2023-08-15 10:40:02 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.928, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.638, task_loss=1.49, contrastive_loss=0.148, total=4062.86, n_correct=2775.7, ppl=4.02, accuracy=68.319, wps=11795.5, ups=1.45, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=33174
2023-08-15 10:41:11 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.923, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.634, task_loss=1.323, contrastive_loss=0.131, total=4157.6, n_correct=2840.31, ppl=4.03, accuracy=68.316, wps=12072.4, ups=1.45, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=33243
2023-08-15 10:42:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:42:29 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.163 | nll_loss 2.422 | w2v_ctc_loss 1.347 | task_loss 4.63 | contrastive_loss 0.299 | total 4003.4 | n_correct 2679.3 | ppl 5.36 | accuracy 66.926 | uer 17.575 | wer 19.708 | raw_wer 19.708 | bleu 22.48 | wps 2232.5 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 22.55
2023-08-15 10:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-15 10:42:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt
2023-08-15 10:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt
2023-08-15 10:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4809.pt (epoch 27 @ 39780 updates, score 22.48) (writing took 21.285217706114054 seconds)
2023-08-15 10:42:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-15 10:42:51 | INFO | train | epoch 027 | loss 1.923 | trans_loss 4.794 | nll_loss 2.002 | w2v_ctc_loss 0.636 | task_loss 1.404 | contrastive_loss 0.132 | total 4138.65 | n_correct 2829.47 | ppl 4.01 | accuracy 68.367 | wps 11354.5 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 17.5 | wall 33343
2023-08-15 10:42:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 10:42:51 | INFO | fairseq.trainer | begin training epoch 28
2023-08-15 10:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 10:43:12 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.91, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.623, task_loss=1.362, contrastive_loss=0.081, total=4107.3, n_correct=2813.97, ppl=3.99, accuracy=68.511, wps=6767.4, ups=0.82, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=33364
2023-08-15 10:44:21 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.908, trans_loss=4.77, nll_loss=1.97, w2v_ctc_loss=0.629, task_loss=1.468, contrastive_loss=0.076, total=4112.44, n_correct=2832.95, ppl=3.92, accuracy=68.887, wps=11944.6, ups=1.45, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=13.5, wall=33433
2023-08-15 10:45:30 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.904, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.622, task_loss=1.326, contrastive_loss=0.085, total=4193.3, n_correct=2886.84, ppl=3.95, accuracy=68.844, wps=12091.9, ups=1.44, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=33502
2023-08-15 10:45:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 10:45:53 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.16 | nll_loss 2.416 | w2v_ctc_loss 1.326 | task_loss 4.636 | contrastive_loss 0.298 | total 4003.4 | n_correct 2686 | ppl 5.34 | accuracy 67.093 | uer 17.601 | wer 19.488 | raw_wer 19.488 | bleu 22.63 | wps 2249.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.63
2023-08-15 10:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-15 10:45:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-15 10:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-15 10:46:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.63) (writing took 51.65023431368172 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 10:47:57 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.942, trans_loss=4.786, nll_loss=1.991, w2v_ctc_loss=0.622, task_loss=1.403, contrastive_loss=0.42, total=4138.69, n_correct=2830.32, ppl=3.98, accuracy=68.387, wps=5663.3, ups=0.68, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=70, gb_free=13, wall=33648
2023-08-15 10:49:05 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.915, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.639, task_loss=1.448, contrastive_loss=0.074, total=4089.84, n_correct=2807.3, ppl=3.96, accuracy=68.641, wps=11859.4, ups=1.45, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=33717
2023-08-15 10:50:15 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.909, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.625, task_loss=1.462, contrastive_loss=0.083, total=4098.92, n_correct=2816.07, ppl=3.95, accuracy=68.703, wps=11792.2, ups=1.44, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=33787
2023-08-15 10:51:24 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.914, trans_loss=4.789, nll_loss=1.995, w2v_ctc_loss=0.634, task_loss=1.416, contrastive_loss=0.085, total=4180.1, n_correct=2866.28, ppl=3.99, accuracy=68.57, wps=12112, ups=1.45, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=33856
2023-08-15 10:52:34 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.922, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.626, task_loss=1.269, contrastive_loss=0.194, total=4191.62, n_correct=2871.37, ppl=4, accuracy=68.503, wps=12043, ups=1.44, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=33926
2023-08-15 10:53:43 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.907, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.626, task_loss=1.387, contrastive_loss=0.076, total=4088.91, n_correct=2810.06, ppl=3.96, accuracy=68.724, wps=11782.1, ups=1.44, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=33995
2023-08-15 10:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 10:54:54 | INFO | train_inner | epoch 028:    921 / 1474 loss=1.925, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.637, task_loss=1.452, contrastive_loss=0.138, total=4120.11, n_correct=2815.54, ppl=4, accuracy=68.337, wps=11605.2, ups=1.41, wpb=8240.2, bsz=300.2, num_updates=40700, lr=7.01e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=71, gb_free=16.6, wall=34066
2023-08-15 10:56:03 | INFO | train_inner | epoch 028:   1021 / 1474 loss=1.929, trans_loss=4.79, nll_loss=1.996, w2v_ctc_loss=0.638, task_loss=1.372, contrastive_loss=0.193, total=4174.98, n_correct=2855.94, ppl=3.99, accuracy=68.406, wps=12055.1, ups=1.44, wpb=8350, bsz=310.9, num_updates=40800, lr=7.0014e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=34135
2023-08-15 10:57:13 | INFO | train_inner | epoch 028:   1121 / 1474 loss=1.913, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.631, task_loss=1.346, contrastive_loss=0.097, total=4222.19, n_correct=2891.02, ppl=3.98, accuracy=68.472, wps=12048.6, ups=1.43, wpb=8444.4, bsz=321.5, num_updates=40900, lr=6.99284e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=34205
2023-08-15 10:58:22 | INFO | train_inner | epoch 028:   1221 / 1474 loss=1.908, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.621, task_loss=1.387, contrastive_loss=0.083, total=4104.72, n_correct=2817.58, ppl=3.98, accuracy=68.642, wps=11905.5, ups=1.45, wpb=8209.4, bsz=305.5, num_updates=41000, lr=6.9843e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=34274
2023-08-15 10:59:32 | INFO | train_inner | epoch 028:   1321 / 1474 loss=1.919, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.638, task_loss=1.558, contrastive_loss=0.1, total=4074.43, n_correct=2791.04, ppl=3.98, accuracy=68.501, wps=11670.7, ups=1.43, wpb=8148.9, bsz=282.9, num_updates=41100, lr=6.9758e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=34344
2023-08-15 11:00:42 | INFO | train_inner | epoch 028:   1421 / 1474 loss=1.917, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.629, task_loss=1.451, contrastive_loss=0.122, total=4156.52, n_correct=2848.66, ppl=3.97, accuracy=68.535, wps=11998.1, ups=1.44, wpb=8313, bsz=300.8, num_updates=41200, lr=6.96733e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=34413
2023-08-15 11:01:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
2023-08-15 11:01:42 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.156 | nll_loss 2.411 | w2v_ctc_loss 1.342 | task_loss 4.666 | contrastive_loss 0.293 | total 4003.4 | n_correct 2685.9 | ppl 5.32 | accuracy 67.09 | uer 17.116 | wer 18.955 | raw_wer 18.955 | bleu 22.42 | wps 2179.7 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 22.63
2023-08-15 11:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-08-15 11:01:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt
2023-08-15 11:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt
2023-08-15 11:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4200.pt (epoch 28 @ 41253 updates, score 22.42) (writing took 38.97503117285669 seconds)
2023-08-15 11:02:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-15 11:02:24 | INFO | train | epoch 028 | loss 1.916 | trans_loss 4.784 | nll_loss 1.989 | w2v_ctc_loss 0.63 | task_loss 1.404 | contrastive_loss 0.13 | total 4138.81 | n_correct 2839.23 | ppl 3.97 | accuracy 68.6 | wps 10395.8 | ups 1.26 | wpb 8277.6 | bsz 305.7 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 16.2 | wall 34516
2023-08-15 11:02:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:02:24 | INFO | fairseq.trainer | begin training epoch 29
2023-08-15 11:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:03:04 | INFO | train_inner | epoch 029:     47 / 1474 loss=1.908, trans_loss=4.774, nll_loss=1.978, w2v_ctc_loss=0.63, task_loss=1.361, contrastive_loss=0.098, total=4169.02, n_correct=2872.51, ppl=3.94, accuracy=68.901, wps=5849.1, ups=0.7, wpb=8338, bsz=315.1, num_updates=41300, lr=6.95889e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=34556
2023-08-15 11:04:14 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.911, trans_loss=4.776, nll_loss=1.978, w2v_ctc_loss=0.629, task_loss=1.398, contrastive_loss=0.114, total=4110.03, n_correct=2827.63, ppl=3.94, accuracy=68.798, wps=11749.5, ups=1.43, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=34626
2023-08-15 11:05:24 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.907, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.611, task_loss=1.277, contrastive_loss=0.194, total=4197.89, n_correct=2895.32, ppl=3.91, accuracy=68.971, wps=12053.7, ups=1.44, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=34696
2023-08-15 11:06:33 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.915, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.641, task_loss=1.507, contrastive_loss=0.079, total=4094.4, n_correct=2811.74, ppl=3.96, accuracy=68.673, wps=11779.7, ups=1.44, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=34765
2023-08-15 11:07:43 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.897, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.62, task_loss=1.344, contrastive_loss=0.074, total=4157.41, n_correct=2872.2, ppl=3.88, accuracy=69.086, wps=11964.7, ups=1.44, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=14.4, wall=34835
2023-08-15 11:08:53 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.924, trans_loss=4.785, nll_loss=1.99, w2v_ctc_loss=0.626, task_loss=1.506, contrastive_loss=0.171, total=4149.27, n_correct=2840.36, ppl=3.97, accuracy=68.454, wps=11868.5, ups=1.43, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=34905
2023-08-15 11:10:02 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.917, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.622, task_loss=1.326, contrastive_loss=0.237, total=4145.39, n_correct=2853.74, ppl=3.93, accuracy=68.841, wps=11874.1, ups=1.43, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=34974
2023-08-15 11:11:13 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.91, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.621, task_loss=1.294, contrastive_loss=0.158, total=4242.46, n_correct=2921.33, ppl=3.93, accuracy=68.859, wps=12078.6, ups=1.42, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=35045
2023-08-15 11:11:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:11:36 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.161 | nll_loss 2.418 | w2v_ctc_loss 1.333 | task_loss 4.614 | contrastive_loss 0.292 | total 4003.4 | n_correct 2686.1 | ppl 5.35 | accuracy 67.095 | uer 17.294 | wer 19.365 | raw_wer 19.365 | bleu 22.62 | wps 2245.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.63
2023-08-15 11:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-15 11:11:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-15 11:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-15 11:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.62) (writing took 42.68160405755043 seconds)
2023-08-15 11:13:28 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.912, trans_loss=4.788, nll_loss=1.993, w2v_ctc_loss=0.624, task_loss=1.559, contrastive_loss=0.072, total=4027.03, n_correct=2756.03, ppl=3.98, accuracy=68.438, wps=5936.3, ups=0.74, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=35180
2023-08-15 11:14:38 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.911, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.634, task_loss=1.436, contrastive_loss=0.081, total=4086.72, n_correct=2808.87, ppl=3.96, accuracy=68.732, wps=11810.3, ups=1.44, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=35250
2023-08-15 11:15:47 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.911, trans_loss=4.775, nll_loss=1.979, w2v_ctc_loss=0.619, task_loss=1.4, contrastive_loss=0.157, total=4139.4, n_correct=2845.16, ppl=3.94, accuracy=68.734, wps=11909.7, ups=1.44, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=35319
2023-08-15 11:16:56 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.915, trans_loss=4.788, nll_loss=1.994, w2v_ctc_loss=0.634, task_loss=1.533, contrastive_loss=0.07, total=4072.33, n_correct=2789.31, ppl=3.98, accuracy=68.494, wps=11793, ups=1.45, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35388
2023-08-15 11:18:06 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.91, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.63, task_loss=1.423, contrastive_loss=0.077, total=4160.52, n_correct=2857.2, ppl=3.97, accuracy=68.674, wps=11976.6, ups=1.44, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=35458
2023-08-15 11:19:15 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.909, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.618, task_loss=1.383, contrastive_loss=0.138, total=4168.02, n_correct=2867.65, ppl=3.93, accuracy=68.801, wps=11946.2, ups=1.43, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=35527
2023-08-15 11:20:25 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.911, trans_loss=4.771, nll_loss=1.974, w2v_ctc_loss=0.625, task_loss=1.371, contrastive_loss=0.173, total=4166.06, n_correct=2872.1, ppl=3.93, accuracy=68.94, wps=12008.7, ups=1.44, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35597
2023-08-15 11:20:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:21:06 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.153 | nll_loss 2.407 | w2v_ctc_loss 1.329 | task_loss 4.623 | contrastive_loss 0.293 | total 4003.4 | n_correct 2690.7 | ppl 5.3 | accuracy 67.21 | uer 16.792 | wer 18.75 | raw_wer 18.75 | bleu 22.45 | wps 2144.6 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.63
2023-08-15 11:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-15 11:21:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt
2023-08-15 11:21:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt
2023-08-15 11:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.4507.pt (epoch 29 @ 42727 updates, score 22.45) (writing took 40.345158483833075 seconds)
2023-08-15 11:21:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-15 11:21:47 | INFO | train | epoch 029 | loss 1.911 | trans_loss 4.776 | nll_loss 1.979 | w2v_ctc_loss 0.625 | task_loss 1.404 | contrastive_loss 0.128 | total 4138.65 | n_correct 2845.71 | ppl 3.94 | accuracy 68.759 | wps 10486.5 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 15.8 | wall 35679
2023-08-15 11:21:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:21:47 | INFO | fairseq.trainer | begin training epoch 30
2023-08-15 11:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:22:46 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.904, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.609, task_loss=1.337, contrastive_loss=0.187, total=4175.11, n_correct=2883.33, ppl=3.9, accuracy=69.06, wps=5935.1, ups=0.71, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=35737
2023-08-15 11:23:55 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.899, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.619, task_loss=1.312, contrastive_loss=0.117, total=4202.64, n_correct=2908.92, ppl=3.86, accuracy=69.216, wps=12086, ups=1.44, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=35807
2023-08-15 11:25:04 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.903, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.626, task_loss=1.451, contrastive_loss=0.071, total=4120.21, n_correct=2841.78, ppl=3.91, accuracy=68.972, wps=11906.9, ups=1.44, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15, wall=35876
2023-08-15 11:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 11:26:14 | INFO | train_inner | epoch 030:    374 / 1474 loss=1.892, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.611, task_loss=1.39, contrastive_loss=0.073, total=4180.19, n_correct=2893.31, ppl=3.88, accuracy=69.215, wps=11932.3, ups=1.43, wpb=8360.4, bsz=308.2, num_updates=43100, lr=6.81203e-05, gnorm=0.512, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=35946
2023-08-15 11:27:23 | INFO | train_inner | epoch 030:    474 / 1474 loss=1.902, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.61, task_loss=1.356, contrastive_loss=0.139, total=4121.08, n_correct=2843.12, ppl=3.91, accuracy=68.99, wps=12017.1, ups=1.46, wpb=8242.2, bsz=311.1, num_updates=43200, lr=6.80414e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=36015
2023-08-15 11:28:32 | INFO | train_inner | epoch 030:    574 / 1474 loss=1.902, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.621, task_loss=1.361, contrastive_loss=0.099, total=4162.58, n_correct=2869.03, ppl=3.91, accuracy=68.924, wps=11976.4, ups=1.44, wpb=8325.2, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=36084
2023-08-15 11:29:42 | INFO | train_inner | epoch 030:    674 / 1474 loss=1.91, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.63, task_loss=1.382, contrastive_loss=0.113, total=4192, n_correct=2881.88, ppl=3.92, accuracy=68.747, wps=12017.3, ups=1.43, wpb=8384, bsz=315.3, num_updates=43400, lr=6.78844e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=36154
2023-08-15 11:30:51 | INFO | train_inner | epoch 030:    774 / 1474 loss=1.921, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.633, task_loss=1.431, contrastive_loss=0.194, total=4103.26, n_correct=2817.3, ppl=3.94, accuracy=68.66, wps=11879.7, ups=1.45, wpb=8206.5, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=36223
2023-08-15 11:32:01 | INFO | train_inner | epoch 030:    874 / 1474 loss=1.908, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.627, task_loss=1.435, contrastive_loss=0.087, total=4111.51, n_correct=2830.68, ppl=3.93, accuracy=68.848, wps=11855.2, ups=1.44, wpb=8223, bsz=297.8, num_updates=43600, lr=6.77285e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=36293
2023-08-15 11:33:10 | INFO | train_inner | epoch 030:    974 / 1474 loss=1.91, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.631, task_loss=1.448, contrastive_loss=0.086, total=4125.95, n_correct=2832.46, ppl=3.95, accuracy=68.65, wps=11861.8, ups=1.44, wpb=8251.9, bsz=298.7, num_updates=43700, lr=6.7651e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=36362
2023-08-15 11:34:20 | INFO | train_inner | epoch 030:   1074 / 1474 loss=1.916, trans_loss=4.776, nll_loss=1.978, w2v_ctc_loss=0.621, task_loss=1.575, contrastive_loss=0.17, total=4096.17, n_correct=2814.1, ppl=3.94, accuracy=68.701, wps=11726.3, ups=1.43, wpb=8192.3, bsz=281.5, num_updates=43800, lr=6.75737e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=36432
2023-08-15 11:35:30 | INFO | train_inner | epoch 030:   1174 / 1474 loss=1.902, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.609, task_loss=1.345, contrastive_loss=0.145, total=4168.92, n_correct=2873.72, ppl=3.92, accuracy=68.932, wps=11992.5, ups=1.44, wpb=8337.8, bsz=314.8, num_updates=43900, lr=6.74967e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=36502
2023-08-15 11:36:39 | INFO | train_inner | epoch 030:   1274 / 1474 loss=1.909, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.631, task_loss=1.556, contrastive_loss=0.078, total=4038.68, n_correct=2777.63, ppl=3.94, accuracy=68.776, wps=11665.3, ups=1.44, wpb=8077.4, bsz=284.1, num_updates=44000, lr=6.742e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=36571
2023-08-15 11:36:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:37:03 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.158 | nll_loss 2.412 | w2v_ctc_loss 1.32 | task_loss 4.674 | contrastive_loss 0.297 | total 4003.4 | n_correct 2684.3 | ppl 5.32 | accuracy 67.051 | uer 17.118 | wer 18.981 | raw_wer 18.981 | bleu 22.7 | wps 2143 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.7
2023-08-15 11:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-15 11:37:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-15 11:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-15 11:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.7) (writing took 52.49361906014383 seconds)
2023-08-15 11:39:06 | INFO | train_inner | epoch 030:   1374 / 1474 loss=1.898, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.616, task_loss=1.321, contrastive_loss=0.089, total=4167.64, n_correct=2872.59, ppl=3.93, accuracy=68.926, wps=5684.7, ups=0.68, wpb=8335.3, bsz=321.9, num_updates=44100, lr=6.73435e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=36717
2023-08-15 11:40:15 | INFO | train_inner | epoch 030:   1474 / 1474 loss=1.913, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.609, task_loss=1.324, contrastive_loss=0.236, total=4117.91, n_correct=2828.63, ppl=3.94, accuracy=68.691, wps=11943, ups=1.45, wpb=8235.8, bsz=312.2, num_updates=44200, lr=6.72673e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=36786
2023-08-15 11:40:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 11:40:38 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.157 | nll_loss 2.412 | w2v_ctc_loss 1.293 | task_loss 4.616 | contrastive_loss 0.298 | total 4003.4 | n_correct 2685.1 | ppl 5.32 | accuracy 67.07 | uer 17.302 | wer 19.16 | raw_wer 19.16 | bleu 22.72 | wps 2175.5 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 22.72
2023-08-15 11:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-08-15 11:40:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 11:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 11:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 30 @ 44200 updates, score 22.72) (writing took 30.31017687357962 seconds)
2023-08-15 11:41:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-15 11:41:09 | INFO | train | epoch 030 | loss 1.906 | trans_loss 4.769 | nll_loss 1.97 | w2v_ctc_loss 0.62 | task_loss 1.402 | contrastive_loss 0.127 | total 4138.58 | n_correct 2850.98 | ppl 3.92 | accuracy 68.888 | wps 10495.7 | ups 1.27 | wpb 8277.2 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 16.9 | wall 36841
2023-08-15 11:41:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:41:09 | INFO | fairseq.trainer | begin training epoch 31
2023-08-15 11:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:42:27 | INFO | train_inner | epoch 031:    100 / 1474 loss=1.898, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.62, task_loss=1.478, contrastive_loss=0.081, total=4085.38, n_correct=2824.27, ppl=3.87, accuracy=69.131, wps=6181.4, ups=0.76, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=36919
2023-08-15 11:43:36 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.896, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.615, task_loss=1.449, contrastive_loss=0.092, total=4139.51, n_correct=2864.18, ppl=3.87, accuracy=69.191, wps=11943.5, ups=1.44, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=36988
2023-08-15 11:44:46 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.9, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.614, task_loss=1.437, contrastive_loss=0.142, total=4148.01, n_correct=2871.22, ppl=3.86, accuracy=69.219, wps=11876.9, ups=1.43, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=37058
2023-08-15 11:45:55 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.897, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.612, task_loss=1.531, contrastive_loss=0.076, total=4095.42, n_correct=2829.89, ppl=3.9, accuracy=69.099, wps=11800.4, ups=1.44, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=37127
2023-08-15 11:47:05 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.899, trans_loss=4.76, nll_loss=1.957, w2v_ctc_loss=0.619, task_loss=1.465, contrastive_loss=0.085, total=4115.61, n_correct=2840.69, ppl=3.88, accuracy=69.022, wps=11846.8, ups=1.44, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=37197
2023-08-15 11:48:14 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.897, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.617, task_loss=1.473, contrastive_loss=0.076, total=4075.9, n_correct=2818.53, ppl=3.88, accuracy=69.151, wps=11734.7, ups=1.44, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=37266
2023-08-15 11:49:24 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.89, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.61, task_loss=1.341, contrastive_loss=0.077, total=4208.99, n_correct=2917.27, ppl=3.86, accuracy=69.31, wps=12079.2, ups=1.43, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=37336
2023-08-15 11:50:34 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.905, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.613, task_loss=1.459, contrastive_loss=0.147, total=4104.19, n_correct=2830.7, ppl=3.9, accuracy=68.971, wps=11719.5, ups=1.43, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=15, wall=37406
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:0')
2023-08-15 11:51:43 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.898, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.619, task_loss=1.484, contrastive_loss=0.092, total=4099.13, n_correct=2833.03, ppl=3.86, accuracy=69.113, wps=11848.3, ups=1.45, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=37475
2023-08-15 11:52:52 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.906, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.613, task_loss=1.314, contrastive_loss=0.177, total=4186.81, n_correct=2888.3, ppl=3.92, accuracy=68.986, wps=12092.2, ups=1.44, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=37544
2023-08-15 11:54:02 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.9, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.612, task_loss=1.371, contrastive_loss=0.122, total=4149.25, n_correct=2865.86, ppl=3.9, accuracy=69.069, wps=12003, ups=1.45, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=37614
2023-08-15 11:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 11:55:11 | INFO | train_inner | epoch 031:   1201 / 1474 loss=1.905, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.607, task_loss=1.309, contrastive_loss=0.239, total=4185.5, n_correct=2892.98, ppl=3.89, accuracy=69.119, wps=11994.4, ups=1.43, wpb=8371, bsz=321, num_updates=45400, lr=6.63723e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=37683
2023-08-15 11:56:20 | INFO | train_inner | epoch 031:   1301 / 1474 loss=1.899, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.618, task_loss=1.267, contrastive_loss=0.082, total=4226.19, n_correct=2913.42, ppl=3.92, accuracy=68.937, wps=12259.8, ups=1.45, wpb=8452.4, bsz=325.1, num_updates=45500, lr=6.62994e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=37752
2023-08-15 11:57:30 | INFO | train_inner | epoch 031:   1401 / 1474 loss=1.919, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.614, task_loss=1.289, contrastive_loss=0.288, total=4192.11, n_correct=2892.21, ppl=3.91, accuracy=68.992, wps=12008.1, ups=1.43, wpb=8384.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=37822
2023-08-15 11:58:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2616, device='cuda:5')
2023-08-15 11:58:44 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.287 | task_loss 4.638 | contrastive_loss 0.293 | total 4003.4 | n_correct 2684.3 | ppl 5.34 | accuracy 67.051 | uer 16.866 | wer 18.899 | raw_wer 18.899 | bleu 22.58 | wps 2163.8 | wpb 4003.4 | bsz 141.8 | num_updates 45673 | best_bleu 22.72
2023-08-15 11:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-08-15 11:58:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt
2023-08-15 11:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt
2023-08-15 11:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint.best_bleu_22.5801.pt (epoch 31 @ 45673 updates, score 22.58) (writing took 24.710560154169798 seconds)
2023-08-15 11:59:09 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-15 11:59:09 | INFO | train | epoch 031 | loss 1.901 | trans_loss 4.761 | nll_loss 1.959 | w2v_ctc_loss 0.615 | task_loss 1.405 | contrastive_loss 0.126 | total 4138.41 | n_correct 2859.15 | ppl 3.89 | accuracy 69.088 | wps 11287.4 | ups 1.36 | wpb 8276.8 | bsz 305.6 | num_updates 45673 | lr 6.61737e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 11.7 | wall 37921
2023-08-15 11:59:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 11:59:09 | INFO | fairseq.trainer | begin training epoch 32
2023-08-15 11:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 11:59:36 | INFO | train_inner | epoch 032:     27 / 1474 loss=1.896, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.619, task_loss=1.463, contrastive_loss=0.072, total=4051.41, n_correct=2803.04, ppl=3.88, accuracy=69.187, wps=6447.7, ups=0.8, wpb=8102.8, bsz=291.6, num_updates=45700, lr=6.61541e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=37948
2023-08-15 12:00:45 | INFO | train_inner | epoch 032:    127 / 1474 loss=1.88, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.598, task_loss=1.316, contrastive_loss=0.082, total=4208.32, n_correct=2928.58, ppl=3.81, accuracy=69.59, wps=12144.5, ups=1.44, wpb=8416.6, bsz=319.1, num_updates=45800, lr=6.60819e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=11.2, wall=38017
2023-08-15 12:01:55 | INFO | train_inner | epoch 032:    227 / 1474 loss=1.891, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.612, task_loss=1.34, contrastive_loss=0.092, total=4157.86, n_correct=2880.16, ppl=3.87, accuracy=69.27, wps=11949, ups=1.44, wpb=8315.7, bsz=320.3, num_updates=45900, lr=6.60098e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=38087
2023-08-15 12:03:04 | INFO | train_inner | epoch 032:    327 / 1474 loss=1.883, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.6, task_loss=1.336, contrastive_loss=0.086, total=4179.17, n_correct=2908.12, ppl=3.82, accuracy=69.586, wps=12017.2, ups=1.44, wpb=8358.3, bsz=313.4, num_updates=46000, lr=6.5938e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=38156
2023-08-15 12:03:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:03:28 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.166 | nll_loss 2.423 | w2v_ctc_loss 1.345 | task_loss 4.631 | contrastive_loss 0.289 | total 4003.4 | n_correct 2684 | ppl 5.36 | accuracy 67.043 | uer 17.126 | wer 18.94 | raw_wer 18.94 | bleu 22.51 | wps 2140.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.72
2023-08-15 12:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-15 12:03:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 12:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 12:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.51) (writing took 39.458953980356455 seconds)
2023-08-15 12:05:22 | INFO | train_inner | epoch 032:    427 / 1474 loss=1.887, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.609, task_loss=1.359, contrastive_loss=0.082, total=4179.5, n_correct=2901.88, ppl=3.83, accuracy=69.431, wps=6073.7, ups=0.73, wpb=8359, bsz=312.2, num_updates=46100, lr=6.58665e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=17.5, wall=38294
2023-08-15 12:06:32 | INFO | train_inner | epoch 032:    527 / 1474 loss=1.904, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.615, task_loss=1.381, contrastive_loss=0.166, total=4188.83, n_correct=2895.28, ppl=3.87, accuracy=69.119, wps=12004.5, ups=1.43, wpb=8377.7, bsz=313.9, num_updates=46200, lr=6.57952e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=38364
2023-08-15 12:07:42 | INFO | train_inner | epoch 032:    627 / 1474 loss=1.898, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.617, task_loss=1.477, contrastive_loss=0.089, total=4133.19, n_correct=2855.47, ppl=3.88, accuracy=69.086, wps=11752.4, ups=1.42, wpb=8266.4, bsz=298.7, num_updates=46300, lr=6.57241e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=38434
2023-08-15 12:08:52 | INFO | train_inner | epoch 032:    727 / 1474 loss=1.895, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.618, task_loss=1.414, contrastive_loss=0.074, total=4162.1, n_correct=2879.7, ppl=3.87, accuracy=69.189, wps=11888.8, ups=1.43, wpb=8324.2, bsz=304.3, num_updates=46400, lr=6.56532e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=15.6, wall=38504
2023-08-15 12:10:02 | INFO | train_inner | epoch 032:    827 / 1474 loss=1.89, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.608, task_loss=1.463, contrastive_loss=0.071, total=4107.86, n_correct=2845.55, ppl=3.86, accuracy=69.271, wps=11786.7, ups=1.43, wpb=8215.7, bsz=292.6, num_updates=46500, lr=6.55826e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=38574
2023-08-15 12:11:11 | INFO | train_inner | epoch 032:    927 / 1474 loss=1.888, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.605, task_loss=1.436, contrastive_loss=0.069, total=4146.9, n_correct=2873.97, ppl=3.86, accuracy=69.304, wps=11975.4, ups=1.44, wpb=8293.8, bsz=300.4, num_updates=46600, lr=6.55122e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=38643
2023-08-15 12:12:20 | INFO | train_inner | epoch 032:   1027 / 1474 loss=1.903, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.616, task_loss=1.395, contrastive_loss=0.164, total=4112.45, n_correct=2842.91, ppl=3.88, accuracy=69.129, wps=11904.5, ups=1.45, wpb=8224.9, bsz=304.3, num_updates=46700, lr=6.5442e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=38712
2023-08-15 12:13:30 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.901, trans_loss=4.754, nll_loss=1.949, w2v_ctc_loss=0.616, task_loss=1.671, contrastive_loss=0.107, total=4015.2, n_correct=2774.52, ppl=3.86, accuracy=69.1, wps=11510.4, ups=1.43, wpb=8030.4, bsz=269.7, num_updates=46800, lr=6.5372e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=14.1, wall=38782
2023-08-15 12:14:40 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.914, trans_loss=4.766, nll_loss=1.967, w2v_ctc_loss=0.614, task_loss=1.376, contrastive_loss=0.218, total=4158.99, n_correct=2866.99, ppl=3.91, accuracy=68.935, wps=11888.3, ups=1.43, wpb=8318, bsz=312.1, num_updates=46900, lr=6.53023e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=38852
2023-08-15 12:15:48 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.894, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.617, task_loss=1.436, contrastive_loss=0.069, total=4079.56, n_correct=2820.04, ppl=3.87, accuracy=69.126, wps=11910.6, ups=1.46, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=38920
2023-08-15 12:16:57 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.919, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.623, task_loss=1.423, contrastive_loss=0.307, total=4107.37, n_correct=2834.63, ppl=3.89, accuracy=69.013, wps=11941.1, ups=1.45, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=38989
2023-08-15 12:17:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:17:53 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.154 | nll_loss 2.411 | w2v_ctc_loss 1.318 | task_loss 4.633 | contrastive_loss 0.293 | total 4003.4 | n_correct 2684.1 | ppl 5.32 | accuracy 67.046 | uer 17.033 | wer 18.922 | raw_wer 18.922 | bleu 22.82 | wps 2249.5 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 22.82
2023-08-15 12:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-08-15 12:17:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 12:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 12:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_best.pt (epoch 32 @ 47147 updates, score 22.82) (writing took 29.111364552751184 seconds)
2023-08-15 12:18:22 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-15 12:18:22 | INFO | train | epoch 032 | loss 1.896 | trans_loss 4.753 | nll_loss 1.949 | w2v_ctc_loss 0.611 | task_loss 1.405 | contrastive_loss 0.124 | total 4138.65 | n_correct 2865.38 | ppl 3.86 | accuracy 69.235 | wps 10578.3 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.533 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 16.2 | wall 39074
2023-08-15 12:18:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 12:18:23 | INFO | fairseq.trainer | begin training epoch 33
2023-08-15 12:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 12:19:08 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.895, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.6, task_loss=1.333, contrastive_loss=0.173, total=4146.91, n_correct=2875.88, ppl=3.85, accuracy=69.35, wps=6355.5, ups=0.77, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=39120
2023-08-15 12:20:17 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.882, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.596, task_loss=1.506, contrastive_loss=0.062, total=4073.36, n_correct=2829.57, ppl=3.81, accuracy=69.465, wps=11797.4, ups=1.45, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=39189
2023-08-15 12:21:26 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.898, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.601, task_loss=1.191, contrastive_loss=0.237, total=4283.64, n_correct=2978.45, ppl=3.82, accuracy=69.531, wps=12341.6, ups=1.44, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=39258
2023-08-15 12:22:35 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.892, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.612, task_loss=1.43, contrastive_loss=0.089, total=4131.27, n_correct=2861.58, ppl=3.84, accuracy=69.266, wps=11974.2, ups=1.45, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=39327
2023-08-15 12:23:44 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.873, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.592, task_loss=1.335, contrastive_loss=0.068, total=4135.1, n_correct=2883.86, ppl=3.79, accuracy=69.741, wps=12012.8, ups=1.45, wpb=8270.2, bsz=309.7, num_updates=47600, lr=6.48204e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=39396
2023-08-15 12:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 12:24:54 | INFO | train_inner | epoch 033:    554 / 1474 loss=1.896, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.615, task_loss=1.458, contrastive_loss=0.092, total=4131.65, n_correct=2860.47, ppl=3.85, accuracy=69.233, wps=11774.9, ups=1.42, wpb=8263.3, bsz=294.4, num_updates=47700, lr=6.47524e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=14.6, wall=39466
2023-08-15 12:26:03 | INFO | train_inner | epoch 033:    654 / 1474 loss=1.895, trans_loss=4.756, nll_loss=1.951, w2v_ctc_loss=0.604, task_loss=1.447, contrastive_loss=0.124, total=4155.56, n_correct=2875.7, ppl=3.87, accuracy=69.201, wps=12000.9, ups=1.44, wpb=8311.1, bsz=300.4, num_updates=47800, lr=6.46846e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=39535
2023-08-15 12:27:12 | INFO | train_inner | epoch 033:    754 / 1474 loss=1.897, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.623, task_loss=1.505, contrastive_loss=0.07, total=4076.72, n_correct=2820.01, ppl=3.86, accuracy=69.174, wps=11852, ups=1.45, wpb=8153.4, bsz=289.6, num_updates=47900, lr=6.46171e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=39604
2023-08-15 12:28:22 | INFO | train_inner | epoch 033:    854 / 1474 loss=1.883, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.594, task_loss=1.347, contrastive_loss=0.14, total=4126.23, n_correct=2871.83, ppl=3.82, accuracy=69.599, wps=11875.8, ups=1.44, wpb=8252.5, bsz=314.4, num_updates=48000, lr=6.45497e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=39674
2023-08-15 12:28:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:28:45 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.332 | task_loss 4.628 | contrastive_loss 0.298 | total 4003.4 | n_correct 2681.3 | ppl 5.34 | accuracy 66.976 | uer 17.158 | wer 19.037 | raw_wer 19.037 | bleu 22.18 | wps 2201.9 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.82
2023-08-15 12:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-15 12:28:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 12:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 12:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.18) (writing took 21.901326628401875 seconds)
2023-08-15 12:30:17 | INFO | train_inner | epoch 033:    954 / 1474 loss=1.891, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.614, task_loss=1.383, contrastive_loss=0.084, total=4161.72, n_correct=2885.19, ppl=3.85, accuracy=69.327, wps=7218, ups=0.87, wpb=8323.4, bsz=312, num_updates=48100, lr=6.44826e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=39789
2023-08-15 12:31:27 | INFO | train_inner | epoch 033:   1054 / 1474 loss=1.897, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.607, task_loss=1.421, contrastive_loss=0.182, total=4134.8, n_correct=2868.27, ppl=3.82, accuracy=69.369, wps=11853.8, ups=1.43, wpb=8269.6, bsz=304.7, num_updates=48200, lr=6.44157e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=39859
2023-08-15 12:32:37 | INFO | train_inner | epoch 033:   1154 / 1474 loss=1.896, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.598, task_loss=1.414, contrastive_loss=0.174, total=4177.62, n_correct=2895.01, ppl=3.87, accuracy=69.298, wps=11989.9, ups=1.44, wpb=8355.2, bsz=309.6, num_updates=48300, lr=6.43489e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=39928
2023-08-15 12:33:46 | INFO | train_inner | epoch 033:   1254 / 1474 loss=1.887, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.609, task_loss=1.471, contrastive_loss=0.074, total=4115.15, n_correct=2859.72, ppl=3.83, accuracy=69.492, wps=11792.4, ups=1.43, wpb=8230.3, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=39998
2023-08-15 12:34:56 | INFO | train_inner | epoch 033:   1354 / 1474 loss=1.887, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.607, task_loss=1.38, contrastive_loss=0.092, total=4121.6, n_correct=2863.35, ppl=3.84, accuracy=69.472, wps=11774.2, ups=1.43, wpb=8243.2, bsz=311.7, num_updates=48500, lr=6.42161e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=40068
2023-08-15 12:35:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-15 12:36:06 | INFO | train_inner | epoch 033:   1455 / 1474 loss=1.899, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.6, task_loss=1.384, contrastive_loss=0.24, total=4136.35, n_correct=2864.88, ppl=3.85, accuracy=69.261, wps=11834.7, ups=1.43, wpb=8272.7, bsz=311, num_updates=48600, lr=6.415e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=40138
2023-08-15 12:36:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:36:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.16 | nll_loss 2.414 | w2v_ctc_loss 1.352 | task_loss 4.628 | contrastive_loss 0.289 | total 4003.4 | n_correct 2687.7 | ppl 5.33 | accuracy 67.135 | uer 16.887 | wer 18.802 | raw_wer 18.802 | bleu 22.4 | wps 2231.5 | wpb 4003.4 | bsz 141.8 | num_updates 48619 | best_bleu 22.82
2023-08-15 12:36:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48619 updates
2023-08-15 12:36:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 12:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 12:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48619 updates, score 22.4) (writing took 16.58786521665752 seconds)
2023-08-15 12:36:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-15 12:36:59 | INFO | train | epoch 033 | loss 1.891 | trans_loss 4.746 | nll_loss 1.94 | w2v_ctc_loss 0.605 | task_loss 1.403 | contrastive_loss 0.123 | total 4138.82 | n_correct 2872 | ppl 3.84 | accuracy 69.392 | wps 10914.8 | ups 1.32 | wpb 8277.6 | bsz 305.8 | num_updates 48619 | lr 6.41375e-05 | gnorm 0.533 | clip 0 | loss_scale 8 | train_wall 1015 | gb_free 17.6 | wall 40191
2023-08-15 12:36:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 12:36:59 | INFO | fairseq.trainer | begin training epoch 34
2023-08-15 12:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 12:38:04 | INFO | train_inner | epoch 034:     81 / 1474 loss=1.881, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.602, task_loss=1.407, contrastive_loss=0.075, total=4113.07, n_correct=2863.75, ppl=3.8, accuracy=69.626, wps=7011.3, ups=0.85, wpb=8226.1, bsz=298.8, num_updates=48700, lr=6.40841e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=40256
2023-08-15 12:39:13 | INFO | train_inner | epoch 034:    181 / 1474 loss=1.876, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.599, task_loss=1.466, contrastive_loss=0.075, total=4069.22, n_correct=2841.8, ppl=3.77, accuracy=69.836, wps=11694.3, ups=1.44, wpb=8138.4, bsz=295.5, num_updates=48800, lr=6.40184e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=12.3, wall=40325
2023-08-15 12:40:23 | INFO | train_inner | epoch 034:    281 / 1474 loss=1.903, trans_loss=4.746, nll_loss=1.939, w2v_ctc_loss=0.595, task_loss=1.302, contrastive_loss=0.285, total=4252.78, n_correct=2954.88, ppl=3.84, accuracy=69.481, wps=12168.4, ups=1.43, wpb=8505.6, bsz=331.2, num_updates=48900, lr=6.39529e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=40395
2023-08-15 12:41:32 | INFO | train_inner | epoch 034:    381 / 1474 loss=1.885, trans_loss=4.728, nll_loss=1.918, w2v_ctc_loss=0.595, task_loss=1.341, contrastive_loss=0.179, total=4151.69, n_correct=2895.11, ppl=3.78, accuracy=69.733, wps=12041.1, ups=1.45, wpb=8303.4, bsz=316.4, num_updates=49000, lr=6.38877e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=68, gb_free=15.6, wall=40464
2023-08-15 12:42:42 | INFO | train_inner | epoch 034:    481 / 1474 loss=1.886, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.608, task_loss=1.53, contrastive_loss=0.068, total=4078.14, n_correct=2835.3, ppl=3.81, accuracy=69.524, wps=11726, ups=1.44, wpb=8156.3, bsz=284.7, num_updates=49100, lr=6.38226e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=40534
2023-08-15 12:43:51 | INFO | train_inner | epoch 034:    581 / 1474 loss=1.875, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.594, task_loss=1.409, contrastive_loss=0.071, total=4130.95, n_correct=2885.43, ppl=3.78, accuracy=69.849, wps=11961.9, ups=1.45, wpb=8261.9, bsz=302, num_updates=49200, lr=6.37577e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=69, gb_free=17.3, wall=40603
2023-08-15 12:45:00 | INFO | train_inner | epoch 034:    681 / 1474 loss=1.881, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.601, task_loss=1.447, contrastive_loss=0.067, total=4110.04, n_correct=2857.74, ppl=3.81, accuracy=69.531, wps=11933.2, ups=1.45, wpb=8220.1, bsz=296.9, num_updates=49300, lr=6.3693e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=40672
2023-08-15 12:46:08 | INFO | train_inner | epoch 034:    781 / 1474 loss=1.893, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.598, task_loss=1.463, contrastive_loss=0.135, total=4079.01, n_correct=2826.77, ppl=3.87, accuracy=69.3, wps=11863.6, ups=1.45, wpb=8158, bsz=295.7, num_updates=49400, lr=6.36285e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=40740
2023-08-15 12:47:18 | INFO | train_inner | epoch 034:    881 / 1474 loss=1.888, trans_loss=4.744, nll_loss=1.937, w2v_ctc_loss=0.606, task_loss=1.487, contrastive_loss=0.094, total=4092.48, n_correct=2841.77, ppl=3.83, accuracy=69.439, wps=11730, ups=1.43, wpb=8185, bsz=295.5, num_updates=49500, lr=6.35642e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=40810
2023-08-15 12:48:28 | INFO | train_inner | epoch 034:    981 / 1474 loss=1.887, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.608, task_loss=1.363, contrastive_loss=0.09, total=4185.89, n_correct=2907.72, ppl=3.83, accuracy=69.465, wps=11943, ups=1.43, wpb=8371.8, bsz=315, num_updates=49600, lr=6.35001e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=40880
2023-08-15 12:49:37 | INFO | train_inner | epoch 034:   1081 / 1474 loss=1.882, trans_loss=4.74, nll_loss=1.931, w2v_ctc_loss=0.606, task_loss=1.368, contrastive_loss=0.071, total=4142.31, n_correct=2881.8, ppl=3.81, accuracy=69.57, wps=12005.4, ups=1.45, wpb=8284.6, bsz=306.1, num_updates=49700, lr=6.34361e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=69, gb_free=17.6, wall=40949
2023-08-15 12:50:46 | INFO | train_inner | epoch 034:   1181 / 1474 loss=1.885, trans_loss=4.742, nll_loss=1.934, w2v_ctc_loss=0.603, task_loss=1.445, contrastive_loss=0.085, total=4101.07, n_correct=2849.57, ppl=3.82, accuracy=69.484, wps=11884.4, ups=1.45, wpb=8202.1, bsz=297.9, num_updates=49800, lr=6.33724e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=69, gb_free=14.5, wall=41018
2023-08-15 12:51:55 | INFO | train_inner | epoch 034:   1281 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.605, task_loss=1.416, contrastive_loss=0.069, total=4150.75, n_correct=2888.79, ppl=3.8, accuracy=69.597, wps=12043.7, ups=1.45, wpb=8301.5, bsz=301.4, num_updates=49900, lr=6.33089e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=41087
2023-08-15 12:53:05 | INFO | train_inner | epoch 034:   1381 / 1474 loss=1.895, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.612, task_loss=1.345, contrastive_loss=0.136, total=4194.17, n_correct=2906.59, ppl=3.84, accuracy=69.301, wps=11972.8, ups=1.43, wpb=8388.3, bsz=320.1, num_updates=50000, lr=6.32456e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=70, gb_free=15.5, wall=41157
2023-08-15 12:53:05 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-15 12:53:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 12:53:28 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.156 | nll_loss 2.408 | w2v_ctc_loss 1.322 | task_loss 4.63 | contrastive_loss 0.284 | total 4003.4 | n_correct 2687.4 | ppl 5.31 | accuracy 67.128 | uer 16.699 | wer 18.463 | raw_wer 18.463 | bleu 22.67 | wps 2242.5 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.82
2023-08-15 12:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-15 12:53:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 12:53:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 12:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_global_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.67) (writing took 40.37162771075964 seconds)
2023-08-15 12:54:10 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-15 12:54:10 | INFO | train | epoch 034 | loss 1.886 | trans_loss 4.739 | nll_loss 1.931 | w2v_ctc_loss 0.602 | task_loss 1.412 | contrastive_loss 0.11 | total 4132.8 | n_correct 2874.54 | ppl 3.81 | accuracy 69.554 | wps 11069.8 | ups 1.34 | wpb 8265.6 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.537 | clip 0 | loss_scale 8 | train_wall 951 | gb_free 15.5 | wall 41222
2023-08-15 12:54:10 | INFO | fairseq_cli.train | done training in 41170.4 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
stage 1: ST Network Training
dev=0,1,2,3,4,5,6,7 data=data_all_ende_lcrm model=./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py data_all_ende_lcrm --config-yaml config_st.yaml --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml --task joint_triple_pretraining_merge --max-tokens 15000 --skip-invalid-size-inputs-valid-test --update-freq 1 --log-interval 100 --save-dir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad --distributed-world-size 8 --ddp-backend no_c10d --fp16 --eval-bleu --eval-tokenized-bleu --eval-bleu-remove-bpe sentencepiece --best-checkpoint-metric bleu --keep-best-checkpoints 10 --maximize-best-checkpoint-metric
[34mRun command: 
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py
        data_all_ende_lcrm
        --config-yaml config_st.yaml
        --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml
        --task joint_triple_pretraining_merge
        --max-tokens 15000
        --skip-invalid-size-inputs-valid-test
        --update-freq 1
        --log-interval 100
        --save-dir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad
        --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad
        
        --distributed-world-size 8
        --ddp-backend no_c10d
        --fp16
        --eval-bleu
        --eval-tokenized-bleu
        --eval-bleu-remove-bpe sentencepiece
        --best-checkpoint-metric bleu
        --keep-best-checkpoints 10
        --maximize-best-checkpoint-metric
        --no-epoch-checkpoints
        --validate-interval 1 
        --save-interval 1 
        --keep-last-epochs 2 
        --save-interval-updates 2000
        --keep-interval-updates 5
        --share-decoder-input-output-embed
        --use-w2v-ctc [0m
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-16 03:44:59 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14074
2023-08-16 03:44:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-16 03:45:00 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 03:45:00 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-16 03:45:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14074', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-16 03:45:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-16 03:45:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-16 03:45:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-16 03:45:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-16 03:45:04 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-16 03:45:09 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-16 03:45:09 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-16 03:45:09 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-16 03:45:11 | INFO | root | load pretrained hubert
2023-08-16 03:45:14 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-16 03:45:15 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-16 03:45:20 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-16 03:45:20 | INFO | root | share the sematic adapter and textual encoder
2023-08-16 03:45:20 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-16 03:45:20 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-16 03:45:20 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-16 03:45:20 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-16 03:45:20 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-16 03:45:20 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-16 03:45:20 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-16 03:45:20 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 03:45:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 03:45:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 03:45:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-16 03:45:24 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-16 03:45:24 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-16 03:45:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 03:45:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-16 03:45:25 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-16 03:45:25 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-16 03:45:25 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt
2023-08-16 03:45:25 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt
2023-08-16 03:45:25 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-16 03:45:25 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-16 03:45:25 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 03:45:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 03:45:27 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 03:45:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 03:46:15 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-16 03:46:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 03:46:15 | INFO | fairseq.trainer | begin training epoch 1
2023-08-16 03:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 03:46:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-16 03:46:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 03:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 03:46:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-16 03:47:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-16 03:47:40 | INFO | train_inner | epoch 001:    105 / 1474 loss=20.038, trans_loss=5.872, nll_loss=4.68, w2v_ctc_loss=22.309, task_loss=4.185, contrastive_loss=3.274, total=4218.67, n_correct=125.81, ppl=25.64, accuracy=2.982, wps=18335.3, ups=1.46, wpb=12587.1, bsz=476.8, num_updates=100, lr=4.098e-06, gnorm=2.872, clip=0, loss_scale=4, train_wall=76, gb_free=19.4, wall=135
2023-08-16 03:48:47 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.623, trans_loss=5.867, nll_loss=4.7, w2v_ctc_loss=17.119, task_loss=4.088, contrastive_loss=3.237, total=4114.86, n_correct=114.55, ppl=26, accuracy=2.784, wps=18539.1, ups=1.51, wpb=12286.8, bsz=458.8, num_updates=200, lr=8.096e-06, gnorm=7.233, clip=16, loss_scale=4, train_wall=66, gb_free=19.4, wall=202
2023-08-16 03:49:51 | INFO | train_inner | epoch 001:    305 / 1474 loss=9.929, trans_loss=5.852, nll_loss=4.719, w2v_ctc_loss=6.893, task_loss=3.982, contrastive_loss=3.176, total=4080.91, n_correct=107.81, ppl=26.34, accuracy=2.642, wps=18819.8, ups=1.54, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.264, clip=0, loss_scale=4, train_wall=64, gb_free=18.6, wall=267
2023-08-16 03:50:57 | INFO | train_inner | epoch 001:    405 / 1474 loss=9.409, trans_loss=5.792, nll_loss=4.675, w2v_ctc_loss=6.116, task_loss=3.413, contrastive_loss=3.208, total=4176.41, n_correct=98.39, ppl=25.55, accuracy=2.356, wps=19022, ups=1.53, wpb=12470, bsz=461.3, num_updates=400, lr=1.6092e-05, gnorm=1.394, clip=1, loss_scale=4, train_wall=65, gb_free=19.5, wall=332
2023-08-16 03:52:03 | INFO | train_inner | epoch 001:    505 / 1474 loss=9.224, trans_loss=5.747, nll_loss=4.639, w2v_ctc_loss=5.818, task_loss=3.062, contrastive_loss=3.306, total=4192.13, n_correct=93.78, ppl=24.91, accuracy=2.237, wps=19098.5, ups=1.52, wpb=12526, bsz=489.2, num_updates=500, lr=2.009e-05, gnorm=1.326, clip=0, loss_scale=4, train_wall=65, gb_free=19.1, wall=398
2023-08-16 03:53:09 | INFO | train_inner | epoch 001:    605 / 1474 loss=9.116, trans_loss=5.794, nll_loss=4.701, w2v_ctc_loss=5.661, task_loss=2.992, contrastive_loss=3.255, total=4131.49, n_correct=89.35, ppl=26, accuracy=2.163, wps=18635.6, ups=1.51, wpb=12320.8, bsz=473.5, num_updates=600, lr=2.4088e-05, gnorm=1.016, clip=0, loss_scale=4, train_wall=66, gb_free=18.9, wall=464
2023-08-16 03:54:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-16 03:54:14 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.012, trans_loss=5.766, nll_loss=4.666, w2v_ctc_loss=5.598, task_loss=3.144, contrastive_loss=3.135, total=4141.41, n_correct=88.54, ppl=25.38, accuracy=2.138, wps=18930.2, ups=1.53, wpb=12368.7, bsz=453.2, num_updates=700, lr=2.8086e-05, gnorm=1.424, clip=0, loss_scale=2, train_wall=65, gb_free=19.5, wall=529
2023-08-16 03:55:19 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.957, trans_loss=5.906, nll_loss=4.841, w2v_ctc_loss=5.418, task_loss=3.036, contrastive_loss=3.152, total=4129.2, n_correct=77.03, ppl=28.66, accuracy=1.865, wps=19073.2, ups=1.55, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.477, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=594
2023-08-16 03:56:24 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.847, trans_loss=5.983, nll_loss=4.93, w2v_ctc_loss=5.234, task_loss=3.084, contrastive_loss=3.06, total=4167.97, n_correct=59.23, ppl=30.49, accuracy=1.421, wps=19142.2, ups=1.54, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.829, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=659
2023-08-16 03:57:30 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.761, trans_loss=6.134, nll_loss=5.122, w2v_ctc_loss=4.983, task_loss=3.084, contrastive_loss=3.054, total=4137.5, n_correct=42.81, ppl=34.83, accuracy=1.035, wps=18719.7, ups=1.51, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.77, clip=0, loss_scale=2, train_wall=65, gb_free=19.3, wall=725
2023-08-16 03:58:35 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.564, trans_loss=6.168, nll_loss=5.156, w2v_ctc_loss=4.764, task_loss=3.171, contrastive_loss=2.962, total=4151.84, n_correct=36.75, ppl=35.65, accuracy=0.885, wps=18992.9, ups=1.53, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=2.021, clip=1, loss_scale=2, train_wall=65, gb_free=18.8, wall=790
2023-08-16 03:59:40 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.379, trans_loss=6.174, nll_loss=5.164, w2v_ctc_loss=4.586, task_loss=3.305, contrastive_loss=2.854, total=4123.25, n_correct=38, ppl=35.86, accuracy=0.922, wps=19028.1, ups=1.54, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.192, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=855
2023-08-16 04:00:44 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.223, trans_loss=6.169, nll_loss=5.157, w2v_ctc_loss=4.401, task_loss=3.111, contrastive_loss=2.807, total=4066.16, n_correct=46.61, ppl=35.68, accuracy=1.146, wps=18888.7, ups=1.56, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.544, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=919
2023-08-16 04:01:49 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8.077, trans_loss=6.15, nll_loss=5.137, w2v_ctc_loss=4.248, task_loss=3.163, contrastive_loss=2.881, total=4119.98, n_correct=50.7, ppl=35.18, accuracy=1.231, wps=18817.9, ups=1.53, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.594, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=984
2023-08-16 04:02:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 04:03:15 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.601 | trans_loss 14.008 | nll_loss 13.887 | w2v_ctc_loss 5.527 | task_loss 18.539 | contrastive_loss 4.121 | total 4003.4 | n_correct 25.6 | ppl 15150.8 | accuracy 0.639 | uer 71.133 | wer 69.345 | raw_wer 69.345 | bleu 0 | wps 1141.1 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-16 04:03:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-16 04:03:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:03:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.898658061400056 seconds)
2023-08-16 04:03:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-16 04:03:22 | INFO | train | epoch 001 | loss 10.136 | trans_loss 5.965 | nll_loss 4.891 | w2v_ctc_loss 7.236 | task_loss 3.327 | contrastive_loss 3.089 | total 4139.17 | n_correct 74.876 | ppl 29.66 | accuracy 1.809 | wps 17960.5 | ups 1.45 | wpb 12357.5 | bsz 458.9 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.293 | clip 1.2 | loss_scale 2 | train_wall 962 | gb_free 18.9 | wall 1077
2023-08-16 04:03:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 04:03:22 | INFO | fairseq.trainer | begin training epoch 2
2023-08-16 04:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 04:03:51 | INFO | train_inner | epoch 002:     32 / 1474 loss=8.004, trans_loss=6.191, nll_loss=5.186, w2v_ctc_loss=4.097, task_loss=2.991, contrastive_loss=2.863, total=4165.61, n_correct=42.44, ppl=36.41, accuracy=1.019, wps=10200, ups=0.82, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.512, clip=0, loss_scale=2, train_wall=66, gb_free=18.7, wall=1106
2023-08-16 04:04:56 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.87, trans_loss=6.188, nll_loss=5.184, w2v_ctc_loss=4.004, task_loss=3.132, contrastive_loss=2.721, total=4153.7, n_correct=42.45, ppl=36.35, accuracy=1.022, wps=19168.7, ups=1.55, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.648, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1171
2023-08-16 04:06:00 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.759, trans_loss=6.167, nll_loss=5.16, w2v_ctc_loss=3.843, task_loss=2.726, contrastive_loss=2.777, total=4201.44, n_correct=47.6, ppl=35.76, accuracy=1.133, wps=19469.3, ups=1.55, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.495, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1235
2023-08-16 04:07:05 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.566, trans_loss=6.149, nll_loss=5.138, w2v_ctc_loss=3.788, task_loss=3.191, contrastive_loss=2.541, total=4130.13, n_correct=49.29, ppl=35.22, accuracy=1.193, wps=19050.5, ups=1.55, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.633, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1300
2023-08-16 04:08:10 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.412, trans_loss=6.134, nll_loss=5.122, w2v_ctc_loss=3.724, task_loss=3.505, contrastive_loss=2.351, total=4035.12, n_correct=48.91, ppl=34.83, accuracy=1.212, wps=18592.1, ups=1.54, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.499, clip=0, loss_scale=2, train_wall=64, gb_free=19, wall=1365
2023-08-16 04:09:15 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.347, trans_loss=6.12, nll_loss=5.101, w2v_ctc_loss=3.584, task_loss=3.024, contrastive_loss=2.503, total=4183.09, n_correct=54.89, ppl=34.31, accuracy=1.312, wps=19109.7, ups=1.53, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.595, clip=0, loss_scale=2, train_wall=65, gb_free=18.5, wall=1430
2023-08-16 04:09:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 04:09:56 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.841 | trans_loss 13.595 | nll_loss 13.356 | w2v_ctc_loss 4.661 | task_loss 18.539 | contrastive_loss 3.562 | total 4003.4 | n_correct 48.8 | ppl 10487.4 | accuracy 1.219 | uer 62.711 | wer 60.859 | raw_wer 60.859 | bleu 0 | wps 1130.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-16 04:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-16 04:09:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_2_2000.pt
2023-08-16 04:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_2_2000.pt
2023-08-16 04:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 30.340473609045148 seconds)
2023-08-16 04:11:30 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.205, trans_loss=6.111, nll_loss=5.089, w2v_ctc_loss=3.492, task_loss=3.107, contrastive_loss=2.323, total=4123.85, n_correct=53.24, ppl=34.03, accuracy=1.291, wps=9103.6, ups=0.74, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.528, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1565
2023-08-16 04:12:35 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.127, trans_loss=6.099, nll_loss=5.075, w2v_ctc_loss=3.427, task_loss=3.073, contrastive_loss=2.391, total=4148.13, n_correct=57.45, ppl=33.71, accuracy=1.385, wps=19194.6, ups=1.55, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.558, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1630
2023-08-16 04:13:40 | INFO | train_inner | epoch 002:    832 / 1474 loss=7.032, trans_loss=6.083, nll_loss=5.057, w2v_ctc_loss=3.374, task_loss=3.108, contrastive_loss=2.341, total=4172.27, n_correct=60.55, ppl=33.29, accuracy=1.451, wps=19180.5, ups=1.54, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.378, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=1695
2023-08-16 04:14:45 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.897, trans_loss=6.076, nll_loss=5.043, w2v_ctc_loss=3.288, task_loss=3.254, contrastive_loss=2.262, total=4101.67, n_correct=56.26, ppl=32.97, accuracy=1.372, wps=18728, ups=1.53, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.425, clip=0, loss_scale=2, train_wall=65, gb_free=18.9, wall=1760
2023-08-16 04:15:50 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.808, trans_loss=6.073, nll_loss=5.039, w2v_ctc_loss=3.223, task_loss=3.161, contrastive_loss=2.153, total=4091.09, n_correct=58.94, ppl=32.87, accuracy=1.441, wps=18835.9, ups=1.54, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.25, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1825
2023-08-16 04:16:55 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.763, trans_loss=6.054, nll_loss=5.016, w2v_ctc_loss=3.123, task_loss=2.739, contrastive_loss=2.368, total=4219.19, n_correct=64.33, ppl=32.36, accuracy=1.525, wps=19366.1, ups=1.54, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.09, clip=0, loss_scale=2, train_wall=65, gb_free=19, wall=1890
2023-08-16 04:18:00 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.656, trans_loss=6.042, nll_loss=5, w2v_ctc_loss=3.089, task_loss=2.891, contrastive_loss=2.175, total=4212.91, n_correct=65.97, ppl=32, accuracy=1.566, wps=19277.3, ups=1.53, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.077, clip=0, loss_scale=2, train_wall=65, gb_free=19.1, wall=1955
2023-08-16 04:19:05 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.548, trans_loss=6.034, nll_loss=4.993, w2v_ctc_loss=3.051, task_loss=3.038, contrastive_loss=1.959, total=4142.48, n_correct=65.83, ppl=31.84, accuracy=1.589, wps=19083.9, ups=1.54, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.114, clip=0, loss_scale=4, train_wall=64, gb_free=18.9, wall=2020
2023-08-16 04:20:10 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.454, trans_loss=6.026, nll_loss=4.98, w2v_ctc_loss=3.004, task_loss=3.311, contrastive_loss=2.018, total=4063.28, n_correct=63.56, ppl=31.57, accuracy=1.564, wps=18651.5, ups=1.54, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=2.097, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2085
2023-08-16 04:20:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 04:21:18 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.94 | trans_loss 13.133 | nll_loss 12.749 | w2v_ctc_loss 3.81 | task_loss 18.538 | contrastive_loss 2.703 | total 4003.4 | n_correct 80.1 | ppl 6883.48 | accuracy 2.001 | uer 53.402 | wer 52.731 | raw_wer 52.731 | bleu 0 | wps 1096.4 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-16 04:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-16 04:21:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:21:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 31.801117369905114 seconds)
2023-08-16 04:21:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-16 04:21:50 | INFO | train | epoch 002 | loss 7.102 | trans_loss 6.097 | nll_loss 5.072 | w2v_ctc_loss 3.431 | task_loss 3.084 | contrastive_loss 2.348 | total 4138.65 | n_correct 56.2883 | ppl 33.63 | accuracy 1.36 | wps 16434.1 | ups 1.33 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.374 | clip 0 | loss_scale 4 | train_wall 948 | gb_free 19 | wall 2185
2023-08-16 04:21:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 04:21:50 | INFO | fairseq.trainer | begin training epoch 3
2023-08-16 04:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 04:22:36 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.351, trans_loss=6.013, nll_loss=4.964, w2v_ctc_loss=2.952, task_loss=3.25, contrastive_loss=1.864, total=4048.67, n_correct=67.21, ppl=31.22, accuracy=1.66, wps=8286.8, ups=0.69, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.878, clip=0, loss_scale=4, train_wall=64, gb_free=18.8, wall=2231
2023-08-16 04:22:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-16 04:24:09 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.7, trans_loss=5.35, nll_loss=4.127, w2v_ctc_loss=2.707, task_loss=2.118, contrastive_loss=1.803, total=4157.08, n_correct=241.92, ppl=17.47, accuracy=5.819, wps=13395.9, ups=1.08, wpb=12413.1, bsz=461.9, num_updates=3100, lr=0.000124038, gnorm=3.979, clip=4, loss_scale=2, train_wall=92, gb_free=16.2, wall=2324
2023-08-16 04:24:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-16 04:25:43 | INFO | train_inner | epoch 003:    260 / 1474 loss=5.026, trans_loss=4.907, nll_loss=3.544, w2v_ctc_loss=2.46, task_loss=2.161, contrastive_loss=1.598, total=4161, n_correct=555.12, ppl=11.66, accuracy=13.341, wps=13154, ups=1.06, wpb=12431.2, bsz=469.1, num_updates=3200, lr=0.000128036, gnorm=4.33, clip=3, loss_scale=1, train_wall=94, gb_free=15.4, wall=2418
2023-08-16 04:27:16 | INFO | train_inner | epoch 003:    360 / 1474 loss=4.579, trans_loss=4.4, nll_loss=2.867, w2v_ctc_loss=2.415, task_loss=2.138, contrastive_loss=1.569, total=4159.93, n_correct=1059.27, ppl=7.3, accuracy=25.464, wps=13353.2, ups=1.08, wpb=12413.4, bsz=467.3, num_updates=3300, lr=0.000132034, gnorm=3.679, clip=3, loss_scale=1, train_wall=92, gb_free=15.8, wall=2511
2023-08-16 04:28:49 | INFO | train_inner | epoch 003:    460 / 1474 loss=4.313, trans_loss=4.23, nll_loss=2.648, w2v_ctc_loss=2.326, task_loss=2.146, contrastive_loss=1.395, total=4196.46, n_correct=1276.14, ppl=6.27, accuracy=30.41, wps=13482.4, ups=1.08, wpb=12527.1, bsz=468.6, num_updates=3400, lr=0.000136032, gnorm=3.152, clip=1, loss_scale=1, train_wall=92, gb_free=15.5, wall=2604
2023-08-16 04:30:21 | INFO | train_inner | epoch 003:    560 / 1474 loss=4.126, trans_loss=4.184, nll_loss=2.593, w2v_ctc_loss=2.236, task_loss=2.316, contrastive_loss=1.283, total=4085.25, n_correct=1299.98, ppl=6.03, accuracy=31.821, wps=13226, ups=1.08, wpb=12203.2, bsz=439.8, num_updates=3500, lr=0.00014003, gnorm=2.735, clip=0, loss_scale=1, train_wall=92, gb_free=15.5, wall=2697
2023-08-16 04:31:55 | INFO | train_inner | epoch 003:    660 / 1474 loss=4.049, trans_loss=4.156, nll_loss=2.552, w2v_ctc_loss=2.158, task_loss=2.05, contrastive_loss=1.356, total=4229.91, n_correct=1400.72, ppl=5.87, accuracy=33.115, wps=13431.9, ups=1.07, wpb=12610.8, bsz=484.8, num_updates=3600, lr=0.000144028, gnorm=2.657, clip=1, loss_scale=1, train_wall=93, gb_free=17.1, wall=2790
2023-08-16 04:33:28 | INFO | train_inner | epoch 003:    760 / 1474 loss=3.928, trans_loss=4.122, nll_loss=2.514, w2v_ctc_loss=2.128, task_loss=2.096, contrastive_loss=1.105, total=4157.48, n_correct=1412.42, ppl=5.71, accuracy=33.973, wps=13404.4, ups=1.08, wpb=12420.7, bsz=467.8, num_updates=3700, lr=0.000148026, gnorm=2.753, clip=1, loss_scale=1, train_wall=92, gb_free=11.1, wall=2883
2023-08-16 04:35:01 | INFO | train_inner | epoch 003:    860 / 1474 loss=3.801, trans_loss=4.114, nll_loss=2.502, w2v_ctc_loss=2.044, task_loss=2.166, contrastive_loss=1.017, total=4172.27, n_correct=1436.88, ppl=5.66, accuracy=34.439, wps=13412.3, ups=1.08, wpb=12457.6, bsz=458.8, num_updates=3800, lr=0.000152024, gnorm=1.991, clip=0, loss_scale=1, train_wall=92, gb_free=16.4, wall=2976
2023-08-16 04:36:34 | INFO | train_inner | epoch 003:    960 / 1474 loss=3.791, trans_loss=4.097, nll_loss=2.478, w2v_ctc_loss=2.055, task_loss=2.083, contrastive_loss=1.054, total=4171.53, n_correct=1471.9, ppl=5.57, accuracy=35.284, wps=13347, ups=1.07, wpb=12442.2, bsz=473.5, num_updates=3900, lr=0.000156022, gnorm=3.229, clip=3, loss_scale=1, train_wall=93, gb_free=15.9, wall=3069
2023-08-16 04:38:06 | INFO | train_inner | epoch 003:   1060 / 1474 loss=3.75, trans_loss=4.077, nll_loss=2.456, w2v_ctc_loss=2.085, task_loss=2.347, contrastive_loss=0.954, total=4051.14, n_correct=1449.93, ppl=5.49, accuracy=35.791, wps=13113.8, ups=1.08, wpb=12099.4, bsz=436.8, num_updates=4000, lr=0.00016002, gnorm=3.419, clip=3, loss_scale=1, train_wall=92, gb_free=16.5, wall=3162
2023-08-16 04:38:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 04:38:35 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.99 | trans_loss 7.115 | nll_loss 4.945 | w2v_ctc_loss 2.48 | task_loss 10.162 | contrastive_loss 1.362 | total 4003.4 | n_correct 1538.7 | ppl 30.8 | accuracy 38.435 | uer 35.798 | wer 35.614 | raw_wer 35.614 | bleu 1.66 | wps 1619.8 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 1.66
2023-08-16 04:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-16 04:38:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_3_4000.pt
2023-08-16 04:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_3_4000.pt
2023-08-16 04:39:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 1.66) (writing took 59.71502703987062 seconds)
2023-08-16 04:41:07 | INFO | train_inner | epoch 003:   1160 / 1474 loss=3.669, trans_loss=4.071, nll_loss=2.445, w2v_ctc_loss=2.029, task_loss=2.317, contrastive_loss=0.908, total=4050.25, n_correct=1466.35, ppl=5.45, accuracy=36.204, wps=6689.6, ups=0.55, wpb=12088.6, bsz=435.7, num_updates=4100, lr=0.000164018, gnorm=2.822, clip=2, loss_scale=1, train_wall=91, gb_free=16, wall=3342
2023-08-16 04:42:39 | INFO | train_inner | epoch 003:   1260 / 1474 loss=3.603, trans_loss=4.049, nll_loss=2.419, w2v_ctc_loss=1.997, task_loss=2.312, contrastive_loss=0.849, total=4058.28, n_correct=1494.76, ppl=5.35, accuracy=36.832, wps=13221.7, ups=1.09, wpb=12119.7, bsz=431.2, num_updates=4200, lr=0.000168016, gnorm=2.793, clip=3, loss_scale=1, train_wall=91, gb_free=16.2, wall=3434
2023-08-16 04:44:12 | INFO | train_inner | epoch 003:   1360 / 1474 loss=3.585, trans_loss=4.03, nll_loss=2.394, w2v_ctc_loss=1.963, task_loss=2.186, contrastive_loss=0.955, total=4134.29, n_correct=1556, ppl=5.25, accuracy=37.636, wps=13242.4, ups=1.07, wpb=12343, bsz=460.8, num_updates=4300, lr=0.000172014, gnorm=2.628, clip=2, loss_scale=1, train_wall=93, gb_free=16.5, wall=3527
2023-08-16 04:45:45 | INFO | train_inner | epoch 003:   1460 / 1474 loss=3.498, trans_loss=4.014, nll_loss=2.374, w2v_ctc_loss=1.913, task_loss=2.063, contrastive_loss=0.882, total=4206.08, n_correct=1615.87, ppl=5.18, accuracy=38.417, wps=13516.9, ups=1.08, wpb=12563.6, bsz=476.5, num_updates=4400, lr=0.000176012, gnorm=1.918, clip=0, loss_scale=1, train_wall=92, gb_free=14.1, wall=3620
2023-08-16 04:45:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 04:46:31 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.683 | trans_loss 6.874 | nll_loss 4.626 | w2v_ctc_loss 2.316 | task_loss 10.187 | contrastive_loss 1.071 | total 4003.4 | n_correct 1671.6 | ppl 24.7 | accuracy 41.755 | uer 33.778 | wer 33.63 | raw_wer 33.63 | bleu 4.09 | wps 1466 | wpb 4003.4 | bsz 141.8 | num_updates 4414 | best_bleu 4.09
2023-08-16 04:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4414 updates
2023-08-16 04:46:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 04:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 3 @ 4414 updates, score 4.09) (writing took 30.216055436059833 seconds)
2023-08-16 04:47:01 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-16 04:47:01 | INFO | train | epoch 003 | loss 4.184 | trans_loss 4.338 | nll_loss 2.794 | w2v_ctc_loss 2.207 | task_loss 2.216 | contrastive_loss 1.223 | total 4138.94 | n_correct 1222.34 | ppl 6.93 | accuracy 29.533 | wps 12036.7 | ups 0.97 | wpb 12356.6 | bsz 458.7 | num_updates 4414 | lr 0.000176572 | gnorm 2.95 | clip 1.8 | loss_scale 1 | train_wall 1342 | gb_free 16.2 | wall 3696
2023-08-16 04:47:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 04:47:01 | INFO | fairseq.trainer | begin training epoch 4
2023-08-16 04:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 04:48:27 | INFO | train_inner | epoch 004:     86 / 1474 loss=3.374, trans_loss=3.985, nll_loss=2.332, w2v_ctc_loss=1.872, task_loss=2.261, contrastive_loss=0.698, total=4096.88, n_correct=1617.07, ppl=5.04, accuracy=39.471, wps=7548.6, ups=0.62, wpb=12226.6, bsz=438.5, num_updates=4500, lr=0.00018001, gnorm=2.982, clip=2, loss_scale=1, train_wall=91, gb_free=13.8, wall=3782
2023-08-16 04:49:59 | INFO | train_inner | epoch 004:    186 / 1474 loss=3.388, trans_loss=3.962, nll_loss=2.305, w2v_ctc_loss=1.898, task_loss=2.064, contrastive_loss=0.731, total=4177.87, n_correct=1683.22, ppl=4.94, accuracy=40.289, wps=13545.2, ups=1.09, wpb=12473.8, bsz=469, num_updates=4600, lr=0.000184008, gnorm=2.191, clip=2, loss_scale=1, train_wall=91, gb_free=15.2, wall=3874
2023-08-16 04:51:32 | INFO | train_inner | epoch 004:    286 / 1474 loss=3.327, trans_loss=3.949, nll_loss=2.29, w2v_ctc_loss=1.838, task_loss=2.176, contrastive_loss=0.81, total=4147.79, n_correct=1693.19, ppl=4.89, accuracy=40.821, wps=13317.4, ups=1.07, wpb=12391.1, bsz=464.6, num_updates=4700, lr=0.000188006, gnorm=1.855, clip=0, loss_scale=1, train_wall=92, gb_free=15.8, wall=3967
2023-08-16 04:52:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-08-16 04:53:05 | INFO | train_inner | epoch 004:    387 / 1474 loss=3.228, trans_loss=3.934, nll_loss=2.267, w2v_ctc_loss=1.806, task_loss=2.278, contrastive_loss=0.611, total=4112.14, n_correct=1709.18, ppl=4.81, accuracy=41.564, wps=13152, ups=1.07, wpb=12269.1, bsz=439.7, num_updates=4800, lr=0.000192004, gnorm=1.636, clip=0, loss_scale=0.5, train_wall=93, gb_free=16.7, wall=4060
2023-08-16 04:54:39 | INFO | train_inner | epoch 004:    487 / 1474 loss=3.296, trans_loss=3.913, nll_loss=2.241, w2v_ctc_loss=1.784, task_loss=1.921, contrastive_loss=1.026, total=4242.53, n_correct=1798.33, ppl=4.73, accuracy=42.388, wps=13575.7, ups=1.07, wpb=12663.6, bsz=507.9, num_updates=4900, lr=0.000196002, gnorm=1.865, clip=0, loss_scale=0.5, train_wall=93, gb_free=16.9, wall=4154
2023-08-16 04:56:11 | INFO | train_inner | epoch 004:    587 / 1474 loss=3.17, trans_loss=3.883, nll_loss=2.201, w2v_ctc_loss=1.774, task_loss=2.047, contrastive_loss=0.654, total=4222.82, n_correct=1841.66, ppl=4.6, accuracy=43.612, wps=13649, ups=1.08, wpb=12606.6, bsz=484.3, num_updates=5000, lr=0.0002, gnorm=1.693, clip=1, loss_scale=0.5, train_wall=92, gb_free=14.3, wall=4246
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:0')
2023-08-16 04:57:45 | INFO | train_inner | epoch 004:    687 / 1474 loss=3.14, trans_loss=3.885, nll_loss=2.2, w2v_ctc_loss=1.761, task_loss=2.269, contrastive_loss=0.69, total=4165.36, n_correct=1827.45, ppl=4.59, accuracy=43.873, wps=13205.2, ups=1.06, wpb=12416.4, bsz=452, num_updates=5100, lr=0.00019803, gnorm=1.212, clip=0, loss_scale=0.5, train_wall=93, gb_free=15.4, wall=4340
2023-08-16 04:59:18 | INFO | train_inner | epoch 004:    787 / 1474 loss=3.095, trans_loss=3.86, nll_loss=2.172, w2v_ctc_loss=1.78, task_loss=2.404, contrastive_loss=0.543, total=4021.88, n_correct=1794.82, ppl=4.51, accuracy=44.626, wps=12978, ups=1.08, wpb=12009.3, bsz=420.1, num_updates=5200, lr=0.000196116, gnorm=1.243, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.2, wall=4433
2023-08-16 05:00:50 | INFO | train_inner | epoch 004:    887 / 1474 loss=3.112, trans_loss=3.837, nll_loss=2.143, w2v_ctc_loss=1.759, task_loss=2.171, contrastive_loss=0.72, total=4185.92, n_correct=1898.99, ppl=4.42, accuracy=45.366, wps=13495.3, ups=1.08, wpb=12500.2, bsz=466.8, num_updates=5300, lr=0.000194257, gnorm=1.123, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.6, wall=4525
2023-08-16 05:02:23 | INFO | train_inner | epoch 004:    987 / 1474 loss=3.021, trans_loss=3.817, nll_loss=2.117, w2v_ctc_loss=1.72, task_loss=2.233, contrastive_loss=0.568, total=4125.22, n_correct=1906.56, ppl=4.34, accuracy=46.217, wps=13298.6, ups=1.08, wpb=12322, bsz=454.4, num_updates=5400, lr=0.00019245, gnorm=1.067, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.5, wall=4618
2023-08-16 05:03:56 | INFO | train_inner | epoch 004:   1087 / 1474 loss=3.018, trans_loss=3.816, nll_loss=2.115, w2v_ctc_loss=1.739, task_loss=2.31, contrastive_loss=0.538, total=4079.97, n_correct=1894.39, ppl=4.33, accuracy=46.431, wps=13148.9, ups=1.08, wpb=12178.8, bsz=440.5, num_updates=5500, lr=0.000190693, gnorm=1.135, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.4, wall=4711
2023-08-16 05:05:28 | INFO | train_inner | epoch 004:   1187 / 1474 loss=3.039, trans_loss=3.802, nll_loss=2.099, w2v_ctc_loss=1.734, task_loss=2.031, contrastive_loss=0.65, total=4171.2, n_correct=1964.59, ppl=4.28, accuracy=47.099, wps=13446.8, ups=1.08, wpb=12457.9, bsz=485.8, num_updates=5600, lr=0.000188982, gnorm=1.172, clip=0, loss_scale=0.5, train_wall=92, gb_free=15.5, wall=4803
2023-08-16 05:07:00 | INFO | train_inner | epoch 004:   1287 / 1474 loss=2.993, trans_loss=3.784, nll_loss=2.075, w2v_ctc_loss=1.72, task_loss=2.112, contrastive_loss=0.597, total=4140.63, n_correct=1974.62, ppl=4.21, accuracy=47.689, wps=13416.2, ups=1.09, wpb=12365.2, bsz=466.8, num_updates=5700, lr=0.000187317, gnorm=1.208, clip=1, loss_scale=0.5, train_wall=92, gb_free=16.6, wall=4895
2023-08-16 05:08:31 | INFO | train_inner | epoch 004:   1387 / 1474 loss=2.944, trans_loss=3.772, nll_loss=2.06, w2v_ctc_loss=1.719, task_loss=2.238, contrastive_loss=0.464, total=4100.54, n_correct=1970.26, ppl=4.17, accuracy=48.049, wps=13476.8, ups=1.1, wpb=12248.6, bsz=438.8, num_updates=5800, lr=0.000185695, gnorm=1.165, clip=0, loss_scale=0.5, train_wall=90, gb_free=17.5, wall=4986
2023-08-16 05:09:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5010, device='cuda:1')
2023-08-16 05:10:17 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.815 | trans_loss 5.977 | nll_loss 3.458 | w2v_ctc_loss 1.927 | task_loss 10.811 | contrastive_loss 0.655 | total 4003.4 | n_correct 2169.2 | ppl 10.99 | accuracy 54.184 | uer 28.219 | wer 29.391 | raw_wer 29.391 | bleu 12.7 | wps 1867.4 | wpb 4003.4 | bsz 141.8 | num_updates 5887 | best_bleu 12.7
2023-08-16 05:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5887 updates
2023-08-16 05:10:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 05:10:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 05:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 4 @ 5887 updates, score 12.7) (writing took 29.185263676568866 seconds)
2023-08-16 05:10:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-16 05:10:46 | INFO | train | epoch 004 | loss 3.136 | trans_loss 3.864 | nll_loss 2.177 | w2v_ctc_loss 1.771 | task_loss 2.178 | contrastive_loss 0.657 | total 4138.79 | n_correct 1838.1 | ppl 4.52 | accuracy 44.412 | wps 12773.5 | ups 1.03 | wpb 12356.2 | bsz 458.6 | num_updates 5887 | lr 0.000184318 | gnorm 1.498 | clip 0.4 | loss_scale 0.5 | train_wall 1352 | gb_free 14.5 | wall 5121
2023-08-16 05:10:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 05:10:46 | INFO | fairseq.trainer | begin training epoch 5
2023-08-16 05:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 05:11:06 | INFO | train_inner | epoch 005:     13 / 1474 loss=2.873, trans_loss=3.755, nll_loss=2.036, w2v_ctc_loss=1.645, task_loss=2.252, contrastive_loss=0.47, total=4049.24, n_correct=1978.37, ppl=4.1, accuracy=48.858, wps=7832.3, ups=0.65, wpb=12086.7, bsz=441.2, num_updates=5900, lr=0.000184115, gnorm=0.927, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.7, wall=5141
2023-08-16 05:12:38 | INFO | train_inner | epoch 005:    113 / 1474 loss=2.809, trans_loss=3.712, nll_loss=1.982, w2v_ctc_loss=1.585, task_loss=1.953, contrastive_loss=0.477, total=4250.33, n_correct=2139.79, ppl=3.95, accuracy=50.344, wps=13700.1, ups=1.08, wpb=12693.9, bsz=497.5, num_updates=6000, lr=0.000182574, gnorm=0.862, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.8, wall=5233
2023-08-16 05:12:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 05:13:05 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.791 | trans_loss 5.957 | nll_loss 3.426 | w2v_ctc_loss 1.912 | task_loss 10.647 | contrastive_loss 0.632 | total 4003.4 | n_correct 2180.8 | ppl 10.75 | accuracy 54.474 | uer 28.511 | wer 29.469 | raw_wer 29.469 | bleu 12.85 | wps 1801.4 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 12.85
2023-08-16 05:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-16 05:13:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_5_6000.pt
2023-08-16 05:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_5_6000.pt
2023-08-16 05:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 12.85) (writing took 29.626459907740355 seconds)
2023-08-16 05:15:06 | INFO | train_inner | epoch 005:    213 / 1474 loss=2.832, trans_loss=3.718, nll_loss=1.987, w2v_ctc_loss=1.587, task_loss=2.021, contrastive_loss=0.66, total=4190.08, n_correct=2109.94, ppl=3.96, accuracy=50.356, wps=8455.3, ups=0.68, wpb=12501.7, bsz=486.7, num_updates=6100, lr=0.000181071, gnorm=0.796, clip=0, loss_scale=0.5, train_wall=91, gb_free=12.3, wall=5381
2023-08-16 05:16:37 | INFO | train_inner | epoch 005:    313 / 1474 loss=2.811, trans_loss=3.699, nll_loss=1.968, w2v_ctc_loss=1.608, task_loss=2.212, contrastive_loss=0.519, total=4096.44, n_correct=2069.51, ppl=3.91, accuracy=50.52, wps=13479.7, ups=1.1, wpb=12249.1, bsz=448.2, num_updates=6200, lr=0.000179605, gnorm=0.963, clip=1, loss_scale=0.5, train_wall=90, gb_free=16.4, wall=5472
2023-08-16 05:18:10 | INFO | train_inner | epoch 005:    413 / 1474 loss=2.793, trans_loss=3.691, nll_loss=1.956, w2v_ctc_loss=1.57, task_loss=2.164, contrastive_loss=0.591, total=4133.67, n_correct=2110.41, ppl=3.88, accuracy=51.054, wps=13323.5, ups=1.08, wpb=12352.7, bsz=463.8, num_updates=6300, lr=0.000178174, gnorm=0.913, clip=0, loss_scale=0.5, train_wall=92, gb_free=16.3, wall=5565
2023-08-16 05:19:42 | INFO | train_inner | epoch 005:    513 / 1474 loss=2.758, trans_loss=3.692, nll_loss=1.956, w2v_ctc_loss=1.568, task_loss=2.366, contrastive_loss=0.518, total=4036.61, n_correct=2062.82, ppl=3.88, accuracy=51.103, wps=13068.2, ups=1.08, wpb=12057.3, bsz=428.7, num_updates=6400, lr=0.000176777, gnorm=0.914, clip=0, loss_scale=0.5, train_wall=92, gb_free=17.6, wall=5657
2023-08-16 05:21:14 | INFO | train_inner | epoch 005:    613 / 1474 loss=2.725, trans_loss=3.689, nll_loss=1.949, w2v_ctc_loss=1.561, task_loss=2.293, contrastive_loss=0.413, total=4112.09, n_correct=2117.06, ppl=3.86, accuracy=51.484, wps=13336.2, ups=1.09, wpb=12268.1, bsz=443.6, num_updates=6500, lr=0.000175412, gnorm=0.811, clip=0, loss_scale=0.5, train_wall=91, gb_free=16.5, wall=5749
2023-08-16 05:22:46 | INFO | train_inner | epoch 005:    713 / 1474 loss=2.73, trans_loss=3.679, nll_loss=1.938, w2v_ctc_loss=1.541, task_loss=2.088, contrastive_loss=0.516, total=4160.15, n_correct=2162.01, ppl=3.83, accuracy=51.97, wps=13454, ups=1.08, wpb=12418.1, bsz=477.6, num_updates=6600, lr=0.000174078, gnorm=0.812, clip=0, loss_scale=0.5, train_wall=92, gb_free=15.3, wall=5841
2023-08-16 05:24:20 | INFO | train_inner | epoch 005:    813 / 1474 loss=2.698, trans_loss=3.669, nll_loss=1.925, w2v_ctc_loss=1.536, task_loss=2.223, contrastive_loss=0.438, total=4129.67, n_correct=2153.19, ppl=3.8, accuracy=52.14, wps=13200.9, ups=1.07, wpb=12327.3, bsz=452.6, num_updates=6700, lr=0.000172774, gnorm=0.8, clip=0, loss_scale=0.5, train_wall=93, gb_free=15.7, wall=5935
2023-08-16 05:25:52 | INFO | train_inner | epoch 005:    913 / 1474 loss=2.647, trans_loss=3.655, nll_loss=1.907, w2v_ctc_loss=1.509, task_loss=2.263, contrastive_loss=0.381, total=4107.27, n_correct=2170.23, ppl=3.75, accuracy=52.839, wps=13344.3, ups=1.09, wpb=12262.1, bsz=446.2, num_updates=6800, lr=0.000171499, gnorm=0.707, clip=0, loss_scale=0.5, train_wall=91, gb_free=12.7, wall=6027
2023-08-16 05:27:23 | INFO | train_inner | epoch 005:   1013 / 1474 loss=2.67, trans_loss=3.656, nll_loss=1.909, w2v_ctc_loss=1.517, task_loss=2.178, contrastive_loss=0.462, total=4154.85, n_correct=2194.6, ppl=3.75, accuracy=52.82, wps=13518.4, ups=1.09, wpb=12403.9, bsz=458.6, num_updates=6900, lr=0.000170251, gnorm=1.078, clip=1, loss_scale=1, train_wall=91, gb_free=15.2, wall=6118
2023-08-16 05:28:57 | INFO | train_inner | epoch 005:   1113 / 1474 loss=2.698, trans_loss=3.652, nll_loss=1.902, w2v_ctc_loss=1.539, task_loss=2.154, contrastive_loss=0.48, total=4178.83, n_correct=2217.04, ppl=3.74, accuracy=53.054, wps=13371.4, ups=1.07, wpb=12465.4, bsz=468.4, num_updates=7000, lr=0.000169031, gnorm=1.025, clip=2, loss_scale=1, train_wall=93, gb_free=12.9, wall=6212
2023-08-16 05:30:29 | INFO | train_inner | epoch 005:   1213 / 1474 loss=2.605, trans_loss=3.639, nll_loss=1.885, w2v_ctc_loss=1.482, task_loss=2.212, contrastive_loss=0.356, total=4163.71, n_correct=2232.11, ppl=3.69, accuracy=53.609, wps=13443.2, ups=1.08, wpb=12420.2, bsz=454, num_updates=7100, lr=0.000167836, gnorm=0.707, clip=0, loss_scale=1, train_wall=92, gb_free=17, wall=6304
2023-08-16 05:32:02 | INFO | train_inner | epoch 005:   1313 / 1474 loss=2.579, trans_loss=3.631, nll_loss=1.876, w2v_ctc_loss=1.474, task_loss=2.24, contrastive_loss=0.314, total=4125.59, n_correct=2226.75, ppl=3.67, accuracy=53.974, wps=13254.1, ups=1.08, wpb=12312.6, bsz=442.8, num_updates=7200, lr=0.000166667, gnorm=0.707, clip=0, loss_scale=1, train_wall=92, gb_free=14.6, wall=6397
2023-08-16 05:33:33 | INFO | train_inner | epoch 005:   1413 / 1474 loss=2.606, trans_loss=3.631, nll_loss=1.878, w2v_ctc_loss=1.475, task_loss=2.181, contrastive_loss=0.394, total=4145.41, n_correct=2233.11, ppl=3.68, accuracy=53.869, wps=13520.8, ups=1.09, wpb=12381.3, bsz=460.5, num_updates=7300, lr=0.000165521, gnorm=0.799, clip=0, loss_scale=1, train_wall=91, gb_free=16.4, wall=6488
2023-08-16 05:34:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 05:34:52 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.493 | trans_loss 5.667 | nll_loss 3.064 | w2v_ctc_loss 1.684 | task_loss 10.977 | contrastive_loss 0.539 | total 4003.4 | n_correct 2349.9 | ppl 8.36 | accuracy 58.698 | uer 26.149 | wer 27.486 | raw_wer 27.486 | bleu 15.99 | wps 2304.5 | wpb 4003.4 | bsz 141.8 | num_updates 7361 | best_bleu 15.99
2023-08-16 05:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7361 updates
2023-08-16 05:34:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 05:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 05:35:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 5 @ 7361 updates, score 15.99) (writing took 31.802234729751945 seconds)
2023-08-16 05:35:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-16 05:35:24 | INFO | train | epoch 005 | loss 2.708 | trans_loss 3.671 | nll_loss 1.928 | w2v_ctc_loss 1.538 | task_loss 2.18 | contrastive_loss 0.465 | total 4138.65 | n_correct 2158.36 | ppl 3.8 | accuracy 52.151 | wps 12322.3 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7361 | lr 0.000164834 | gnorm 0.846 | clip 0.3 | loss_scale 1 | train_wall 1351 | gb_free 16 | wall 6599
2023-08-16 05:35:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 05:35:24 | INFO | fairseq.trainer | begin training epoch 6
2023-08-16 05:35:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 05:36:08 | INFO | train_inner | epoch 006:     39 / 1474 loss=2.575, trans_loss=3.612, nll_loss=1.851, w2v_ctc_loss=1.461, task_loss=2.255, contrastive_loss=0.376, total=4112.54, n_correct=2241.18, ppl=3.61, accuracy=54.496, wps=7922.6, ups=0.65, wpb=12270.9, bsz=445.9, num_updates=7400, lr=0.000164399, gnorm=0.699, clip=0, loss_scale=1, train_wall=92, gb_free=16.2, wall=6643
2023-08-16 05:37:40 | INFO | train_inner | epoch 006:    139 / 1474 loss=2.522, trans_loss=3.583, nll_loss=1.816, w2v_ctc_loss=1.409, task_loss=2.157, contrastive_loss=0.406, total=4157.02, n_correct=2297.81, ppl=3.52, accuracy=55.275, wps=13501.2, ups=1.09, wpb=12417.6, bsz=457.6, num_updates=7500, lr=0.000163299, gnorm=0.67, clip=0, loss_scale=1, train_wall=91, gb_free=14.1, wall=6735
2023-08-16 05:39:12 | INFO | train_inner | epoch 006:    239 / 1474 loss=2.52, trans_loss=3.59, nll_loss=1.826, w2v_ctc_loss=1.433, task_loss=2.291, contrastive_loss=0.33, total=4120.34, n_correct=2270.11, ppl=3.55, accuracy=55.095, wps=13439, ups=1.09, wpb=12308.9, bsz=444.8, num_updates=7600, lr=0.000162221, gnorm=0.657, clip=0, loss_scale=1, train_wall=91, gb_free=17.3, wall=6827
2023-08-16 05:40:46 | INFO | train_inner | epoch 006:    339 / 1474 loss=2.543, trans_loss=3.579, nll_loss=1.81, w2v_ctc_loss=1.382, task_loss=2.086, contrastive_loss=0.605, total=4160.74, n_correct=2312.01, ppl=3.51, accuracy=55.567, wps=13221.2, ups=1.06, wpb=12422.4, bsz=482.1, num_updates=7700, lr=0.000161165, gnorm=0.667, clip=0, loss_scale=1, train_wall=93, gb_free=15.9, wall=6921
2023-08-16 05:42:17 | INFO | train_inner | epoch 006:    439 / 1474 loss=2.471, trans_loss=3.57, nll_loss=1.799, w2v_ctc_loss=1.385, task_loss=2.089, contrastive_loss=0.321, total=4157.21, n_correct=2330.63, ppl=3.48, accuracy=56.062, wps=13612.3, ups=1.1, wpb=12413.9, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.647, clip=0, loss_scale=1, train_wall=91, gb_free=15.3, wall=7012
2023-08-16 05:43:49 | INFO | train_inner | epoch 006:    539 / 1474 loss=2.481, trans_loss=3.575, nll_loss=1.805, w2v_ctc_loss=1.406, task_loss=2.188, contrastive_loss=0.307, total=4168.09, n_correct=2333.24, ppl=3.49, accuracy=55.979, wps=13470.5, ups=1.08, wpb=12441.1, bsz=456, num_updates=7900, lr=0.000159111, gnorm=0.726, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=7104
2023-08-16 05:45:21 | INFO | train_inner | epoch 006:    639 / 1474 loss=2.463, trans_loss=3.57, nll_loss=1.799, w2v_ctc_loss=1.376, task_loss=2.061, contrastive_loss=0.353, total=4152.97, n_correct=2331.37, ppl=3.48, accuracy=56.137, wps=13550.1, ups=1.09, wpb=12396.5, bsz=473.1, num_updates=8000, lr=0.000158114, gnorm=0.632, clip=0, loss_scale=1, train_wall=91, gb_free=15.1, wall=7196
2023-08-16 05:45:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 05:45:43 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.387 | trans_loss 5.562 | nll_loss 2.929 | w2v_ctc_loss 1.655 | task_loss 11.033 | contrastive_loss 0.468 | total 4003.4 | n_correct 2413.8 | ppl 7.61 | accuracy 60.294 | uer 24.864 | wer 26.304 | raw_wer 26.304 | bleu 17.23 | wps 2345.7 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.23
2023-08-16 05:45:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-16 05:45:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_6_8000.pt
2023-08-16 05:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_6_8000.pt
2023-08-16 05:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.23) (writing took 56.69494282454252 seconds)
2023-08-16 05:48:13 | INFO | train_inner | epoch 006:    739 / 1474 loss=2.455, trans_loss=3.569, nll_loss=1.798, w2v_ctc_loss=1.388, task_loss=2.243, contrastive_loss=0.304, total=4136.55, n_correct=2330.97, ppl=3.48, accuracy=56.351, wps=7180.9, ups=0.58, wpb=12349.7, bsz=450.8, num_updates=8100, lr=0.000157135, gnorm=0.635, clip=0, loss_scale=1, train_wall=92, gb_free=16.5, wall=7368
2023-08-16 05:49:45 | INFO | train_inner | epoch 006:    839 / 1474 loss=2.436, trans_loss=3.567, nll_loss=1.796, w2v_ctc_loss=1.373, task_loss=2.256, contrastive_loss=0.281, total=4134.7, n_correct=2327.9, ppl=3.47, accuracy=56.302, wps=13395.9, ups=1.09, wpb=12344.1, bsz=447.8, num_updates=8200, lr=0.000156174, gnorm=0.621, clip=0, loss_scale=1, train_wall=92, gb_free=14.5, wall=7460
2023-08-16 05:51:18 | INFO | train_inner | epoch 006:    939 / 1474 loss=2.467, trans_loss=3.57, nll_loss=1.799, w2v_ctc_loss=1.382, task_loss=2.33, contrastive_loss=0.384, total=4074.92, n_correct=2291.72, ppl=3.48, accuracy=56.24, wps=13088.4, ups=1.08, wpb=12163, bsz=439.9, num_updates=8300, lr=0.00015523, gnorm=0.625, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=7553
2023-08-16 05:52:50 | INFO | train_inner | epoch 006:   1039 / 1474 loss=2.452, trans_loss=3.553, nll_loss=1.778, w2v_ctc_loss=1.351, task_loss=2.051, contrastive_loss=0.454, total=4167.38, n_correct=2368.63, ppl=3.43, accuracy=56.837, wps=13556, ups=1.09, wpb=12438.7, bsz=478.3, num_updates=8400, lr=0.000154303, gnorm=0.625, clip=0, loss_scale=1, train_wall=91, gb_free=16, wall=7645
2023-08-16 05:54:21 | INFO | train_inner | epoch 006:   1139 / 1474 loss=2.426, trans_loss=3.553, nll_loss=1.778, w2v_ctc_loss=1.371, task_loss=2.425, contrastive_loss=0.283, total=4066.48, n_correct=2304, ppl=3.43, accuracy=56.658, wps=13229.3, ups=1.09, wpb=12140, bsz=428.3, num_updates=8500, lr=0.000153393, gnorm=0.728, clip=1, loss_scale=1, train_wall=91, gb_free=15.6, wall=7737
2023-08-16 05:55:54 | INFO | train_inner | epoch 006:   1239 / 1474 loss=2.464, trans_loss=3.541, nll_loss=1.764, w2v_ctc_loss=1.339, task_loss=2.141, contrastive_loss=0.596, total=4143.59, n_correct=2369.46, ppl=3.4, accuracy=57.184, wps=13337.9, ups=1.08, wpb=12377.1, bsz=471.5, num_updates=8600, lr=0.000152499, gnorm=0.623, clip=0, loss_scale=1, train_wall=92, gb_free=16.9, wall=7829
2023-08-16 05:57:26 | INFO | train_inner | epoch 006:   1339 / 1474 loss=2.381, trans_loss=3.543, nll_loss=1.763, w2v_ctc_loss=1.336, task_loss=2.163, contrastive_loss=0.256, total=4125.75, n_correct=2367.12, ppl=3.39, accuracy=57.374, wps=13391.1, ups=1.09, wpb=12308.4, bsz=454.4, num_updates=8700, lr=0.00015162, gnorm=0.594, clip=0, loss_scale=1, train_wall=91, gb_free=15.9, wall=7921
2023-08-16 05:58:59 | INFO | train_inner | epoch 006:   1439 / 1474 loss=2.381, trans_loss=3.536, nll_loss=1.756, w2v_ctc_loss=1.335, task_loss=2.183, contrastive_loss=0.265, total=4194.06, n_correct=2410.87, ppl=3.38, accuracy=57.483, wps=13454, ups=1.07, wpb=12518.6, bsz=462, num_updates=8800, lr=0.000150756, gnorm=0.586, clip=0, loss_scale=1, train_wall=92, gb_free=16, wall=8014
2023-08-16 05:59:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 05:59:54 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.281 | trans_loss 5.47 | nll_loss 2.816 | w2v_ctc_loss 1.545 | task_loss 11.278 | contrastive_loss 0.435 | total 4003.4 | n_correct 2462.5 | ppl 7.04 | accuracy 61.51 | uer 23.667 | wer 25.323 | raw_wer 25.323 | bleu 18.2 | wps 2135.5 | wpb 4003.4 | bsz 141.8 | num_updates 8835 | best_bleu 18.2
2023-08-16 05:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8835 updates
2023-08-16 05:59:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:00:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 6 @ 8835 updates, score 18.2) (writing took 33.97555558755994 seconds)
2023-08-16 06:00:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-16 06:00:28 | INFO | train | epoch 006 | loss 2.461 | trans_loss 3.564 | nll_loss 1.792 | w2v_ctc_loss 1.376 | task_loss 2.184 | contrastive_loss 0.366 | total 4138.65 | n_correct 2331.09 | ppl 3.46 | accuracy 56.325 | wps 12107.9 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 8835 | lr 0.000150457 | gnorm 0.644 | clip 0.1 | loss_scale 1 | train_wall 1350 | gb_free 14.8 | wall 8103
2023-08-16 06:00:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 06:00:29 | INFO | fairseq.trainer | begin training epoch 7
2023-08-16 06:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 06:01:36 | INFO | train_inner | epoch 007:     65 / 1474 loss=2.351, trans_loss=3.522, nll_loss=1.738, w2v_ctc_loss=1.305, task_loss=2.143, contrastive_loss=0.278, total=4103.49, n_correct=2378.85, ppl=3.34, accuracy=57.971, wps=7800.4, ups=0.64, wpb=12251.2, bsz=461.5, num_updates=8900, lr=0.000149906, gnorm=0.655, clip=0, loss_scale=2, train_wall=91, gb_free=16.7, wall=8171
2023-08-16 06:03:08 | INFO | train_inner | epoch 007:    165 / 1474 loss=2.351, trans_loss=3.514, nll_loss=1.728, w2v_ctc_loss=1.292, task_loss=2.208, contrastive_loss=0.347, total=4110.42, n_correct=2391.03, ppl=3.31, accuracy=58.17, wps=13385.7, ups=1.09, wpb=12272.5, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.606, clip=0, loss_scale=2, train_wall=91, gb_free=16.1, wall=8263
2023-08-16 06:04:40 | INFO | train_inner | epoch 007:    265 / 1474 loss=2.322, trans_loss=3.507, nll_loss=1.717, w2v_ctc_loss=1.289, task_loss=2.202, contrastive_loss=0.25, total=4130.95, n_correct=2416.16, ppl=3.29, accuracy=58.489, wps=13386.3, ups=1.09, wpb=12328.4, bsz=454.4, num_updates=9100, lr=0.00014825, gnorm=0.578, clip=0, loss_scale=2, train_wall=92, gb_free=17.4, wall=8355
2023-08-16 06:06:13 | INFO | train_inner | epoch 007:    365 / 1474 loss=2.37, trans_loss=3.51, nll_loss=1.722, w2v_ctc_loss=1.278, task_loss=2.102, contrastive_loss=0.512, total=4204.16, n_correct=2453.89, ppl=3.3, accuracy=58.368, wps=13498.5, ups=1.08, wpb=12547.1, bsz=481.5, num_updates=9200, lr=0.000147442, gnorm=0.573, clip=0, loss_scale=2, train_wall=92, gb_free=16.9, wall=8448
2023-08-16 06:07:45 | INFO | train_inner | epoch 007:    465 / 1474 loss=2.348, trans_loss=3.509, nll_loss=1.722, w2v_ctc_loss=1.274, task_loss=2.191, contrastive_loss=0.428, total=4147.32, n_correct=2420.78, ppl=3.3, accuracy=58.37, wps=13494, ups=1.09, wpb=12384.6, bsz=458.5, num_updates=9300, lr=0.000146647, gnorm=0.598, clip=0, loss_scale=2, train_wall=91, gb_free=17.6, wall=8540
2023-08-16 06:09:17 | INFO | train_inner | epoch 007:    565 / 1474 loss=2.311, trans_loss=3.506, nll_loss=1.715, w2v_ctc_loss=1.277, task_loss=2.138, contrastive_loss=0.256, total=4171.72, n_correct=2445.89, ppl=3.28, accuracy=58.63, wps=13540.9, ups=1.09, wpb=12445.8, bsz=460.5, num_updates=9400, lr=0.000145865, gnorm=0.574, clip=0, loss_scale=2, train_wall=91, gb_free=15.5, wall=8632
2023-08-16 06:10:50 | INFO | train_inner | epoch 007:    665 / 1474 loss=2.301, trans_loss=3.503, nll_loss=1.712, w2v_ctc_loss=1.271, task_loss=2.18, contrastive_loss=0.241, total=4150.49, n_correct=2441.12, ppl=3.28, accuracy=58.815, wps=13352.5, ups=1.08, wpb=12385.7, bsz=454.7, num_updates=9500, lr=0.000145095, gnorm=0.585, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=8725
2023-08-16 06:12:22 | INFO | train_inner | epoch 007:    765 / 1474 loss=2.293, trans_loss=3.493, nll_loss=1.701, w2v_ctc_loss=1.267, task_loss=2.265, contrastive_loss=0.238, total=4132.17, n_correct=2432.26, ppl=3.25, accuracy=58.862, wps=13373.6, ups=1.08, wpb=12338.5, bsz=450.8, num_updates=9600, lr=0.000144338, gnorm=0.572, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=8817
2023-08-16 06:13:54 | INFO | train_inner | epoch 007:    865 / 1474 loss=2.295, trans_loss=3.504, nll_loss=1.714, w2v_ctc_loss=1.264, task_loss=2.214, contrastive_loss=0.251, total=4140.18, n_correct=2431.68, ppl=3.28, accuracy=58.734, wps=13331.8, ups=1.08, wpb=12352.6, bsz=457.8, num_updates=9700, lr=0.000143592, gnorm=0.614, clip=0, loss_scale=2, train_wall=92, gb_free=15.3, wall=8910
2023-08-16 06:15:27 | INFO | train_inner | epoch 007:    965 / 1474 loss=2.299, trans_loss=3.489, nll_loss=1.697, w2v_ctc_loss=1.247, task_loss=2.086, contrastive_loss=0.346, total=4144.65, n_correct=2453.13, ppl=3.24, accuracy=59.188, wps=13397.3, ups=1.08, wpb=12374.9, bsz=475.4, num_updates=9800, lr=0.000142857, gnorm=0.564, clip=0, loss_scale=2, train_wall=92, gb_free=14.8, wall=9002
2023-08-16 06:16:59 | INFO | train_inner | epoch 007:   1065 / 1474 loss=2.279, trans_loss=3.499, nll_loss=1.71, w2v_ctc_loss=1.264, task_loss=2.301, contrastive_loss=0.213, total=4097.24, n_correct=2414.96, ppl=3.27, accuracy=58.941, wps=13334.8, ups=1.09, wpb=12232.2, bsz=435.9, num_updates=9900, lr=0.000142134, gnorm=0.554, clip=0, loss_scale=2, train_wall=91, gb_free=15.9, wall=9094
2023-08-16 06:18:31 | INFO | train_inner | epoch 007:   1165 / 1474 loss=2.327, trans_loss=3.483, nll_loss=1.692, w2v_ctc_loss=1.246, task_loss=2.12, contrastive_loss=0.479, total=4142.16, n_correct=2454.81, ppl=3.23, accuracy=59.264, wps=13370.7, ups=1.08, wpb=12377.5, bsz=471.9, num_updates=10000, lr=0.000141421, gnorm=0.567, clip=0, loss_scale=2, train_wall=92, gb_free=15, wall=9186
2023-08-16 06:18:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 06:18:55 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.39 | nll_loss 2.718 | w2v_ctc_loss 1.476 | task_loss 11.298 | contrastive_loss 0.409 | total 4003.4 | n_correct 2517.6 | ppl 6.58 | accuracy 62.887 | uer 22.013 | wer 23.791 | raw_wer 23.791 | bleu 19.22 | wps 2183.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.22
2023-08-16 06:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-16 06:18:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_7_10000.pt
2023-08-16 06:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_7_10000.pt
2023-08-16 06:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.22) (writing took 32.033928679302335 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:0')
2023-08-16 06:20:58 | INFO | train_inner | epoch 007:   1265 / 1474 loss=2.266, trans_loss=3.485, nll_loss=1.693, w2v_ctc_loss=1.245, task_loss=2.241, contrastive_loss=0.241, total=4119.52, n_correct=2443.19, ppl=3.23, accuracy=59.308, wps=8369.3, ups=0.68, wpb=12302.1, bsz=446.6, num_updates=10100, lr=0.00014072, gnorm=0.439, clip=0, loss_scale=2, train_wall=91, gb_free=13.5, wall=9333
2023-08-16 06:22:30 | INFO | train_inner | epoch 007:   1365 / 1474 loss=2.282, trans_loss=3.48, nll_loss=1.686, w2v_ctc_loss=1.251, task_loss=2.03, contrastive_loss=0.279, total=4185.65, n_correct=2491.64, ppl=3.22, accuracy=59.528, wps=13633.5, ups=1.09, wpb=12496.2, bsz=480.7, num_updates=10200, lr=0.000140028, gnorm=0.463, clip=0, loss_scale=2, train_wall=91, gb_free=16.7, wall=9425
2023-08-16 06:24:04 | INFO | train_inner | epoch 007:   1465 / 1474 loss=2.285, trans_loss=3.482, nll_loss=1.69, w2v_ctc_loss=1.246, task_loss=2.34, contrastive_loss=0.339, total=4113.9, n_correct=2445.49, ppl=3.23, accuracy=59.445, wps=13042.1, ups=1.06, wpb=12290.7, bsz=446.9, num_updates=10300, lr=0.000139347, gnorm=0.446, clip=0, loss_scale=2, train_wall=94, gb_free=16.3, wall=9519
2023-08-16 06:24:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:1')
2023-08-16 06:24:36 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.368 | nll_loss 2.686 | w2v_ctc_loss 1.449 | task_loss 11.298 | contrastive_loss 0.392 | total 4003.4 | n_correct 2528.1 | ppl 6.44 | accuracy 63.149 | uer 21.639 | wer 23.422 | raw_wer 23.422 | bleu 19.47 | wps 2106.7 | wpb 4003.4 | bsz 141.8 | num_updates 10309 | best_bleu 19.47
2023-08-16 06:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10309 updates
2023-08-16 06:24:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:24:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 7 @ 10309 updates, score 19.47) (writing took 32.062112007290125 seconds)
2023-08-16 06:25:08 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-16 06:25:08 | INFO | train | epoch 007 | loss 2.31 | trans_loss 3.498 | nll_loss 1.708 | w2v_ctc_loss 1.267 | task_loss 2.189 | contrastive_loss 0.315 | total 4138.65 | n_correct 2434.83 | ppl 3.27 | accuracy 58.832 | wps 12307.9 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 10309 | lr 0.000139286 | gnorm 0.558 | clip 0 | loss_scale 2 | train_wall 1351 | gb_free 12.8 | wall 9583
2023-08-16 06:25:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 06:25:08 | INFO | fairseq.trainer | begin training epoch 8
2023-08-16 06:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 06:26:40 | INFO | train_inner | epoch 008:     91 / 1474 loss=2.234, trans_loss=3.472, nll_loss=1.671, w2v_ctc_loss=1.217, task_loss=2.358, contrastive_loss=0.231, total=4095.89, n_correct=2456.19, ppl=3.18, accuracy=59.967, wps=7850.9, ups=0.64, wpb=12213.1, bsz=435.6, num_updates=10400, lr=0.000138675, gnorm=0.458, clip=0, loss_scale=2, train_wall=91, gb_free=17.5, wall=9675
2023-08-16 06:28:11 | INFO | train_inner | epoch 008:    191 / 1474 loss=2.229, trans_loss=3.462, nll_loss=1.658, w2v_ctc_loss=1.206, task_loss=2.374, contrastive_loss=0.254, total=4040.13, n_correct=2433.17, ppl=3.16, accuracy=60.225, wps=13160.3, ups=1.09, wpb=12049.1, bsz=429, num_updates=10500, lr=0.000138013, gnorm=0.448, clip=0, loss_scale=2, train_wall=91, gb_free=15.8, wall=9766
2023-08-16 06:29:44 | INFO | train_inner | epoch 008:    291 / 1474 loss=2.226, trans_loss=3.455, nll_loss=1.652, w2v_ctc_loss=1.207, task_loss=2.048, contrastive_loss=0.25, total=4216.54, n_correct=2547.48, ppl=3.14, accuracy=60.416, wps=13584.7, ups=1.08, wpb=12583.3, bsz=489.6, num_updates=10600, lr=0.000137361, gnorm=0.439, clip=0, loss_scale=2, train_wall=92, gb_free=15.8, wall=9859
2023-08-16 06:31:17 | INFO | train_inner | epoch 008:    391 / 1474 loss=2.236, trans_loss=3.459, nll_loss=1.656, w2v_ctc_loss=1.215, task_loss=2.298, contrastive_loss=0.272, total=4134.8, n_correct=2491.05, ppl=3.15, accuracy=60.246, wps=13230.4, ups=1.07, wpb=12337.2, bsz=446.1, num_updates=10700, lr=0.000136717, gnorm=0.434, clip=0, loss_scale=2, train_wall=93, gb_free=16.1, wall=9952
2023-08-16 06:32:50 | INFO | train_inner | epoch 008:    491 / 1474 loss=2.289, trans_loss=3.455, nll_loss=1.654, w2v_ctc_loss=1.193, task_loss=1.982, contrastive_loss=0.538, total=4193.98, n_correct=2529.53, ppl=3.15, accuracy=60.313, wps=13506.3, ups=1.08, wpb=12521.7, bsz=500.7, num_updates=10800, lr=0.000136083, gnorm=0.445, clip=0, loss_scale=2, train_wall=92, gb_free=17.5, wall=10045
2023-08-16 06:34:22 | INFO | train_inner | epoch 008:    591 / 1474 loss=2.221, trans_loss=3.454, nll_loss=1.655, w2v_ctc_loss=1.219, task_loss=2.402, contrastive_loss=0.202, total=4063.58, n_correct=2445.19, ppl=3.15, accuracy=60.173, wps=13157.7, ups=1.08, wpb=12147.8, bsz=426.8, num_updates=10900, lr=0.000135457, gnorm=0.441, clip=0, loss_scale=2, train_wall=92, gb_free=12.1, wall=10137
2023-08-16 06:35:55 | INFO | train_inner | epoch 008:    691 / 1474 loss=2.21, trans_loss=3.448, nll_loss=1.644, w2v_ctc_loss=1.208, task_loss=2.244, contrastive_loss=0.216, total=4138.77, n_correct=2513.54, ppl=3.13, accuracy=60.732, wps=13352.8, ups=1.08, wpb=12354.5, bsz=450.4, num_updates=11000, lr=0.00013484, gnorm=0.43, clip=0, loss_scale=4, train_wall=92, gb_free=16.3, wall=10230
2023-08-16 06:37:27 | INFO | train_inner | epoch 008:    791 / 1474 loss=2.221, trans_loss=3.445, nll_loss=1.643, w2v_ctc_loss=1.198, task_loss=2.239, contrastive_loss=0.302, total=4122.32, n_correct=2496.78, ppl=3.12, accuracy=60.567, wps=13364.2, ups=1.08, wpb=12319.9, bsz=449, num_updates=11100, lr=0.000134231, gnorm=0.455, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=10322
2023-08-16 06:38:59 | INFO | train_inner | epoch 008:    891 / 1474 loss=2.221, trans_loss=3.449, nll_loss=1.647, w2v_ctc_loss=1.185, task_loss=2.083, contrastive_loss=0.313, total=4180.85, n_correct=2536.45, ppl=3.13, accuracy=60.668, wps=13518.2, ups=1.08, wpb=12485.3, bsz=477, num_updates=11200, lr=0.000133631, gnorm=0.439, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=10414
2023-08-16 06:40:31 | INFO | train_inner | epoch 008:    991 / 1474 loss=2.187, trans_loss=3.445, nll_loss=1.641, w2v_ctc_loss=1.185, task_loss=2.122, contrastive_loss=0.205, total=4145.35, n_correct=2525.07, ppl=3.12, accuracy=60.913, wps=13554.6, ups=1.1, wpb=12377.4, bsz=460.4, num_updates=11300, lr=0.000133038, gnorm=0.417, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=10506
2023-08-16 06:42:03 | INFO | train_inner | epoch 008:   1091 / 1474 loss=2.234, trans_loss=3.448, nll_loss=1.644, w2v_ctc_loss=1.185, task_loss=2.182, contrastive_loss=0.428, total=4191.42, n_correct=2545.53, ppl=3.13, accuracy=60.732, wps=13466.9, ups=1.08, wpb=12511.3, bsz=464.9, num_updates=11400, lr=0.000132453, gnorm=0.43, clip=0, loss_scale=4, train_wall=92, gb_free=17.3, wall=10598
2023-08-16 06:43:35 | INFO | train_inner | epoch 008:   1191 / 1474 loss=2.195, trans_loss=3.441, nll_loss=1.637, w2v_ctc_loss=1.19, task_loss=2.069, contrastive_loss=0.217, total=4187.13, n_correct=2546.74, ppl=3.11, accuracy=60.823, wps=13620.1, ups=1.09, wpb=12506.2, bsz=474, num_updates=11500, lr=0.000131876, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=12.8, wall=10690
2023-08-16 06:45:07 | INFO | train_inner | epoch 008:   1291 / 1474 loss=2.2, trans_loss=3.445, nll_loss=1.641, w2v_ctc_loss=1.196, task_loss=2.309, contrastive_loss=0.237, total=4055.06, n_correct=2458.72, ppl=3.12, accuracy=60.633, wps=13253, ups=1.09, wpb=12112.2, bsz=434.6, num_updates=11600, lr=0.000131306, gnorm=0.435, clip=0, loss_scale=4, train_wall=91, gb_free=16.2, wall=10782
2023-08-16 06:46:38 | INFO | train_inner | epoch 008:   1391 / 1474 loss=2.211, trans_loss=3.445, nll_loss=1.642, w2v_ctc_loss=1.182, task_loss=2.105, contrastive_loss=0.307, total=4166, n_correct=2538.39, ppl=3.12, accuracy=60.931, wps=13583.9, ups=1.09, wpb=12439.6, bsz=471.7, num_updates=11700, lr=0.000130744, gnorm=0.443, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=10873
2023-08-16 06:47:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 06:48:18 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.111 | trans_loss 5.301 | nll_loss 2.601 | w2v_ctc_loss 1.421 | task_loss 11.414 | contrastive_loss 0.378 | total 4003.4 | n_correct 2567.9 | ppl 6.07 | accuracy 64.143 | uer 20.832 | wer 22.825 | raw_wer 22.825 | bleu 19.96 | wps 2117.4 | wpb 4003.4 | bsz 141.8 | num_updates 11783 | best_bleu 19.96
2023-08-16 06:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11783 updates
2023-08-16 06:48:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:48:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 06:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 8 @ 11783 updates, score 19.96) (writing took 30.374866975471377 seconds)
2023-08-16 06:48:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-16 06:48:49 | INFO | train | epoch 008 | loss 2.221 | trans_loss 3.451 | nll_loss 1.648 | w2v_ctc_loss 1.197 | task_loss 2.191 | contrastive_loss 0.289 | total 4138.65 | n_correct 2506.19 | ppl 3.13 | accuracy 60.556 | wps 12819 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 11783 | lr 0.000130283 | gnorm 0.438 | clip 0 | loss_scale 4 | train_wall 1348 | gb_free 16.6 | wall 11004
2023-08-16 06:48:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 06:48:49 | INFO | fairseq.trainer | begin training epoch 9
2023-08-16 06:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 06:49:13 | INFO | train_inner | epoch 009:     17 / 1474 loss=2.205, trans_loss=3.439, nll_loss=1.632, w2v_ctc_loss=1.166, task_loss=2.161, contrastive_loss=0.399, total=4113.19, n_correct=2512.79, ppl=3.1, accuracy=61.091, wps=7943.4, ups=0.65, wpb=12275.6, bsz=463.4, num_updates=11800, lr=0.000130189, gnorm=0.421, clip=0, loss_scale=4, train_wall=91, gb_free=17.5, wall=11028
2023-08-16 06:50:45 | INFO | train_inner | epoch 009:    117 / 1474 loss=2.151, trans_loss=3.413, nll_loss=1.601, w2v_ctc_loss=1.145, task_loss=2.053, contrastive_loss=0.233, total=4192.68, n_correct=2590.15, ppl=3.03, accuracy=61.778, wps=13628.8, ups=1.09, wpb=12520.8, bsz=481.1, num_updates=11900, lr=0.000129641, gnorm=0.423, clip=0, loss_scale=4, train_wall=91, gb_free=15.5, wall=11120
2023-08-16 06:52:17 | INFO | train_inner | epoch 009:    217 / 1474 loss=2.137, trans_loss=3.418, nll_loss=1.606, w2v_ctc_loss=1.145, task_loss=2.374, contrastive_loss=0.184, total=4065.4, n_correct=2510.43, ppl=3.04, accuracy=61.751, wps=13104.7, ups=1.08, wpb=12138.7, bsz=429.9, num_updates=12000, lr=0.000129099, gnorm=0.433, clip=0, loss_scale=4, train_wall=92, gb_free=15.7, wall=11212
2023-08-16 06:52:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 06:52:41 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.101 | trans_loss 5.304 | nll_loss 2.605 | w2v_ctc_loss 1.387 | task_loss 11.361 | contrastive_loss 0.372 | total 4003.4 | n_correct 2564.3 | ppl 6.08 | accuracy 64.053 | uer 21.044 | wer 23.116 | raw_wer 23.116 | bleu 20.03 | wps 2185 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.03
2023-08-16 06:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-16 06:52:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_9_12000.pt
2023-08-16 06:52:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_9_12000.pt
2023-08-16 06:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.03) (writing took 30.898704547435045 seconds)
2023-08-16 06:54:44 | INFO | train_inner | epoch 009:    317 / 1474 loss=2.137, trans_loss=3.406, nll_loss=1.592, w2v_ctc_loss=1.129, task_loss=2.041, contrastive_loss=0.241, total=4152.87, n_correct=2577.62, ppl=3.02, accuracy=62.068, wps=8456.2, ups=0.68, wpb=12408.5, bsz=479.2, num_updates=12100, lr=0.000128565, gnorm=0.43, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=11359
2023-08-16 06:56:17 | INFO | train_inner | epoch 009:    417 / 1474 loss=2.14, trans_loss=3.422, nll_loss=1.611, w2v_ctc_loss=1.14, task_loss=2.171, contrastive_loss=0.203, total=4191.41, n_correct=2580.64, ppl=3.05, accuracy=61.57, wps=13440.1, ups=1.07, wpb=12514.6, bsz=464.1, num_updates=12200, lr=0.000128037, gnorm=0.421, clip=0, loss_scale=4, train_wall=93, gb_free=13.7, wall=11452
2023-08-16 06:57:48 | INFO | train_inner | epoch 009:    517 / 1474 loss=2.167, trans_loss=3.42, nll_loss=1.608, w2v_ctc_loss=1.164, task_loss=2.292, contrastive_loss=0.252, total=4119.12, n_correct=2538.09, ppl=3.05, accuracy=61.617, wps=13489.4, ups=1.1, wpb=12295.1, bsz=438.8, num_updates=12300, lr=0.000127515, gnorm=0.433, clip=0, loss_scale=4, train_wall=90, gb_free=16.4, wall=11543
2023-08-16 06:59:20 | INFO | train_inner | epoch 009:    617 / 1474 loss=2.153, trans_loss=3.413, nll_loss=1.602, w2v_ctc_loss=1.133, task_loss=2.195, contrastive_loss=0.307, total=4140.76, n_correct=2557.19, ppl=3.04, accuracy=61.757, wps=13458.3, ups=1.09, wpb=12374.8, bsz=463.2, num_updates=12400, lr=0.000127, gnorm=0.434, clip=0, loss_scale=4, train_wall=91, gb_free=15.2, wall=11635
2023-08-16 07:00:51 | INFO | train_inner | epoch 009:    717 / 1474 loss=2.143, trans_loss=3.418, nll_loss=1.608, w2v_ctc_loss=1.154, task_loss=2.272, contrastive_loss=0.198, total=4075.27, n_correct=2513.68, ppl=3.05, accuracy=61.681, wps=13364.6, ups=1.1, wpb=12176.3, bsz=443.7, num_updates=12500, lr=0.000126491, gnorm=0.432, clip=0, loss_scale=4, train_wall=91, gb_free=16.7, wall=11726
2023-08-16 07:02:25 | INFO | train_inner | epoch 009:    817 / 1474 loss=2.206, trans_loss=3.413, nll_loss=1.603, w2v_ctc_loss=1.146, task_loss=1.988, contrastive_loss=0.446, total=4215.48, n_correct=2602.96, ppl=3.04, accuracy=61.748, wps=13478.7, ups=1.07, wpb=12596.2, bsz=499.7, num_updates=12600, lr=0.000125988, gnorm=0.433, clip=0, loss_scale=4, train_wall=93, gb_free=16.6, wall=11820
2023-08-16 07:03:58 | INFO | train_inner | epoch 009:    917 / 1474 loss=2.174, trans_loss=3.416, nll_loss=1.602, w2v_ctc_loss=1.139, task_loss=2.258, contrastive_loss=0.416, total=4152.4, n_correct=2567.31, ppl=3.03, accuracy=61.827, wps=13302.7, ups=1.07, wpb=12388.2, bsz=450.8, num_updates=12700, lr=0.000125491, gnorm=0.419, clip=0, loss_scale=4, train_wall=93, gb_free=11.5, wall=11913
2023-08-16 07:05:30 | INFO | train_inner | epoch 009:   1017 / 1474 loss=2.138, trans_loss=3.422, nll_loss=1.611, w2v_ctc_loss=1.146, task_loss=2.444, contrastive_loss=0.199, total=4101.32, n_correct=2527.84, ppl=3.05, accuracy=61.635, wps=13305.9, ups=1.09, wpb=12242.4, bsz=424.9, num_updates=12800, lr=0.000125, gnorm=0.428, clip=0, loss_scale=4, train_wall=91, gb_free=15.5, wall=12005
2023-08-16 07:07:02 | INFO | train_inner | epoch 009:   1117 / 1474 loss=2.137, trans_loss=3.419, nll_loss=1.604, w2v_ctc_loss=1.137, task_loss=2.08, contrastive_loss=0.22, total=4172.83, n_correct=2586.7, ppl=3.04, accuracy=61.989, wps=13584.5, ups=1.09, wpb=12437.9, bsz=471.9, num_updates=12900, lr=0.000124515, gnorm=0.438, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=12097
2023-08-16 07:08:35 | INFO | train_inner | epoch 009:   1217 / 1474 loss=2.142, trans_loss=3.417, nll_loss=1.606, w2v_ctc_loss=1.153, task_loss=2.311, contrastive_loss=0.204, total=4138.15, n_correct=2553.81, ppl=3.04, accuracy=61.714, wps=13279.9, ups=1.07, wpb=12357.2, bsz=448.8, num_updates=13000, lr=0.000124035, gnorm=0.447, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=12190
2023-08-16 07:10:07 | INFO | train_inner | epoch 009:   1317 / 1474 loss=2.164, trans_loss=3.409, nll_loss=1.594, w2v_ctc_loss=1.128, task_loss=2.005, contrastive_loss=0.391, total=4205.27, n_correct=2613.04, ppl=3.02, accuracy=62.137, wps=13636.1, ups=1.09, wpb=12548.1, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=0.419, clip=0, loss_scale=8, train_wall=91, gb_free=16.4, wall=12282
2023-08-16 07:11:37 | INFO | train_inner | epoch 009:   1417 / 1474 loss=2.127, trans_loss=3.423, nll_loss=1.611, w2v_ctc_loss=1.141, task_loss=2.36, contrastive_loss=0.176, total=4071.37, n_correct=2515.56, ppl=3.06, accuracy=61.787, wps=13376.9, ups=1.1, wpb=12147.5, bsz=429, num_updates=13200, lr=0.000123091, gnorm=0.422, clip=0, loss_scale=8, train_wall=90, gb_free=14.5, wall=12372
2023-08-16 07:12:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 07:12:51 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.064 | trans_loss 5.27 | nll_loss 2.569 | w2v_ctc_loss 1.354 | task_loss 11.46 | contrastive_loss 0.366 | total 4003.4 | n_correct 2590.1 | ppl 5.94 | accuracy 64.698 | uer 20.012 | wer 21.752 | raw_wer 21.752 | bleu 20.17 | wps 2278 | wpb 4003.4 | bsz 141.8 | num_updates 13257 | best_bleu 20.17
2023-08-16 07:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13257 updates
2023-08-16 07:12:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 07:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 07:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 9 @ 13257 updates, score 20.17) (writing took 31.83903350867331 seconds)
2023-08-16 07:13:24 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-16 07:13:24 | INFO | train | epoch 009 | loss 2.151 | trans_loss 3.416 | nll_loss 1.604 | w2v_ctc_loss 1.143 | task_loss 2.193 | contrastive_loss 0.268 | total 4138.65 | n_correct 2557.81 | ppl 3.04 | accuracy 61.803 | wps 12346.2 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 13257 | lr 0.000122827 | gnorm 0.429 | clip 0 | loss_scale 8 | train_wall 1348 | gb_free 11.2 | wall 12479
2023-08-16 07:13:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 07:13:24 | INFO | fairseq.trainer | begin training epoch 10
2023-08-16 07:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 07:14:12 | INFO | train_inner | epoch 010:     43 / 1474 loss=2.126, trans_loss=3.404, nll_loss=1.588, w2v_ctc_loss=1.116, task_loss=2.051, contrastive_loss=0.274, total=4113.02, n_correct=2564.98, ppl=3.01, accuracy=62.362, wps=7963.6, ups=0.65, wpb=12276.4, bsz=475.9, num_updates=13300, lr=0.000122628, gnorm=0.423, clip=0, loss_scale=8, train_wall=90, gb_free=16.1, wall=12527
2023-08-16 07:15:44 | INFO | train_inner | epoch 010:    143 / 1474 loss=2.08, trans_loss=3.388, nll_loss=1.568, w2v_ctc_loss=1.09, task_loss=2.112, contrastive_loss=0.195, total=4234.99, n_correct=2660.12, ppl=2.97, accuracy=62.813, wps=13710.8, ups=1.08, wpb=12647.2, bsz=473.2, num_updates=13400, lr=0.000122169, gnorm=0.408, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=12619
2023-08-16 07:17:16 | INFO | train_inner | epoch 010:    243 / 1474 loss=2.107, trans_loss=3.384, nll_loss=1.561, w2v_ctc_loss=1.095, task_loss=2.154, contrastive_loss=0.316, total=4131.11, n_correct=2596.28, ppl=2.95, accuracy=62.847, wps=13429.5, ups=1.09, wpb=12328.7, bsz=463.9, num_updates=13500, lr=0.000121716, gnorm=0.414, clip=0, loss_scale=8, train_wall=91, gb_free=15.9, wall=12711
2023-08-16 07:18:48 | INFO | train_inner | epoch 010:    343 / 1474 loss=2.086, trans_loss=3.385, nll_loss=1.567, w2v_ctc_loss=1.09, task_loss=2.218, contrastive_loss=0.229, total=4135.65, n_correct=2593.88, ppl=2.96, accuracy=62.72, wps=13417.3, ups=1.09, wpb=12362.4, bsz=454, num_updates=13600, lr=0.000121268, gnorm=0.416, clip=0, loss_scale=8, train_wall=91, gb_free=15.4, wall=12803
2023-08-16 07:20:21 | INFO | train_inner | epoch 010:    443 / 1474 loss=2.11, trans_loss=3.388, nll_loss=1.568, w2v_ctc_loss=1.077, task_loss=2.103, contrastive_loss=0.4, total=4199.14, n_correct=2635.07, ppl=2.97, accuracy=62.753, wps=13491.9, ups=1.08, wpb=12535.9, bsz=482.3, num_updates=13700, lr=0.000120824, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=16.6, wall=12896
2023-08-16 07:21:53 | INFO | train_inner | epoch 010:    543 / 1474 loss=2.095, trans_loss=3.399, nll_loss=1.579, w2v_ctc_loss=1.115, task_loss=2.393, contrastive_loss=0.181, total=4094.23, n_correct=2557.05, ppl=2.99, accuracy=62.455, wps=13183.1, ups=1.08, wpb=12209.6, bsz=433.2, num_updates=13800, lr=0.000120386, gnorm=0.418, clip=0, loss_scale=8, train_wall=92, gb_free=14, wall=12988
2023-08-16 07:23:26 | INFO | train_inner | epoch 010:    643 / 1474 loss=2.113, trans_loss=3.393, nll_loss=1.573, w2v_ctc_loss=1.101, task_loss=2.055, contrastive_loss=0.301, total=4182.84, n_correct=2622.55, ppl=2.98, accuracy=62.698, wps=13444.7, ups=1.08, wpb=12481.2, bsz=481.3, num_updates=13900, lr=0.000119952, gnorm=0.418, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13081
2023-08-16 07:24:57 | INFO | train_inner | epoch 010:    743 / 1474 loss=2.095, trans_loss=3.391, nll_loss=1.572, w2v_ctc_loss=1.117, task_loss=2.208, contrastive_loss=0.179, total=4120.62, n_correct=2582.11, ppl=2.97, accuracy=62.663, wps=13519, ups=1.1, wpb=12301.2, bsz=451.7, num_updates=14000, lr=0.000119523, gnorm=0.423, clip=0, loss_scale=8, train_wall=90, gb_free=16.6, wall=13172
2023-08-16 07:24:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 07:25:20 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.075 | trans_loss 5.256 | nll_loss 2.544 | w2v_ctc_loss 1.426 | task_loss 11.506 | contrastive_loss 0.363 | total 4003.4 | n_correct 2601.4 | ppl 5.83 | accuracy 64.98 | uer 20.301 | wer 22.061 | raw_wer 22.061 | bleu 20.79 | wps 2202.1 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 20.79
2023-08-16 07:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-16 07:25:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_10_14000.pt
2023-08-16 07:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_10_14000.pt
2023-08-16 07:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 20.79) (writing took 54.28392775915563 seconds)
2023-08-16 07:27:49 | INFO | train_inner | epoch 010:    843 / 1474 loss=2.074, trans_loss=3.389, nll_loss=1.57, w2v_ctc_loss=1.092, task_loss=2.16, contrastive_loss=0.182, total=4132.62, n_correct=2592.96, ppl=2.97, accuracy=62.744, wps=7193.8, ups=0.58, wpb=12339.2, bsz=457.4, num_updates=14100, lr=0.000119098, gnorm=0.409, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13344
2023-08-16 07:29:20 | INFO | train_inner | epoch 010:    943 / 1474 loss=2.09, trans_loss=3.389, nll_loss=1.567, w2v_ctc_loss=1.099, task_loss=2.108, contrastive_loss=0.22, total=4160.84, n_correct=2611.25, ppl=2.96, accuracy=62.758, wps=13572.1, ups=1.09, wpb=12411.3, bsz=467.9, num_updates=14200, lr=0.000118678, gnorm=0.416, clip=0, loss_scale=8, train_wall=90, gb_free=15.5, wall=13435
2023-08-16 07:30:53 | INFO | train_inner | epoch 010:   1043 / 1474 loss=2.083, trans_loss=3.389, nll_loss=1.57, w2v_ctc_loss=1.101, task_loss=2.399, contrastive_loss=0.193, total=4059.22, n_correct=2543.46, ppl=2.97, accuracy=62.659, wps=13116.7, ups=1.08, wpb=12120, bsz=431.2, num_updates=14300, lr=0.000118262, gnorm=0.428, clip=0, loss_scale=8, train_wall=91, gb_free=9.1, wall=13528
2023-08-16 07:32:24 | INFO | train_inner | epoch 010:   1143 / 1474 loss=2.087, trans_loss=3.396, nll_loss=1.578, w2v_ctc_loss=1.111, task_loss=2.44, contrastive_loss=0.173, total=4045.82, n_correct=2526.99, ppl=2.99, accuracy=62.459, wps=13226.2, ups=1.09, wpb=12079.3, bsz=422.8, num_updates=14400, lr=0.000117851, gnorm=0.417, clip=0, loss_scale=8, train_wall=91, gb_free=12.5, wall=13619
2023-08-16 07:33:56 | INFO | train_inner | epoch 010:   1243 / 1474 loss=2.081, trans_loss=3.381, nll_loss=1.563, w2v_ctc_loss=1.109, task_loss=2.239, contrastive_loss=0.171, total=4107.6, n_correct=2579.92, ppl=2.96, accuracy=62.808, wps=13300.5, ups=1.08, wpb=12284.6, bsz=446.5, num_updates=14500, lr=0.000117444, gnorm=0.453, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=13711
2023-08-16 07:35:28 | INFO | train_inner | epoch 010:   1343 / 1474 loss=2.08, trans_loss=3.389, nll_loss=1.57, w2v_ctc_loss=1.103, task_loss=2.238, contrastive_loss=0.182, total=4127.69, n_correct=2591.18, ppl=2.97, accuracy=62.776, wps=13393.8, ups=1.09, wpb=12326.4, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=0.426, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=13803
2023-08-16 07:37:01 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.132, trans_loss=3.396, nll_loss=1.577, w2v_ctc_loss=1.079, task_loss=2.065, contrastive_loss=0.432, total=4195.02, n_correct=2628.94, ppl=2.98, accuracy=62.668, wps=13480, ups=1.08, wpb=12514.1, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.411, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=13896
2023-08-16 07:37:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 07:37:53 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.043 | trans_loss 5.243 | nll_loss 2.531 | w2v_ctc_loss 1.365 | task_loss 11.5 | contrastive_loss 0.349 | total 4003.4 | n_correct 2603.5 | ppl 5.78 | accuracy 65.032 | uer 19.133 | wer 20.782 | raw_wer 20.782 | bleu 21.28 | wps 2096 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.28
2023-08-16 07:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-16 07:37:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 07:38:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 07:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 10 @ 14731 updates, score 21.28) (writing took 34.666544331237674 seconds)
2023-08-16 07:38:29 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-16 07:38:29 | INFO | train | epoch 010 | loss 2.095 | trans_loss 3.39 | nll_loss 1.57 | w2v_ctc_loss 1.097 | task_loss 2.194 | contrastive_loss 0.251 | total 4138.65 | n_correct 2595.3 | ppl 2.97 | accuracy 62.709 | wps 12104 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14731 | lr 0.00011652 | gnorm 0.419 | clip 0 | loss_scale 8 | train_wall 1348 | gb_free 17 | wall 13984
2023-08-16 07:38:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 07:38:29 | INFO | fairseq.trainer | begin training epoch 11
2023-08-16 07:38:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 07:39:39 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.062, trans_loss=3.368, nll_loss=1.542, w2v_ctc_loss=1.068, task_loss=2.051, contrastive_loss=0.255, total=4166, n_correct=2642.15, ppl=2.91, accuracy=63.422, wps=7884.9, ups=0.63, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.405, clip=0, loss_scale=8, train_wall=90, gb_free=17.6, wall=14054
2023-08-16 07:41:12 | INFO | train_inner | epoch 011:    169 / 1474 loss=2.044, trans_loss=3.369, nll_loss=1.545, w2v_ctc_loss=1.066, task_loss=2.25, contrastive_loss=0.178, total=4100.74, n_correct=2595.89, ppl=2.92, accuracy=63.303, wps=13172.3, ups=1.08, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.424, clip=0, loss_scale=8, train_wall=92, gb_free=14.1, wall=14147
2023-08-16 07:42:44 | INFO | train_inner | epoch 011:    269 / 1474 loss=2.033, trans_loss=3.367, nll_loss=1.541, w2v_ctc_loss=1.062, task_loss=2.267, contrastive_loss=0.162, total=4115.58, n_correct=2610.22, ppl=2.91, accuracy=63.423, wps=13366.5, ups=1.09, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.425, clip=0, loss_scale=8, train_wall=91, gb_free=15.7, wall=14239
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:0')
2023-08-16 07:43:53 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.087, trans_loss=5.005, nll_loss=2.293, w2v_ctc_loss=0.794, task_loss=3.38, contrastive_loss=0.13, total=4094.16, n_correct=2594.72, ppl=4.9, accuracy=63.376, wps=11945, ups=1.45, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=12.4, wall=14308
2023-08-16 07:45:02 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.108, trans_loss=5.039, nll_loss=2.317, w2v_ctc_loss=0.796, task_loss=3.414, contrastive_loss=0.251, total=4112.8, n_correct=2591.25, ppl=4.98, accuracy=63.005, wps=11900.3, ups=1.45, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.554, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=14377
2023-08-16 07:46:12 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.107, trans_loss=5.036, nll_loss=2.313, w2v_ctc_loss=0.803, task_loss=3.547, contrastive_loss=0.246, total=4071.06, n_correct=2571.74, ppl=4.97, accuracy=63.171, wps=11629.3, ups=1.43, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.564, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=14447
2023-08-16 07:47:21 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.106, trans_loss=5.026, nll_loss=2.3, w2v_ctc_loss=0.795, task_loss=3.226, contrastive_loss=0.307, total=4156.4, n_correct=2632.2, ppl=4.93, accuracy=63.329, wps=12015.7, ups=1.45, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.557, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=14516
2023-08-16 07:48:30 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.099, trans_loss=5.039, nll_loss=2.317, w2v_ctc_loss=0.81, task_loss=3.337, contrastive_loss=0.13, total=4169.17, n_correct=2639.25, ppl=4.98, accuracy=63.304, wps=12011.9, ups=1.44, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.561, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=14585
2023-08-16 07:49:39 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.097, trans_loss=5.039, nll_loss=2.317, w2v_ctc_loss=0.805, task_loss=3.454, contrastive_loss=0.119, total=4120.01, n_correct=2600.04, ppl=4.98, accuracy=63.108, wps=11994.2, ups=1.46, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.549, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=14654
2023-08-16 07:50:49 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.094, trans_loss=5.035, nll_loss=2.313, w2v_ctc_loss=0.804, task_loss=3.329, contrastive_loss=0.132, total=4145.45, n_correct=2620.95, ppl=4.97, accuracy=63.225, wps=11936.4, ups=1.44, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.552, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=14724
2023-08-16 07:51:57 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.094, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.804, task_loss=3.228, contrastive_loss=0.15, total=4141.18, n_correct=2624.04, ppl=4.95, accuracy=63.365, wps=12042.2, ups=1.45, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=14792
2023-08-16 07:53:06 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.096, trans_loss=5.038, nll_loss=2.317, w2v_ctc_loss=0.809, task_loss=3.301, contrastive_loss=0.135, total=4173.93, n_correct=2638.31, ppl=4.98, accuracy=63.209, wps=12090.3, ups=1.45, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=14861
2023-08-16 07:54:16 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.101, trans_loss=5.029, nll_loss=2.305, w2v_ctc_loss=0.805, task_loss=3.16, contrastive_loss=0.207, total=4174.26, n_correct=2639.56, ppl=4.94, accuracy=63.234, wps=12081.4, ups=1.45, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=14931
2023-08-16 07:54:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:3')
2023-08-16 07:54:39 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.054 | trans_loss 5.235 | nll_loss 2.52 | w2v_ctc_loss 1.413 | task_loss 11.532 | contrastive_loss 0.357 | total 4003.4 | n_correct 2609.5 | ppl 5.74 | accuracy 65.182 | uer 19.659 | wer 21.42 | raw_wer 21.42 | bleu 20.58 | wps 2134 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.28
2023-08-16 07:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-16 07:54:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_11_16000.pt
2023-08-16 07:54:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_11_16000.pt
2023-08-16 07:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.58) (writing took 41.09884432516992 seconds)
2023-08-16 07:56:31 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.111, trans_loss=5.031, nll_loss=2.308, w2v_ctc_loss=0.793, task_loss=3.034, contrastive_loss=0.364, total=4191.56, n_correct=2654.01, ppl=4.95, accuracy=63.318, wps=6187.2, ups=0.74, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.555, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=15066
2023-08-16 07:57:40 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.088, trans_loss=5.033, nll_loss=2.311, w2v_ctc_loss=0.795, task_loss=3.158, contrastive_loss=0.14, total=4161.81, n_correct=2636.09, ppl=4.96, accuracy=63.34, wps=12004.7, ups=1.44, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.544, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=15135
2023-08-16 07:57:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 07:58:07 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.034 | trans_loss 5.235 | nll_loss 2.519 | w2v_ctc_loss 1.349 | task_loss 11.495 | contrastive_loss 0.351 | total 4003.4 | n_correct 2613.6 | ppl 5.73 | accuracy 65.285 | uer 19.396 | wer 21.185 | raw_wer 21.185 | bleu 21.12 | wps 2196 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.28
2023-08-16 07:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-16 07:58:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.1203.pt
2023-08-16 07:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.1203.pt
2023-08-16 07:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.1203.pt (epoch 11 @ 16205 updates, score 21.12) (writing took 22.946355184540153 seconds)
2023-08-16 07:58:30 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-16 07:58:30 | INFO | train | epoch 011 | loss 2.085 | trans_loss 4.616 | nll_loss 2.118 | w2v_ctc_loss 0.867 | task_loss 3.017 | contrastive_loss 0.188 | total 4138.65 | n_correct 2618.86 | ppl 4.34 | accuracy 63.278 | wps 11071.2 | ups 1.23 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1073 | gb_free 16.9 | wall 15185
2023-08-16 07:58:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 07:58:30 | INFO | fairseq.trainer | begin training epoch 12
2023-08-16 07:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 07:59:43 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.071, trans_loss=4.993, nll_loss=2.258, w2v_ctc_loss=0.783, task_loss=3.172, contrastive_loss=0.169, total=4139.2, n_correct=2653.05, ppl=4.78, accuracy=64.096, wps=6754, ups=0.82, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=15258
2023-08-16 08:00:52 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.073, trans_loss=4.997, nll_loss=2.263, w2v_ctc_loss=0.788, task_loss=3.384, contrastive_loss=0.121, total=4126.87, n_correct=2637.5, ppl=4.8, accuracy=63.91, wps=11975.3, ups=1.45, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=15327
2023-08-16 08:02:01 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.068, trans_loss=4.998, nll_loss=2.266, w2v_ctc_loss=0.773, task_loss=3.073, contrastive_loss=0.151, total=4203.54, n_correct=2690.63, ppl=4.81, accuracy=64.009, wps=12133.5, ups=1.44, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.551, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=15396
2023-08-16 08:03:10 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.071, trans_loss=5.001, nll_loss=2.267, w2v_ctc_loss=0.784, task_loss=3.225, contrastive_loss=0.135, total=4149.28, n_correct=2654.65, ppl=4.81, accuracy=63.979, wps=12023.4, ups=1.45, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=15465
2023-08-16 08:04:19 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.081, trans_loss=5.015, nll_loss=2.287, w2v_ctc_loss=0.793, task_loss=3.318, contrastive_loss=0.142, total=4106.46, n_correct=2618.51, ppl=4.88, accuracy=63.766, wps=11925.9, ups=1.45, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=15534
2023-08-16 08:05:29 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.08, trans_loss=5.002, nll_loss=2.271, w2v_ctc_loss=0.787, task_loss=3.136, contrastive_loss=0.207, total=4190.91, n_correct=2678, ppl=4.83, accuracy=63.9, wps=11955.4, ups=1.43, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.555, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=15604
2023-08-16 08:06:38 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.076, trans_loss=4.998, nll_loss=2.266, w2v_ctc_loss=0.77, task_loss=3.031, contrastive_loss=0.29, total=4203.66, n_correct=2691.48, ppl=4.81, accuracy=64.027, wps=12185.1, ups=1.45, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=15673
2023-08-16 08:07:47 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.07, trans_loss=4.996, nll_loss=2.262, w2v_ctc_loss=0.786, task_loss=3.328, contrastive_loss=0.13, total=4095.72, n_correct=2624.35, ppl=4.8, accuracy=64.075, wps=11875.9, ups=1.45, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=15742
2023-08-16 08:08:56 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.079, trans_loss=5.002, nll_loss=2.271, w2v_ctc_loss=0.785, task_loss=3.372, contrastive_loss=0.184, total=4162.82, n_correct=2661.08, ppl=4.83, accuracy=63.925, wps=12034.8, ups=1.45, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=15811
2023-08-16 08:10:05 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.08, trans_loss=5.006, nll_loss=2.275, w2v_ctc_loss=0.789, task_loss=3.356, contrastive_loss=0.191, total=4117.63, n_correct=2631.21, ppl=4.84, accuracy=63.901, wps=11922.7, ups=1.45, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=15880
2023-08-16 08:11:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 08:11:15 | INFO | train_inner | epoch 012:   1096 / 1474 loss=2.09, trans_loss=5.01, nll_loss=2.281, w2v_ctc_loss=0.792, task_loss=3.45, contrastive_loss=0.235, total=4048, n_correct=2581.63, ppl=4.86, accuracy=63.775, wps=11629.1, ups=1.44, wpb=8096, bsz=289.8, num_updates=17300, lr=0.000107521, gnorm=0.568, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=15950
2023-08-16 08:12:25 | INFO | train_inner | epoch 012:   1196 / 1474 loss=2.095, trans_loss=5.027, nll_loss=2.302, w2v_ctc_loss=0.805, task_loss=3.2, contrastive_loss=0.205, total=4196.85, n_correct=2664.09, ppl=4.93, accuracy=63.478, wps=12070.6, ups=1.44, wpb=8393.7, bsz=319, num_updates=17400, lr=0.000107211, gnorm=0.572, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=16020
2023-08-16 08:13:33 | INFO | train_inner | epoch 012:   1296 / 1474 loss=2.082, trans_loss=5.009, nll_loss=2.279, w2v_ctc_loss=0.806, task_loss=3.689, contrastive_loss=0.116, total=4067.78, n_correct=2592.49, ppl=4.85, accuracy=63.732, wps=11840.6, ups=1.46, wpb=8135.6, bsz=285.5, num_updates=17500, lr=0.000106904, gnorm=0.569, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=16088
2023-08-16 08:14:43 | INFO | train_inner | epoch 012:   1396 / 1474 loss=2.087, trans_loss=5.017, nll_loss=2.291, w2v_ctc_loss=0.789, task_loss=3.312, contrastive_loss=0.221, total=4142.88, n_correct=2635.98, ppl=4.89, accuracy=63.627, wps=11932.3, ups=1.44, wpb=8285.8, bsz=306.2, num_updates=17600, lr=0.0001066, gnorm=0.563, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=16158
2023-08-16 08:15:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 08:16:00 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.022 | trans_loss 5.218 | nll_loss 2.499 | w2v_ctc_loss 1.356 | task_loss 11.49 | contrastive_loss 0.345 | total 4003.4 | n_correct 2625.5 | ppl 5.65 | accuracy 65.582 | uer 18.984 | wer 20.879 | raw_wer 20.879 | bleu 21.22 | wps 2328.3 | wpb 4003.4 | bsz 141.8 | num_updates 17678 | best_bleu 21.28
2023-08-16 08:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17678 updates
2023-08-16 08:16:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.2205.pt
2023-08-16 08:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.2205.pt
2023-08-16 08:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.2205.pt (epoch 12 @ 17678 updates, score 21.22) (writing took 24.7643031347543 seconds)
2023-08-16 08:16:25 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-16 08:16:25 | INFO | train | epoch 012 | loss 2.079 | trans_loss 5.006 | nll_loss 2.275 | w2v_ctc_loss 0.788 | task_loss 3.289 | contrastive_loss 0.176 | total 4138.6 | n_correct 2643.24 | ppl 4.84 | accuracy 63.868 | wps 11345.3 | ups 1.37 | wpb 8277.2 | bsz 305.7 | num_updates 17678 | lr 0.000106365 | gnorm 0.548 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 12.5 | wall 16260
2023-08-16 08:16:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 08:16:25 | INFO | fairseq.trainer | begin training epoch 13
2023-08-16 08:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 08:16:48 | INFO | train_inner | epoch 013:     22 / 1474 loss=2.08, trans_loss=5.013, nll_loss=2.284, w2v_ctc_loss=0.8, task_loss=3.392, contrastive_loss=0.125, total=4097.08, n_correct=2614.31, ppl=4.87, accuracy=63.809, wps=6552.6, ups=0.8, wpb=8194.2, bsz=296.6, num_updates=17700, lr=0.000106299, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=16283
2023-08-16 08:17:57 | INFO | train_inner | epoch 013:    122 / 1474 loss=2.061, trans_loss=4.982, nll_loss=2.243, w2v_ctc_loss=0.774, task_loss=3.315, contrastive_loss=0.138, total=4164.24, n_correct=2680.02, ppl=4.74, accuracy=64.358, wps=11987.3, ups=1.44, wpb=8328.5, bsz=301.9, num_updates=17800, lr=0.000106, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=16352
2023-08-16 08:19:07 | INFO | train_inner | epoch 013:    222 / 1474 loss=2.077, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.769, task_loss=3.05, contrastive_loss=0.35, total=4201.52, n_correct=2703, ppl=4.76, accuracy=64.334, wps=12107, ups=1.44, wpb=8403, bsz=328.5, num_updates=17900, lr=0.000105703, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=12.7, wall=16422
2023-08-16 08:20:16 | INFO | train_inner | epoch 013:    322 / 1474 loss=2.054, trans_loss=4.973, nll_loss=2.232, w2v_ctc_loss=0.769, task_loss=3.42, contrastive_loss=0.121, total=4102.53, n_correct=2651.55, ppl=4.7, accuracy=64.632, wps=11803.2, ups=1.44, wpb=8205.1, bsz=293.9, num_updates=18000, lr=0.000105409, gnorm=0.563, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=16491
2023-08-16 08:20:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 08:20:40 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.02 | trans_loss 5.22 | nll_loss 2.5 | w2v_ctc_loss 1.342 | task_loss 11.462 | contrastive_loss 0.348 | total 4003.4 | n_correct 2620.8 | ppl 5.66 | accuracy 65.464 | uer 19.069 | wer 20.92 | raw_wer 20.92 | bleu 21.03 | wps 2202.3 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.28
2023-08-16 08:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-16 08:20:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_13_18000.pt
2023-08-16 08:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_13_18000.pt
2023-08-16 08:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.03) (writing took 40.45241045765579 seconds)
2023-08-16 08:22:32 | INFO | train_inner | epoch 013:    422 / 1474 loss=2.057, trans_loss=4.977, nll_loss=2.238, w2v_ctc_loss=0.77, task_loss=3.057, contrastive_loss=0.171, total=4190.45, n_correct=2704.24, ppl=4.72, accuracy=64.533, wps=6164.4, ups=0.74, wpb=8380.9, bsz=320.3, num_updates=18100, lr=0.000105118, gnorm=0.549, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=16627
2023-08-16 08:23:42 | INFO | train_inner | epoch 013:    522 / 1474 loss=2.064, trans_loss=4.984, nll_loss=2.247, w2v_ctc_loss=0.775, task_loss=3.18, contrastive_loss=0.203, total=4194.45, n_correct=2695.03, ppl=4.75, accuracy=64.252, wps=12037.3, ups=1.43, wpb=8388.9, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=16697
2023-08-16 08:24:51 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.05, trans_loss=4.979, nll_loss=2.241, w2v_ctc_loss=0.768, task_loss=3.217, contrastive_loss=0.116, total=4158.04, n_correct=2685.36, ppl=4.73, accuracy=64.582, wps=12054.5, ups=1.45, wpb=8316.1, bsz=306.7, num_updates=18300, lr=0.000104542, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=16766
2023-08-16 08:26:01 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.07, trans_loss=4.988, nll_loss=2.251, w2v_ctc_loss=0.797, task_loss=3.644, contrastive_loss=0.119, total=4099.91, n_correct=2632.73, ppl=4.76, accuracy=64.214, wps=11764.7, ups=1.43, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.584, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=16836
2023-08-16 08:27:10 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.066, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.776, task_loss=3.335, contrastive_loss=0.166, total=4122.78, n_correct=2647.15, ppl=4.76, accuracy=64.208, wps=11888.1, ups=1.44, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.555, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=16905
2023-08-16 08:28:19 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.057, trans_loss=4.982, nll_loss=2.245, w2v_ctc_loss=0.774, task_loss=3.359, contrastive_loss=0.127, total=4102.59, n_correct=2644.48, ppl=4.74, accuracy=64.459, wps=11916.1, ups=1.45, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=16974
2023-08-16 08:29:27 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.072, trans_loss=4.989, nll_loss=2.253, w2v_ctc_loss=0.786, task_loss=3.491, contrastive_loss=0.18, total=4087.8, n_correct=2624.8, ppl=4.77, accuracy=64.211, wps=11954.9, ups=1.46, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=17042
2023-08-16 08:30:36 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.054, trans_loss=4.975, nll_loss=2.235, w2v_ctc_loss=0.769, task_loss=3.264, contrastive_loss=0.158, total=4098.77, n_correct=2645.52, ppl=4.71, accuracy=64.544, wps=11852.5, ups=1.45, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=13.3, wall=17111
2023-08-16 08:31:46 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.062, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.782, task_loss=3.486, contrastive_loss=0.119, total=4115.57, n_correct=2645.97, ppl=4.76, accuracy=64.292, wps=11865.5, ups=1.44, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=17181
2023-08-16 08:32:55 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.067, trans_loss=4.98, nll_loss=2.242, w2v_ctc_loss=0.779, task_loss=3.26, contrastive_loss=0.218, total=4111.02, n_correct=2651.33, ppl=4.73, accuracy=64.493, wps=11903.3, ups=1.45, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.592, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=17250
2023-08-16 08:34:04 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.068, trans_loss=4.985, nll_loss=2.249, w2v_ctc_loss=0.773, task_loss=3.231, contrastive_loss=0.225, total=4179.06, n_correct=2690.21, ppl=4.75, accuracy=64.374, wps=12103.4, ups=1.45, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=17319
2023-08-16 08:34:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 08:35:03 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.01 | trans_loss 5.207 | nll_loss 2.481 | w2v_ctc_loss 1.348 | task_loss 11.546 | contrastive_loss 0.345 | total 4003.4 | n_correct 2627.4 | ppl 5.58 | accuracy 65.629 | uer 18.992 | wer 20.726 | raw_wer 20.726 | bleu 21.55 | wps 2143.6 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 21.55
2023-08-16 08:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-16 08:35:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 08:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 08:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 13 @ 19152 updates, score 21.55) (writing took 30.35535119473934 seconds)
2023-08-16 08:35:34 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-16 08:35:34 | INFO | train | epoch 013 | loss 2.062 | trans_loss 4.982 | nll_loss 2.244 | w2v_ctc_loss 0.776 | task_loss 3.291 | contrastive_loss 0.172 | total 4138.65 | n_correct 2665.55 | ppl 4.74 | accuracy 64.406 | wps 10618 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 1011 | gb_free 17.4 | wall 17409
2023-08-16 08:35:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 08:35:34 | INFO | fairseq.trainer | begin training epoch 14
2023-08-16 08:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 08:36:15 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.04, trans_loss=4.955, nll_loss=2.211, w2v_ctc_loss=0.762, task_loss=3.023, contrastive_loss=0.132, total=4179.66, n_correct=2716.48, ppl=4.63, accuracy=64.993, wps=6355, ups=0.76, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=10.1, wall=17450
2023-08-16 08:37:24 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.034, trans_loss=4.944, nll_loss=2.195, w2v_ctc_loss=0.761, task_loss=3.299, contrastive_loss=0.114, total=4081.01, n_correct=2659.64, ppl=4.58, accuracy=65.171, wps=11874, ups=1.45, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=17519
2023-08-16 08:38:33 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.053, trans_loss=4.963, nll_loss=2.219, w2v_ctc_loss=0.763, task_loss=3.437, contrastive_loss=0.213, total=4109.83, n_correct=2665.22, ppl=4.66, accuracy=64.85, wps=11977.2, ups=1.46, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=17588
2023-08-16 08:38:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 08:39:42 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.044, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.759, task_loss=3.139, contrastive_loss=0.147, total=4154.06, n_correct=2695.6, ppl=4.66, accuracy=64.891, wps=11925.3, ups=1.44, wpb=8308.1, bsz=314.4, num_updates=19500, lr=0.000101274, gnorm=0.56, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=17658
2023-08-16 08:40:52 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.041, trans_loss=4.962, nll_loss=2.219, w2v_ctc_loss=0.756, task_loss=3.242, contrastive_loss=0.132, total=4155.83, n_correct=2697.53, ppl=4.66, accuracy=64.91, wps=12012.4, ups=1.45, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=17727
2023-08-16 08:42:01 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.057, trans_loss=4.967, nll_loss=2.224, w2v_ctc_loss=0.783, task_loss=3.578, contrastive_loss=0.126, total=4064.87, n_correct=2626.24, ppl=4.67, accuracy=64.608, wps=11763.7, ups=1.45, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=17796
2023-08-16 08:43:10 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.054, trans_loss=4.966, nll_loss=2.223, w2v_ctc_loss=0.766, task_loss=3.267, contrastive_loss=0.19, total=4167.34, n_correct=2700.26, ppl=4.67, accuracy=64.796, wps=12032.8, ups=1.44, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.549, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=17865
2023-08-16 08:44:19 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.043, trans_loss=4.953, nll_loss=2.208, w2v_ctc_loss=0.769, task_loss=3.232, contrastive_loss=0.123, total=4142.94, n_correct=2690, ppl=4.62, accuracy=64.93, wps=12011.6, ups=1.45, wpb=8285.9, bsz=308.6, num_updates=19900, lr=0.000100251, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=17934
2023-08-16 08:45:29 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.053, trans_loss=4.956, nll_loss=2.212, w2v_ctc_loss=0.761, task_loss=3.141, contrastive_loss=0.232, total=4173.06, n_correct=2705.71, ppl=4.63, accuracy=64.838, wps=12002.9, ups=1.44, wpb=8346.1, bsz=319.1, num_updates=20000, lr=0.0001, gnorm=0.567, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=18004
2023-08-16 08:45:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 08:45:53 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.018 | trans_loss 5.197 | nll_loss 2.47 | w2v_ctc_loss 1.397 | task_loss 11.58 | contrastive_loss 0.349 | total 4003.4 | n_correct 2641.2 | ppl 5.54 | accuracy 65.974 | uer 19.04 | wer 20.998 | raw_wer 20.998 | bleu 21.43 | wps 2041.6 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.55
2023-08-16 08:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-16 08:45:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_14_20000.pt
2023-08-16 08:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_14_20000.pt
2023-08-16 08:46:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.43) (writing took 42.777806585654616 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:0')
2023-08-16 08:47:47 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.049, trans_loss=4.963, nll_loss=2.22, w2v_ctc_loss=0.761, task_loss=3.281, contrastive_loss=0.169, total=4166.71, n_correct=2696.83, ppl=4.66, accuracy=64.723, wps=6004, ups=0.72, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=18142
2023-08-16 08:48:57 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.049, trans_loss=4.964, nll_loss=2.222, w2v_ctc_loss=0.764, task_loss=3.343, contrastive_loss=0.147, total=4145.57, n_correct=2688.45, ppl=4.67, accuracy=64.851, wps=11945.1, ups=1.44, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=18212
2023-08-16 08:50:06 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.076, trans_loss=4.966, nll_loss=2.224, w2v_ctc_loss=0.772, task_loss=3.103, contrastive_loss=0.415, total=4219.9, n_correct=2730.57, ppl=4.67, accuracy=64.707, wps=12161.9, ups=1.44, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=18281
2023-08-16 08:51:15 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.053, trans_loss=4.97, nll_loss=2.228, w2v_ctc_loss=0.781, task_loss=3.816, contrastive_loss=0.104, total=4032.06, n_correct=2606.47, ppl=4.69, accuracy=64.644, wps=11702.1, ups=1.45, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=18350
2023-08-16 08:52:24 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.041, trans_loss=4.963, nll_loss=2.221, w2v_ctc_loss=0.761, task_loss=3.127, contrastive_loss=0.121, total=4205.07, n_correct=2728.44, ppl=4.66, accuracy=64.885, wps=12144.1, ups=1.44, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18419
2023-08-16 08:53:33 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.048, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.762, task_loss=3.291, contrastive_loss=0.158, total=4126.44, n_correct=2673.77, ppl=4.68, accuracy=64.796, wps=11992, ups=1.45, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=18488
2023-08-16 08:53:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:1')
2023-08-16 08:54:13 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.001 | trans_loss 5.196 | nll_loss 2.468 | w2v_ctc_loss 1.348 | task_loss 11.495 | contrastive_loss 0.336 | total 4003.4 | n_correct 2642.6 | ppl 5.53 | accuracy 66.009 | uer 18.87 | wer 20.708 | raw_wer 20.708 | bleu 21.36 | wps 2254 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.55
2023-08-16 08:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-16 08:54:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.3601.pt
2023-08-16 08:54:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.3601.pt
2023-08-16 08:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.3601.pt (epoch 14 @ 20625 updates, score 21.36) (writing took 23.27131944335997 seconds)
2023-08-16 08:54:37 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-16 08:54:37 | INFO | train | epoch 014 | loss 2.049 | trans_loss 4.962 | nll_loss 2.219 | w2v_ctc_loss 0.765 | task_loss 3.296 | contrastive_loss 0.17 | total 4137.96 | n_correct 2682.73 | ppl 4.65 | accuracy 64.832 | wps 10663.8 | ups 1.29 | wpb 8275.9 | bsz 305.4 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.551 | clip 0 | loss_scale 16 | train_wall 1011 | gb_free 16.1 | wall 18552
2023-08-16 08:54:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 08:54:37 | INFO | fairseq.trainer | begin training epoch 15
2023-08-16 08:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 08:55:36 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.041, trans_loss=4.949, nll_loss=2.202, w2v_ctc_loss=0.751, task_loss=3.304, contrastive_loss=0.206, total=4090.99, n_correct=2665.47, ppl=4.6, accuracy=65.155, wps=6688.1, ups=0.82, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=18611
2023-08-16 08:56:45 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.029, trans_loss=4.938, nll_loss=2.187, w2v_ctc_loss=0.754, task_loss=3.419, contrastive_loss=0.116, total=4115.56, n_correct=2690.62, ppl=4.55, accuracy=65.377, wps=11859.2, ups=1.44, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=18680
2023-08-16 08:57:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-16 08:57:54 | INFO | train_inner | epoch 015:    276 / 1474 loss=2.027, trans_loss=4.941, nll_loss=2.191, w2v_ctc_loss=0.751, task_loss=3.209, contrastive_loss=0.108, total=4179.62, n_correct=2730.66, ppl=4.57, accuracy=65.333, wps=12069.4, ups=1.44, wpb=8359.2, bsz=310.2, num_updates=20900, lr=9.78232e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=69, gb_free=16, wall=18749
2023-08-16 08:59:03 | INFO | train_inner | epoch 015:    376 / 1474 loss=2.028, trans_loss=4.934, nll_loss=2.183, w2v_ctc_loss=0.747, task_loss=3.283, contrastive_loss=0.134, total=4176.34, n_correct=2729.84, ppl=4.54, accuracy=65.364, wps=12082.3, ups=1.45, wpb=8352.7, bsz=308.5, num_updates=21000, lr=9.759e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=18818
2023-08-16 09:00:12 | INFO | train_inner | epoch 015:    476 / 1474 loss=2.041, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.748, task_loss=3.461, contrastive_loss=0.219, total=4076.17, n_correct=2657.33, ppl=4.58, accuracy=65.192, wps=11828.2, ups=1.45, wpb=8152.3, bsz=293.1, num_updates=21100, lr=9.73585e-05, gnorm=0.617, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=18887
2023-08-16 09:01:22 | INFO | train_inner | epoch 015:    576 / 1474 loss=2.033, trans_loss=4.942, nll_loss=2.193, w2v_ctc_loss=0.755, task_loss=3.373, contrastive_loss=0.136, total=4151.89, n_correct=2709.61, ppl=4.57, accuracy=65.262, wps=11905, ups=1.43, wpb=8303.8, bsz=302, num_updates=21200, lr=9.71286e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=69, gb_free=13.2, wall=18957
2023-08-16 09:02:31 | INFO | train_inner | epoch 015:    676 / 1474 loss=2.033, trans_loss=4.933, nll_loss=2.181, w2v_ctc_loss=0.75, task_loss=3.36, contrastive_loss=0.179, total=4122.17, n_correct=2699.54, ppl=4.54, accuracy=65.488, wps=11963, ups=1.45, wpb=8244.3, bsz=304, num_updates=21300, lr=9.69003e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=19026
2023-08-16 09:03:41 | INFO | train_inner | epoch 015:    776 / 1474 loss=2.032, trans_loss=4.946, nll_loss=2.198, w2v_ctc_loss=0.759, task_loss=3.295, contrastive_loss=0.117, total=4181.07, n_correct=2726.22, ppl=4.59, accuracy=65.204, wps=12007.8, ups=1.44, wpb=8362.1, bsz=307.1, num_updates=21400, lr=9.66736e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=19096
2023-08-16 09:04:49 | INFO | train_inner | epoch 015:    876 / 1474 loss=2.032, trans_loss=4.944, nll_loss=2.196, w2v_ctc_loss=0.756, task_loss=3.563, contrastive_loss=0.109, total=4052.17, n_correct=2642.28, ppl=4.58, accuracy=65.207, wps=11791.2, ups=1.45, wpb=8104.3, bsz=286.4, num_updates=21500, lr=9.64486e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=19164
2023-08-16 09:05:58 | INFO | train_inner | epoch 015:    976 / 1474 loss=2.035, trans_loss=4.944, nll_loss=2.196, w2v_ctc_loss=0.747, task_loss=3.281, contrastive_loss=0.197, total=4135.95, n_correct=2700.45, ppl=4.58, accuracy=65.292, wps=12005.8, ups=1.45, wpb=8271.9, bsz=304.3, num_updates=21600, lr=9.6225e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=68, gb_free=16.3, wall=19233
2023-08-16 09:07:08 | INFO | train_inner | epoch 015:   1076 / 1474 loss=2.054, trans_loss=4.95, nll_loss=2.205, w2v_ctc_loss=0.753, task_loss=3.086, contrastive_loss=0.354, total=4187.18, n_correct=2723.12, ppl=4.61, accuracy=65.035, wps=12016.3, ups=1.43, wpb=8374.4, bsz=324.7, num_updates=21700, lr=9.60031e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=69, gb_free=13.6, wall=19303
2023-08-16 09:08:17 | INFO | train_inner | epoch 015:   1176 / 1474 loss=2.021, trans_loss=4.94, nll_loss=2.192, w2v_ctc_loss=0.734, task_loss=2.958, contrastive_loss=0.157, total=4184.18, n_correct=2741.28, ppl=4.57, accuracy=65.515, wps=12181.1, ups=1.46, wpb=8368.4, bsz=328.4, num_updates=21800, lr=9.57826e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=19372
2023-08-16 09:09:25 | INFO | train_inner | epoch 015:   1276 / 1474 loss=2.037, trans_loss=4.942, nll_loss=2.193, w2v_ctc_loss=0.769, task_loss=3.374, contrastive_loss=0.114, total=4141.39, n_correct=2696.86, ppl=4.57, accuracy=65.12, wps=12062.3, ups=1.46, wpb=8282.8, bsz=302.1, num_updates=21900, lr=9.55637e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=19440
2023-08-16 09:10:34 | INFO | train_inner | epoch 015:   1376 / 1474 loss=2.027, trans_loss=4.94, nll_loss=2.191, w2v_ctc_loss=0.753, task_loss=3.398, contrastive_loss=0.1, total=4106.11, n_correct=2683.71, ppl=4.57, accuracy=65.359, wps=11904.1, ups=1.45, wpb=8212.2, bsz=294.2, num_updates=22000, lr=9.53463e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=19509
2023-08-16 09:10:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 09:10:58 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.982 | trans_loss 5.197 | nll_loss 2.467 | w2v_ctc_loss 1.291 | task_loss 11.569 | contrastive_loss 0.334 | total 4003.4 | n_correct 2644.8 | ppl 5.53 | accuracy 66.064 | uer 18.392 | wer 20.283 | raw_wer 20.283 | bleu 21.77 | wps 2210.9 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.77
2023-08-16 09:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-16 09:10:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_15_22000.pt
2023-08-16 09:11:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_15_22000.pt
2023-08-16 09:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.77) (writing took 31.071872785687447 seconds)
2023-08-16 09:12:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 09:13:02 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.988 | trans_loss 5.193 | nll_loss 2.466 | w2v_ctc_loss 1.313 | task_loss 11.546 | contrastive_loss 0.341 | total 4003.4 | n_correct 2645.4 | ppl 5.53 | accuracy 66.079 | uer 18.69 | wer 20.592 | raw_wer 20.592 | bleu 21.71 | wps 2180.8 | wpb 4003.4 | bsz 141.8 | num_updates 22098 | best_bleu 21.77
2023-08-16 09:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22098 updates
2023-08-16 09:13:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.7100.pt
2023-08-16 09:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.7100.pt
2023-08-16 09:13:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.7100.pt (epoch 15 @ 22098 updates, score 21.71) (writing took 24.28326863795519 seconds)
2023-08-16 09:13:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-16 09:13:27 | INFO | train | epoch 015 | loss 2.033 | trans_loss 4.942 | nll_loss 2.193 | w2v_ctc_loss 0.751 | task_loss 3.292 | contrastive_loss 0.164 | total 4138.88 | n_correct 2702.11 | ppl 4.57 | accuracy 65.286 | wps 10794.6 | ups 1.3 | wpb 8277.8 | bsz 305.7 | num_updates 22098 | lr 9.51346e-05 | gnorm 0.55 | clip 0 | loss_scale 8 | train_wall 1010 | gb_free 16.7 | wall 19682
2023-08-16 09:13:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 09:13:27 | INFO | fairseq.trainer | begin training epoch 16
2023-08-16 09:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 09:13:36 | INFO | train_inner | epoch 016:      2 / 1474 loss=2.035, trans_loss=4.947, nll_loss=2.201, w2v_ctc_loss=0.747, task_loss=3.142, contrastive_loss=0.19, total=4152.6, n_correct=2708.92, ppl=4.6, accuracy=65.234, wps=4566.2, ups=0.55, wpb=8305.2, bsz=316.4, num_updates=22100, lr=9.51303e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=19691
2023-08-16 09:14:45 | INFO | train_inner | epoch 016:    102 / 1474 loss=2.016, trans_loss=4.922, nll_loss=2.167, w2v_ctc_loss=0.742, task_loss=3.17, contrastive_loss=0.131, total=4115.14, n_correct=2701.94, ppl=4.49, accuracy=65.659, wps=11981.9, ups=1.46, wpb=8230.3, bsz=313.9, num_updates=22200, lr=9.49158e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=68, gb_free=12.2, wall=19760
2023-08-16 09:15:54 | INFO | train_inner | epoch 016:    202 / 1474 loss=2.009, trans_loss=4.914, nll_loss=2.157, w2v_ctc_loss=0.731, task_loss=3.376, contrastive_loss=0.105, total=4109.58, n_correct=2705.07, ppl=4.46, accuracy=65.824, wps=11873.1, ups=1.44, wpb=8219.2, bsz=297.3, num_updates=22300, lr=9.47027e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=69, gb_free=14.7, wall=19829
2023-08-16 09:17:03 | INFO | train_inner | epoch 016:    302 / 1474 loss=2.024, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.744, task_loss=3.268, contrastive_loss=0.179, total=4164.1, n_correct=2733.9, ppl=4.5, accuracy=65.654, wps=12055.9, ups=1.45, wpb=8328.2, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=19898
2023-08-16 09:18:12 | INFO | train_inner | epoch 016:    402 / 1474 loss=2.028, trans_loss=4.922, nll_loss=2.167, w2v_ctc_loss=0.747, task_loss=3.532, contrastive_loss=0.194, total=4065.22, n_correct=2664.7, ppl=4.49, accuracy=65.549, wps=11807.1, ups=1.45, wpb=8130.4, bsz=286.4, num_updates=22500, lr=9.42809e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=19967
2023-08-16 09:19:22 | INFO | train_inner | epoch 016:    502 / 1474 loss=2.015, trans_loss=4.925, nll_loss=2.171, w2v_ctc_loss=0.736, task_loss=3.159, contrastive_loss=0.136, total=4181.93, n_correct=2751.9, ppl=4.5, accuracy=65.805, wps=12026.1, ups=1.44, wpb=8363.9, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=69, gb_free=15.5, wall=20037
2023-08-16 09:20:30 | INFO | train_inner | epoch 016:    602 / 1474 loss=2.019, trans_loss=4.927, nll_loss=2.174, w2v_ctc_loss=0.746, task_loss=3.287, contrastive_loss=0.102, total=4122.97, n_correct=2704.2, ppl=4.51, accuracy=65.589, wps=12038, ups=1.46, wpb=8245.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=20105
2023-08-16 09:21:38 | INFO | train_inner | epoch 016:    702 / 1474 loss=2.019, trans_loss=4.926, nll_loss=2.172, w2v_ctc_loss=0.747, task_loss=3.39, contrastive_loss=0.104, total=4093.15, n_correct=2684.55, ppl=4.51, accuracy=65.586, wps=11990.1, ups=1.46, wpb=8186.3, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=68, gb_free=17.6, wall=20173
2023-08-16 09:22:48 | INFO | train_inner | epoch 016:    802 / 1474 loss=2.018, trans_loss=4.921, nll_loss=2.167, w2v_ctc_loss=0.733, task_loss=3.147, contrastive_loss=0.165, total=4183.24, n_correct=2748.62, ppl=4.49, accuracy=65.706, wps=12089.4, ups=1.44, wpb=8366.5, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=20243
2023-08-16 09:23:57 | INFO | train_inner | epoch 016:    902 / 1474 loss=2.019, trans_loss=4.923, nll_loss=2.17, w2v_ctc_loss=0.737, task_loss=3.237, contrastive_loss=0.156, total=4150.23, n_correct=2728.67, ppl=4.5, accuracy=65.747, wps=12021.7, ups=1.45, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=20312
2023-08-16 09:25:06 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.028, trans_loss=4.93, nll_loss=2.178, w2v_ctc_loss=0.753, task_loss=3.391, contrastive_loss=0.155, total=4116.59, n_correct=2693.92, ppl=4.53, accuracy=65.441, wps=11899.9, ups=1.45, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=20381
2023-08-16 09:26:15 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.029, trans_loss=4.935, nll_loss=2.185, w2v_ctc_loss=0.756, task_loss=3.495, contrastive_loss=0.129, total=4112.71, n_correct=2689.27, ppl=4.55, accuracy=65.389, wps=11819.5, ups=1.44, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=11.8, wall=20450
2023-08-16 09:27:25 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.024, trans_loss=4.928, nll_loss=2.175, w2v_ctc_loss=0.727, task_loss=3.339, contrastive_loss=0.223, total=4161.11, n_correct=2725.38, ppl=4.52, accuracy=65.496, wps=11951.3, ups=1.44, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=20520
2023-08-16 09:28:34 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.027, trans_loss=4.925, nll_loss=2.171, w2v_ctc_loss=0.746, task_loss=3.242, contrastive_loss=0.204, total=4149.14, n_correct=2720.86, ppl=4.5, accuracy=65.576, wps=12024, ups=1.45, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=10.9, wall=20589
2023-08-16 09:29:43 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.017, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.744, task_loss=3.121, contrastive_loss=0.134, total=4200.01, n_correct=2756.65, ppl=4.51, accuracy=65.634, wps=12104.5, ups=1.44, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=20659
2023-08-16 09:30:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 09:30:56 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.186 | nll_loss 2.453 | w2v_ctc_loss 1.282 | task_loss 11.551 | contrastive_loss 0.328 | total 4003.4 | n_correct 2651.5 | ppl 5.48 | accuracy 66.231 | uer 18.18 | wer 20.048 | raw_wer 20.048 | bleu 21.93 | wps 2208.9 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 21.93
2023-08-16 09:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-08-16 09:30:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 09:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 09:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 16 @ 23572 updates, score 21.93) (writing took 33.11140190809965 seconds)
2023-08-16 09:31:30 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-16 09:31:30 | INFO | train | epoch 016 | loss 2.021 | trans_loss 4.924 | nll_loss 2.171 | w2v_ctc_loss 0.741 | task_loss 3.293 | contrastive_loss 0.16 | total 4138.65 | n_correct 2715.87 | ppl 4.5 | accuracy 65.622 | wps 11261.1 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.54 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 15.1 | wall 20765
2023-08-16 09:31:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 09:31:30 | INFO | fairseq.trainer | begin training epoch 17
2023-08-16 09:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 09:31:58 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.021, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.73, task_loss=3.384, contrastive_loss=0.267, total=4141.79, n_correct=2724.61, ppl=4.45, accuracy=65.783, wps=6181.3, ups=0.75, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=20793
2023-08-16 09:33:06 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.003, trans_loss=4.901, nll_loss=2.14, w2v_ctc_loss=0.731, task_loss=3.411, contrastive_loss=0.103, total=4110.88, n_correct=2715.25, ppl=4.41, accuracy=66.05, wps=11934.8, ups=1.45, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=20861
2023-08-16 09:34:15 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.016, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.722, task_loss=3.088, contrastive_loss=0.27, total=4171.95, n_correct=2758.84, ppl=4.41, accuracy=66.128, wps=12149.3, ups=1.46, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=20930
2023-08-16 09:35:24 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.016, trans_loss=4.906, nll_loss=2.146, w2v_ctc_loss=0.725, task_loss=3.29, contrastive_loss=0.271, total=4157.94, n_correct=2743.15, ppl=4.43, accuracy=65.974, wps=12022.2, ups=1.45, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=14.2, wall=20999
2023-08-16 09:36:34 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.002, trans_loss=4.906, nll_loss=2.147, w2v_ctc_loss=0.731, task_loss=3.281, contrastive_loss=0.101, total=4141.8, n_correct=2738.17, ppl=4.43, accuracy=66.111, wps=11951.2, ups=1.44, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=21069
2023-08-16 09:36:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 09:36:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.985 | trans_loss 5.183 | nll_loss 2.45 | w2v_ctc_loss 1.341 | task_loss 11.548 | contrastive_loss 0.32 | total 4003.4 | n_correct 2653.7 | ppl 5.46 | accuracy 66.286 | uer 18.464 | wer 20.376 | raw_wer 20.376 | bleu 22.13 | wps 2128.1 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.13
2023-08-16 09:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-16 09:36:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_17_24000.pt
2023-08-16 09:37:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_17_24000.pt
2023-08-16 09:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 22.13) (writing took 55.39373370818794 seconds)
2023-08-16 09:39:05 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.011, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.733, task_loss=3.431, contrastive_loss=0.147, total=4180.09, n_correct=2753.42, ppl=4.45, accuracy=65.87, wps=5539.1, ups=0.66, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=21220
2023-08-16 09:40:13 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.004, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.731, task_loss=3.32, contrastive_loss=0.098, total=4166.6, n_correct=2750.11, ppl=4.45, accuracy=66.004, wps=12135.5, ups=1.46, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=21288
2023-08-16 09:41:22 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.019, trans_loss=4.914, nll_loss=2.157, w2v_ctc_loss=0.749, task_loss=3.254, contrastive_loss=0.148, total=4168.97, n_correct=2743, ppl=4.46, accuracy=65.796, wps=12088.4, ups=1.45, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=21357
2023-08-16 09:42:31 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.006, trans_loss=4.909, nll_loss=2.151, w2v_ctc_loss=0.734, task_loss=3.315, contrastive_loss=0.109, total=4097.38, n_correct=2703.33, ppl=4.44, accuracy=65.977, wps=11900.7, ups=1.45, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=10.1, wall=21426
2023-08-16 09:43:39 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.006, trans_loss=4.912, nll_loss=2.154, w2v_ctc_loss=0.734, task_loss=3.255, contrastive_loss=0.107, total=4105.01, n_correct=2704.98, ppl=4.45, accuracy=65.895, wps=12091.2, ups=1.47, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=21494
2023-08-16 09:44:48 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.007, trans_loss=4.909, nll_loss=2.152, w2v_ctc_loss=0.737, task_loss=3.296, contrastive_loss=0.111, total=4105.88, n_correct=2707.05, ppl=4.44, accuracy=65.931, wps=11946.1, ups=1.45, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=21563
2023-08-16 09:45:56 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.001, trans_loss=4.906, nll_loss=2.147, w2v_ctc_loss=0.724, task_loss=3.371, contrastive_loss=0.102, total=4095.58, n_correct=2708.93, ppl=4.43, accuracy=66.143, wps=11917.1, ups=1.45, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=21631
2023-08-16 09:47:06 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.03, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.727, task_loss=3.231, contrastive_loss=0.341, total=4162.14, n_correct=2734.36, ppl=4.48, accuracy=65.696, wps=11915.5, ups=1.43, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=21701
2023-08-16 09:48:16 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.011, trans_loss=4.914, nll_loss=2.158, w2v_ctc_loss=0.721, task_loss=3.286, contrastive_loss=0.181, total=4149.03, n_correct=2734.38, ppl=4.46, accuracy=65.904, wps=11961.3, ups=1.44, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=21771
2023-08-16 09:49:24 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.002, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.728, task_loss=3.308, contrastive_loss=0.101, total=4117.13, n_correct=2717.16, ppl=4.45, accuracy=65.996, wps=11963.4, ups=1.45, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=21840
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:0')
2023-08-16 09:49:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:2')
2023-08-16 09:50:20 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.973 | trans_loss 5.181 | nll_loss 2.45 | w2v_ctc_loss 1.31 | task_loss 11.581 | contrastive_loss 0.323 | total 4003.4 | n_correct 2646.8 | ppl 5.46 | accuracy 66.114 | uer 18.132 | wer 19.962 | raw_wer 19.962 | bleu 22.08 | wps 2163.1 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 22.13
2023-08-16 09:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-16 09:50:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0809.pt
2023-08-16 09:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0809.pt
2023-08-16 09:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0809.pt (epoch 17 @ 25046 updates, score 22.08) (writing took 21.882599029690027 seconds)
2023-08-16 09:50:42 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-16 09:50:42 | INFO | train | epoch 017 | loss 2.009 | trans_loss 4.909 | nll_loss 2.151 | w2v_ctc_loss 0.731 | task_loss 3.297 | contrastive_loss 0.155 | total 4138.65 | n_correct 2730.29 | ppl 4.44 | accuracy 65.971 | wps 10591.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 1010 | gb_free 16.1 | wall 21917
2023-08-16 09:50:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 09:50:42 | INFO | fairseq.trainer | begin training epoch 18
2023-08-16 09:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 09:51:27 | INFO | train_inner | epoch 018:     54 / 1474 loss=2, trans_loss=4.9, nll_loss=2.139, w2v_ctc_loss=0.731, task_loss=3.355, contrastive_loss=0.111, total=4138.21, n_correct=2740.6, ppl=4.41, accuracy=66.227, wps=6737.8, ups=0.81, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=21962
2023-08-16 09:52:36 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.996, trans_loss=4.882, nll_loss=2.116, w2v_ctc_loss=0.703, task_loss=3.131, contrastive_loss=0.232, total=4158.88, n_correct=2766.68, ppl=4.33, accuracy=66.525, wps=12035.2, ups=1.45, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=22032
2023-08-16 09:53:46 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.987, trans_loss=4.885, nll_loss=2.119, w2v_ctc_loss=0.717, task_loss=3.194, contrastive_loss=0.101, total=4164.11, n_correct=2771.26, ppl=4.35, accuracy=66.551, wps=11995.8, ups=1.44, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=22101
2023-08-16 09:54:55 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.99, trans_loss=4.89, nll_loss=2.126, w2v_ctc_loss=0.711, task_loss=3.345, contrastive_loss=0.115, total=4163.13, n_correct=2764.7, ppl=4.36, accuracy=66.409, wps=12034.1, ups=1.45, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=22170
2023-08-16 09:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 09:56:06 | INFO | train_inner | epoch 018:    455 / 1474 loss=2.008, trans_loss=4.899, nll_loss=2.137, w2v_ctc_loss=0.722, task_loss=3.564, contrastive_loss=0.206, total=4078.15, n_correct=2696.17, ppl=4.4, accuracy=66.113, wps=11529.7, ups=1.41, wpb=8156.3, bsz=292.7, num_updates=25500, lr=8.85615e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=22241
2023-08-16 09:57:18 | INFO | train_inner | epoch 018:    555 / 1474 loss=1.982, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.706, task_loss=2.947, contrastive_loss=0.116, total=4218.07, n_correct=2812.27, ppl=4.33, accuracy=66.672, wps=11697.3, ups=1.39, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=71, gb_free=15.6, wall=22313
2023-08-16 09:58:29 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.011, trans_loss=4.904, nll_loss=2.144, w2v_ctc_loss=0.734, task_loss=3.405, contrastive_loss=0.186, total=4093.44, n_correct=2705.44, ppl=4.42, accuracy=66.092, wps=11500.9, ups=1.4, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=71, gb_free=14.9, wall=22384
2023-08-16 09:59:40 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.012, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.727, task_loss=3.14, contrastive_loss=0.274, total=4202.99, n_correct=2785.61, ppl=4.4, accuracy=66.277, wps=11864.9, ups=1.41, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=70, gb_free=17.3, wall=22455
2023-08-16 10:00:55 | INFO | train_inner | epoch 018:    855 / 1474 loss=1.997, trans_loss=4.896, nll_loss=2.134, w2v_ctc_loss=0.724, task_loss=3.315, contrastive_loss=0.101, total=4177.43, n_correct=2766.14, ppl=4.39, accuracy=66.216, wps=11097.1, ups=1.33, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=75, gb_free=15.9, wall=22530
2023-08-16 10:02:08 | INFO | train_inner | epoch 018:    955 / 1474 loss=1.985, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.706, task_loss=3.07, contrastive_loss=0.109, total=4138.23, n_correct=2750.9, ppl=4.36, accuracy=66.475, wps=11312.6, ups=1.37, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=73, gb_free=16.3, wall=22604
2023-08-16 10:02:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:02:34 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.185 | nll_loss 2.45 | w2v_ctc_loss 1.328 | task_loss 11.592 | contrastive_loss 0.33 | total 4003.4 | n_correct 2650.8 | ppl 5.46 | accuracy 66.214 | uer 18.52 | wer 20.312 | raw_wer 20.312 | bleu 21.77 | wps 2007.7 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.13
2023-08-16 10:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-16 10:02:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_18_26000.pt
2023-08-16 10:02:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_18_26000.pt
2023-08-16 10:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.77) (writing took 25.56634896993637 seconds)
2023-08-16 10:04:10 | INFO | train_inner | epoch 018:   1055 / 1474 loss=1.994, trans_loss=4.895, nll_loss=2.133, w2v_ctc_loss=0.717, task_loss=3.47, contrastive_loss=0.101, total=4133.59, n_correct=2737.33, ppl=4.39, accuracy=66.222, wps=6825.1, ups=0.83, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=22725
2023-08-16 10:05:22 | INFO | train_inner | epoch 018:   1155 / 1474 loss=2, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.719, task_loss=3.117, contrastive_loss=0.207, total=4154.22, n_correct=2758.75, ppl=4.36, accuracy=66.408, wps=11467.1, ups=1.38, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=72, gb_free=14.6, wall=22797
2023-08-16 10:06:36 | INFO | train_inner | epoch 018:   1255 / 1474 loss=1.996, trans_loss=4.903, nll_loss=2.143, w2v_ctc_loss=0.719, task_loss=3.537, contrastive_loss=0.096, total=4089.17, n_correct=2703.19, ppl=4.42, accuracy=66.106, wps=11026.2, ups=1.35, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=74, gb_free=16.4, wall=22871
2023-08-16 10:07:50 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.009, trans_loss=4.904, nll_loss=2.145, w2v_ctc_loss=0.742, task_loss=3.52, contrastive_loss=0.124, total=4068.84, n_correct=2687.74, ppl=4.42, accuracy=66.057, wps=11084.1, ups=1.36, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=73, gb_free=15.1, wall=22945
2023-08-16 10:09:00 | INFO | train_inner | epoch 018:   1455 / 1474 loss=2.003, trans_loss=4.903, nll_loss=2.143, w2v_ctc_loss=0.734, task_loss=3.498, contrastive_loss=0.111, total=4113.23, n_correct=2720.63, ppl=4.42, accuracy=66.143, wps=11762.9, ups=1.43, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=23015
2023-08-16 10:09:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:09:37 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.997 | trans_loss 5.183 | nll_loss 2.45 | w2v_ctc_loss 1.382 | task_loss 11.62 | contrastive_loss 0.325 | total 4003.4 | n_correct 2651.7 | ppl 5.46 | accuracy 66.236 | uer 18.217 | wer 20.227 | raw_wer 20.227 | bleu 22.08 | wps 2046.1 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.13
2023-08-16 10:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-16 10:09:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0803.pt
2023-08-16 10:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0803.pt
2023-08-16 10:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.0803.pt (epoch 18 @ 26519 updates, score 22.08) (writing took 24.0322956033051 seconds)
2023-08-16 10:10:02 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-16 10:10:02 | INFO | train | epoch 018 | loss 1.998 | trans_loss 4.894 | nll_loss 2.131 | w2v_ctc_loss 0.72 | task_loss 3.297 | contrastive_loss 0.152 | total 4138.61 | n_correct 2744.08 | ppl 4.38 | accuracy 66.304 | wps 10515.5 | ups 1.27 | wpb 8277.2 | bsz 305.6 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1043 | gb_free 15.7 | wall 23077
2023-08-16 10:10:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 10:10:02 | INFO | fairseq.trainer | begin training epoch 19
2023-08-16 10:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 10:11:08 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.988, trans_loss=4.875, nll_loss=2.107, w2v_ctc_loss=0.709, task_loss=3.28, contrastive_loss=0.158, total=4107.26, n_correct=2737.59, ppl=4.31, accuracy=66.652, wps=6413.3, ups=0.78, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=23143
2023-08-16 10:12:17 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.991, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.722, task_loss=3.068, contrastive_loss=0.151, total=4222.18, n_correct=2812.75, ppl=4.31, accuracy=66.618, wps=12143, ups=1.44, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=69, gb_free=11.3, wall=23212
2023-08-16 10:13:26 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.977, trans_loss=4.87, nll_loss=2.1, w2v_ctc_loss=0.707, task_loss=3.232, contrastive_loss=0.093, total=4187.37, n_correct=2796.4, ppl=4.29, accuracy=66.782, wps=12127.4, ups=1.45, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=23281
2023-08-16 10:14:35 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.989, trans_loss=4.871, nll_loss=2.102, w2v_ctc_loss=0.703, task_loss=3.252, contrastive_loss=0.2, total=4170.67, n_correct=2779.78, ppl=4.29, accuracy=66.651, wps=12101.2, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=23350
2023-08-16 10:15:44 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.99, trans_loss=4.882, nll_loss=2.115, w2v_ctc_loss=0.722, task_loss=3.379, contrastive_loss=0.109, total=4115.22, n_correct=2737.39, ppl=4.33, accuracy=66.519, wps=11932.4, ups=1.45, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=23419
2023-08-16 10:16:53 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.983, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.703, task_loss=3.233, contrastive_loss=0.173, total=4129.22, n_correct=2754.7, ppl=4.3, accuracy=66.712, wps=12036.2, ups=1.46, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=23488
2023-08-16 10:18:02 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.975, trans_loss=4.879, nll_loss=2.112, w2v_ctc_loss=0.697, task_loss=3.011, contrastive_loss=0.1, total=4197.2, n_correct=2803.1, ppl=4.32, accuracy=66.785, wps=12203, ups=1.45, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=14.3, wall=23557
2023-08-16 10:19:11 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.986, trans_loss=4.878, nll_loss=2.111, w2v_ctc_loss=0.715, task_loss=3.316, contrastive_loss=0.114, total=4142.6, n_correct=2755.52, ppl=4.32, accuracy=66.517, wps=11973.1, ups=1.45, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=23626
2023-08-16 10:20:20 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.989, trans_loss=4.887, nll_loss=2.122, w2v_ctc_loss=0.718, task_loss=3.368, contrastive_loss=0.097, total=4153.47, n_correct=2758.65, ppl=4.35, accuracy=66.418, wps=11973.7, ups=1.44, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=23695
2023-08-16 10:21:30 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.01, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.711, task_loss=3.287, contrastive_loss=0.331, total=4101.29, n_correct=2722.51, ppl=4.38, accuracy=66.382, wps=11694.5, ups=1.43, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=23765
2023-08-16 10:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 10:22:40 | INFO | train_inner | epoch 019:   1082 / 1474 loss=1.99, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.708, task_loss=3.508, contrastive_loss=0.137, total=4045.08, n_correct=2687.64, ppl=4.36, accuracy=66.442, wps=11666.7, ups=1.44, wpb=8090.2, bsz=292.4, num_updates=27600, lr=8.51257e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=23835
2023-08-16 10:23:49 | INFO | train_inner | epoch 019:   1182 / 1474 loss=2.005, trans_loss=4.889, nll_loss=2.125, w2v_ctc_loss=0.721, task_loss=3.375, contrastive_loss=0.223, total=4129.82, n_correct=2737.6, ppl=4.36, accuracy=66.289, wps=11921.6, ups=1.44, wpb=8259.6, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=23904
2023-08-16 10:24:58 | INFO | train_inner | epoch 019:   1282 / 1474 loss=1.989, trans_loss=4.886, nll_loss=2.121, w2v_ctc_loss=0.711, task_loss=3.314, contrastive_loss=0.12, total=4147.96, n_correct=2759.6, ppl=4.35, accuracy=66.529, wps=12060.9, ups=1.45, wpb=8295.9, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=23973
2023-08-16 10:26:07 | INFO | train_inner | epoch 019:   1382 / 1474 loss=1.986, trans_loss=4.882, nll_loss=2.116, w2v_ctc_loss=0.714, task_loss=3.368, contrastive_loss=0.107, total=4125.32, n_correct=2745.15, ppl=4.34, accuracy=66.544, wps=11979.9, ups=1.45, wpb=8250.6, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24042
2023-08-16 10:27:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:27:34 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.974 | trans_loss 5.172 | nll_loss 2.435 | w2v_ctc_loss 1.337 | task_loss 11.613 | contrastive_loss 0.318 | total 4003.4 | n_correct 2663 | ppl 5.41 | accuracy 66.518 | uer 18.026 | wer 19.943 | raw_wer 19.943 | bleu 21.89 | wps 2211.2 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 22.13
2023-08-16 10:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-08-16 10:27:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.8904.pt
2023-08-16 10:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.8904.pt
2023-08-16 10:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_21.8904.pt (epoch 19 @ 27992 updates, score 21.89) (writing took 24.516689993441105 seconds)
2023-08-16 10:27:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-16 10:27:59 | INFO | train | epoch 019 | loss 1.989 | trans_loss 4.88 | nll_loss 2.113 | w2v_ctc_loss 0.712 | task_loss 3.293 | contrastive_loss 0.15 | total 4139.01 | n_correct 2755.48 | ppl 4.33 | accuracy 66.573 | wps 11319.8 | ups 1.37 | wpb 8278 | bsz 305.8 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.543 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 17.1 | wall 24154
2023-08-16 10:27:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 10:27:59 | INFO | fairseq.trainer | begin training epoch 20
2023-08-16 10:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 10:28:13 | INFO | train_inner | epoch 020:      8 / 1474 loss=1.987, trans_loss=4.873, nll_loss=2.105, w2v_ctc_loss=0.706, task_loss=3.322, contrastive_loss=0.186, total=4124.63, n_correct=2752.42, ppl=4.3, accuracy=66.731, wps=6545.3, ups=0.79, wpb=8249.3, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=24168
2023-08-16 10:28:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:28:35 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.177 | nll_loss 2.442 | w2v_ctc_loss 1.292 | task_loss 11.652 | contrastive_loss 0.314 | total 4003.4 | n_correct 2659.9 | ppl 5.43 | accuracy 66.441 | uer 17.925 | wer 19.779 | raw_wer 19.779 | bleu 21.76 | wps 2254.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.13
2023-08-16 10:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-16 10:28:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_20_28000.pt
2023-08-16 10:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_20_28000.pt
2023-08-16 10:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.76) (writing took 38.66642082110047 seconds)
2023-08-16 10:30:24 | INFO | train_inner | epoch 020:    108 / 1474 loss=1.966, trans_loss=4.855, nll_loss=2.081, w2v_ctc_loss=0.691, task_loss=3.184, contrastive_loss=0.113, total=4199.19, n_correct=2821.22, ppl=4.23, accuracy=67.185, wps=6407.5, ups=0.76, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=24299
2023-08-16 10:31:33 | INFO | train_inner | epoch 020:    208 / 1474 loss=1.981, trans_loss=4.865, nll_loss=2.093, w2v_ctc_loss=0.705, task_loss=3.42, contrastive_loss=0.165, total=4148.29, n_correct=2772.91, ppl=4.27, accuracy=66.845, wps=11913.2, ups=1.44, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=24368
2023-08-16 10:32:42 | INFO | train_inner | epoch 020:    308 / 1474 loss=1.967, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.697, task_loss=2.984, contrastive_loss=0.103, total=4191.34, n_correct=2812.47, ppl=4.25, accuracy=67.102, wps=12169.8, ups=1.45, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=24437
2023-08-16 10:33:51 | INFO | train_inner | epoch 020:    408 / 1474 loss=1.969, trans_loss=4.856, nll_loss=2.082, w2v_ctc_loss=0.696, task_loss=3.342, contrastive_loss=0.099, total=4114.19, n_correct=2759.62, ppl=4.23, accuracy=67.076, wps=11999, ups=1.46, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=24506
2023-08-16 10:35:00 | INFO | train_inner | epoch 020:    508 / 1474 loss=1.979, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.691, task_loss=3.386, contrastive_loss=0.187, total=4108.2, n_correct=2747.51, ppl=4.28, accuracy=66.879, wps=11890.4, ups=1.45, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=24575
2023-08-16 10:35:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-16 10:36:10 | INFO | train_inner | epoch 020:    609 / 1474 loss=1.988, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.705, task_loss=3.487, contrastive_loss=0.191, total=4090.94, n_correct=2736.6, ppl=4.28, accuracy=66.894, wps=11726.1, ups=1.43, wpb=8181.9, bsz=295, num_updates=28600, lr=8.36242e-05, gnorm=0.57, clip=0, loss_scale=8, train_wall=69, gb_free=11.9, wall=24645
2023-08-16 10:37:19 | INFO | train_inner | epoch 020:    709 / 1474 loss=1.98, trans_loss=4.872, nll_loss=2.103, w2v_ctc_loss=0.713, task_loss=3.29, contrastive_loss=0.095, total=4134.98, n_correct=2759.4, ppl=4.3, accuracy=66.733, wps=12018.7, ups=1.45, wpb=8270, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=68, gb_free=13.8, wall=24714
2023-08-16 10:38:28 | INFO | train_inner | epoch 020:    809 / 1474 loss=1.977, trans_loss=4.871, nll_loss=2.102, w2v_ctc_loss=0.706, task_loss=3.263, contrastive_loss=0.099, total=4145.82, n_correct=2773.01, ppl=4.29, accuracy=66.887, wps=11992.9, ups=1.45, wpb=8291.6, bsz=306.6, num_updates=28800, lr=8.33333e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=68, gb_free=12.1, wall=24783
2023-08-16 10:39:37 | INFO | train_inner | epoch 020:    909 / 1474 loss=2.008, trans_loss=4.877, nll_loss=2.11, w2v_ctc_loss=0.703, task_loss=3.119, contrastive_loss=0.388, total=4161.77, n_correct=2769.01, ppl=4.32, accuracy=66.534, wps=11942.1, ups=1.43, wpb=8323.5, bsz=324.4, num_updates=28900, lr=8.3189e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=24852
2023-08-16 10:40:47 | INFO | train_inner | epoch 020:   1009 / 1474 loss=1.974, trans_loss=4.87, nll_loss=2.101, w2v_ctc_loss=0.695, task_loss=3.299, contrastive_loss=0.103, total=4167.85, n_correct=2784.72, ppl=4.29, accuracy=66.814, wps=11945.2, ups=1.43, wpb=8335.7, bsz=306.3, num_updates=29000, lr=8.30455e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=24922
2023-08-16 10:41:56 | INFO | train_inner | epoch 020:   1109 / 1474 loss=1.993, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.704, task_loss=3.174, contrastive_loss=0.242, total=4169.06, n_correct=2782.81, ppl=4.3, accuracy=66.749, wps=12054.1, ups=1.45, wpb=8338.1, bsz=315.8, num_updates=29100, lr=8.29027e-05, gnorm=0.572, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=24991
2023-08-16 10:43:06 | INFO | train_inner | epoch 020:   1209 / 1474 loss=1.981, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.716, task_loss=3.665, contrastive_loss=0.091, total=4023.64, n_correct=2684.75, ppl=4.27, accuracy=66.724, wps=11613.6, ups=1.44, wpb=8047.3, bsz=282.8, num_updates=29200, lr=8.27606e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=25061
2023-08-16 10:44:15 | INFO | train_inner | epoch 020:   1309 / 1474 loss=1.977, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.703, task_loss=3.455, contrastive_loss=0.097, total=4128.46, n_correct=2756.31, ppl=4.3, accuracy=66.764, wps=11950.5, ups=1.45, wpb=8256.9, bsz=299.2, num_updates=29300, lr=8.26192e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=25130
2023-08-16 10:45:24 | INFO | train_inner | epoch 020:   1409 / 1474 loss=1.98, trans_loss=4.873, nll_loss=2.104, w2v_ctc_loss=0.709, task_loss=3.479, contrastive_loss=0.093, total=4120.53, n_correct=2750.03, ppl=4.3, accuracy=66.74, wps=11874.4, ups=1.44, wpb=8241.1, bsz=294.2, num_updates=29400, lr=8.24786e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=69, gb_free=15.5, wall=25199
2023-08-16 10:46:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:46:32 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.178 | nll_loss 2.44 | w2v_ctc_loss 1.273 | task_loss 11.608 | contrastive_loss 0.311 | total 4003.4 | n_correct 2657 | ppl 5.43 | accuracy 66.369 | uer 17.663 | wer 19.608 | raw_wer 19.608 | bleu 22.28 | wps 2142.8 | wpb 4003.4 | bsz 141.8 | num_updates 29465 | best_bleu 22.28
2023-08-16 10:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29465 updates
2023-08-16 10:46:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 10:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 10:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 20 @ 29465 updates, score 22.28) (writing took 31.80751238577068 seconds)
2023-08-16 10:47:05 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-16 10:47:05 | INFO | train | epoch 020 | loss 1.98 | trans_loss 4.867 | nll_loss 2.097 | w2v_ctc_loss 0.702 | task_loss 3.3 | contrastive_loss 0.148 | total 4138.46 | n_correct 2766.74 | ppl 4.28 | accuracy 66.854 | wps 10639.1 | ups 1.29 | wpb 8276.9 | bsz 305.6 | num_updates 29465 | lr 8.23876e-05 | gnorm 0.547 | clip 0 | loss_scale 8 | train_wall 1011 | gb_free 15.9 | wall 25300
2023-08-16 10:47:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 10:47:05 | INFO | fairseq.trainer | begin training epoch 21
2023-08-16 10:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 10:47:37 | INFO | train_inner | epoch 021:     35 / 1474 loss=1.982, trans_loss=4.867, nll_loss=2.098, w2v_ctc_loss=0.694, task_loss=3.152, contrastive_loss=0.215, total=4145.63, n_correct=2772.55, ppl=4.28, accuracy=66.879, wps=6237.7, ups=0.75, wpb=8291.3, bsz=315.4, num_updates=29500, lr=8.23387e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=25332
2023-08-16 10:48:46 | INFO | train_inner | epoch 021:    135 / 1474 loss=1.973, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.691, task_loss=3.087, contrastive_loss=0.206, total=4194.57, n_correct=2820.32, ppl=4.2, accuracy=67.237, wps=12167.7, ups=1.45, wpb=8389.1, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=25401
2023-08-16 10:49:55 | INFO | train_inner | epoch 021:    235 / 1474 loss=1.962, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.682, task_loss=3.169, contrastive_loss=0.16, total=4152.42, n_correct=2794.88, ppl=4.2, accuracy=67.307, wps=12121.6, ups=1.46, wpb=8304.8, bsz=312, num_updates=29700, lr=8.2061e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=68, gb_free=17.1, wall=25470
2023-08-16 10:51:04 | INFO | train_inner | epoch 021:    335 / 1474 loss=1.974, trans_loss=4.855, nll_loss=2.081, w2v_ctc_loss=0.7, task_loss=3.271, contrastive_loss=0.164, total=4157.2, n_correct=2788.88, ppl=4.23, accuracy=67.086, wps=11903.6, ups=1.43, wpb=8314.4, bsz=311.1, num_updates=29800, lr=8.19232e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=69, gb_free=14.9, wall=25539
2023-08-16 10:52:14 | INFO | train_inner | epoch 021:    435 / 1474 loss=1.958, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.685, task_loss=3.166, contrastive_loss=0.087, total=4181.07, n_correct=2817.32, ppl=4.21, accuracy=67.383, wps=12082.4, ups=1.44, wpb=8362.1, bsz=308.2, num_updates=29900, lr=8.17861e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=69, gb_free=14.7, wall=25609
2023-08-16 10:53:23 | INFO | train_inner | epoch 021:    535 / 1474 loss=1.958, trans_loss=4.841, nll_loss=2.063, w2v_ctc_loss=0.691, task_loss=3.412, contrastive_loss=0.085, total=4089.72, n_correct=2756.7, ppl=4.18, accuracy=67.406, wps=11861.2, ups=1.45, wpb=8179.4, bsz=295.7, num_updates=30000, lr=8.16497e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=68, gb_free=14.1, wall=25678
2023-08-16 10:53:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 10:53:46 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.176 | nll_loss 2.439 | w2v_ctc_loss 1.322 | task_loss 11.578 | contrastive_loss 0.308 | total 4003.4 | n_correct 2665.5 | ppl 5.42 | accuracy 66.581 | uer 17.928 | wer 19.686 | raw_wer 19.686 | bleu 22.28 | wps 2158.9 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.28
2023-08-16 10:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-16 10:53:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_21_30000.pt
2023-08-16 10:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_21_30000.pt
2023-08-16 10:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.28) (writing took 32.24819314852357 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:0')
2023-08-16 10:55:29 | INFO | train_inner | epoch 021:    635 / 1474 loss=1.98, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.693, task_loss=3.27, contrastive_loss=0.259, total=4210.28, n_correct=2824.47, ppl=4.22, accuracy=67.085, wps=6659.9, ups=0.79, wpb=8420.6, bsz=315.7, num_updates=30100, lr=8.15139e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=69, gb_free=16.4, wall=25804
2023-08-16 10:56:38 | INFO | train_inner | epoch 021:    735 / 1474 loss=1.97, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.692, task_loss=3.31, contrastive_loss=0.119, total=4149.01, n_correct=2781.79, ppl=4.25, accuracy=67.047, wps=11967.1, ups=1.44, wpb=8298, bsz=307.4, num_updates=30200, lr=8.13788e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=25873
2023-08-16 10:57:48 | INFO | train_inner | epoch 021:    835 / 1474 loss=1.977, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.698, task_loss=3.473, contrastive_loss=0.132, total=4075.99, n_correct=2726.57, ppl=4.27, accuracy=66.893, wps=11714.6, ups=1.44, wpb=8152, bsz=295.7, num_updates=30300, lr=8.12444e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=69, gb_free=16, wall=25943
2023-08-16 10:58:57 | INFO | train_inner | epoch 021:    935 / 1474 loss=1.965, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.693, task_loss=3.308, contrastive_loss=0.104, total=4091.88, n_correct=2748.16, ppl=4.22, accuracy=67.161, wps=11926.7, ups=1.46, wpb=8183.8, bsz=300, num_updates=30400, lr=8.11107e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=26012
2023-08-16 11:00:05 | INFO | train_inner | epoch 021:   1035 / 1474 loss=1.969, trans_loss=4.861, nll_loss=2.089, w2v_ctc_loss=0.696, task_loss=3.346, contrastive_loss=0.101, total=4107.66, n_correct=2751.46, ppl=4.25, accuracy=66.984, wps=11936.8, ups=1.45, wpb=8215.3, bsz=299.5, num_updates=30500, lr=8.09776e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=68, gb_free=14.3, wall=26080
2023-08-16 11:01:14 | INFO | train_inner | epoch 021:   1135 / 1474 loss=1.969, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.697, task_loss=3.537, contrastive_loss=0.105, total=4118.94, n_correct=2765.29, ppl=4.23, accuracy=67.136, wps=11944.7, ups=1.45, wpb=8237.9, bsz=294.9, num_updates=30600, lr=8.08452e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=26149
2023-08-16 11:02:23 | INFO | train_inner | epoch 021:   1235 / 1474 loss=1.972, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.694, task_loss=3.156, contrastive_loss=0.158, total=4151.84, n_correct=2788.93, ppl=4.24, accuracy=67.173, wps=12072.2, ups=1.45, wpb=8303.7, bsz=309.1, num_updates=30700, lr=8.07134e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=26218
2023-08-16 11:03:32 | INFO | train_inner | epoch 021:   1335 / 1474 loss=1.965, trans_loss=4.854, nll_loss=2.082, w2v_ctc_loss=0.689, task_loss=3.187, contrastive_loss=0.117, total=4145.91, n_correct=2789.55, ppl=4.23, accuracy=67.284, wps=12032.4, ups=1.45, wpb=8291.8, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=26287
2023-08-16 11:04:42 | INFO | train_inner | epoch 021:   1435 / 1474 loss=1.986, trans_loss=4.865, nll_loss=2.095, w2v_ctc_loss=0.713, task_loss=3.461, contrastive_loss=0.169, total=4136.27, n_correct=2762.24, ppl=4.27, accuracy=66.781, wps=11878.4, ups=1.44, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=26357
2023-08-16 11:05:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2448, device='cuda:4')
2023-08-16 11:05:33 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.961 | trans_loss 5.166 | nll_loss 2.428 | w2v_ctc_loss 1.307 | task_loss 11.587 | contrastive_loss 0.319 | total 4003.4 | n_correct 2671.4 | ppl 5.38 | accuracy 66.728 | uer 17.984 | wer 19.872 | raw_wer 19.872 | bleu 22.43 | wps 2178.8 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 22.43
2023-08-16 11:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-16 11:05:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 11:05:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-16 11:06:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 21 @ 30939 updates, score 22.43) (writing took 30.311263406649232 seconds)
2023-08-16 11:06:03 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-16 11:06:03 | INFO | train | epoch 021 | loss 1.97 | trans_loss 4.854 | nll_loss 2.081 | w2v_ctc_loss 0.694 | task_loss 3.3 | contrastive_loss 0.145 | total 4138.65 | n_correct 2778.62 | ppl 4.23 | accuracy 67.138 | wps 10714.7 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 15.1 | wall 26439
2023-08-16 11:06:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 11:06:04 | INFO | fairseq.trainer | begin training epoch 22
2023-08-16 11:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 11:06:53 | INFO | train_inner | epoch 022:     61 / 1474 loss=1.959, trans_loss=4.841, nll_loss=2.063, w2v_ctc_loss=0.69, task_loss=3.311, contrastive_loss=0.089, total=4133.81, n_correct=2791.52, ppl=4.18, accuracy=67.529, wps=6319.7, ups=0.76, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=26488
2023-08-16 11:08:02 | INFO | train_inner | epoch 022:    161 / 1474 loss=1.966, trans_loss=4.84, nll_loss=2.061, w2v_ctc_loss=0.691, task_loss=3.373, contrastive_loss=0.167, total=4116.11, n_correct=2772.07, ppl=4.17, accuracy=67.347, wps=11862.6, ups=1.44, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=26557
2023-08-16 11:09:11 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.95, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.678, task_loss=2.885, contrastive_loss=0.112, total=4272.11, n_correct=2890.38, ppl=4.15, accuracy=67.657, wps=12364.4, ups=1.45, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=26626
2023-08-16 11:10:21 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.981, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.691, task_loss=3.356, contrastive_loss=0.266, total=4178.4, n_correct=2806.7, ppl=4.2, accuracy=67.172, wps=11879, ups=1.42, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=70, gb_free=15.1, wall=26696
2023-08-16 11:11:30 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.969, trans_loss=4.845, nll_loss=2.067, w2v_ctc_loss=0.69, task_loss=3.462, contrastive_loss=0.152, total=4132.96, n_correct=2782.04, ppl=4.19, accuracy=67.313, wps=12003.9, ups=1.45, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=26765
2023-08-16 11:12:40 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.953, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.681, task_loss=3.301, contrastive_loss=0.098, total=4158.17, n_correct=2807.11, ppl=4.16, accuracy=67.508, wps=11974.5, ups=1.44, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=26835
2023-08-16 11:13:48 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.956, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.674, task_loss=3.143, contrastive_loss=0.18, total=4139.66, n_correct=2799.84, ppl=4.15, accuracy=67.635, wps=12145.6, ups=1.47, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=26903
2023-08-16 11:14:58 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.959, trans_loss=4.838, nll_loss=2.058, w2v_ctc_loss=0.691, task_loss=3.384, contrastive_loss=0.1, total=4167.89, n_correct=2811.14, ppl=4.16, accuracy=67.448, wps=11972.3, ups=1.44, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=26973
2023-08-16 11:16:07 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.963, trans_loss=4.85, nll_loss=2.075, w2v_ctc_loss=0.693, task_loss=3.576, contrastive_loss=0.086, total=4075.79, n_correct=2735.09, ppl=4.21, accuracy=67.106, wps=11760.5, ups=1.44, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=27042
2023-08-16 11:17:16 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.955, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.686, task_loss=3.322, contrastive_loss=0.087, total=4134.72, n_correct=2788.31, ppl=4.18, accuracy=67.436, wps=11950, ups=1.45, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=69, gb_free=13.9, wall=27111
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 3 terminated with signal SIGKILL
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1049 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11078
2023-08-17 02:07:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-17 02:07:19 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-17 02:07:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11078', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-17 02:07:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-17 02:07:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-17 02:07:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-17 02:07:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-17 02:07:24 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 02:07:29 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-17 02:07:29 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-17 02:07:29 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-17 02:07:31 | INFO | root | load pretrained hubert
2023-08-17 02:07:33 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 02:07:34 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 02:07:35 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 02:07:35 | INFO | root | share the sematic adapter and textual encoder
2023-08-17 02:07:35 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-17 02:07:35 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-17 02:07:35 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-17 02:07:35 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-17 02:07:35 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-17 02:07:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-17 02:07:35 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 02:07:35 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 02:07:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 02:07:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 02:07:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-17 02:07:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-17 02:07:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-17 02:07:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 02:07:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 02:07:42 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-17 02:07:42 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-17 02:07:42 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt
2023-08-17 02:07:46 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
2023-08-17 02:07:46 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-17 02:07:47 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt (epoch 22 @ 30939 updates)
2023-08-17 02:07:47 | INFO | fairseq.trainer | loading train data for epoch 22
2023-08-17 02:07:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 02:07:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 02:07:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 02:07:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 02:07:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
2023-08-17 02:08:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 02:08:46 | INFO | fairseq.trainer | begin training epoch 22
2023-08-17 02:08:46 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
2023-08-17 02:09:47 | INFO | train_inner | epoch 022:     61 / 1474 loss=1.964, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.703, task_loss=3.319, contrastive_loss=0.091, total=4139.28, n_correct=2796.31, ppl=4.17, accuracy=67.556, wps=11482.1, ups=1.39, wpb=8278.6, bsz=300, num_updates=31000, lr=8.03219e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=52, gb_free=16.1, wall=125
2023-08-17 02:10:58 | INFO | train_inner | epoch 022:    161 / 1474 loss=1.964, trans_loss=4.838, nll_loss=2.059, w2v_ctc_loss=0.69, task_loss=3.371, contrastive_loss=0.165, total=4116.11, n_correct=2776.64, ppl=4.17, accuracy=67.458, wps=11528.6, ups=1.4, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=71, gb_free=16.4, wall=196
2023-08-17 02:12:09 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.947, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.671, task_loss=2.883, contrastive_loss=0.111, total=4272.11, n_correct=2894.42, ppl=4.15, accuracy=67.752, wps=12101.3, ups=1.42, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=267
2023-08-17 02:13:20 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.982, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.691, task_loss=3.351, contrastive_loss=0.268, total=4178.4, n_correct=2805.51, ppl=4.2, accuracy=67.143, wps=11687.2, ups=1.4, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=71, gb_free=15.1, wall=338
2023-08-17 02:14:32 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.971, trans_loss=4.846, nll_loss=2.069, w2v_ctc_loss=0.695, task_loss=3.466, contrastive_loss=0.151, total=4132.96, n_correct=2779.55, ppl=4.2, accuracy=67.253, wps=11637.9, ups=1.41, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=71, gb_free=16.7, wall=410
2023-08-17 02:15:42 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.958, trans_loss=4.84, nll_loss=2.061, w2v_ctc_loss=0.69, task_loss=3.306, contrastive_loss=0.099, total=4158.17, n_correct=2806.51, ppl=4.17, accuracy=67.494, wps=11768.5, ups=1.42, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=480
2023-08-17 02:16:52 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.959, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.678, task_loss=3.148, contrastive_loss=0.181, total=4139.66, n_correct=2796.58, ppl=4.16, accuracy=67.556, wps=11920.6, ups=1.44, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=550
2023-08-17 02:18:02 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.958, trans_loss=4.839, nll_loss=2.06, w2v_ctc_loss=0.687, task_loss=3.391, contrastive_loss=0.099, total=4167.89, n_correct=2806.96, ppl=4.17, accuracy=67.347, wps=11794.5, ups=1.41, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=620
2023-08-17 02:19:13 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.959, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.686, task_loss=3.57, contrastive_loss=0.085, total=4075.79, n_correct=2740.59, ppl=4.2, accuracy=67.241, wps=11457.2, ups=1.41, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=71, gb_free=16, wall=691
2023-08-17 02:20:24 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.955, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.682, task_loss=3.324, contrastive_loss=0.087, total=4134.72, n_correct=2787.66, ppl=4.18, accuracy=67.421, wps=11774.6, ups=1.42, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=70, gb_free=13.9, wall=762
2023-08-17 02:21:34 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.965, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.677, task_loss=3.15, contrastive_loss=0.256, total=4160.57, n_correct=2808.35, ppl=4.17, accuracy=67.499, wps=11909.3, ups=1.43, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=832
2023-08-17 02:21:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 02:21:57 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.165 | nll_loss 2.427 | w2v_ctc_loss 1.308 | task_loss 11.633 | contrastive_loss 0.305 | total 4003.4 | n_correct 2670.9 | ppl 5.38 | accuracy 66.716 | uer 17.644 | wer 19.507 | raw_wer 19.507 | bleu 22.26 | wps 2259.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.43
2023-08-17 02:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-17 02:21:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_22_32000.pt
2023-08-17 02:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_22_32000.pt
2023-08-17 02:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.26) (writing took 27.86553611047566 seconds)
2023-08-17 02:23:50 | INFO | train_inner | epoch 022:   1161 / 1474 loss=1.973, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.695, task_loss=3.391, contrastive_loss=0.138, total=4099.59, n_correct=2748.73, ppl=4.25, accuracy=67.049, wps=6003.7, ups=0.73, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=968
2023-08-17 02:24:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-17 02:25:01 | INFO | train_inner | epoch 022:   1262 / 1474 loss=1.964, trans_loss=4.855, nll_loss=2.083, w2v_ctc_loss=0.688, task_loss=3.081, contrastive_loss=0.127, total=4168.08, n_correct=2802.46, ppl=4.24, accuracy=67.236, wps=11711.1, ups=1.4, wpb=8336.2, bsz=319, num_updates=32200, lr=7.8811e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=71, gb_free=16.9, wall=1039
2023-08-17 02:26:10 | INFO | train_inner | epoch 022:   1362 / 1474 loss=1.961, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.684, task_loss=3.292, contrastive_loss=0.156, total=4061.14, n_correct=2736.95, ppl=4.18, accuracy=67.394, wps=11761.9, ups=1.45, wpb=8122.3, bsz=299.1, num_updates=32300, lr=7.86889e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=1108
2023-08-17 02:27:21 | INFO | train_inner | epoch 022:   1462 / 1474 loss=1.966, trans_loss=4.855, nll_loss=2.08, w2v_ctc_loss=0.694, task_loss=3.525, contrastive_loss=0.103, total=4083.08, n_correct=2741.24, ppl=4.23, accuracy=67.137, wps=11641.7, ups=1.43, wpb=8166.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.578, clip=0, loss_scale=8, train_wall=70, gb_free=16, wall=1179
2023-08-17 02:27:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 02:27:53 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.17 | nll_loss 2.433 | w2v_ctc_loss 1.296 | task_loss 11.49 | contrastive_loss 0.315 | total 4003.4 | n_correct 2667.1 | ppl 5.4 | accuracy 66.621 | uer 17.655 | wer 19.507 | raw_wer 19.507 | bleu 22.12 | wps 2146.6 | wpb 4003.4 | bsz 141.8 | num_updates 32412 | best_bleu 22.43
2023-08-17 02:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-08-17 02:27:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.1203.pt
2023-08-17 02:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.1203.pt
2023-08-17 02:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.1203.pt (epoch 22 @ 32412 updates, score 22.12) (writing took 25.533925127238035 seconds)
2023-08-17 02:28:19 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-17 02:28:19 | INFO | train | epoch 022 | loss 1.963 | trans_loss 4.844 | nll_loss 2.067 | w2v_ctc_loss 0.687 | task_loss 3.299 | contrastive_loss 0.143 | total 4137.83 | n_correct 2787.43 | ppl 4.19 | accuracy 67.365 | wps 10541.3 | ups 1.27 | wpb 8275.7 | bsz 305.4 | num_updates 32412 | lr 7.85529e-05 | gnorm 0.547 | clip 0 | loss_scale 8 | train_wall 1041 | gb_free 11.3 | wall 1237
2023-08-17 02:28:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 02:28:20 | INFO | fairseq.trainer | begin training epoch 23
2023-08-17 02:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 02:29:29 | INFO | train_inner | epoch 023:     88 / 1474 loss=1.95, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.685, task_loss=3.338, contrastive_loss=0.093, total=4093.3, n_correct=2773.38, ppl=4.12, accuracy=67.754, wps=6373.4, ups=0.78, wpb=8186.6, bsz=301.3, num_updates=32500, lr=7.84465e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=1307
2023-08-17 02:30:40 | INFO | train_inner | epoch 023:    188 / 1474 loss=1.948, trans_loss=4.821, nll_loss=2.037, w2v_ctc_loss=0.678, task_loss=3.5, contrastive_loss=0.09, total=4116.26, n_correct=2789.13, ppl=4.1, accuracy=67.759, wps=11573.7, ups=1.41, wpb=8232.5, bsz=294.4, num_updates=32600, lr=7.8326e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=71, gb_free=16.7, wall=1378
2023-08-17 02:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-17 02:31:51 | INFO | train_inner | epoch 023:    289 / 1474 loss=1.956, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.672, task_loss=3.349, contrastive_loss=0.168, total=4144.62, n_correct=2803.79, ppl=4.15, accuracy=67.649, wps=11711.9, ups=1.41, wpb=8289.2, bsz=304.3, num_updates=32700, lr=7.82062e-05, gnorm=0.54, clip=0, loss_scale=4, train_wall=70, gb_free=16.4, wall=1449
2023-08-17 02:33:00 | INFO | train_inner | epoch 023:    389 / 1474 loss=1.944, trans_loss=4.82, nll_loss=2.035, w2v_ctc_loss=0.676, task_loss=3.406, contrastive_loss=0.082, total=4115.12, n_correct=2792.41, ppl=4.1, accuracy=67.857, wps=11901.5, ups=1.45, wpb=8230.2, bsz=294.4, num_updates=32800, lr=7.80869e-05, gnorm=0.552, clip=0, loss_scale=4, train_wall=69, gb_free=12.9, wall=1518
2023-08-17 02:34:10 | INFO | train_inner | epoch 023:    489 / 1474 loss=1.954, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.678, task_loss=3.225, contrastive_loss=0.139, total=4156.86, n_correct=2809.03, ppl=4.15, accuracy=67.576, wps=11840.4, ups=1.42, wpb=8313.7, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.541, clip=0, loss_scale=4, train_wall=70, gb_free=14.8, wall=1588
2023-08-17 02:35:21 | INFO | train_inner | epoch 023:    589 / 1474 loss=1.94, trans_loss=4.822, nll_loss=2.038, w2v_ctc_loss=0.67, task_loss=3.114, contrastive_loss=0.088, total=4172.99, n_correct=2833.13, ppl=4.11, accuracy=67.892, wps=11792.8, ups=1.41, wpb=8346, bsz=316.1, num_updates=33000, lr=7.78499e-05, gnorm=0.543, clip=0, loss_scale=4, train_wall=70, gb_free=15.7, wall=1659
2023-08-17 02:36:30 | INFO | train_inner | epoch 023:    689 / 1474 loss=1.955, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.678, task_loss=3.312, contrastive_loss=0.128, total=4135.85, n_correct=2793.02, ppl=4.15, accuracy=67.532, wps=11935.9, ups=1.44, wpb=8271.7, bsz=301.9, num_updates=33100, lr=7.77322e-05, gnorm=0.539, clip=0, loss_scale=4, train_wall=69, gb_free=13.8, wall=1728
2023-08-17 02:37:40 | INFO | train_inner | epoch 023:    789 / 1474 loss=1.957, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.69, task_loss=3.315, contrastive_loss=0.108, total=4155.54, n_correct=2801.9, ppl=4.16, accuracy=67.426, wps=11958.6, ups=1.44, wpb=8311.1, bsz=306.6, num_updates=33200, lr=7.76151e-05, gnorm=0.571, clip=0, loss_scale=4, train_wall=69, gb_free=16.5, wall=1798
2023-08-17 02:38:49 | INFO | train_inner | epoch 023:    889 / 1474 loss=1.951, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.671, task_loss=3.008, contrastive_loss=0.186, total=4180.56, n_correct=2834.56, ppl=4.12, accuracy=67.803, wps=12023.7, ups=1.44, wpb=8361.1, bsz=324.5, num_updates=33300, lr=7.74984e-05, gnorm=0.539, clip=0, loss_scale=4, train_wall=69, gb_free=16.2, wall=1867
2023-08-17 02:40:01 | INFO | train_inner | epoch 023:    989 / 1474 loss=1.971, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.674, task_loss=3.315, contrastive_loss=0.344, total=4163.63, n_correct=2812.07, ppl=4.14, accuracy=67.539, wps=11716.6, ups=1.41, wpb=8327.3, bsz=309.2, num_updates=33400, lr=7.73823e-05, gnorm=0.55, clip=0, loss_scale=4, train_wall=71, gb_free=11.3, wall=1938
2023-08-17 02:41:10 | INFO | train_inner | epoch 023:   1089 / 1474 loss=1.96, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.69, task_loss=3.505, contrastive_loss=0.096, total=4094.62, n_correct=2759.06, ppl=4.18, accuracy=67.383, wps=11708.2, ups=1.43, wpb=8189.2, bsz=291.3, num_updates=33500, lr=7.72667e-05, gnorm=0.579, clip=0, loss_scale=4, train_wall=70, gb_free=17.1, wall=2008
2023-08-17 02:42:21 | INFO | train_inner | epoch 023:   1189 / 1474 loss=1.951, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.681, task_loss=3.275, contrastive_loss=0.087, total=4161.7, n_correct=2808.47, ppl=4.17, accuracy=67.484, wps=11843, ups=1.42, wpb=8323.4, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.529, clip=0, loss_scale=4, train_wall=70, gb_free=16.7, wall=2079
2023-08-17 02:43:30 | INFO | train_inner | epoch 023:   1289 / 1474 loss=1.948, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.675, task_loss=3.21, contrastive_loss=0.098, total=4133.96, n_correct=2796.72, ppl=4.15, accuracy=67.652, wps=11952.7, ups=1.45, wpb=8267.9, bsz=309.3, num_updates=33700, lr=7.70371e-05, gnorm=0.561, clip=0, loss_scale=4, train_wall=69, gb_free=16.5, wall=2148
2023-08-17 02:44:41 | INFO | train_inner | epoch 023:   1389 / 1474 loss=1.975, trans_loss=4.852, nll_loss=2.077, w2v_ctc_loss=0.696, task_loss=3.299, contrastive_loss=0.181, total=4159.95, n_correct=2791.93, ppl=4.22, accuracy=67.115, wps=11675.1, ups=1.4, wpb=8319.9, bsz=308.8, num_updates=33800, lr=7.69231e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=71, gb_free=10.4, wall=2219
2023-08-17 02:45:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 02:46:04 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.977 | trans_loss 5.167 | nll_loss 2.426 | w2v_ctc_loss 1.366 | task_loss 11.629 | contrastive_loss 0.31 | total 4003.4 | n_correct 2669.2 | ppl 5.38 | accuracy 66.673 | uer 17.734 | wer 19.541 | raw_wer 19.541 | bleu 22.23 | wps 2164.6 | wpb 4003.4 | bsz 141.8 | num_updates 33885 | best_bleu 22.43
2023-08-17 02:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33885 updates
2023-08-17 02:46:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2307.pt
2023-08-17 02:46:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2307.pt
2023-08-17 02:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2307.pt (epoch 23 @ 33885 updates, score 22.23) (writing took 25.206842336803675 seconds)
2023-08-17 02:46:30 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-17 02:46:30 | INFO | train | epoch 023 | loss 1.955 | trans_loss 4.833 | nll_loss 2.053 | w2v_ctc_loss 0.68 | task_loss 3.3 | contrastive_loss 0.141 | total 4138.4 | n_correct 2796.97 | ppl 4.15 | accuracy 67.586 | wps 11180.2 | ups 1.35 | wpb 8276.8 | bsz 305.6 | num_updates 33885 | lr 7.68265e-05 | gnorm 0.552 | clip 0 | loss_scale 4 | train_wall 1026 | gb_free 13.4 | wall 2328
2023-08-17 02:46:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 02:46:30 | INFO | fairseq.trainer | begin training epoch 24
2023-08-17 02:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 02:46:49 | INFO | train_inner | epoch 024:     15 / 1474 loss=1.977, trans_loss=4.846, nll_loss=2.069, w2v_ctc_loss=0.679, task_loss=3.275, contrastive_loss=0.28, total=4099.91, n_correct=2759.66, ppl=4.2, accuracy=67.31, wps=6418.9, ups=0.78, wpb=8199.8, bsz=308.7, num_updates=33900, lr=7.68095e-05, gnorm=0.579, clip=0, loss_scale=4, train_wall=70, gb_free=16.7, wall=2347
2023-08-17 02:47:58 | INFO | train_inner | epoch 024:    115 / 1474 loss=1.947, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.67, task_loss=3.116, contrastive_loss=0.191, total=4147.74, n_correct=2820.28, ppl=4.07, accuracy=67.996, wps=11988.3, ups=1.45, wpb=8295.5, bsz=317.7, num_updates=34000, lr=7.66965e-05, gnorm=0.569, clip=0, loss_scale=4, train_wall=69, gb_free=15.5, wall=2416
2023-08-17 02:47:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 02:48:22 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.17 | nll_loss 2.429 | w2v_ctc_loss 1.3 | task_loss 11.571 | contrastive_loss 0.314 | total 4003.4 | n_correct 2661.6 | ppl 5.38 | accuracy 66.483 | uer 17.811 | wer 19.824 | raw_wer 19.824 | bleu 22.25 | wps 2122.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.43
2023-08-17 02:48:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-17 02:48:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_24_34000.pt
2023-08-17 02:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_24_34000.pt
2023-08-17 02:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.25) (writing took 44.654837952926755 seconds)
2023-08-17 02:50:19 | INFO | train_inner | epoch 024:    215 / 1474 loss=1.956, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.661, task_loss=2.889, contrastive_loss=0.302, total=4244.96, n_correct=2882.02, ppl=4.1, accuracy=67.893, wps=6044.7, ups=0.71, wpb=8489.9, bsz=340, num_updates=34100, lr=7.6584e-05, gnorm=0.528, clip=0, loss_scale=4, train_wall=70, gb_free=15.2, wall=2557
2023-08-17 02:51:28 | INFO | train_inner | epoch 024:    315 / 1474 loss=1.937, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.668, task_loss=3.174, contrastive_loss=0.084, total=4144.64, n_correct=2816.26, ppl=4.09, accuracy=67.949, wps=11871.6, ups=1.43, wpb=8289.3, bsz=309.2, num_updates=34200, lr=7.64719e-05, gnorm=0.542, clip=0, loss_scale=4, train_wall=69, gb_free=16.4, wall=2626
2023-08-17 02:52:38 | INFO | train_inner | epoch 024:    415 / 1474 loss=1.966, trans_loss=4.821, nll_loss=2.036, w2v_ctc_loss=0.683, task_loss=3.513, contrastive_loss=0.229, total=4152.59, n_correct=2808.07, ppl=4.1, accuracy=67.622, wps=11918.5, ups=1.44, wpb=8305.2, bsz=297.1, num_updates=34300, lr=7.63604e-05, gnorm=0.543, clip=0, loss_scale=4, train_wall=69, gb_free=10.5, wall=2696
2023-08-17 02:53:47 | INFO | train_inner | epoch 024:    515 / 1474 loss=1.948, trans_loss=4.818, nll_loss=2.033, w2v_ctc_loss=0.672, task_loss=3.401, contrastive_loss=0.153, total=4135.54, n_correct=2808.75, ppl=4.09, accuracy=67.917, wps=11987.8, ups=1.45, wpb=8271.1, bsz=300.8, num_updates=34400, lr=7.62493e-05, gnorm=0.532, clip=0, loss_scale=4, train_wall=69, gb_free=16.2, wall=2765
2023-08-17 02:54:57 | INFO | train_inner | epoch 024:    615 / 1474 loss=1.942, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.668, task_loss=3.29, contrastive_loss=0.117, total=4163.63, n_correct=2825.57, ppl=4.1, accuracy=67.863, wps=11914.1, ups=1.43, wpb=8327.3, bsz=309.2, num_updates=34500, lr=7.61387e-05, gnorm=0.561, clip=0, loss_scale=4, train_wall=69, gb_free=16.4, wall=2835
2023-08-17 02:56:06 | INFO | train_inner | epoch 024:    715 / 1474 loss=1.954, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.68, task_loss=3.394, contrastive_loss=0.129, total=4100.27, n_correct=2771.54, ppl=4.14, accuracy=67.594, wps=11832.8, ups=1.44, wpb=8200.5, bsz=295.4, num_updates=34600, lr=7.60286e-05, gnorm=0.547, clip=0, loss_scale=4, train_wall=69, gb_free=15.3, wall=2904
2023-08-17 02:57:15 | INFO | train_inner | epoch 024:    815 / 1474 loss=1.945, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.672, task_loss=3.3, contrastive_loss=0.102, total=4129.03, n_correct=2799.48, ppl=4.13, accuracy=67.8, wps=11947.4, ups=1.45, wpb=8258.1, bsz=307.8, num_updates=34700, lr=7.5919e-05, gnorm=0.531, clip=0, loss_scale=4, train_wall=69, gb_free=17.2, wall=2973
2023-08-17 02:58:24 | INFO | train_inner | epoch 024:    915 / 1474 loss=1.949, trans_loss=4.826, nll_loss=2.042, w2v_ctc_loss=0.681, task_loss=3.699, contrastive_loss=0.078, total=4035.8, n_correct=2732.18, ppl=4.12, accuracy=67.699, wps=11800.4, ups=1.46, wpb=8071.6, bsz=278.8, num_updates=34800, lr=7.58098e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=68, gb_free=11.9, wall=3042
2023-08-17 02:59:34 | INFO | train_inner | epoch 024:   1015 / 1474 loss=1.943, trans_loss=4.826, nll_loss=2.043, w2v_ctc_loss=0.671, task_loss=3.446, contrastive_loss=0.083, total=4124.2, n_correct=2797.9, ppl=4.12, accuracy=67.841, wps=11779.6, ups=1.43, wpb=8248.4, bsz=295.7, num_updates=34900, lr=7.57011e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=70, gb_free=12.9, wall=3112
2023-08-17 03:00:43 | INFO | train_inner | epoch 024:   1115 / 1474 loss=1.941, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.672, task_loss=3.155, contrastive_loss=0.125, total=4133.96, n_correct=2813.28, ppl=4.07, accuracy=68.053, wps=11956.8, ups=1.45, wpb=8267.9, bsz=310.6, num_updates=35000, lr=7.55929e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=3181
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 03:01:52 | INFO | train_inner | epoch 024:   1215 / 1474 loss=1.945, trans_loss=4.824, nll_loss=2.041, w2v_ctc_loss=0.671, task_loss=3.286, contrastive_loss=0.115, total=4152.6, n_correct=2818.92, ppl=4.11, accuracy=67.883, wps=11975.9, ups=1.44, wpb=8305.2, bsz=310.7, num_updates=35100, lr=7.54851e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=69, gb_free=17.1, wall=3250
2023-08-17 03:03:02 | INFO | train_inner | epoch 024:   1315 / 1474 loss=1.952, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.687, task_loss=3.534, contrastive_loss=0.087, total=4108.12, n_correct=2780.02, ppl=4.13, accuracy=67.671, wps=11842.7, ups=1.44, wpb=8216.2, bsz=293.3, num_updates=35200, lr=7.53778e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=69, gb_free=12.7, wall=3320
2023-08-17 03:04:11 | INFO | train_inner | epoch 024:   1415 / 1474 loss=1.945, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.676, task_loss=3.404, contrastive_loss=0.084, total=4099.36, n_correct=2779.58, ppl=4.13, accuracy=67.805, wps=11774.1, ups=1.44, wpb=8198.7, bsz=294.7, num_updates=35300, lr=7.5271e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=69, gb_free=14.9, wall=3389
2023-08-17 03:04:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 03:05:16 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.168 | nll_loss 2.43 | w2v_ctc_loss 1.31 | task_loss 11.657 | contrastive_loss 0.304 | total 4003.4 | n_correct 2669.6 | ppl 5.39 | accuracy 66.683 | uer 17.474 | wer 19.19 | raw_wer 19.19 | bleu 22.54 | wps 2237.1 | wpb 4003.4 | bsz 141.8 | num_updates 35359 | best_bleu 22.54
2023-08-17 03:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35359 updates
2023-08-17 03:05:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-17 03:05:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt
2023-08-17 03:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_best.pt (epoch 24 @ 35359 updates, score 22.54) (writing took 31.58388763666153 seconds)
2023-08-17 03:05:48 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-17 03:05:48 | INFO | train | epoch 024 | loss 1.948 | trans_loss 4.822 | nll_loss 2.038 | w2v_ctc_loss 0.673 | task_loss 3.301 | contrastive_loss 0.139 | total 4138.65 | n_correct 2807.26 | ppl 4.11 | accuracy 67.83 | wps 10537.7 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 35359 | lr 7.52082e-05 | gnorm 0.545 | clip 0 | loss_scale 8 | train_wall 1018 | gb_free 15.9 | wall 3486
2023-08-17 03:05:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 03:05:48 | INFO | fairseq.trainer | begin training epoch 25
2023-08-17 03:05:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 03:06:24 | INFO | train_inner | epoch 025:     41 / 1474 loss=1.936, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.668, task_loss=3.2, contrastive_loss=0.093, total=4161.08, n_correct=2834.98, ppl=4.08, accuracy=68.131, wps=6267.2, ups=0.75, wpb=8322.2, bsz=309.6, num_updates=35400, lr=7.51646e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=3522
2023-08-17 03:07:33 | INFO | train_inner | epoch 025:    141 / 1474 loss=1.925, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.654, task_loss=3.193, contrastive_loss=0.09, total=4139.23, n_correct=2827.56, ppl=4.02, accuracy=68.311, wps=12063.7, ups=1.46, wpb=8278.5, bsz=309.8, num_updates=35500, lr=7.50587e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=3591
2023-08-17 03:08:42 | INFO | train_inner | epoch 025:    241 / 1474 loss=1.933, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.665, task_loss=3.383, contrastive_loss=0.094, total=4117.76, n_correct=2806.25, ppl=4.05, accuracy=68.15, wps=11891.3, ups=1.44, wpb=8235.5, bsz=302.9, num_updates=35600, lr=7.49532e-05, gnorm=0.552, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=3660
2023-08-17 03:09:52 | INFO | train_inner | epoch 025:    341 / 1474 loss=1.938, trans_loss=4.807, nll_loss=2.018, w2v_ctc_loss=0.664, task_loss=3.494, contrastive_loss=0.122, total=4142.17, n_correct=2820.3, ppl=4.05, accuracy=68.088, wps=11851, ups=1.43, wpb=8284.3, bsz=295.5, num_updates=35700, lr=7.48481e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=69, gb_free=15.4, wall=3730
2023-08-17 03:11:02 | INFO | train_inner | epoch 025:    441 / 1474 loss=1.955, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.681, task_loss=3.469, contrastive_loss=0.2, total=4167.72, n_correct=2835.75, ppl=4.06, accuracy=68.041, wps=11898, ups=1.43, wpb=8335.4, bsz=296.8, num_updates=35800, lr=7.47435e-05, gnorm=0.603, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=3800
2023-08-17 03:12:11 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.936, trans_loss=4.816, nll_loss=2.03, w2v_ctc_loss=0.665, task_loss=3.225, contrastive_loss=0.095, total=4154.79, n_correct=2828.01, ppl=4.09, accuracy=68.066, wps=12048.5, ups=1.45, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=68, gb_free=17.3, wall=3869
2023-08-17 03:13:20 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.938, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.664, task_loss=3.276, contrastive_loss=0.162, total=4156.33, n_correct=2833.9, ppl=4.04, accuracy=68.183, wps=12069.6, ups=1.45, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=3938
2023-08-17 03:13:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 03:13:45 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.174 | nll_loss 2.435 | w2v_ctc_loss 1.332 | task_loss 11.576 | contrastive_loss 0.31 | total 4003.4 | n_correct 2664.1 | ppl 5.41 | accuracy 66.546 | uer 17.641 | wer 19.384 | raw_wer 19.384 | bleu 22.47 | wps 2177.7 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.54
2023-08-17 03:13:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-17 03:13:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_25_36000.pt
2023-08-17 03:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_25_36000.pt
2023-08-17 03:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.47) (writing took 43.912319634109735 seconds)
2023-08-17 03:15:39 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.941, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.663, task_loss=3.326, contrastive_loss=0.159, total=4133.94, n_correct=2817.34, ppl=4.05, accuracy=68.151, wps=5964.9, ups=0.72, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=69, gb_free=14.8, wall=4077
2023-08-17 03:16:47 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.933, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.662, task_loss=3.048, contrastive_loss=0.103, total=4174.24, n_correct=2844.65, ppl=4.07, accuracy=68.148, wps=12126.1, ups=1.45, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=68, gb_free=16.1, wall=4145
2023-08-17 03:17:57 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.943, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.668, task_loss=3.137, contrastive_loss=0.161, total=4154.13, n_correct=2825.6, ppl=4.08, accuracy=68.019, wps=12008.3, ups=1.45, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=69, gb_free=10.5, wall=4215
2023-08-17 03:19:06 | INFO | train_inner | epoch 025:   1041 / 1474 loss=1.954, trans_loss=4.821, nll_loss=2.037, w2v_ctc_loss=0.661, task_loss=3.275, contrastive_loss=0.27, total=4178.3, n_correct=2833.5, ppl=4.1, accuracy=67.815, wps=12067.5, ups=1.44, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=4284
2023-08-17 03:20:15 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.935, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.661, task_loss=3.546, contrastive_loss=0.078, total=4042.33, n_correct=2750.26, ppl=4.07, accuracy=68.037, wps=11645.4, ups=1.44, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=4353
2023-08-17 03:21:24 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.939, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.667, task_loss=3.36, contrastive_loss=0.087, total=4087.78, n_correct=2776.87, ppl=4.1, accuracy=67.931, wps=11945.5, ups=1.46, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=68, gb_free=17.4, wall=4422
2023-08-17 03:22:32 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.947, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.671, task_loss=3.226, contrastive_loss=0.179, total=4166.64, n_correct=2831.14, ppl=4.08, accuracy=67.948, wps=12113.2, ups=1.45, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=4490
2023-08-17 03:23:42 | INFO | train_inner | epoch 025:   1441 / 1474 loss=1.95, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.669, task_loss=3.362, contrastive_loss=0.148, total=4114.64, n_correct=2782.74, ppl=4.13, accuracy=67.63, wps=11761.1, ups=1.43, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=4560
2023-08-17 03:24:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 03:24:29 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.163 | nll_loss 2.421 | w2v_ctc_loss 1.281 | task_loss 11.573 | contrastive_loss 0.308 | total 4003.4 | n_correct 2674 | ppl 5.35 | accuracy 66.793 | uer 17.357 | wer 19.231 | raw_wer 19.231 | bleu 22.29 | wps 2141 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 22.54
2023-08-17 03:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-17 03:24:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2902.pt
2023-08-17 03:24:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2902.pt
2023-08-17 03:24:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.2902.pt (epoch 25 @ 36833 updates, score 22.29) (writing took 21.508168311789632 seconds)
2023-08-17 03:24:51 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-17 03:24:51 | INFO | train | epoch 025 | loss 1.94 | trans_loss 4.812 | nll_loss 2.025 | w2v_ctc_loss 0.665 | task_loss 3.298 | contrastive_loss 0.137 | total 4138.65 | n_correct 2816.17 | ppl 4.07 | accuracy 68.046 | wps 10673.5 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 14 | wall 4629
2023-08-17 03:24:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 03:24:51 | INFO | fairseq.trainer | begin training epoch 26
2023-08-17 03:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 03:25:46 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.922, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.646, task_loss=3.118, contrastive_loss=0.111, total=4172.16, n_correct=2855.66, ppl=4.01, accuracy=68.446, wps=6780.1, ups=0.81, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=4684
2023-08-17 03:26:55 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.935, trans_loss=4.796, nll_loss=2.006, w2v_ctc_loss=0.638, task_loss=2.903, contrastive_loss=0.287, total=4265.22, n_correct=2922.32, ppl=4.02, accuracy=68.515, wps=12313.9, ups=1.44, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=15.1, wall=4753
2023-08-17 03:28:04 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.936, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.66, task_loss=3.279, contrastive_loss=0.177, total=4123.94, n_correct=2821.05, ppl=4.01, accuracy=68.407, wps=11967.4, ups=1.45, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=4822
2023-08-17 03:29:13 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.931, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.659, task_loss=3.154, contrastive_loss=0.132, total=4168.11, n_correct=2847.18, ppl=4.02, accuracy=68.309, wps=12106.8, ups=1.45, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=4891
2023-08-17 03:30:22 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.932, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.658, task_loss=3.158, contrastive_loss=0.177, total=4167.53, n_correct=2853.09, ppl=3.99, accuracy=68.46, wps=12005.6, ups=1.44, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=13.7, wall=4960
2023-08-17 03:31:31 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.933, trans_loss=4.8, nll_loss=2.009, w2v_ctc_loss=0.668, task_loss=3.3, contrastive_loss=0.098, total=4158.48, n_correct=2837.98, ppl=4.02, accuracy=68.246, wps=12040, ups=1.45, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=69, gb_free=12.5, wall=5029
2023-08-17 03:32:40 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.927, trans_loss=4.801, nll_loss=2.01, w2v_ctc_loss=0.654, task_loss=3.386, contrastive_loss=0.083, total=4129.11, n_correct=2817.54, ppl=4.03, accuracy=68.236, wps=11962.7, ups=1.45, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=13.5, wall=5098
2023-08-17 03:33:49 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.939, trans_loss=4.804, nll_loss=2.014, w2v_ctc_loss=0.654, task_loss=3.322, contrastive_loss=0.195, total=4096.84, n_correct=2793.47, ppl=4.04, accuracy=68.186, wps=11890.2, ups=1.45, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=5167
2023-08-17 03:34:58 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.934, trans_loss=4.802, nll_loss=2.012, w2v_ctc_loss=0.667, task_loss=3.286, contrastive_loss=0.098, total=4176.27, n_correct=2847.95, ppl=4.03, accuracy=68.194, wps=12038.4, ups=1.44, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=5236
2023-08-17 03:36:08 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.934, trans_loss=4.807, nll_loss=2.018, w2v_ctc_loss=0.65, task_loss=3.395, contrastive_loss=0.15, total=4141.01, n_correct=2822.78, ppl=4.05, accuracy=68.166, wps=11972.1, ups=1.45, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=5306
2023-08-17 03:37:17 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.933, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.667, task_loss=3.489, contrastive_loss=0.083, total=4113.69, n_correct=2808.07, ppl=4.04, accuracy=68.262, wps=11937.1, ups=1.45, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=5375
2023-08-17 03:38:26 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.938, trans_loss=4.812, nll_loss=2.025, w2v_ctc_loss=0.662, task_loss=3.447, contrastive_loss=0.123, total=4116.78, n_correct=2800.8, ppl=4.07, accuracy=68.034, wps=11887.5, ups=1.44, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=5444
2023-08-17 03:38:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 03:38:51 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.167 | nll_loss 2.427 | w2v_ctc_loss 1.328 | task_loss 11.671 | contrastive_loss 0.299 | total 4003.4 | n_correct 2676.6 | ppl 5.38 | accuracy 66.858 | uer 17.678 | wer 19.518 | raw_wer 19.518 | bleu 22.38 | wps 2237.7 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.54
2023-08-17 03:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-17 03:38:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_26_38000.pt
2023-08-17 03:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_26_38000.pt
2023-08-17 03:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.38) (writing took 40.17571981996298 seconds)
2023-08-17 03:40:41 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.94, trans_loss=4.817, nll_loss=2.031, w2v_ctc_loss=0.671, task_loss=3.664, contrastive_loss=0.086, total=4001.06, n_correct=2719.24, ppl=4.09, accuracy=67.963, wps=5941.6, ups=0.74, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=5579
2023-08-17 03:41:50 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.928, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.65, task_loss=3.299, contrastive_loss=0.096, total=4157.69, n_correct=2838.69, ppl=4.07, accuracy=68.276, wps=12005.4, ups=1.44, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=5648
2023-08-17 03:42:59 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.923, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.649, task_loss=3.127, contrastive_loss=0.09, total=4158.47, n_correct=2840.41, ppl=4.04, accuracy=68.304, wps=12070.9, ups=1.45, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=5717
2023-08-17 03:43:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 03:43:26 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.167 | nll_loss 2.426 | w2v_ctc_loss 1.289 | task_loss 11.626 | contrastive_loss 0.298 | total 4003.4 | n_correct 2668.4 | ppl 5.38 | accuracy 66.653 | uer 17.639 | wer 19.522 | raw_wer 19.522 | bleu 22.02 | wps 2239.7 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 22.54
2023-08-17 03:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-17 03:43:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt
2023-08-17 03:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt
2023-08-17 03:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_last.pt (epoch 26 @ 38307 updates, score 22.02) (writing took 17.001817613840103 seconds)
2023-08-17 03:43:43 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-17 03:43:43 | INFO | train | epoch 026 | loss 1.933 | trans_loss 4.802 | nll_loss 2.012 | w2v_ctc_loss 0.657 | task_loss 3.296 | contrastive_loss 0.134 | total 4138.65 | n_correct 2825.49 | ppl 4.03 | accuracy 68.271 | wps 10772.8 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.539 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 15.7 | wall 5761
2023-08-17 03:43:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 03:43:44 | INFO | fairseq.trainer | begin training epoch 27
2023-08-17 03:43:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 03:44:54 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.917, trans_loss=4.775, nll_loss=1.977, w2v_ctc_loss=0.65, task_loss=3.532, contrastive_loss=0.072, total=4067.62, n_correct=2793.76, ppl=3.94, accuracy=68.683, wps=7026.8, ups=0.86, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=5832
2023-08-17 03:46:04 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.917, trans_loss=4.783, nll_loss=1.988, w2v_ctc_loss=0.651, task_loss=3.159, contrastive_loss=0.1, total=4185.52, n_correct=2874.11, ppl=3.97, accuracy=68.668, wps=12059.6, ups=1.44, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=5902
2023-08-17 03:47:13 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.918, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.649, task_loss=3.291, contrastive_loss=0.084, total=4167.92, n_correct=2863.7, ppl=3.98, accuracy=68.708, wps=12063, ups=1.45, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=5971
2023-08-17 03:48:23 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.941, trans_loss=4.793, nll_loss=2, w2v_ctc_loss=0.652, task_loss=3.462, contrastive_loss=0.267, total=4075.21, n_correct=2790.27, ppl=4, accuracy=68.469, wps=11705.9, ups=1.44, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=6041
2023-08-17 03:49:32 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.937, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.657, task_loss=3.016, contrastive_loss=0.203, total=4249.35, n_correct=2900.41, ppl=4.04, accuracy=68.255, wps=12174.7, ups=1.43, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=6110
2023-08-17 03:50:42 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.925, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.652, task_loss=3.228, contrastive_loss=0.142, total=4133.39, n_correct=2835.36, ppl=3.98, accuracy=68.596, wps=11955.8, ups=1.45, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=11.7, wall=6180
2023-08-17 03:51:51 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.928, trans_loss=4.794, nll_loss=2.001, w2v_ctc_loss=0.657, task_loss=3.28, contrastive_loss=0.12, total=4162.71, n_correct=2847.45, ppl=4, accuracy=68.404, wps=12072.2, ups=1.45, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=6249
2023-08-17 03:52:59 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.925, trans_loss=4.792, nll_loss=1.999, w2v_ctc_loss=0.659, task_loss=3.461, contrastive_loss=0.084, total=4103.81, n_correct=2810.2, ppl=4, accuracy=68.478, wps=12041.5, ups=1.47, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=6317
2023-08-17 03:54:08 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.922, trans_loss=4.799, nll_loss=2.008, w2v_ctc_loss=0.648, task_loss=3.435, contrastive_loss=0.073, total=4101.56, n_correct=2807.27, ppl=4.02, accuracy=68.444, wps=11921.7, ups=1.45, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=6386
2023-08-17 03:55:18 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.94, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.653, task_loss=3.188, contrastive_loss=0.263, total=4199.56, n_correct=2869.53, ppl=4.02, accuracy=68.329, wps=11965.2, ups=1.42, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=70, gb_free=11.2, wall=6456
2023-08-17 03:56:26 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.923, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.654, task_loss=3.317, contrastive_loss=0.094, total=4150.97, n_correct=2837.29, ppl=4.01, accuracy=68.352, wps=12127.2, ups=1.46, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=6524
2023-08-17 03:57:35 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.928, trans_loss=4.796, nll_loss=2.005, w2v_ctc_loss=0.66, task_loss=3.443, contrastive_loss=0.098, total=4103.06, n_correct=2803.34, ppl=4.01, accuracy=68.323, wps=11935.5, ups=1.45, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=6593
2023-08-17 03:58:44 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.934, trans_loss=4.799, nll_loss=2.008, w2v_ctc_loss=0.656, task_loss=3.531, contrastive_loss=0.149, total=4062.52, n_correct=2775.18, ppl=4.02, accuracy=68.312, wps=11813.1, ups=1.45, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=6662
2023-08-17 03:59:53 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.925, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.647, task_loss=3.113, contrastive_loss=0.132, total=4152, n_correct=2839.8, ppl=4.02, accuracy=68.396, wps=12037.7, ups=1.45, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=6731
2023-08-17 04:00:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:01:12 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.167 | nll_loss 2.427 | w2v_ctc_loss 1.282 | task_loss 11.567 | contrastive_loss 0.302 | total 4003.4 | n_correct 2671.8 | ppl 5.38 | accuracy 66.738 | uer 17.843 | wer 19.731 | raw_wer 19.731 | bleu 22.46 | wps 2147 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 22.54
2023-08-17 04:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-17 04:01:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4605.pt
2023-08-17 04:01:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4605.pt
2023-08-17 04:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4605.pt (epoch 27 @ 39781 updates, score 22.46) (writing took 26.14247843809426 seconds)
2023-08-17 04:01:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-17 04:01:38 | INFO | train | epoch 027 | loss 1.927 | trans_loss 4.792 | nll_loss 2 | w2v_ctc_loss 0.653 | task_loss 3.297 | contrastive_loss 0.133 | total 4138.65 | n_correct 2833.55 | ppl 4 | accuracy 68.466 | wps 11350.1 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 1010 | gb_free 17.5 | wall 6836
2023-08-17 04:01:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 04:01:39 | INFO | fairseq.trainer | begin training epoch 28
2023-08-17 04:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 04:01:59 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.915, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.644, task_loss=3.19, contrastive_loss=0.084, total=4108.43, n_correct=2820.91, ppl=3.99, accuracy=68.662, wps=6504.1, ups=0.79, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=6857
2023-08-17 04:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-17 04:03:08 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.911, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.646, task_loss=3.437, contrastive_loss=0.078, total=4114.98, n_correct=2837.52, ppl=3.92, accuracy=68.956, wps=11852.5, ups=1.44, wpb=8230, bsz=293.7, num_updates=39900, lr=7.07992e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=13.5, wall=6926
2023-08-17 04:04:18 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.908, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.637, task_loss=3.109, contrastive_loss=0.087, total=4193.3, n_correct=2889.79, ppl=3.94, accuracy=68.914, wps=12100.2, ups=1.44, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=6996
2023-08-17 04:04:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:04:41 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.167 | nll_loss 2.425 | w2v_ctc_loss 1.284 | task_loss 11.574 | contrastive_loss 0.304 | total 4003.4 | n_correct 2683 | ppl 5.37 | accuracy 67.018 | uer 17.575 | wer 19.433 | raw_wer 19.433 | bleu 22.3 | wps 2169.3 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.54
2023-08-17 04:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-17 04:04:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_28_40000.pt
2023-08-17 04:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_28_40000.pt
2023-08-17 04:05:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.3) (writing took 31.3638881649822 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 04:06:23 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.946, trans_loss=4.787, nll_loss=1.992, w2v_ctc_loss=0.637, task_loss=3.29, contrastive_loss=0.416, total=4138.69, n_correct=2833.25, ppl=3.98, accuracy=68.458, wps=6638.3, ups=0.8, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=7120
2023-08-17 04:07:31 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.913, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.647, task_loss=3.405, contrastive_loss=0.075, total=4089.84, n_correct=2814, ppl=3.94, accuracy=68.805, wps=12022.1, ups=1.47, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=7189
2023-08-17 04:08:39 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.913, trans_loss=4.779, nll_loss=1.982, w2v_ctc_loss=0.642, task_loss=3.428, contrastive_loss=0.085, total=4098.92, n_correct=2819.29, ppl=3.95, accuracy=68.781, wps=11948.7, ups=1.46, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=7257
2023-08-17 04:09:48 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.918, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.647, task_loss=3.324, contrastive_loss=0.087, total=4180.1, n_correct=2868.95, ppl=3.99, accuracy=68.634, wps=12089.4, ups=1.45, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=7326
2023-08-17 04:10:57 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.929, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.648, task_loss=2.97, contrastive_loss=0.199, total=4191.62, n_correct=2874.97, ppl=4, accuracy=68.589, wps=12149, ups=1.45, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=7395
2023-08-17 04:12:06 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.912, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.645, task_loss=3.271, contrastive_loss=0.077, total=4088.91, n_correct=2811.52, ppl=3.96, accuracy=68.76, wps=11966.7, ups=1.46, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=7464
2023-08-17 04:13:15 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.925, trans_loss=4.788, nll_loss=1.994, w2v_ctc_loss=0.646, task_loss=3.418, contrastive_loss=0.139, total=4117.01, n_correct=2819.47, ppl=3.98, accuracy=68.483, wps=11842.8, ups=1.44, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=7533
2023-08-17 04:14:24 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.932, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.653, task_loss=3.212, contrastive_loss=0.194, total=4182.85, n_correct=2868.76, ppl=3.98, accuracy=68.584, wps=12110.5, ups=1.45, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=7602
2023-08-17 04:15:34 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.913, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.64, task_loss=3.165, contrastive_loss=0.1, total=4220.16, n_correct=2898.97, ppl=3.96, accuracy=68.693, wps=12121.3, ups=1.44, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=7672
2023-08-17 04:16:42 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.917, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.646, task_loss=3.289, contrastive_loss=0.085, total=4092.46, n_correct=2807.05, ppl=3.99, accuracy=68.591, wps=11937.3, ups=1.46, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=7740
2023-08-17 04:17:52 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.924, trans_loss=4.788, nll_loss=1.993, w2v_ctc_loss=0.655, task_loss=3.613, contrastive_loss=0.101, total=4084.55, n_correct=2798.72, ppl=3.98, accuracy=68.52, wps=11803.1, ups=1.44, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=7810
2023-08-17 04:19:01 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.932, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.66, task_loss=3.451, contrastive_loss=0.124, total=4154.09, n_correct=2838.25, ppl=4, accuracy=68.324, wps=12000.5, ups=1.44, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=7879
2023-08-17 04:19:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 04:20:02 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.168 | nll_loss 2.426 | w2v_ctc_loss 1.282 | task_loss 11.618 | contrastive_loss 0.308 | total 4003.4 | n_correct 2675.9 | ppl 5.37 | accuracy 66.841 | uer 17.53 | wer 19.343 | raw_wer 19.343 | bleu 22.39 | wps 2178.4 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 22.54
2023-08-17 04:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-17 04:20:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3909.pt
2023-08-17 04:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3909.pt
2023-08-17 04:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3909.pt (epoch 28 @ 41254 updates, score 22.39) (writing took 21.920960407704115 seconds)
2023-08-17 04:20:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-17 04:20:24 | INFO | train | epoch 028 | loss 1.921 | trans_loss 4.784 | nll_loss 1.989 | w2v_ctc_loss 0.646 | task_loss 3.298 | contrastive_loss 0.131 | total 4138.57 | n_correct 2841.69 | ppl 3.97 | accuracy 68.664 | wps 10829.2 | ups 1.31 | wpb 8277.1 | bsz 305.6 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 16.2 | wall 7962
2023-08-17 04:20:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 04:20:24 | INFO | fairseq.trainer | begin training epoch 29
2023-08-17 04:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 04:21:04 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.909, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.643, task_loss=3.162, contrastive_loss=0.097, total=4169.12, n_correct=2875.27, ppl=3.93, accuracy=68.966, wps=6785.1, ups=0.81, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=8002
2023-08-17 04:22:13 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.915, trans_loss=4.776, nll_loss=1.978, w2v_ctc_loss=0.642, task_loss=3.288, contrastive_loss=0.117, total=4105.72, n_correct=2829.05, ppl=3.94, accuracy=68.905, wps=11891.5, ups=1.45, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=8071
2023-08-17 04:23:22 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.917, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.635, task_loss=3.005, contrastive_loss=0.198, total=4199.67, n_correct=2893.28, ppl=3.92, accuracy=68.893, wps=12126.3, ups=1.44, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=8140
2023-08-17 04:24:31 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.921, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.657, task_loss=3.543, contrastive_loss=0.08, total=4095.17, n_correct=2810.93, ppl=3.97, accuracy=68.64, wps=11839, ups=1.45, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=8209
2023-08-17 04:25:40 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.897, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.629, task_loss=3.177, contrastive_loss=0.077, total=4157.44, n_correct=2882.99, ppl=3.86, accuracy=69.345, wps=12100.5, ups=1.46, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=8278
2023-08-17 04:26:50 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.927, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.642, task_loss=3.52, contrastive_loss=0.173, total=4150.87, n_correct=2849.05, ppl=3.96, accuracy=68.637, wps=11932.3, ups=1.44, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=8348
2023-08-17 04:27:58 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.92, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.637, task_loss=3.121, contrastive_loss=0.239, total=4143.02, n_correct=2854.43, ppl=3.93, accuracy=68.897, wps=12050.7, ups=1.45, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=8416
2023-08-17 04:28:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-17 04:29:09 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.918, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.643, task_loss=3.036, contrastive_loss=0.16, total=4241.89, n_correct=2918.22, ppl=3.93, accuracy=68.795, wps=12070.3, ups=1.42, wpb=8483.8, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=8487
2023-08-17 04:29:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:29:33 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.966 | trans_loss 5.167 | nll_loss 2.423 | w2v_ctc_loss 1.338 | task_loss 11.567 | contrastive_loss 0.307 | total 4003.4 | n_correct 2674.1 | ppl 5.36 | accuracy 66.796 | uer 17.718 | wer 19.503 | raw_wer 19.503 | bleu 22.29 | wps 2167.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.54
2023-08-17 04:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-17 04:29:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_29_42000.pt
2023-08-17 04:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_29_42000.pt
2023-08-17 04:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.29) (writing took 40.88137359172106 seconds)
2023-08-17 04:31:24 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.914, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.64, task_loss=3.658, contrastive_loss=0.074, total=4027.03, n_correct=2763.39, ppl=3.97, accuracy=68.621, wps=5959, ups=0.74, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=8622
2023-08-17 04:32:32 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.918, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.654, task_loss=3.383, contrastive_loss=0.086, total=4086.72, n_correct=2810.15, ppl=3.96, accuracy=68.763, wps=11971.3, ups=1.46, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=8690
2023-08-17 04:33:41 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.916, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.638, task_loss=3.302, contrastive_loss=0.159, total=4139.4, n_correct=2851.3, ppl=3.94, accuracy=68.882, wps=12095.2, ups=1.46, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=8759
2023-08-17 04:34:50 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.919, trans_loss=4.788, nll_loss=1.993, w2v_ctc_loss=0.651, task_loss=3.598, contrastive_loss=0.072, total=4072.33, n_correct=2795.6, ppl=3.98, accuracy=68.649, wps=11734.5, ups=1.44, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=8828
2023-08-17 04:35:59 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.913, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.642, task_loss=3.345, contrastive_loss=0.078, total=4160.52, n_correct=2860.85, ppl=3.96, accuracy=68.762, wps=12077.8, ups=1.45, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=8897
2023-08-17 04:37:08 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.917, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.642, task_loss=3.262, contrastive_loss=0.143, total=4168.02, n_correct=2868.14, ppl=3.93, accuracy=68.813, wps=12088, ups=1.45, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=8966
2023-08-17 04:38:17 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.913, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.634, task_loss=3.219, contrastive_loss=0.168, total=4166.06, n_correct=2869.18, ppl=3.93, accuracy=68.87, wps=12112.6, ups=1.45, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=9035
2023-08-17 04:38:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:38:58 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.939 | trans_loss 5.162 | nll_loss 2.419 | w2v_ctc_loss 1.262 | task_loss 11.611 | contrastive_loss 0.304 | total 4003.4 | n_correct 2677.4 | ppl 5.35 | accuracy 66.878 | uer 17.158 | wer 19.067 | raw_wer 19.067 | bleu 22.36 | wps 2242.8 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.54
2023-08-17 04:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-17 04:38:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3601.pt
2023-08-17 04:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3601.pt
2023-08-17 04:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3601.pt (epoch 29 @ 42727 updates, score 22.36) (writing took 23.02539734914899 seconds)
2023-08-17 04:39:26 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-17 04:39:26 | INFO | train | epoch 029 | loss 1.915 | trans_loss 4.776 | nll_loss 1.978 | w2v_ctc_loss 0.641 | task_loss 3.3 | contrastive_loss 0.13 | total 4138.49 | n_correct 2848.56 | ppl 3.94 | accuracy 68.831 | wps 10676.9 | ups 1.29 | wpb 8277 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1009 | gb_free 15.8 | wall 9104
2023-08-17 04:39:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 04:39:26 | INFO | fairseq.trainer | begin training epoch 30
2023-08-17 04:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 04:40:25 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.913, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.631, task_loss=3.135, contrastive_loss=0.189, total=4175.11, n_correct=2879.45, ppl=3.91, accuracy=68.967, wps=6513.9, ups=0.78, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=9163
2023-08-17 04:41:34 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.899, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.63, task_loss=3.086, contrastive_loss=0.119, total=4202.64, n_correct=2917.45, ppl=3.85, accuracy=69.419, wps=12220.3, ups=1.45, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=9232
2023-08-17 04:42:42 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.909, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.644, task_loss=3.405, contrastive_loss=0.074, total=4120.21, n_correct=2842.1, ppl=3.91, accuracy=68.979, wps=12026.3, ups=1.46, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=9300
2023-08-17 04:43:51 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.895, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.626, task_loss=3.289, contrastive_loss=0.076, total=4178.23, n_correct=2894.46, ppl=3.87, accuracy=69.275, wps=12074.7, ups=1.44, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=9.6, wall=9369
2023-08-17 04:45:00 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.906, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.63, task_loss=3.16, contrastive_loss=0.139, total=4124.47, n_correct=2848.62, ppl=3.9, accuracy=69.066, wps=12023.3, ups=1.46, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=9438
2023-08-17 04:46:09 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.903, trans_loss=4.764, nll_loss=1.964, w2v_ctc_loss=0.632, task_loss=3.199, contrastive_loss=0.103, total=4168.41, n_correct=2879.95, ppl=3.9, accuracy=69.09, wps=12161.8, ups=1.46, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=9507
2023-08-17 04:47:18 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.908, trans_loss=4.765, nll_loss=1.963, w2v_ctc_loss=0.64, task_loss=3.268, contrastive_loss=0.115, total=4187.95, n_correct=2888.51, ppl=3.9, accuracy=68.972, wps=12122.5, ups=1.45, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=9576
2023-08-17 04:48:27 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.924, trans_loss=4.774, nll_loss=1.975, w2v_ctc_loss=0.648, task_loss=3.364, contrastive_loss=0.193, total=4105.32, n_correct=2825.44, ppl=3.93, accuracy=68.824, wps=11871.2, ups=1.45, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=69, gb_free=12.6, wall=9645
2023-08-17 04:49:36 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.904, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.629, task_loss=3.395, contrastive_loss=0.087, total=4102.11, n_correct=2831.94, ppl=3.91, accuracy=69.036, wps=11864.6, ups=1.45, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=9714
2023-08-17 04:50:45 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.91, trans_loss=4.774, nll_loss=1.975, w2v_ctc_loss=0.641, task_loss=3.376, contrastive_loss=0.09, total=4129.98, n_correct=2842.27, ppl=3.93, accuracy=68.82, wps=11992.3, ups=1.45, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=9783
2023-08-17 04:51:54 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.919, trans_loss=4.774, nll_loss=1.975, w2v_ctc_loss=0.639, task_loss=3.699, contrastive_loss=0.166, total=4101.17, n_correct=2824.83, ppl=3.93, accuracy=68.879, wps=11867.1, ups=1.45, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=9852
2023-08-17 04:53:03 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.908, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.63, task_loss=3.174, contrastive_loss=0.147, total=4168.36, n_correct=2877.56, ppl=3.91, accuracy=69.033, wps=12068.9, ups=1.45, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=9921
2023-08-17 04:54:13 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.91, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.643, task_loss=3.65, contrastive_loss=0.08, total=4036.17, n_correct=2781.59, ppl=3.92, accuracy=68.917, wps=11558.5, ups=1.43, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=9991
2023-08-17 04:54:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:54:36 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.951 | trans_loss 5.164 | nll_loss 2.421 | w2v_ctc_loss 1.303 | task_loss 11.668 | contrastive_loss 0.298 | total 4003.4 | n_correct 2673.9 | ppl 5.35 | accuracy 66.791 | uer 17.347 | wer 19.104 | raw_wer 19.104 | bleu 22.21 | wps 2227.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.54
2023-08-17 04:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-17 04:54:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_30_44000.pt
2023-08-17 04:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_30_44000.pt
2023-08-17 04:55:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.21) (writing took 25.574974179267883 seconds)
2023-08-17 04:56:11 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.902, trans_loss=4.769, nll_loss=1.971, w2v_ctc_loss=0.633, task_loss=3.107, contrastive_loss=0.09, total=4165.07, n_correct=2875.99, ppl=3.92, accuracy=69.05, wps=7036.9, ups=0.84, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=10109
2023-08-17 04:56:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-17 04:57:20 | INFO | train_inner | epoch 030:   1474 / 1474 loss=1.916, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.628, task_loss=3.108, contrastive_loss=0.236, total=4119.06, n_correct=2838.8, ppl=3.93, accuracy=68.919, wps=11951.5, ups=1.45, wpb=8238.1, bsz=312.4, num_updates=44200, lr=6.72673e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=10178
2023-08-17 04:57:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 04:57:43 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.941 | trans_loss 5.167 | nll_loss 2.425 | w2v_ctc_loss 1.265 | task_loss 11.596 | contrastive_loss 0.297 | total 4003.4 | n_correct 2669.7 | ppl 5.37 | accuracy 66.686 | uer 17.514 | wer 19.373 | raw_wer 19.373 | bleu 22.39 | wps 2243.9 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 22.54
2023-08-17 04:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-08-17 04:57:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3902.pt
2023-08-17 04:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3902.pt
2023-08-17 04:58:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3902.pt (epoch 30 @ 44200 updates, score 22.39) (writing took 24.228594291955233 seconds)
2023-08-17 04:58:08 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-17 04:58:08 | INFO | train | epoch 030 | loss 1.908 | trans_loss 4.767 | nll_loss 1.967 | w2v_ctc_loss 0.635 | task_loss 3.296 | contrastive_loss 0.128 | total 4138.61 | n_correct 2856.47 | ppl 3.91 | accuracy 69.02 | wps 10871.2 | ups 1.31 | wpb 8277.2 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.545 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 16.9 | wall 10226
2023-08-17 04:58:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 04:58:08 | INFO | fairseq.trainer | begin training epoch 31
2023-08-17 04:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 04:59:25 | INFO | train_inner | epoch 031:    100 / 1474 loss=1.903, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.64, task_loss=3.471, contrastive_loss=0.084, total=4085.38, n_correct=2829.58, ppl=3.87, accuracy=69.261, wps=6564.4, ups=0.8, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=10303
2023-08-17 05:00:34 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.903, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.635, task_loss=3.407, contrastive_loss=0.094, total=4139.51, n_correct=2862.62, ppl=3.88, accuracy=69.154, wps=11970.9, ups=1.45, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=10372
2023-08-17 05:01:43 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.901, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.625, task_loss=3.381, contrastive_loss=0.14, total=4148.01, n_correct=2875.99, ppl=3.86, accuracy=69.334, wps=11995.1, ups=1.45, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=10441
2023-08-17 05:02:52 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.905, trans_loss=4.767, nll_loss=1.966, w2v_ctc_loss=0.633, task_loss=3.603, contrastive_loss=0.078, total=4095.42, n_correct=2826.73, ppl=3.91, accuracy=69.022, wps=11951.7, ups=1.46, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=10510
2023-08-17 05:04:01 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.901, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.639, task_loss=3.439, contrastive_loss=0.086, total=4115.61, n_correct=2847.72, ppl=3.87, accuracy=69.193, wps=11870.7, ups=1.44, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=10579
2023-08-17 05:05:10 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.897, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.627, task_loss=3.46, contrastive_loss=0.075, total=4075.9, n_correct=2822.56, ppl=3.87, accuracy=69.25, wps=11771.2, ups=1.44, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=10648
2023-08-17 05:06:19 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.89, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.619, task_loss=3.139, contrastive_loss=0.077, total=4208.99, n_correct=2918.52, ppl=3.86, accuracy=69.34, wps=12275.6, ups=1.46, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=10717
2023-08-17 05:06:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-17 05:07:28 | INFO | train_inner | epoch 031:    801 / 1474 loss=1.905, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.626, task_loss=3.472, contrastive_loss=0.13, total=4089.46, n_correct=2824.12, ppl=3.89, accuracy=69.059, wps=11793, ups=1.44, wpb=8178.9, bsz=293.7, num_updates=45000, lr=6.66667e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=69, gb_free=15.4, wall=10786
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 05:08:37 | INFO | train_inner | epoch 031:    901 / 1474 loss=1.903, trans_loss=4.753, nll_loss=1.948, w2v_ctc_loss=0.639, task_loss=3.486, contrastive_loss=0.093, total=4098.59, n_correct=2839.27, ppl=3.86, accuracy=69.274, wps=11903.4, ups=1.45, wpb=8197.2, bsz=293.9, num_updates=45100, lr=6.65927e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=10855
2023-08-17 05:09:46 | INFO | train_inner | epoch 031:   1001 / 1474 loss=1.91, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.631, task_loss=3.084, contrastive_loss=0.175, total=4184.36, n_correct=2888.44, ppl=3.92, accuracy=69.029, wps=12078.3, ups=1.44, wpb=8368.7, bsz=320.3, num_updates=45200, lr=6.6519e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=10924
2023-08-17 05:10:55 | INFO | train_inner | epoch 031:   1101 / 1474 loss=1.904, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.63, task_loss=3.218, contrastive_loss=0.122, total=4150.56, n_correct=2870.15, ppl=3.89, accuracy=69.151, wps=12105.3, ups=1.46, wpb=8301.1, bsz=315.1, num_updates=45300, lr=6.64455e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=68, gb_free=14.9, wall=10993
2023-08-17 05:12:03 | INFO | train_inner | epoch 031:   1201 / 1474 loss=1.911, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.627, task_loss=3.069, contrastive_loss=0.239, total=4190.99, n_correct=2897.8, ppl=3.89, accuracy=69.144, wps=12271.5, ups=1.46, wpb=8382, bsz=323, num_updates=45400, lr=6.63723e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=68, gb_free=16.9, wall=11061
2023-08-17 05:13:11 | INFO | train_inner | epoch 031:   1301 / 1474 loss=1.897, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.63, task_loss=2.966, contrastive_loss=0.083, total=4226.19, n_correct=2923.52, ppl=3.9, accuracy=69.176, wps=12408, ups=1.47, wpb=8452.4, bsz=325.1, num_updates=45500, lr=6.62994e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=11129
2023-08-17 05:14:21 | INFO | train_inner | epoch 031:   1401 / 1474 loss=1.921, trans_loss=4.764, nll_loss=1.964, w2v_ctc_loss=0.627, task_loss=3.013, contrastive_loss=0.286, total=4192.11, n_correct=2891.84, ppl=3.9, accuracy=68.983, wps=11977.1, ups=1.43, wpb=8384.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=70, gb_free=16, wall=11199
2023-08-17 05:15:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
mt_weight tensor(0.5000)
asr_weight tensor(0.2448)
2023-08-17 05:15:35 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.332 | task_loss 11.61 | contrastive_loss 0.302 | total 4003.4 | n_correct 2680.4 | ppl 5.34 | accuracy 66.953 | uer 17.233 | wer 19.004 | raw_wer 19.004 | bleu 22.31 | wps 2160.4 | wpb 4003.4 | bsz 141.8 | num_updates 45673 | best_bleu 22.54
2023-08-17 05:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-08-17 05:15:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3106.pt
2023-08-17 05:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3106.pt
2023-08-17 05:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3106.pt (epoch 31 @ 45673 updates, score 22.31) (writing took 25.744560597464442 seconds)
2023-08-17 05:16:01 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-17 05:16:01 | INFO | train | epoch 031 | loss 1.904 | trans_loss 4.759 | nll_loss 1.957 | w2v_ctc_loss 0.63 | task_loss 3.3 | contrastive_loss 0.125 | total 4137.67 | n_correct 2861.83 | ppl 3.88 | accuracy 69.165 | wps 11356.9 | ups 1.37 | wpb 8275.3 | bsz 305.4 | num_updates 45673 | lr 6.61737e-05 | gnorm 0.554 | clip 0 | loss_scale 8 | train_wall 1009 | gb_free 11.7 | wall 11299
2023-08-17 05:16:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 05:16:01 | INFO | fairseq.trainer | begin training epoch 32
2023-08-17 05:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 05:16:28 | INFO | train_inner | epoch 032:     27 / 1474 loss=1.897, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.629, task_loss=3.44, contrastive_loss=0.074, total=4051.41, n_correct=2805.11, ppl=3.87, accuracy=69.238, wps=6412.4, ups=0.79, wpb=8102.8, bsz=291.6, num_updates=45700, lr=6.61541e-05, gnorm=0.583, clip=0, loss_scale=8, train_wall=68, gb_free=15.7, wall=11326
2023-08-17 05:17:36 | INFO | train_inner | epoch 032:    127 / 1474 loss=1.883, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.612, task_loss=3.087, contrastive_loss=0.083, total=4208.32, n_correct=2932.24, ppl=3.81, accuracy=69.677, wps=12234.2, ups=1.45, wpb=8416.6, bsz=319.1, num_updates=45800, lr=6.60819e-05, gnorm=0.581, clip=0, loss_scale=8, train_wall=68, gb_free=11.2, wall=11394
2023-08-17 05:18:46 | INFO | train_inner | epoch 032:    227 / 1474 loss=1.893, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.625, task_loss=3.144, contrastive_loss=0.092, total=4157.86, n_correct=2880.38, ppl=3.87, accuracy=69.276, wps=11984.3, ups=1.44, wpb=8315.7, bsz=320.3, num_updates=45900, lr=6.60098e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=69, gb_free=14, wall=11464
2023-08-17 05:19:55 | INFO | train_inner | epoch 032:    327 / 1474 loss=1.882, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.611, task_loss=3.129, contrastive_loss=0.086, total=4179.17, n_correct=2916.96, ppl=3.8, accuracy=69.798, wps=12116.2, ups=1.45, wpb=8358.3, bsz=313.4, num_updates=46000, lr=6.5938e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=11533
2023-08-17 05:19:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 05:20:18 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.166 | nll_loss 2.424 | w2v_ctc_loss 1.317 | task_loss 11.631 | contrastive_loss 0.292 | total 4003.4 | n_correct 2673.8 | ppl 5.37 | accuracy 66.788 | uer 17.54 | wer 19.324 | raw_wer 19.324 | bleu 22.31 | wps 2243.6 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.54
2023-08-17 05:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-17 05:20:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_32_46000.pt
2023-08-17 05:20:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_32_46000.pt
2023-08-17 05:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.31) (writing took 41.262721514329314 seconds)
2023-08-17 05:22:12 | INFO | train_inner | epoch 032:    427 / 1474 loss=1.888, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.623, task_loss=3.185, contrastive_loss=0.083, total=4179.5, n_correct=2908.94, ppl=3.82, accuracy=69.6, wps=6114.3, ups=0.73, wpb=8359, bsz=312.2, num_updates=46100, lr=6.58665e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=68, gb_free=17.5, wall=11670
2023-08-17 05:23:21 | INFO | train_inner | epoch 032:    527 / 1474 loss=1.906, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.631, task_loss=3.247, contrastive_loss=0.165, total=4188.83, n_correct=2901.31, ppl=3.87, accuracy=69.263, wps=12098.1, ups=1.44, wpb=8377.7, bsz=313.9, num_updates=46200, lr=6.57952e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=69, gb_free=12.4, wall=11739
2023-08-17 05:24:30 | INFO | train_inner | epoch 032:    627 / 1474 loss=1.899, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.631, task_loss=3.455, contrastive_loss=0.09, total=4133.19, n_correct=2861.31, ppl=3.87, accuracy=69.228, wps=11893.5, ups=1.44, wpb=8266.4, bsz=298.7, num_updates=46300, lr=6.57241e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=11808
2023-08-17 05:25:40 | INFO | train_inner | epoch 032:    727 / 1474 loss=1.897, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.632, task_loss=3.314, contrastive_loss=0.074, total=4162.1, n_correct=2883.47, ppl=3.87, accuracy=69.279, wps=12021.1, ups=1.44, wpb=8324.2, bsz=304.3, num_updates=46400, lr=6.56532e-05, gnorm=0.591, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=11878
2023-08-17 05:26:48 | INFO | train_inner | epoch 032:    827 / 1474 loss=1.895, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.627, task_loss=3.433, contrastive_loss=0.073, total=4107.86, n_correct=2848.21, ppl=3.86, accuracy=69.336, wps=12028, ups=1.46, wpb=8215.7, bsz=292.6, num_updates=46500, lr=6.55826e-05, gnorm=0.642, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=11946
2023-08-17 05:27:57 | INFO | train_inner | epoch 032:    927 / 1474 loss=1.891, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.622, task_loss=3.374, contrastive_loss=0.069, total=4146.9, n_correct=2875.64, ppl=3.85, accuracy=69.344, wps=12054.8, ups=1.45, wpb=8293.8, bsz=300.4, num_updates=46600, lr=6.55122e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=12015
2023-08-17 05:29:06 | INFO | train_inner | epoch 032:   1027 / 1474 loss=1.904, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.627, task_loss=3.276, contrastive_loss=0.163, total=4112.45, n_correct=2848.84, ppl=3.87, accuracy=69.274, wps=11902, ups=1.45, wpb=8224.9, bsz=304.3, num_updates=46700, lr=6.5442e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=69, gb_free=16.9, wall=12084
2023-08-17 05:30:15 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.909, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.637, task_loss=3.922, contrastive_loss=0.107, total=4015.2, n_correct=2772.32, ppl=3.88, accuracy=69.046, wps=11558.2, ups=1.44, wpb=8030.4, bsz=269.7, num_updates=46800, lr=6.5372e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=69, gb_free=14.1, wall=12153
2023-08-17 05:31:24 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.912, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.623, task_loss=3.224, contrastive_loss=0.213, total=4158.99, n_correct=2874.2, ppl=3.89, accuracy=69.108, wps=12096.5, ups=1.45, wpb=8318, bsz=312.1, num_updates=46900, lr=6.53023e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=68, gb_free=15.9, wall=12222
2023-08-17 05:32:32 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.897, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.632, task_loss=3.351, contrastive_loss=0.072, total=4079.56, n_correct=2824, ppl=3.86, accuracy=69.223, wps=12015.9, ups=1.47, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=12290
2023-08-17 05:33:41 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.921, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.636, task_loss=3.342, contrastive_loss=0.307, total=4107.37, n_correct=2838.86, ppl=3.88, accuracy=69.116, wps=11924.1, ups=1.45, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=12359
2023-08-17 05:34:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 05:34:36 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.159 | nll_loss 2.413 | w2v_ctc_loss 1.327 | task_loss 11.626 | contrastive_loss 0.297 | total 4003.4 | n_correct 2676.7 | ppl 5.33 | accuracy 66.861 | uer 17.27 | wer 19.104 | raw_wer 19.104 | bleu 22.38 | wps 2220.5 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 22.54
2023-08-17 05:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-08-17 05:34:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3804.pt
2023-08-17 05:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3804.pt
2023-08-17 05:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.3804.pt (epoch 32 @ 47147 updates, score 22.38) (writing took 26.746611887589097 seconds)
2023-08-17 05:35:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-17 05:35:04 | INFO | train | epoch 032 | loss 1.898 | trans_loss 4.752 | nll_loss 1.947 | w2v_ctc_loss 0.626 | task_loss 3.294 | contrastive_loss 0.125 | total 4138.65 | n_correct 2869.23 | ppl 3.86 | accuracy 69.328 | wps 10678.6 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.563 | clip 0 | loss_scale 16 | train_wall 1009 | gb_free 16.2 | wall 12442
2023-08-17 05:35:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 05:35:04 | INFO | fairseq.trainer | begin training epoch 33
2023-08-17 05:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 05:35:48 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.9, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.62, task_loss=3.12, contrastive_loss=0.175, total=4146.91, n_correct=2876.56, ppl=3.85, accuracy=69.366, wps=6533.7, ups=0.79, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=12486
2023-08-17 05:36:56 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.883, trans_loss=4.736, nll_loss=1.926, w2v_ctc_loss=0.612, task_loss=3.535, contrastive_loss=0.062, total=4073.36, n_correct=2838.96, ppl=3.8, accuracy=69.696, wps=11904.1, ups=1.46, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=12554
2023-08-17 05:38:05 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.898, trans_loss=4.736, nll_loss=1.928, w2v_ctc_loss=0.61, task_loss=2.785, contrastive_loss=0.238, total=4283.64, n_correct=2982.85, ppl=3.81, accuracy=69.634, wps=12391.9, ups=1.45, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=12623
2023-08-17 05:39:15 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.894, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.628, task_loss=3.354, contrastive_loss=0.09, total=4131.27, n_correct=2867.13, ppl=3.83, accuracy=69.401, wps=11895.9, ups=1.44, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=12693
2023-08-17 05:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-17 05:40:23 | INFO | train_inner | epoch 033:    454 / 1474 loss=1.877, trans_loss=4.731, nll_loss=1.92, w2v_ctc_loss=0.61, task_loss=3.141, contrastive_loss=0.069, total=4131.66, n_correct=2883.04, ppl=3.78, accuracy=69.779, wps=12038.7, ups=1.46, wpb=8263.3, bsz=308.8, num_updates=47600, lr=6.48204e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=68, gb_free=15.4, wall=12761
2023-08-17 05:41:32 | INFO | train_inner | epoch 033:    554 / 1474 loss=1.895, trans_loss=4.747, nll_loss=1.94, w2v_ctc_loss=0.625, task_loss=3.423, contrastive_loss=0.093, total=4136.29, n_correct=2872.36, ppl=3.84, accuracy=69.443, wps=12026.5, ups=1.45, wpb=8272.6, bsz=294.8, num_updates=47700, lr=6.47524e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=68, gb_free=14.6, wall=12830
2023-08-17 05:42:41 | INFO | train_inner | epoch 033:    654 / 1474 loss=1.901, trans_loss=4.758, nll_loss=1.954, w2v_ctc_loss=0.623, task_loss=3.398, contrastive_loss=0.125, total=4155.56, n_correct=2878.44, ppl=3.87, accuracy=69.267, wps=12017.5, ups=1.45, wpb=8311.1, bsz=300.4, num_updates=47800, lr=6.46846e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=69, gb_free=14.9, wall=12899
2023-08-17 05:43:51 | INFO | train_inner | epoch 033:    754 / 1474 loss=1.898, trans_loss=4.749, nll_loss=1.943, w2v_ctc_loss=0.638, task_loss=3.528, contrastive_loss=0.071, total=4076.72, n_correct=2828.29, ppl=3.85, accuracy=69.377, wps=11728.1, ups=1.44, wpb=8153.4, bsz=289.6, num_updates=47900, lr=6.46171e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=12969
2023-08-17 05:45:00 | INFO | train_inner | epoch 033:    854 / 1474 loss=1.888, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.613, task_loss=3.152, contrastive_loss=0.141, total=4126.23, n_correct=2874.02, ppl=3.82, accuracy=69.652, wps=12009, ups=1.46, wpb=8252.5, bsz=314.4, num_updates=48000, lr=6.45497e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=68, gb_free=15.7, wall=13038
2023-08-17 05:45:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 05:45:22 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.173 | nll_loss 2.431 | w2v_ctc_loss 1.304 | task_loss 11.562 | contrastive_loss 0.297 | total 4003.4 | n_correct 2674.7 | ppl 5.39 | accuracy 66.811 | uer 17.328 | wer 19.097 | raw_wer 19.097 | bleu 22.14 | wps 2255.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.54
2023-08-17 05:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-17 05:45:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_33_48000.pt
2023-08-17 05:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_33_48000.pt
2023-08-17 05:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.14) (writing took 26.180449228733778 seconds)
2023-08-17 05:46:57 | INFO | train_inner | epoch 033:    954 / 1474 loss=1.894, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.633, task_loss=3.25, contrastive_loss=0.085, total=4161.72, n_correct=2889.78, ppl=3.84, accuracy=69.437, wps=7075.3, ups=0.85, wpb=8323.4, bsz=312, num_updates=48100, lr=6.44826e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=68, gb_free=15.7, wall=13155
2023-08-17 05:48:07 | INFO | train_inner | epoch 033:   1054 / 1474 loss=1.899, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.621, task_loss=3.342, contrastive_loss=0.185, total=4134.8, n_correct=2874.43, ppl=3.82, accuracy=69.518, wps=11946.9, ups=1.44, wpb=8269.6, bsz=304.7, num_updates=48200, lr=6.44157e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=13225
2023-08-17 05:49:17 | INFO | train_inner | epoch 033:   1154 / 1474 loss=1.899, trans_loss=4.754, nll_loss=1.949, w2v_ctc_loss=0.615, task_loss=3.311, contrastive_loss=0.173, total=4177.62, n_correct=2898.29, ppl=3.86, accuracy=69.377, wps=11913.2, ups=1.43, wpb=8355.2, bsz=309.6, num_updates=48300, lr=6.43489e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=13295
2023-08-17 05:50:25 | INFO | train_inner | epoch 033:   1254 / 1474 loss=1.892, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.625, task_loss=3.455, contrastive_loss=0.074, total=4115.15, n_correct=2860.01, ppl=3.83, accuracy=69.5, wps=11965.1, ups=1.45, wpb=8230.3, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=13363
2023-08-17 05:51:34 | INFO | train_inner | epoch 033:   1354 / 1474 loss=1.89, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.624, task_loss=3.233, contrastive_loss=0.094, total=4121.6, n_correct=2868.24, ppl=3.84, accuracy=69.59, wps=11949.8, ups=1.45, wpb=8243.2, bsz=311.7, num_updates=48500, lr=6.42161e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=69, gb_free=15.1, wall=13432
2023-08-17 05:52:43 | INFO | train_inner | epoch 033:   1454 / 1474 loss=1.903, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.618, task_loss=3.273, contrastive_loss=0.237, total=4131.62, n_correct=2867.91, ppl=3.85, accuracy=69.414, wps=12040.6, ups=1.46, wpb=8263.2, bsz=309.9, num_updates=48600, lr=6.415e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=13501
2023-08-17 05:52:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 05:53:20 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.164 | nll_loss 2.42 | w2v_ctc_loss 1.349 | task_loss 11.71 | contrastive_loss 0.295 | total 4003.4 | n_correct 2677 | ppl 5.35 | accuracy 66.868 | uer 17.437 | wer 19.265 | raw_wer 19.265 | bleu 22.46 | wps 2129.6 | wpb 4003.4 | bsz 141.8 | num_updates 48620 | best_bleu 22.54
2023-08-17 05:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48620 updates
2023-08-17 05:53:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4600.pt
2023-08-17 05:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4600.pt
2023-08-17 05:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint.best_bleu_22.4600.pt (epoch 33 @ 48620 updates, score 22.46) (writing took 24.22829613648355 seconds)
2023-08-17 05:53:45 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-17 05:53:45 | INFO | train | epoch 033 | loss 1.893 | trans_loss 4.744 | nll_loss 1.938 | w2v_ctc_loss 0.621 | task_loss 3.294 | contrastive_loss 0.123 | total 4138.71 | n_correct 2876.74 | ppl 3.83 | accuracy 69.508 | wps 10874.8 | ups 1.31 | wpb 8277.4 | bsz 305.7 | num_updates 48620 | lr 6.41368e-05 | gnorm 0.552 | clip 0 | loss_scale 8 | train_wall 1009 | gb_free 17.6 | wall 13563
2023-08-17 05:53:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 05:53:45 | INFO | fairseq.trainer | begin training epoch 34
2023-08-17 05:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 05:54:49 | INFO | train_inner | epoch 034:     80 / 1474 loss=1.885, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.62, task_loss=3.28, contrastive_loss=0.076, total=4123.05, n_correct=2874.66, ppl=3.79, accuracy=69.722, wps=6560.5, ups=0.8, wpb=8246.1, bsz=300.6, num_updates=48700, lr=6.40841e-05, gnorm=0.552, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=13627
2023-08-17 05:55:58 | INFO | train_inner | epoch 034:    180 / 1474 loss=1.878, trans_loss=4.723, nll_loss=1.909, w2v_ctc_loss=0.613, task_loss=3.438, contrastive_loss=0.077, total=4066.35, n_correct=2848.88, ppl=3.76, accuracy=70.06, wps=11816.7, ups=1.45, wpb=8132.7, bsz=295.2, num_updates=48800, lr=6.40184e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=13696
2023-08-17 05:57:07 | INFO | train_inner | epoch 034:    280 / 1474 loss=1.905, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.609, task_loss=3.07, contrastive_loss=0.281, total=4247.33, n_correct=2952.46, ppl=3.83, accuracy=69.513, wps=12298.5, ups=1.45, wpb=8494.7, bsz=329.5, num_updates=48900, lr=6.39529e-05, gnorm=0.549, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=13765
2023-08-17 05:58:16 | INFO | train_inner | epoch 034:    380 / 1474 loss=1.886, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.609, task_loss=3.143, contrastive_loss=0.177, total=4152.22, n_correct=2898.97, ppl=3.77, accuracy=69.817, wps=12028.1, ups=1.45, wpb=8304.4, bsz=316.1, num_updates=49000, lr=6.38877e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=13834
2023-08-17 05:59:25 | INFO | train_inner | epoch 034:    480 / 1474 loss=1.888, trans_loss=4.737, nll_loss=1.926, w2v_ctc_loss=0.624, task_loss=3.586, contrastive_loss=0.07, total=4080.7, n_correct=2842.72, ppl=3.8, accuracy=69.663, wps=11710.4, ups=1.43, wpb=8161.4, bsz=286.7, num_updates=49100, lr=6.38226e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=69, gb_free=15.4, wall=13903
2023-08-17 06:00:34 | INFO | train_inner | epoch 034:    580 / 1474 loss=1.879, trans_loss=4.728, nll_loss=1.916, w2v_ctc_loss=0.613, task_loss=3.345, contrastive_loss=0.071, total=4126.98, n_correct=2884.45, ppl=3.77, accuracy=69.893, wps=12109.6, ups=1.47, wpb=8254, bsz=300.1, num_updates=49200, lr=6.37577e-05, gnorm=0.598, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=13972
2023-08-17 06:01:42 | INFO | train_inner | epoch 034:    680 / 1474 loss=1.878, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.609, task_loss=3.398, contrastive_loss=0.066, total=4110.23, n_correct=2869.9, ppl=3.79, accuracy=69.823, wps=12045.5, ups=1.47, wpb=8220.5, bsz=297.1, num_updates=49300, lr=6.3693e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=14040
2023-08-17 06:02:50 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.892, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.608, task_loss=3.419, contrastive_loss=0.136, total=4087.05, n_correct=2838.25, ppl=3.86, accuracy=69.445, wps=11978, ups=1.47, wpb=8174.1, bsz=297.4, num_updates=49400, lr=6.36285e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=14108
2023-08-17 06:04:00 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.891, trans_loss=4.744, nll_loss=1.936, w2v_ctc_loss=0.619, task_loss=3.51, contrastive_loss=0.094, total=4088.94, n_correct=2841.25, ppl=3.83, accuracy=69.486, wps=11736.3, ups=1.44, wpb=8177.9, bsz=294.2, num_updates=49500, lr=6.35642e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=69, gb_free=14.5, wall=14178
2023-08-17 06:05:09 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.891, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.626, task_loss=3.226, contrastive_loss=0.091, total=4175.9, n_correct=2902.25, ppl=3.82, accuracy=69.5, wps=12149.3, ups=1.45, wpb=8351.8, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=13.4, wall=14246
2023-08-17 06:06:17 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.885, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.621, task_loss=3.177, contrastive_loss=0.072, total=4152.17, n_correct=2896.3, ppl=3.81, accuracy=69.754, wps=12174.1, ups=1.47, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=14315
2023-08-17 06:07:25 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.889, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.621, task_loss=3.388, contrastive_loss=0.085, total=4101.68, n_correct=2854.74, ppl=3.82, accuracy=69.599, wps=12003, ups=1.46, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=14383
2023-08-17 06:08:35 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.886, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.619, task_loss=3.316, contrastive_loss=0.07, total=4146.01, n_correct=2881.79, ppl=3.81, accuracy=69.508, wps=11920.9, ups=1.44, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=14453
2023-08-17 06:09:44 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.893, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.621, task_loss=3.151, contrastive_loss=0.133, total=4197.99, n_correct=2916.89, ppl=3.83, accuracy=69.483, wps=12170.6, ups=1.45, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=14522
2023-08-17 06:09:44 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-17 06:09:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 06:10:07 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.169 | nll_loss 2.424 | w2v_ctc_loss 1.317 | task_loss 11.643 | contrastive_loss 0.295 | total 4003.4 | n_correct 2675.9 | ppl 5.37 | accuracy 66.841 | uer 17.339 | wer 19.22 | raw_wer 19.22 | bleu 22.81 | wps 2207.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.81
2023-08-17 06:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-17 06:10:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_34_50000.pt
2023-08-17 06:10:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_34_50000.pt
2023-08-17 06:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_AT_sentence_alpha2.5_mt0.5_nopad/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.81) (writing took 44.455249501392245 seconds)
2023-08-17 06:10:52 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-17 06:10:52 | INFO | train | epoch 034 | loss 1.888 | trans_loss 4.737 | nll_loss 1.928 | w2v_ctc_loss 0.617 | task_loss 3.315 | contrastive_loss 0.109 | total 4133.03 | n_correct 2879.21 | ppl 3.81 | accuracy 69.663 | wps 11104.2 | ups 1.34 | wpb 8266.1 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.557 | clip 0 | loss_scale 16 | train_wall 944 | gb_free 17 | wall 14590
2023-08-17 06:10:52 | INFO | fairseq_cli.train | done training in 14525.7 seconds
Exception in thread Thread-9:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 560 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
stage 1: ST Network Training
dev=0,1,2,3,4,5,6,7 data=data_all_ende_lcrm model=./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py data_all_ende_lcrm --config-yaml config_st.yaml --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml --task joint_triple_pretraining_merge --max-tokens 15000 --skip-invalid-size-inputs-valid-test --update-freq 1 --log-interval 100 --save-dir ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard --distributed-world-size 8 --ddp-backend no_c10d --fp16 --eval-bleu --eval-tokenized-bleu --eval-bleu-remove-bpe sentencepiece --best-checkpoint-metric bleu --keep-best-checkpoints 10 --maximize-best-checkpoint-metric
[34mRun command: 
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py
        data_all_ende_lcrm
        --config-yaml config_st.yaml
        --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml
        --task joint_triple_pretraining_merge
        --max-tokens 15000
        --skip-invalid-size-inputs-valid-test
        --update-freq 1
        --log-interval 100
        --save-dir ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard
        --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard
        
        --distributed-world-size 8
        --ddp-backend no_c10d
        --fp16
        --eval-bleu
        --eval-tokenized-bleu
        --eval-bleu-remove-bpe sentencepiece
        --best-checkpoint-metric bleu
        --keep-best-checkpoints 10
        --maximize-best-checkpoint-metric
        --no-epoch-checkpoints
        --validate-interval 1 
        --save-interval 1 
        --keep-last-epochs 2 
        --save-interval-updates 2000
        --keep-interval-updates 5
        --share-decoder-input-output-embed
        --use-w2v-ctc [0m
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12642
2023-08-23 01:42:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-23 01:42:59 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-23 01:43:02 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12642', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-23 01:43:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-23 01:43:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-23 01:43:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-23 01:43:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-23 01:43:02 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-23 01:43:07 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-23 01:43:07 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-23 01:43:07 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-23 01:43:08 | INFO | root | load pretrained hubert
2023-08-23 01:43:16 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-23 01:43:19 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-23 01:43:24 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-23 01:43:24 | INFO | root | share the sematic adapter and textual encoder
2023-08-23 01:43:24 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-23 01:43:24 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-23 01:43:24 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-23 01:43:24 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-23 01:43:24 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-23 01:43:24 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-23 01:43:24 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 01:43:24 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-23 01:43:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-23 01:43:24 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 01:43:40 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-23 01:43:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-23 01:43:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-23 01:43:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 01:43:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 01:43:43 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-23 01:43:43 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-23 01:43:43 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_last.pt
2023-08-23 01:43:43 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_last.pt
2023-08-23 01:43:43 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-23 01:43:43 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 01:43:43 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-23 01:43:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-23 01:43:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 01:43:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 01:44:28 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-23 01:44:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 01:44:28 | INFO | fairseq.trainer | begin training epoch 1
2023-08-23 01:44:28 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-23 01:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
2023-08-23 01:44:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 01:44:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
True False
None None None
2023-08-23 01:44:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
True False
None None None
True False
None None None
True False
None None None
2023-08-23 01:45:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-23 01:45:43 | INFO | train_inner | epoch 001:    105 / 1474 loss=20.038, trans_loss=5.871, nll_loss=4.679, w2v_ctc_loss=22.307, task_loss=1.676, contrastive_loss=3.276, total=4220.8, n_correct=124.01, ppl=25.62, accuracy=2.938, wps=19838.9, ups=1.58, wpb=12594.8, bsz=477.2, num_updates=100, lr=4.098e-06, gnorm=2.809, clip=0, loss_scale=4, train_wall=68, gb_free=19.4, wall=119
2023-08-23 01:46:43 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.612, trans_loss=5.855, nll_loss=4.685, w2v_ctc_loss=17.115, task_loss=1.618, contrastive_loss=3.237, total=4114.86, n_correct=115.66, ppl=25.73, accuracy=2.811, wps=20422.1, ups=1.66, wpb=12286.8, bsz=458.8, num_updates=200, lr=8.096e-06, gnorm=7.313, clip=18, loss_scale=4, train_wall=60, gb_free=19.3, wall=180
2023-08-23 01:47:44 | INFO | train_inner | epoch 001:    305 / 1474 loss=9.925, trans_loss=5.841, nll_loss=4.705, w2v_ctc_loss=6.901, task_loss=1.567, contrastive_loss=3.175, total=4080.91, n_correct=110.42, ppl=26.09, accuracy=2.706, wps=19902.9, ups=1.63, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.082, clip=0, loss_scale=4, train_wall=61, gb_free=18.6, wall=241
2023-08-23 01:48:45 | INFO | train_inner | epoch 001:    405 / 1474 loss=9.408, trans_loss=5.811, nll_loss=4.702, w2v_ctc_loss=6.096, task_loss=1.347, contrastive_loss=3.207, total=4176.41, n_correct=96.2, ppl=26.02, accuracy=2.303, wps=20559.1, ups=1.65, wpb=12470, bsz=461.3, num_updates=400, lr=1.6092e-05, gnorm=1.297, clip=0, loss_scale=4, train_wall=60, gb_free=19.4, wall=302
2023-08-23 01:49:45 | INFO | train_inner | epoch 001:    505 / 1474 loss=9.197, trans_loss=5.728, nll_loss=4.612, w2v_ctc_loss=5.798, task_loss=1.217, contrastive_loss=3.304, total=4192.13, n_correct=98.5, ppl=24.45, accuracy=2.35, wps=20728.1, ups=1.65, wpb=12526, bsz=489.2, num_updates=500, lr=2.009e-05, gnorm=1.369, clip=0, loss_scale=4, train_wall=60, gb_free=19.1, wall=362
2023-08-23 01:50:45 | INFO | train_inner | epoch 001:    605 / 1474 loss=9.084, trans_loss=5.75, nll_loss=4.629, w2v_ctc_loss=5.66, task_loss=1.194, contrastive_loss=3.253, total=4131.49, n_correct=103.78, ppl=24.75, accuracy=2.512, wps=20562.5, ups=1.67, wpb=12320.8, bsz=473.5, num_updates=600, lr=2.4088e-05, gnorm=1.505, clip=1, loss_scale=4, train_wall=59, gb_free=18.9, wall=422
2023-08-23 01:51:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-23 01:51:46 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.028, trans_loss=5.785, nll_loss=4.679, w2v_ctc_loss=5.611, task_loss=1.25, contrastive_loss=3.132, total=4143.61, n_correct=93.56, ppl=25.62, accuracy=2.258, wps=20454.3, ups=1.65, wpb=12374.2, bsz=454.2, num_updates=700, lr=2.8086e-05, gnorm=1.25, clip=0, loss_scale=2, train_wall=60, gb_free=19.5, wall=482
2023-08-23 01:52:46 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.931, trans_loss=5.852, nll_loss=4.764, w2v_ctc_loss=5.442, task_loss=1.214, contrastive_loss=3.148, total=4129.2, n_correct=84.14, ppl=27.18, accuracy=2.038, wps=20547.6, ups=1.67, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.431, clip=0, loss_scale=2, train_wall=59, gb_free=19.2, wall=542
2023-08-23 01:53:47 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.783, trans_loss=5.864, nll_loss=4.775, w2v_ctc_loss=5.27, task_loss=1.234, contrastive_loss=3.055, total=4167.97, n_correct=85.87, ppl=27.39, accuracy=2.06, wps=20337.2, ups=1.63, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.58, clip=0, loss_scale=2, train_wall=61, gb_free=18.6, wall=604
2023-08-23 01:54:47 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.693, trans_loss=6.009, nll_loss=4.96, w2v_ctc_loss=5.019, task_loss=1.234, contrastive_loss=3.049, total=4137.5, n_correct=69.03, ppl=31.13, accuracy=1.668, wps=20445, ups=1.65, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.891, clip=0, loss_scale=2, train_wall=60, gb_free=19.3, wall=664
2023-08-23 01:55:47 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.5, trans_loss=6.064, nll_loss=5.018, w2v_ctc_loss=4.785, task_loss=1.269, contrastive_loss=2.956, total=4151.84, n_correct=65.1, ppl=32.4, accuracy=1.568, wps=20701.7, ups=1.67, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=1.831, clip=0, loss_scale=2, train_wall=59, gb_free=18.8, wall=724
2023-08-23 01:56:47 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.33, trans_loss=6.096, nll_loss=5.063, w2v_ctc_loss=4.596, task_loss=1.322, contrastive_loss=2.849, total=4123.25, n_correct=65.82, ppl=33.42, accuracy=1.596, wps=20528.2, ups=1.67, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.159, clip=0, loss_scale=2, train_wall=59, gb_free=19.6, wall=784
2023-08-23 01:57:47 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.171, trans_loss=6.104, nll_loss=5.073, w2v_ctc_loss=4.403, task_loss=1.244, contrastive_loss=2.797, total=4066.16, n_correct=69.06, ppl=33.66, accuracy=1.698, wps=20362.9, ups=1.68, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.356, clip=0, loss_scale=2, train_wall=59, gb_free=18.8, wall=843
2023-08-23 01:58:47 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8, trans_loss=6.06, nll_loss=5.019, w2v_ctc_loss=4.241, task_loss=1.265, contrastive_loss=2.87, total=4119.98, n_correct=72.31, ppl=32.42, accuracy=1.755, wps=20344.8, ups=1.65, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.438, clip=0, loss_scale=2, train_wall=60, gb_free=18.6, wall=904
2023-08-23 01:59:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-23 02:00:16 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.505 | trans_loss 13.881 | nll_loss 13.726 | w2v_ctc_loss 5.518 | task_loss 7.545 | contrastive_loss 4.104 | total 4003.4 | n_correct 41.1 | ppl 13548.7 | accuracy 1.027 | uer 70.363 | wer 68.424 | raw_wer 68.424 | bleu 0 | wps 1027.8 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-23 02:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-23 02:00:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:00:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 4.893041018978693 seconds)
2023-08-23 02:00:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-23 02:00:21 | INFO | train | epoch 001 | loss 10.1 | trans_loss 5.913 | nll_loss 4.821 | w2v_ctc_loss 7.243 | task_loss 1.326 | contrastive_loss 3.085 | total 4139.46 | n_correct 88.7255 | ppl 28.26 | accuracy 2.143 | wps 19266.6 | ups 1.56 | wpb 12358.4 | bsz 459 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.253 | clip 1.3 | loss_scale 2 | train_wall 885 | gb_free 18.9 | wall 998
2023-08-23 02:00:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 02:00:21 | INFO | fairseq.trainer | begin training epoch 2
2023-08-23 02:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 02:00:51 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.905, trans_loss=6.088, nll_loss=5.054, w2v_ctc_loss=4.087, task_loss=1.196, contrastive_loss=2.847, total=4165.61, n_correct=67.81, ppl=33.22, accuracy=1.628, wps=10014.5, ups=0.81, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.706, clip=0, loss_scale=2, train_wall=60, gb_free=18.7, wall=1028
2023-08-23 02:01:51 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.773, trans_loss=6.076, nll_loss=5.041, w2v_ctc_loss=4, task_loss=1.253, contrastive_loss=2.704, total=4153.7, n_correct=70.81, ppl=32.92, accuracy=1.705, wps=20815.9, ups=1.68, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.465, clip=0, loss_scale=2, train_wall=59, gb_free=19.1, wall=1088
2023-08-23 02:02:51 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.702, trans_loss=6.105, nll_loss=5.082, w2v_ctc_loss=3.839, task_loss=1.09, contrastive_loss=2.767, total=4201.44, n_correct=64.43, ppl=33.87, accuracy=1.534, wps=21060.5, ups=1.68, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.514, clip=0, loss_scale=2, train_wall=59, gb_free=18.9, wall=1147
2023-08-23 02:03:50 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.51, trans_loss=6.09, nll_loss=5.065, w2v_ctc_loss=3.783, task_loss=1.277, contrastive_loss=2.53, total=4130.13, n_correct=67.47, ppl=33.47, accuracy=1.634, wps=20662.5, ups=1.68, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.672, clip=0, loss_scale=2, train_wall=59, gb_free=18.7, wall=1207
2023-08-23 02:04:50 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.37, trans_loss=6.103, nll_loss=5.087, w2v_ctc_loss=3.714, task_loss=1.402, contrastive_loss=2.336, total=4035.12, n_correct=62.65, ppl=33.98, accuracy=1.553, wps=20225.1, ups=1.68, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.367, clip=0, loss_scale=2, train_wall=59, gb_free=19, wall=1266
2023-08-23 02:05:50 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.296, trans_loss=6.08, nll_loss=5.054, w2v_ctc_loss=3.574, task_loss=1.21, contrastive_loss=2.485, total=4183.09, n_correct=73.67, ppl=33.22, accuracy=1.761, wps=20757.5, ups=1.66, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.504, clip=0, loss_scale=2, train_wall=59, gb_free=18.5, wall=1327
2023-08-23 02:05:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 02:06:37 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.733 | trans_loss 13.452 | nll_loss 13.2 | w2v_ctc_loss 4.641 | task_loss 7.545 | contrastive_loss 3.539 | total 4003.4 | n_correct 63.2 | ppl 9407.75 | accuracy 1.579 | uer 62.419 | wer 60.52 | raw_wer 60.52 | bleu 0 | wps 1039.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-23 02:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-23 02:06:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_2_2000.pt
2023-08-23 02:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_2_2000.pt
2023-08-23 02:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 11.33712304290384 seconds)
2023-08-23 02:07:48 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.14, trans_loss=6.064, nll_loss=5.034, w2v_ctc_loss=3.479, task_loss=1.243, contrastive_loss=2.296, total=4123.85, n_correct=71.09, ppl=32.75, accuracy=1.724, wps=10457.5, ups=0.85, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.479, clip=0, loss_scale=2, train_wall=59, gb_free=18.6, wall=1444
2023-08-23 02:08:47 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.065, trans_loss=6.058, nll_loss=5.025, w2v_ctc_loss=3.412, task_loss=1.229, contrastive_loss=2.365, total=4148.13, n_correct=74.11, ppl=32.56, accuracy=1.787, wps=20796.3, ups=1.68, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.58, clip=0, loss_scale=2, train_wall=59, gb_free=18.5, wall=1504
2023-08-23 02:09:47 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.976, trans_loss=6.052, nll_loss=5.019, w2v_ctc_loss=3.361, task_loss=1.243, contrastive_loss=2.314, total=4172.27, n_correct=74.62, ppl=32.43, accuracy=1.788, wps=20862, ups=1.67, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.375, clip=0, loss_scale=2, train_wall=59, gb_free=18.8, wall=1564
2023-08-23 02:10:47 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.832, trans_loss=6.044, nll_loss=5.007, w2v_ctc_loss=3.273, task_loss=1.302, contrastive_loss=2.225, total=4101.67, n_correct=72.07, ppl=32.15, accuracy=1.757, wps=20545.2, ups=1.68, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.325, clip=0, loss_scale=2, train_wall=59, gb_free=18.9, wall=1623
2023-08-23 02:11:47 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.744, trans_loss=6.039, nll_loss=5, w2v_ctc_loss=3.21, task_loss=1.265, contrastive_loss=2.116, total=4091.09, n_correct=73.04, ppl=32, accuracy=1.785, wps=20336.1, ups=1.66, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.159, clip=0, loss_scale=2, train_wall=59, gb_free=19.2, wall=1683
2023-08-23 02:12:47 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.705, trans_loss=6.024, nll_loss=4.982, w2v_ctc_loss=3.111, task_loss=1.096, contrastive_loss=2.335, total=4219.19, n_correct=76.08, ppl=31.6, accuracy=1.803, wps=20787.9, ups=1.65, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.136, clip=0, loss_scale=2, train_wall=60, gb_free=19, wall=1744
2023-08-23 02:13:47 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.593, trans_loss=6.006, nll_loss=4.958, w2v_ctc_loss=3.079, task_loss=1.156, contrastive_loss=2.14, total=4212.91, n_correct=78.19, ppl=31.08, accuracy=1.856, wps=20922.1, ups=1.66, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.058, clip=0, loss_scale=2, train_wall=60, gb_free=19.1, wall=1804
2023-08-23 02:14:47 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.478, trans_loss=5.995, nll_loss=4.946, w2v_ctc_loss=3.042, task_loss=1.215, contrastive_loss=1.917, total=4142.48, n_correct=78.66, ppl=30.83, accuracy=1.899, wps=20887.1, ups=1.69, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.078, clip=0, loss_scale=4, train_wall=59, gb_free=18.9, wall=1863
2023-08-23 02:15:46 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.384, trans_loss=5.991, nll_loss=4.939, w2v_ctc_loss=2.996, task_loss=1.325, contrastive_loss=1.971, total=4063.28, n_correct=73.9, ppl=30.68, accuracy=1.819, wps=20311.9, ups=1.67, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=1.973, clip=0, loss_scale=4, train_wall=59, gb_free=19.6, wall=1923
2023-08-23 02:16:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 02:16:58 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.859 | trans_loss 13.046 | nll_loss 12.651 | w2v_ctc_loss 3.808 | task_loss 7.545 | contrastive_loss 2.649 | total 4003.4 | n_correct 86.2 | ppl 6431.07 | accuracy 2.153 | uer 53.242 | wer 52.366 | raw_wer 52.366 | bleu 0.01 | wps 1033.8 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0.01
2023-08-23 02:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-23 02:16:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.01) (writing took 11.278868613066152 seconds)
2023-08-23 02:17:10 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-23 02:17:10 | INFO | train | epoch 002 | loss 7.04 | trans_loss 6.052 | nll_loss 5.017 | w2v_ctc_loss 3.421 | task_loss 1.234 | contrastive_loss 2.321 | total 4138.65 | n_correct 72.133 | ppl 32.37 | accuracy 1.743 | wps 18050.6 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.333 | clip 0 | loss_scale 4 | train_wall 872 | gb_free 19 | wall 2007
2023-08-23 02:17:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 02:17:10 | INFO | fairseq.trainer | begin training epoch 3
2023-08-23 02:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 02:17:52 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.284, trans_loss=5.971, nll_loss=4.914, w2v_ctc_loss=2.944, task_loss=1.3, contrastive_loss=1.828, total=4048.67, n_correct=78.46, ppl=30.15, accuracy=1.938, wps=9612.1, ups=0.8, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.842, clip=0, loss_scale=4, train_wall=59, gb_free=18.8, wall=2049
2023-08-23 02:19:18 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.669, trans_loss=5.364, nll_loss=4.146, w2v_ctc_loss=2.709, task_loss=0.857, contrastive_loss=1.765, total=4148.1, n_correct=234.55, ppl=17.7, accuracy=5.654, wps=14373.4, ups=1.16, wpb=12386.6, bsz=459, num_updates=3100, lr=0.000124038, gnorm=3.868, clip=3, loss_scale=4, train_wall=86, gb_free=16.3, wall=2135
2023-08-23 02:20:46 | INFO | train_inner | epoch 003:    258 / 1474 loss=5.027, trans_loss=5.085, nll_loss=3.787, w2v_ctc_loss=2.392, task_loss=0.862, contrastive_loss=1.518, total=4161.13, n_correct=413.45, ppl=13.8, accuracy=9.936, wps=14164.4, ups=1.14, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=2.32, clip=0, loss_scale=4, train_wall=87, gb_free=16.8, wall=2223
2023-08-23 02:22:13 | INFO | train_inner | epoch 003:    358 / 1474 loss=4.753, trans_loss=4.953, nll_loss=3.606, w2v_ctc_loss=2.266, task_loss=0.866, contrastive_loss=1.439, total=4150.02, n_correct=516.98, ppl=12.17, accuracy=12.457, wps=14260.9, ups=1.15, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=2.154, clip=0, loss_scale=4, train_wall=86, gb_free=16.8, wall=2309
2023-08-23 02:23:40 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.492, trans_loss=4.82, nll_loss=3.427, w2v_ctc_loss=2.154, task_loss=0.841, contrastive_loss=1.268, total=4209.57, n_correct=630.95, ppl=10.76, accuracy=14.988, wps=14414.8, ups=1.15, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.923, clip=0, loss_scale=4, train_wall=87, gb_free=15.7, wall=2397
2023-08-23 02:25:06 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.265, trans_loss=4.72, nll_loss=3.296, w2v_ctc_loss=2.067, task_loss=0.921, contrastive_loss=1.13, total=4088.48, n_correct=694.92, ppl=9.82, accuracy=16.997, wps=14140.7, ups=1.16, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.854, clip=0, loss_scale=4, train_wall=86, gb_free=17.4, wall=2483
2023-08-23 02:26:35 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.118, trans_loss=4.613, nll_loss=3.148, w2v_ctc_loss=1.984, task_loss=0.827, contrastive_loss=1.196, total=4221.58, n_correct=843.86, ppl=8.86, accuracy=19.989, wps=14150.3, ups=1.12, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.72, clip=0, loss_scale=4, train_wall=88, gb_free=16.1, wall=2572
2023-08-23 02:28:02 | INFO | train_inner | epoch 003:    758 / 1474 loss=3.932, trans_loss=4.497, nll_loss=2.999, w2v_ctc_loss=1.965, task_loss=0.825, contrastive_loss=0.928, total=4167.41, n_correct=954.8, ppl=7.99, accuracy=22.911, wps=14345.8, ups=1.15, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.809, clip=0, loss_scale=4, train_wall=86, gb_free=16.1, wall=2659
2023-08-23 02:29:29 | INFO | train_inner | epoch 003:    858 / 1474 loss=3.748, trans_loss=4.339, nll_loss=2.789, w2v_ctc_loss=1.922, task_loss=0.875, contrastive_loss=0.852, total=4165.53, n_correct=1147.98, ppl=6.91, accuracy=27.559, wps=14372.3, ups=1.16, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.924, clip=0, loss_scale=4, train_wall=86, gb_free=16.7, wall=2745
2023-08-23 02:30:56 | INFO | train_inner | epoch 003:    958 / 1474 loss=3.57, trans_loss=4.138, nll_loss=2.526, w2v_ctc_loss=1.898, task_loss=0.839, contrastive_loss=0.857, total=4162.3, n_correct=1431.2, ppl=5.76, accuracy=34.385, wps=14298.7, ups=1.15, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.777, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2832
2023-08-23 02:32:22 | INFO | train_inner | epoch 003:   1058 / 1474 loss=3.431, trans_loss=4.046, nll_loss=2.409, w2v_ctc_loss=1.876, task_loss=0.92, contrastive_loss=0.76, total=4069.95, n_correct=1533.63, ppl=5.31, accuracy=37.682, wps=14046.9, ups=1.16, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.602, clip=0, loss_scale=4, train_wall=86, gb_free=16.1, wall=2919
2023-08-23 02:32:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 02:33:01 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.517 | trans_loss 6.713 | nll_loss 4.389 | w2v_ctc_loss 2.201 | task_loss 4.303 | contrastive_loss 1.003 | total 4003.4 | n_correct 1746.5 | ppl 20.96 | accuracy 43.625 | uer 32.172 | wer 32.728 | raw_wer 32.728 | bleu 6.43 | wps 1253.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.43
2023-08-23 02:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-23 02:33:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_3_4000.pt
2023-08-23 02:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_3_4000.pt
2023-08-23 02:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.43) (writing took 11.787538783974014 seconds)
2023-08-23 02:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-23 02:34:40 | INFO | train_inner | epoch 003:   1159 / 1474 loss=3.319, trans_loss=4.001, nll_loss=2.35, w2v_ctc_loss=1.831, task_loss=0.939, contrastive_loss=0.689, total=4034.56, n_correct=1594.08, ppl=5.1, accuracy=39.511, wps=8733.8, ups=0.73, wpb=12042.4, bsz=431.2, num_updates=4100, lr=0.000164018, gnorm=1.509, clip=0, loss_scale=2, train_wall=86, gb_free=15.8, wall=3057
2023-08-23 02:36:07 | INFO | train_inner | epoch 003:   1259 / 1474 loss=3.229, trans_loss=3.95, nll_loss=2.286, w2v_ctc_loss=1.79, task_loss=0.919, contrastive_loss=0.642, total=4064.26, n_correct=1682.72, ppl=4.88, accuracy=41.403, wps=13966.2, ups=1.15, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.41, clip=0, loss_scale=2, train_wall=86, gb_free=16.4, wall=3143
2023-08-23 02:37:34 | INFO | train_inner | epoch 003:   1359 / 1474 loss=3.185, trans_loss=3.915, nll_loss=2.242, w2v_ctc_loss=1.747, task_loss=0.874, contrastive_loss=0.723, total=4137.36, n_correct=1772.71, ppl=4.73, accuracy=42.846, wps=14125.5, ups=1.14, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.372, clip=0, loss_scale=2, train_wall=87, gb_free=15.8, wall=3231
2023-08-23 02:39:01 | INFO | train_inner | epoch 003:   1459 / 1474 loss=3.128, trans_loss=3.887, nll_loss=2.207, w2v_ctc_loss=1.723, task_loss=0.826, contrastive_loss=0.686, total=4207.75, n_correct=1849.3, ppl=4.62, accuracy=43.95, wps=14470, ups=1.15, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.303, clip=0, loss_scale=2, train_wall=86, gb_free=17.1, wall=3318
2023-08-23 02:39:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 02:39:51 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.103 | trans_loss 6.296 | nll_loss 3.859 | w2v_ctc_loss 1.999 | task_loss 4.15 | contrastive_loss 0.811 | total 4003.4 | n_correct 1997.2 | ppl 14.51 | accuracy 49.888 | uer 30.858 | wer 31.054 | raw_wer 31.054 | bleu 10.04 | wps 1342 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 10.04
2023-08-23 02:39:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-23 02:39:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:39:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 02:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 3 @ 4415 updates, score 10.04) (writing took 10.7379254080588 seconds)
2023-08-23 02:40:02 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-23 02:40:02 | INFO | train | epoch 003 | loss 4.074 | trans_loss 4.508 | nll_loss 3.016 | w2v_ctc_loss 2.056 | task_loss 0.886 | contrastive_loss 1.065 | total 4138.4 | n_correct 1059.61 | ppl 8.09 | accuracy 25.604 | wps 13261.4 | ups 1.07 | wpb 12355.1 | bsz 458.4 | num_updates 4415 | lr 0.000176612 | gnorm 1.889 | clip 0.2 | loss_scale 2 | train_wall 1256 | gb_free 16 | wall 3379
2023-08-23 02:40:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 02:40:03 | INFO | fairseq.trainer | begin training epoch 4
2023-08-23 02:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 02:41:22 | INFO | train_inner | epoch 004:     85 / 1474 loss=3, trans_loss=3.853, nll_loss=2.16, w2v_ctc_loss=1.678, task_loss=0.905, contrastive_loss=0.506, total=4095.18, n_correct=1852.74, ppl=4.47, accuracy=45.242, wps=8679, ups=0.71, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.238, clip=0, loss_scale=2, train_wall=85, gb_free=12.2, wall=3459
2023-08-23 02:42:48 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.964, trans_loss=3.82, nll_loss=2.118, w2v_ctc_loss=1.654, task_loss=0.823, contrastive_loss=0.52, total=4178.83, n_correct=1937.65, ppl=4.34, accuracy=46.368, wps=14439.2, ups=1.16, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=1.193, clip=0, loss_scale=2, train_wall=86, gb_free=14.4, wall=3545
2023-08-23 02:44:16 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.96, trans_loss=3.813, nll_loss=2.111, w2v_ctc_loss=1.648, task_loss=0.878, contrastive_loss=0.624, total=4142.3, n_correct=1935.89, ppl=4.32, accuracy=46.735, wps=14198.2, ups=1.15, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.23, clip=0, loss_scale=2, train_wall=87, gb_free=12.9, wall=3632
2023-08-23 02:45:42 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.885, trans_loss=3.797, nll_loss=2.087, w2v_ctc_loss=1.625, task_loss=0.903, contrastive_loss=0.453, total=4124.92, n_correct=1956.25, ppl=4.25, accuracy=47.425, wps=14265.9, ups=1.16, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=1.168, clip=0, loss_scale=2, train_wall=86, gb_free=12, wall=3718
2023-08-23 02:47:09 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.922, trans_loss=3.776, nll_loss=2.063, w2v_ctc_loss=1.583, task_loss=0.79, contrastive_loss=0.825, total=4216.09, n_correct=2036.92, ppl=4.18, accuracy=48.313, wps=14433.5, ups=1.15, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.15, clip=0, loss_scale=2, train_wall=87, gb_free=16.5, wall=3806
2023-08-23 02:48:36 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.845, trans_loss=3.755, nll_loss=2.035, w2v_ctc_loss=1.597, task_loss=0.81, contrastive_loss=0.515, total=4231.12, n_correct=2081.14, ppl=4.1, accuracy=49.187, wps=14525.4, ups=1.15, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=1.139, clip=0, loss_scale=2, train_wall=86, gb_free=15.8, wall=3893
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:0')
2023-08-23 02:50:04 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.797, trans_loss=3.751, nll_loss=2.026, w2v_ctc_loss=1.564, task_loss=0.901, contrastive_loss=0.533, total=4176.95, n_correct=2070.15, ppl=4.07, accuracy=49.561, wps=14078.2, ups=1.13, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.79, clip=0, loss_scale=2, train_wall=88, gb_free=14.7, wall=3981
2023-08-23 02:51:31 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.759, trans_loss=3.73, nll_loss=2.004, w2v_ctc_loss=1.581, task_loss=0.965, contrastive_loss=0.396, total=4016.91, n_correct=2010.39, ppl=4.01, accuracy=50.048, wps=13814.9, ups=1.15, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.765, clip=0, loss_scale=2, train_wall=86, gb_free=15.8, wall=4068
2023-08-23 02:52:58 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.78, trans_loss=3.712, nll_loss=1.982, w2v_ctc_loss=1.564, task_loss=0.873, contrastive_loss=0.561, total=4183.4, n_correct=2122.83, ppl=3.95, accuracy=50.744, wps=14382.7, ups=1.15, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.736, clip=0, loss_scale=2, train_wall=86, gb_free=15.2, wall=4155
2023-08-23 02:54:25 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.724, trans_loss=3.699, nll_loss=1.965, w2v_ctc_loss=1.545, task_loss=0.887, contrastive_loss=0.436, total=4128.78, n_correct=2120.49, ppl=3.91, accuracy=51.359, wps=14188.7, ups=1.15, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.747, clip=0, loss_scale=2, train_wall=86, gb_free=15.6, wall=4242
2023-08-23 02:55:52 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.716, trans_loss=3.699, nll_loss=1.964, w2v_ctc_loss=1.553, task_loss=0.936, contrastive_loss=0.405, total=4080.2, n_correct=2099.11, ppl=3.9, accuracy=51.446, wps=14063.4, ups=1.15, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.77, clip=0, loss_scale=2, train_wall=86, gb_free=15.8, wall=4328
2023-08-23 02:57:18 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.713, trans_loss=3.683, nll_loss=1.946, w2v_ctc_loss=1.528, task_loss=0.817, contrastive_loss=0.51, total=4163.45, n_correct=2167.92, ppl=3.85, accuracy=52.07, wps=14362.7, ups=1.15, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.703, clip=0, loss_scale=2, train_wall=86, gb_free=14.9, wall=4415
2023-08-23 02:58:45 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.674, trans_loss=3.666, nll_loss=1.924, w2v_ctc_loss=1.512, task_loss=0.834, contrastive_loss=0.46, total=4152.41, n_correct=2185.11, ppl=3.8, accuracy=52.623, wps=14303.6, ups=1.15, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.677, clip=0, loss_scale=2, train_wall=86, gb_free=12.5, wall=4502
2023-08-23 03:00:10 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.621, trans_loss=3.656, nll_loss=1.91, w2v_ctc_loss=1.504, task_loss=0.897, contrastive_loss=0.333, total=4103.57, n_correct=2175.66, ppl=3.76, accuracy=53.019, wps=14353.8, ups=1.17, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.663, clip=0, loss_scale=2, train_wall=85, gb_free=16.4, wall=4587
2023-08-23 03:01:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4919, device='cuda:3')
2023-08-23 03:02:03 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.479 | trans_loss 5.66 | nll_loss 3.05 | w2v_ctc_loss 1.68 | task_loss 4.415 | contrastive_loss 0.513 | total 4003.4 | n_correct 2351 | ppl 8.28 | accuracy 58.725 | uer 25.342 | wer 26.93 | raw_wer 26.93 | bleu 16.09 | wps 1417.7 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.09
2023-08-23 03:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-23 03:02:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.09) (writing took 10.833442158997059 seconds)
2023-08-23 03:02:13 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-23 03:02:13 | INFO | train | epoch 004 | loss 2.798 | trans_loss 3.737 | nll_loss 2.013 | w2v_ctc_loss 1.574 | task_loss 0.872 | contrastive_loss 0.5 | total 4138.65 | n_correct 2062.82 | ppl 4.04 | accuracy 49.843 | wps 13683.1 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.907 | clip 0 | loss_scale 2 | train_wall 1268 | gb_free 14.5 | wall 4710
2023-08-23 03:02:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 03:02:14 | INFO | fairseq.trainer | begin training epoch 5
2023-08-23 03:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 03:02:30 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.603, trans_loss=3.648, nll_loss=1.9, w2v_ctc_loss=1.477, task_loss=0.913, contrastive_loss=0.349, total=4031.51, n_correct=2150.13, ppl=3.73, accuracy=53.333, wps=8627, ups=0.72, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.667, clip=0, loss_scale=2, train_wall=85, gb_free=13.9, wall=4726
2023-08-23 03:03:57 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.533, trans_loss=3.609, nll_loss=1.849, w2v_ctc_loss=1.399, task_loss=0.78, contrastive_loss=0.366, total=4256.63, n_correct=2331.44, ppl=3.6, accuracy=54.772, wps=14640.2, ups=1.15, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.627, clip=0, loss_scale=2, train_wall=86, gb_free=15.9, wall=4813
2023-08-23 03:03:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 03:04:30 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.456 | trans_loss 5.644 | nll_loss 3.028 | w2v_ctc_loss 1.654 | task_loss 4.428 | contrastive_loss 0.5 | total 4003.4 | n_correct 2362 | ppl 8.16 | accuracy 59 | uer 24.729 | wer 26.147 | raw_wer 26.147 | bleu 16.67 | wps 1614.8 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.67
2023-08-23 03:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-23 03:04:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_5_6000.pt
2023-08-23 03:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_5_6000.pt
2023-08-23 03:04:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.67) (writing took 12.063447497901507 seconds)
2023-08-23 03:06:08 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.569, trans_loss=3.615, nll_loss=1.855, w2v_ctc_loss=1.414, task_loss=0.811, contrastive_loss=0.551, total=4186.83, n_correct=2293.55, ppl=3.62, accuracy=54.78, wps=9529.8, ups=0.76, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.63, clip=0, loss_scale=2, train_wall=85, gb_free=15.8, wall=4944
2023-08-23 03:07:35 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.539, trans_loss=3.6, nll_loss=1.842, w2v_ctc_loss=1.428, task_loss=0.893, contrastive_loss=0.405, total=4094.07, n_correct=2240.05, ppl=3.58, accuracy=54.715, wps=14103.2, ups=1.15, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.632, clip=0, loss_scale=4, train_wall=86, gb_free=15.9, wall=5031
2023-08-23 03:09:02 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.529, trans_loss=3.591, nll_loss=1.829, w2v_ctc_loss=1.392, task_loss=0.856, contrastive_loss=0.483, total=4140.39, n_correct=2285.18, ppl=3.55, accuracy=55.192, wps=14212.2, ups=1.15, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.638, clip=0, loss_scale=4, train_wall=86, gb_free=15.7, wall=5118
2023-08-23 03:10:28 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.477, trans_loss=3.593, nll_loss=1.83, w2v_ctc_loss=1.4, task_loss=0.976, contrastive_loss=0.274, total=4026.21, n_correct=2221.57, ppl=3.56, accuracy=55.178, wps=13915.1, ups=1.16, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.618, clip=0, loss_scale=4, train_wall=86, gb_free=16.7, wall=5205
2023-08-23 03:11:55 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.504, trans_loss=3.598, nll_loss=1.833, w2v_ctc_loss=1.387, task_loss=0.905, contrastive_loss=0.447, total=4109.94, n_correct=2278.12, ppl=3.56, accuracy=55.43, wps=14154.7, ups=1.15, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.639, clip=0, loss_scale=4, train_wall=86, gb_free=15.1, wall=5291
2023-08-23 03:13:21 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.499, trans_loss=3.591, nll_loss=1.826, w2v_ctc_loss=1.383, task_loss=0.824, contrastive_loss=0.42, total=4176.83, n_correct=2324.88, ppl=3.55, accuracy=55.661, wps=14410, ups=1.16, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.622, clip=0, loss_scale=4, train_wall=86, gb_free=16.7, wall=5378
2023-08-23 03:14:49 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.466, trans_loss=3.58, nll_loss=1.811, w2v_ctc_loss=1.377, task_loss=0.905, contrastive_loss=0.342, total=4127.9, n_correct=2308.41, ppl=3.51, accuracy=55.922, wps=14113.9, ups=1.15, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.603, clip=0, loss_scale=4, train_wall=87, gb_free=15.4, wall=5465
2023-08-23 03:16:15 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.431, trans_loss=3.57, nll_loss=1.8, w2v_ctc_loss=1.36, task_loss=0.901, contrastive_loss=0.301, total=4101.19, n_correct=2307.52, ppl=3.48, accuracy=56.265, wps=14155.9, ups=1.16, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.599, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=5552
2023-08-23 03:17:41 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.447, trans_loss=3.574, nll_loss=1.805, w2v_ctc_loss=1.361, task_loss=0.867, contrastive_loss=0.375, total=4164.27, n_correct=2342.41, ppl=3.49, accuracy=56.25, wps=14441.6, ups=1.16, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.601, clip=0, loss_scale=4, train_wall=85, gb_free=14.6, wall=5638
2023-08-23 03:19:08 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.46, trans_loss=3.569, nll_loss=1.798, w2v_ctc_loss=1.371, task_loss=0.874, contrastive_loss=0.38, total=4168.94, n_correct=2357.13, ppl=3.48, accuracy=56.54, wps=14272.1, ups=1.15, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.595, clip=0, loss_scale=4, train_wall=87, gb_free=16.3, wall=5725
2023-08-23 03:20:35 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.409, trans_loss=3.562, nll_loss=1.789, w2v_ctc_loss=1.344, task_loss=0.888, contrastive_loss=0.283, total=4171.16, n_correct=2366.93, ppl=3.45, accuracy=56.745, wps=14360.5, ups=1.15, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.589, clip=0, loss_scale=4, train_wall=86, gb_free=15.5, wall=5812
2023-08-23 03:22:02 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.38, trans_loss=3.555, nll_loss=1.78, w2v_ctc_loss=1.329, task_loss=0.894, contrastive_loss=0.241, total=4126.97, n_correct=2351.6, ppl=3.44, accuracy=56.981, wps=14151, ups=1.15, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.578, clip=0, loss_scale=4, train_wall=86, gb_free=15.1, wall=5899
2023-08-23 03:23:29 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.397, trans_loss=3.556, nll_loss=1.783, w2v_ctc_loss=1.328, task_loss=0.88, contrastive_loss=0.307, total=4138.54, n_correct=2361.53, ppl=3.44, accuracy=57.062, wps=14284.6, ups=1.16, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.589, clip=0, loss_scale=4, train_wall=86, gb_free=16.4, wall=5985
2023-08-23 03:24:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 03:24:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.277 | trans_loss 5.482 | nll_loss 2.831 | w2v_ctc_loss 1.493 | task_loss 4.484 | contrastive_loss 0.443 | total 4003.4 | n_correct 2464.8 | ppl 7.11 | accuracy 61.568 | uer 23.186 | wer 24.846 | raw_wer 24.846 | bleu 18.58 | wps 1650.2 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 18.58
2023-08-23 03:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-23 03:24:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 5 @ 7363 updates, score 18.58) (writing took 12.043395632994361 seconds)
2023-08-23 03:25:08 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-23 03:25:08 | INFO | train | epoch 005 | loss 2.472 | trans_loss 3.582 | nll_loss 1.815 | w2v_ctc_loss 1.376 | task_loss 0.875 | contrastive_loss 0.369 | total 4138.65 | n_correct 2311.98 | ppl 3.52 | accuracy 55.863 | wps 13251.5 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.611 | clip 0 | loss_scale 4 | train_wall 1268 | gb_free 15.8 | wall 6084
2023-08-23 03:25:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 03:25:08 | INFO | fairseq.trainer | begin training epoch 6
2023-08-23 03:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 03:25:47 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.38, trans_loss=3.54, nll_loss=1.761, w2v_ctc_loss=1.322, task_loss=0.902, contrastive_loss=0.301, total=4113.87, n_correct=2365.52, ppl=3.39, accuracy=57.501, wps=8868.5, ups=0.72, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.588, clip=0, loss_scale=4, train_wall=86, gb_free=17.5, wall=6124
2023-08-23 03:27:13 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.332, trans_loss=3.51, nll_loss=1.724, w2v_ctc_loss=1.268, task_loss=0.867, contrastive_loss=0.338, total=4161.2, n_correct=2424.21, ppl=3.3, accuracy=58.257, wps=14444.7, ups=1.16, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.565, clip=0, loss_scale=4, train_wall=85, gb_free=16.6, wall=6210
2023-08-23 03:28:39 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.336, trans_loss=3.523, nll_loss=1.741, w2v_ctc_loss=1.301, task_loss=0.941, contrastive_loss=0.246, total=4110.12, n_correct=2379.28, ppl=3.34, accuracy=57.888, wps=14249.8, ups=1.16, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.565, clip=0, loss_scale=4, train_wall=86, gb_free=16.8, wall=6296
2023-08-23 03:30:07 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.368, trans_loss=3.511, nll_loss=1.725, w2v_ctc_loss=1.25, task_loss=0.822, contrastive_loss=0.546, total=4170.52, n_correct=2433.9, ppl=3.31, accuracy=58.36, wps=14168.9, ups=1.14, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.58, clip=0, loss_scale=4, train_wall=87, gb_free=15.3, wall=6384
2023-08-23 03:31:33 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.301, trans_loss=3.507, nll_loss=1.72, w2v_ctc_loss=1.258, task_loss=0.842, contrastive_loss=0.258, total=4154.89, n_correct=2438.08, ppl=3.29, accuracy=58.68, wps=14417.5, ups=1.16, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.564, clip=0, loss_scale=4, train_wall=85, gb_free=16, wall=6470
2023-08-23 03:32:59 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.299, trans_loss=3.509, nll_loss=1.721, w2v_ctc_loss=1.266, task_loss=0.872, contrastive_loss=0.244, total=4174.46, n_correct=2450.79, ppl=3.3, accuracy=58.709, wps=14432.1, ups=1.16, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.555, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=6556
2023-08-23 03:34:25 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.302, trans_loss=3.511, nll_loss=1.725, w2v_ctc_loss=1.251, task_loss=0.833, contrastive_loss=0.296, total=4145.19, n_correct=2431.45, ppl=3.3, accuracy=58.657, wps=14414.9, ups=1.17, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.557, clip=0, loss_scale=4, train_wall=85, gb_free=15.5, wall=6642
2023-08-23 03:34:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 03:34:58 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.406 | nll_loss 2.734 | w2v_ctc_loss 1.529 | task_loss 4.554 | contrastive_loss 0.397 | total 4003.4 | n_correct 2508 | ppl 6.65 | accuracy 62.647 | uer 22.669 | wer 24.615 | raw_wer 24.615 | bleu 19.02 | wps 1638 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 19.02
2023-08-23 03:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-23 03:34:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_6_8000.pt
2023-08-23 03:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_6_8000.pt
2023-08-23 03:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 19.02) (writing took 11.978508225060068 seconds)
2023-08-23 03:36:37 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.297, trans_loss=3.509, nll_loss=1.722, w2v_ctc_loss=1.266, task_loss=0.892, contrastive_loss=0.248, total=4151.01, n_correct=2436.76, ppl=3.3, accuracy=58.703, wps=9410.9, ups=0.76, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.553, clip=0, loss_scale=4, train_wall=86, gb_free=12.6, wall=6774
2023-08-23 03:38:04 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.287, trans_loss=3.511, nll_loss=1.724, w2v_ctc_loss=1.259, task_loss=0.928, contrastive_loss=0.228, total=4108.83, n_correct=2409.22, ppl=3.3, accuracy=58.635, wps=14135.5, ups=1.15, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.553, clip=0, loss_scale=8, train_wall=86, gb_free=16.8, wall=6860
2023-08-23 03:39:31 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.314, trans_loss=3.513, nll_loss=1.727, w2v_ctc_loss=1.265, task_loss=0.921, contrastive_loss=0.328, total=4076.46, n_correct=2386.85, ppl=3.31, accuracy=58.552, wps=13986.9, ups=1.15, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.561, clip=0, loss_scale=8, train_wall=86, gb_free=12.3, wall=6947
2023-08-23 03:40:57 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.304, trans_loss=3.498, nll_loss=1.709, w2v_ctc_loss=1.239, task_loss=0.823, contrastive_loss=0.396, total=4175.9, n_correct=2462.81, ppl=3.27, accuracy=58.977, wps=14473.5, ups=1.16, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.561, clip=0, loss_scale=8, train_wall=85, gb_free=13.8, wall=7033
2023-08-23 03:42:23 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.278, trans_loss=3.498, nll_loss=1.709, w2v_ctc_loss=1.254, task_loss=0.966, contrastive_loss=0.234, total=4077.2, n_correct=2402.88, ppl=3.27, accuracy=58.935, wps=14090.8, ups=1.16, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.558, clip=0, loss_scale=8, train_wall=86, gb_free=16, wall=7120
2023-08-23 03:43:50 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.327, trans_loss=3.491, nll_loss=1.702, w2v_ctc_loss=1.234, task_loss=0.86, contrastive_loss=0.543, total=4133.46, n_correct=2441.72, ppl=3.25, accuracy=59.072, wps=14171.3, ups=1.15, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.562, clip=0, loss_scale=8, train_wall=86, gb_free=11.9, wall=7207
2023-08-23 03:45:16 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.248, trans_loss=3.493, nll_loss=1.7, w2v_ctc_loss=1.234, task_loss=0.869, contrastive_loss=0.21, total=4127.77, n_correct=2455.23, ppl=3.25, accuracy=59.481, wps=14377.2, ups=1.17, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.547, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=7293
2023-08-23 03:46:43 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.247, trans_loss=3.486, nll_loss=1.694, w2v_ctc_loss=1.231, task_loss=0.88, contrastive_loss=0.217, total=4190.32, n_correct=2495.28, ppl=3.23, accuracy=59.549, wps=14326.3, ups=1.15, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.539, clip=0, loss_scale=8, train_wall=87, gb_free=16.5, wall=7380
2023-08-23 03:47:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 03:47:48 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.161 | trans_loss 5.361 | nll_loss 2.683 | w2v_ctc_loss 1.45 | task_loss 4.556 | contrastive_loss 0.382 | total 4003.4 | n_correct 2529.1 | ppl 6.42 | accuracy 63.174 | uer 21.61 | wer 23.318 | raw_wer 23.318 | bleu 19.57 | wps 1597.6 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 19.57
2023-08-23 03:47:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-23 03:47:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 03:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 6 @ 8837 updates, score 19.57) (writing took 11.065078565035947 seconds)
2023-08-23 03:47:59 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-23 03:47:59 | INFO | train | epoch 006 | loss 2.301 | trans_loss 3.505 | nll_loss 1.717 | w2v_ctc_loss 1.255 | task_loss 0.877 | contrastive_loss 0.308 | total 4138.65 | n_correct 2431.95 | ppl 3.29 | accuracy 58.762 | wps 13279.8 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.558 | clip 0 | loss_scale 8 | train_wall 1265 | gb_free 14.7 | wall 7456
2023-08-23 03:47:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 03:47:59 | INFO | fairseq.trainer | begin training epoch 7
2023-08-23 03:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 03:49:01 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.215, trans_loss=3.472, nll_loss=1.676, w2v_ctc_loss=1.2, task_loss=0.853, contrastive_loss=0.227, total=4110.43, n_correct=2466.41, ppl=3.2, accuracy=60.004, wps=8889.2, ups=0.72, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.538, clip=0, loss_scale=8, train_wall=86, gb_free=17.1, wall=7518
2023-08-23 03:50:27 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.217, trans_loss=3.465, nll_loss=1.666, w2v_ctc_loss=1.187, task_loss=0.89, contrastive_loss=0.295, total=4109.53, n_correct=2471.36, ppl=3.17, accuracy=60.137, wps=14302.3, ups=1.17, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.547, clip=0, loss_scale=8, train_wall=85, gb_free=13.2, wall=7604
2023-08-23 03:51:53 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.195, trans_loss=3.459, nll_loss=1.657, w2v_ctc_loss=1.19, task_loss=0.879, contrastive_loss=0.204, total=4133.29, n_correct=2495.54, ppl=3.15, accuracy=60.377, wps=14334.2, ups=1.16, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.544, clip=0, loss_scale=8, train_wall=85, gb_free=14.8, wall=7690
2023-08-23 03:53:20 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.242, trans_loss=3.465, nll_loss=1.666, w2v_ctc_loss=1.177, task_loss=0.852, contrastive_loss=0.463, total=4194.76, n_correct=2525.41, ppl=3.17, accuracy=60.204, wps=14382.7, ups=1.15, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.533, clip=0, loss_scale=8, train_wall=86, gb_free=12.6, wall=7777
2023-08-23 03:54:47 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.224, trans_loss=3.462, nll_loss=1.664, w2v_ctc_loss=1.176, task_loss=0.869, contrastive_loss=0.386, total=4153.22, n_correct=2502.6, ppl=3.17, accuracy=60.257, wps=14280.6, ups=1.15, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.537, clip=0, loss_scale=8, train_wall=86, gb_free=16.4, wall=7864
2023-08-23 03:56:13 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.187, trans_loss=3.458, nll_loss=1.656, w2v_ctc_loss=1.179, task_loss=0.86, contrastive_loss=0.211, total=4168.14, n_correct=2526.34, ppl=3.15, accuracy=60.611, wps=14489.7, ups=1.17, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.533, clip=0, loss_scale=8, train_wall=85, gb_free=16.6, wall=7950
2023-08-23 03:57:40 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.173, trans_loss=3.456, nll_loss=1.654, w2v_ctc_loss=1.17, task_loss=0.87, contrastive_loss=0.195, total=4157.82, n_correct=2524.55, ppl=3.15, accuracy=60.718, wps=14314.2, ups=1.15, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.529, clip=0, loss_scale=8, train_wall=86, gb_free=15.2, wall=8036
2023-08-23 03:59:07 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.172, trans_loss=3.45, nll_loss=1.648, w2v_ctc_loss=1.174, task_loss=0.918, contrastive_loss=0.189, total=4122.1, n_correct=2498.93, ppl=3.13, accuracy=60.623, wps=14107.1, ups=1.15, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.532, clip=0, loss_scale=8, train_wall=87, gb_free=15.3, wall=8123
2023-08-23 04:00:34 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.177, trans_loss=3.458, nll_loss=1.657, w2v_ctc_loss=1.173, task_loss=0.883, contrastive_loss=0.209, total=4147.23, n_correct=2511.38, ppl=3.15, accuracy=60.556, wps=14243.6, ups=1.15, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.536, clip=0, loss_scale=8, train_wall=86, gb_free=17.2, wall=8210
2023-08-23 04:02:01 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.187, trans_loss=3.45, nll_loss=1.648, w2v_ctc_loss=1.159, task_loss=0.834, contrastive_loss=0.303, total=4140.14, n_correct=2513.3, ppl=3.13, accuracy=60.706, wps=14194, ups=1.15, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.535, clip=0, loss_scale=8, train_wall=86, gb_free=15.6, wall=8297
2023-08-23 04:03:28 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.166, trans_loss=3.459, nll_loss=1.659, w2v_ctc_loss=1.173, task_loss=0.92, contrastive_loss=0.175, total=4103.51, n_correct=2485.74, ppl=3.16, accuracy=60.576, wps=14144.1, ups=1.15, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.526, clip=0, loss_scale=8, train_wall=86, gb_free=16.4, wall=8384
2023-08-23 04:04:54 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.216, trans_loss=3.444, nll_loss=1.642, w2v_ctc_loss=1.16, task_loss=0.853, contrastive_loss=0.431, total=4137.04, n_correct=2520, ppl=3.12, accuracy=60.913, wps=14329.4, ups=1.16, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.538, clip=0, loss_scale=8, train_wall=86, gb_free=15.7, wall=8470
2023-08-23 04:04:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 04:05:27 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.093 | trans_loss 5.302 | nll_loss 2.606 | w2v_ctc_loss 1.386 | task_loss 4.616 | contrastive_loss 0.359 | total 4003.4 | n_correct 2568 | ppl 6.09 | accuracy 64.145 | uer 20.128 | wer 21.819 | raw_wer 21.819 | bleu 20.24 | wps 1623.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 20.24
2023-08-23 04:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-23 04:05:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_7_10000.pt
2023-08-23 04:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_7_10000.pt
2023-08-23 04:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 20.24) (writing took 13.470186279038899 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 04:07:06 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.156, trans_loss=3.447, nll_loss=1.645, w2v_ctc_loss=1.156, task_loss=0.889, contrastive_loss=0.201, total=4129.52, n_correct=2512.41, ppl=3.13, accuracy=60.84, wps=9347.3, ups=0.76, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.427, clip=0, loss_scale=8, train_wall=85, gb_free=16.5, wall=8602
2023-08-23 04:08:32 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.174, trans_loss=3.441, nll_loss=1.637, w2v_ctc_loss=1.165, task_loss=0.825, contrastive_loss=0.239, total=4172.87, n_correct=2550.21, ppl=3.11, accuracy=61.114, wps=14467.5, ups=1.16, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.43, clip=0, loss_scale=8, train_wall=85, gb_free=16.8, wall=8688
2023-08-23 04:10:00 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.183, trans_loss=3.445, nll_loss=1.644, w2v_ctc_loss=1.164, task_loss=0.947, contrastive_loss=0.3, total=4109.42, n_correct=2497.91, ppl=3.13, accuracy=60.785, wps=13987.8, ups=1.14, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.429, clip=0, loss_scale=16, train_wall=87, gb_free=16, wall=8776
2023-08-23 04:10:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
2023-08-23 04:10:42 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.097 | trans_loss 5.299 | nll_loss 2.6 | w2v_ctc_loss 1.402 | task_loss 4.593 | contrastive_loss 0.367 | total 4003.4 | n_correct 2566.2 | ppl 6.06 | accuracy 64.101 | uer 20.54 | wer 22.199 | raw_wer 22.199 | bleu 20.15 | wps 1591.8 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 20.24
2023-08-23 04:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-23 04:10:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_20.1504.pt
2023-08-23 04:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_20.1504.pt
2023-08-23 04:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_20.1504.pt (epoch 7 @ 10311 updates, score 20.15) (writing took 8.2530571219977 seconds)
2023-08-23 04:10:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-23 04:10:51 | INFO | train | epoch 007 | loss 2.191 | trans_loss 3.455 | nll_loss 1.653 | w2v_ctc_loss 1.172 | task_loss 0.878 | contrastive_loss 0.27 | total 4138.65 | n_correct 2507.43 | ppl 3.15 | accuracy 60.586 | wps 13277.4 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.513 | clip 0 | loss_scale 16 | train_wall 1267 | gb_free 12.8 | wall 8827
2023-08-23 04:10:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 04:10:51 | INFO | fairseq.trainer | begin training epoch 8
2023-08-23 04:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 04:12:16 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.124, trans_loss=3.433, nll_loss=1.623, w2v_ctc_loss=1.127, task_loss=0.925, contrastive_loss=0.194, total=4116.25, n_correct=2530.21, ppl=3.08, accuracy=61.469, wps=9023.8, ups=0.74, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.424, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=8912
2023-08-23 04:13:42 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.125, trans_loss=3.424, nll_loss=1.611, w2v_ctc_loss=1.125, task_loss=0.952, contrastive_loss=0.215, total=4037.23, n_correct=2489.26, ppl=3.06, accuracy=61.658, wps=13952.3, ups=1.16, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.43, clip=0, loss_scale=16, train_wall=86, gb_free=12.4, wall=8999
2023-08-23 04:15:08 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.12, trans_loss=3.419, nll_loss=1.606, w2v_ctc_loss=1.122, task_loss=0.822, contrastive_loss=0.209, total=4207.78, n_correct=2599.8, ppl=3.05, accuracy=61.786, wps=14556.4, ups=1.16, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.429, clip=0, loss_scale=16, train_wall=86, gb_free=12.4, wall=9085
2023-08-23 04:16:36 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.137, trans_loss=3.424, nll_loss=1.613, w2v_ctc_loss=1.137, task_loss=0.936, contrastive_loss=0.233, total=4127.24, n_correct=2541.86, ppl=3.06, accuracy=61.587, wps=14075.3, ups=1.14, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.426, clip=0, loss_scale=16, train_wall=87, gb_free=11.3, wall=9172
2023-08-23 04:18:03 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.188, trans_loss=3.422, nll_loss=1.612, w2v_ctc_loss=1.115, task_loss=0.787, contrastive_loss=0.492, total=4203.76, n_correct=2595.39, ppl=3.06, accuracy=61.74, wps=14438.9, ups=1.15, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.428, clip=0, loss_scale=16, train_wall=86, gb_free=14.1, wall=9259
2023-08-23 04:19:29 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.122, trans_loss=3.419, nll_loss=1.611, w2v_ctc_loss=1.138, task_loss=0.96, contrastive_loss=0.168, total=4062.5, n_correct=2498.81, ppl=3.06, accuracy=61.509, wps=13985.9, ups=1.15, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.427, clip=0, loss_scale=16, train_wall=86, gb_free=10.8, wall=9346
2023-08-23 04:20:56 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.113, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.131, task_loss=0.906, contrastive_loss=0.179, total=4142.78, n_correct=2564.61, ppl=3.04, accuracy=61.906, wps=14262.6, ups=1.15, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.421, clip=0, loss_scale=16, train_wall=86, gb_free=15.4, wall=9433
2023-08-23 04:22:22 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.125, trans_loss=3.412, nll_loss=1.602, w2v_ctc_loss=1.123, task_loss=0.901, contrastive_loss=0.265, total=4118.9, n_correct=2547.77, ppl=3.04, accuracy=61.856, wps=14301.8, ups=1.16, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.425, clip=0, loss_scale=16, train_wall=85, gb_free=14.9, wall=9519
2023-08-23 04:23:49 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.122, trans_loss=3.416, nll_loss=1.606, w2v_ctc_loss=1.11, task_loss=0.84, contrastive_loss=0.273, total=4169.01, n_correct=2581.84, ppl=3.04, accuracy=61.929, wps=14424.2, ups=1.16, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.423, clip=0, loss_scale=16, train_wall=86, gb_free=15.7, wall=9605
2023-08-23 04:25:15 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.095, trans_loss=3.414, nll_loss=1.602, w2v_ctc_loss=1.111, task_loss=0.839, contrastive_loss=0.172, total=4154.69, n_correct=2581.05, ppl=3.03, accuracy=62.124, wps=14429, ups=1.16, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.419, clip=0, loss_scale=16, train_wall=85, gb_free=17.4, wall=9691
2023-08-23 04:26:43 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.141, trans_loss=3.418, nll_loss=1.607, w2v_ctc_loss=1.11, task_loss=0.874, contrastive_loss=0.394, total=4199.1, n_correct=2596.74, ppl=3.05, accuracy=61.84, wps=14246.1, ups=1.14, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.419, clip=0, loss_scale=16, train_wall=87, gb_free=12.2, wall=9779
2023-08-23 04:28:08 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.1, trans_loss=3.409, nll_loss=1.597, w2v_ctc_loss=1.114, task_loss=0.827, contrastive_loss=0.181, total=4177.31, n_correct=2595.55, ppl=3.02, accuracy=62.134, wps=14560.3, ups=1.17, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.418, clip=0, loss_scale=16, train_wall=85, gb_free=14.4, wall=9865
2023-08-23 04:29:34 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.109, trans_loss=3.413, nll_loss=1.602, w2v_ctc_loss=1.123, task_loss=0.917, contrastive_loss=0.204, total=4063.85, n_correct=2514.29, ppl=3.04, accuracy=61.87, wps=14140, ups=1.16, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.423, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=9951
2023-08-23 04:31:00 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.118, trans_loss=3.416, nll_loss=1.606, w2v_ctc_loss=1.113, task_loss=0.868, contrastive_loss=0.253, total=4141.5, n_correct=2569.83, ppl=3.04, accuracy=62.051, wps=14427, ups=1.17, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.421, clip=0, loss_scale=16, train_wall=85, gb_free=16.1, wall=10036
2023-08-23 04:32:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 04:32:47 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.043 | trans_loss 5.249 | nll_loss 2.536 | w2v_ctc_loss 1.359 | task_loss 4.581 | contrastive_loss 0.339 | total 4003.4 | n_correct 2598.3 | ppl 5.8 | accuracy 64.902 | uer 19.81 | wer 21.576 | raw_wer 21.576 | bleu 20.66 | wps 1587 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 20.66
2023-08-23 04:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-23 04:32:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 04:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 04:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 8 @ 11785 updates, score 20.66) (writing took 12.743634168058634 seconds)
2023-08-23 04:33:00 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-23 04:33:00 | INFO | train | epoch 008 | loss 2.124 | trans_loss 3.418 | nll_loss 1.607 | w2v_ctc_loss 1.12 | task_loss 0.878 | contrastive_loss 0.252 | total 4138.65 | n_correct 2559.3 | ppl 3.05 | accuracy 61.839 | wps 13702.9 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.423 | clip 0 | loss_scale 16 | train_wall 1265 | gb_free 16.5 | wall 10157
2023-08-23 04:33:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 04:33:00 | INFO | fairseq.trainer | begin training epoch 9
2023-08-23 04:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 04:33:21 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.123, trans_loss=3.412, nll_loss=1.598, w2v_ctc_loss=1.097, task_loss=0.844, contrastive_loss=0.376, total=4139.35, n_correct=2574.55, ppl=3.03, accuracy=62.197, wps=8759, ups=0.71, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.415, clip=0, loss_scale=16, train_wall=86, gb_free=15.2, wall=10177
2023-08-23 04:34:47 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.059, trans_loss=3.385, nll_loss=1.565, w2v_ctc_loss=1.071, task_loss=0.832, contrastive_loss=0.195, total=4181.9, n_correct=2635.7, ppl=2.96, accuracy=63.026, wps=14471.1, ups=1.16, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.417, clip=0, loss_scale=16, train_wall=86, gb_free=15.9, wall=10264
2023-08-23 04:36:13 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.051, trans_loss=3.39, nll_loss=1.57, w2v_ctc_loss=1.075, task_loss=0.946, contrastive_loss=0.154, total=4062.07, n_correct=2552.08, ppl=2.97, accuracy=62.827, wps=14058.2, ups=1.16, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.415, clip=0, loss_scale=16, train_wall=86, gb_free=15.1, wall=10350
2023-08-23 04:36:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 04:36:47 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.034 | trans_loss 5.256 | nll_loss 2.545 | w2v_ctc_loss 1.317 | task_loss 4.573 | contrastive_loss 0.34 | total 4003.4 | n_correct 2600.8 | ppl 5.83 | accuracy 64.965 | uer 19.369 | wer 21.252 | raw_wer 21.252 | bleu 20.77 | wps 1549.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.77
2023-08-23 04:36:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-23 04:36:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_9_12000.pt
2023-08-23 04:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_9_12000.pt
2023-08-23 04:37:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.77) (writing took 12.444202940096147 seconds)
2023-08-23 04:38:26 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.048, trans_loss=3.378, nll_loss=1.558, w2v_ctc_loss=1.059, task_loss=0.819, contrastive_loss=0.202, total=4152.1, n_correct=2620.42, ppl=2.94, accuracy=63.111, wps=9382.7, ups=0.76, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.413, clip=0, loss_scale=16, train_wall=85, gb_free=16, wall=10482
2023-08-23 04:39:53 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.055, trans_loss=3.394, nll_loss=1.576, w2v_ctc_loss=1.071, task_loss=0.859, contrastive_loss=0.172, total=4203.78, n_correct=2632.12, ppl=2.98, accuracy=62.613, wps=14353.8, ups=1.14, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.417, clip=0, loss_scale=16, train_wall=87, gb_free=16.8, wall=10570
2023-08-23 04:41:19 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.085, trans_loss=3.394, nll_loss=1.575, w2v_ctc_loss=1.096, task_loss=0.923, contrastive_loss=0.221, total=4112.78, n_correct=2574.1, ppl=2.98, accuracy=62.588, wps=14249.2, ups=1.16, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.418, clip=0, loss_scale=32, train_wall=86, gb_free=15.8, wall=10656
2023-08-23 04:42:46 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.045, trans_loss=3.384, nll_loss=1.566, w2v_ctc_loss=1.063, task_loss=0.896, contrastive_loss=0.18, total=4131.32, n_correct=2598.28, ppl=2.96, accuracy=62.892, wps=14279.1, ups=1.16, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.413, clip=0, loss_scale=32, train_wall=86, gb_free=17.5, wall=10742
2023-08-23 04:44:12 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.084, trans_loss=3.393, nll_loss=1.577, w2v_ctc_loss=1.088, task_loss=0.899, contrastive_loss=0.261, total=4082.11, n_correct=2555.38, ppl=2.98, accuracy=62.599, wps=14192.2, ups=1.16, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.419, clip=0, loss_scale=32, train_wall=85, gb_free=16.7, wall=10828
2023-08-23 04:45:39 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.119, trans_loss=3.385, nll_loss=1.568, w2v_ctc_loss=1.08, task_loss=0.791, contrastive_loss=0.404, total=4221.08, n_correct=2650.59, ppl=2.96, accuracy=62.794, wps=14454.1, ups=1.15, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.42, clip=0, loss_scale=32, train_wall=87, gb_free=17.4, wall=10915
2023-08-23 04:47:06 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.092, trans_loss=3.391, nll_loss=1.571, w2v_ctc_loss=1.073, task_loss=0.909, contrastive_loss=0.383, total=4142.34, n_correct=2600.83, ppl=2.97, accuracy=62.786, wps=14158.6, ups=1.15, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.411, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=11003
2023-08-23 04:48:33 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.061, trans_loss=3.397, nll_loss=1.579, w2v_ctc_loss=1.086, task_loss=0.986, contrastive_loss=0.168, total=4097.15, n_correct=2564.73, ppl=2.99, accuracy=62.598, wps=14167.9, ups=1.16, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.418, clip=0, loss_scale=32, train_wall=86, gb_free=16.5, wall=11089
2023-08-23 04:49:59 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.057, trans_loss=3.394, nll_loss=1.573, w2v_ctc_loss=1.071, task_loss=0.819, contrastive_loss=0.19, total=4182.29, n_correct=2630.75, ppl=2.98, accuracy=62.902, wps=14352.1, ups=1.15, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.411, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=11176
2023-08-23 04:51:27 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.066, trans_loss=3.392, nll_loss=1.574, w2v_ctc_loss=1.091, task_loss=0.934, contrastive_loss=0.173, total=4141.43, n_correct=2598.26, ppl=2.98, accuracy=62.738, wps=14184.9, ups=1.15, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.417, clip=0, loss_scale=32, train_wall=87, gb_free=17.2, wall=11263
2023-08-23 04:52:53 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.092, trans_loss=3.387, nll_loss=1.568, w2v_ctc_loss=1.066, task_loss=0.797, contrastive_loss=0.365, total=4203.91, n_correct=2646.23, ppl=2.96, accuracy=62.947, wps=14514.7, ups=1.16, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.413, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=11350
2023-08-23 04:54:19 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.051, trans_loss=3.396, nll_loss=1.578, w2v_ctc_loss=1.079, task_loss=0.949, contrastive_loss=0.15, total=4077.08, n_correct=2555.5, ppl=2.99, accuracy=62.68, wps=14181.3, ups=1.17, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.411, clip=0, loss_scale=32, train_wall=85, gb_free=17, wall=11435
2023-08-23 04:55:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 04:55:42 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.024 | trans_loss 5.23 | nll_loss 2.517 | w2v_ctc_loss 1.347 | task_loss 4.643 | contrastive_loss 0.332 | total 4003.4 | n_correct 2608 | ppl 5.72 | accuracy 65.145 | uer 19.144 | wer 20.946 | raw_wer 20.946 | bleu 20.9 | wps 1645.5 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 20.9
2023-08-23 04:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-23 04:55:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 04:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 04:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 9 @ 13259 updates, score 20.9) (writing took 11.498548886971548 seconds)
2023-08-23 04:55:54 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-23 04:55:54 | INFO | train | epoch 009 | loss 2.069 | trans_loss 3.39 | nll_loss 1.571 | w2v_ctc_loss 1.076 | task_loss 0.878 | contrastive_loss 0.235 | total 4138.65 | n_correct 2599.2 | ppl 2.97 | accuracy 62.803 | wps 13253.6 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.415 | clip 0 | loss_scale 32 | train_wall 1266 | gb_free 11.2 | wall 11531
2023-08-23 04:55:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 04:55:54 | INFO | fairseq.trainer | begin training epoch 10
2023-08-23 04:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 04:56:37 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.051, trans_loss=3.381, nll_loss=1.559, w2v_ctc_loss=1.056, task_loss=0.837, contrastive_loss=0.243, total=4100.86, n_correct=2594.6, ppl=2.95, accuracy=63.27, wps=8877.5, ups=0.73, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.414, clip=0, loss_scale=32, train_wall=85, gb_free=16, wall=11573
2023-08-23 04:58:04 | INFO | train_inner | epoch 010:    141 / 1474 loss=2.005, trans_loss=3.362, nll_loss=1.536, w2v_ctc_loss=1.027, task_loss=0.829, contrastive_loss=0.168, total=4240.18, n_correct=2702.77, ppl=2.9, accuracy=63.742, wps=14537.9, ups=1.15, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.402, clip=0, loss_scale=32, train_wall=86, gb_free=14.6, wall=11660
2023-08-23 04:59:30 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.038, trans_loss=3.361, nll_loss=1.533, w2v_ctc_loss=1.04, task_loss=0.87, contrastive_loss=0.29, total=4126.3, n_correct=2630.05, ppl=2.89, accuracy=63.739, wps=14278.9, ups=1.16, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.406, clip=0, loss_scale=32, train_wall=86, gb_free=15.2, wall=11747
2023-08-23 05:00:57 | INFO | train_inner | epoch 010:    341 / 1474 loss=2.012, trans_loss=3.361, nll_loss=1.537, w2v_ctc_loss=1.03, task_loss=0.892, contrastive_loss=0.203, total=4132.25, n_correct=2629.64, ppl=2.9, accuracy=63.637, wps=14183.8, ups=1.15, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.409, clip=0, loss_scale=32, train_wall=86, gb_free=14.3, wall=11834
2023-08-23 05:02:25 | INFO | train_inner | epoch 010:    441 / 1474 loss=2.038, trans_loss=3.366, nll_loss=1.541, w2v_ctc_loss=1.019, task_loss=0.843, contrastive_loss=0.37, total=4203.14, n_correct=2674.92, ppl=2.91, accuracy=63.641, wps=14301.1, ups=1.14, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.408, clip=0, loss_scale=32, train_wall=87, gb_free=16, wall=11921
2023-08-23 05:03:52 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.027, trans_loss=3.376, nll_loss=1.55, w2v_ctc_loss=1.058, task_loss=0.935, contrastive_loss=0.156, total=4106.5, n_correct=2602.68, ppl=2.93, accuracy=63.38, wps=14087, ups=1.15, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.414, clip=0, loss_scale=32, train_wall=86, gb_free=16.1, wall=12008
2023-08-23 05:05:19 | INFO | train_inner | epoch 010:    641 / 1474 loss=2.045, trans_loss=3.371, nll_loss=1.547, w2v_ctc_loss=1.046, task_loss=0.836, contrastive_loss=0.272, total=4170.61, n_correct=2649.34, ppl=2.92, accuracy=63.524, wps=14325.2, ups=1.15, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.411, clip=0, loss_scale=32, train_wall=86, gb_free=10.3, wall=12095
2023-08-23 05:06:45 | INFO | train_inner | epoch 010:    741 / 1474 loss=2.025, trans_loss=3.37, nll_loss=1.545, w2v_ctc_loss=1.059, task_loss=0.883, contrastive_loss=0.154, total=4123.31, n_correct=2616.55, ppl=2.92, accuracy=63.458, wps=14213.9, ups=1.15, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.416, clip=0, loss_scale=32, train_wall=86, gb_free=16.6, wall=12182
2023-08-23 05:06:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 05:07:18 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.016 | trans_loss 5.227 | nll_loss 2.51 | w2v_ctc_loss 1.332 | task_loss 4.624 | contrastive_loss 0.33 | total 4003.4 | n_correct 2615.1 | ppl 5.69 | accuracy 65.322 | uer 19.391 | wer 21.297 | raw_wer 21.297 | bleu 21.32 | wps 1609.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.32
2023-08-23 05:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-23 05:07:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_10_14000.pt
2023-08-23 05:07:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_10_14000.pt
2023-08-23 05:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.32) (writing took 13.274086127988994 seconds)
2023-08-23 05:08:58 | INFO | train_inner | epoch 010:    841 / 1474 loss=2.004, trans_loss=3.365, nll_loss=1.541, w2v_ctc_loss=1.032, task_loss=0.868, contrastive_loss=0.156, total=4125.69, n_correct=2625.99, ppl=2.91, accuracy=63.65, wps=9259.3, ups=0.75, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.405, clip=0, loss_scale=32, train_wall=85, gb_free=15.4, wall=12315
2023-08-23 05:10:24 | INFO | train_inner | epoch 010:    941 / 1474 loss=2.022, trans_loss=3.367, nll_loss=1.539, w2v_ctc_loss=1.041, task_loss=0.839, contrastive_loss=0.193, total=4170.41, n_correct=2656.71, ppl=2.91, accuracy=63.704, wps=14487.1, ups=1.16, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.408, clip=0, loss_scale=32, train_wall=85, gb_free=15.8, wall=12401
2023-08-23 05:11:51 | INFO | train_inner | epoch 010:   1041 / 1474 loss=2.015, trans_loss=3.365, nll_loss=1.54, w2v_ctc_loss=1.045, task_loss=0.952, contrastive_loss=0.167, total=4072.57, n_correct=2586.25, ppl=2.91, accuracy=63.504, wps=14060.7, ups=1.16, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.416, clip=0, loss_scale=32, train_wall=86, gb_free=16.5, wall=12487
2023-08-23 05:13:16 | INFO | train_inner | epoch 010:   1141 / 1474 loss=2.023, trans_loss=3.375, nll_loss=1.552, w2v_ctc_loss=1.057, task_loss=0.978, contrastive_loss=0.15, total=4041.97, n_correct=2557.82, ppl=2.93, accuracy=63.282, wps=14076.7, ups=1.17, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.413, clip=0, loss_scale=64, train_wall=85, gb_free=16.2, wall=12573
2023-08-23 05:14:43 | INFO | train_inner | epoch 010:   1241 / 1474 loss=2.009, trans_loss=3.359, nll_loss=1.536, w2v_ctc_loss=1.049, task_loss=0.904, contrastive_loss=0.145, total=4103.65, n_correct=2613.14, ppl=2.9, accuracy=63.678, wps=14156.1, ups=1.15, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.41, clip=0, loss_scale=64, train_wall=86, gb_free=15.2, wall=12660
2023-08-23 05:16:10 | INFO | train_inner | epoch 010:   1341 / 1474 loss=2.012, trans_loss=3.366, nll_loss=1.542, w2v_ctc_loss=1.045, task_loss=0.897, contrastive_loss=0.157, total=4121.93, n_correct=2625.66, ppl=2.91, accuracy=63.7, wps=14254.2, ups=1.16, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.412, clip=0, loss_scale=64, train_wall=86, gb_free=16.3, wall=12746
2023-08-23 05:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 05:17:37 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.053, trans_loss=3.375, nll_loss=1.551, w2v_ctc_loss=1.026, task_loss=0.84, contrastive_loss=0.353, total=4181.55, n_correct=2655.2, ppl=2.93, accuracy=63.498, wps=14253.3, ups=1.14, wpb=12473.5, bsz=475, num_updates=14700, lr=0.000116642, gnorm=0.411, clip=0, loss_scale=32, train_wall=87, gb_free=16.7, wall=12834
2023-08-23 05:18:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 05:18:37 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.01 | trans_loss 5.205 | nll_loss 2.48 | w2v_ctc_loss 1.365 | task_loss 4.628 | contrastive_loss 0.328 | total 4003.4 | n_correct 2630.8 | ppl 5.58 | accuracy 65.714 | uer 18.634 | wer 20.301 | raw_wer 20.301 | bleu 21.56 | wps 1642.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 21.56
2023-08-23 05:18:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-23 05:18:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 05:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 05:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 10 @ 14732 updates, score 21.56) (writing took 11.3230907660909 seconds)
2023-08-23 05:18:49 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-23 05:18:49 | INFO | train | epoch 010 | loss 2.024 | trans_loss 3.367 | nll_loss 1.542 | w2v_ctc_loss 1.039 | task_loss 0.879 | contrastive_loss 0.22 | total 4137.97 | n_correct 2631.43 | ppl 2.91 | accuracy 63.592 | wps 13238.1 | ups 1.07 | wpb 12353.8 | bsz 458.1 | num_updates 14732 | lr 0.000116516 | gnorm 0.41 | clip 0 | loss_scale 32 | train_wall 1266 | gb_free 17 | wall 12905
2023-08-23 05:18:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 05:18:49 | INFO | fairseq.trainer | begin training epoch 11
2023-08-23 05:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 05:19:54 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.992, trans_loss=3.346, nll_loss=1.515, w2v_ctc_loss=1.009, task_loss=0.811, contrastive_loss=0.229, total=4175.24, n_correct=2683.53, ppl=2.86, accuracy=64.272, wps=9109.7, ups=0.73, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.401, clip=0, loss_scale=32, train_wall=84, gb_free=16.4, wall=12970
2023-08-23 05:21:20 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.979, trans_loss=3.347, nll_loss=1.519, w2v_ctc_loss=1.014, task_loss=0.907, contrastive_loss=0.149, total=4087.78, n_correct=2622.76, ppl=2.87, accuracy=64.161, wps=14159.7, ups=1.16, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.415, clip=0, loss_scale=32, train_wall=85, gb_free=16, wall=13057
2023-08-23 05:21:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-23 05:22:47 | INFO | train_inner | epoch 011:    269 / 1474 loss=1.968, trans_loss=3.345, nll_loss=1.514, w2v_ctc_loss=1.006, task_loss=0.905, contrastive_loss=0.142, total=4124.44, n_correct=2650.31, ppl=2.86, accuracy=64.259, wps=14140.4, ups=1.15, wpb=12316, bsz=446.2, num_updates=15000, lr=0.00011547, gnorm=0.407, clip=0, loss_scale=16, train_wall=86, gb_free=15.7, wall=13144
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 05:23:48 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.051, trans_loss=4.974, nll_loss=2.253, w2v_ctc_loss=0.753, task_loss=1.353, contrastive_loss=0.112, total=4094.16, n_correct=2628.27, ppl=4.77, accuracy=64.196, wps=13450.4, ups=1.63, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.535, clip=0, loss_scale=16, train_wall=61, gb_free=12.3, wall=13205
2023-08-23 05:24:50 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.073, trans_loss=5.008, nll_loss=2.278, w2v_ctc_loss=0.757, task_loss=1.364, contrastive_loss=0.232, total=4112.8, n_correct=2626.66, ppl=4.85, accuracy=63.865, wps=13281.1, ups=1.61, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=13267
2023-08-23 05:25:52 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.071, trans_loss=5.005, nll_loss=2.274, w2v_ctc_loss=0.761, task_loss=1.421, contrastive_loss=0.228, total=4071.06, n_correct=2603.54, ppl=4.84, accuracy=63.952, wps=13167.1, ups=1.62, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=13329
2023-08-23 05:26:54 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.072, trans_loss=4.996, nll_loss=2.263, w2v_ctc_loss=0.756, task_loss=1.293, contrastive_loss=0.29, total=4156.4, n_correct=2664.76, ppl=4.8, accuracy=64.112, wps=13463, ups=1.62, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=13390
2023-08-23 05:27:56 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.062, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.767, task_loss=1.336, contrastive_loss=0.111, total=4169.17, n_correct=2670.55, ppl=4.85, accuracy=64.055, wps=13388.7, ups=1.61, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.529, clip=0, loss_scale=16, train_wall=62, gb_free=11.7, wall=13453
2023-08-23 05:28:57 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.06, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.762, task_loss=1.381, contrastive_loss=0.101, total=4120.01, n_correct=2633.58, ppl=4.84, accuracy=63.922, wps=13456.7, ups=1.63, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=13, wall=13514
2023-08-23 05:29:59 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.061, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.765, task_loss=1.331, contrastive_loss=0.114, total=4145.45, n_correct=2651.6, ppl=4.84, accuracy=63.964, wps=13433.6, ups=1.62, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=13576
2023-08-23 05:31:00 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.059, trans_loss=5, nll_loss=2.269, w2v_ctc_loss=0.764, task_loss=1.292, contrastive_loss=0.132, total=4141.18, n_correct=2656.5, ppl=4.82, accuracy=64.148, wps=13531.7, ups=1.63, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=13637
2023-08-23 05:32:02 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.063, trans_loss=5.009, nll_loss=2.281, w2v_ctc_loss=0.769, task_loss=1.324, contrastive_loss=0.117, total=4173.93, n_correct=2666.34, ppl=4.86, accuracy=63.881, wps=13521.6, ups=1.62, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=13699
2023-08-23 05:33:05 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.068, trans_loss=5.001, nll_loss=2.271, w2v_ctc_loss=0.768, task_loss=1.265, contrastive_loss=0.188, total=4174.26, n_correct=2670.48, ppl=4.83, accuracy=63.975, wps=13345.9, ups=1.6, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.54, clip=0, loss_scale=16, train_wall=62, gb_free=17.1, wall=13761
2023-08-23 05:33:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
2023-08-23 05:33:38 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.02 | trans_loss 5.211 | nll_loss 2.49 | w2v_ctc_loss 1.392 | task_loss 4.635 | contrastive_loss 0.322 | total 4003.4 | n_correct 2624.5 | ppl 5.62 | accuracy 65.557 | uer 18.65 | wer 20.454 | raw_wer 20.454 | bleu 21.37 | wps 1611.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.56
2023-08-23 05:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-23 05:33:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_11_16000.pt
2023-08-23 05:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_11_16000.pt
2023-08-23 05:33:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.37) (writing took 8.520537490025163 seconds)
2023-08-23 05:34:49 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.075, trans_loss=5, nll_loss=2.27, w2v_ctc_loss=0.751, task_loss=1.216, contrastive_loss=0.346, total=4191.56, n_correct=2683.86, ppl=4.82, accuracy=64.03, wps=8054.9, ups=0.96, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.537, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=13865
2023-08-23 05:35:51 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.054, trans_loss=5.003, nll_loss=2.273, w2v_ctc_loss=0.757, task_loss=1.265, contrastive_loss=0.121, total=4161.81, n_correct=2669.84, ppl=4.83, accuracy=64.151, wps=13446.3, ups=1.62, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=13927
2023-08-23 05:35:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 05:36:27 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.994 | trans_loss 5.204 | nll_loss 2.479 | w2v_ctc_loss 1.321 | task_loss 4.631 | contrastive_loss 0.32 | total 4003.4 | n_correct 2635.2 | ppl 5.57 | accuracy 65.824 | uer 18.467 | wer 20.245 | raw_wer 20.245 | bleu 21.52 | wps 1558.3 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.56
2023-08-23 05:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-23 05:36:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.5204.pt
2023-08-23 05:36:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.5204.pt
2023-08-23 05:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.5204.pt (epoch 11 @ 16205 updates, score 21.52) (writing took 7.618640549015254 seconds)
2023-08-23 05:36:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-23 05:36:35 | INFO | train | epoch 011 | loss 2.042 | trans_loss 4.589 | nll_loss 2.083 | w2v_ctc_loss 0.822 | task_loss 1.208 | contrastive_loss 0.168 | total 4138.69 | n_correct 2651.3 | ppl 4.24 | accuracy 64.061 | wps 12462.2 | ups 1.38 | wpb 9021.6 | bsz 333.3 | num_updates 16205 | lr 0.000111094 | gnorm 0.513 | clip 0 | loss_scale 16 | train_wall 967 | gb_free 16.8 | wall 13972
2023-08-23 05:36:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 05:36:35 | INFO | fairseq.trainer | begin training epoch 12
2023-08-23 05:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 05:37:41 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.038, trans_loss=4.964, nll_loss=2.222, w2v_ctc_loss=0.744, task_loss=1.271, contrastive_loss=0.151, total=4139.2, n_correct=2683.22, ppl=4.66, accuracy=64.825, wps=7516.9, ups=0.91, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.527, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=14037
2023-08-23 05:38:42 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.04, trans_loss=4.97, nll_loss=2.229, w2v_ctc_loss=0.75, task_loss=1.353, contrastive_loss=0.103, total=4126.87, n_correct=2665.59, ppl=4.69, accuracy=64.591, wps=13467.1, ups=1.63, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=14099
2023-08-23 05:39:44 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.034, trans_loss=4.968, nll_loss=2.228, w2v_ctc_loss=0.734, task_loss=1.231, contrastive_loss=0.132, total=4203.54, n_correct=2723.95, ppl=4.68, accuracy=64.801, wps=13544.3, ups=1.61, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.53, clip=0, loss_scale=16, train_wall=62, gb_free=14.3, wall=14161
2023-08-23 05:40:46 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.038, trans_loss=4.972, nll_loss=2.232, w2v_ctc_loss=0.744, task_loss=1.293, contrastive_loss=0.118, total=4149.28, n_correct=2684.22, ppl=4.7, accuracy=64.691, wps=13419.2, ups=1.62, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=14.8, wall=14223
2023-08-23 05:41:47 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.05, trans_loss=4.987, nll_loss=2.252, w2v_ctc_loss=0.757, task_loss=1.328, contrastive_loss=0.125, total=4106.46, n_correct=2650.07, ppl=4.76, accuracy=64.534, wps=13469.1, ups=1.64, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=14284
2023-08-23 05:42:49 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.048, trans_loss=4.975, nll_loss=2.236, w2v_ctc_loss=0.747, task_loss=1.258, contrastive_loss=0.19, total=4190.91, n_correct=2709.38, ppl=4.71, accuracy=64.649, wps=13521.8, ups=1.61, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=14346
2023-08-23 05:43:50 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.046, trans_loss=4.971, nll_loss=2.233, w2v_ctc_loss=0.733, task_loss=1.212, contrastive_loss=0.276, total=4203.66, n_correct=2722.57, ppl=4.7, accuracy=64.767, wps=13823, ups=1.64, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.534, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=14406
2023-08-23 05:44:51 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.039, trans_loss=4.97, nll_loss=2.229, w2v_ctc_loss=0.75, task_loss=1.333, contrastive_loss=0.115, total=4095.72, n_correct=2651.22, ppl=4.69, accuracy=64.731, wps=13325.5, ups=1.63, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=14468
2023-08-23 05:45:54 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.049, trans_loss=4.977, nll_loss=2.239, w2v_ctc_loss=0.749, task_loss=1.352, contrastive_loss=0.166, total=4162.82, n_correct=2687.86, ppl=4.72, accuracy=64.568, wps=13269.4, ups=1.59, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.537, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=14531
2023-08-23 05:46:55 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.049, trans_loss=4.979, nll_loss=2.242, w2v_ctc_loss=0.752, task_loss=1.344, contrastive_loss=0.174, total=4117.63, n_correct=2657.01, ppl=4.73, accuracy=64.528, wps=13440.7, ups=1.63, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=14592
2023-08-23 05:47:57 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.06, trans_loss=4.983, nll_loss=2.247, w2v_ctc_loss=0.757, task_loss=1.386, contrastive_loss=0.222, total=4046.48, n_correct=2608.62, ppl=4.75, accuracy=64.466, wps=13150.4, ups=1.62, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.546, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=14653
2023-08-23 05:48:59 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.062, trans_loss=4.999, nll_loss=2.269, w2v_ctc_loss=0.764, task_loss=1.282, contrastive_loss=0.187, total=4201.13, n_correct=2698.86, ppl=4.82, accuracy=64.241, wps=13612.5, ups=1.62, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=14715
2023-08-23 05:50:00 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.049, trans_loss=4.98, nll_loss=2.243, w2v_ctc_loss=0.765, task_loss=1.47, contrastive_loss=0.102, total=4070.27, n_correct=2625.01, ppl=4.73, accuracy=64.492, wps=13183.3, ups=1.62, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.549, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=14777
2023-08-23 05:51:02 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.052, trans_loss=4.987, nll_loss=2.251, w2v_ctc_loss=0.747, task_loss=1.327, contrastive_loss=0.206, total=4139.63, n_correct=2667.9, ppl=4.76, accuracy=64.448, wps=13335.8, ups=1.61, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.53, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=14839
2023-08-23 05:51:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 05:52:25 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.998 | trans_loss 5.19 | nll_loss 2.464 | w2v_ctc_loss 1.37 | task_loss 4.628 | contrastive_loss 0.315 | total 4003.4 | n_correct 2640.9 | ppl 5.52 | accuracy 65.966 | uer 18.711 | wer 20.514 | raw_wer 20.514 | bleu 21.58 | wps 1570.4 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 21.58
2023-08-23 05:52:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-23 05:52:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 05:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 05:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 12 @ 17679 updates, score 21.58) (writing took 10.401859897072427 seconds)
2023-08-23 05:52:35 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-23 05:52:35 | INFO | train | epoch 012 | loss 2.047 | trans_loss 4.978 | nll_loss 2.24 | w2v_ctc_loss 0.75 | task_loss 1.317 | contrastive_loss 0.16 | total 4138.65 | n_correct 2673.13 | ppl 4.72 | accuracy 64.59 | wps 12708 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 899 | gb_free 12.5 | wall 14932
2023-08-23 05:52:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 05:52:35 | INFO | fairseq.trainer | begin training epoch 13
2023-08-23 05:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 05:52:55 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.048, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.763, task_loss=1.369, contrastive_loss=0.108, total=4096.49, n_correct=2639.04, ppl=4.76, accuracy=64.422, wps=7246.2, ups=0.88, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=14.2, wall=14952
2023-08-23 05:53:57 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.028, trans_loss=4.952, nll_loss=2.206, w2v_ctc_loss=0.736, task_loss=1.325, contrastive_loss=0.122, total=4160.97, n_correct=2706.52, ppl=4.62, accuracy=65.045, wps=13505.8, ups=1.62, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=15014
2023-08-23 05:54:59 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.048, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.733, task_loss=1.215, contrastive_loss=0.333, total=4212.08, n_correct=2735.09, ppl=4.66, accuracy=64.934, wps=13686.2, ups=1.62, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=14.3, wall=15075
2023-08-23 05:56:00 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.022, trans_loss=4.946, nll_loss=2.198, w2v_ctc_loss=0.734, task_loss=1.367, contrastive_loss=0.105, total=4102.3, n_correct=2676.18, ppl=4.59, accuracy=65.236, wps=13338.6, ups=1.63, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=15137
2023-08-23 05:56:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 05:56:34 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.994 | trans_loss 5.196 | nll_loss 2.469 | w2v_ctc_loss 1.34 | task_loss 4.653 | contrastive_loss 0.326 | total 4003.4 | n_correct 2636.6 | ppl 5.54 | accuracy 65.859 | uer 18.546 | wer 20.391 | raw_wer 20.391 | bleu 21.45 | wps 1581.8 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.58
2023-08-23 05:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-23 05:56:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_13_18000.pt
2023-08-23 05:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_13_18000.pt
2023-08-23 05:56:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.45) (writing took 8.828516528010368 seconds)
2023-08-23 05:57:45 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.025, trans_loss=4.951, nll_loss=2.205, w2v_ctc_loss=0.73, task_loss=1.235, contrastive_loss=0.153, total=4177.29, n_correct=2726, ppl=4.61, accuracy=65.258, wps=7999.3, ups=0.96, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=15241
2023-08-23 05:58:46 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.036, trans_loss=4.96, nll_loss=2.217, w2v_ctc_loss=0.741, task_loss=1.277, contrastive_loss=0.185, total=4201.22, n_correct=2726.85, ppl=4.65, accuracy=64.906, wps=13638.4, ups=1.62, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=12.5, wall=15303
2023-08-23 05:59:48 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.019, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.731, task_loss=1.282, contrastive_loss=0.101, total=4161.98, n_correct=2717.01, ppl=4.61, accuracy=65.282, wps=13569.2, ups=1.63, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=15364
2023-08-23 06:00:49 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.037, trans_loss=4.959, nll_loss=2.215, w2v_ctc_loss=0.756, task_loss=1.467, contrastive_loss=0.102, total=4096.76, n_correct=2658.07, ppl=4.64, accuracy=64.882, wps=13290.5, ups=1.62, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=15426
2023-08-23 06:01:52 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.034, trans_loss=4.96, nll_loss=2.218, w2v_ctc_loss=0.737, task_loss=1.332, contrastive_loss=0.148, total=4121.73, n_correct=2673.13, ppl=4.65, accuracy=64.855, wps=13227.4, ups=1.6, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.539, clip=0, loss_scale=32, train_wall=62, gb_free=14.5, wall=15488
2023-08-23 06:02:54 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.026, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.736, task_loss=1.342, contrastive_loss=0.11, total=4107.01, n_correct=2673.44, ppl=4.64, accuracy=65.095, wps=13169.5, ups=1.6, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.529, clip=0, loss_scale=32, train_wall=62, gb_free=15.6, wall=15550
2023-08-23 06:03:55 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.043, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.752, task_loss=1.394, contrastive_loss=0.162, total=4081.02, n_correct=2644.86, ppl=4.67, accuracy=64.809, wps=13316.2, ups=1.63, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=15612
2023-08-23 06:04:57 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.024, trans_loss=4.95, nll_loss=2.204, w2v_ctc_loss=0.732, task_loss=1.297, contrastive_loss=0.143, total=4105.62, n_correct=2678.55, ppl=4.61, accuracy=65.241, wps=13394.9, ups=1.63, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=15673
2023-08-23 06:05:58 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.033, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.745, task_loss=1.403, contrastive_loss=0.102, total=4110.35, n_correct=2668.8, ppl=4.66, accuracy=64.929, wps=13371.9, ups=1.63, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=14.6, wall=15735
2023-08-23 06:07:00 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.036, trans_loss=4.954, nll_loss=2.21, w2v_ctc_loss=0.742, task_loss=1.296, contrastive_loss=0.2, total=4112.2, n_correct=2679.61, ppl=4.63, accuracy=65.162, wps=13355.7, ups=1.62, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=15796
2023-08-23 06:08:01 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.039, trans_loss=4.961, nll_loss=2.22, w2v_ctc_loss=0.735, task_loss=1.294, contrastive_loss=0.21, total=4180.88, n_correct=2716.6, ppl=4.66, accuracy=64.977, wps=13518, ups=1.62, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.535, clip=0, loss_scale=64, train_wall=61, gb_free=14.9, wall=15858
2023-08-23 06:08:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 06:09:08 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.184 | nll_loss 2.451 | w2v_ctc_loss 1.326 | task_loss 4.645 | contrastive_loss 0.311 | total 4003.4 | n_correct 2646.9 | ppl 5.47 | accuracy 66.116 | uer 18.188 | wer 19.996 | raw_wer 19.996 | bleu 21.77 | wps 1596.9 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 21.77
2023-08-23 06:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-08-23 06:09:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 06:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 06:09:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 13 @ 19153 updates, score 21.77) (writing took 11.544573031016625 seconds)
2023-08-23 06:09:19 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-23 06:09:19 | INFO | train | epoch 013 | loss 2.032 | trans_loss 4.956 | nll_loss 2.212 | w2v_ctc_loss 0.739 | task_loss 1.318 | contrastive_loss 0.156 | total 4138.65 | n_correct 2691.93 | ppl 4.63 | accuracy 65.044 | wps 12148.6 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.53 | clip 0 | loss_scale 64 | train_wall 901 | gb_free 17.4 | wall 15936
2023-08-23 06:09:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 06:09:20 | INFO | fairseq.trainer | begin training epoch 14
2023-08-23 06:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 06:09:55 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.011, trans_loss=4.929, nll_loss=2.179, w2v_ctc_loss=0.729, task_loss=1.204, contrastive_loss=0.116, total=4176.2, n_correct=2738.76, ppl=4.53, accuracy=65.58, wps=7343.6, ups=0.88, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.532, clip=0, loss_scale=64, train_wall=61, gb_free=10.1, wall=15972
2023-08-23 06:10:56 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.006, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.726, task_loss=1.329, contrastive_loss=0.097, total=4080.86, n_correct=2682.64, ppl=4.49, accuracy=65.737, wps=13435.6, ups=1.65, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.527, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=16033
2023-08-23 06:11:57 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.026, trans_loss=4.94, nll_loss=2.192, w2v_ctc_loss=0.728, task_loss=1.384, contrastive_loss=0.198, total=4106.97, n_correct=2682.22, ppl=4.57, accuracy=65.309, wps=13425, ups=1.63, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.535, clip=0, loss_scale=64, train_wall=61, gb_free=11.9, wall=16094
2023-08-23 06:12:58 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.01, trans_loss=4.934, nll_loss=2.184, w2v_ctc_loss=0.72, task_loss=1.208, contrastive_loss=0.131, total=4179.8, n_correct=2743.36, ppl=4.54, accuracy=65.634, wps=13624.6, ups=1.63, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=16155
2023-08-23 06:14:00 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.012, trans_loss=4.94, nll_loss=2.191, w2v_ctc_loss=0.723, task_loss=1.36, contrastive_loss=0.094, total=4120.38, n_correct=2695.01, ppl=4.57, accuracy=65.407, wps=13391.9, ups=1.63, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=16217
2023-08-23 06:15:02 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.028, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.746, task_loss=1.394, contrastive_loss=0.129, total=4089.86, n_correct=2668.44, ppl=4.57, accuracy=65.245, wps=13130.5, ups=1.61, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.54, clip=0, loss_scale=64, train_wall=62, gb_free=11.6, wall=16279
2023-08-23 06:16:04 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.025, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.732, task_loss=1.316, contrastive_loss=0.173, total=4158.94, n_correct=2717.61, ppl=4.57, accuracy=65.344, wps=13463.8, ups=1.62, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.534, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=16341
2023-08-23 06:17:05 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.012, trans_loss=4.929, nll_loss=2.178, w2v_ctc_loss=0.73, task_loss=1.279, contrastive_loss=0.105, total=4150.03, n_correct=2724.42, ppl=4.53, accuracy=65.648, wps=13601.3, ups=1.64, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.531, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=16402
2023-08-23 06:18:06 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.022, trans_loss=4.931, nll_loss=2.18, w2v_ctc_loss=0.725, task_loss=1.261, contrastive_loss=0.216, total=4162.8, n_correct=2728.06, ppl=4.53, accuracy=65.534, wps=13627.6, ups=1.64, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.522, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=16463
2023-08-23 06:18:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 06:18:39 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.985 | trans_loss 5.177 | nll_loss 2.445 | w2v_ctc_loss 1.364 | task_loss 4.657 | contrastive_loss 0.309 | total 4003.4 | n_correct 2651.9 | ppl 5.44 | accuracy 66.241 | uer 18.366 | wer 20.32 | raw_wer 20.32 | bleu 21.98 | wps 1644.8 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.98
2023-08-23 06:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-23 06:18:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_14_20000.pt
2023-08-23 06:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_14_20000.pt
2023-08-23 06:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.98) (writing took 13.71952548599802 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 06:19:55 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.013, trans_loss=4.935, nll_loss=2.185, w2v_ctc_loss=0.728, task_loss=1.342, contrastive_loss=0.104, total=4159.46, n_correct=2722.1, ppl=4.55, accuracy=65.444, wps=7663.2, ups=0.92, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=16571
2023-08-23 06:20:57 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.023, trans_loss=4.94, nll_loss=2.192, w2v_ctc_loss=0.726, task_loss=1.311, contrastive_loss=0.173, total=4155.93, n_correct=2721.63, ppl=4.57, accuracy=65.488, wps=13341.1, ups=1.61, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=62, gb_free=16, wall=16634
2023-08-23 06:21:59 | INFO | train_inner | epoch 014:   1147 / 1474 loss=2.045, trans_loss=4.94, nll_loss=2.193, w2v_ctc_loss=0.735, task_loss=1.238, contrastive_loss=0.393, total=4228.09, n_correct=2765, ppl=4.57, accuracy=65.396, wps=13579.8, ups=1.61, wpb=8456.2, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=16696
2023-08-23 06:23:01 | INFO | train_inner | epoch 014:   1247 / 1474 loss=2.025, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.746, task_loss=1.536, contrastive_loss=0.089, total=4027.71, n_correct=2629.21, ppl=4.58, accuracy=65.278, wps=13153.6, ups=1.63, wpb=8055.4, bsz=273.6, num_updates=20400, lr=9.90148e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=16757
2023-08-23 06:24:02 | INFO | train_inner | epoch 014:   1347 / 1474 loss=2.011, trans_loss=4.937, nll_loss=2.189, w2v_ctc_loss=0.725, task_loss=1.26, contrastive_loss=0.103, total=4198.71, n_correct=2750.02, ppl=4.56, accuracy=65.497, wps=13702.2, ups=1.63, wpb=8397.4, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=16818
2023-08-23 06:25:04 | INFO | train_inner | epoch 014:   1447 / 1474 loss=2.022, trans_loss=4.946, nll_loss=2.2, w2v_ctc_loss=0.728, task_loss=1.297, contrastive_loss=0.145, total=4140.5, n_correct=2705.14, ppl=4.59, accuracy=65.334, wps=13437.9, ups=1.62, wpb=8281, bsz=307.1, num_updates=20600, lr=9.85329e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=16880
2023-08-23 06:25:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
2023-08-23 06:25:54 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.175 | nll_loss 2.443 | w2v_ctc_loss 1.363 | task_loss 4.633 | contrastive_loss 0.312 | total 4003.4 | n_correct 2657.1 | ppl 5.44 | accuracy 66.371 | uer 18.249 | wer 20.26 | raw_wer 20.26 | bleu 21.72 | wps 1551.3 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 21.98
2023-08-23 06:25:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-08-23 06:25:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.7203.pt
2023-08-23 06:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.7203.pt
2023-08-23 06:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.7203.pt (epoch 14 @ 20627 updates, score 21.72) (writing took 7.378343140007928 seconds)
2023-08-23 06:26:02 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-23 06:26:02 | INFO | train | epoch 014 | loss 2.019 | trans_loss 4.937 | nll_loss 2.188 | w2v_ctc_loss 0.73 | task_loss 1.317 | contrastive_loss 0.153 | total 4138.65 | n_correct 2709.11 | ppl 4.56 | accuracy 65.459 | wps 12173 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.529 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 16.1 | wall 16938
2023-08-23 06:26:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 06:26:02 | INFO | fairseq.trainer | begin training epoch 15
2023-08-23 06:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 06:26:53 | INFO | train_inner | epoch 015:     73 / 1474 loss=2.014, trans_loss=4.926, nll_loss=2.173, w2v_ctc_loss=0.717, task_loss=1.322, contrastive_loss=0.191, total=4083.93, n_correct=2682.61, ppl=4.51, accuracy=65.687, wps=7452.6, ups=0.91, wpb=8167.9, bsz=300.1, num_updates=20700, lr=9.82946e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=16990
2023-08-23 06:27:54 | INFO | train_inner | epoch 015:    173 / 1474 loss=2.002, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.721, task_loss=1.366, contrastive_loss=0.101, total=4122.67, n_correct=2719.24, ppl=4.47, accuracy=65.958, wps=13449.9, ups=1.63, wpb=8245.3, bsz=299.1, num_updates=20800, lr=9.80581e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=17051
2023-08-23 06:28:56 | INFO | train_inner | epoch 015:    273 / 1474 loss=1.996, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.713, task_loss=1.27, contrastive_loss=0.093, total=4190.11, n_correct=2765.06, ppl=4.47, accuracy=65.99, wps=13683.5, ups=1.63, wpb=8380.2, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=17112
2023-08-23 06:29:57 | INFO | train_inner | epoch 015:    373 / 1474 loss=2, trans_loss=4.91, nll_loss=2.153, w2v_ctc_loss=0.713, task_loss=1.353, contrastive_loss=0.114, total=4150.33, n_correct=2737.88, ppl=4.45, accuracy=65.968, wps=13574.3, ups=1.64, wpb=8300.7, bsz=301, num_updates=21000, lr=9.759e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=17173
2023-08-23 06:30:58 | INFO | train_inner | epoch 015:    473 / 1474 loss=2.01, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.708, task_loss=1.354, contrastive_loss=0.206, total=4082.7, n_correct=2687.54, ppl=4.47, accuracy=65.828, wps=13319.4, ups=1.63, wpb=8165.4, bsz=298.5, num_updates=21100, lr=9.73585e-05, gnorm=0.524, clip=0, loss_scale=128, train_wall=61, gb_free=16.8, wall=17235
2023-08-23 06:32:00 | INFO | train_inner | epoch 015:    573 / 1474 loss=2.002, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.72, task_loss=1.392, contrastive_loss=0.096, total=4130.96, n_correct=2720.47, ppl=4.47, accuracy=65.856, wps=13316.4, ups=1.61, wpb=8261.9, bsz=293.4, num_updates=21200, lr=9.71286e-05, gnorm=0.525, clip=0, loss_scale=128, train_wall=61, gb_free=16.9, wall=17297
2023-08-23 06:33:01 | INFO | train_inner | epoch 015:    673 / 1474 loss=2.007, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.717, task_loss=1.311, contrastive_loss=0.169, total=4138.41, n_correct=2730.7, ppl=4.46, accuracy=65.984, wps=13544.5, ups=1.64, wpb=8276.8, bsz=309.4, num_updates=21300, lr=9.69003e-05, gnorm=0.531, clip=0, loss_scale=128, train_wall=61, gb_free=16.5, wall=17358
2023-08-23 06:34:03 | INFO | train_inner | epoch 015:    773 / 1474 loss=2.008, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.725, task_loss=1.326, contrastive_loss=0.118, total=4186.48, n_correct=2752.36, ppl=4.5, accuracy=65.744, wps=13542.5, ups=1.62, wpb=8373, bsz=307.9, num_updates=21400, lr=9.66736e-05, gnorm=0.525, clip=0, loss_scale=128, train_wall=61, gb_free=16.4, wall=17420
2023-08-23 06:35:04 | INFO | train_inner | epoch 015:    873 / 1474 loss=2.008, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.726, task_loss=1.436, contrastive_loss=0.096, total=4054.09, n_correct=2661.87, ppl=4.51, accuracy=65.659, wps=13338.5, ups=1.65, wpb=8108.2, bsz=286.2, num_updates=21500, lr=9.64486e-05, gnorm=0.533, clip=0, loss_scale=128, train_wall=60, gb_free=15.6, wall=17481
2023-08-23 06:35:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 06:36:06 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.002, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.712, task_loss=1.331, contrastive_loss=0.158, total=4112.28, n_correct=2709.26, ppl=4.47, accuracy=65.882, wps=13300.8, ups=1.62, wpb=8224.6, bsz=299.3, num_updates=21600, lr=9.6225e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=17542
2023-08-23 06:37:09 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.026, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.718, task_loss=1.235, contrastive_loss=0.335, total=4192.24, n_correct=2752.89, ppl=4.52, accuracy=65.666, wps=13341.6, ups=1.59, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=17605
2023-08-23 06:38:10 | INFO | train_inner | epoch 015:   1174 / 1474 loss=1.995, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.704, task_loss=1.179, contrastive_loss=0.144, total=4185, n_correct=2765.01, ppl=4.47, accuracy=66.07, wps=13712.8, ups=1.64, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=17666
2023-08-23 06:39:11 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.008, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.732, task_loss=1.346, contrastive_loss=0.101, total=4152.04, n_correct=2730.77, ppl=4.47, accuracy=65.769, wps=13534.3, ups=1.63, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=16.1, wall=17728
2023-08-23 06:40:12 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.717, task_loss=1.36, contrastive_loss=0.088, total=4100.21, n_correct=2701.7, ppl=4.47, accuracy=65.892, wps=13436.5, ups=1.64, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=17789
2023-08-23 06:40:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 06:40:45 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.177 | nll_loss 2.443 | w2v_ctc_loss 1.282 | task_loss 4.62 | contrastive_loss 0.304 | total 4003.4 | n_correct 2652 | ppl 5.44 | accuracy 66.244 | uer 17.875 | wer 19.776 | raw_wer 19.776 | bleu 22.03 | wps 1608.5 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.03
2023-08-23 06:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-23 06:40:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_15_22000.pt
2023-08-23 06:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_15_22000.pt
2023-08-23 06:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 22.03) (writing took 14.296733501018025 seconds)
2023-08-23 06:42:03 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.011, trans_loss=4.925, nll_loss=2.174, w2v_ctc_loss=0.717, task_loss=1.276, contrastive_loss=0.177, total=4141.17, n_correct=2722.92, ppl=4.51, accuracy=65.752, wps=7483.7, ups=0.9, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=62, gb_free=16.5, wall=17899
2023-08-23 06:42:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 06:42:36 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.175 | nll_loss 2.442 | w2v_ctc_loss 1.301 | task_loss 4.646 | contrastive_loss 0.311 | total 4003.4 | n_correct 2650.6 | ppl 5.43 | accuracy 66.209 | uer 17.835 | wer 19.705 | raw_wer 19.705 | bleu 21.94 | wps 1593.2 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 22.03
2023-08-23 06:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-23 06:42:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9408.pt
2023-08-23 06:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9408.pt
2023-08-23 06:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9408.pt (epoch 15 @ 22100 updates, score 21.94) (writing took 7.466881332104094 seconds)
2023-08-23 06:42:44 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-23 06:42:44 | INFO | train | epoch 015 | loss 2.006 | trans_loss 4.918 | nll_loss 2.163 | w2v_ctc_loss 0.717 | task_loss 1.319 | contrastive_loss 0.148 | total 4137.64 | n_correct 2725.12 | ppl 4.48 | accuracy 65.862 | wps 12163 | ups 1.47 | wpb 8275.3 | bsz 305.4 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.527 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 16.5 | wall 17941
2023-08-23 06:42:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 06:42:44 | INFO | fairseq.trainer | begin training epoch 16
2023-08-23 06:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 06:43:53 | INFO | train_inner | epoch 016:    100 / 1474 loss=1.988, trans_loss=4.899, nll_loss=2.139, w2v_ctc_loss=0.705, task_loss=1.258, contrastive_loss=0.117, total=4126.22, n_correct=2736.28, ppl=4.41, accuracy=66.314, wps=7500.6, ups=0.91, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=18009
2023-08-23 06:44:54 | INFO | train_inner | epoch 016:    200 / 1474 loss=1.982, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.698, task_loss=1.354, contrastive_loss=0.092, total=4100.6, n_correct=2723.01, ppl=4.36, accuracy=66.405, wps=13403.7, ups=1.63, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=61, gb_free=12.3, wall=18071
2023-08-23 06:45:55 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.998, trans_loss=4.9, nll_loss=2.141, w2v_ctc_loss=0.712, task_loss=1.311, contrastive_loss=0.167, total=4166.94, n_correct=2760.14, ppl=4.41, accuracy=66.239, wps=13553.2, ups=1.63, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=18132
2023-08-23 06:46:57 | INFO | train_inner | epoch 016:    400 / 1474 loss=2, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.713, task_loss=1.403, contrastive_loss=0.179, total=4073.3, n_correct=2698.7, ppl=4.4, accuracy=66.253, wps=13336.8, ups=1.64, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=18193
2023-08-23 06:47:58 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.989, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.703, task_loss=1.269, contrastive_loss=0.124, total=4174.67, n_correct=2769.02, ppl=4.41, accuracy=66.329, wps=13488, ups=1.62, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=15.7, wall=18255
2023-08-23 06:49:00 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.994, trans_loss=4.906, nll_loss=2.147, w2v_ctc_loss=0.715, task_loss=1.333, contrastive_loss=0.089, total=4124.65, n_correct=2728.28, ppl=4.43, accuracy=66.146, wps=13472.2, ups=1.63, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=18316
2023-08-23 06:50:01 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.99, trans_loss=4.9, nll_loss=2.139, w2v_ctc_loss=0.712, task_loss=1.349, contrastive_loss=0.09, total=4095.49, n_correct=2712.26, ppl=4.41, accuracy=66.226, wps=13404.9, ups=1.64, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=18377
2023-08-23 06:51:02 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.993, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.703, task_loss=1.267, contrastive_loss=0.151, total=4174.94, n_correct=2764.05, ppl=4.41, accuracy=66.206, wps=13571.9, ups=1.63, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=16.1, wall=18439
2023-08-23 06:52:04 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.993, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.705, task_loss=1.279, contrastive_loss=0.143, total=4163.19, n_correct=2756.94, ppl=4.41, accuracy=66.222, wps=13596.7, ups=1.63, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=18500
2023-08-23 06:53:05 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.002, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.72, task_loss=1.376, contrastive_loss=0.141, total=4103.45, n_correct=2707.02, ppl=4.44, accuracy=65.969, wps=13255.8, ups=1.62, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=14.5, wall=18562
2023-08-23 06:54:07 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.002, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.719, task_loss=1.407, contrastive_loss=0.116, total=4119.27, n_correct=2718.38, ppl=4.46, accuracy=65.992, wps=13350.4, ups=1.62, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=18624
2023-08-23 06:54:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 06:55:10 | INFO | train_inner | epoch 016:   1201 / 1474 loss=1.988, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.701, task_loss=1.377, contrastive_loss=0.095, total=4132.57, n_correct=2735.99, ppl=4.43, accuracy=66.206, wps=13065.1, ups=1.58, wpb=8265.1, bsz=298.8, num_updates=23300, lr=9.26482e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=63, gb_free=14.5, wall=18687
2023-08-23 06:56:12 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.001, trans_loss=4.903, nll_loss=2.145, w2v_ctc_loss=0.715, task_loss=1.279, contrastive_loss=0.19, total=4151.03, n_correct=2747.13, ppl=4.42, accuracy=66.179, wps=13539.6, ups=1.63, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=18748
2023-08-23 06:57:13 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.991, trans_loss=4.902, nll_loss=2.144, w2v_ctc_loss=0.711, task_loss=1.255, contrastive_loss=0.119, total=4201.47, n_correct=2782.77, ppl=4.42, accuracy=66.233, wps=13637.7, ups=1.62, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=18810
2023-08-23 06:57:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 06:58:32 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.967 | trans_loss 5.165 | nll_loss 2.427 | w2v_ctc_loss 1.34 | task_loss 4.662 | contrastive_loss 0.303 | total 4003.4 | n_correct 2662.2 | ppl 5.38 | accuracy 66.498 | uer 18.122 | wer 19.988 | raw_wer 19.988 | bleu 21.98 | wps 1602.9 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 22.03
2023-08-23 06:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-23 06:58:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9808.pt
2023-08-23 06:58:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9808.pt
2023-08-23 06:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9808.pt (epoch 16 @ 23573 updates, score 21.98) (writing took 8.207074707956053 seconds)
2023-08-23 06:58:40 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-23 06:58:40 | INFO | train | epoch 016 | loss 1.994 | trans_loss 4.902 | nll_loss 2.143 | w2v_ctc_loss 0.709 | task_loss 1.321 | contrastive_loss 0.139 | total 4137.02 | n_correct 2739.15 | ppl 4.42 | accuracy 66.211 | wps 12742.9 | ups 1.54 | wpb 8274 | bsz 305.1 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 15.1 | wall 18897
2023-08-23 06:58:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 06:58:41 | INFO | fairseq.trainer | begin training epoch 17
2023-08-23 06:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 06:59:04 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.995, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.695, task_loss=1.348, contrastive_loss=0.253, total=4145.04, n_correct=2753.22, ppl=4.37, accuracy=66.422, wps=7472.3, ups=0.9, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=18921
2023-08-23 07:00:05 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.979, trans_loss=4.879, nll_loss=2.112, w2v_ctc_loss=0.701, task_loss=1.357, contrastive_loss=0.092, total=4117.27, n_correct=2743.38, ppl=4.32, accuracy=66.631, wps=13473.8, ups=1.64, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=18982
2023-08-23 07:01:08 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.991, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.69, task_loss=1.251, contrastive_loss=0.256, total=4159.6, n_correct=2770.9, ppl=4.32, accuracy=66.615, wps=13396.6, ups=1.61, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=19044
2023-08-23 07:02:09 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.992, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.695, task_loss=1.31, contrastive_loss=0.259, total=4156.91, n_correct=2766.19, ppl=4.35, accuracy=66.544, wps=13554.7, ups=1.63, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=19105
2023-08-23 07:03:10 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.977, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.7, task_loss=1.305, contrastive_loss=0.09, total=4146.43, n_correct=2766.21, ppl=4.34, accuracy=66.713, wps=13527.2, ups=1.63, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=19167
2023-08-23 07:03:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 07:03:43 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.984 | trans_loss 5.167 | nll_loss 2.427 | w2v_ctc_loss 1.392 | task_loss 4.631 | contrastive_loss 0.303 | total 4003.4 | n_correct 2662.3 | ppl 5.38 | accuracy 66.501 | uer 18.607 | wer 20.536 | raw_wer 20.536 | bleu 22.02 | wps 1636.8 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.03
2023-08-23 07:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-23 07:03:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_17_24000.pt
2023-08-23 07:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_17_24000.pt
2023-08-23 07:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 22.02) (writing took 8.52687803003937 seconds)
2023-08-23 07:04:55 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.985, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.7, task_loss=1.372, contrastive_loss=0.136, total=4182.1, n_correct=2778.47, ppl=4.36, accuracy=66.437, wps=8005, ups=0.96, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=19271
2023-08-23 07:05:56 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.976, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.694, task_loss=1.331, contrastive_loss=0.085, total=4167.27, n_correct=2776.5, ppl=4.35, accuracy=66.626, wps=13575.7, ups=1.63, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=61, gb_free=10.3, wall=19333
2023-08-23 07:06:58 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.993, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.716, task_loss=1.304, contrastive_loss=0.134, total=4166.12, n_correct=2765.49, ppl=4.37, accuracy=66.38, wps=13456.4, ups=1.61, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=19395
2023-08-23 07:07:59 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.982, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.702, task_loss=1.337, contrastive_loss=0.098, total=4091.64, n_correct=2722.57, ppl=4.36, accuracy=66.54, wps=13446.1, ups=1.64, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=19455
2023-08-23 07:09:00 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.977, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.697, task_loss=1.303, contrastive_loss=0.095, total=4106.83, n_correct=2729.25, ppl=4.36, accuracy=66.456, wps=13510.1, ups=1.64, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=19516
2023-08-23 07:10:01 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.981, trans_loss=4.888, nll_loss=2.126, w2v_ctc_loss=0.704, task_loss=1.301, contrastive_loss=0.099, total=4115.49, n_correct=2733.89, ppl=4.36, accuracy=66.429, wps=13477.7, ups=1.64, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=19577
2023-08-23 07:11:02 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.977, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.695, task_loss=1.37, contrastive_loss=0.086, total=4078.39, n_correct=2716.37, ppl=4.35, accuracy=66.604, wps=13360.6, ups=1.64, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=19638
2023-08-23 07:12:04 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.006, trans_loss=4.896, nll_loss=2.135, w2v_ctc_loss=0.695, task_loss=1.277, contrastive_loss=0.329, total=4173.49, n_correct=2764.21, ppl=4.39, accuracy=66.233, wps=13392.3, ups=1.6, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=62, gb_free=15.7, wall=19701
2023-08-23 07:13:06 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.987, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.692, task_loss=1.307, contrastive_loss=0.171, total=4156.28, n_correct=2762.23, ppl=4.37, accuracy=66.459, wps=13515.4, ups=1.63, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=19762
2023-08-23 07:14:07 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.98, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.697, task_loss=1.328, contrastive_loss=0.093, total=4112.95, n_correct=2735.97, ppl=4.37, accuracy=66.521, wps=13365.6, ups=1.62, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=19824
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 07:14:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
2023-08-23 07:15:09 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.972 | trans_loss 5.166 | nll_loss 2.43 | w2v_ctc_loss 1.353 | task_loss 4.653 | contrastive_loss 0.305 | total 4003.4 | n_correct 2662.6 | ppl 5.39 | accuracy 66.508 | uer 18.164 | wer 20.107 | raw_wer 20.107 | bleu 21.91 | wps 1638.2 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 22.03
2023-08-23 07:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-08-23 07:15:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9102.pt
2023-08-23 07:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9102.pt
2023-08-23 07:15:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9102.pt (epoch 17 @ 25047 updates, score 21.91) (writing took 7.787852736073546 seconds)
2023-08-23 07:15:17 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-23 07:15:17 | INFO | train | epoch 017 | loss 1.984 | trans_loss 4.887 | nll_loss 2.123 | w2v_ctc_loss 0.699 | task_loss 1.319 | contrastive_loss 0.143 | total 4138.65 | n_correct 2753.12 | ppl 4.36 | accuracy 66.522 | wps 12239.8 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 16.1 | wall 19894
2023-08-23 07:15:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 07:15:17 | INFO | fairseq.trainer | begin training epoch 18
2023-08-23 07:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 07:15:58 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.977, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.701, task_loss=1.344, contrastive_loss=0.1, total=4139.04, n_correct=2761.53, ppl=4.33, accuracy=66.719, wps=7473.6, ups=0.9, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=19935
2023-08-23 07:16:59 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.971, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.669, task_loss=1.26, contrastive_loss=0.223, total=4154.85, n_correct=2785.65, ppl=4.25, accuracy=67.046, wps=13534.8, ups=1.63, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=19996
2023-08-23 07:18:01 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.964, trans_loss=4.863, nll_loss=2.093, w2v_ctc_loss=0.687, task_loss=1.279, contrastive_loss=0.092, total=4162.72, n_correct=2793.69, ppl=4.27, accuracy=67.112, wps=13428.5, ups=1.61, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=61, gb_free=15.7, wall=20058
2023-08-23 07:19:03 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.968, trans_loss=4.869, nll_loss=2.099, w2v_ctc_loss=0.685, task_loss=1.336, contrastive_loss=0.105, total=4161.22, n_correct=2783.43, ppl=4.29, accuracy=66.89, wps=13469, ups=1.62, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=14, wall=20120
2023-08-23 07:20:05 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.982, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.686, task_loss=1.407, contrastive_loss=0.196, total=4092.36, n_correct=2732.52, ppl=4.31, accuracy=66.771, wps=13230.9, ups=1.62, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=20182
2023-08-23 07:21:06 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.957, trans_loss=4.858, nll_loss=2.087, w2v_ctc_loss=0.675, task_loss=1.183, contrastive_loss=0.103, total=4206.45, n_correct=2824.56, ppl=4.25, accuracy=67.148, wps=13744, ups=1.63, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=20243
2023-08-23 07:21:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 07:22:08 | INFO | train_inner | epoch 018:    654 / 1474 loss=1.985, trans_loss=4.88, nll_loss=2.115, w2v_ctc_loss=0.701, task_loss=1.357, contrastive_loss=0.172, total=4094.82, n_correct=2732.91, ppl=4.33, accuracy=66.741, wps=13205.7, ups=1.61, wpb=8189.6, bsz=299.1, num_updates=25700, lr=8.82162e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=20305
2023-08-23 07:23:10 | INFO | train_inner | epoch 018:    754 / 1474 loss=1.989, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.696, task_loss=1.256, contrastive_loss=0.261, total=4208.29, n_correct=2809.82, ppl=4.33, accuracy=66.769, wps=13654.3, ups=1.62, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=20366
2023-08-23 07:24:12 | INFO | train_inner | epoch 018:    854 / 1474 loss=1.969, trans_loss=4.873, nll_loss=2.105, w2v_ctc_loss=0.69, task_loss=1.339, contrastive_loss=0.082, total=4166.81, n_correct=2783.44, ppl=4.3, accuracy=66.8, wps=13528.3, ups=1.62, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=12.2, wall=20428
2023-08-23 07:25:12 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.962, trans_loss=4.867, nll_loss=2.098, w2v_ctc_loss=0.677, task_loss=1.224, contrastive_loss=0.104, total=4142.65, n_correct=2775.34, ppl=4.28, accuracy=66.994, wps=13704, ups=1.65, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=14.5, wall=20489
2023-08-23 07:25:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 07:25:45 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.164 | nll_loss 2.424 | w2v_ctc_loss 1.327 | task_loss 4.63 | contrastive_loss 0.304 | total 4003.4 | n_correct 2667.1 | ppl 5.37 | accuracy 66.621 | uer 18.093 | wer 20.133 | raw_wer 20.133 | bleu 22.1 | wps 1644.8 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.1
2023-08-23 07:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-23 07:25:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_18_26000.pt
2023-08-23 07:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_18_26000.pt
2023-08-23 07:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.1) (writing took 16.373361150035635 seconds)
2023-08-23 07:27:04 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.967, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.683, task_loss=1.37, contrastive_loss=0.091, total=4137.77, n_correct=2767.21, ppl=4.3, accuracy=66.877, wps=7420, ups=0.9, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=20600
2023-08-23 07:28:05 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.976, trans_loss=4.863, nll_loss=2.094, w2v_ctc_loss=0.688, task_loss=1.246, contrastive_loss=0.197, total=4153.69, n_correct=2782.56, ppl=4.27, accuracy=66.99, wps=13470.2, ups=1.62, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=14.8, wall=20662
2023-08-23 07:29:06 | INFO | train_inner | epoch 018:   1254 / 1474 loss=1.973, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.69, task_loss=1.417, contrastive_loss=0.086, total=4087.62, n_correct=2726.27, ppl=4.34, accuracy=66.696, wps=13357, ups=1.63, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=20723
2023-08-23 07:30:08 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.984, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.71, task_loss=1.407, contrastive_loss=0.111, total=4070.69, n_correct=2711.65, ppl=4.34, accuracy=66.614, wps=13246.5, ups=1.63, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=20784
2023-08-23 07:31:09 | INFO | train_inner | epoch 018:   1454 / 1474 loss=1.977, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.701, task_loss=1.394, contrastive_loss=0.098, total=4113.2, n_correct=2744.99, ppl=4.33, accuracy=66.736, wps=13375.6, ups=1.63, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=20846
2023-08-23 07:31:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 07:31:54 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.163 | nll_loss 2.425 | w2v_ctc_loss 1.364 | task_loss 4.636 | contrastive_loss 0.295 | total 4003.4 | n_correct 2667 | ppl 5.37 | accuracy 66.618 | uer 17.872 | wer 19.872 | raw_wer 19.872 | bleu 22.18 | wps 1622.7 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 22.18
2023-08-23 07:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-23 07:31:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 07:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 07:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 18 @ 26520 updates, score 22.18) (writing took 13.72594183892943 seconds)
2023-08-23 07:32:09 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-23 07:32:09 | INFO | train | epoch 018 | loss 1.973 | trans_loss 4.872 | nll_loss 2.104 | w2v_ctc_loss 0.688 | task_loss 1.318 | contrastive_loss 0.14 | total 4138.72 | n_correct 2767.44 | ppl 4.3 | accuracy 66.867 | wps 12053.2 | ups 1.46 | wpb 8277.4 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 15.5 | wall 20905
2023-08-23 07:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 07:32:09 | INFO | fairseq.trainer | begin training epoch 19
2023-08-23 07:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 07:33:05 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.966, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.681, task_loss=1.321, contrastive_loss=0.147, total=4102.06, n_correct=2755.25, ppl=4.24, accuracy=67.167, wps=7089.2, ups=0.86, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=20962
2023-08-23 07:34:07 | INFO | train_inner | epoch 019:    180 / 1474 loss=1.968, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.692, task_loss=1.228, contrastive_loss=0.139, total=4227.7, n_correct=2841.62, ppl=4.24, accuracy=67.214, wps=13612.4, ups=1.61, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=21024
2023-08-23 07:35:08 | INFO | train_inner | epoch 019:    280 / 1474 loss=1.954, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.679, task_loss=1.3, contrastive_loss=0.082, total=4187.34, n_correct=2818.97, ppl=4.2, accuracy=67.321, wps=13675.8, ups=1.63, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=21085
2023-08-23 07:36:10 | INFO | train_inner | epoch 019:    380 / 1474 loss=1.968, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.677, task_loss=1.298, contrastive_loss=0.192, total=4170.52, n_correct=2800.51, ppl=4.23, accuracy=67.15, wps=13467.1, ups=1.61, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=21147
2023-08-23 07:37:11 | INFO | train_inner | epoch 019:    480 / 1474 loss=1.967, trans_loss=4.861, nll_loss=2.089, w2v_ctc_loss=0.694, task_loss=1.35, contrastive_loss=0.098, total=4113.89, n_correct=2761.67, ppl=4.25, accuracy=67.13, wps=13531.7, ups=1.64, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=21208
2023-08-23 07:38:12 | INFO | train_inner | epoch 019:    580 / 1474 loss=1.963, trans_loss=4.855, nll_loss=2.082, w2v_ctc_loss=0.677, task_loss=1.291, contrastive_loss=0.159, total=4128.58, n_correct=2774.28, ppl=4.23, accuracy=67.197, wps=13605, ups=1.65, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=21268
2023-08-23 07:39:13 | INFO | train_inner | epoch 019:    680 / 1474 loss=1.952, trans_loss=4.86, nll_loss=2.089, w2v_ctc_loss=0.666, task_loss=1.199, contrastive_loss=0.089, total=4201.56, n_correct=2823.93, ppl=4.25, accuracy=67.211, wps=13747.8, ups=1.64, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=21330
2023-08-23 07:40:15 | INFO | train_inner | epoch 019:    780 / 1474 loss=1.962, trans_loss=4.857, nll_loss=2.084, w2v_ctc_loss=0.686, task_loss=1.36, contrastive_loss=0.094, total=4124.03, n_correct=2767, ppl=4.24, accuracy=67.095, wps=13415.3, ups=1.63, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=21391
2023-08-23 07:41:17 | INFO | train_inner | epoch 019:    880 / 1474 loss=1.964, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.686, task_loss=1.315, contrastive_loss=0.091, total=4177.8, n_correct=2800.67, ppl=4.27, accuracy=67.037, wps=13451.7, ups=1.61, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=62, gb_free=14.5, wall=21453
2023-08-23 07:42:19 | INFO | train_inner | epoch 019:    980 / 1474 loss=1.985, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.679, task_loss=1.338, contrastive_loss=0.317, total=4084.26, n_correct=2734.61, ppl=4.29, accuracy=66.955, wps=13164.6, ups=1.61, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=21515
2023-08-23 07:43:20 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.965, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.675, task_loss=1.383, contrastive_loss=0.128, total=4042.73, n_correct=2708.41, ppl=4.28, accuracy=66.995, wps=13150.1, ups=1.63, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=21577
2023-08-23 07:44:22 | INFO | train_inner | epoch 019:   1180 / 1474 loss=1.982, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.692, task_loss=1.343, contrastive_loss=0.212, total=4140.95, n_correct=2767.74, ppl=4.29, accuracy=66.838, wps=13392.5, ups=1.62, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=61, gb_free=12.3, wall=21639
2023-08-23 07:45:23 | INFO | train_inner | epoch 019:   1280 / 1474 loss=1.965, trans_loss=4.866, nll_loss=2.097, w2v_ctc_loss=0.679, task_loss=1.336, contrastive_loss=0.108, total=4135.79, n_correct=2766.96, ppl=4.28, accuracy=66.903, wps=13599.4, ups=1.64, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=21699
2023-08-23 07:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 07:46:25 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.964, trans_loss=4.863, nll_loss=2.092, w2v_ctc_loss=0.685, task_loss=1.342, contrastive_loss=0.095, total=4139.76, n_correct=2774.57, ppl=4.26, accuracy=67.022, wps=13311.4, ups=1.61, wpb=8279.5, bsz=301.2, num_updates=27900, lr=8.46668e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=62, gb_free=15.9, wall=21762
2023-08-23 07:47:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 07:47:55 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.164 | nll_loss 2.425 | w2v_ctc_loss 1.363 | task_loss 4.649 | contrastive_loss 0.298 | total 4003.4 | n_correct 2663.7 | ppl 5.37 | accuracy 66.536 | uer 17.848 | wer 19.82 | raw_wer 19.82 | bleu 22.19 | wps 1645 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 22.19
2023-08-23 07:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-23 07:47:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 07:48:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 07:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 19 @ 27993 updates, score 22.19) (writing took 12.764961283071898 seconds)
2023-08-23 07:48:08 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-23 07:48:08 | INFO | train | epoch 019 | loss 1.966 | trans_loss 4.86 | nll_loss 2.088 | w2v_ctc_loss 0.682 | task_loss 1.317 | contrastive_loss 0.139 | total 4138.84 | n_correct 2777.25 | ppl 4.25 | accuracy 67.102 | wps 12713.8 | ups 1.54 | wpb 8277.7 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 17.1 | wall 21864
2023-08-23 07:48:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 07:48:08 | INFO | fairseq.trainer | begin training epoch 20
2023-08-23 07:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 07:48:20 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.963, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.674, task_loss=1.331, contrastive_loss=0.176, total=4119.08, n_correct=2769.59, ppl=4.23, accuracy=67.238, wps=7194.6, ups=0.87, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=21876
2023-08-23 07:48:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 07:48:52 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.16 | nll_loss 2.421 | w2v_ctc_loss 1.327 | task_loss 4.667 | contrastive_loss 0.297 | total 4003.4 | n_correct 2665.8 | ppl 5.35 | accuracy 66.588 | uer 17.564 | wer 19.6 | raw_wer 19.6 | bleu 22.1 | wps 1635.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.19
2023-08-23 07:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-23 07:48:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_20_28000.pt
2023-08-23 07:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_20_28000.pt
2023-08-23 07:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.1) (writing took 7.517138193012215 seconds)
2023-08-23 07:50:02 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.942, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.661, task_loss=1.272, contrastive_loss=0.1, total=4195.03, n_correct=2838.12, ppl=4.15, accuracy=67.654, wps=8177, ups=0.97, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=14.7, wall=21979
2023-08-23 07:51:04 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.958, trans_loss=4.844, nll_loss=2.067, w2v_ctc_loss=0.674, task_loss=1.365, contrastive_loss=0.152, total=4154.14, n_correct=2798.67, ppl=4.19, accuracy=67.371, wps=13403, ups=1.61, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=22041
2023-08-23 07:52:05 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.942, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.667, task_loss=1.19, contrastive_loss=0.09, total=4188.05, n_correct=2834.19, ppl=4.17, accuracy=67.673, wps=13804.8, ups=1.65, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22101
2023-08-23 07:53:07 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.946, trans_loss=4.837, nll_loss=2.058, w2v_ctc_loss=0.665, task_loss=1.338, contrastive_loss=0.088, total=4115.16, n_correct=2780.21, ppl=4.16, accuracy=67.56, wps=13302.7, ups=1.62, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=22163
2023-08-23 07:54:08 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.959, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.666, task_loss=1.351, contrastive_loss=0.177, total=4108.46, n_correct=2766.83, ppl=4.21, accuracy=67.345, wps=13371.1, ups=1.63, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=22225
2023-08-23 07:55:09 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.963, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.672, task_loss=1.386, contrastive_loss=0.178, total=4094.9, n_correct=2760.49, ppl=4.2, accuracy=67.413, wps=13425.4, ups=1.64, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=11.5, wall=22286
2023-08-23 07:56:10 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.956, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.681, task_loss=1.319, contrastive_loss=0.083, total=4140.23, n_correct=2784.7, ppl=4.22, accuracy=67.26, wps=13541.8, ups=1.64, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=22347
2023-08-23 07:57:11 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.953, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.677, task_loss=1.306, contrastive_loss=0.085, total=4140.66, n_correct=2789.77, ppl=4.22, accuracy=67.375, wps=13582.2, ups=1.64, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=22408
2023-08-23 07:58:14 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.986, trans_loss=4.858, nll_loss=2.087, w2v_ctc_loss=0.675, task_loss=1.261, contrastive_loss=0.375, total=4157.15, n_correct=2789.31, ppl=4.25, accuracy=67.097, wps=13298.3, ups=1.6, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=62, gb_free=17.4, wall=22470
2023-08-23 07:59:16 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.948, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.666, task_loss=1.302, contrastive_loss=0.091, total=4171.86, n_correct=2812.56, ppl=4.2, accuracy=67.417, wps=13438.7, ups=1.61, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=62, gb_free=15.3, wall=22532
2023-08-23 08:00:17 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.969, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.673, task_loss=1.272, contrastive_loss=0.229, total=4162.96, n_correct=2800.43, ppl=4.22, accuracy=67.27, wps=13628.6, ups=1.64, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=22594
2023-08-23 08:01:19 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.955, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.684, task_loss=1.444, contrastive_loss=0.08, total=4033.74, n_correct=2716.72, ppl=4.18, accuracy=67.35, wps=13073.9, ups=1.62, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=22655
2023-08-23 08:02:21 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.954, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.673, task_loss=1.396, contrastive_loss=0.085, total=4124.42, n_correct=2776.45, ppl=4.22, accuracy=67.317, wps=13306.7, ups=1.61, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=22717
2023-08-23 08:03:22 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.958, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.68, task_loss=1.402, contrastive_loss=0.083, total=4114.1, n_correct=2764.36, ppl=4.23, accuracy=67.192, wps=13392.2, ups=1.63, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=14, wall=22779
2023-08-23 08:04:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:04:37 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.157 | nll_loss 2.412 | w2v_ctc_loss 1.305 | task_loss 4.656 | contrastive_loss 0.294 | total 4003.4 | n_correct 2669 | ppl 5.32 | accuracy 66.668 | uer 17.522 | wer 19.28 | raw_wer 19.28 | bleu 21.93 | wps 1589.6 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 22.19
2023-08-23 08:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-23 08:04:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9300.pt
2023-08-23 08:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9300.pt
2023-08-23 08:04:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_21.9300.pt (epoch 20 @ 29467 updates, score 21.93) (writing took 7.642237010993995 seconds)
2023-08-23 08:04:45 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-23 08:04:45 | INFO | train | epoch 020 | loss 1.956 | trans_loss 4.846 | nll_loss 2.071 | w2v_ctc_loss 0.672 | task_loss 1.319 | contrastive_loss 0.136 | total 4138.65 | n_correct 2788.57 | ppl 4.2 | accuracy 67.379 | wps 12239.9 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 15.9 | wall 22861
2023-08-23 08:04:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 08:04:45 | INFO | fairseq.trainer | begin training epoch 21
2023-08-23 08:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 08:05:13 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.961, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.668, task_loss=1.246, contrastive_loss=0.204, total=4155.01, n_correct=2799.19, ppl=4.21, accuracy=67.369, wps=7525.7, ups=0.91, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=22889
2023-08-23 08:06:14 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.949, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.659, task_loss=1.244, contrastive_loss=0.193, total=4186.67, n_correct=2834.61, ppl=4.12, accuracy=67.706, wps=13652.9, ups=1.63, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=61, gb_free=12.5, wall=22950
2023-08-23 08:07:15 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.939, trans_loss=4.83, nll_loss=2.049, w2v_ctc_loss=0.652, task_loss=1.244, contrastive_loss=0.146, total=4166.37, n_correct=2823.85, ppl=4.14, accuracy=67.777, wps=13720.7, ups=1.65, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=13.7, wall=23011
2023-08-23 08:08:17 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.951, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.669, task_loss=1.339, contrastive_loss=0.149, total=4132.25, n_correct=2791.21, ppl=4.15, accuracy=67.547, wps=13339.5, ups=1.61, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=23073
2023-08-23 08:09:18 | INFO | train_inner | epoch 021:    433 / 1474 loss=1.937, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.656, task_loss=1.255, contrastive_loss=0.082, total=4195.53, n_correct=2845.55, ppl=4.14, accuracy=67.823, wps=13782.4, ups=1.64, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=23134
2023-08-23 08:10:20 | INFO | train_inner | epoch 021:    533 / 1474 loss=1.938, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.666, task_loss=1.362, contrastive_loss=0.077, total=4085.05, n_correct=2773.76, ppl=4.11, accuracy=67.9, wps=13166.1, ups=1.61, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=62, gb_free=15.9, wall=23196
2023-08-23 08:10:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:10:53 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.159 | nll_loss 2.417 | w2v_ctc_loss 1.303 | task_loss 4.662 | contrastive_loss 0.291 | total 4003.4 | n_correct 2669.4 | ppl 5.34 | accuracy 66.678 | uer 17.49 | wer 19.399 | raw_wer 19.399 | bleu 22.01 | wps 1633.3 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.19
2023-08-23 08:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-23 08:10:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_21_30000.pt
2023-08-23 08:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_21_30000.pt
2023-08-23 08:11:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.01) (writing took 8.475676998961717 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 08:12:04 | INFO | train_inner | epoch 021:    633 / 1474 loss=1.955, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.66, task_loss=1.304, contrastive_loss=0.247, total=4220.3, n_correct=2858.93, ppl=4.14, accuracy=67.742, wps=8112.6, ups=0.96, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=23300
2023-08-23 08:13:05 | INFO | train_inner | epoch 021:    733 / 1474 loss=1.947, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.662, task_loss=1.321, contrastive_loss=0.11, total=4148.18, n_correct=2803.75, ppl=4.18, accuracy=67.59, wps=13480.9, ups=1.62, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=11.5, wall=23362
2023-08-23 08:14:07 | INFO | train_inner | epoch 021:    833 / 1474 loss=1.954, trans_loss=4.844, nll_loss=2.068, w2v_ctc_loss=0.671, task_loss=1.406, contrastive_loss=0.122, total=4062.56, n_correct=2741.17, ppl=4.19, accuracy=67.474, wps=13218, ups=1.63, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=15.9, wall=23423
2023-08-23 08:15:07 | INFO | train_inner | epoch 021:    933 / 1474 loss=1.941, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.662, task_loss=1.314, contrastive_loss=0.094, total=4103.66, n_correct=2779.02, ppl=4.15, accuracy=67.721, wps=13502.4, ups=1.65, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=23484
2023-08-23 08:16:09 | INFO | train_inner | epoch 021:   1033 / 1474 loss=1.947, trans_loss=4.843, nll_loss=2.066, w2v_ctc_loss=0.668, task_loss=1.348, contrastive_loss=0.091, total=4100.54, n_correct=2769.2, ppl=4.19, accuracy=67.533, wps=13423.5, ups=1.64, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=23545
2023-08-23 08:17:10 | INFO | train_inner | epoch 021:   1133 / 1474 loss=1.945, trans_loss=4.832, nll_loss=2.051, w2v_ctc_loss=0.667, task_loss=1.417, contrastive_loss=0.095, total=4119.98, n_correct=2789.51, ppl=4.14, accuracy=67.707, wps=13440.6, ups=1.63, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=23606
2023-08-23 08:18:11 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.95, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.664, task_loss=1.244, contrastive_loss=0.146, total=4161.49, n_correct=2811.27, ppl=4.17, accuracy=67.554, wps=13634.6, ups=1.64, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=23667
2023-08-23 08:19:12 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.945, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.663, task_loss=1.276, contrastive_loss=0.108, total=4141.76, n_correct=2803.39, ppl=4.17, accuracy=67.686, wps=13485.6, ups=1.63, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=23729
2023-08-23 08:19:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 08:20:15 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.958, trans_loss=4.844, nll_loss=2.067, w2v_ctc_loss=0.687, task_loss=1.424, contrastive_loss=0.098, total=4116, n_correct=2772.42, ppl=4.19, accuracy=67.357, wps=13236, ups=1.61, wpb=8232, bsz=296.9, num_updates=30900, lr=8.04518e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=62, gb_free=15.2, wall=23791
2023-08-23 08:20:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
2023-08-23 08:21:12 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.162 | nll_loss 2.421 | w2v_ctc_loss 1.309 | task_loss 4.654 | contrastive_loss 0.301 | total 4003.4 | n_correct 2662.2 | ppl 5.36 | accuracy 66.498 | uer 17.601 | wer 19.544 | raw_wer 19.544 | bleu 22.09 | wps 1652.9 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 22.19
2023-08-23 08:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-23 08:21:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.0900.pt
2023-08-23 08:21:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.0900.pt
2023-08-23 08:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.0900.pt (epoch 21 @ 30940 updates, score 22.09) (writing took 7.375109995016828 seconds)
2023-08-23 08:21:20 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-23 08:21:20 | INFO | train | epoch 021 | loss 1.947 | trans_loss 4.834 | nll_loss 2.055 | w2v_ctc_loss 0.664 | task_loss 1.322 | contrastive_loss 0.13 | total 4137.4 | n_correct 2799.01 | ppl 4.16 | accuracy 67.652 | wps 12242.2 | ups 1.48 | wpb 8274.8 | bsz 305.2 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 897 | gb_free 15.1 | wall 23857
2023-08-23 08:21:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 08:21:21 | INFO | fairseq.trainer | begin training epoch 22
2023-08-23 08:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 08:22:04 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.935, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.661, task_loss=1.342, contrastive_loss=0.077, total=4128.84, n_correct=2808.31, ppl=4.1, accuracy=68.017, wps=7521.5, ups=0.91, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=61, gb_free=13.8, wall=23901
2023-08-23 08:23:06 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.942, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.661, task_loss=1.33, contrastive_loss=0.157, total=4123.35, n_correct=2800.12, ppl=4.1, accuracy=67.909, wps=13362.2, ups=1.62, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=14.3, wall=23963
2023-08-23 08:24:07 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.926, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.648, task_loss=1.162, contrastive_loss=0.099, total=4267.16, n_correct=2912.65, ppl=4.08, accuracy=68.257, wps=13888.2, ups=1.63, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=24024
2023-08-23 08:25:10 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.957, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.661, task_loss=1.341, contrastive_loss=0.253, total=4180.09, n_correct=2829.65, ppl=4.12, accuracy=67.694, wps=13332.1, ups=1.59, wpb=8360.2, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=62, gb_free=17.3, wall=24087
2023-08-23 08:26:12 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.947, trans_loss=4.826, nll_loss=2.043, w2v_ctc_loss=0.662, task_loss=1.39, contrastive_loss=0.142, total=4132.62, n_correct=2804.29, ppl=4.12, accuracy=67.857, wps=13448.8, ups=1.63, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=24148
2023-08-23 08:27:14 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.933, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.657, task_loss=1.326, contrastive_loss=0.088, total=4155.5, n_correct=2827.57, ppl=4.1, accuracy=68.044, wps=13383.7, ups=1.61, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=24210
2023-08-23 08:28:15 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.934, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.645, task_loss=1.245, contrastive_loss=0.169, total=4147.84, n_correct=2825.34, ppl=4.08, accuracy=68.116, wps=13568.4, ups=1.64, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=12.7, wall=24271
2023-08-23 08:29:17 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.933, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.656, task_loss=1.35, contrastive_loss=0.088, total=4166.89, n_correct=2834.08, ppl=4.09, accuracy=68.014, wps=13506.9, ups=1.62, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=24333
2023-08-23 08:30:19 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.941, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.664, task_loss=1.435, contrastive_loss=0.076, total=4074.75, n_correct=2756.4, ppl=4.14, accuracy=67.646, wps=13133.5, ups=1.61, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=24395
2023-08-23 08:31:20 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.931, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.653, task_loss=1.325, contrastive_loss=0.077, total=4136.34, n_correct=2810.16, ppl=4.1, accuracy=67.938, wps=13500.8, ups=1.63, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=24456
2023-08-23 08:32:21 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.942, trans_loss=4.816, nll_loss=2.032, w2v_ctc_loss=0.647, task_loss=1.257, contrastive_loss=0.244, total=4157.21, n_correct=2827.24, ppl=4.09, accuracy=68.008, wps=13535.8, ups=1.63, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=61, gb_free=11.7, wall=24518
2023-08-23 08:32:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:32:54 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.157 | nll_loss 2.417 | w2v_ctc_loss 1.317 | task_loss 4.654 | contrastive_loss 0.292 | total 4003.4 | n_correct 2670 | ppl 5.34 | accuracy 66.693 | uer 17.835 | wer 19.884 | raw_wer 19.884 | bleu 22.46 | wps 1627.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.46
2023-08-23 08:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-23 08:32:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_22_32000.pt
2023-08-23 08:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_22_32000.pt
2023-08-23 08:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.46) (writing took 12.965930729056709 seconds)
2023-08-23 08:34:09 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.95, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.666, task_loss=1.375, contrastive_loss=0.128, total=4092.91, n_correct=2766.27, ppl=4.17, accuracy=67.587, wps=7596.9, ups=0.93, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=24626
2023-08-23 08:35:11 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.947, trans_loss=4.839, nll_loss=2.063, w2v_ctc_loss=0.665, task_loss=1.219, contrastive_loss=0.123, total=4182.65, n_correct=2826.74, ppl=4.18, accuracy=67.583, wps=13599.7, ups=1.63, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=24687
2023-08-23 08:36:12 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.938, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.653, task_loss=1.31, contrastive_loss=0.143, total=4071.58, n_correct=2763.42, ppl=4.12, accuracy=67.871, wps=13358.2, ups=1.64, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=24748
2023-08-23 08:37:13 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.946, trans_loss=4.835, nll_loss=2.055, w2v_ctc_loss=0.671, task_loss=1.409, contrastive_loss=0.092, total=4077.83, n_correct=2759.9, ppl=4.16, accuracy=67.681, wps=13363.2, ups=1.64, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=24809
2023-08-23 08:37:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:37:54 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.311 | task_loss 4.616 | contrastive_loss 0.294 | total 4003.4 | n_correct 2672.4 | ppl 5.31 | accuracy 66.753 | uer 17.692 | wer 19.66 | raw_wer 19.66 | bleu 22.31 | wps 1614.8 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 22.46
2023-08-23 08:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-08-23 08:37:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.3109.pt
2023-08-23 08:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.3109.pt
2023-08-23 08:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.3109.pt (epoch 22 @ 32414 updates, score 22.31) (writing took 7.036329783964902 seconds)
2023-08-23 08:38:02 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-23 08:38:02 | INFO | train | epoch 022 | loss 1.94 | trans_loss 4.823 | nll_loss 2.041 | w2v_ctc_loss 0.658 | task_loss 1.319 | contrastive_loss 0.132 | total 4138.65 | n_correct 2809.43 | ppl 4.12 | accuracy 67.883 | wps 12182.4 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 899 | gb_free 11.3 | wall 24858
2023-08-23 08:38:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 08:38:02 | INFO | fairseq.trainer | begin training epoch 23
2023-08-23 08:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 08:39:03 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.931, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.661, task_loss=1.364, contrastive_loss=0.083, total=4089.8, n_correct=2787.09, ppl=4.06, accuracy=68.147, wps=7437.8, ups=0.91, wpb=8179.6, bsz=299.5, num_updates=32500, lr=7.84465e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=24919
2023-08-23 08:40:04 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.924, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.647, task_loss=1.388, contrastive_loss=0.08, total=4117.76, n_correct=2812.76, ppl=4.03, accuracy=68.308, wps=13341.2, ups=1.62, wpb=8235.5, bsz=296, num_updates=32600, lr=7.8326e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=24981
2023-08-23 08:41:06 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.935, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.644, task_loss=1.343, contrastive_loss=0.157, total=4144.73, n_correct=2822.55, ppl=4.08, accuracy=68.1, wps=13388.6, ups=1.62, wpb=8289.5, bsz=304, num_updates=32700, lr=7.82062e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=25043
2023-08-23 08:42:07 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.921, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.645, task_loss=1.355, contrastive_loss=0.072, total=4126.79, n_correct=2819.46, ppl=4.03, accuracy=68.321, wps=13484.6, ups=1.63, wpb=8253.6, bsz=296.4, num_updates=32800, lr=7.80869e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=25104
2023-08-23 08:43:09 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.931, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.647, task_loss=1.288, contrastive_loss=0.13, total=4150.15, n_correct=2827.15, ppl=4.08, accuracy=68.122, wps=13552.4, ups=1.63, wpb=8300.3, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=25165
2023-08-23 08:44:10 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.919, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.643, task_loss=1.244, contrastive_loss=0.078, total=4174.6, n_correct=2853.52, ppl=4.04, accuracy=68.354, wps=13627.2, ups=1.63, wpb=8349.2, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=25227
2023-08-23 08:45:11 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.933, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.65, task_loss=1.327, contrastive_loss=0.118, total=4136.6, n_correct=2820, ppl=4.08, accuracy=68.172, wps=13469.5, ups=1.63, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=25288
2023-08-23 08:46:13 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.932, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.655, task_loss=1.329, contrastive_loss=0.097, total=4147.22, n_correct=2821.82, ppl=4.08, accuracy=68.041, wps=13524.9, ups=1.63, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=25349
2023-08-23 08:47:14 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.93, trans_loss=4.808, nll_loss=2.022, w2v_ctc_loss=0.644, task_loss=1.191, contrastive_loss=0.173, total=4193.16, n_correct=2863.58, ppl=4.06, accuracy=68.292, wps=13694, ups=1.63, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=61, gb_free=15.6, wall=25411
2023-08-23 08:48:16 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.949, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.644, task_loss=1.315, contrastive_loss=0.328, total=4164.33, n_correct=2833.18, ppl=4.08, accuracy=68.034, wps=13423.8, ups=1.61, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=25473
2023-08-23 08:49:18 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.938, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.663, task_loss=1.417, contrastive_loss=0.085, total=4088.37, n_correct=2776.46, ppl=4.1, accuracy=67.911, wps=13219.1, ups=1.62, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=25534
2023-08-23 08:50:21 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.93, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.657, task_loss=1.31, contrastive_loss=0.077, total=4162.3, n_correct=2830.89, ppl=4.1, accuracy=68.013, wps=13294.9, ups=1.6, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=62, gb_free=15.3, wall=25597
2023-08-23 08:51:21 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.925, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.647, task_loss=1.284, contrastive_loss=0.089, total=4131.74, n_correct=2818.41, ppl=4.08, accuracy=68.214, wps=13556.7, ups=1.64, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=25658
2023-08-23 08:52:23 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.942, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.655, task_loss=1.333, contrastive_loss=0.144, total=4141.25, n_correct=2809.33, ppl=4.13, accuracy=67.838, wps=13480.3, ups=1.63, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=25719
2023-08-23 08:52:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 08:53:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:53:51 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.931 | trans_loss 5.151 | nll_loss 2.407 | w2v_ctc_loss 1.272 | task_loss 4.672 | contrastive_loss 0.287 | total 4003.4 | n_correct 2676.2 | ppl 5.3 | accuracy 66.848 | uer 17.373 | wer 19.298 | raw_wer 19.298 | bleu 22.29 | wps 1566.4 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 22.46
2023-08-23 08:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-23 08:53:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2902.pt
2023-08-23 08:53:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2902.pt
2023-08-23 08:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2902.pt (epoch 23 @ 33887 updates, score 22.29) (writing took 7.217349193990231 seconds)
2023-08-23 08:53:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-23 08:53:59 | INFO | train | epoch 023 | loss 1.932 | trans_loss 4.812 | nll_loss 2.027 | w2v_ctc_loss 0.65 | task_loss 1.322 | contrastive_loss 0.123 | total 4136.71 | n_correct 2818.09 | ppl 4.07 | accuracy 68.124 | wps 12728.5 | ups 1.54 | wpb 8273.4 | bsz 305 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 900 | gb_free 13.2 | wall 25816
2023-08-23 08:53:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 08:53:59 | INFO | fairseq.trainer | begin training epoch 24
2023-08-23 08:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 08:54:15 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.934, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.65, task_loss=1.37, contrastive_loss=0.108, total=4062.78, n_correct=2761.37, ppl=4.1, accuracy=67.968, wps=7239.7, ups=0.89, wpb=8125.6, bsz=295.2, num_updates=33900, lr=7.68095e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=62, gb_free=12.2, wall=25832
2023-08-23 08:55:17 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.928, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.635, task_loss=1.219, contrastive_loss=0.239, total=4171.44, n_correct=2857.31, ppl=4, accuracy=68.497, wps=13554.2, ups=1.62, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=25893
2023-08-23 08:55:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 08:55:50 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.157 | nll_loss 2.411 | w2v_ctc_loss 1.33 | task_loss 4.683 | contrastive_loss 0.294 | total 4003.4 | n_correct 2671 | ppl 5.32 | accuracy 66.718 | uer 17.209 | wer 19.138 | raw_wer 19.138 | bleu 22.1 | wps 1637.1 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.46
2023-08-23 08:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-23 08:55:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_24_34000.pt
2023-08-23 08:55:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_24_34000.pt
2023-08-23 08:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.1) (writing took 7.740185391972773 seconds)
2023-08-23 08:57:00 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.933, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.628, task_loss=1.149, contrastive_loss=0.292, total=4251.29, n_correct=2909.12, ppl=4.03, accuracy=68.429, wps=8250.1, ups=0.97, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=25996
2023-08-23 08:58:01 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.918, trans_loss=4.799, nll_loss=2.009, w2v_ctc_loss=0.643, task_loss=1.291, contrastive_loss=0.074, total=4128.18, n_correct=2821.71, ppl=4.03, accuracy=68.352, wps=13562.6, ups=1.64, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=26057
2023-08-23 08:59:02 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.942, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.65, task_loss=1.383, contrastive_loss=0.217, total=4158.92, n_correct=2838.07, ppl=4.04, accuracy=68.241, wps=13482.7, ups=1.62, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=26119
2023-08-23 09:00:04 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.925, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.645, task_loss=1.339, contrastive_loss=0.141, total=4144.91, n_correct=2834.24, ppl=4.02, accuracy=68.379, wps=13410.6, ups=1.62, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=26181
2023-08-23 09:01:05 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.92, trans_loss=4.798, nll_loss=2.009, w2v_ctc_loss=0.636, task_loss=1.322, contrastive_loss=0.106, total=4165.3, n_correct=2848.16, ppl=4.03, accuracy=68.378, wps=13610.4, ups=1.63, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=26242
2023-08-23 09:02:07 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.927, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.641, task_loss=1.361, contrastive_loss=0.119, total=4102.21, n_correct=2799.48, ppl=4.05, accuracy=68.243, wps=13298.4, ups=1.62, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=26304
2023-08-23 09:03:09 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.925, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.646, task_loss=1.331, contrastive_loss=0.093, total=4110.6, n_correct=2805.96, ppl=4.07, accuracy=68.262, wps=13360.1, ups=1.63, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=26365
2023-08-23 09:04:10 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.93, trans_loss=4.808, nll_loss=2.02, w2v_ctc_loss=0.658, task_loss=1.464, contrastive_loss=0.07, total=4043.03, n_correct=2752.41, ppl=4.06, accuracy=68.078, wps=13271.4, ups=1.64, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=10.8, wall=26426
2023-08-23 09:05:11 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.922, trans_loss=4.808, nll_loss=2.02, w2v_ctc_loss=0.643, task_loss=1.359, contrastive_loss=0.075, total=4136.81, n_correct=2828.2, ppl=4.06, accuracy=68.367, wps=13432.6, ups=1.62, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=26488
2023-08-23 09:06:13 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.922, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.647, task_loss=1.269, contrastive_loss=0.117, total=4135.73, n_correct=2832.28, ppl=4.01, accuracy=68.483, wps=13441.9, ups=1.63, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=26549
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 09:07:15 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.926, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.644, task_loss=1.305, contrastive_loss=0.105, total=4148.3, n_correct=2829.37, ppl=4.06, accuracy=68.206, wps=13397.5, ups=1.61, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=26611
2023-08-23 09:08:17 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.929, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.656, task_loss=1.406, contrastive_loss=0.078, total=4110.05, n_correct=2803.4, ppl=4.06, accuracy=68.208, wps=13158.2, ups=1.6, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=26674
2023-08-23 09:09:18 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.93, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.659, task_loss=1.381, contrastive_loss=0.077, total=4090.91, n_correct=2790.03, ppl=4.07, accuracy=68.201, wps=13406.1, ups=1.64, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=26735
2023-08-23 09:09:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
2023-08-23 09:10:28 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.312 | task_loss 4.655 | contrastive_loss 0.286 | total 4003.4 | n_correct 2684 | ppl 5.31 | accuracy 67.043 | uer 17.421 | wer 19.321 | raw_wer 19.321 | bleu 22.84 | wps 1657.5 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 22.84
2023-08-23 09:10:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-23 09:10:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 09:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt
2023-08-23 09:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_best.pt (epoch 24 @ 35361 updates, score 22.84) (writing took 11.85986351093743 seconds)
2023-08-23 09:10:40 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-23 09:10:40 | INFO | train | epoch 024 | loss 1.926 | trans_loss 4.803 | nll_loss 2.014 | w2v_ctc_loss 0.644 | task_loss 1.318 | contrastive_loss 0.129 | total 4138.65 | n_correct 2827.4 | ppl 4.04 | accuracy 68.317 | wps 12191.6 | ups 1.47 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 898 | gb_free 15.8 | wall 26817
2023-08-23 09:10:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 09:10:40 | INFO | fairseq.trainer | begin training epoch 25
2023-08-23 09:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 09:11:11 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.912, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.635, task_loss=1.263, contrastive_loss=0.083, total=4166.95, n_correct=2861.07, ppl=4.01, accuracy=68.661, wps=7389.7, ups=0.89, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=26847
2023-08-23 09:12:12 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.906, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.63, task_loss=1.292, contrastive_loss=0.081, total=4133.64, n_correct=2846.33, ppl=3.96, accuracy=68.858, wps=13506.5, ups=1.63, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=26909
2023-08-23 09:13:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-23 09:13:15 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.913, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.639, task_loss=1.355, contrastive_loss=0.084, total=4117.21, n_correct=2825.64, ppl=3.98, accuracy=68.63, wps=13191.8, ups=1.6, wpb=8234.4, bsz=302.4, num_updates=35600, lr=7.49532e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=62, gb_free=16.9, wall=26971
2023-08-23 09:14:17 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.918, trans_loss=4.789, nll_loss=1.995, w2v_ctc_loss=0.636, task_loss=1.408, contrastive_loss=0.114, total=4141.49, n_correct=2837.58, ppl=3.99, accuracy=68.516, wps=13290.6, ups=1.6, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=62, gb_free=14.9, wall=27033
2023-08-23 09:15:19 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.934, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.652, task_loss=1.379, contrastive_loss=0.196, total=4167.4, n_correct=2854.3, ppl=3.99, accuracy=68.491, wps=13518.6, ups=1.62, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=27095
2023-08-23 09:16:20 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.917, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.638, task_loss=1.287, contrastive_loss=0.086, total=4160.61, n_correct=2847.87, ppl=4.03, accuracy=68.448, wps=13505.8, ups=1.62, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=27157
2023-08-23 09:17:22 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.919, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.641, task_loss=1.307, contrastive_loss=0.149, total=4153.68, n_correct=2849.59, ppl=3.98, accuracy=68.604, wps=13444.5, ups=1.62, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=27218
2023-08-23 09:17:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 09:17:55 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.158 | nll_loss 2.413 | w2v_ctc_loss 1.331 | task_loss 4.652 | contrastive_loss 0.287 | total 4003.4 | n_correct 2676.8 | ppl 5.32 | accuracy 66.863 | uer 17.371 | wer 19.28 | raw_wer 19.28 | bleu 22.5 | wps 1613.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.84
2023-08-23 09:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-23 09:17:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_25_36000.pt
2023-08-23 09:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_25_36000.pt
2023-08-23 09:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.5) (writing took 8.132533363997936 seconds)
2023-08-23 09:19:05 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.922, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.639, task_loss=1.336, contrastive_loss=0.147, total=4128.34, n_correct=2829.94, ppl=3.98, accuracy=68.549, wps=8006.8, ups=0.97, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=27322
2023-08-23 09:20:07 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.914, trans_loss=4.794, nll_loss=2.004, w2v_ctc_loss=0.638, task_loss=1.213, contrastive_loss=0.093, total=4182.4, n_correct=2869.55, ppl=4.01, accuracy=68.61, wps=13578.3, ups=1.62, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=27383
2023-08-23 09:21:08 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.921, trans_loss=4.794, nll_loss=2.004, w2v_ctc_loss=0.639, task_loss=1.249, contrastive_loss=0.151, total=4155.21, n_correct=2849.89, ppl=4.01, accuracy=68.586, wps=13518.8, ups=1.63, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=13.7, wall=27445
2023-08-23 09:22:10 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.935, trans_loss=4.804, nll_loss=2.016, w2v_ctc_loss=0.634, task_loss=1.312, contrastive_loss=0.261, total=4177.7, n_correct=2852.25, ppl=4.04, accuracy=68.273, wps=13543.9, ups=1.62, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=27506
2023-08-23 09:23:11 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.914, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.635, task_loss=1.424, contrastive_loss=0.069, total=4039.24, n_correct=2768.9, ppl=4.01, accuracy=68.55, wps=13201.5, ups=1.63, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=27568
2023-08-23 09:24:12 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.917, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.638, task_loss=1.334, contrastive_loss=0.077, total=4090.59, n_correct=2800.55, ppl=4.03, accuracy=68.463, wps=13446.3, ups=1.64, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=27628
2023-08-23 09:25:14 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.922, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.637, task_loss=1.284, contrastive_loss=0.172, total=4164.34, n_correct=2855.05, ppl=4, accuracy=68.559, wps=13398.5, ups=1.61, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=62, gb_free=16.5, wall=27691
2023-08-23 09:26:16 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.931, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.647, task_loss=1.372, contrastive_loss=0.121, total=4099.11, n_correct=2790.41, ppl=4.07, accuracy=68.074, wps=13198, ups=1.61, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=62, gb_free=11.8, wall=27753
2023-08-23 09:26:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 09:27:11 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.15 | nll_loss 2.405 | w2v_ctc_loss 1.329 | task_loss 4.665 | contrastive_loss 0.29 | total 4003.4 | n_correct 2674 | ppl 5.3 | accuracy 66.793 | uer 17.368 | wer 19.444 | raw_wer 19.444 | bleu 22.43 | wps 1600 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 22.84
2023-08-23 09:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-23 09:27:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4309.pt
2023-08-23 09:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4309.pt
2023-08-23 09:27:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4309.pt (epoch 25 @ 36834 updates, score 22.43) (writing took 7.146354853059165 seconds)
2023-08-23 09:27:18 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-23 09:27:18 | INFO | train | epoch 025 | loss 1.92 | trans_loss 4.794 | nll_loss 2.002 | w2v_ctc_loss 0.639 | task_loss 1.318 | contrastive_loss 0.127 | total 4138.64 | n_correct 2835.82 | ppl 4.01 | accuracy 68.52 | wps 12217.2 | ups 1.48 | wpb 8277.3 | bsz 305.6 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 900 | gb_free 13.9 | wall 27815
2023-08-23 09:27:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 09:27:18 | INFO | fairseq.trainer | begin training epoch 26
2023-08-23 09:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 09:28:06 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.906, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.626, task_loss=1.236, contrastive_loss=0.107, total=4180.21, n_correct=2876.82, ppl=3.95, accuracy=68.82, wps=7625.1, ups=0.91, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=27862
2023-08-23 09:29:07 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.919, trans_loss=4.78, nll_loss=1.986, w2v_ctc_loss=0.616, task_loss=1.156, contrastive_loss=0.288, total=4270.78, n_correct=2943.49, ppl=3.96, accuracy=68.922, wps=13857.1, ups=1.62, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=61, gb_free=14.9, wall=27924
2023-08-23 09:30:09 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.918, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.638, task_loss=1.307, contrastive_loss=0.165, total=4125.04, n_correct=2836.87, ppl=3.95, accuracy=68.772, wps=13418.5, ups=1.63, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=61, gb_free=14.8, wall=27986
2023-08-23 09:31:11 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.912, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.632, task_loss=1.263, contrastive_loss=0.124, total=4165.74, n_correct=2865.21, ppl=3.96, accuracy=68.78, wps=13485.9, ups=1.62, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=28047
2023-08-23 09:32:12 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.912, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.632, task_loss=1.257, contrastive_loss=0.168, total=4170.23, n_correct=2874.57, ppl=3.93, accuracy=68.931, wps=13607.1, ups=1.63, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=28109
2023-08-23 09:33:13 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.915, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.644, task_loss=1.329, contrastive_loss=0.091, total=4155.02, n_correct=2851.98, ppl=3.97, accuracy=68.639, wps=13551.3, ups=1.63, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=28170
2023-08-23 09:34:15 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.906, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.626, task_loss=1.345, contrastive_loss=0.076, total=4136.96, n_correct=2845.03, ppl=3.96, accuracy=68.771, wps=13508, ups=1.63, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=28231
2023-08-23 09:35:16 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.922, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.632, task_loss=1.341, contrastive_loss=0.192, total=4086.28, n_correct=2804.72, ppl=3.97, accuracy=68.637, wps=13324.4, ups=1.63, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=28293
2023-08-23 09:36:17 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.914, trans_loss=4.784, nll_loss=1.99, w2v_ctc_loss=0.64, task_loss=1.306, contrastive_loss=0.091, total=4183.26, n_correct=2874.28, ppl=3.97, accuracy=68.709, wps=13686.9, ups=1.64, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=28354
2023-08-23 09:37:19 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.915, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.624, task_loss=1.365, contrastive_loss=0.142, total=4137.96, n_correct=2837.49, ppl=3.99, accuracy=68.572, wps=13373.7, ups=1.62, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=28416
2023-08-23 09:38:21 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.91, trans_loss=4.784, nll_loss=1.99, w2v_ctc_loss=0.635, task_loss=1.383, contrastive_loss=0.074, total=4120.53, n_correct=2834.29, ppl=3.97, accuracy=68.785, wps=13373.2, ups=1.62, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=28477
2023-08-23 09:39:23 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.916, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.633, task_loss=1.38, contrastive_loss=0.115, total=4113.86, n_correct=2820.75, ppl=4, accuracy=68.567, wps=13293.8, ups=1.62, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=28539
2023-08-23 09:39:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 09:39:57 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.354 | task_loss 4.683 | contrastive_loss 0.287 | total 4003.4 | n_correct 2674.3 | ppl 5.32 | accuracy 66.801 | uer 17.623 | wer 19.552 | raw_wer 19.552 | bleu 21.73 | wps 1551.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.84
2023-08-23 09:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-23 09:39:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_26_38000.pt
2023-08-23 09:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_26_38000.pt
2023-08-23 09:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 21.73) (writing took 7.054617670015432 seconds)
2023-08-23 09:41:05 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.924, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.653, task_loss=1.474, contrastive_loss=0.077, total=3996.19, n_correct=2732.44, ppl=4.03, accuracy=68.376, wps=7797, ups=0.98, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=28642
2023-08-23 09:42:07 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.908, trans_loss=4.79, nll_loss=1.998, w2v_ctc_loss=0.626, task_loss=1.312, contrastive_loss=0.088, total=4159.74, n_correct=2858.85, ppl=3.99, accuracy=68.727, wps=13322.1, ups=1.6, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=28704
2023-08-23 09:43:09 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.906, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.626, task_loss=1.249, contrastive_loss=0.084, total=4165.66, n_correct=2865.23, ppl=3.98, accuracy=68.782, wps=13527.6, ups=1.62, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=28766
2023-08-23 09:43:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 09:43:47 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.153 | nll_loss 2.409 | w2v_ctc_loss 1.343 | task_loss 4.664 | contrastive_loss 0.287 | total 4003.4 | n_correct 2675.8 | ppl 5.31 | accuracy 66.838 | uer 17.604 | wer 19.485 | raw_wer 19.485 | bleu 22.19 | wps 1596.6 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22.84
2023-08-23 09:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-23 09:43:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1905.pt
2023-08-23 09:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1905.pt
2023-08-23 09:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1905.pt (epoch 26 @ 38308 updates, score 22.19) (writing took 6.880853686016053 seconds)
2023-08-23 09:43:54 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-23 09:43:54 | INFO | train | epoch 026 | loss 1.913 | trans_loss 4.784 | nll_loss 1.989 | w2v_ctc_loss 0.632 | task_loss 1.318 | contrastive_loss 0.126 | total 4138.65 | n_correct 2844.47 | ppl 3.97 | accuracy 68.729 | wps 12243.2 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 899 | gb_free 15.7 | wall 28811
2023-08-23 09:43:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 09:43:55 | INFO | fairseq.trainer | begin training epoch 27
2023-08-23 09:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 09:44:58 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.891, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.614, task_loss=1.424, contrastive_loss=0.064, total=4054.57, n_correct=2813.38, ppl=3.86, accuracy=69.388, wps=7450.4, ups=0.92, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=28874
2023-08-23 09:45:59 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.895, trans_loss=4.764, nll_loss=1.964, w2v_ctc_loss=0.62, task_loss=1.255, contrastive_loss=0.091, total=4195.2, n_correct=2901.79, ppl=3.9, accuracy=69.169, wps=13704.7, ups=1.63, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=28936
2023-08-23 09:47:01 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.9, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.625, task_loss=1.326, contrastive_loss=0.075, total=4162.23, n_correct=2877.91, ppl=3.92, accuracy=69.143, wps=13479.8, ups=1.62, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=28997
2023-08-23 09:48:03 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.924, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.628, task_loss=1.385, contrastive_loss=0.256, total=4079.05, n_correct=2806.58, ppl=3.95, accuracy=68.805, wps=13079.3, ups=1.6, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=29060
2023-08-23 09:49:06 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.916, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.626, task_loss=1.206, contrastive_loss=0.194, total=4243.25, n_correct=2920.14, ppl=3.97, accuracy=68.818, wps=13618.4, ups=1.6, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=62, gb_free=15.4, wall=29122
2023-08-23 09:50:06 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.908, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.63, task_loss=1.285, contrastive_loss=0.133, total=4137.92, n_correct=2854.07, ppl=3.92, accuracy=68.974, wps=13619.1, ups=1.65, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=29183
2023-08-23 09:51:08 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.909, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.629, task_loss=1.322, contrastive_loss=0.113, total=4158.48, n_correct=2861.24, ppl=3.95, accuracy=68.805, wps=13411.2, ups=1.61, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=29245
2023-08-23 09:52:10 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.908, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.635, task_loss=1.396, contrastive_loss=0.075, total=4100.88, n_correct=2823.75, ppl=3.94, accuracy=68.857, wps=13416.9, ups=1.64, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=29306
2023-08-23 09:53:11 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.901, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.621, task_loss=1.359, contrastive_loss=0.068, total=4111.94, n_correct=2838.21, ppl=3.95, accuracy=69.024, wps=13434.4, ups=1.63, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=29367
2023-08-23 09:54:13 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.92, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.627, task_loss=1.281, contrastive_loss=0.253, total=4189.27, n_correct=2883.34, ppl=3.95, accuracy=68.827, wps=13404.6, ups=1.6, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=62, gb_free=14, wall=29430
2023-08-23 09:55:15 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.9, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.62, task_loss=1.312, contrastive_loss=0.086, total=4160.42, n_correct=2869.33, ppl=3.94, accuracy=68.967, wps=13512.6, ups=1.62, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=29491
2023-08-23 09:56:17 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.91, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.637, task_loss=1.387, contrastive_loss=0.089, total=4103.72, n_correct=2821.07, ppl=3.96, accuracy=68.744, wps=13277, ups=1.62, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=29553
2023-08-23 09:57:18 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.914, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.629, task_loss=1.41, contrastive_loss=0.141, total=4065.94, n_correct=2794.02, ppl=3.96, accuracy=68.718, wps=13279.6, ups=1.63, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=29614
2023-08-23 09:58:19 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.905, trans_loss=4.778, nll_loss=1.983, w2v_ctc_loss=0.62, task_loss=1.247, contrastive_loss=0.123, total=4149.21, n_correct=2858.93, ppl=3.95, accuracy=68.903, wps=13604.9, ups=1.64, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=29675
2023-08-23 09:59:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 09:59:42 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.331 | task_loss 4.662 | contrastive_loss 0.281 | total 4003.4 | n_correct 2676.3 | ppl 5.31 | accuracy 66.851 | uer 17.317 | wer 19.406 | raw_wer 19.406 | bleu 22.18 | wps 1642.6 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 22.84
2023-08-23 09:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-23 09:59:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1806.pt
2023-08-23 09:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1806.pt
2023-08-23 09:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.1806.pt (epoch 27 @ 39782 updates, score 22.18) (writing took 6.962854278972372 seconds)
2023-08-23 09:59:50 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-23 09:59:50 | INFO | train | epoch 027 | loss 1.907 | trans_loss 4.774 | nll_loss 1.977 | w2v_ctc_loss 0.625 | task_loss 1.319 | contrastive_loss 0.124 | total 4138.65 | n_correct 2853.4 | ppl 3.94 | accuracy 68.945 | wps 12773.1 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.529 | clip 0 | loss_scale 64 | train_wall 899 | gb_free 17.5 | wall 29766
2023-08-23 09:59:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 09:59:50 | INFO | fairseq.trainer | begin training epoch 28
2023-08-23 09:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 10:00:08 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.897, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.62, task_loss=1.277, contrastive_loss=0.076, total=4106.72, n_correct=2836.5, ppl=3.93, accuracy=69.07, wps=7496.2, ups=0.91, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=29785
2023-08-23 10:01:10 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.891, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.619, task_loss=1.391, contrastive_loss=0.071, total=4103.42, n_correct=2851.84, ppl=3.85, accuracy=69.499, wps=13373.1, ups=1.63, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=29846
2023-08-23 10:02:11 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.888, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.612, task_loss=1.236, contrastive_loss=0.079, total=4200.12, n_correct=2912.86, ppl=3.88, accuracy=69.352, wps=13702.7, ups=1.63, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=10.6, wall=29908
2023-08-23 10:02:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 10:02:45 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.155 | nll_loss 2.411 | w2v_ctc_loss 1.366 | task_loss 4.665 | contrastive_loss 0.285 | total 4003.4 | n_correct 2676.8 | ppl 5.32 | accuracy 66.863 | uer 17.583 | wer 19.462 | raw_wer 19.462 | bleu 22.37 | wps 1569 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.84
2023-08-23 10:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-23 10:02:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_28_40000.pt
2023-08-23 10:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_28_40000.pt
2023-08-23 10:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.37) (writing took 7.080187103012577 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 10:03:54 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.929, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.613, task_loss=1.315, contrastive_loss=0.408, total=4147.36, n_correct=2855.37, ppl=3.93, accuracy=68.848, wps=8045.9, ups=0.97, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=30011
2023-08-23 10:04:55 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.897, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.627, task_loss=1.361, contrastive_loss=0.066, total=4087.34, n_correct=2831.45, ppl=3.88, accuracy=69.274, wps=13415.9, ups=1.64, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=30072
2023-08-23 10:05:57 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.896, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.617, task_loss=1.37, contrastive_loss=0.079, total=4099.71, n_correct=2833.77, ppl=3.9, accuracy=69.121, wps=13321.2, ups=1.62, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=14.9, wall=30133
2023-08-23 10:06:58 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.901, trans_loss=4.773, nll_loss=1.974, w2v_ctc_loss=0.624, task_loss=1.337, contrastive_loss=0.079, total=4177.06, n_correct=2881.37, ppl=3.93, accuracy=68.981, wps=13584.5, ups=1.63, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=30195
2023-08-23 10:08:00 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.906, trans_loss=4.773, nll_loss=1.977, w2v_ctc_loss=0.616, task_loss=1.188, contrastive_loss=0.186, total=4190.74, n_correct=2895.87, ppl=3.94, accuracy=69.102, wps=13631.2, ups=1.63, wpb=8381.5, bsz=328.5, num_updates=40500, lr=7.02728e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=30256
2023-08-23 10:09:01 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.893, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.618, task_loss=1.306, contrastive_loss=0.071, total=4091.75, n_correct=2830.86, ppl=3.91, accuracy=69.185, wps=13445.9, ups=1.64, wpb=8183.5, bsz=306, num_updates=40600, lr=7.01862e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=30317
2023-08-23 10:10:03 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.909, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.627, task_loss=1.361, contrastive_loss=0.133, total=4123.89, n_correct=2842.7, ppl=3.92, accuracy=68.932, wps=13274.5, ups=1.61, wpb=8247.8, bsz=301, num_updates=40700, lr=7.01e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=62, gb_free=16.8, wall=30379
2023-08-23 10:11:04 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.912, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.626, task_loss=1.285, contrastive_loss=0.183, total=4176.06, n_correct=2879.9, ppl=3.92, accuracy=68.962, wps=13555.3, ups=1.62, wpb=8352.1, bsz=311.4, num_updates=40800, lr=7.0014e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=61, gb_free=16.6, wall=30441
2023-08-23 10:12:06 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.896, trans_loss=4.765, nll_loss=1.966, w2v_ctc_loss=0.619, task_loss=1.284, contrastive_loss=0.09, total=4206.08, n_correct=2904.9, ppl=3.91, accuracy=69.064, wps=13585.3, ups=1.61, wpb=8412.2, bsz=317.3, num_updates=40900, lr=6.99284e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=30503
2023-08-23 10:13:07 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.895, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.616, task_loss=1.302, contrastive_loss=0.077, total=4109.72, n_correct=2839.49, ppl=3.92, accuracy=69.092, wps=13446, ups=1.64, wpb=8219.4, bsz=306.9, num_updates=41000, lr=6.9843e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=30564
2023-08-23 10:14:09 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.905, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.63, task_loss=1.441, contrastive_loss=0.091, total=4085.44, n_correct=2817.22, ppl=3.92, accuracy=68.958, wps=13304.1, ups=1.63, wpb=8170.9, bsz=285.6, num_updates=41100, lr=6.9758e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=30625
2023-08-23 10:15:11 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.902, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.619, task_loss=1.401, contrastive_loss=0.114, total=4137.47, n_correct=2856.75, ppl=3.91, accuracy=69.046, wps=13380.3, ups=1.62, wpb=8274.9, bsz=294.8, num_updates=41200, lr=6.96733e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=30687
2023-08-23 10:15:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
2023-08-23 10:16:19 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.16 | nll_loss 2.416 | w2v_ctc_loss 1.338 | task_loss 4.65 | contrastive_loss 0.287 | total 4003.4 | n_correct 2677.1 | ppl 5.34 | accuracy 66.871 | uer 17.349 | wer 19.213 | raw_wer 19.213 | bleu 22.48 | wps 1582.3 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 22.84
2023-08-23 10:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-08-23 10:16:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4805.pt
2023-08-23 10:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4805.pt
2023-08-23 10:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4805.pt (epoch 28 @ 41256 updates, score 22.48) (writing took 7.786229080986232 seconds)
2023-08-23 10:16:27 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-23 10:16:27 | INFO | train | epoch 028 | loss 1.901 | trans_loss 4.766 | nll_loss 1.966 | w2v_ctc_loss 0.62 | task_loss 1.32 | contrastive_loss 0.123 | total 4138.65 | n_correct 2860.17 | ppl 3.91 | accuracy 69.109 | wps 12234 | ups 1.48 | wpb 8277.3 | bsz 305.7 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 16.2 | wall 30764
2023-08-23 10:16:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 10:16:27 | INFO | fairseq.trainer | begin training epoch 29
2023-08-23 10:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 10:17:01 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.894, trans_loss=4.758, nll_loss=1.958, w2v_ctc_loss=0.623, task_loss=1.267, contrastive_loss=0.083, total=4168.25, n_correct=2889.15, ppl=3.88, accuracy=69.313, wps=7537.3, ups=0.9, wpb=8336.5, bsz=315.7, num_updates=41300, lr=6.95889e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=30798
2023-08-23 10:18:03 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.897, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.62, task_loss=1.294, contrastive_loss=0.113, total=4117.66, n_correct=2857.28, ppl=3.88, accuracy=69.391, wps=13380.7, ups=1.62, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=30859
2023-08-23 10:19:05 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.893, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.603, task_loss=1.201, contrastive_loss=0.188, total=4198.99, n_correct=2918.22, ppl=3.85, accuracy=69.498, wps=13599.2, ups=1.62, wpb=8398, bsz=330.7, num_updates=41500, lr=6.9421e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=61, gb_free=14.9, wall=30921
2023-08-23 10:20:06 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.9, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.628, task_loss=1.416, contrastive_loss=0.073, total=4091.28, n_correct=2828.82, ppl=3.9, accuracy=69.143, wps=13281.4, ups=1.62, wpb=8182.6, bsz=290.4, num_updates=41600, lr=6.93375e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=30983
2023-08-23 10:21:08 | INFO | train_inner | epoch 029:    444 / 1474 loss=1.879, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.608, task_loss=1.276, contrastive_loss=0.067, total=4158.09, n_correct=2898.5, ppl=3.81, accuracy=69.707, wps=13545.8, ups=1.63, wpb=8316.2, bsz=307.2, num_updates=41700, lr=6.92543e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=61, gb_free=15.7, wall=31044
2023-08-23 10:22:10 | INFO | train_inner | epoch 029:    544 / 1474 loss=1.905, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.615, task_loss=1.4, contrastive_loss=0.162, total=4156.12, n_correct=2872.02, ppl=3.9, accuracy=69.103, wps=13313.3, ups=1.6, wpb=8312.2, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.53, clip=0, loss_scale=128, train_wall=62, gb_free=11.9, wall=31107
2023-08-23 10:23:12 | INFO | train_inner | epoch 029:    644 / 1474 loss=1.901, trans_loss=4.757, nll_loss=1.955, w2v_ctc_loss=0.611, task_loss=1.236, contrastive_loss=0.229, total=4153.45, n_correct=2878.81, ppl=3.88, accuracy=69.311, wps=13409.8, ups=1.61, wpb=8306.9, bsz=320.5, num_updates=41900, lr=6.90889e-05, gnorm=0.527, clip=0, loss_scale=128, train_wall=61, gb_free=16.2, wall=31169
2023-08-23 10:24:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 10:24:14 | INFO | train_inner | epoch 029:    745 / 1474 loss=1.884, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.608, task_loss=1.244, contrastive_loss=0.088, total=4215.86, n_correct=2930.57, ppl=3.85, accuracy=69.513, wps=13565.1, ups=1.61, wpb=8431.7, bsz=321.7, num_updates=42000, lr=6.90066e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=62, gb_free=16.4, wall=31231
2023-08-23 10:24:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 10:24:47 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.159 | nll_loss 2.415 | w2v_ctc_loss 1.34 | task_loss 4.65 | contrastive_loss 0.282 | total 4003.4 | n_correct 2676.1 | ppl 5.33 | accuracy 66.846 | uer 17.331 | wer 19.172 | raw_wer 19.172 | bleu 22.06 | wps 1661.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.84
2023-08-23 10:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-23 10:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_29_42000.pt
2023-08-23 10:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_29_42000.pt
2023-08-23 10:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.06) (writing took 6.859069583006203 seconds)
2023-08-23 10:25:55 | INFO | train_inner | epoch 029:    845 / 1474 loss=1.896, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.616, task_loss=1.458, contrastive_loss=0.067, total=4033.21, n_correct=2786.63, ppl=3.92, accuracy=69.092, wps=8007.6, ups=0.99, wpb=8066.4, bsz=281.6, num_updates=42100, lr=6.89246e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=31331
2023-08-23 10:26:56 | INFO | train_inner | epoch 029:    945 / 1474 loss=1.894, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.617, task_loss=1.347, contrastive_loss=0.076, total=4085.97, n_correct=2827.74, ppl=3.9, accuracy=69.206, wps=13391.9, ups=1.64, wpb=8171.9, bsz=296.8, num_updates=42200, lr=6.88428e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=31392
2023-08-23 10:27:57 | INFO | train_inner | epoch 029:   1045 / 1474 loss=1.896, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.613, task_loss=1.32, contrastive_loss=0.148, total=4140.84, n_correct=2871.64, ppl=3.87, accuracy=69.349, wps=13520, ups=1.63, wpb=8281.7, bsz=306.7, num_updates=42300, lr=6.87614e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=31454
2023-08-23 10:28:59 | INFO | train_inner | epoch 029:   1145 / 1474 loss=1.898, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.625, task_loss=1.438, contrastive_loss=0.065, total=4068.4, n_correct=2809.63, ppl=3.91, accuracy=69.06, wps=13248, ups=1.63, wpb=8136.8, bsz=284.2, num_updates=42400, lr=6.86803e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=31515
2023-08-23 10:30:00 | INFO | train_inner | epoch 029:   1245 / 1474 loss=1.895, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.618, task_loss=1.35, contrastive_loss=0.07, total=4154.79, n_correct=2873.04, ppl=3.91, accuracy=69.15, wps=13595.3, ups=1.64, wpb=8309.6, bsz=299.6, num_updates=42500, lr=6.85994e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=31576
2023-08-23 10:31:01 | INFO | train_inner | epoch 029:   1345 / 1474 loss=1.891, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.606, task_loss=1.292, contrastive_loss=0.133, total=4166.4, n_correct=2891.33, ppl=3.86, accuracy=69.396, wps=13536.5, ups=1.62, wpb=8332.8, bsz=311.5, num_updates=42600, lr=6.85189e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=31638
2023-08-23 10:32:02 | INFO | train_inner | epoch 029:   1445 / 1474 loss=1.903, trans_loss=4.761, nll_loss=1.96, w2v_ctc_loss=0.623, task_loss=1.291, contrastive_loss=0.163, total=4169.4, n_correct=2884.53, ppl=3.89, accuracy=69.183, wps=13670, ups=1.64, wpb=8338.8, bsz=312, num_updates=42700, lr=6.84386e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=31699
2023-08-23 10:32:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 10:32:53 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.153 | nll_loss 2.406 | w2v_ctc_loss 1.365 | task_loss 4.658 | contrastive_loss 0.289 | total 4003.4 | n_correct 2677.2 | ppl 5.3 | accuracy 66.873 | uer 17.163 | wer 19.097 | raw_wer 19.097 | bleu 22.25 | wps 1601.6 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 22.84
2023-08-23 10:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-08-23 10:32:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2501.pt
2023-08-23 10:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2501.pt
2023-08-23 10:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.2501.pt (epoch 29 @ 42729 updates, score 22.25) (writing took 7.209283227100968 seconds)
2023-08-23 10:33:01 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-23 10:33:01 | INFO | train | epoch 029 | loss 1.895 | trans_loss 4.757 | nll_loss 1.955 | w2v_ctc_loss 0.615 | task_loss 1.32 | contrastive_loss 0.117 | total 4137.56 | n_correct 2867.51 | ppl 3.88 | accuracy 69.304 | wps 12258.7 | ups 1.48 | wpb 8275.1 | bsz 305.3 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.529 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 15.8 | wall 31758
2023-08-23 10:33:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 10:33:02 | INFO | fairseq.trainer | begin training epoch 30
2023-08-23 10:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 10:33:53 | INFO | train_inner | epoch 030:     71 / 1474 loss=1.889, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.599, task_loss=1.251, contrastive_loss=0.178, total=4176.73, n_correct=2904, ppl=3.83, accuracy=69.528, wps=7550.8, ups=0.9, wpb=8353.5, bsz=319, num_updates=42800, lr=6.83586e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=31809
2023-08-23 10:34:54 | INFO | train_inner | epoch 030:    171 / 1474 loss=1.882, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.607, task_loss=1.227, contrastive_loss=0.111, total=4202.84, n_correct=2934.18, ppl=3.79, accuracy=69.814, wps=13731, ups=1.63, wpb=8405.7, bsz=318.6, num_updates=42900, lr=6.82789e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=12.3, wall=31871
2023-08-23 10:35:55 | INFO | train_inner | epoch 030:    271 / 1474 loss=1.889, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.618, task_loss=1.356, contrastive_loss=0.067, total=4120.08, n_correct=2865.57, ppl=3.85, accuracy=69.551, wps=13425.3, ups=1.63, wpb=8240.2, bsz=296.4, num_updates=43000, lr=6.81994e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=31932
2023-08-23 10:36:58 | INFO | train_inner | epoch 030:    371 / 1474 loss=1.879, trans_loss=4.739, nll_loss=1.932, w2v_ctc_loss=0.604, task_loss=1.317, contrastive_loss=0.069, total=4175.82, n_correct=2912.68, ppl=3.81, accuracy=69.751, wps=13469.4, ups=1.61, wpb=8351.6, bsz=306.1, num_updates=43100, lr=6.81203e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=61, gb_free=15.4, wall=31994
2023-08-23 10:37:58 | INFO | train_inner | epoch 030:    471 / 1474 loss=1.883, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.6, task_loss=1.264, contrastive_loss=0.131, total=4128.9, n_correct=2875.82, ppl=3.82, accuracy=69.651, wps=13547.1, ups=1.64, wpb=8257.8, bsz=312.5, num_updates=43200, lr=6.80414e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=32055
2023-08-23 10:39:00 | INFO | train_inner | epoch 030:    571 / 1474 loss=1.888, trans_loss=4.752, nll_loss=1.949, w2v_ctc_loss=0.612, task_loss=1.285, contrastive_loss=0.093, total=4162.83, n_correct=2892.6, ppl=3.86, accuracy=69.486, wps=13486.2, ups=1.62, wpb=8325.7, bsz=311.5, num_updates=43300, lr=6.79628e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=61, gb_free=14.8, wall=32117
2023-08-23 10:40:02 | INFO | train_inner | epoch 030:    671 / 1474 loss=1.892, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.619, task_loss=1.285, contrastive_loss=0.107, total=4197.56, n_correct=2911.47, ppl=3.84, accuracy=69.361, wps=13614.2, ups=1.62, wpb=8395.1, bsz=317.6, num_updates=43400, lr=6.78844e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=32178
2023-08-23 10:41:04 | INFO | train_inner | epoch 030:    771 / 1474 loss=1.906, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.621, task_loss=1.356, contrastive_loss=0.188, total=4097.27, n_correct=2834.51, ppl=3.88, accuracy=69.18, wps=13185.8, ups=1.61, wpb=8194.5, bsz=301.1, num_updates=43500, lr=6.78064e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=62, gb_free=14.6, wall=32241
2023-08-23 10:42:05 | INFO | train_inner | epoch 030:    871 / 1474 loss=1.892, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.617, task_loss=1.377, contrastive_loss=0.071, total=4097.18, n_correct=2841.84, ppl=3.87, accuracy=69.361, wps=13404.7, ups=1.64, wpb=8194.4, bsz=292.2, num_updates=43600, lr=6.77285e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=32302
2023-08-23 10:43:06 | INFO | train_inner | epoch 030:    971 / 1474 loss=1.894, trans_loss=4.757, nll_loss=1.954, w2v_ctc_loss=0.618, task_loss=1.326, contrastive_loss=0.089, total=4140.12, n_correct=2868.04, ppl=3.87, accuracy=69.274, wps=13530.8, ups=1.63, wpb=8280.2, bsz=304.6, num_updates=43700, lr=6.7651e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=32363
2023-08-23 10:43:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 10:44:09 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.897, trans_loss=4.762, nll_loss=1.959, w2v_ctc_loss=0.621, task_loss=1.516, contrastive_loss=0.059, total=4084.1, n_correct=2824.86, ppl=3.89, accuracy=69.167, wps=12957.6, ups=1.59, wpb=8168.2, bsz=275.5, num_updates=43800, lr=6.75737e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=32426
2023-08-23 10:45:11 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.885, trans_loss=4.747, nll_loss=1.943, w2v_ctc_loss=0.598, task_loss=1.261, contrastive_loss=0.138, total=4168.22, n_correct=2902.89, ppl=3.85, accuracy=69.643, wps=13521.1, ups=1.62, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=32488
2023-08-23 10:46:13 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.896, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.622, task_loss=1.473, contrastive_loss=0.073, total=4032.74, n_correct=2790.75, ppl=3.88, accuracy=69.202, wps=13015.3, ups=1.61, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=32550
2023-08-23 10:46:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 10:46:46 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.155 | nll_loss 2.408 | w2v_ctc_loss 1.33 | task_loss 4.654 | contrastive_loss 0.29 | total 4003.4 | n_correct 2682.3 | ppl 5.31 | accuracy 67.001 | uer 17.227 | wer 19.093 | raw_wer 19.093 | bleu 22.56 | wps 1627.4 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.84
2023-08-23 10:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-23 10:46:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_30_44000.pt
2023-08-23 10:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_30_44000.pt
2023-08-23 10:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.56) (writing took 9.09629597608 seconds)
2023-08-23 10:47:57 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.885, trans_loss=4.753, nll_loss=1.951, w2v_ctc_loss=0.609, task_loss=1.24, contrastive_loss=0.083, total=4166.96, n_correct=2891.96, ppl=3.87, accuracy=69.402, wps=8030.2, ups=0.96, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=15, wall=32653
2023-08-23 10:48:58 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.894, trans_loss=4.751, nll_loss=1.948, w2v_ctc_loss=0.599, task_loss=1.26, contrastive_loss=0.227, total=4125.17, n_correct=2865.17, ppl=3.86, accuracy=69.456, wps=13517.7, ups=1.64, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=32714
2023-08-23 10:48:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 10:49:32 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.942 | trans_loss 5.154 | nll_loss 2.408 | w2v_ctc_loss 1.306 | task_loss 4.664 | contrastive_loss 0.285 | total 4003.4 | n_correct 2682.5 | ppl 5.31 | accuracy 67.006 | uer 17.262 | wer 19.28 | raw_wer 19.28 | bleu 22.49 | wps 1617.2 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 22.84
2023-08-23 10:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-08-23 10:49:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4908.pt
2023-08-23 10:49:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4908.pt
2023-08-23 10:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.4908.pt (epoch 30 @ 44202 updates, score 22.49) (writing took 7.552278996095993 seconds)
2023-08-23 10:49:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-23 10:49:40 | INFO | train | epoch 030 | loss 1.89 | trans_loss 4.75 | nll_loss 1.946 | w2v_ctc_loss 0.611 | task_loss 1.318 | contrastive_loss 0.114 | total 4137.79 | n_correct 2873.9 | ppl 3.85 | accuracy 69.455 | wps 12207.1 | ups 1.48 | wpb 8275.6 | bsz 305.2 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 899 | gb_free 16.8 | wall 32756
2023-08-23 10:49:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 10:49:40 | INFO | fairseq.trainer | begin training epoch 31
2023-08-23 10:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 10:50:48 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.88, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.606, task_loss=1.367, contrastive_loss=0.07, total=4081.34, n_correct=2846.28, ppl=3.81, accuracy=69.739, wps=7407.5, ups=0.91, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=32825
2023-08-23 10:51:50 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.882, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.605, task_loss=1.35, contrastive_loss=0.095, total=4146.03, n_correct=2889.49, ppl=3.81, accuracy=69.693, wps=13479.2, ups=1.63, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=12.9, wall=32886
2023-08-23 10:52:52 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.884, trans_loss=4.734, nll_loss=1.923, w2v_ctc_loss=0.605, task_loss=1.355, contrastive_loss=0.132, total=4146.75, n_correct=2892.1, ppl=3.79, accuracy=69.744, wps=13347.5, ups=1.61, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=62, gb_free=17.3, wall=32948
2023-08-23 10:53:53 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.885, trans_loss=4.747, nll_loss=1.941, w2v_ctc_loss=0.605, task_loss=1.441, contrastive_loss=0.071, total=4089.43, n_correct=2842.41, ppl=3.84, accuracy=69.506, wps=13360.6, ups=1.63, wpb=8178.9, bsz=285.5, num_updates=44600, lr=6.6965e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=33009
2023-08-23 10:54:54 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.884, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.613, task_loss=1.372, contrastive_loss=0.079, total=4114.41, n_correct=2864.31, ppl=3.82, accuracy=69.617, wps=13379.4, ups=1.63, wpb=8228.8, bsz=300.9, num_updates=44700, lr=6.689e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=33071
2023-08-23 10:55:56 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.878, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.601, task_loss=1.375, contrastive_loss=0.069, total=4084.36, n_correct=2846.7, ppl=3.81, accuracy=69.698, wps=13314.6, ups=1.63, wpb=8168.7, bsz=295, num_updates=44800, lr=6.68153e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=33132
2023-08-23 10:56:57 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.874, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.599, task_loss=1.256, contrastive_loss=0.07, total=4210.09, n_correct=2937.41, ppl=3.8, accuracy=69.771, wps=13778.6, ups=1.64, wpb=8420.2, bsz=314.9, num_updates=44900, lr=6.67409e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=61, gb_free=14.3, wall=33193
2023-08-23 10:57:59 | INFO | train_inner | epoch 031:    798 / 1474 loss=1.892, trans_loss=4.748, nll_loss=1.942, w2v_ctc_loss=0.607, task_loss=1.382, contrastive_loss=0.141, total=4098.1, n_correct=2844.41, ppl=3.84, accuracy=69.408, wps=13187.7, ups=1.61, wpb=8196.2, bsz=295.7, num_updates=45000, lr=6.66667e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=62, gb_free=16.6, wall=33256
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:0')
2023-08-23 10:59:00 | INFO | train_inner | epoch 031:    898 / 1474 loss=1.881, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.607, task_loss=1.367, contrastive_loss=0.086, total=4101.05, n_correct=2858.43, ppl=3.8, accuracy=69.7, wps=13397.6, ups=1.63, wpb=8202.1, bsz=296.9, num_updates=45100, lr=6.65927e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=33317
2023-08-23 11:00:02 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.892, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.605, task_loss=1.248, contrastive_loss=0.169, total=4186.3, n_correct=2910.7, ppl=3.86, accuracy=69.529, wps=13651.4, ups=1.63, wpb=8372.6, bsz=318.6, num_updates=45200, lr=6.6519e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=33378
2023-08-23 11:01:03 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.885, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.603, task_loss=1.294, contrastive_loss=0.115, total=4147.34, n_correct=2888.11, ppl=3.83, accuracy=69.638, wps=13563.9, ups=1.64, wpb=8294.7, bsz=314.6, num_updates=45300, lr=6.64455e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33439
2023-08-23 11:02:04 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.891, trans_loss=4.745, nll_loss=1.939, w2v_ctc_loss=0.598, task_loss=1.229, contrastive_loss=0.232, total=4185.34, n_correct=2914.76, ppl=3.83, accuracy=69.642, wps=13704.6, ups=1.64, wpb=8370.7, bsz=321.6, num_updates=45400, lr=6.63723e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=33500
2023-08-23 11:03:05 | INFO | train_inner | epoch 031:   1298 / 1474 loss=1.883, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.608, task_loss=1.192, contrastive_loss=0.076, total=4223.54, n_correct=2936.56, ppl=3.86, accuracy=69.528, wps=13771.5, ups=1.63, wpb=8447.1, bsz=325, num_updates=45500, lr=6.62994e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=13.2, wall=33562
2023-08-23 11:04:07 | INFO | train_inner | epoch 031:   1398 / 1474 loss=1.904, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.605, task_loss=1.2, contrastive_loss=0.278, total=4195.76, n_correct=2915.85, ppl=3.85, accuracy=69.495, wps=13490.3, ups=1.61, wpb=8391.5, bsz=328.2, num_updates=45600, lr=6.62266e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=62, gb_free=16.3, wall=33624
2023-08-23 11:04:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2463, device='cuda:1')
2023-08-23 11:05:27 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.152 | nll_loss 2.404 | w2v_ctc_loss 1.339 | task_loss 4.64 | contrastive_loss 0.279 | total 4003.4 | n_correct 2682 | ppl 5.29 | accuracy 66.993 | uer 17.15 | wer 18.993 | raw_wer 18.993 | bleu 22.6 | wps 1636.6 | wpb 4003.4 | bsz 141.8 | num_updates 45676 | best_bleu 22.84
2023-08-23 11:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45676 updates
2023-08-23 11:05:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6001.pt
2023-08-23 11:05:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6001.pt
2023-08-23 11:05:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6001.pt (epoch 31 @ 45676 updates, score 22.6) (writing took 7.147062359028496 seconds)
2023-08-23 11:05:34 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-23 11:05:34 | INFO | train | epoch 031 | loss 1.885 | trans_loss 4.743 | nll_loss 1.936 | w2v_ctc_loss 0.605 | task_loss 1.318 | contrastive_loss 0.119 | total 4138.65 | n_correct 2881.33 | ppl 3.83 | accuracy 69.62 | wps 12784.1 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 45676 | lr 6.61715e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 897 | gb_free 11.7 | wall 33711
2023-08-23 11:05:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 11:05:35 | INFO | fairseq.trainer | begin training epoch 32
2023-08-23 11:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 11:05:56 | INFO | train_inner | epoch 032:     24 / 1474 loss=1.883, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.613, task_loss=1.403, contrastive_loss=0.064, total=4039.04, n_correct=2815.66, ppl=3.81, accuracy=69.711, wps=7420.3, ups=0.92, wpb=8078.1, bsz=287.3, num_updates=45700, lr=6.61541e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=33733
2023-08-23 11:06:58 | INFO | train_inner | epoch 032:    124 / 1474 loss=1.863, trans_loss=4.718, nll_loss=1.905, w2v_ctc_loss=0.587, task_loss=1.222, contrastive_loss=0.076, total=4224.84, n_correct=2963.13, ppl=3.74, accuracy=70.136, wps=13757.5, ups=1.63, wpb=8449.7, bsz=322.5, num_updates=45800, lr=6.60819e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=33794
2023-08-23 11:08:00 | INFO | train_inner | epoch 032:    224 / 1474 loss=1.874, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.598, task_loss=1.247, contrastive_loss=0.084, total=4163.01, n_correct=2906.66, ppl=3.8, accuracy=69.821, wps=13471, ups=1.62, wpb=8326, bsz=322.2, num_updates=45900, lr=6.60098e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=33856
2023-08-23 11:08:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 11:09:01 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.868, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.592, task_loss=1.243, contrastive_loss=0.081, total=4181.19, n_correct=2932.93, ppl=3.76, accuracy=70.146, wps=13517.6, ups=1.62, wpb=8362.4, bsz=314.6, num_updates=46000, lr=6.5938e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=33918
2023-08-23 11:09:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 11:09:34 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.162 | nll_loss 2.415 | w2v_ctc_loss 1.342 | task_loss 4.651 | contrastive_loss 0.285 | total 4003.4 | n_correct 2680.9 | ppl 5.33 | accuracy 66.966 | uer 17.381 | wer 19.395 | raw_wer 19.395 | bleu 22.41 | wps 1632.5 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.84
2023-08-23 11:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-23 11:09:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_32_46000.pt
2023-08-23 11:09:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_32_46000.pt
2023-08-23 11:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.41) (writing took 8.269404588965699 seconds)
2023-08-23 11:10:45 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.874, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.602, task_loss=1.313, contrastive_loss=0.074, total=4157.28, n_correct=2908.1, ppl=3.78, accuracy=69.952, wps=8061.7, ups=0.97, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=14.6, wall=34021
2023-08-23 11:11:47 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.887, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.604, task_loss=1.277, contrastive_loss=0.16, total=4198.93, n_correct=2927.36, ppl=3.81, accuracy=69.717, wps=13475.4, ups=1.6, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=62, gb_free=17, wall=34083
2023-08-23 11:12:49 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.877, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.601, task_loss=1.359, contrastive_loss=0.083, total=4142.69, n_correct=2889.72, ppl=3.8, accuracy=69.755, wps=13377.8, ups=1.61, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=34145
2023-08-23 11:13:51 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.88, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.61, task_loss=1.344, contrastive_loss=0.067, total=4154.59, n_correct=2899.86, ppl=3.81, accuracy=69.799, wps=13433.5, ups=1.62, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=34207
2023-08-23 11:14:52 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.873, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.596, task_loss=1.354, contrastive_loss=0.065, total=4114.54, n_correct=2872.81, ppl=3.79, accuracy=69.821, wps=13503.9, ups=1.64, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=34268
2023-08-23 11:15:53 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.874, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.595, task_loss=1.366, contrastive_loss=0.063, total=4139.67, n_correct=2889.94, ppl=3.8, accuracy=69.811, wps=13378.7, ups=1.62, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=34330
2023-08-23 11:16:55 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.886, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.603, task_loss=1.306, contrastive_loss=0.158, total=4119.15, n_correct=2871.99, ppl=3.82, accuracy=69.723, wps=13393.8, ups=1.63, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=34392
2023-08-23 11:17:57 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.884, trans_loss=4.736, nll_loss=1.926, w2v_ctc_loss=0.602, task_loss=1.558, contrastive_loss=0.1, total=4019.61, n_correct=2799.52, ppl=3.8, accuracy=69.647, wps=13038.1, ups=1.62, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=34453
2023-08-23 11:18:59 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.899, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.606, task_loss=1.303, contrastive_loss=0.208, total=4149.28, n_correct=2880.4, ppl=3.85, accuracy=69.419, wps=13387.5, ups=1.61, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=34515
2023-08-23 11:20:01 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.877, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.603, task_loss=1.35, contrastive_loss=0.064, total=4079.22, n_correct=2842.2, ppl=3.8, accuracy=69.675, wps=13027.2, ups=1.6, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=62, gb_free=14.7, wall=34578
2023-08-23 11:21:07 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.905, trans_loss=4.742, nll_loss=1.936, w2v_ctc_loss=0.615, task_loss=1.325, contrastive_loss=0.295, total=4111.41, n_correct=2861.64, ppl=3.83, accuracy=69.602, wps=12522.7, ups=1.52, wpb=8222.8, bsz=306.1, num_updates=47100, lr=6.51635e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=65, gb_free=15.7, wall=34644
2023-08-23 11:21:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 11:22:13 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.159 | nll_loss 2.414 | w2v_ctc_loss 1.372 | task_loss 4.676 | contrastive_loss 0.284 | total 4003.4 | n_correct 2682.3 | ppl 5.33 | accuracy 67.001 | uer 17.145 | wer 19.034 | raw_wer 19.034 | bleu 22.62 | wps 1438.7 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 22.84
2023-08-23 11:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-08-23 11:22:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6203.pt
2023-08-23 11:22:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6203.pt
2023-08-23 11:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6203.pt (epoch 32 @ 47149 updates, score 22.62) (writing took 10.570428697974421 seconds)
2023-08-23 11:22:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-23 11:22:23 | INFO | train | epoch 032 | loss 1.88 | trans_loss 4.735 | nll_loss 1.926 | w2v_ctc_loss 0.601 | task_loss 1.318 | contrastive_loss 0.118 | total 4138.66 | n_correct 2888.35 | ppl 3.8 | accuracy 69.789 | wps 12081.9 | ups 1.46 | wpb 8277.3 | bsz 305.7 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 904 | gb_free 16.1 | wall 34720
2023-08-23 11:22:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 11:22:24 | INFO | fairseq.trainer | begin training epoch 33
2023-08-23 11:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 11:23:05 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.881, trans_loss=4.735, nll_loss=1.927, w2v_ctc_loss=0.592, task_loss=1.229, contrastive_loss=0.168, total=4156.71, n_correct=2901.38, ppl=3.8, accuracy=69.8, wps=7036.6, ups=0.85, wpb=8313.4, bsz=322.5, num_updates=47200, lr=6.50945e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=34762
2023-08-23 11:24:13 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.862, trans_loss=4.716, nll_loss=1.901, w2v_ctc_loss=0.583, task_loss=1.421, contrastive_loss=0.056, total=4071.44, n_correct=2858.44, ppl=3.73, accuracy=70.207, wps=11981.7, ups=1.47, wpb=8142.9, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=34830
2023-08-23 11:25:22 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.883, trans_loss=4.721, nll_loss=1.909, w2v_ctc_loss=0.592, task_loss=1.123, contrastive_loss=0.23, total=4281.28, n_correct=3001.75, ppl=3.75, accuracy=70.113, wps=12502.2, ups=1.46, wpb=8562.6, bsz=346.3, num_updates=47400, lr=6.4957e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=34898
2023-08-23 11:26:24 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.875, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.599, task_loss=1.359, contrastive_loss=0.082, total=4111.69, n_correct=2877.2, ppl=3.77, accuracy=69.976, wps=13259.9, ups=1.61, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=34960
2023-08-23 11:27:26 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.857, trans_loss=4.715, nll_loss=1.899, w2v_ctc_loss=0.584, task_loss=1.238, contrastive_loss=0.064, total=4147.28, n_correct=2914.9, ppl=3.73, accuracy=70.285, wps=13406.5, ups=1.62, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=35022
2023-08-23 11:28:32 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.879, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.605, task_loss=1.382, contrastive_loss=0.085, total=4127.68, n_correct=2880.83, ppl=3.78, accuracy=69.793, wps=12349.5, ups=1.5, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=66, gb_free=15.2, wall=35089
2023-08-23 11:29:39 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.881, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.595, task_loss=1.348, contrastive_loss=0.119, total=4164.1, n_correct=2904.26, ppl=3.81, accuracy=69.745, wps=12522.6, ups=1.5, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=66, gb_free=15.1, wall=35155
2023-08-23 11:30:44 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.883, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.614, task_loss=1.441, contrastive_loss=0.066, total=4064.29, n_correct=2834.01, ppl=3.8, accuracy=69.73, wps=12480.2, ups=1.54, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=65, gb_free=16.3, wall=35221
2023-08-23 11:31:45 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.865, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.582, task_loss=1.242, contrastive_loss=0.131, total=4141.12, n_correct=2907.61, ppl=3.76, accuracy=70.213, wps=13530.3, ups=1.63, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=35282
2023-08-23 11:31:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 11:32:18 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.967 | trans_loss 5.158 | nll_loss 2.41 | w2v_ctc_loss 1.381 | task_loss 4.682 | contrastive_loss 0.283 | total 4003.4 | n_correct 2682.9 | ppl 5.32 | accuracy 67.016 | uer 17.079 | wer 18.989 | raw_wer 18.989 | bleu 22.49 | wps 1632.2 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.84
2023-08-23 11:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-23 11:32:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_33_48000.pt
2023-08-23 11:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_33_48000.pt
2023-08-23 11:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.49) (writing took 8.551763089955784 seconds)
2023-08-23 11:33:29 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.875, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.604, task_loss=1.314, contrastive_loss=0.076, total=4147.76, n_correct=2897.45, ppl=3.78, accuracy=69.856, wps=8028.7, ups=0.97, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=35385
2023-08-23 11:33:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 11:34:35 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.872, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.6, task_loss=1.36, contrastive_loss=0.067, total=4116.77, n_correct=2880.48, ppl=3.77, accuracy=69.969, wps=12381.5, ups=1.5, wpb=8233.5, bsz=299.3, num_updates=48200, lr=6.44157e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=66, gb_free=11.2, wall=35452
2023-08-23 11:35:37 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.883, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.591, task_loss=1.326, contrastive_loss=0.167, total=4182.67, n_correct=2915.44, ppl=3.81, accuracy=69.703, wps=13534.8, ups=1.62, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=35513
2023-08-23 11:36:39 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.873, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.601, task_loss=1.387, contrastive_loss=0.068, total=4110.02, n_correct=2877.07, ppl=3.77, accuracy=70.001, wps=13336.6, ups=1.62, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=35575
2023-08-23 11:37:41 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.873, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.597, task_loss=1.292, contrastive_loss=0.087, total=4128.82, n_correct=2884.87, ppl=3.79, accuracy=69.872, wps=13278.3, ups=1.61, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=62, gb_free=15.7, wall=35637
2023-08-23 11:38:42 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.885, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.594, task_loss=1.313, contrastive_loss=0.232, total=4123.47, n_correct=2880.96, ppl=3.79, accuracy=69.867, wps=13359.6, ups=1.62, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=35699
2023-08-23 11:38:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 11:39:29 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.16 | nll_loss 2.412 | w2v_ctc_loss 1.368 | task_loss 4.666 | contrastive_loss 0.285 | total 4003.4 | n_correct 2675.8 | ppl 5.32 | accuracy 66.838 | uer 17.27 | wer 19.045 | raw_wer 19.045 | bleu 22.66 | wps 1647.6 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 22.84
2023-08-23 11:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-23 11:39:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6603.pt
2023-08-23 11:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6603.pt
2023-08-23 11:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint.best_bleu_22.6603.pt (epoch 33 @ 48622 updates, score 22.66) (writing took 8.073069646023214 seconds)
2023-08-23 11:39:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-23 11:39:37 | INFO | train | epoch 033 | loss 1.874 | trans_loss 4.727 | nll_loss 1.916 | w2v_ctc_loss 0.596 | task_loss 1.32 | contrastive_loss 0.109 | total 4137.28 | n_correct 2894.18 | ppl 3.77 | accuracy 69.954 | wps 11788.8 | ups 1.42 | wpb 8274.6 | bsz 305.2 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 935 | gb_free 17.5 | wall 35754
2023-08-23 11:39:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-23 11:39:38 | INFO | fairseq.trainer | begin training epoch 34
2023-08-23 11:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 11:40:32 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.864, trans_loss=4.715, nll_loss=1.9, w2v_ctc_loss=0.59, task_loss=1.299, contrastive_loss=0.07, total=4128.94, n_correct=2898.19, ppl=3.73, accuracy=70.192, wps=7518.2, ups=0.91, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=35809
2023-08-23 11:41:34 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.86, trans_loss=4.707, nll_loss=1.889, w2v_ctc_loss=0.588, task_loss=1.377, contrastive_loss=0.071, total=4071.22, n_correct=2866.63, ppl=3.7, accuracy=70.412, wps=13260.8, ups=1.63, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=35870
2023-08-23 11:42:36 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.889, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.586, task_loss=1.242, contrastive_loss=0.283, total=4237.89, n_correct=2963.93, ppl=3.77, accuracy=69.939, wps=13676.1, ups=1.61, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=61, gb_free=10, wall=35932
2023-08-23 11:43:37 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.867, trans_loss=4.71, nll_loss=1.894, w2v_ctc_loss=0.583, task_loss=1.244, contrastive_loss=0.167, total=4167, n_correct=2930.67, ppl=3.72, accuracy=70.33, wps=13485.5, ups=1.62, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=35994
2023-08-23 11:44:39 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.872, trans_loss=4.721, nll_loss=1.907, w2v_ctc_loss=0.602, task_loss=1.441, contrastive_loss=0.064, total=4071.65, n_correct=2851.18, ppl=3.75, accuracy=70.025, wps=13332.8, ups=1.64, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=11.2, wall=36055
2023-08-23 11:45:39 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.861, trans_loss=4.709, nll_loss=1.892, w2v_ctc_loss=0.588, task_loss=1.336, contrastive_loss=0.066, total=4110.13, n_correct=2888.85, ppl=3.71, accuracy=70.286, wps=13533.1, ups=1.65, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=36116
2023-08-23 11:46:40 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.864, trans_loss=4.718, nll_loss=1.904, w2v_ctc_loss=0.59, task_loss=1.337, contrastive_loss=0.062, total=4128.65, n_correct=2898.58, ppl=3.74, accuracy=70.206, wps=13498.6, ups=1.63, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=36177
2023-08-23 11:47:42 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.879, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.59, task_loss=1.382, contrastive_loss=0.13, total=4075.69, n_correct=2844.07, ppl=3.81, accuracy=69.781, wps=13313.5, ups=1.63, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=36238
2023-08-23 11:48:44 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.874, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.596, task_loss=1.392, contrastive_loss=0.088, total=4104.97, n_correct=2872.61, ppl=3.77, accuracy=69.979, wps=13255.9, ups=1.61, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=36300
2023-08-23 11:49:45 | INFO | train_inner | epoch 034:    978 / 1474 loss=1.873, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.6, task_loss=1.288, contrastive_loss=0.084, total=4168.94, n_correct=2914, ppl=3.77, accuracy=69.898, wps=13622.7, ups=1.63, wpb=8337.9, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=14.6, wall=36361
2023-08-23 11:50:46 | INFO | train_inner | epoch 034:   1078 / 1474 loss=1.87, trans_loss=4.725, nll_loss=1.912, w2v_ctc_loss=0.599, task_loss=1.267, contrastive_loss=0.068, total=4155.12, n_correct=2909.28, ppl=3.76, accuracy=70.017, wps=13629.5, ups=1.64, wpb=8310.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=36422
2023-08-23 11:51:48 | INFO | train_inner | epoch 034:   1178 / 1474 loss=1.868, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.591, task_loss=1.359, contrastive_loss=0.079, total=4096.48, n_correct=2867.77, ppl=3.76, accuracy=70.006, wps=13261.8, ups=1.62, wpb=8193, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=36484
2023-08-23 11:52:48 | INFO | train_inner | epoch 034:   1278 / 1474 loss=1.868, trans_loss=4.721, nll_loss=1.908, w2v_ctc_loss=0.595, task_loss=1.336, contrastive_loss=0.063, total=4149.03, n_correct=2904.73, ppl=3.75, accuracy=70.01, wps=13637.6, ups=1.64, wpb=8298.1, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=36545
2023-08-23 11:53:51 | INFO | train_inner | epoch 034:   1378 / 1474 loss=1.879, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.601, task_loss=1.258, contrastive_loss=0.128, total=4200.34, n_correct=2932.76, ppl=3.78, accuracy=69.822, wps=13468.9, ups=1.6, wpb=8400.7, bsz=321.9, num_updates=50000, lr=6.32456e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=62, gb_free=14.7, wall=36607
2023-08-23 11:53:51 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-23 11:53:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 11:54:24 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.159 | nll_loss 2.413 | w2v_ctc_loss 1.372 | task_loss 4.662 | contrastive_loss 0.28 | total 4003.4 | n_correct 2678.7 | ppl 5.32 | accuracy 66.911 | uer 17.251 | wer 19.142 | raw_wer 19.142 | bleu 22.37 | wps 1646 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.84
2023-08-23 11:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-23 11:54:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_34_50000.pt
2023-08-23 11:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_34_50000.pt
2023-08-23 11:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0823_topCL_AT_sentence_mixup0307_alpha1.5_mt0.5_nogard/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.37) (writing took 7.35492642398458 seconds)
2023-08-23 11:54:31 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-23 11:54:31 | INFO | train | epoch 034 | loss 1.871 | trans_loss 4.721 | nll_loss 1.908 | w2v_ctc_loss 0.593 | task_loss 1.325 | contrastive_loss 0.104 | total 4133.33 | n_correct 2895.98 | ppl 3.75 | accuracy 70.064 | wps 12744.7 | ups 1.54 | wpb 8266.7 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.535 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 14.7 | wall 36648
2023-08-23 11:54:31 | INFO | fairseq_cli.train | done training in 36603.5 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
sleep_train.sh: 行 3: 163628 已终止               sleep 3.9h
stage 1: ST Network Training
dev=0,1,2,3,4,5,6,7 data=data_all_ende_lcrm model=./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py data_all_ende_lcrm --config-yaml config_st.yaml --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml --task joint_triple_pretraining_merge --max-tokens 15000 --skip-invalid-size-inputs-valid-test --update-freq 1 --log-interval 100 --save-dir ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5 --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5 --distributed-world-size 8 --ddp-backend no_c10d --fp16 --eval-bleu --eval-tokenized-bleu --eval-bleu-remove-bpe sentencepiece --best-checkpoint-metric bleu --keep-best-checkpoints 10 --maximize-best-checkpoint-metric
[34mRun command: 
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py
        data_all_ende_lcrm
        --config-yaml config_st.yaml
        --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml
        --task joint_triple_pretraining_merge
        --max-tokens 15000
        --skip-invalid-size-inputs-valid-test
        --update-freq 1
        --log-interval 100
        --save-dir ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5
        --tensorboard-logdir ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5
        
        --distributed-world-size 8
        --ddp-backend no_c10d
        --fp16
        --eval-bleu
        --eval-tokenized-bleu
        --eval-bleu-remove-bpe sentencepiece
        --best-checkpoint-metric bleu
        --keep-best-checkpoints 10
        --maximize-best-checkpoint-metric
        --no-epoch-checkpoints
        --validate-interval 1 
        --save-interval 1 
        --keep-last-epochs 2 
        --save-interval-updates 2000
        --keep-interval-updates 5
        --share-decoder-input-output-embed
        --use-w2v-ctc [0m
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18103
2023-08-24 02:14:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-24 02:14:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-24 02:14:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-24 02:14:22 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18103', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-24 02:14:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-24 02:14:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-24 02:14:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-24 02:14:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-24 02:14:22 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-24 02:14:27 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-24 02:14:27 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-24 02:14:27 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-24 02:14:29 | INFO | root | load pretrained hubert
2023-08-24 02:14:37 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-24 02:14:43 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-24 02:14:49 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-24 02:14:49 | INFO | root | share the sematic adapter and textual encoder
2023-08-24 02:14:49 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-24 02:14:49 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-24 02:14:49 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-24 02:14:49 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-24 02:14:49 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-24 02:14:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-24 02:14:49 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-24 02:14:49 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-24 02:14:49 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-24 02:14:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-24 02:15:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-24 02:15:05 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-24 02:15:05 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-24 02:15:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-24 02:15:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-24 02:15:06 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-24 02:15:06 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-24 02:15:06 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 02:15:06 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 02:15:06 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-24 02:15:06 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-24 02:15:06 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-24 02:15:06 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-24 02:15:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-24 02:15:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-24 02:15:50 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-24 02:15:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 02:15:50 | INFO | fairseq.trainer | begin training epoch 1
2023-08-24 02:15:50 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-24 02:16:59 | INFO | train_inner | epoch 001:    100 / 1474 loss=17.34, trans_loss=5.619, nll_loss=4.189, w2v_ctc_loss=22.483, task_loss=4.162, contrastive_loss=0, total=4207.04, n_correct=204.94, ppl=18.24, accuracy=4.871, wps=21677.7, ups=1.72, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.856, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=113
2023-08-24 02:17:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 02:17:57 | INFO | train_inner | epoch 001:    201 / 1474 loss=15.246, trans_loss=5.584, nll_loss=4.199, w2v_ctc_loss=19.282, task_loss=4.036, contrastive_loss=0, total=4121.36, n_correct=205.85, ppl=18.37, accuracy=4.995, wps=21238.7, ups=1.73, wpb=12305.5, bsz=461.4, num_updates=200, lr=8.096e-06, gnorm=3.682, clip=0, loss_scale=64, train_wall=57, gb_free=19.2, wall=171
2023-08-24 02:18:56 | INFO | train_inner | epoch 001:    301 / 1474 loss=8.396, trans_loss=5.576, nll_loss=4.242, w2v_ctc_loss=8.737, task_loss=4.013, contrastive_loss=0, total=4079.62, n_correct=200.17, ppl=18.92, accuracy=4.907, wps=20719.8, ups=1.7, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.573, clip=0, loss_scale=64, train_wall=58, gb_free=19.9, wall=230
2023-08-24 02:19:54 | INFO | train_inner | epoch 001:    401 / 1474 loss=7.121, trans_loss=5.561, nll_loss=4.247, w2v_ctc_loss=6.796, task_loss=3.535, contrastive_loss=0, total=4174.14, n_correct=184.85, ppl=18.99, accuracy=4.428, wps=21514.4, ups=1.73, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.926, clip=0, loss_scale=64, train_wall=57, gb_free=18.9, wall=288
2023-08-24 02:20:51 | INFO | train_inner | epoch 001:    501 / 1474 loss=6.671, trans_loss=5.506, nll_loss=4.197, w2v_ctc_loss=6.159, task_loss=3.275, contrastive_loss=0, total=4176.18, n_correct=193.71, ppl=18.34, accuracy=4.638, wps=21840, ups=1.75, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.386, clip=0, loss_scale=64, train_wall=56, gb_free=19.2, wall=345
2023-08-24 02:21:49 | INFO | train_inner | epoch 001:    601 / 1474 loss=6.427, trans_loss=5.511, nll_loss=4.214, w2v_ctc_loss=5.782, task_loss=3.059, contrastive_loss=0, total=4147.79, n_correct=199.58, ppl=18.55, accuracy=4.812, wps=21531.2, ups=1.74, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.647, clip=0, loss_scale=64, train_wall=57, gb_free=18.9, wall=403
2023-08-24 02:22:46 | INFO | train_inner | epoch 001:    701 / 1474 loss=6.354, trans_loss=5.534, nll_loss=4.254, w2v_ctc_loss=5.641, task_loss=3.154, contrastive_loss=0, total=4152.1, n_correct=205.12, ppl=19.08, accuracy=4.94, wps=21590.5, ups=1.74, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=57, gb_free=19.5, wall=460
2023-08-24 02:23:43 | INFO | train_inner | epoch 001:    801 / 1474 loss=6.178, trans_loss=5.553, nll_loss=4.281, w2v_ctc_loss=5.349, task_loss=3.047, contrastive_loss=0, total=4123.83, n_correct=205.36, ppl=19.45, accuracy=4.98, wps=21589.2, ups=1.75, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=56, gb_free=19.1, wall=517
2023-08-24 02:24:41 | INFO | train_inner | epoch 001:    901 / 1474 loss=5.981, trans_loss=5.56, nll_loss=4.297, w2v_ctc_loss=5.038, task_loss=3.097, contrastive_loss=0, total=4163.61, n_correct=204.65, ppl=19.66, accuracy=4.915, wps=21402.1, ups=1.72, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=57, gb_free=18.8, wall=575
2023-08-24 02:25:39 | INFO | train_inner | epoch 001:   1001 / 1474 loss=5.755, trans_loss=5.563, nll_loss=4.302, w2v_ctc_loss=4.685, task_loss=3.119, contrastive_loss=0, total=4135.34, n_correct=208.3, ppl=19.72, accuracy=5.037, wps=21503.2, ups=1.74, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=57, gb_free=19, wall=633
2023-08-24 02:26:36 | INFO | train_inner | epoch 001:   1101 / 1474 loss=5.554, trans_loss=5.561, nll_loss=4.295, w2v_ctc_loss=4.383, task_loss=3.148, contrastive_loss=0, total=4147.38, n_correct=219.66, ppl=19.63, accuracy=5.296, wps=21711.4, ups=1.76, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=18.8, wall=690
2023-08-24 02:26:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 02:27:33 | INFO | train_inner | epoch 001:   1202 / 1474 loss=5.411, trans_loss=5.559, nll_loss=4.294, w2v_ctc_loss=4.158, task_loss=3.354, contrastive_loss=0, total=4119.73, n_correct=228.79, ppl=19.62, accuracy=5.554, wps=21353.5, ups=1.74, wpb=12305.9, bsz=431.8, num_updates=1200, lr=4.8076e-05, gnorm=0.668, clip=0, loss_scale=32, train_wall=57, gb_free=19.6, wall=748
2023-08-24 02:28:30 | INFO | train_inner | epoch 001:   1302 / 1474 loss=5.262, trans_loss=5.555, nll_loss=4.288, w2v_ctc_loss=3.939, task_loss=3.128, contrastive_loss=0, total=4055.44, n_correct=226.33, ppl=19.53, accuracy=5.581, wps=21318.2, ups=1.76, wpb=12107.5, bsz=442.9, num_updates=1300, lr=5.2074e-05, gnorm=0.681, clip=0, loss_scale=32, train_wall=56, gb_free=19.3, wall=804
2023-08-24 02:29:27 | INFO | train_inner | epoch 001:   1402 / 1474 loss=5.129, trans_loss=5.536, nll_loss=4.266, w2v_ctc_loss=3.754, task_loss=3.152, contrastive_loss=0, total=4125.61, n_correct=239.92, ppl=19.24, accuracy=5.815, wps=21541.2, ups=1.75, wpb=12328.1, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=0.759, clip=0, loss_scale=32, train_wall=57, gb_free=18.8, wall=862
2023-08-24 02:30:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-24 02:30:56 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.321 | trans_loss 11.67 | nll_loss 10.779 | w2v_ctc_loss 4.77 | task_loss 18.863 | contrastive_loss 0 | total 4003.4 | n_correct 274.7 | ppl 1756.89 | accuracy 6.862 | uer 62.605 | wer 60.855 | raw_wer 60.855 | bleu 0 | wps 1043.1 | wpb 4003.4 | bsz 141.8 | num_updates 1472
2023-08-24 02:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1472 updates
2023-08-24 02:30:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 02:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 02:31:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 1 @ 1472 updates, score 0.0) (writing took 4.5339794820174575 seconds)
2023-08-24 02:31:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-24 02:31:01 | INFO | train | epoch 001 | loss 7.514 | trans_loss 5.555 | nll_loss 4.255 | w2v_ctc_loss 7.408 | task_loss 3.359 | contrastive_loss 0 | total 4137.26 | n_correct 210.751 | ppl 19.09 | accuracy 5.094 | wps 20211.3 | ups 1.64 | wpb 12351.7 | bsz 458 | num_updates 1472 | lr 5.89506e-05 | gnorm 1.316 | clip 0 | loss_scale 32 | train_wall 842 | gb_free 19.2 | wall 955
2023-08-24 02:31:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 02:31:01 | INFO | fairseq.trainer | begin training epoch 2
2023-08-24 02:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 02:31:25 | INFO | train_inner | epoch 002:     28 / 1474 loss=5.016, trans_loss=5.534, nll_loss=4.256, w2v_ctc_loss=3.585, task_loss=2.96, contrastive_loss=0, total=4164.65, n_correct=243.81, ppl=19.1, accuracy=5.854, wps=10580.9, ups=0.85, wpb=12421.6, bsz=471.6, num_updates=1500, lr=6.007e-05, gnorm=0.876, clip=0, loss_scale=32, train_wall=57, gb_free=18.9, wall=979
2023-08-24 02:32:22 | INFO | train_inner | epoch 002:    128 / 1474 loss=4.949, trans_loss=5.529, nll_loss=4.248, w2v_ctc_loss=3.482, task_loss=3.191, contrastive_loss=0, total=4153.14, n_correct=240.18, ppl=19, accuracy=5.783, wps=21706.6, ups=1.75, wpb=12386.1, bsz=450.6, num_updates=1600, lr=6.4068e-05, gnorm=0.868, clip=0, loss_scale=32, train_wall=56, gb_free=19.8, wall=1036
2023-08-24 02:33:18 | INFO | train_inner | epoch 002:    228 / 1474 loss=4.825, trans_loss=5.502, nll_loss=4.218, w2v_ctc_loss=3.324, task_loss=2.717, contrastive_loss=0, total=4192.9, n_correct=240.8, ppl=18.61, accuracy=5.743, wps=22092.7, ups=1.76, wpb=12523.7, bsz=493, num_updates=1700, lr=6.8066e-05, gnorm=0.794, clip=0, loss_scale=32, train_wall=56, gb_free=19.2, wall=1093
2023-08-24 02:34:16 | INFO | train_inner | epoch 002:    328 / 1474 loss=4.791, trans_loss=5.505, nll_loss=4.22, w2v_ctc_loss=3.261, task_loss=3.208, contrastive_loss=0, total=4132.45, n_correct=239.96, ppl=18.64, accuracy=5.807, wps=21596.6, ups=1.75, wpb=12335.7, bsz=443.2, num_updates=1800, lr=7.2064e-05, gnorm=0.858, clip=0, loss_scale=32, train_wall=56, gb_free=19.4, wall=1150
2023-08-24 02:35:12 | INFO | train_inner | epoch 002:    428 / 1474 loss=4.738, trans_loss=5.495, nll_loss=4.209, w2v_ctc_loss=3.191, task_loss=3.471, contrastive_loss=0, total=4037.61, n_correct=235.27, ppl=18.49, accuracy=5.827, wps=21273.3, ups=1.76, wpb=12068.2, bsz=415.8, num_updates=1900, lr=7.6062e-05, gnorm=0.747, clip=0, loss_scale=32, train_wall=56, gb_free=19.9, wall=1207
2023-08-24 02:36:09 | INFO | train_inner | epoch 002:    528 / 1474 loss=4.643, trans_loss=5.48, nll_loss=4.187, w2v_ctc_loss=3.066, task_loss=3.008, contrastive_loss=0, total=4183.4, n_correct=239.87, ppl=18.21, accuracy=5.734, wps=21877.6, ups=1.75, wpb=12481.5, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=0.747, clip=0, loss_scale=32, train_wall=56, gb_free=19, wall=1264
2023-08-24 02:36:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 02:36:56 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.96 | trans_loss 11.49 | nll_loss 10.529 | w2v_ctc_loss 3.974 | task_loss 18.863 | contrastive_loss 0 | total 4003.4 | n_correct 268.1 | ppl 1477.34 | accuracy 6.697 | uer 55.326 | wer 53.988 | raw_wer 53.988 | bleu 0 | wps 1042.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-24 02:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-24 02:36:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-08-24 02:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-08-24 02:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 13.134084079996683 seconds)
2023-08-24 02:38:07 | INFO | train_inner | epoch 002:    628 / 1474 loss=4.595, trans_loss=5.481, nll_loss=4.187, w2v_ctc_loss=2.993, task_loss=3.11, contrastive_loss=0, total=4126.46, n_correct=238.46, ppl=18.22, accuracy=5.779, wps=10467.1, ups=0.85, wpb=12316, bsz=446.7, num_updates=2100, lr=8.4058e-05, gnorm=0.865, clip=0, loss_scale=32, train_wall=57, gb_free=19.3, wall=1381
2023-08-24 02:39:04 | INFO | train_inner | epoch 002:    728 / 1474 loss=4.545, trans_loss=5.458, nll_loss=4.16, w2v_ctc_loss=2.943, task_loss=3.084, contrastive_loss=0, total=4148.66, n_correct=242.73, ppl=17.88, accuracy=5.851, wps=21789, ups=1.76, wpb=12384.1, bsz=462.9, num_updates=2200, lr=8.8056e-05, gnorm=0.764, clip=0, loss_scale=32, train_wall=56, gb_free=19.7, wall=1438
2023-08-24 02:40:01 | INFO | train_inner | epoch 002:    828 / 1474 loss=4.512, trans_loss=5.451, nll_loss=4.155, w2v_ctc_loss=2.898, task_loss=3.161, contrastive_loss=0, total=4164.61, n_correct=244.55, ppl=17.81, accuracy=5.872, wps=21763.6, ups=1.75, wpb=12439.5, bsz=459.2, num_updates=2300, lr=9.2054e-05, gnorm=0.653, clip=0, loss_scale=32, train_wall=57, gb_free=19.5, wall=1495
2023-08-24 02:40:58 | INFO | train_inner | epoch 002:    928 / 1474 loss=4.477, trans_loss=5.466, nll_loss=4.172, w2v_ctc_loss=2.829, task_loss=3.183, contrastive_loss=0, total=4109.63, n_correct=242.8, ppl=18.03, accuracy=5.908, wps=21685.3, ups=1.77, wpb=12270.1, bsz=447.9, num_updates=2400, lr=9.6052e-05, gnorm=0.745, clip=0, loss_scale=32, train_wall=56, gb_free=18.9, wall=1552
2023-08-24 02:41:55 | INFO | train_inner | epoch 002:   1028 / 1474 loss=4.444, trans_loss=5.462, nll_loss=4.169, w2v_ctc_loss=2.783, task_loss=3.146, contrastive_loss=0, total=4101.19, n_correct=241.5, ppl=17.99, accuracy=5.889, wps=21449.7, ups=1.75, wpb=12245.2, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=0.646, clip=0, loss_scale=32, train_wall=56, gb_free=19, wall=1609
2023-08-24 02:42:53 | INFO | train_inner | epoch 002:   1128 / 1474 loss=4.406, trans_loss=5.476, nll_loss=4.186, w2v_ctc_loss=2.718, task_loss=2.81, contrastive_loss=0, total=4192.73, n_correct=239.83, ppl=18.2, accuracy=5.72, wps=21650.6, ups=1.73, wpb=12513.6, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=0.608, clip=0, loss_scale=32, train_wall=57, gb_free=18.9, wall=1667
2023-08-24 02:43:50 | INFO | train_inner | epoch 002:   1228 / 1474 loss=4.375, trans_loss=5.456, nll_loss=4.16, w2v_ctc_loss=2.691, task_loss=2.859, contrastive_loss=0, total=4219.96, n_correct=249.96, ppl=17.88, accuracy=5.923, wps=22039.7, ups=1.75, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=0.567, clip=0, loss_scale=32, train_wall=57, gb_free=18.9, wall=1724
2023-08-24 02:44:46 | INFO | train_inner | epoch 002:   1328 / 1474 loss=4.366, trans_loss=5.464, nll_loss=4.172, w2v_ctc_loss=2.665, task_loss=2.988, contrastive_loss=0, total=4163.26, n_correct=244.93, ppl=18.02, accuracy=5.883, wps=21942, ups=1.76, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=0.523, clip=0, loss_scale=32, train_wall=56, gb_free=19, wall=1781
2023-08-24 02:45:43 | INFO | train_inner | epoch 002:   1428 / 1474 loss=4.344, trans_loss=5.452, nll_loss=4.157, w2v_ctc_loss=2.646, task_loss=3.386, contrastive_loss=0, total=4049.42, n_correct=238.38, ppl=17.84, accuracy=5.887, wps=21316.5, ups=1.76, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=0.664, clip=0, loss_scale=32, train_wall=56, gb_free=19.2, wall=1837
2023-08-24 02:46:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 02:46:56 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.606 | trans_loss 11.217 | nll_loss 10.201 | w2v_ctc_loss 3.408 | task_loss 18.863 | contrastive_loss 0 | total 4003.4 | n_correct 281.2 | ppl 1176.71 | accuracy 7.024 | uer 49.372 | wer 47.884 | raw_wer 47.884 | bleu 0.01 | wps 1045.7 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.01
2023-08-24 02:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-24 02:46:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 02:47:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 02:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.01) (writing took 13.694104020949453 seconds)
2023-08-24 02:47:09 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-24 02:47:09 | INFO | train | epoch 002 | loss 4.573 | trans_loss 5.478 | nll_loss 4.187 | w2v_ctc_loss 2.964 | task_loss 3.084 | contrastive_loss 0 | total 4138.65 | n_correct 241.246 | ppl 18.21 | accuracy 5.829 | wps 18800 | ups 1.52 | wpb 12355.8 | bsz 458.5 | num_updates 2946 | lr 0.000117881 | gnorm 0.715 | clip 0 | loss_scale 32 | train_wall 830 | gb_free 19.3 | wall 1924
2023-08-24 02:47:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 02:47:10 | INFO | fairseq.trainer | begin training epoch 3
2023-08-24 02:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 02:47:47 | INFO | train_inner | epoch 003:     54 / 1474 loss=4.316, trans_loss=5.452, nll_loss=4.155, w2v_ctc_loss=2.594, task_loss=3.172, contrastive_loss=0, total=4067, n_correct=242.88, ppl=17.82, accuracy=5.972, wps=9766, ups=0.8, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=0.585, clip=0, loss_scale=32, train_wall=56, gb_free=19.2, wall=1962
2023-08-24 02:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-24 02:48:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-24 02:49:14 | INFO | train_inner | epoch 003:    156 / 1474 loss=3.364, trans_loss=4.367, nll_loss=2.783, w2v_ctc_loss=2.276, task_loss=2.245, contrastive_loss=0, total=4114.98, n_correct=1070.64, ppl=6.88, accuracy=26.018, wps=14268.7, ups=1.16, wpb=12285.9, bsz=445.6, num_updates=3100, lr=0.000124038, gnorm=1.225, clip=0, loss_scale=8, train_wall=85, gb_free=16.2, wall=2048
2023-08-24 02:50:39 | INFO | train_inner | epoch 003:    256 / 1474 loss=3.061, trans_loss=4.176, nll_loss=2.534, w2v_ctc_loss=2.012, task_loss=2.164, contrastive_loss=0, total=4148.62, n_correct=1322.65, ppl=5.79, accuracy=31.882, wps=14458.5, ups=1.17, wpb=12396.7, bsz=463.7, num_updates=3200, lr=0.000128036, gnorm=0.872, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=2134
2023-08-24 02:52:04 | INFO | train_inner | epoch 003:    356 / 1474 loss=2.93, trans_loss=4.078, nll_loss=2.4, w2v_ctc_loss=1.922, task_loss=2.121, contrastive_loss=0, total=4171.73, n_correct=1495.58, ppl=5.28, accuracy=35.85, wps=14785, ups=1.19, wpb=12449.7, bsz=468.2, num_updates=3300, lr=0.000132034, gnorm=0.93, clip=0, loss_scale=8, train_wall=84, gb_free=15.3, wall=2218
2023-08-24 02:53:28 | INFO | train_inner | epoch 003:    456 / 1474 loss=2.831, trans_loss=3.997, nll_loss=2.293, w2v_ctc_loss=1.853, task_loss=2.1, contrastive_loss=0, total=4197.48, n_correct=1643.29, ppl=4.9, accuracy=39.149, wps=14831, ups=1.18, wpb=12527.9, bsz=474.4, num_updates=3400, lr=0.000136032, gnorm=0.865, clip=0, loss_scale=8, train_wall=84, gb_free=12.2, wall=2302
2023-08-24 02:54:52 | INFO | train_inner | epoch 003:    556 / 1474 loss=2.751, trans_loss=3.953, nll_loss=2.236, w2v_ctc_loss=1.783, task_loss=2.29, contrastive_loss=0, total=4095.16, n_correct=1677.18, ppl=4.71, accuracy=40.955, wps=14566.3, ups=1.19, wpb=12233.8, bsz=440.6, num_updates=3500, lr=0.00014003, gnorm=0.843, clip=0, loss_scale=8, train_wall=83, gb_free=15.7, wall=2386
2023-08-24 02:56:18 | INFO | train_inner | epoch 003:    656 / 1474 loss=2.676, trans_loss=3.906, nll_loss=2.169, w2v_ctc_loss=1.721, task_loss=2.048, contrastive_loss=0, total=4223.37, n_correct=1816.19, ppl=4.5, accuracy=43.003, wps=14689.6, ups=1.17, wpb=12593.2, bsz=484, num_updates=3600, lr=0.000144028, gnorm=0.804, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=2472
2023-08-24 02:57:42 | INFO | train_inner | epoch 003:    756 / 1474 loss=2.641, trans_loss=3.872, nll_loss=2.129, w2v_ctc_loss=1.701, task_loss=2.073, contrastive_loss=0, total=4165.36, n_correct=1839.27, ppl=4.37, accuracy=44.156, wps=14747.9, ups=1.19, wpb=12442.1, bsz=470.9, num_updates=3700, lr=0.000148026, gnorm=0.825, clip=0, loss_scale=8, train_wall=84, gb_free=15, wall=2556
2023-08-24 02:59:06 | INFO | train_inner | epoch 003:    856 / 1474 loss=2.599, trans_loss=3.858, nll_loss=2.109, w2v_ctc_loss=1.657, task_loss=2.159, contrastive_loss=0, total=4164.94, n_correct=1874.16, ppl=4.31, accuracy=44.998, wps=14861.4, ups=1.2, wpb=12434.8, bsz=457.9, num_updates=3800, lr=0.000152024, gnorm=0.793, clip=0, loss_scale=8, train_wall=83, gb_free=14.9, wall=2640
2023-08-24 03:00:31 | INFO | train_inner | epoch 003:    956 / 1474 loss=2.571, trans_loss=3.835, nll_loss=2.077, w2v_ctc_loss=1.638, task_loss=2.122, contrastive_loss=0, total=4156.71, n_correct=1917.69, ppl=4.22, accuracy=46.135, wps=14613.1, ups=1.18, wpb=12401.4, bsz=465.4, num_updates=3900, lr=0.000156022, gnorm=0.797, clip=0, loss_scale=8, train_wall=84, gb_free=16.9, wall=2725
2023-08-24 03:01:55 | INFO | train_inner | epoch 003:   1056 / 1474 loss=2.559, trans_loss=3.819, nll_loss=2.059, w2v_ctc_loss=1.629, task_loss=2.331, contrastive_loss=0, total=4063.38, n_correct=1892.55, ppl=4.17, accuracy=46.576, wps=14439.5, ups=1.19, wpb=12134.6, bsz=439.1, num_updates=4000, lr=0.00016002, gnorm=0.809, clip=0, loss_scale=8, train_wall=83, gb_free=17.4, wall=2809
2023-08-24 03:01:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 03:02:30 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.806 | trans_loss 6.269 | nll_loss 3.769 | w2v_ctc_loss 1.893 | task_loss 10.859 | contrastive_loss 0 | total 4003.4 | n_correct 2048.6 | ppl 13.63 | accuracy 51.172 | uer 28.609 | wer 29.402 | raw_wer 29.402 | bleu 12.23 | wps 1468.7 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 12.23
2023-08-24 03:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-24 03:02:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_3_4000.pt
2023-08-24 03:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_3_4000.pt
2023-08-24 03:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 12.23) (writing took 13.89308838301804 seconds)
2023-08-24 03:04:07 | INFO | train_inner | epoch 003:   1156 / 1474 loss=2.522, trans_loss=3.81, nll_loss=2.044, w2v_ctc_loss=1.591, task_loss=2.312, contrastive_loss=0, total=4049.57, n_correct=1910.5, ppl=4.12, accuracy=47.178, wps=9124.2, ups=0.76, wpb=12084.5, bsz=438, num_updates=4100, lr=0.000164018, gnorm=0.784, clip=0, loss_scale=8, train_wall=83, gb_free=16.7, wall=2941
2023-08-24 03:05:31 | INFO | train_inner | epoch 003:   1256 / 1474 loss=2.492, trans_loss=3.792, nll_loss=2.023, w2v_ctc_loss=1.564, task_loss=2.294, contrastive_loss=0, total=4061.36, n_correct=1944.88, ppl=4.06, accuracy=47.887, wps=14529.2, ups=1.2, wpb=12130, bsz=433.6, num_updates=4200, lr=0.000168016, gnorm=0.771, clip=0, loss_scale=8, train_wall=83, gb_free=16.3, wall=3025
2023-08-24 03:06:55 | INFO | train_inner | epoch 003:   1356 / 1474 loss=2.458, trans_loss=3.773, nll_loss=1.999, w2v_ctc_loss=1.53, task_loss=2.164, contrastive_loss=0, total=4141.12, n_correct=2011.07, ppl=4, accuracy=48.563, wps=14657.7, ups=1.19, wpb=12364.3, bsz=463.2, num_updates=4300, lr=0.000172014, gnorm=0.771, clip=0, loss_scale=8, train_wall=84, gb_free=14.7, wall=3109
2023-08-24 03:08:19 | INFO | train_inner | epoch 003:   1456 / 1474 loss=2.441, trans_loss=3.767, nll_loss=1.992, w2v_ctc_loss=1.517, task_loss=2.062, contrastive_loss=0, total=4211.06, n_correct=2059.7, ppl=3.98, accuracy=48.912, wps=14890.9, ups=1.18, wpb=12576.2, bsz=477.6, num_updates=4400, lr=0.000176012, gnorm=0.769, clip=0, loss_scale=8, train_wall=84, gb_free=17.2, wall=3194
2023-08-24 03:08:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 03:09:08 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.659 | trans_loss 6.13 | nll_loss 3.583 | w2v_ctc_loss 1.716 | task_loss 10.795 | contrastive_loss 0 | total 4003.4 | n_correct 2133 | ppl 11.98 | accuracy 53.28 | uer 27.11 | wer 28.097 | raw_wer 28.097 | bleu 14.58 | wps 1578.3 | wpb 4003.4 | bsz 141.8 | num_updates 4418 | best_bleu 14.58
2023-08-24 03:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4418 updates
2023-08-24 03:09:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 3 @ 4418 updates, score 14.58) (writing took 10.676908669061959 seconds)
2023-08-24 03:09:18 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-24 03:09:18 | INFO | train | epoch 003 | loss 2.762 | trans_loss 3.982 | nll_loss 2.272 | w2v_ctc_loss 1.77 | task_loss 2.211 | contrastive_loss 0 | total 4137.67 | n_correct 1695.41 | ppl 4.83 | accuracy 40.975 | wps 13682 | ups 1.11 | wpb 12353 | bsz 458.1 | num_updates 4418 | lr 0.000176732 | gnorm 0.837 | clip 0 | loss_scale 8 | train_wall 1219 | gb_free 16.4 | wall 3253
2023-08-24 03:09:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 03:09:19 | INFO | fairseq.trainer | begin training epoch 4
2023-08-24 03:09:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 03:10:34 | INFO | train_inner | epoch 004:     82 / 1474 loss=2.396, trans_loss=3.735, nll_loss=1.947, w2v_ctc_loss=1.47, task_loss=2.265, contrastive_loss=0, total=4090.08, n_correct=2041.38, ppl=3.86, accuracy=49.911, wps=9069.9, ups=0.74, wpb=12208.2, bsz=437, num_updates=4500, lr=0.00018001, gnorm=0.759, clip=0, loss_scale=8, train_wall=83, gb_free=16.5, wall=3328
2023-08-24 03:11:57 | INFO | train_inner | epoch 004:    182 / 1474 loss=2.371, trans_loss=3.717, nll_loss=1.924, w2v_ctc_loss=1.451, task_loss=2.075, contrastive_loss=0, total=4179.17, n_correct=2115.35, ppl=3.8, accuracy=50.617, wps=14975.4, ups=1.2, wpb=12477, bsz=468, num_updates=4600, lr=0.000184008, gnorm=0.754, clip=0, loss_scale=8, train_wall=83, gb_free=10.6, wall=3412
2023-08-24 03:13:22 | INFO | train_inner | epoch 004:    282 / 1474 loss=2.37, trans_loss=3.719, nll_loss=1.93, w2v_ctc_loss=1.451, task_loss=2.174, contrastive_loss=0, total=4139.78, n_correct=2092.44, ppl=3.81, accuracy=50.545, wps=14649.1, ups=1.18, wpb=12367.7, bsz=462.4, num_updates=4700, lr=0.000188006, gnorm=0.746, clip=0, loss_scale=8, train_wall=84, gb_free=17, wall=3496
2023-08-24 03:14:46 | INFO | train_inner | epoch 004:    382 / 1474 loss=2.364, trans_loss=3.725, nll_loss=1.932, w2v_ctc_loss=1.439, task_loss=2.261, contrastive_loss=0, total=4132.58, n_correct=2097.73, ppl=3.82, accuracy=50.761, wps=14655.8, ups=1.19, wpb=12328, bsz=443.4, num_updates=4800, lr=0.000192004, gnorm=0.74, clip=0, loss_scale=8, train_wall=84, gb_free=16.1, wall=3580
2023-08-24 03:16:10 | INFO | train_inner | epoch 004:    482 / 1474 loss=2.331, trans_loss=3.705, nll_loss=1.91, w2v_ctc_loss=1.406, task_loss=2.017, contrastive_loss=0, total=4193.12, n_correct=2152.93, ppl=3.76, accuracy=51.344, wps=14903.5, ups=1.19, wpb=12516.7, bsz=487.4, num_updates=4900, lr=0.000196002, gnorm=0.743, clip=0, loss_scale=8, train_wall=83, gb_free=13.5, wall=3664
2023-08-24 03:17:34 | INFO | train_inner | epoch 004:    582 / 1474 loss=2.338, trans_loss=3.705, nll_loss=1.911, w2v_ctc_loss=1.42, task_loss=2.004, contrastive_loss=0, total=4234.09, n_correct=2178.83, ppl=3.76, accuracy=51.459, wps=14994.6, ups=1.19, wpb=12638.3, bsz=495.1, num_updates=5000, lr=0.0002, gnorm=0.73, clip=0, loss_scale=8, train_wall=84, gb_free=16.5, wall=3749
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:0')
2023-08-24 03:19:00 | INFO | train_inner | epoch 004:    682 / 1474 loss=2.317, trans_loss=3.707, nll_loss=1.91, w2v_ctc_loss=1.392, task_loss=2.216, contrastive_loss=0, total=4195.52, n_correct=2169.27, ppl=3.76, accuracy=51.704, wps=14630.2, ups=1.17, wpb=12507.9, bsz=461.1, num_updates=5100, lr=0.00019803, gnorm=0.475, clip=0, loss_scale=16, train_wall=85, gb_free=13.5, wall=3834
2023-08-24 03:20:24 | INFO | train_inner | epoch 004:    782 / 1474 loss=2.327, trans_loss=3.703, nll_loss=1.909, w2v_ctc_loss=1.407, task_loss=2.442, contrastive_loss=0, total=4009.24, n_correct=2076.34, ppl=3.75, accuracy=51.789, wps=14144.6, ups=1.18, wpb=11973.6, bsz=415.7, num_updates=5200, lr=0.000196116, gnorm=0.49, clip=0, loss_scale=16, train_wall=84, gb_free=17, wall=3919
2023-08-24 03:21:48 | INFO | train_inner | epoch 004:    882 / 1474 loss=2.312, trans_loss=3.688, nll_loss=1.89, w2v_ctc_loss=1.4, task_loss=2.173, contrastive_loss=0, total=4191.91, n_correct=2193.24, ppl=3.71, accuracy=52.321, wps=14897, ups=1.19, wpb=12517.7, bsz=467.3, num_updates=5300, lr=0.000194257, gnorm=0.48, clip=0, loss_scale=16, train_wall=83, gb_free=14.8, wall=4003
2023-08-24 03:23:12 | INFO | train_inner | epoch 004:    982 / 1474 loss=2.294, trans_loss=3.682, nll_loss=1.884, w2v_ctc_loss=1.378, task_loss=2.201, contrastive_loss=0, total=4129.3, n_correct=2171.11, ppl=3.69, accuracy=52.578, wps=14714.4, ups=1.19, wpb=12332.9, bsz=458.1, num_updates=5400, lr=0.00019245, gnorm=0.47, clip=0, loss_scale=16, train_wall=83, gb_free=17.8, wall=4087
2023-08-24 03:24:37 | INFO | train_inner | epoch 004:   1082 / 1474 loss=2.304, trans_loss=3.691, nll_loss=1.893, w2v_ctc_loss=1.387, task_loss=2.352, contrastive_loss=0, total=4072.56, n_correct=2136.07, ppl=3.71, accuracy=52.45, wps=14405.9, ups=1.19, wpb=12155.9, bsz=436.5, num_updates=5500, lr=0.000190693, gnorm=0.48, clip=0, loss_scale=16, train_wall=84, gb_free=16.3, wall=4171
2023-08-24 03:26:00 | INFO | train_inner | epoch 004:   1182 / 1474 loss=2.286, trans_loss=3.681, nll_loss=1.885, w2v_ctc_loss=1.376, task_loss=2.047, contrastive_loss=0, total=4164, n_correct=2193.11, ppl=3.69, accuracy=52.668, wps=14858.9, ups=1.19, wpb=12440.4, bsz=483.3, num_updates=5600, lr=0.000188982, gnorm=0.468, clip=0, loss_scale=16, train_wall=83, gb_free=15.9, wall=4255
2023-08-24 03:27:25 | INFO | train_inner | epoch 004:   1282 / 1474 loss=2.271, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=1.362, task_loss=2.091, contrastive_loss=0, total=4155.14, n_correct=2206.34, ppl=3.66, accuracy=53.099, wps=14682.4, ups=1.18, wpb=12409.1, bsz=472.5, num_updates=5700, lr=0.000187317, gnorm=0.466, clip=0, loss_scale=16, train_wall=84, gb_free=16.4, wall=4339
2023-08-24 03:28:47 | INFO | train_inner | epoch 004:   1382 / 1474 loss=2.268, trans_loss=3.671, nll_loss=1.87, w2v_ctc_loss=1.356, task_loss=2.235, contrastive_loss=0, total=4101.03, n_correct=2184.65, ppl=3.66, accuracy=53.271, wps=14847.9, ups=1.21, wpb=12248.2, bsz=438, num_updates=5800, lr=0.000185695, gnorm=0.466, clip=0, loss_scale=16, train_wall=82, gb_free=16.9, wall=4422
2023-08-24 03:30:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4633, device='cuda:2')
2023-08-24 03:30:37 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.421 | trans_loss 5.856 | nll_loss 3.212 | w2v_ctc_loss 1.539 | task_loss 11.243 | contrastive_loss 0 | total 4003.4 | n_correct 2293.8 | ppl 9.27 | accuracy 57.296 | uer 23.083 | wer 24.734 | raw_wer 24.734 | bleu 17.18 | wps 1604.7 | wpb 4003.4 | bsz 141.8 | num_updates 5892 | best_bleu 17.18
2023-08-24 03:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5892 updates
2023-08-24 03:30:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 4 @ 5892 updates, score 17.18) (writing took 10.41041028208565 seconds)
2023-08-24 03:30:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-24 03:30:48 | INFO | train | epoch 004 | loss 2.32 | trans_loss 3.697 | nll_loss 1.902 | w2v_ctc_loss 1.402 | task_loss 2.181 | contrastive_loss 0 | total 4138.65 | n_correct 2147.22 | ppl 3.74 | accuracy 51.882 | wps 14128.2 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 5892 | lr 0.00018424 | gnorm 0.581 | clip 0 | loss_scale 16 | train_wall 1229 | gb_free 14.8 | wall 4542
2023-08-24 03:30:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 03:30:48 | INFO | fairseq.trainer | begin training epoch 5
2023-08-24 03:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 03:31:01 | INFO | train_inner | epoch 005:      8 / 1474 loss=2.256, trans_loss=3.667, nll_loss=1.863, w2v_ctc_loss=1.339, task_loss=2.297, contrastive_loss=0, total=4036.88, n_correct=2157.65, ppl=3.64, accuracy=53.448, wps=8994.4, ups=0.75, wpb=12051.7, bsz=437.2, num_updates=5900, lr=0.000184115, gnorm=0.471, clip=0, loss_scale=16, train_wall=82, gb_free=16.6, wall=4556
2023-08-24 03:32:25 | INFO | train_inner | epoch 005:    108 / 1474 loss=2.172, trans_loss=3.607, nll_loss=1.787, w2v_ctc_loss=1.256, task_loss=1.976, contrastive_loss=0, total=4241.19, n_correct=2346.73, ppl=3.45, accuracy=55.332, wps=15074.4, ups=1.19, wpb=12664.5, bsz=494.6, num_updates=6000, lr=0.000182574, gnorm=0.449, clip=0, loss_scale=16, train_wall=83, gb_free=17, wall=4640
2023-08-24 03:32:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 03:32:59 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.412 | trans_loss 5.861 | nll_loss 3.219 | w2v_ctc_loss 1.497 | task_loss 11.259 | contrastive_loss 0 | total 4003.4 | n_correct 2290.4 | ppl 9.31 | accuracy 57.211 | uer 22.924 | wer 24.701 | raw_wer 24.701 | bleu 16.68 | wps 1539.8 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 17.18
2023-08-24 03:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-24 03:32:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_5_6000.pt
2023-08-24 03:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_5_6000.pt
2023-08-24 03:33:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.68) (writing took 7.052294263034128 seconds)
2023-08-24 03:34:29 | INFO | train_inner | epoch 005:    208 / 1474 loss=2.188, trans_loss=3.621, nll_loss=1.802, w2v_ctc_loss=1.275, task_loss=2.016, contrastive_loss=0, total=4184.8, n_correct=2298.72, ppl=3.49, accuracy=54.93, wps=10106.7, ups=0.81, wpb=12486.5, bsz=486.4, num_updates=6100, lr=0.000181071, gnorm=0.457, clip=0, loss_scale=16, train_wall=82, gb_free=16.5, wall=4763
2023-08-24 03:35:52 | INFO | train_inner | epoch 005:    308 / 1474 loss=2.199, trans_loss=3.617, nll_loss=1.802, w2v_ctc_loss=1.292, task_loss=2.216, contrastive_loss=0, total=4104.88, n_correct=2251.34, ppl=3.49, accuracy=54.845, wps=14681.5, ups=1.2, wpb=12271.4, bsz=449.2, num_updates=6200, lr=0.000179605, gnorm=0.467, clip=0, loss_scale=16, train_wall=83, gb_free=15.5, wall=4847
2023-08-24 03:37:17 | INFO | train_inner | epoch 005:    408 / 1474 loss=2.171, trans_loss=3.607, nll_loss=1.791, w2v_ctc_loss=1.257, task_loss=2.103, contrastive_loss=0, total=4146.85, n_correct=2290.79, ppl=3.46, accuracy=55.242, wps=14672.7, ups=1.18, wpb=12393.9, bsz=473.3, num_updates=6300, lr=0.000178174, gnorm=0.466, clip=0, loss_scale=16, train_wall=84, gb_free=15.9, wall=4931
2023-08-24 03:38:40 | INFO | train_inner | epoch 005:    508 / 1474 loss=2.19, trans_loss=3.623, nll_loss=1.809, w2v_ctc_loss=1.273, task_loss=2.454, contrastive_loss=0, total=4030.36, n_correct=2209.33, ppl=3.5, accuracy=54.817, wps=14422.5, ups=1.2, wpb=12039.6, bsz=417.1, num_updates=6400, lr=0.000176777, gnorm=0.466, clip=0, loss_scale=16, train_wall=83, gb_free=14.7, wall=5015
2023-08-24 03:40:04 | INFO | train_inner | epoch 005:    608 / 1474 loss=2.182, trans_loss=3.626, nll_loss=1.81, w2v_ctc_loss=1.261, task_loss=2.267, contrastive_loss=0, total=4110.02, n_correct=2259.5, ppl=3.51, accuracy=54.975, wps=14626, ups=1.19, wpb=12261.7, bsz=450.3, num_updates=6500, lr=0.000175412, gnorm=0.467, clip=0, loss_scale=16, train_wall=83, gb_free=16.8, wall=5099
2023-08-24 03:41:28 | INFO | train_inner | epoch 005:    708 / 1474 loss=2.175, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=1.26, task_loss=2.083, contrastive_loss=0, total=4163.49, n_correct=2299.14, ppl=3.5, accuracy=55.221, wps=14831.9, ups=1.19, wpb=12427.8, bsz=479, num_updates=6600, lr=0.000174078, gnorm=0.456, clip=0, loss_scale=16, train_wall=83, gb_free=11.6, wall=5182
2023-08-24 03:42:53 | INFO | train_inner | epoch 005:    808 / 1474 loss=2.172, trans_loss=3.622, nll_loss=1.805, w2v_ctc_loss=1.252, task_loss=2.253, contrastive_loss=0, total=4130.46, n_correct=2279.9, ppl=3.5, accuracy=55.197, wps=14540.2, ups=1.18, wpb=12327.4, bsz=448, num_updates=6700, lr=0.000172774, gnorm=0.457, clip=0, loss_scale=16, train_wall=84, gb_free=12.2, wall=5267
2023-08-24 03:44:16 | INFO | train_inner | epoch 005:    908 / 1474 loss=2.163, trans_loss=3.615, nll_loss=1.799, w2v_ctc_loss=1.248, task_loss=2.279, contrastive_loss=0, total=4091.87, n_correct=2266.66, ppl=3.48, accuracy=55.394, wps=14646.1, ups=1.2, wpb=12217.7, bsz=444, num_updates=6800, lr=0.000171499, gnorm=0.458, clip=0, loss_scale=16, train_wall=83, gb_free=15.1, wall=5351
2023-08-24 03:45:40 | INFO | train_inner | epoch 005:   1008 / 1474 loss=2.16, trans_loss=3.615, nll_loss=1.799, w2v_ctc_loss=1.245, task_loss=2.151, contrastive_loss=0, total=4164.94, n_correct=2311.69, ppl=3.48, accuracy=55.504, wps=14867.6, ups=1.2, wpb=12434.2, bsz=465, num_updates=6900, lr=0.000170251, gnorm=0.449, clip=0, loss_scale=16, train_wall=83, gb_free=15.7, wall=5434
2023-08-24 03:47:04 | INFO | train_inner | epoch 005:   1108 / 1474 loss=2.17, trans_loss=3.616, nll_loss=1.799, w2v_ctc_loss=1.257, task_loss=2.157, contrastive_loss=0, total=4176.06, n_correct=2319.21, ppl=3.48, accuracy=55.536, wps=14739.2, ups=1.18, wpb=12460.6, bsz=465.6, num_updates=7000, lr=0.000169031, gnorm=0.456, clip=0, loss_scale=16, train_wall=84, gb_free=16.8, wall=5519
2023-08-24 03:48:28 | INFO | train_inner | epoch 005:   1208 / 1474 loss=2.154, trans_loss=3.615, nll_loss=1.797, w2v_ctc_loss=1.235, task_loss=2.257, contrastive_loss=0, total=4160.61, n_correct=2321.67, ppl=3.47, accuracy=55.801, wps=14759.2, ups=1.19, wpb=12406.9, bsz=449.4, num_updates=7100, lr=0.000167836, gnorm=0.459, clip=0, loss_scale=16, train_wall=83, gb_free=16.6, wall=5603
2023-08-24 03:49:53 | INFO | train_inner | epoch 005:   1308 / 1474 loss=2.144, trans_loss=3.612, nll_loss=1.795, w2v_ctc_loss=1.221, task_loss=2.202, contrastive_loss=0, total=4145.72, n_correct=2306.32, ppl=3.47, accuracy=55.631, wps=14618.8, ups=1.18, wpb=12374.5, bsz=450.8, num_updates=7200, lr=0.000166667, gnorm=0.45, clip=0, loss_scale=32, train_wall=84, gb_free=17.5, wall=5687
2023-08-24 03:51:17 | INFO | train_inner | epoch 005:   1408 / 1474 loss=2.142, trans_loss=3.614, nll_loss=1.8, w2v_ctc_loss=1.219, task_loss=2.195, contrastive_loss=0, total=4134.3, n_correct=2301.52, ppl=3.48, accuracy=55.669, wps=14750.4, ups=1.19, wpb=12348.1, bsz=458.6, num_updates=7300, lr=0.000165521, gnorm=0.454, clip=0, loss_scale=32, train_wall=83, gb_free=17.5, wall=5771
2023-08-24 03:52:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 03:52:45 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.32 | trans_loss 5.78 | nll_loss 3.119 | w2v_ctc_loss 1.373 | task_loss 11.425 | contrastive_loss 0 | total 4003.4 | n_correct 2339.8 | ppl 8.69 | accuracy 58.445 | uer 21.238 | wer 22.844 | raw_wer 22.844 | bleu 17.82 | wps 1600.9 | wpb 4003.4 | bsz 141.8 | num_updates 7366 | best_bleu 17.82
2023-08-24 03:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7366 updates
2023-08-24 03:52:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 03:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 5 @ 7366 updates, score 17.82) (writing took 10.778137260000221 seconds)
2023-08-24 03:52:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-24 03:52:56 | INFO | train | epoch 005 | loss 2.17 | trans_loss 3.616 | nll_loss 1.8 | w2v_ctc_loss 1.253 | task_loss 2.185 | contrastive_loss 0 | total 4138.65 | n_correct 2289 | ppl 3.48 | accuracy 55.308 | wps 13706.1 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 7366 | lr 0.000164778 | gnorm 0.458 | clip 0 | loss_scale 32 | train_wall 1227 | gb_free 16.2 | wall 5871
2023-08-24 03:52:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 03:52:57 | INFO | fairseq.trainer | begin training epoch 6
2023-08-24 03:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 03:53:32 | INFO | train_inner | epoch 006:     34 / 1474 loss=2.128, trans_loss=3.59, nll_loss=1.766, w2v_ctc_loss=1.213, task_loss=2.224, contrastive_loss=0, total=4117.6, n_correct=2318.91, ppl=3.4, accuracy=56.317, wps=9079.1, ups=0.74, wpb=12284.3, bsz=450.3, num_updates=7400, lr=0.000164399, gnorm=0.46, clip=0, loss_scale=32, train_wall=83, gb_free=15.9, wall=5907
2023-08-24 03:54:56 | INFO | train_inner | epoch 006:    134 / 1474 loss=2.086, trans_loss=3.558, nll_loss=1.726, w2v_ctc_loss=1.17, task_loss=2.196, contrastive_loss=0, total=4143.22, n_correct=2365.73, ppl=3.31, accuracy=57.099, wps=14843, ups=1.2, wpb=12376.3, bsz=453.8, num_updates=7500, lr=0.000163299, gnorm=0.452, clip=0, loss_scale=32, train_wall=83, gb_free=16.4, wall=5990
2023-08-24 03:56:19 | INFO | train_inner | epoch 006:    234 / 1474 loss=2.111, trans_loss=3.571, nll_loss=1.744, w2v_ctc_loss=1.2, task_loss=2.351, contrastive_loss=0, total=4119.9, n_correct=2336.89, ppl=3.35, accuracy=56.722, wps=14807.5, ups=1.2, wpb=12310.3, bsz=438.5, num_updates=7600, lr=0.000162221, gnorm=0.453, clip=0, loss_scale=32, train_wall=83, gb_free=17, wall=6073
2023-08-24 03:57:44 | INFO | train_inner | epoch 006:    334 / 1474 loss=2.071, trans_loss=3.557, nll_loss=1.725, w2v_ctc_loss=1.151, task_loss=2.105, contrastive_loss=0, total=4147.01, n_correct=2375.55, ppl=3.31, accuracy=57.283, wps=14591.5, ups=1.18, wpb=12381.6, bsz=476, num_updates=7700, lr=0.000161165, gnorm=0.45, clip=0, loss_scale=32, train_wall=84, gb_free=17.3, wall=6158
2023-08-24 03:59:08 | INFO | train_inner | epoch 006:    434 / 1474 loss=2.074, trans_loss=3.561, nll_loss=1.732, w2v_ctc_loss=1.155, task_loss=2.028, contrastive_loss=0, total=4184.32, n_correct=2393.09, ppl=3.32, accuracy=57.192, wps=14805, ups=1.18, wpb=12495.1, bsz=485.6, num_updates=7800, lr=0.000160128, gnorm=0.451, clip=0, loss_scale=32, train_wall=84, gb_free=16.2, wall=6242
2023-08-24 04:00:31 | INFO | train_inner | epoch 006:    534 / 1474 loss=2.089, trans_loss=3.57, nll_loss=1.741, w2v_ctc_loss=1.173, task_loss=2.189, contrastive_loss=0, total=4170.23, n_correct=2387.01, ppl=3.34, accuracy=57.239, wps=14924.4, ups=1.2, wpb=12444.2, bsz=456, num_updates=7900, lr=0.000159111, gnorm=0.456, clip=0, loss_scale=32, train_wall=83, gb_free=16.4, wall=6326
2023-08-24 04:01:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-24 04:01:55 | INFO | train_inner | epoch 006:    635 / 1474 loss=2.082, trans_loss=3.571, nll_loss=1.744, w2v_ctc_loss=1.161, task_loss=2.101, contrastive_loss=0, total=4145.21, n_correct=2366.89, ppl=3.35, accuracy=57.099, wps=14726.7, ups=1.19, wpb=12373.6, bsz=466.4, num_updates=8000, lr=0.000158114, gnorm=0.448, clip=0, loss_scale=16, train_wall=83, gb_free=16.3, wall=6410
2023-08-24 04:01:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 04:02:28 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.304 | trans_loss 5.748 | nll_loss 3.073 | w2v_ctc_loss 1.393 | task_loss 11.28 | contrastive_loss 0 | total 4003.4 | n_correct 2353.2 | ppl 8.42 | accuracy 58.78 | uer 20.657 | wer 22.188 | raw_wer 22.188 | bleu 18 | wps 1665 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18
2023-08-24 04:02:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-24 04:02:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_8000.pt
2023-08-24 04:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_8000.pt
2023-08-24 04:02:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.0) (writing took 10.538525106967427 seconds)
2023-08-24 04:04:02 | INFO | train_inner | epoch 006:    735 / 1474 loss=2.089, trans_loss=3.573, nll_loss=1.747, w2v_ctc_loss=1.172, task_loss=2.213, contrastive_loss=0, total=4152.24, n_correct=2369.44, ppl=3.36, accuracy=57.064, wps=9759.7, ups=0.79, wpb=12398.2, bsz=455.7, num_updates=8100, lr=0.000157135, gnorm=0.452, clip=0, loss_scale=16, train_wall=83, gb_free=16.4, wall=6537
2023-08-24 04:05:26 | INFO | train_inner | epoch 006:    835 / 1474 loss=2.092, trans_loss=3.583, nll_loss=1.759, w2v_ctc_loss=1.167, task_loss=2.313, contrastive_loss=0, total=4110.55, n_correct=2337.13, ppl=3.39, accuracy=56.857, wps=14620.6, ups=1.19, wpb=12271.3, bsz=440.6, num_updates=8200, lr=0.000156174, gnorm=0.452, clip=0, loss_scale=16, train_wall=83, gb_free=15.7, wall=6621
2023-08-24 04:06:50 | INFO | train_inner | epoch 006:    935 / 1474 loss=2.092, trans_loss=3.583, nll_loss=1.76, w2v_ctc_loss=1.169, task_loss=2.272, contrastive_loss=0, total=4084.53, n_correct=2321.37, ppl=3.39, accuracy=56.833, wps=14513.7, ups=1.19, wpb=12190.9, bsz=445.3, num_updates=8300, lr=0.00015523, gnorm=0.455, clip=0, loss_scale=16, train_wall=83, gb_free=15.9, wall=6705
2023-08-24 04:08:14 | INFO | train_inner | epoch 006:   1035 / 1474 loss=2.07, trans_loss=3.567, nll_loss=1.74, w2v_ctc_loss=1.151, task_loss=2.088, contrastive_loss=0, total=4159.43, n_correct=2380.32, ppl=3.34, accuracy=57.227, wps=14830.4, ups=1.19, wpb=12417.6, bsz=475.9, num_updates=8400, lr=0.000154303, gnorm=0.456, clip=0, loss_scale=16, train_wall=83, gb_free=15.9, wall=6788
2023-08-24 04:09:37 | INFO | train_inner | epoch 006:   1135 / 1474 loss=2.09, trans_loss=3.575, nll_loss=1.75, w2v_ctc_loss=1.166, task_loss=2.415, contrastive_loss=0, total=4072.85, n_correct=2320.38, ppl=3.36, accuracy=56.972, wps=14589.6, ups=1.2, wpb=12158.5, bsz=428.8, num_updates=8500, lr=0.000153393, gnorm=0.457, clip=0, loss_scale=16, train_wall=83, gb_free=13.7, wall=6872
2023-08-24 04:11:02 | INFO | train_inner | epoch 006:   1235 / 1474 loss=2.071, trans_loss=3.566, nll_loss=1.741, w2v_ctc_loss=1.15, task_loss=2.14, contrastive_loss=0, total=4142.18, n_correct=2370.75, ppl=3.34, accuracy=57.234, wps=14649.1, ups=1.18, wpb=12371.6, bsz=473.3, num_updates=8600, lr=0.000152499, gnorm=0.452, clip=0, loss_scale=16, train_wall=84, gb_free=15.2, wall=6956
2023-08-24 04:12:24 | INFO | train_inner | epoch 006:   1335 / 1474 loss=2.07, trans_loss=3.573, nll_loss=1.746, w2v_ctc_loss=1.148, task_loss=2.165, contrastive_loss=0, total=4133.08, n_correct=2374.35, ppl=3.35, accuracy=57.447, wps=14942.8, ups=1.21, wpb=12329.2, bsz=455.6, num_updates=8700, lr=0.00015162, gnorm=0.449, clip=0, loss_scale=16, train_wall=82, gb_free=14.9, wall=7039
2023-08-24 04:13:49 | INFO | train_inner | epoch 006:   1435 / 1474 loss=2.067, trans_loss=3.566, nll_loss=1.74, w2v_ctc_loss=1.148, task_loss=2.198, contrastive_loss=0, total=4185.57, n_correct=2411.16, ppl=3.34, accuracy=57.606, wps=14777.2, ups=1.18, wpb=12495.1, bsz=459.6, num_updates=8800, lr=0.000150756, gnorm=0.445, clip=0, loss_scale=16, train_wall=84, gb_free=16.9, wall=7123
2023-08-24 04:14:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 04:14:54 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.27 | trans_loss 5.71 | nll_loss 3.028 | w2v_ctc_loss 1.366 | task_loss 11.451 | contrastive_loss 0 | total 4003.4 | n_correct 2380.7 | ppl 8.15 | accuracy 59.467 | uer 19.823 | wer 21.468 | raw_wer 21.468 | bleu 18.28 | wps 1613.9 | wpb 4003.4 | bsz 141.8 | num_updates 8839 | best_bleu 18.28
2023-08-24 04:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8839 updates
2023-08-24 04:14:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 04:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 04:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 6 @ 8839 updates, score 18.28) (writing took 11.126752728014253 seconds)
2023-08-24 04:15:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-24 04:15:05 | INFO | train | epoch 006 | loss 2.082 | trans_loss 3.569 | nll_loss 1.742 | w2v_ctc_loss 1.162 | task_loss 2.19 | contrastive_loss 0 | total 4138.46 | n_correct 2365.33 | ppl 3.34 | accuracy 57.155 | wps 13694.8 | ups 1.11 | wpb 12355.3 | bsz 458.3 | num_updates 8839 | lr 0.000150423 | gnorm 0.452 | clip 0 | loss_scale 16 | train_wall 1225 | gb_free 15 | wall 7200
2023-08-24 04:15:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 04:15:05 | INFO | fairseq.trainer | begin training epoch 7
2023-08-24 04:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 04:16:04 | INFO | train_inner | epoch 007:     61 / 1474 loss=2.039, trans_loss=3.545, nll_loss=1.712, w2v_ctc_loss=1.12, task_loss=2.135, contrastive_loss=0, total=4110.58, n_correct=2387.62, ppl=3.28, accuracy=58.085, wps=9087, ups=0.74, wpb=12271.6, bsz=461.4, num_updates=8900, lr=0.000149906, gnorm=0.451, clip=0, loss_scale=16, train_wall=83, gb_free=11.9, wall=7258
2023-08-24 04:17:27 | INFO | train_inner | epoch 007:    161 / 1474 loss=2.025, trans_loss=3.532, nll_loss=1.694, w2v_ctc_loss=1.103, task_loss=2.209, contrastive_loss=0, total=4110.69, n_correct=2399.55, ppl=3.24, accuracy=58.373, wps=14754.4, ups=1.2, wpb=12273, bsz=456.8, num_updates=9000, lr=0.000149071, gnorm=0.453, clip=0, loss_scale=16, train_wall=83, gb_free=17.1, wall=7342
2023-08-24 04:18:51 | INFO | train_inner | epoch 007:    261 / 1474 loss=2.026, trans_loss=3.53, nll_loss=1.69, w2v_ctc_loss=1.109, task_loss=2.232, contrastive_loss=0, total=4124.47, n_correct=2413.25, ppl=3.23, accuracy=58.511, wps=14765.1, ups=1.2, wpb=12308.3, bsz=448.9, num_updates=9100, lr=0.00014825, gnorm=0.452, clip=0, loss_scale=16, train_wall=83, gb_free=17.7, wall=7425
2023-08-24 04:20:15 | INFO | train_inner | epoch 007:    361 / 1474 loss=2.023, trans_loss=3.537, nll_loss=1.701, w2v_ctc_loss=1.101, task_loss=2.09, contrastive_loss=0, total=4211.96, n_correct=2453.39, ppl=3.25, accuracy=58.248, wps=14953.9, ups=1.19, wpb=12570.9, bsz=483.3, num_updates=9200, lr=0.000147442, gnorm=0.453, clip=0, loss_scale=16, train_wall=83, gb_free=16.8, wall=7509
2023-08-24 04:21:38 | INFO | train_inner | epoch 007:    461 / 1474 loss=2.021, trans_loss=3.537, nll_loss=1.703, w2v_ctc_loss=1.098, task_loss=2.155, contrastive_loss=0, total=4148.75, n_correct=2416.47, ppl=3.25, accuracy=58.246, wps=14867.3, ups=1.2, wpb=12390.2, bsz=464, num_updates=9300, lr=0.000146647, gnorm=0.448, clip=0, loss_scale=16, train_wall=83, gb_free=15.6, wall=7592
2023-08-24 04:23:02 | INFO | train_inner | epoch 007:    561 / 1474 loss=2.022, trans_loss=3.538, nll_loss=1.7, w2v_ctc_loss=1.1, task_loss=2.156, contrastive_loss=0, total=4163.25, n_correct=2432.99, ppl=3.25, accuracy=58.44, wps=14860.8, ups=1.2, wpb=12419.4, bsz=458.1, num_updates=9400, lr=0.000145865, gnorm=0.449, clip=0, loss_scale=16, train_wall=83, gb_free=15.4, wall=7676
2023-08-24 04:24:25 | INFO | train_inner | epoch 007:    661 / 1474 loss=2.018, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=1.094, task_loss=2.197, contrastive_loss=0, total=4148.73, n_correct=2426.16, ppl=3.25, accuracy=58.48, wps=14856, ups=1.2, wpb=12379.1, bsz=451.8, num_updates=9500, lr=0.000145095, gnorm=0.452, clip=0, loss_scale=16, train_wall=83, gb_free=16.1, wall=7759
2023-08-24 04:25:49 | INFO | train_inner | epoch 007:    761 / 1474 loss=2.02, trans_loss=3.532, nll_loss=1.696, w2v_ctc_loss=1.097, task_loss=2.272, contrastive_loss=0, total=4132.8, n_correct=2417.9, ppl=3.24, accuracy=58.505, wps=14601.1, ups=1.18, wpb=12341.2, bsz=449.9, num_updates=9600, lr=0.000144338, gnorm=0.449, clip=0, loss_scale=16, train_wall=84, gb_free=16.1, wall=7844
2023-08-24 04:27:14 | INFO | train_inner | epoch 007:    861 / 1474 loss=2.021, trans_loss=3.542, nll_loss=1.708, w2v_ctc_loss=1.098, task_loss=2.208, contrastive_loss=0, total=4150.73, n_correct=2424.87, ppl=3.27, accuracy=58.42, wps=14684.8, ups=1.19, wpb=12388.8, bsz=461.3, num_updates=9700, lr=0.000143592, gnorm=0.448, clip=0, loss_scale=16, train_wall=84, gb_free=10.8, wall=7928
2023-08-24 04:28:38 | INFO | train_inner | epoch 007:    961 / 1474 loss=2.011, trans_loss=3.536, nll_loss=1.702, w2v_ctc_loss=1.088, task_loss=2.099, contrastive_loss=0, total=4134.12, n_correct=2417.42, ppl=3.25, accuracy=58.475, wps=14722.9, ups=1.19, wpb=12340, bsz=471.7, num_updates=9800, lr=0.000142857, gnorm=0.451, clip=0, loss_scale=16, train_wall=83, gb_free=17.7, wall=8012
2023-08-24 04:30:01 | INFO | train_inner | epoch 007:   1061 / 1474 loss=2.022, trans_loss=3.546, nll_loss=1.714, w2v_ctc_loss=1.097, task_loss=2.259, contrastive_loss=0, total=4109.02, n_correct=2396.84, ppl=3.28, accuracy=58.331, wps=14659.6, ups=1.2, wpb=12266.8, bsz=441, num_updates=9900, lr=0.000142134, gnorm=0.452, clip=0, loss_scale=16, train_wall=83, gb_free=15.5, wall=8096
2023-08-24 04:31:25 | INFO | train_inner | epoch 007:   1161 / 1474 loss=2.015, trans_loss=3.535, nll_loss=1.704, w2v_ctc_loss=1.093, task_loss=2.144, contrastive_loss=0, total=4133.4, n_correct=2413.7, ppl=3.26, accuracy=58.395, wps=14699.3, ups=1.19, wpb=12352.8, bsz=469.7, num_updates=10000, lr=0.000141421, gnorm=0.46, clip=0, loss_scale=16, train_wall=83, gb_free=16.5, wall=8180
2023-08-24 04:31:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 04:31:58 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.678 | nll_loss 2.982 | w2v_ctc_loss 1.331 | task_loss 11.453 | contrastive_loss 0 | total 4003.4 | n_correct 2400.1 | ppl 7.9 | accuracy 59.952 | uer 18.708 | wer 20.391 | raw_wer 20.391 | bleu 18.84 | wps 1642.4 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.84
2023-08-24 04:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-24 04:31:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_10000.pt
2023-08-24 04:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_10000.pt
2023-08-24 04:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.84) (writing took 11.983996105962433 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 04:33:33 | INFO | train_inner | epoch 007:   1261 / 1474 loss=2.009, trans_loss=3.541, nll_loss=1.709, w2v_ctc_loss=1.082, task_loss=2.237, contrastive_loss=0, total=4122.48, n_correct=2407.24, ppl=3.27, accuracy=58.393, wps=9654.2, ups=0.78, wpb=12309.6, bsz=446.8, num_updates=10100, lr=0.00014072, gnorm=0.376, clip=0, loss_scale=32, train_wall=82, gb_free=17.3, wall=8307
2023-08-24 04:34:56 | INFO | train_inner | epoch 007:   1361 / 1474 loss=2.015, trans_loss=3.534, nll_loss=1.7, w2v_ctc_loss=1.096, task_loss=2.036, contrastive_loss=0, total=4184.94, n_correct=2460.16, ppl=3.25, accuracy=58.786, wps=14933.1, ups=1.2, wpb=12492.2, bsz=479.3, num_updates=10200, lr=0.000140028, gnorm=0.372, clip=0, loss_scale=32, train_wall=83, gb_free=15.7, wall=8391
2023-08-24 04:36:22 | INFO | train_inner | epoch 007:   1461 / 1474 loss=2.018, trans_loss=3.538, nll_loss=1.709, w2v_ctc_loss=1.094, task_loss=2.355, contrastive_loss=0, total=4105.52, n_correct=2395.8, ppl=3.27, accuracy=58.356, wps=14401.5, ups=1.17, wpb=12267.8, bsz=443.4, num_updates=10300, lr=0.000139347, gnorm=0.383, clip=0, loss_scale=32, train_wall=85, gb_free=16.1, wall=8476
2023-08-24 04:36:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
2023-08-24 04:37:05 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.233 | trans_loss 5.672 | nll_loss 2.978 | w2v_ctc_loss 1.327 | task_loss 11.432 | contrastive_loss 0 | total 4003.4 | n_correct 2403.3 | ppl 7.88 | accuracy 60.031 | uer 18.926 | wer 20.667 | raw_wer 20.667 | bleu 18.73 | wps 1616.3 | wpb 4003.4 | bsz 141.8 | num_updates 10313 | best_bleu 18.84
2023-08-24 04:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10313 updates
2023-08-24 04:37:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_18.7303.pt
2023-08-24 04:37:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_18.7303.pt
2023-08-24 04:37:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_18.7303.pt (epoch 7 @ 10313 updates, score 18.73) (writing took 6.083382473094389 seconds)
2023-08-24 04:37:12 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-24 04:37:12 | INFO | train | epoch 007 | loss 2.019 | trans_loss 3.536 | nll_loss 1.702 | w2v_ctc_loss 1.097 | task_loss 2.189 | contrastive_loss 0 | total 4138.65 | n_correct 2418.15 | ppl 3.25 | accuracy 58.429 | wps 13731.3 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 10313 | lr 0.000139259 | gnorm 0.436 | clip 0 | loss_scale 32 | train_wall 1225 | gb_free 13 | wall 8526
2023-08-24 04:37:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 04:37:12 | INFO | fairseq.trainer | begin training epoch 8
2023-08-24 04:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 04:38:33 | INFO | train_inner | epoch 008:     87 / 1474 loss=1.982, trans_loss=3.515, nll_loss=1.67, w2v_ctc_loss=1.058, task_loss=2.281, contrastive_loss=0, total=4123.81, n_correct=2447.27, ppl=3.18, accuracy=59.345, wps=9379.4, ups=0.76, wpb=12296.3, bsz=446.4, num_updates=10400, lr=0.000138675, gnorm=0.377, clip=0, loss_scale=32, train_wall=83, gb_free=15.1, wall=8607
2023-08-24 04:39:56 | INFO | train_inner | epoch 008:    187 / 1474 loss=1.979, trans_loss=3.509, nll_loss=1.662, w2v_ctc_loss=1.054, task_loss=2.42, contrastive_loss=0, total=4025.52, n_correct=2389.49, ppl=3.16, accuracy=59.359, wps=14387.4, ups=1.2, wpb=12006.1, bsz=423.4, num_updates=10500, lr=0.000138013, gnorm=0.384, clip=0, loss_scale=32, train_wall=83, gb_free=13.5, wall=8691
2023-08-24 04:41:20 | INFO | train_inner | epoch 008:    287 / 1474 loss=1.971, trans_loss=3.502, nll_loss=1.657, w2v_ctc_loss=1.052, task_loss=2.031, contrastive_loss=0, total=4211.24, n_correct=2508.89, ppl=3.15, accuracy=59.576, wps=15053.6, ups=1.2, wpb=12567.1, bsz=491.5, num_updates=10600, lr=0.000137361, gnorm=0.379, clip=0, loss_scale=32, train_wall=83, gb_free=16.6, wall=8774
2023-08-24 04:42:44 | INFO | train_inner | epoch 008:    387 / 1474 loss=1.992, trans_loss=3.514, nll_loss=1.671, w2v_ctc_loss=1.072, task_loss=2.34, contrastive_loss=0, total=4126.7, n_correct=2442.5, ppl=3.19, accuracy=59.188, wps=14583.3, ups=1.18, wpb=12315.4, bsz=439.4, num_updates=10700, lr=0.000136717, gnorm=0.379, clip=0, loss_scale=32, train_wall=84, gb_free=9.4, wall=8858
2023-08-24 04:44:08 | INFO | train_inner | epoch 008:    487 / 1474 loss=1.969, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.045, task_loss=1.972, contrastive_loss=0, total=4196.99, n_correct=2493.62, ppl=3.17, accuracy=59.414, wps=14866.7, ups=1.19, wpb=12526, bsz=503, num_updates=10800, lr=0.000136083, gnorm=0.374, clip=0, loss_scale=32, train_wall=84, gb_free=16.5, wall=8943
2023-08-24 04:45:32 | INFO | train_inner | epoch 008:    587 / 1474 loss=1.986, trans_loss=3.508, nll_loss=1.67, w2v_ctc_loss=1.066, task_loss=2.333, contrastive_loss=0, total=4070.43, n_correct=2412.54, ppl=3.18, accuracy=59.27, wps=14488.9, ups=1.19, wpb=12169.7, bsz=433.3, num_updates=10900, lr=0.000135457, gnorm=0.383, clip=0, loss_scale=32, train_wall=83, gb_free=17.2, wall=9027
2023-08-24 04:46:57 | INFO | train_inner | epoch 008:    687 / 1474 loss=1.985, trans_loss=3.509, nll_loss=1.666, w2v_ctc_loss=1.067, task_loss=2.281, contrastive_loss=0, total=4143.18, n_correct=2463.52, ppl=3.17, accuracy=59.46, wps=14590.9, ups=1.18, wpb=12365.1, bsz=447.1, num_updates=11000, lr=0.00013484, gnorm=0.376, clip=0, loss_scale=32, train_wall=84, gb_free=12.8, wall=9111
2023-08-24 04:48:20 | INFO | train_inner | epoch 008:    787 / 1474 loss=1.976, trans_loss=3.506, nll_loss=1.668, w2v_ctc_loss=1.056, task_loss=2.258, contrastive_loss=0, total=4119.53, n_correct=2449.36, ppl=3.18, accuracy=59.457, wps=14776, ups=1.2, wpb=12314.2, bsz=446.2, num_updates=11100, lr=0.000134231, gnorm=0.38, clip=0, loss_scale=32, train_wall=83, gb_free=16.2, wall=9195
2023-08-24 04:49:44 | INFO | train_inner | epoch 008:    887 / 1474 loss=1.968, trans_loss=3.508, nll_loss=1.669, w2v_ctc_loss=1.046, task_loss=2.129, contrastive_loss=0, total=4154.7, n_correct=2473.31, ppl=3.18, accuracy=59.53, wps=14785.1, ups=1.19, wpb=12408, bsz=468.7, num_updates=11200, lr=0.000133631, gnorm=0.38, clip=0, loss_scale=32, train_wall=83, gb_free=16.3, wall=9279
2023-08-24 04:51:08 | INFO | train_inner | epoch 008:    987 / 1474 loss=1.967, trans_loss=3.508, nll_loss=1.668, w2v_ctc_loss=1.044, task_loss=2.05, contrastive_loss=0, total=4170.42, n_correct=2488.68, ppl=3.18, accuracy=59.675, wps=14972.9, ups=1.2, wpb=12451.9, bsz=471.9, num_updates=11300, lr=0.000133038, gnorm=0.375, clip=0, loss_scale=32, train_wall=83, gb_free=12.8, wall=9362
2023-08-24 04:52:32 | INFO | train_inner | epoch 008:   1087 / 1474 loss=1.975, trans_loss=3.518, nll_loss=1.68, w2v_ctc_loss=1.049, task_loss=2.186, contrastive_loss=0, total=4195.51, n_correct=2479.59, ppl=3.2, accuracy=59.101, wps=14811.4, ups=1.18, wpb=12522.2, bsz=464.1, num_updates=11400, lr=0.000132453, gnorm=0.382, clip=0, loss_scale=32, train_wall=84, gb_free=12, wall=9446
2023-08-24 04:53:55 | INFO | train_inner | epoch 008:   1187 / 1474 loss=1.971, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=1.049, task_loss=2.107, contrastive_loss=0, total=4164.98, n_correct=2481.14, ppl=3.18, accuracy=59.571, wps=14951.3, ups=1.2, wpb=12440.1, bsz=466, num_updates=11500, lr=0.000131876, gnorm=0.374, clip=0, loss_scale=32, train_wall=83, gb_free=15.4, wall=9530
2023-08-24 04:55:18 | INFO | train_inner | epoch 008:   1287 / 1474 loss=1.98, trans_loss=3.512, nll_loss=1.675, w2v_ctc_loss=1.06, task_loss=2.235, contrastive_loss=0, total=4079.71, n_correct=2417.44, ppl=3.19, accuracy=59.255, wps=14684.8, ups=1.2, wpb=12187.6, bsz=446.2, num_updates=11600, lr=0.000131306, gnorm=0.383, clip=0, loss_scale=32, train_wall=82, gb_free=10.4, wall=9613
2023-08-24 04:56:42 | INFO | train_inner | epoch 008:   1387 / 1474 loss=1.978, trans_loss=3.518, nll_loss=1.683, w2v_ctc_loss=1.053, task_loss=2.177, contrastive_loss=0, total=4143.1, n_correct=2459.14, ppl=3.21, accuracy=59.355, wps=14821.2, ups=1.2, wpb=12373.5, bsz=459.8, num_updates=11700, lr=0.000130744, gnorm=0.377, clip=0, loss_scale=32, train_wall=83, gb_free=11.7, wall=9696
2023-08-24 04:57:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 04:58:27 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.219 | trans_loss 5.642 | nll_loss 2.936 | w2v_ctc_loss 1.347 | task_loss 11.497 | contrastive_loss 0 | total 4003.4 | n_correct 2426.6 | ppl 7.65 | accuracy 60.613 | uer 18.342 | wer 20.119 | raw_wer 20.119 | bleu 19.21 | wps 1650.1 | wpb 4003.4 | bsz 141.8 | num_updates 11787 | best_bleu 19.21
2023-08-24 04:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11787 updates
2023-08-24 04:58:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 04:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 04:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 8 @ 11787 updates, score 19.21) (writing took 13.714572317083366 seconds)
2023-08-24 04:58:41 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-24 04:58:41 | INFO | train | epoch 008 | loss 1.976 | trans_loss 3.511 | nll_loss 1.67 | w2v_ctc_loss 1.054 | task_loss 2.19 | contrastive_loss 0 | total 4138.65 | n_correct 2458.58 | ppl 3.18 | accuracy 59.405 | wps 14123.6 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 11787 | lr 0.000130261 | gnorm 0.379 | clip 0 | loss_scale 32 | train_wall 1225 | gb_free 16.7 | wall 9815
2023-08-24 04:58:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 04:58:41 | INFO | fairseq.trainer | begin training epoch 9
2023-08-24 04:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 04:58:59 | INFO | train_inner | epoch 009:     13 / 1474 loss=1.96, trans_loss=3.512, nll_loss=1.671, w2v_ctc_loss=1.033, task_loss=2.162, contrastive_loss=0, total=4119.86, n_correct=2453.24, ppl=3.18, accuracy=59.547, wps=8946.5, ups=0.73, wpb=12291, bsz=465.6, num_updates=11800, lr=0.000130189, gnorm=0.381, clip=0, loss_scale=32, train_wall=83, gb_free=16.9, wall=9834
2023-08-24 05:00:23 | INFO | train_inner | epoch 009:    113 / 1474 loss=1.929, trans_loss=3.474, nll_loss=1.624, w2v_ctc_loss=1.01, task_loss=2.072, contrastive_loss=0, total=4182.81, n_correct=2537.16, ppl=3.08, accuracy=60.657, wps=14944.4, ups=1.2, wpb=12492, bsz=477.5, num_updates=11900, lr=0.000129641, gnorm=0.376, clip=0, loss_scale=32, train_wall=83, gb_free=16.8, wall=9917
2023-08-24 05:01:47 | INFO | train_inner | epoch 009:    213 / 1474 loss=1.936, trans_loss=3.479, nll_loss=1.63, w2v_ctc_loss=1.013, task_loss=2.326, contrastive_loss=0, total=4078.8, n_correct=2465.32, ppl=3.09, accuracy=60.442, wps=14544.7, ups=1.19, wpb=12179.2, bsz=438.1, num_updates=12000, lr=0.000129099, gnorm=0.384, clip=0, loss_scale=32, train_wall=83, gb_free=10.7, wall=10001
2023-08-24 05:01:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 05:02:19 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.65 | nll_loss 2.948 | w2v_ctc_loss 1.299 | task_loss 11.474 | contrastive_loss 0 | total 4003.4 | n_correct 2418.1 | ppl 7.72 | accuracy 60.401 | uer 18.35 | wer 20.174 | raw_wer 20.174 | bleu 18.96 | wps 1664.2 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.21
2023-08-24 05:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-24 05:02:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_12000.pt
2023-08-24 05:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_12000.pt
2023-08-24 05:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.96) (writing took 7.950542301055975 seconds)
2023-08-24 05:03:51 | INFO | train_inner | epoch 009:    313 / 1474 loss=1.92, trans_loss=3.469, nll_loss=1.619, w2v_ctc_loss=1.001, task_loss=2.053, contrastive_loss=0, total=4147, n_correct=2517.94, ppl=3.07, accuracy=60.717, wps=9996.2, ups=0.81, wpb=12390.6, bsz=475.2, num_updates=12100, lr=0.000128565, gnorm=0.377, clip=0, loss_scale=64, train_wall=82, gb_free=17.6, wall=10125
2023-08-24 05:05:15 | INFO | train_inner | epoch 009:    413 / 1474 loss=1.934, trans_loss=3.485, nll_loss=1.638, w2v_ctc_loss=1.011, task_loss=2.155, contrastive_loss=0, total=4199.03, n_correct=2530.33, ppl=3.11, accuracy=60.26, wps=14847.2, ups=1.18, wpb=12539.2, bsz=468.6, num_updates=12200, lr=0.000128037, gnorm=0.376, clip=0, loss_scale=64, train_wall=84, gb_free=16.7, wall=10209
2023-08-24 05:06:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 05:06:39 | INFO | train_inner | epoch 009:    514 / 1474 loss=1.952, trans_loss=3.49, nll_loss=1.642, w2v_ctc_loss=1.03, task_loss=2.325, contrastive_loss=0, total=4104.26, n_correct=2469.52, ppl=3.12, accuracy=60.17, wps=14612.5, ups=1.19, wpb=12248.8, bsz=432.2, num_updates=12300, lr=0.000127515, gnorm=0.38, clip=0, loss_scale=32, train_wall=83, gb_free=15.1, wall=10293
2023-08-24 05:08:03 | INFO | train_inner | epoch 009:    614 / 1474 loss=1.932, trans_loss=3.482, nll_loss=1.637, w2v_ctc_loss=1.009, task_loss=2.246, contrastive_loss=0, total=4124.71, n_correct=2487.85, ppl=3.11, accuracy=60.316, wps=14610.5, ups=1.19, wpb=12328.1, bsz=452.6, num_updates=12400, lr=0.000127, gnorm=0.378, clip=0, loss_scale=32, train_wall=84, gb_free=17.3, wall=10378
2023-08-24 05:09:27 | INFO | train_inner | epoch 009:    714 / 1474 loss=1.95, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.029, task_loss=2.252, contrastive_loss=0, total=4077.28, n_correct=2449.92, ppl=3.14, accuracy=60.087, wps=14590.4, ups=1.2, wpb=12181.2, bsz=448.7, num_updates=12500, lr=0.000126491, gnorm=0.385, clip=0, loss_scale=32, train_wall=83, gb_free=17.1, wall=10461
2023-08-24 05:10:51 | INFO | train_inner | epoch 009:    814 / 1474 loss=1.937, trans_loss=3.484, nll_loss=1.642, w2v_ctc_loss=1.018, task_loss=1.962, contrastive_loss=0, total=4233.18, n_correct=2548.38, ppl=3.12, accuracy=60.2, wps=15046, ups=1.19, wpb=12650.2, bsz=504.7, num_updates=12600, lr=0.000125988, gnorm=0.374, clip=0, loss_scale=32, train_wall=83, gb_free=15.1, wall=10545
2023-08-24 05:12:15 | INFO | train_inner | epoch 009:    914 / 1474 loss=1.942, trans_loss=3.492, nll_loss=1.645, w2v_ctc_loss=1.018, task_loss=2.274, contrastive_loss=0, total=4136.02, n_correct=2487.94, ppl=3.13, accuracy=60.153, wps=14628.7, ups=1.19, wpb=12341.6, bsz=448.1, num_updates=12700, lr=0.000125491, gnorm=0.377, clip=0, loss_scale=32, train_wall=84, gb_free=12.8, wall=10629
2023-08-24 05:13:39 | INFO | train_inner | epoch 009:   1014 / 1474 loss=1.951, trans_loss=3.498, nll_loss=1.654, w2v_ctc_loss=1.025, task_loss=2.428, contrastive_loss=0, total=4101.79, n_correct=2458.09, ppl=3.15, accuracy=59.927, wps=14584.8, ups=1.19, wpb=12242.8, bsz=425.5, num_updates=12800, lr=0.000125, gnorm=0.387, clip=0, loss_scale=32, train_wall=83, gb_free=16.5, wall=10713
2023-08-24 05:15:02 | INFO | train_inner | epoch 009:   1114 / 1474 loss=1.94, trans_loss=3.496, nll_loss=1.649, w2v_ctc_loss=1.015, task_loss=2.066, contrastive_loss=0, total=4179.48, n_correct=2520.85, ppl=3.14, accuracy=60.315, wps=14959, ups=1.2, wpb=12459.2, bsz=475.5, num_updates=12900, lr=0.000124515, gnorm=0.378, clip=0, loss_scale=32, train_wall=83, gb_free=17.4, wall=10797
2023-08-24 05:16:27 | INFO | train_inner | epoch 009:   1214 / 1474 loss=1.956, trans_loss=3.498, nll_loss=1.656, w2v_ctc_loss=1.035, task_loss=2.323, contrastive_loss=0, total=4147.82, n_correct=2484.47, ppl=3.15, accuracy=59.898, wps=14642.7, ups=1.18, wpb=12380.9, bsz=447.6, num_updates=13000, lr=0.000124035, gnorm=0.38, clip=0, loss_scale=32, train_wall=84, gb_free=16.1, wall=10881
2023-08-24 05:17:50 | INFO | train_inner | epoch 009:   1314 / 1474 loss=1.932, trans_loss=3.491, nll_loss=1.648, w2v_ctc_loss=1.009, task_loss=1.983, contrastive_loss=0, total=4204.88, n_correct=2535.67, ppl=3.13, accuracy=60.303, wps=15097.4, ups=1.2, wpb=12549.3, bsz=493, num_updates=13100, lr=0.00012356, gnorm=0.375, clip=0, loss_scale=32, train_wall=82, gb_free=16.9, wall=10964
2023-08-24 05:19:13 | INFO | train_inner | epoch 009:   1414 / 1474 loss=1.952, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.025, task_loss=2.384, contrastive_loss=0, total=4075, n_correct=2443.58, ppl=3.16, accuracy=59.965, wps=14584.9, ups=1.2, wpb=12158.5, bsz=427.2, num_updates=13200, lr=0.000123091, gnorm=0.381, clip=0, loss_scale=32, train_wall=83, gb_free=12.6, wall=11048
2023-08-24 05:20:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 05:20:35 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.625 | nll_loss 2.92 | w2v_ctc_loss 1.318 | task_loss 11.506 | contrastive_loss 0 | total 4003.4 | n_correct 2429.4 | ppl 7.57 | accuracy 60.683 | uer 18.162 | wer 19.824 | raw_wer 19.824 | bleu 19.12 | wps 1655.7 | wpb 4003.4 | bsz 141.8 | num_updates 13260 | best_bleu 19.21
2023-08-24 05:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13260 updates
2023-08-24 05:20:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.1200.pt
2023-08-24 05:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.1200.pt
2023-08-24 05:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.1200.pt (epoch 9 @ 13260 updates, score 19.12) (writing took 7.120951111079194 seconds)
2023-08-24 05:20:42 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-24 05:20:42 | INFO | train | epoch 009 | loss 1.94 | trans_loss 3.488 | nll_loss 1.643 | w2v_ctc_loss 1.018 | task_loss 2.195 | contrastive_loss 0 | total 4137.53 | n_correct 2492.73 | ppl 3.12 | accuracy 60.247 | wps 13770.7 | ups 1.11 | wpb 12352.5 | bsz 458 | num_updates 13260 | lr 0.000122813 | gnorm 0.379 | clip 0 | loss_scale 32 | train_wall 1222 | gb_free 11.4 | wall 11137
2023-08-24 05:20:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 05:20:43 | INFO | fairseq.trainer | begin training epoch 10
2023-08-24 05:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 05:21:23 | INFO | train_inner | epoch 010:     40 / 1474 loss=1.923, trans_loss=3.482, nll_loss=1.635, w2v_ctc_loss=1.001, task_loss=2.092, contrastive_loss=0, total=4088.59, n_correct=2478.15, ppl=3.11, accuracy=60.611, wps=9400.2, ups=0.77, wpb=12204, bsz=467.6, num_updates=13300, lr=0.000122628, gnorm=0.379, clip=0, loss_scale=32, train_wall=82, gb_free=16.8, wall=11178
2023-08-24 05:22:47 | INFO | train_inner | epoch 010:    140 / 1474 loss=1.895, trans_loss=3.454, nll_loss=1.6, w2v_ctc_loss=0.974, task_loss=2.068, contrastive_loss=0, total=4241, n_correct=2601.05, ppl=3.03, accuracy=61.331, wps=15092.5, ups=1.19, wpb=12666.9, bsz=480.3, num_updates=13400, lr=0.000122169, gnorm=0.37, clip=0, loss_scale=32, train_wall=83, gb_free=16, wall=11262
2023-08-24 05:24:11 | INFO | train_inner | epoch 010:    240 / 1474 loss=1.905, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=0.985, task_loss=2.16, contrastive_loss=0, total=4135.58, n_correct=2531.33, ppl=3.04, accuracy=61.209, wps=14722.2, ups=1.19, wpb=12340.9, bsz=462.8, num_updates=13500, lr=0.000121716, gnorm=0.377, clip=0, loss_scale=32, train_wall=83, gb_free=12.6, wall=11345
2023-08-24 05:25:35 | INFO | train_inner | epoch 010:    340 / 1474 loss=1.899, trans_loss=3.458, nll_loss=1.608, w2v_ctc_loss=0.977, task_loss=2.215, contrastive_loss=0, total=4128.98, n_correct=2523.33, ppl=3.05, accuracy=61.113, wps=14670.2, ups=1.19, wpb=12340.4, bsz=453.3, num_updates=13600, lr=0.000121268, gnorm=0.379, clip=0, loss_scale=32, train_wall=84, gb_free=17.3, wall=11429
2023-08-24 05:26:59 | INFO | train_inner | epoch 010:    440 / 1474 loss=1.894, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=0.967, task_loss=2.111, contrastive_loss=0, total=4204.32, n_correct=2569.16, ppl=3.06, accuracy=61.108, wps=14891.4, ups=1.19, wpb=12552.3, bsz=481.2, num_updates=13700, lr=0.000120824, gnorm=0.375, clip=0, loss_scale=32, train_wall=84, gb_free=15, wall=11514
2023-08-24 05:28:23 | INFO | train_inner | epoch 010:    540 / 1474 loss=1.925, trans_loss=3.478, nll_loss=1.625, w2v_ctc_loss=1.004, task_loss=2.337, contrastive_loss=0, total=4105.89, n_correct=2496.34, ppl=3.09, accuracy=60.799, wps=14564.4, ups=1.19, wpb=12242.4, bsz=439.7, num_updates=13800, lr=0.000120386, gnorm=0.381, clip=0, loss_scale=32, train_wall=83, gb_free=16.6, wall=11598
2023-08-24 05:29:47 | INFO | train_inner | epoch 010:    640 / 1474 loss=1.915, trans_loss=3.47, nll_loss=1.62, w2v_ctc_loss=0.994, task_loss=2.08, contrastive_loss=0, total=4173.95, n_correct=2544.85, ppl=3.07, accuracy=60.97, wps=14867.5, ups=1.19, wpb=12457.5, bsz=477.3, num_updates=13900, lr=0.000119952, gnorm=0.382, clip=0, loss_scale=32, train_wall=83, gb_free=17.6, wall=11682
2023-08-24 05:31:11 | INFO | train_inner | epoch 010:    740 / 1474 loss=1.926, trans_loss=3.475, nll_loss=1.625, w2v_ctc_loss=1.008, task_loss=2.217, contrastive_loss=0, total=4121.45, n_correct=2505.08, ppl=3.09, accuracy=60.782, wps=14709.2, ups=1.2, wpb=12301.6, bsz=451.9, num_updates=14000, lr=0.000119523, gnorm=0.386, clip=0, loss_scale=32, train_wall=83, gb_free=16.2, wall=11765
2023-08-24 05:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 05:31:43 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.62 | nll_loss 2.913 | w2v_ctc_loss 1.311 | task_loss 11.472 | contrastive_loss 0 | total 4003.4 | n_correct 2444.2 | ppl 7.53 | accuracy 61.053 | uer 18.345 | wer 20.204 | raw_wer 20.204 | bleu 19.4 | wps 1667.4 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.4
2023-08-24 05:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-24 05:31:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_10_14000.pt
2023-08-24 05:31:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_10_14000.pt
2023-08-24 05:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.4) (writing took 11.95630216889549 seconds)
2023-08-24 05:33:20 | INFO | train_inner | epoch 010:    840 / 1474 loss=1.904, trans_loss=3.468, nll_loss=1.62, w2v_ctc_loss=0.98, task_loss=2.162, contrastive_loss=0, total=4126.74, n_correct=2517.31, ppl=3.07, accuracy=61, wps=9551.1, ups=0.77, wpb=12324.6, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.375, clip=0, loss_scale=32, train_wall=83, gb_free=15.7, wall=11894
2023-08-24 05:34:43 | INFO | train_inner | epoch 010:    940 / 1474 loss=1.91, trans_loss=3.472, nll_loss=1.62, w2v_ctc_loss=0.988, task_loss=2.087, contrastive_loss=0, total=4169.25, n_correct=2541.85, ppl=3.07, accuracy=60.967, wps=15061.5, ups=1.21, wpb=12434.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.38, clip=0, loss_scale=32, train_wall=82, gb_free=17.2, wall=11977
2023-08-24 05:36:06 | INFO | train_inner | epoch 010:   1040 / 1474 loss=1.919, trans_loss=3.474, nll_loss=1.625, w2v_ctc_loss=0.995, task_loss=2.373, contrastive_loss=0, total=4076.84, n_correct=2473.83, ppl=3.09, accuracy=60.68, wps=14548.4, ups=1.2, wpb=12174.2, bsz=435.5, num_updates=14300, lr=0.000118262, gnorm=0.384, clip=0, loss_scale=32, train_wall=83, gb_free=16.5, wall=12061
2023-08-24 05:37:29 | INFO | train_inner | epoch 010:   1140 / 1474 loss=1.932, trans_loss=3.484, nll_loss=1.638, w2v_ctc_loss=1.008, task_loss=2.451, contrastive_loss=0, total=4035.21, n_correct=2438.8, ppl=3.11, accuracy=60.438, wps=14507.9, ups=1.2, wpb=12044.6, bsz=419.5, num_updates=14400, lr=0.000117851, gnorm=0.384, clip=0, loss_scale=64, train_wall=82, gb_free=16.8, wall=12144
2023-08-24 05:38:53 | INFO | train_inner | epoch 010:   1240 / 1474 loss=1.917, trans_loss=3.467, nll_loss=1.622, w2v_ctc_loss=0.998, task_loss=2.253, contrastive_loss=0, total=4099.89, n_correct=2497.06, ppl=3.08, accuracy=60.906, wps=14631.9, ups=1.19, wpb=12263, bsz=444.4, num_updates=14500, lr=0.000117444, gnorm=0.383, clip=0, loss_scale=64, train_wall=83, gb_free=17.2, wall=12227
2023-08-24 05:40:17 | INFO | train_inner | epoch 010:   1340 / 1474 loss=1.917, trans_loss=3.478, nll_loss=1.633, w2v_ctc_loss=0.994, task_loss=2.244, contrastive_loss=0, total=4126.18, n_correct=2506.09, ppl=3.1, accuracy=60.736, wps=14700.1, ups=1.19, wpb=12320.3, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.38, clip=0, loss_scale=64, train_wall=83, gb_free=16.4, wall=12311
2023-08-24 05:41:41 | INFO | train_inner | epoch 010:   1440 / 1474 loss=1.907, trans_loss=3.484, nll_loss=1.639, w2v_ctc_loss=0.978, task_loss=2.045, contrastive_loss=0, total=4198.18, n_correct=2546.36, ppl=3.11, accuracy=60.654, wps=14953.4, ups=1.19, wpb=12524.3, bsz=484.3, num_updates=14700, lr=0.000116642, gnorm=0.376, clip=0, loss_scale=64, train_wall=83, gb_free=12.2, wall=12395
2023-08-24 05:42:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 05:42:41 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.608 | nll_loss 2.898 | w2v_ctc_loss 1.348 | task_loss 11.49 | contrastive_loss 0 | total 4003.4 | n_correct 2447 | ppl 7.45 | accuracy 61.123 | uer 17.88 | wer 19.727 | raw_wer 19.727 | bleu 19.61 | wps 1625 | wpb 4003.4 | bsz 141.8 | num_updates 14734 | best_bleu 19.61
2023-08-24 05:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14734 updates
2023-08-24 05:42:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 05:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 05:42:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 10 @ 14734 updates, score 19.61) (writing took 10.953985142987221 seconds)
2023-08-24 05:42:53 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-24 05:42:53 | INFO | train | epoch 010 | loss 1.911 | trans_loss 3.47 | nll_loss 1.62 | w2v_ctc_loss 0.988 | task_loss 2.192 | contrastive_loss 0 | total 4138.65 | n_correct 2521.11 | ppl 3.07 | accuracy 60.916 | wps 13688.9 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 14734 | lr 0.000116508 | gnorm 0.379 | clip 0 | loss_scale 64 | train_wall 1224 | gb_free 17.1 | wall 12467
2023-08-24 05:42:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 05:42:53 | INFO | fairseq.trainer | begin training epoch 11
2023-08-24 05:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 05:43:54 | INFO | train_inner | epoch 011:     66 / 1474 loss=1.884, trans_loss=3.448, nll_loss=1.591, w2v_ctc_loss=0.965, task_loss=2.046, contrastive_loss=0, total=4166.62, n_correct=2571.73, ppl=3.01, accuracy=61.722, wps=9302.3, ups=0.75, wpb=12438, bsz=477.4, num_updates=14800, lr=0.000116248, gnorm=0.378, clip=0, loss_scale=64, train_wall=81, gb_free=15.5, wall=12529
2023-08-24 05:45:17 | INFO | train_inner | epoch 011:    166 / 1474 loss=1.887, trans_loss=3.448, nll_loss=1.593, w2v_ctc_loss=0.967, task_loss=2.268, contrastive_loss=0, total=4086.7, n_correct=2517.74, ppl=3.02, accuracy=61.608, wps=14681.3, ups=1.2, wpb=12209.9, bsz=443.6, num_updates=14900, lr=0.000115857, gnorm=0.382, clip=0, loss_scale=64, train_wall=82, gb_free=15.1, wall=12612
2023-08-24 05:46:41 | INFO | train_inner | epoch 011:    266 / 1474 loss=1.875, trans_loss=3.444, nll_loss=1.588, w2v_ctc_loss=0.952, task_loss=2.239, contrastive_loss=0, total=4132.11, n_correct=2554.37, ppl=3.01, accuracy=61.818, wps=14738.6, ups=1.19, wpb=12339.9, bsz=449.7, num_updates=15000, lr=0.00011547, gnorm=0.374, clip=0, loss_scale=64, train_wall=83, gb_free=15.1, wall=12696
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 05:47:42 | INFO | train_inner | epoch 011:    366 / 1474 loss=2.076, trans_loss=5.135, nll_loss=2.376, w2v_ctc_loss=0.722, task_loss=3.405, contrastive_loss=0, total=4093.56, n_correct=2516.17, ppl=5.19, accuracy=61.467, wps=13596, ups=1.65, wpb=8217.8, bsz=295.7, num_updates=15100, lr=0.000115087, gnorm=0.504, clip=0, loss_scale=64, train_wall=60, gb_free=12.6, wall=12756
2023-08-24 05:48:42 | INFO | train_inner | epoch 011:    466 / 1474 loss=2.077, trans_loss=5.161, nll_loss=2.394, w2v_ctc_loss=0.71, task_loss=3.407, contrastive_loss=0, total=4117.22, n_correct=2522.5, ppl=5.26, accuracy=61.267, wps=13590.4, ups=1.65, wpb=8234.4, bsz=302.3, num_updates=15200, lr=0.000114708, gnorm=0.505, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=12817
2023-08-24 05:49:43 | INFO | train_inner | epoch 011:    566 / 1474 loss=2.083, trans_loss=5.162, nll_loss=2.395, w2v_ctc_loss=0.725, task_loss=3.567, contrastive_loss=0, total=4053.03, n_correct=2483.54, ppl=5.26, accuracy=61.276, wps=13396.4, ups=1.65, wpb=8106.1, bsz=290.3, num_updates=15300, lr=0.000114332, gnorm=0.518, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=12877
2023-08-24 05:50:43 | INFO | train_inner | epoch 011:    666 / 1474 loss=2.079, trans_loss=5.16, nll_loss=2.395, w2v_ctc_loss=0.718, task_loss=3.266, contrastive_loss=0, total=4152.19, n_correct=2542.81, ppl=5.26, accuracy=61.24, wps=13742.9, ups=1.65, wpb=8304.4, bsz=307.4, num_updates=15400, lr=0.000113961, gnorm=0.504, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=12938
2023-08-24 05:51:44 | INFO | train_inner | epoch 011:    766 / 1474 loss=2.083, trans_loss=5.168, nll_loss=2.405, w2v_ctc_loss=0.729, task_loss=3.304, contrastive_loss=0, total=4170.37, n_correct=2562.6, ppl=5.3, accuracy=61.448, wps=13732.3, ups=1.65, wpb=8340.7, bsz=305.8, num_updates=15500, lr=0.000113592, gnorm=0.506, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=12998
2023-08-24 05:52:45 | INFO | train_inner | epoch 011:    866 / 1474 loss=2.083, trans_loss=5.17, nll_loss=2.407, w2v_ctc_loss=0.724, task_loss=3.369, contrastive_loss=0, total=4134.37, n_correct=2531.18, ppl=5.31, accuracy=61.223, wps=13628.6, ups=1.65, wpb=8268.7, bsz=298.4, num_updates=15600, lr=0.000113228, gnorm=0.504, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=13059
2023-08-24 05:53:45 | INFO | train_inner | epoch 011:    966 / 1474 loss=2.085, trans_loss=5.171, nll_loss=2.41, w2v_ctc_loss=0.731, task_loss=3.346, contrastive_loss=0, total=4147.96, n_correct=2535.86, ppl=5.32, accuracy=61.135, wps=13718.2, ups=1.65, wpb=8295.9, bsz=302.3, num_updates=15700, lr=0.000112867, gnorm=0.515, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=13119
2023-08-24 05:54:45 | INFO | train_inner | epoch 011:   1066 / 1474 loss=2.081, trans_loss=5.164, nll_loss=2.401, w2v_ctc_loss=0.732, task_loss=3.242, contrastive_loss=0, total=4135.97, n_correct=2538.62, ppl=5.28, accuracy=61.379, wps=13734.1, ups=1.66, wpb=8271.9, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.506, clip=0, loss_scale=64, train_wall=59, gb_free=12.9, wall=13180
2023-08-24 05:55:46 | INFO | train_inner | epoch 011:   1166 / 1474 loss=2.083, trans_loss=5.172, nll_loss=2.411, w2v_ctc_loss=0.729, task_loss=3.32, contrastive_loss=0, total=4168.11, n_correct=2553.47, ppl=5.32, accuracy=61.262, wps=13833.4, ups=1.66, wpb=8336.2, bsz=306.2, num_updates=15900, lr=0.000112154, gnorm=0.506, clip=0, loss_scale=64, train_wall=60, gb_free=14.7, wall=13240
2023-08-24 05:56:46 | INFO | train_inner | epoch 011:   1266 / 1474 loss=2.085, trans_loss=5.169, nll_loss=2.41, w2v_ctc_loss=0.736, task_loss=3.118, contrastive_loss=0, total=4185.89, n_correct=2559.39, ppl=5.31, accuracy=61.143, wps=13844.7, ups=1.65, wpb=8371.8, bsz=317.9, num_updates=16000, lr=0.000111803, gnorm=0.501, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=13300
2023-08-24 05:56:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
2023-08-24 05:57:19 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.609 | nll_loss 2.899 | w2v_ctc_loss 1.379 | task_loss 11.654 | contrastive_loss 0 | total 4003.4 | n_correct 2452.1 | ppl 7.46 | accuracy 61.25 | uer 17.854 | wer 19.451 | raw_wer 19.451 | bleu 19.42 | wps 1633.1 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.61
2023-08-24 05:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-24 05:57:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_16000.pt
2023-08-24 05:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_16000.pt
2023-08-24 05:57:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.42) (writing took 7.674199994071387 seconds)
2023-08-24 05:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 05:58:30 | INFO | train_inner | epoch 011:   1367 / 1474 loss=2.078, trans_loss=5.168, nll_loss=2.408, w2v_ctc_loss=0.72, task_loss=3.04, contrastive_loss=0, total=4185.49, n_correct=2562.82, ppl=5.31, accuracy=61.231, wps=8078, ups=0.97, wpb=8371, bsz=326.8, num_updates=16100, lr=0.000111456, gnorm=0.5, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=13404
2023-08-24 05:59:30 | INFO | train_inner | epoch 011:   1467 / 1474 loss=2.081, trans_loss=5.171, nll_loss=2.412, w2v_ctc_loss=0.725, task_loss=3.211, contrastive_loss=0, total=4154.28, n_correct=2544.82, ppl=5.32, accuracy=61.258, wps=13729.5, ups=1.65, wpb=8308.6, bsz=310.4, num_updates=16200, lr=0.000111111, gnorm=0.506, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=13465
2023-08-24 05:59:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 06:00:07 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.594 | nll_loss 2.88 | w2v_ctc_loss 1.352 | task_loss 11.633 | contrastive_loss 0 | total 4003.4 | n_correct 2455.4 | ppl 7.36 | accuracy 61.333 | uer 18.066 | wer 19.813 | raw_wer 19.813 | bleu 19.64 | wps 1636.4 | wpb 4003.4 | bsz 141.8 | num_updates 16207 | best_bleu 19.64
2023-08-24 06:00:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16207 updates
2023-08-24 06:00:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:00:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 11 @ 16207 updates, score 19.64) (writing took 9.903887499007396 seconds)
2023-08-24 06:00:17 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-24 06:00:17 | INFO | train | epoch 011 | loss 2.032 | trans_loss 4.739 | nll_loss 2.201 | w2v_ctc_loss 0.783 | task_loss 3.019 | contrastive_loss 0 | total 4138.22 | n_correct 2539.65 | ppl 4.6 | accuracy 61.371 | wps 12714 | ups 1.41 | wpb 9014.8 | bsz 333.1 | num_updates 16207 | lr 0.000111087 | gnorm 0.483 | clip 0 | loss_scale 32 | train_wall 942 | gb_free 17.1 | wall 13512
2023-08-24 06:00:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 06:00:17 | INFO | fairseq.trainer | begin training epoch 12
2023-08-24 06:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 06:01:20 | INFO | train_inner | epoch 012:     93 / 1474 loss=2.052, trans_loss=5.114, nll_loss=2.335, w2v_ctc_loss=0.707, task_loss=3.113, contrastive_loss=0, total=4151.96, n_correct=2588.46, ppl=5.05, accuracy=62.343, wps=7574.5, ups=0.91, wpb=8303.9, bsz=315.5, num_updates=16300, lr=0.00011077, gnorm=0.502, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=13574
2023-08-24 06:02:20 | INFO | train_inner | epoch 012:    193 / 1474 loss=2.064, trans_loss=5.125, nll_loss=2.348, w2v_ctc_loss=0.718, task_loss=3.425, contrastive_loss=0, total=4115.75, n_correct=2552.73, ppl=5.09, accuracy=62.023, wps=13806, ups=1.68, wpb=8231.5, bsz=293.8, num_updates=16400, lr=0.000110432, gnorm=0.508, clip=0, loss_scale=32, train_wall=59, gb_free=17.4, wall=13634
2023-08-24 06:03:20 | INFO | train_inner | epoch 012:    293 / 1474 loss=2.052, trans_loss=5.12, nll_loss=2.343, w2v_ctc_loss=0.702, task_loss=3.075, contrastive_loss=0, total=4203.07, n_correct=2614.4, ppl=5.07, accuracy=62.202, wps=13952.1, ups=1.66, wpb=8406.1, bsz=321, num_updates=16500, lr=0.000110096, gnorm=0.497, clip=0, loss_scale=32, train_wall=60, gb_free=14.3, wall=13694
2023-08-24 06:04:21 | INFO | train_inner | epoch 012:    393 / 1474 loss=2.063, trans_loss=5.132, nll_loss=2.358, w2v_ctc_loss=0.716, task_loss=3.247, contrastive_loss=0, total=4148.54, n_correct=2571.07, ppl=5.13, accuracy=61.975, wps=13577, ups=1.64, wpb=8297.1, bsz=306.7, num_updates=16600, lr=0.000109764, gnorm=0.505, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=13755
2023-08-24 06:05:21 | INFO | train_inner | epoch 012:    493 / 1474 loss=2.074, trans_loss=5.149, nll_loss=2.381, w2v_ctc_loss=0.725, task_loss=3.257, contrastive_loss=0, total=4114.61, n_correct=2537.4, ppl=5.21, accuracy=61.668, wps=13750.3, ups=1.67, wpb=8229.2, bsz=303.7, num_updates=16700, lr=0.000109435, gnorm=0.503, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=13815
2023-08-24 06:06:22 | INFO | train_inner | epoch 012:    593 / 1474 loss=2.066, trans_loss=5.138, nll_loss=2.368, w2v_ctc_loss=0.718, task_loss=3.175, contrastive_loss=0, total=4193.09, n_correct=2592.53, ppl=5.16, accuracy=61.829, wps=13803.7, ups=1.65, wpb=8386.2, bsz=314.8, num_updates=16800, lr=0.000109109, gnorm=0.506, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=13876
2023-08-24 06:07:21 | INFO | train_inner | epoch 012:    693 / 1474 loss=2.053, trans_loss=5.133, nll_loss=2.362, w2v_ctc_loss=0.697, task_loss=3.063, contrastive_loss=0, total=4189.86, n_correct=2601.42, ppl=5.14, accuracy=62.088, wps=13982.1, ups=1.67, wpb=8379.7, bsz=321.2, num_updates=16900, lr=0.000108786, gnorm=0.495, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=13936
2023-08-24 06:08:22 | INFO | train_inner | epoch 012:    793 / 1474 loss=2.063, trans_loss=5.132, nll_loss=2.36, w2v_ctc_loss=0.719, task_loss=3.314, contrastive_loss=0, total=4099.87, n_correct=2543.31, ppl=5.13, accuracy=62.034, wps=13576.5, ups=1.66, wpb=8199.7, bsz=300.6, num_updates=17000, lr=0.000108465, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=13996
2023-08-24 06:09:23 | INFO | train_inner | epoch 012:    893 / 1474 loss=2.066, trans_loss=5.143, nll_loss=2.374, w2v_ctc_loss=0.715, task_loss=3.37, contrastive_loss=0, total=4159.64, n_correct=2574.53, ppl=5.18, accuracy=61.893, wps=13589.2, ups=1.63, wpb=8319.3, bsz=305.7, num_updates=17100, lr=0.000108148, gnorm=0.508, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=14057
2023-08-24 06:10:23 | INFO | train_inner | epoch 012:    993 / 1474 loss=2.074, trans_loss=5.152, nll_loss=2.385, w2v_ctc_loss=0.724, task_loss=3.368, contrastive_loss=0, total=4115.42, n_correct=2536.5, ppl=5.22, accuracy=61.634, wps=13631.6, ups=1.66, wpb=8230.8, bsz=300.1, num_updates=17200, lr=0.000107833, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=14118
2023-08-24 06:11:24 | INFO | train_inner | epoch 012:   1093 / 1474 loss=2.077, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.726, task_loss=3.415, contrastive_loss=0, total=4049.99, n_correct=2492.58, ppl=5.24, accuracy=61.545, wps=13467.5, ups=1.66, wpb=8100, bsz=291.8, num_updates=17300, lr=0.000107521, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=14178
2023-08-24 06:12:24 | INFO | train_inner | epoch 012:   1193 / 1474 loss=2.08, trans_loss=5.165, nll_loss=2.404, w2v_ctc_loss=0.734, task_loss=3.265, contrastive_loss=0, total=4185.54, n_correct=2567.76, ppl=5.29, accuracy=61.348, wps=13839.3, ups=1.65, wpb=8371.1, bsz=313.6, num_updates=17400, lr=0.000107211, gnorm=0.504, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=14238
2023-08-24 06:13:25 | INFO | train_inner | epoch 012:   1293 / 1474 loss=2.078, trans_loss=5.152, nll_loss=2.386, w2v_ctc_loss=0.733, task_loss=3.564, contrastive_loss=0, total=4092.3, n_correct=2518.94, ppl=5.23, accuracy=61.553, wps=13534.9, ups=1.65, wpb=8184.6, bsz=292.6, num_updates=17500, lr=0.000106904, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=14299
2023-08-24 06:14:25 | INFO | train_inner | epoch 012:   1393 / 1474 loss=2.067, trans_loss=5.154, nll_loss=2.39, w2v_ctc_loss=0.709, task_loss=3.319, contrastive_loss=0, total=4134.01, n_correct=2547.98, ppl=5.24, accuracy=61.635, wps=13723.1, ups=1.66, wpb=8268, bsz=305.1, num_updates=17600, lr=0.0001066, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=14359
2023-08-24 06:15:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 06:15:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.59 | nll_loss 2.876 | w2v_ctc_loss 1.344 | task_loss 11.55 | contrastive_loss 0 | total 4003.4 | n_correct 2458 | ppl 7.34 | accuracy 61.398 | uer 17.798 | wer 19.492 | raw_wer 19.492 | bleu 19.27 | wps 1643.2 | wpb 4003.4 | bsz 141.8 | num_updates 17681 | best_bleu 19.64
2023-08-24 06:15:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17681 updates
2023-08-24 06:15:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.2709.pt
2023-08-24 06:15:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.2709.pt
2023-08-24 06:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.2709.pt (epoch 12 @ 17681 updates, score 19.27) (writing took 6.729702991084196 seconds)
2023-08-24 06:15:54 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-24 06:15:54 | INFO | train | epoch 012 | loss 2.067 | trans_loss 5.141 | nll_loss 2.372 | w2v_ctc_loss 0.718 | task_loss 3.287 | contrastive_loss 0 | total 4138.65 | n_correct 2558.96 | ppl 5.18 | accuracy 61.831 | wps 13023.4 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 17681 | lr 0.000106356 | gnorm 0.506 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 12.7 | wall 14448
2023-08-24 06:15:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 06:15:54 | INFO | fairseq.trainer | begin training epoch 13
2023-08-24 06:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 06:16:14 | INFO | train_inner | epoch 013:     19 / 1474 loss=2.077, trans_loss=5.157, nll_loss=2.394, w2v_ctc_loss=0.73, task_loss=3.416, contrastive_loss=0, total=4100.58, n_correct=2528.02, ppl=5.26, accuracy=61.65, wps=7541.8, ups=0.92, wpb=8201.2, bsz=296, num_updates=17700, lr=0.000106299, gnorm=0.509, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=14468
2023-08-24 06:17:14 | INFO | train_inner | epoch 013:    119 / 1474 loss=2.048, trans_loss=5.106, nll_loss=2.324, w2v_ctc_loss=0.703, task_loss=3.284, contrastive_loss=0, total=4161.46, n_correct=2602.54, ppl=5.01, accuracy=62.539, wps=13821.5, ups=1.66, wpb=8322.9, bsz=302.8, num_updates=17800, lr=0.000106, gnorm=0.498, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=14528
2023-08-24 06:18:14 | INFO | train_inner | epoch 013:    219 / 1474 loss=2.051, trans_loss=5.12, nll_loss=2.346, w2v_ctc_loss=0.706, task_loss=3.04, contrastive_loss=0, total=4208.4, n_correct=2621.11, ppl=5.08, accuracy=62.283, wps=13887.4, ups=1.65, wpb=8416.8, bsz=328.7, num_updates=17900, lr=0.000105703, gnorm=0.505, clip=0, loss_scale=32, train_wall=60, gb_free=14, wall=14589
2023-08-24 06:19:15 | INFO | train_inner | epoch 013:    319 / 1474 loss=2.046, trans_loss=5.105, nll_loss=2.324, w2v_ctc_loss=0.698, task_loss=3.38, contrastive_loss=0, total=4109.49, n_correct=2576.28, ppl=5.01, accuracy=62.691, wps=13627, ups=1.66, wpb=8219, bsz=296.3, num_updates=18000, lr=0.000105409, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=14649
2023-08-24 06:19:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 06:19:47 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.185 | trans_loss 5.602 | nll_loss 2.888 | w2v_ctc_loss 1.327 | task_loss 11.514 | contrastive_loss 0 | total 4003.4 | n_correct 2457.3 | ppl 7.4 | accuracy 61.38 | uer 17.88 | wer 19.664 | raw_wer 19.664 | bleu 19.42 | wps 1635 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.64
2023-08-24 06:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-24 06:19:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_13_18000.pt
2023-08-24 06:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_13_18000.pt
2023-08-24 06:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.42) (writing took 7.387859735987149 seconds)
2023-08-24 06:20:55 | INFO | train_inner | epoch 013:    419 / 1474 loss=2.046, trans_loss=5.114, nll_loss=2.336, w2v_ctc_loss=0.703, task_loss=3.09, contrastive_loss=0, total=4181.75, n_correct=2616.27, ppl=5.05, accuracy=62.564, wps=8343.9, ups=1, wpb=8363.5, bsz=317.7, num_updates=18100, lr=0.000105118, gnorm=0.502, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=14749
2023-08-24 06:21:56 | INFO | train_inner | epoch 013:    519 / 1474 loss=2.054, trans_loss=5.122, nll_loss=2.347, w2v_ctc_loss=0.711, task_loss=3.233, contrastive_loss=0, total=4185.88, n_correct=2604.52, ppl=5.09, accuracy=62.222, wps=13655.8, ups=1.63, wpb=8371.8, bsz=315.4, num_updates=18200, lr=0.000104828, gnorm=0.503, clip=0, loss_scale=64, train_wall=60, gb_free=14.6, wall=14811
2023-08-24 06:22:56 | INFO | train_inner | epoch 013:    619 / 1474 loss=2.042, trans_loss=5.111, nll_loss=2.334, w2v_ctc_loss=0.697, task_loss=3.141, contrastive_loss=0, total=4165.77, n_correct=2608.96, ppl=5.04, accuracy=62.629, wps=13894.2, ups=1.67, wpb=8331.5, bsz=311.3, num_updates=18300, lr=0.000104542, gnorm=0.502, clip=0, loss_scale=64, train_wall=59, gb_free=14.1, wall=14871
2023-08-24 06:23:57 | INFO | train_inner | epoch 013:    719 / 1474 loss=2.067, trans_loss=5.128, nll_loss=2.354, w2v_ctc_loss=0.726, task_loss=3.645, contrastive_loss=0, total=4104.39, n_correct=2548.9, ppl=5.11, accuracy=62.102, wps=13590.3, ups=1.66, wpb=8208.8, bsz=285.6, num_updates=18400, lr=0.000104257, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=11.9, wall=14931
2023-08-24 06:24:58 | INFO | train_inner | epoch 013:    819 / 1474 loss=2.056, trans_loss=5.127, nll_loss=2.355, w2v_ctc_loss=0.706, task_loss=3.342, contrastive_loss=0, total=4124.92, n_correct=2563.73, ppl=5.11, accuracy=62.152, wps=13539.4, ups=1.64, wpb=8249.8, bsz=306.3, num_updates=18500, lr=0.000103975, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=14992
2023-08-24 06:25:58 | INFO | train_inner | epoch 013:    919 / 1474 loss=2.058, trans_loss=5.133, nll_loss=2.361, w2v_ctc_loss=0.707, task_loss=3.369, contrastive_loss=0, total=4100.02, n_correct=2549.63, ppl=5.14, accuracy=62.186, wps=13654, ups=1.67, wpb=8200, bsz=295.8, num_updates=18600, lr=0.000103695, gnorm=0.51, clip=0, loss_scale=64, train_wall=59, gb_free=11.8, wall=15052
2023-08-24 06:26:58 | INFO | train_inner | epoch 013:   1019 / 1474 loss=2.067, trans_loss=5.135, nll_loss=2.365, w2v_ctc_loss=0.722, task_loss=3.502, contrastive_loss=0, total=4076.33, n_correct=2529.33, ppl=5.15, accuracy=62.049, wps=13428.8, ups=1.65, wpb=8152.7, bsz=291.6, num_updates=18700, lr=0.000103418, gnorm=0.522, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=15113
2023-08-24 06:27:59 | INFO | train_inner | epoch 013:   1119 / 1474 loss=2.054, trans_loss=5.125, nll_loss=2.353, w2v_ctc_loss=0.707, task_loss=3.276, contrastive_loss=0, total=4100.28, n_correct=2555.39, ppl=5.11, accuracy=62.322, wps=13602, ups=1.66, wpb=8200.6, bsz=304.1, num_updates=18800, lr=0.000103142, gnorm=0.506, clip=0, loss_scale=64, train_wall=60, gb_free=11.5, wall=15173
2023-08-24 06:28:59 | INFO | train_inner | epoch 013:   1219 / 1474 loss=2.061, trans_loss=5.136, nll_loss=2.367, w2v_ctc_loss=0.714, task_loss=3.442, contrastive_loss=0, total=4120.06, n_correct=2560.52, ppl=5.16, accuracy=62.148, wps=13715.8, ups=1.66, wpb=8240.1, bsz=298.6, num_updates=18900, lr=0.000102869, gnorm=0.514, clip=0, loss_scale=64, train_wall=59, gb_free=17.6, wall=15233
2023-08-24 06:29:59 | INFO | train_inner | epoch 013:   1319 / 1474 loss=2.053, trans_loss=5.124, nll_loss=2.352, w2v_ctc_loss=0.708, task_loss=3.24, contrastive_loss=0, total=4114.06, n_correct=2565.78, ppl=5.11, accuracy=62.366, wps=13670.5, ups=1.66, wpb=8228.1, bsz=307.9, num_updates=19000, lr=0.000102598, gnorm=0.509, clip=0, loss_scale=64, train_wall=59, gb_free=12.5, wall=15293
2023-08-24 06:30:59 | INFO | train_inner | epoch 013:   1419 / 1474 loss=2.056, trans_loss=5.136, nll_loss=2.369, w2v_ctc_loss=0.702, task_loss=3.195, contrastive_loss=0, total=4182.79, n_correct=2599.84, ppl=5.17, accuracy=62.156, wps=13915.7, ups=1.66, wpb=8365.6, bsz=313.3, num_updates=19100, lr=0.000102329, gnorm=0.501, clip=0, loss_scale=64, train_wall=59, gb_free=15.6, wall=15353
2023-08-24 06:31:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 06:32:06 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.167 | trans_loss 5.585 | nll_loss 2.865 | w2v_ctc_loss 1.306 | task_loss 11.504 | contrastive_loss 0 | total 4003.4 | n_correct 2466.8 | ppl 7.29 | accuracy 61.618 | uer 17.461 | wer 19.239 | raw_wer 19.239 | bleu 19.67 | wps 1598.6 | wpb 4003.4 | bsz 141.8 | num_updates 19155 | best_bleu 19.67
2023-08-24 06:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19155 updates
2023-08-24 06:32:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 13 @ 19155 updates, score 19.67) (writing took 10.878723558038473 seconds)
2023-08-24 06:32:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-24 06:32:17 | INFO | train | epoch 013 | loss 2.054 | trans_loss 5.123 | nll_loss 2.349 | w2v_ctc_loss 0.708 | task_loss 3.286 | contrastive_loss 0 | total 4138.65 | n_correct 2579.04 | ppl 5.09 | accuracy 62.316 | wps 12408.1 | ups 1.5 | wpb 8277.3 | bsz 305.7 | num_updates 19155 | lr 0.000102182 | gnorm 0.508 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 17.6 | wall 15432
2023-08-24 06:32:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 06:32:18 | INFO | fairseq.trainer | begin training epoch 14
2023-08-24 06:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 06:32:51 | INFO | train_inner | epoch 014:     45 / 1474 loss=2.039, trans_loss=5.098, nll_loss=2.319, w2v_ctc_loss=0.703, task_loss=3.032, contrastive_loss=0, total=4162.33, n_correct=2615.1, ppl=4.99, accuracy=62.828, wps=7403, ups=0.89, wpb=8324.7, bsz=319.9, num_updates=19200, lr=0.000102062, gnorm=0.503, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=15466
2023-08-24 06:33:52 | INFO | train_inner | epoch 014:    145 / 1474 loss=2.028, trans_loss=5.077, nll_loss=2.29, w2v_ctc_loss=0.688, task_loss=3.319, contrastive_loss=0, total=4091.57, n_correct=2589.62, ppl=4.89, accuracy=63.292, wps=13624.4, ups=1.66, wpb=8183.1, bsz=299.3, num_updates=19300, lr=0.000101797, gnorm=0.499, clip=0, loss_scale=64, train_wall=59, gb_free=13.4, wall=15526
2023-08-24 06:34:51 | INFO | train_inner | epoch 014:    245 / 1474 loss=2.039, trans_loss=5.097, nll_loss=2.315, w2v_ctc_loss=0.692, task_loss=3.416, contrastive_loss=0, total=4111.46, n_correct=2586.78, ppl=4.98, accuracy=62.916, wps=13750.1, ups=1.67, wpb=8222.9, bsz=295.7, num_updates=19400, lr=0.000101535, gnorm=0.51, clip=0, loss_scale=64, train_wall=59, gb_free=17.7, wall=15586
2023-08-24 06:35:51 | INFO | train_inner | epoch 014:    345 / 1474 loss=2.033, trans_loss=5.09, nll_loss=2.307, w2v_ctc_loss=0.694, task_loss=3.059, contrastive_loss=0, total=4172.59, n_correct=2629.13, ppl=4.95, accuracy=63.01, wps=13911.9, ups=1.67, wpb=8345.2, bsz=320.2, num_updates=19500, lr=0.000101274, gnorm=0.504, clip=0, loss_scale=64, train_wall=59, gb_free=11.7, wall=15646
2023-08-24 06:36:52 | INFO | train_inner | epoch 014:    445 / 1474 loss=2.042, trans_loss=5.105, nll_loss=2.326, w2v_ctc_loss=0.695, task_loss=3.403, contrastive_loss=0, total=4108.61, n_correct=2575.34, ppl=5.01, accuracy=62.682, wps=13652, ups=1.66, wpb=8217.2, bsz=294.5, num_updates=19600, lr=0.000101015, gnorm=0.505, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=15706
2023-08-24 06:37:53 | INFO | train_inner | epoch 014:    545 / 1474 loss=2.05, trans_loss=5.108, nll_loss=2.329, w2v_ctc_loss=0.713, task_loss=3.421, contrastive_loss=0, total=4103.97, n_correct=2568.28, ppl=5.03, accuracy=62.58, wps=13462.4, ups=1.64, wpb=8207.9, bsz=298.7, num_updates=19700, lr=0.000100759, gnorm=0.51, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=15767
2023-08-24 06:38:53 | INFO | train_inner | epoch 014:    645 / 1474 loss=2.045, trans_loss=5.109, nll_loss=2.331, w2v_ctc_loss=0.701, task_loss=3.288, contrastive_loss=0, total=4158.28, n_correct=2604.86, ppl=5.03, accuracy=62.643, wps=13680.5, ups=1.64, wpb=8316.6, bsz=307.1, num_updates=19800, lr=0.000100504, gnorm=0.508, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=15828
2023-08-24 06:39:53 | INFO | train_inner | epoch 014:    745 / 1474 loss=2.038, trans_loss=5.1, nll_loss=2.319, w2v_ctc_loss=0.697, task_loss=3.201, contrastive_loss=0, total=4149.79, n_correct=2608.76, ppl=4.99, accuracy=62.865, wps=13899.4, ups=1.67, wpb=8299.6, bsz=309.9, num_updates=19900, lr=0.000100251, gnorm=0.505, clip=0, loss_scale=64, train_wall=59, gb_free=15.4, wall=15887
2023-08-24 06:40:53 | INFO | train_inner | epoch 014:    845 / 1474 loss=2.034, trans_loss=5.096, nll_loss=2.316, w2v_ctc_loss=0.691, task_loss=3.124, contrastive_loss=0, total=4165.7, n_correct=2620.01, ppl=4.98, accuracy=62.895, wps=13902.6, ups=1.67, wpb=8331.4, bsz=318.2, num_updates=20000, lr=0.0001, gnorm=0.504, clip=0, loss_scale=64, train_wall=59, gb_free=12.2, wall=15947
2023-08-24 06:40:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 06:41:26 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.185 | trans_loss 5.582 | nll_loss 2.861 | w2v_ctc_loss 1.372 | task_loss 11.544 | contrastive_loss 0 | total 4003.4 | n_correct 2469.5 | ppl 7.27 | accuracy 61.685 | uer 17.864 | wer 19.761 | raw_wer 19.761 | bleu 19.71 | wps 1646.5 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.71
2023-08-24 06:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-24 06:41:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_20000.pt
2023-08-24 06:41:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_20000.pt
2023-08-24 06:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.71) (writing took 11.191010124981403 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 06:42:38 | INFO | train_inner | epoch 014:    945 / 1474 loss=2.044, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.703, task_loss=3.351, contrastive_loss=0, total=4148.78, n_correct=2596.27, ppl=5.04, accuracy=62.579, wps=7884.4, ups=0.95, wpb=8297.6, bsz=304.9, num_updates=20100, lr=9.97509e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=16053
2023-08-24 06:43:39 | INFO | train_inner | epoch 014:   1045 / 1474 loss=2.048, trans_loss=5.117, nll_loss=2.343, w2v_ctc_loss=0.698, task_loss=3.274, contrastive_loss=0, total=4165.56, n_correct=2601.09, ppl=5.07, accuracy=62.443, wps=13647.8, ups=1.64, wpb=8331.1, bsz=306.4, num_updates=20200, lr=9.95037e-05, gnorm=0.501, clip=0, loss_scale=128, train_wall=60, gb_free=16.4, wall=16114
2023-08-24 06:44:40 | INFO | train_inner | epoch 014:   1145 / 1474 loss=2.045, trans_loss=5.11, nll_loss=2.337, w2v_ctc_loss=0.701, task_loss=3.099, contrastive_loss=0, total=4220.71, n_correct=2636.49, ppl=5.05, accuracy=62.466, wps=13820.4, ups=1.64, wpb=8441.4, bsz=325.5, num_updates=20300, lr=9.92583e-05, gnorm=0.505, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=16175
2023-08-24 06:45:40 | INFO | train_inner | epoch 014:   1245 / 1474 loss=2.065, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.721, task_loss=3.78, contrastive_loss=0, total=4038.97, n_correct=2509.62, ppl=5.14, accuracy=62.135, wps=13439.6, ups=1.66, wpb=8077.9, bsz=276.2, num_updates=20400, lr=9.90148e-05, gnorm=0.525, clip=0, loss_scale=128, train_wall=60, gb_free=15.8, wall=16235
2023-08-24 06:46:41 | INFO | train_inner | epoch 014:   1345 / 1474 loss=2.048, trans_loss=5.12, nll_loss=2.347, w2v_ctc_loss=0.701, task_loss=3.221, contrastive_loss=0, total=4182.25, n_correct=2612.74, ppl=5.09, accuracy=62.472, wps=13892.8, ups=1.66, wpb=8364.5, bsz=309.9, num_updates=20500, lr=9.8773e-05, gnorm=0.508, clip=0, loss_scale=128, train_wall=60, gb_free=17.7, wall=16295
2023-08-24 06:47:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 06:47:41 | INFO | train_inner | epoch 014:   1446 / 1474 loss=2.048, trans_loss=5.125, nll_loss=2.354, w2v_ctc_loss=0.699, task_loss=3.236, contrastive_loss=0, total=4141.73, n_correct=2587.54, ppl=5.11, accuracy=62.475, wps=13695.7, ups=1.65, wpb=8283.5, bsz=306.7, num_updates=20600, lr=9.85329e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=16355
2023-08-24 06:47:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
2023-08-24 06:48:30 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.171 | trans_loss 5.58 | nll_loss 2.864 | w2v_ctc_loss 1.33 | task_loss 11.476 | contrastive_loss 0 | total 4003.4 | n_correct 2472.9 | ppl 7.28 | accuracy 61.77 | uer 17.62 | wer 19.488 | raw_wer 19.488 | bleu 19.98 | wps 1683.7 | wpb 4003.4 | bsz 141.8 | num_updates 20628 | best_bleu 19.98
2023-08-24 06:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20628 updates
2023-08-24 06:48:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:48:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 06:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 14 @ 20628 updates, score 19.98) (writing took 11.2461009810213 seconds)
2023-08-24 06:48:42 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-24 06:48:42 | INFO | train | epoch 014 | loss 2.043 | trans_loss 5.106 | nll_loss 2.329 | w2v_ctc_loss 0.7 | task_loss 3.289 | contrastive_loss 0 | total 4137.73 | n_correct 2593.68 | ppl 5.02 | accuracy 62.684 | wps 12378.5 | ups 1.5 | wpb 8275.5 | bsz 305.3 | num_updates 20628 | lr 9.8466e-05 | gnorm 0.507 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 16.3 | wall 16417
2023-08-24 06:48:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 06:48:42 | INFO | fairseq.trainer | begin training epoch 15
2023-08-24 06:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 06:49:33 | INFO | train_inner | epoch 015:     72 / 1474 loss=2.034, trans_loss=5.092, nll_loss=2.31, w2v_ctc_loss=0.69, task_loss=3.287, contrastive_loss=0, total=4075.94, n_correct=2570.72, ppl=4.96, accuracy=63.071, wps=7301.1, ups=0.9, wpb=8151.9, bsz=299.9, num_updates=20700, lr=9.82946e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=16467
2023-08-24 06:50:33 | INFO | train_inner | epoch 015:    172 / 1474 loss=2.036, trans_loss=5.084, nll_loss=2.299, w2v_ctc_loss=0.699, task_loss=3.436, contrastive_loss=0, total=4125.04, n_correct=2602.6, ppl=4.92, accuracy=63.093, wps=13658.8, ups=1.66, wpb=8250.1, bsz=297.5, num_updates=20800, lr=9.80581e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=16528
2023-08-24 06:51:33 | INFO | train_inner | epoch 015:    272 / 1474 loss=2.025, trans_loss=5.083, nll_loss=2.298, w2v_ctc_loss=0.683, task_loss=3.143, contrastive_loss=0, total=4187.82, n_correct=2649.37, ppl=4.92, accuracy=63.264, wps=13975.8, ups=1.67, wpb=8375.6, bsz=313.1, num_updates=20900, lr=9.78232e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=16587
2023-08-24 06:52:34 | INFO | train_inner | epoch 015:    372 / 1474 loss=2.032, trans_loss=5.08, nll_loss=2.294, w2v_ctc_loss=0.692, task_loss=3.397, contrastive_loss=0, total=4147.17, n_correct=2620.96, ppl=4.9, accuracy=63.199, wps=13735.7, ups=1.66, wpb=8294.3, bsz=299.7, num_updates=21000, lr=9.759e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=16648
2023-08-24 06:53:34 | INFO | train_inner | epoch 015:    472 / 1474 loss=2.031, trans_loss=5.087, nll_loss=2.303, w2v_ctc_loss=0.684, task_loss=3.331, contrastive_loss=0, total=4089.07, n_correct=2577.12, ppl=4.94, accuracy=63.025, wps=13586.2, ups=1.66, wpb=8178.1, bsz=300.4, num_updates=21100, lr=9.73585e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=16708
2023-08-24 06:54:34 | INFO | train_inner | epoch 015:    572 / 1474 loss=2.034, trans_loss=5.085, nll_loss=2.3, w2v_ctc_loss=0.695, task_loss=3.496, contrastive_loss=0, total=4126.64, n_correct=2604.09, ppl=4.93, accuracy=63.104, wps=13604.9, ups=1.65, wpb=8253.3, bsz=292.4, num_updates=21200, lr=9.71286e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=16769
2023-08-24 06:55:35 | INFO | train_inner | epoch 015:    672 / 1474 loss=2.032, trans_loss=5.085, nll_loss=2.302, w2v_ctc_loss=0.695, task_loss=3.252, contrastive_loss=0, total=4139.44, n_correct=2615.06, ppl=4.93, accuracy=63.174, wps=13668.6, ups=1.65, wpb=8278.9, bsz=310.2, num_updates=21300, lr=9.69003e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=16829
2023-08-24 06:56:36 | INFO | train_inner | epoch 015:    772 / 1474 loss=2.037, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.696, task_loss=3.299, contrastive_loss=0, total=4187.25, n_correct=2632.36, ppl=4.98, accuracy=62.866, wps=13791.9, ups=1.65, wpb=8374.5, bsz=307.8, num_updates=21400, lr=9.66736e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=16890
2023-08-24 06:57:36 | INFO | train_inner | epoch 015:    872 / 1474 loss=2.042, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.701, task_loss=3.551, contrastive_loss=0, total=4067.38, n_correct=2557.86, ppl=5, accuracy=62.887, wps=13583.5, ups=1.67, wpb=8134.8, bsz=288.1, num_updates=21500, lr=9.64486e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=59, gb_free=15.1, wall=16950
2023-08-24 06:58:36 | INFO | train_inner | epoch 015:    972 / 1474 loss=2.032, trans_loss=5.095, nll_loss=2.315, w2v_ctc_loss=0.686, task_loss=3.298, contrastive_loss=0, total=4116.05, n_correct=2595.44, ppl=4.97, accuracy=63.057, wps=13694.5, ups=1.66, wpb=8232.1, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=17010
2023-08-24 06:59:36 | INFO | train_inner | epoch 015:   1072 / 1474 loss=2.033, trans_loss=5.1, nll_loss=2.323, w2v_ctc_loss=0.691, task_loss=3.056, contrastive_loss=0, total=4195.99, n_correct=2636.32, ppl=5, accuracy=62.83, wps=13817, ups=1.65, wpb=8392, bsz=326.9, num_updates=21700, lr=9.60031e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=17071
2023-08-24 07:00:36 | INFO | train_inner | epoch 015:   1172 / 1474 loss=2.021, trans_loss=5.089, nll_loss=2.31, w2v_ctc_loss=0.676, task_loss=2.987, contrastive_loss=0, total=4176.34, n_correct=2643.08, ppl=4.96, accuracy=63.287, wps=13904.7, ups=1.66, wpb=8352.7, bsz=326.6, num_updates=21800, lr=9.57826e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=17131
2023-08-24 07:01:37 | INFO | train_inner | epoch 015:   1272 / 1474 loss=2.037, trans_loss=5.097, nll_loss=2.319, w2v_ctc_loss=0.7, task_loss=3.324, contrastive_loss=0, total=4152.51, n_correct=2613.56, ppl=4.99, accuracy=62.939, wps=13811.2, ups=1.66, wpb=8305, bsz=305, num_updates=21900, lr=9.55637e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=17191
2023-08-24 07:02:37 | INFO | train_inner | epoch 015:   1372 / 1474 loss=2.039, trans_loss=5.101, nll_loss=2.324, w2v_ctc_loss=0.697, task_loss=3.386, contrastive_loss=0, total=4110.45, n_correct=2585.6, ppl=5.01, accuracy=62.903, wps=13677, ups=1.66, wpb=8220.9, bsz=294.4, num_updates=22000, lr=9.53463e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=17251
2023-08-24 07:02:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:03:10 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.17 | trans_loss 5.577 | nll_loss 2.851 | w2v_ctc_loss 1.334 | task_loss 11.537 | contrastive_loss 0 | total 4003.4 | n_correct 2473.7 | ppl 7.22 | accuracy 61.79 | uer 17.639 | wer 19.5 | raw_wer 19.5 | bleu 19.85 | wps 1621.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.98
2023-08-24 07:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-24 07:03:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_15_22000.pt
2023-08-24 07:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_15_22000.pt
2023-08-24 07:03:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.85) (writing took 7.205906354007311 seconds)
2023-08-24 07:04:19 | INFO | train_inner | epoch 015:   1472 / 1474 loss=2.037, trans_loss=5.105, nll_loss=2.33, w2v_ctc_loss=0.695, task_loss=3.234, contrastive_loss=0, total=4146.43, n_correct=2607.38, ppl=5.03, accuracy=62.883, wps=8116.3, ups=0.98, wpb=8292.9, bsz=312.1, num_updates=22100, lr=9.51303e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=17353
2023-08-24 07:04:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:04:53 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.158 | trans_loss 5.567 | nll_loss 2.842 | w2v_ctc_loss 1.315 | task_loss 11.527 | contrastive_loss 0 | total 4003.4 | n_correct 2482.2 | ppl 7.17 | accuracy 62.002 | uer 17.644 | wer 19.529 | raw_wer 19.529 | bleu 20.12 | wps 1611.7 | wpb 4003.4 | bsz 141.8 | num_updates 22102 | best_bleu 20.12
2023-08-24 07:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22102 updates
2023-08-24 07:04:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 07:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 07:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 15 @ 22102 updates, score 20.12) (writing took 11.469834677991457 seconds)
2023-08-24 07:05:05 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-24 07:05:05 | INFO | train | epoch 015 | loss 2.033 | trans_loss 5.091 | nll_loss 2.31 | w2v_ctc_loss 0.692 | task_loss 3.284 | contrastive_loss 0 | total 4138.65 | n_correct 2609.76 | ppl 4.96 | accuracy 63.058 | wps 12412.6 | ups 1.5 | wpb 8277.3 | bsz 305.7 | num_updates 22102 | lr 9.5126e-05 | gnorm 0.511 | clip 0 | loss_scale 64 | train_wall 880 | gb_free 16.9 | wall 17399
2023-08-24 07:05:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 07:05:05 | INFO | fairseq.trainer | begin training epoch 16
2023-08-24 07:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 07:06:11 | INFO | train_inner | epoch 016:     98 / 1474 loss=2.007, trans_loss=5.056, nll_loss=2.264, w2v_ctc_loss=0.67, task_loss=3.107, contrastive_loss=0, total=4110.66, n_correct=2624.37, ppl=4.8, accuracy=63.843, wps=7356.7, ups=0.89, wpb=8221.3, bsz=314.8, num_updates=22200, lr=9.49158e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=17465
2023-08-24 07:07:12 | INFO | train_inner | epoch 016:    198 / 1474 loss=2.014, trans_loss=5.058, nll_loss=2.267, w2v_ctc_loss=0.673, task_loss=3.363, contrastive_loss=0, total=4100.94, n_correct=2614.21, ppl=4.81, accuracy=63.747, wps=13464.2, ups=1.64, wpb=8201.9, bsz=297.9, num_updates=22300, lr=9.47027e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=15, wall=17526
2023-08-24 07:08:12 | INFO | train_inner | epoch 016:    298 / 1474 loss=2.022, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.685, task_loss=3.261, contrastive_loss=0, total=4164.67, n_correct=2641.07, ppl=4.86, accuracy=63.416, wps=13787, ups=1.66, wpb=8329.3, bsz=309.2, num_updates=22400, lr=9.44911e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=14.2, wall=17586
2023-08-24 07:09:12 | INFO | train_inner | epoch 016:    398 / 1474 loss=2.023, trans_loss=5.069, nll_loss=2.28, w2v_ctc_loss=0.68, task_loss=3.49, contrastive_loss=0, total=4078.99, n_correct=2588.54, ppl=4.86, accuracy=63.46, wps=13679.1, ups=1.68, wpb=8158, bsz=288.4, num_updates=22500, lr=9.42809e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=59, gb_free=14.5, wall=17646
2023-08-24 07:10:12 | INFO | train_inner | epoch 016:    498 / 1474 loss=2.016, trans_loss=5.068, nll_loss=2.281, w2v_ctc_loss=0.677, task_loss=3.175, contrastive_loss=0, total=4167.57, n_correct=2650.19, ppl=4.86, accuracy=63.591, wps=13716.2, ups=1.65, wpb=8335.1, bsz=316.8, num_updates=22600, lr=9.40721e-05, gnorm=0.51, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=17707
2023-08-24 07:10:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 07:11:13 | INFO | train_inner | epoch 016:    599 / 1474 loss=2.02, trans_loss=5.07, nll_loss=2.283, w2v_ctc_loss=0.68, task_loss=3.309, contrastive_loss=0, total=4131.14, n_correct=2627.12, ppl=4.87, accuracy=63.593, wps=13603.5, ups=1.65, wpb=8262.3, bsz=300, num_updates=22700, lr=9.38647e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=17768
2023-08-24 07:12:13 | INFO | train_inner | epoch 016:    699 / 1474 loss=2.024, trans_loss=5.078, nll_loss=2.293, w2v_ctc_loss=0.683, task_loss=3.359, contrastive_loss=0, total=4096.68, n_correct=2595.97, ppl=4.9, accuracy=63.368, wps=13689.4, ups=1.67, wpb=8193.4, bsz=297.2, num_updates=22800, lr=9.36586e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=17827
2023-08-24 07:13:13 | INFO | train_inner | epoch 016:    799 / 1474 loss=2.018, trans_loss=5.078, nll_loss=2.293, w2v_ctc_loss=0.672, task_loss=3.179, contrastive_loss=0, total=4173.41, n_correct=2644.55, ppl=4.9, accuracy=63.367, wps=13860.6, ups=1.66, wpb=8346.8, bsz=309.5, num_updates=22900, lr=9.34539e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=17888
2023-08-24 07:14:13 | INFO | train_inner | epoch 016:    899 / 1474 loss=2.02, trans_loss=5.075, nll_loss=2.291, w2v_ctc_loss=0.679, task_loss=3.203, contrastive_loss=0, total=4153.99, n_correct=2637.25, ppl=4.89, accuracy=63.487, wps=13837.5, ups=1.67, wpb=8308, bsz=309, num_updates=23000, lr=9.32505e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=59, gb_free=12.7, wall=17948
2023-08-24 07:15:14 | INFO | train_inner | epoch 016:    999 / 1474 loss=2.03, trans_loss=5.085, nll_loss=2.302, w2v_ctc_loss=0.693, task_loss=3.39, contrastive_loss=0, total=4114.34, n_correct=2598.79, ppl=4.93, accuracy=63.164, wps=13551.5, ups=1.65, wpb=8228.7, bsz=301, num_updates=23100, lr=9.30484e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=18008
2023-08-24 07:16:14 | INFO | train_inner | epoch 016:   1099 / 1474 loss=2.034, trans_loss=5.093, nll_loss=2.313, w2v_ctc_loss=0.695, task_loss=3.486, contrastive_loss=0, total=4122.73, n_correct=2600.3, ppl=4.97, accuracy=63.072, wps=13678.4, ups=1.66, wpb=8245.5, bsz=296.3, num_updates=23200, lr=9.28477e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=18069
2023-08-24 07:17:15 | INFO | train_inner | epoch 016:   1199 / 1474 loss=2.025, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.676, task_loss=3.36, contrastive_loss=0, total=4162.91, n_correct=2630.62, ppl=4.95, accuracy=63.192, wps=13631.7, ups=1.64, wpb=8325.8, bsz=307.3, num_updates=23300, lr=9.26482e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=14.9, wall=18130
2023-08-24 07:18:16 | INFO | train_inner | epoch 016:   1299 / 1474 loss=2.032, trans_loss=5.091, nll_loss=2.31, w2v_ctc_loss=0.696, task_loss=3.243, contrastive_loss=0, total=4129.01, n_correct=2609.78, ppl=4.96, accuracy=63.206, wps=13637.8, ups=1.65, wpb=8258, bsz=310.6, num_updates=23400, lr=9.245e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=18190
2023-08-24 07:19:16 | INFO | train_inner | epoch 016:   1399 / 1474 loss=2.027, trans_loss=5.089, nll_loss=2.31, w2v_ctc_loss=0.691, task_loss=3.115, contrastive_loss=0, total=4213.36, n_correct=2661.94, ppl=4.96, accuracy=63.179, wps=13960.6, ups=1.66, wpb=8426.7, bsz=323.2, num_updates=23500, lr=9.22531e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=18251
2023-08-24 07:20:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:20:35 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.163 | trans_loss 5.565 | nll_loss 2.839 | w2v_ctc_loss 1.337 | task_loss 11.551 | contrastive_loss 0 | total 4003.4 | n_correct 2481.9 | ppl 7.16 | accuracy 61.995 | uer 17.442 | wer 19.317 | raw_wer 19.317 | bleu 19.99 | wps 1581.6 | wpb 4003.4 | bsz 141.8 | num_updates 23575 | best_bleu 20.12
2023-08-24 07:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23575 updates
2023-08-24 07:20:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.9909.pt
2023-08-24 07:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.9909.pt
2023-08-24 07:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.9909.pt (epoch 16 @ 23575 updates, score 19.99) (writing took 6.807748986990191 seconds)
2023-08-24 07:20:42 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-24 07:20:42 | INFO | train | epoch 016 | loss 2.023 | trans_loss 5.077 | nll_loss 2.292 | w2v_ctc_loss 0.682 | task_loss 3.289 | contrastive_loss 0 | total 4138.54 | n_correct 2623.51 | ppl 4.9 | accuracy 63.392 | wps 13010.8 | ups 1.57 | wpb 8277.1 | bsz 305.7 | num_updates 23575 | lr 9.21063e-05 | gnorm 0.51 | clip 0 | loss_scale 64 | train_wall 880 | gb_free 15.3 | wall 18337
2023-08-24 07:20:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 07:20:42 | INFO | fairseq.trainer | begin training epoch 17
2023-08-24 07:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 07:21:05 | INFO | train_inner | epoch 017:     25 / 1474 loss=2.019, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.673, task_loss=3.335, contrastive_loss=0, total=4145.29, n_correct=2632.45, ppl=4.87, accuracy=63.505, wps=7650.5, ups=0.92, wpb=8290.6, bsz=303.6, num_updates=23600, lr=9.20575e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=18359
2023-08-24 07:22:05 | INFO | train_inner | epoch 017:    125 / 1474 loss=2.012, trans_loss=5.049, nll_loss=2.255, w2v_ctc_loss=0.68, task_loss=3.389, contrastive_loss=0, total=4118.29, n_correct=2632.25, ppl=4.77, accuracy=63.916, wps=13687.7, ups=1.66, wpb=8236.6, bsz=295.5, num_updates=23700, lr=9.1863e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=18419
2023-08-24 07:23:05 | INFO | train_inner | epoch 017:    225 / 1474 loss=2.004, trans_loss=5.047, nll_loss=2.254, w2v_ctc_loss=0.664, task_loss=3.15, contrastive_loss=0, total=4153.83, n_correct=2655.92, ppl=4.77, accuracy=63.939, wps=13727.4, ups=1.65, wpb=8307.7, bsz=316, num_updates=23800, lr=9.16698e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=18480
2023-08-24 07:24:05 | INFO | train_inner | epoch 017:    325 / 1474 loss=2.008, trans_loss=5.052, nll_loss=2.259, w2v_ctc_loss=0.669, task_loss=3.279, contrastive_loss=0, total=4156.07, n_correct=2658.98, ppl=4.79, accuracy=63.978, wps=13830.9, ups=1.66, wpb=8312.1, bsz=305.6, num_updates=23900, lr=9.14779e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=59, gb_free=15.4, wall=18540
2023-08-24 07:25:06 | INFO | train_inner | epoch 017:    425 / 1474 loss=2.009, trans_loss=5.055, nll_loss=2.264, w2v_ctc_loss=0.673, task_loss=3.278, contrastive_loss=0, total=4137.22, n_correct=2649.6, ppl=4.8, accuracy=64.043, wps=13705.1, ups=1.66, wpb=8274.4, bsz=305.6, num_updates=24000, lr=9.12871e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=18600
2023-08-24 07:25:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:25:40 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.572 | nll_loss 2.845 | w2v_ctc_loss 1.349 | task_loss 11.522 | contrastive_loss 0 | total 4003.4 | n_correct 2473.9 | ppl 7.18 | accuracy 61.795 | uer 17.222 | wer 19.131 | raw_wer 19.131 | bleu 19.45 | wps 1568.7 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.12
2023-08-24 07:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-24 07:25:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_24000.pt
2023-08-24 07:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_24000.pt
2023-08-24 07:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.45) (writing took 8.387583720032126 seconds)
2023-08-24 07:26:50 | INFO | train_inner | epoch 017:    525 / 1474 loss=2.013, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.678, task_loss=3.368, contrastive_loss=0, total=4198.45, n_correct=2674.72, ppl=4.82, accuracy=63.707, wps=8090.3, ups=0.96, wpb=8396.9, bsz=311.3, num_updates=24100, lr=9.10975e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=14.1, wall=18704
2023-08-24 07:27:50 | INFO | train_inner | epoch 017:    625 / 1474 loss=2.01, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.667, task_loss=3.304, contrastive_loss=0, total=4166.23, n_correct=2658.98, ppl=4.83, accuracy=63.822, wps=13806.7, ups=1.66, wpb=8332.5, bsz=302.1, num_updates=24200, lr=9.09091e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=18764
2023-08-24 07:28:50 | INFO | train_inner | epoch 017:    725 / 1474 loss=2.022, trans_loss=5.072, nll_loss=2.287, w2v_ctc_loss=0.688, task_loss=3.265, contrastive_loss=0, total=4162.79, n_correct=2647.68, ppl=4.88, accuracy=63.603, wps=13828.9, ups=1.66, wpb=8325.6, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=18825
2023-08-24 07:29:50 | INFO | train_inner | epoch 017:    825 / 1474 loss=2.016, trans_loss=5.067, nll_loss=2.278, w2v_ctc_loss=0.678, task_loss=3.284, contrastive_loss=0, total=4095.17, n_correct=2606.11, ppl=4.85, accuracy=63.639, wps=13597.8, ups=1.66, wpb=8190.3, bsz=297.6, num_updates=24400, lr=9.05357e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=60, gb_free=15, wall=18885
2023-08-24 07:30:50 | INFO | train_inner | epoch 017:    925 / 1474 loss=2.015, trans_loss=5.069, nll_loss=2.283, w2v_ctc_loss=0.676, task_loss=3.281, contrastive_loss=0, total=4105.79, n_correct=2612.16, ppl=4.87, accuracy=63.621, wps=13807.4, ups=1.68, wpb=8211.6, bsz=302.4, num_updates=24500, lr=9.03508e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=18944
2023-08-24 07:31:50 | INFO | train_inner | epoch 017:   1025 / 1474 loss=2.015, trans_loss=5.065, nll_loss=2.279, w2v_ctc_loss=0.679, task_loss=3.234, contrastive_loss=0, total=4125.36, n_correct=2627.07, ppl=4.85, accuracy=63.681, wps=13845.1, ups=1.68, wpb=8250.7, bsz=307.3, num_updates=24600, lr=9.0167e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=59, gb_free=14.8, wall=19004
2023-08-24 07:32:49 | INFO | train_inner | epoch 017:   1125 / 1474 loss=2.013, trans_loss=5.065, nll_loss=2.278, w2v_ctc_loss=0.667, task_loss=3.465, contrastive_loss=0, total=4049.08, n_correct=2580.86, ppl=4.85, accuracy=63.739, wps=13580.8, ups=1.68, wpb=8098.2, bsz=289.9, num_updates=24700, lr=8.99843e-05, gnorm=0.52, clip=0, loss_scale=128, train_wall=59, gb_free=14.9, wall=19063
2023-08-24 07:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 07:33:51 | INFO | train_inner | epoch 017:   1226 / 1474 loss=2.018, trans_loss=5.077, nll_loss=2.295, w2v_ctc_loss=0.674, task_loss=3.186, contrastive_loss=0, total=4184.09, n_correct=2648.41, ppl=4.91, accuracy=63.297, wps=13589.6, ups=1.62, wpb=8368.2, bsz=324.5, num_updates=24800, lr=8.98027e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=61, gb_free=13.5, wall=19125
2023-08-24 07:34:52 | INFO | train_inner | epoch 017:   1326 / 1474 loss=2.012, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.666, task_loss=3.217, contrastive_loss=0, total=4166.32, n_correct=2649.1, ppl=4.88, accuracy=63.584, wps=13697, ups=1.64, wpb=8332.6, bsz=311.2, num_updates=24900, lr=8.96221e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=19186
2023-08-24 07:35:52 | INFO | train_inner | epoch 017:   1426 / 1474 loss=2.015, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.673, task_loss=3.297, contrastive_loss=0, total=4115.33, n_correct=2615.93, ppl=4.88, accuracy=63.565, wps=13515.3, ups=1.64, wpb=8230.7, bsz=303.3, num_updates=25000, lr=8.94427e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=11.3, wall=19247
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 07:36:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
2023-08-24 07:36:55 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.159 | trans_loss 5.558 | nll_loss 2.837 | w2v_ctc_loss 1.336 | task_loss 11.532 | contrastive_loss 0 | total 4003.4 | n_correct 2478.5 | ppl 7.14 | accuracy 61.91 | uer 17.405 | wer 19.164 | raw_wer 19.164 | bleu 19.88 | wps 1606.9 | wpb 4003.4 | bsz 141.8 | num_updates 25048 | best_bleu 20.12
2023-08-24 07:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25048 updates
2023-08-24 07:36:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.8801.pt
2023-08-24 07:36:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.8801.pt
2023-08-24 07:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_19.8801.pt (epoch 17 @ 25048 updates, score 19.88) (writing took 6.642691320972517 seconds)
2023-08-24 07:37:02 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-24 07:37:02 | INFO | train | epoch 017 | loss 2.013 | trans_loss 5.063 | nll_loss 2.275 | w2v_ctc_loss 0.674 | task_loss 3.286 | contrastive_loss 0 | total 4138.87 | n_correct 2637.69 | ppl 4.84 | accuracy 63.73 | wps 12445.9 | ups 1.5 | wpb 8277.7 | bsz 305.7 | num_updates 25048 | lr 8.9357e-05 | gnorm 0.51 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 16.3 | wall 19316
2023-08-24 07:37:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 07:37:02 | INFO | fairseq.trainer | begin training epoch 18
2023-08-24 07:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 07:37:41 | INFO | train_inner | epoch 018:     52 / 1474 loss=2.011, trans_loss=5.058, nll_loss=2.269, w2v_ctc_loss=0.676, task_loss=3.343, contrastive_loss=0, total=4144.39, n_correct=2647.62, ppl=4.82, accuracy=63.884, wps=7627.1, ups=0.92, wpb=8288.8, bsz=303.7, num_updates=25100, lr=8.92644e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=19355
2023-08-24 07:38:42 | INFO | train_inner | epoch 018:    152 / 1474 loss=1.992, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.652, task_loss=3.148, contrastive_loss=0, total=4146.83, n_correct=2665.62, ppl=4.7, accuracy=64.281, wps=13687.4, ups=1.65, wpb=8293.7, bsz=311.2, num_updates=25200, lr=8.90871e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=19416
2023-08-24 07:39:42 | INFO | train_inner | epoch 018:    252 / 1474 loss=1.993, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.659, task_loss=3.195, contrastive_loss=0, total=4158.7, n_correct=2678.07, ppl=4.71, accuracy=64.397, wps=13760.1, ups=1.65, wpb=8317.4, bsz=312.4, num_updates=25300, lr=8.89108e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=9.6, wall=19477
2023-08-24 07:40:43 | INFO | train_inner | epoch 018:    352 / 1474 loss=2, trans_loss=5.042, nll_loss=2.246, w2v_ctc_loss=0.661, task_loss=3.32, contrastive_loss=0, total=4169.64, n_correct=2677.2, ppl=4.74, accuracy=64.207, wps=13695.8, ups=1.64, wpb=8339.3, bsz=302.8, num_updates=25400, lr=8.87357e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=19537
2023-08-24 07:41:44 | INFO | train_inner | epoch 018:    452 / 1474 loss=2.007, trans_loss=5.048, nll_loss=2.255, w2v_ctc_loss=0.669, task_loss=3.508, contrastive_loss=0, total=4091.07, n_correct=2617.94, ppl=4.77, accuracy=63.992, wps=13509.2, ups=1.65, wpb=8182.1, bsz=295, num_updates=25500, lr=8.85615e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=19598
2023-08-24 07:42:44 | INFO | train_inner | epoch 018:    552 / 1474 loss=1.991, trans_loss=5.036, nll_loss=2.241, w2v_ctc_loss=0.657, task_loss=2.949, contrastive_loss=0, total=4206.23, n_correct=2707.02, ppl=4.73, accuracy=64.357, wps=14038.5, ups=1.67, wpb=8412.5, bsz=328.7, num_updates=25600, lr=8.83883e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=59, gb_free=14.7, wall=19658
2023-08-24 07:43:43 | INFO | train_inner | epoch 018:    652 / 1474 loss=2.009, trans_loss=5.058, nll_loss=2.269, w2v_ctc_loss=0.668, task_loss=3.367, contrastive_loss=0, total=4099.25, n_correct=2617.48, ppl=4.82, accuracy=63.853, wps=13722.3, ups=1.67, wpb=8198.5, bsz=299.8, num_updates=25700, lr=8.82162e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=59, gb_free=15, wall=19718
2023-08-24 07:44:44 | INFO | train_inner | epoch 018:    752 / 1474 loss=2.009, trans_loss=5.055, nll_loss=2.266, w2v_ctc_loss=0.674, task_loss=3.176, contrastive_loss=0, total=4203.13, n_correct=2686.25, ppl=4.81, accuracy=63.911, wps=13806.8, ups=1.64, wpb=8406.3, bsz=320, num_updates=25800, lr=8.80451e-05, gnorm=0.506, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=19779
2023-08-24 07:45:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 07:45:46 | INFO | train_inner | epoch 018:    853 / 1474 loss=2.007, trans_loss=5.055, nll_loss=2.265, w2v_ctc_loss=0.667, task_loss=3.319, contrastive_loss=0, total=4162.27, n_correct=2664.93, ppl=4.81, accuracy=64.026, wps=13546.4, ups=1.63, wpb=8324.5, bsz=303.1, num_updates=25900, lr=8.7875e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=19840
2023-08-24 07:46:46 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.995, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.654, task_loss=3.05, contrastive_loss=0, total=4141.27, n_correct=2659.35, ppl=4.77, accuracy=64.216, wps=13823, ups=1.67, wpb=8282.5, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=59, gb_free=16, wall=19900
2023-08-24 07:46:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:47:19 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.164 | trans_loss 5.566 | nll_loss 2.839 | w2v_ctc_loss 1.337 | task_loss 11.546 | contrastive_loss 0 | total 4003.4 | n_correct 2480.4 | ppl 7.15 | accuracy 61.957 | uer 17.355 | wer 19.28 | raw_wer 19.28 | bleu 19.78 | wps 1610.2 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.12
2023-08-24 07:47:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-24 07:47:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_18_26000.pt
2023-08-24 07:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_18_26000.pt
2023-08-24 07:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.78) (writing took 7.479830657015555 seconds)
2023-08-24 07:48:27 | INFO | train_inner | epoch 018:   1053 / 1474 loss=2.007, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.665, task_loss=3.415, contrastive_loss=0, total=4134.55, n_correct=2643.26, ppl=4.81, accuracy=63.931, wps=8166.8, ups=0.99, wpb=8269.1, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=15.9, wall=20001
2023-08-24 07:49:27 | INFO | train_inner | epoch 018:   1153 / 1474 loss=2.001, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.663, task_loss=3.124, contrastive_loss=0, total=4157.63, n_correct=2666.36, ppl=4.77, accuracy=64.132, wps=13836, ups=1.66, wpb=8315.3, bsz=314, num_updates=26200, lr=8.73704e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=20061
2023-08-24 07:50:27 | INFO | train_inner | epoch 018:   1253 / 1474 loss=2.009, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.662, task_loss=3.546, contrastive_loss=0, total=4085.66, n_correct=2608.81, ppl=4.84, accuracy=63.853, wps=13589.3, ups=1.66, wpb=8171.3, bsz=286.6, num_updates=26300, lr=8.72041e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=59, gb_free=17.4, wall=20121
2023-08-24 07:51:27 | INFO | train_inner | epoch 018:   1353 / 1474 loss=2.017, trans_loss=5.07, nll_loss=2.285, w2v_ctc_loss=0.679, task_loss=3.518, contrastive_loss=0, total=4065.6, n_correct=2588.87, ppl=4.87, accuracy=63.677, wps=13594.6, ups=1.67, wpb=8131.2, bsz=291.1, num_updates=26400, lr=8.70388e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=13, wall=20181
2023-08-24 07:52:28 | INFO | train_inner | epoch 018:   1453 / 1474 loss=2.014, trans_loss=5.067, nll_loss=2.281, w2v_ctc_loss=0.674, task_loss=3.431, contrastive_loss=0, total=4122.48, n_correct=2624.89, ppl=4.86, accuracy=63.673, wps=13577, ups=1.65, wpb=8245, bsz=299.5, num_updates=26500, lr=8.68744e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=20242
2023-08-24 07:52:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 07:53:14 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.167 | trans_loss 5.565 | nll_loss 2.842 | w2v_ctc_loss 1.352 | task_loss 11.47 | contrastive_loss 0 | total 4003.4 | n_correct 2481.4 | ppl 7.17 | accuracy 61.982 | uer 17.325 | wer 19.22 | raw_wer 19.22 | bleu 20.02 | wps 1582.4 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 20.12
2023-08-24 07:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-08-24 07:53:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0209.pt
2023-08-24 07:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0209.pt
2023-08-24 07:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0209.pt (epoch 18 @ 26521 updates, score 20.02) (writing took 6.880317621049471 seconds)
2023-08-24 07:53:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-24 07:53:22 | INFO | train | epoch 018 | loss 2.004 | trans_loss 5.05 | nll_loss 2.259 | w2v_ctc_loss 0.665 | task_loss 3.285 | contrastive_loss 0 | total 4138.3 | n_correct 2649.98 | ppl 4.79 | accuracy 64.036 | wps 12443 | ups 1.5 | wpb 8276.6 | bsz 305.6 | num_updates 26521 | lr 8.684e-05 | gnorm 0.513 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 15.8 | wall 20296
2023-08-24 07:53:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 07:53:22 | INFO | fairseq.trainer | begin training epoch 19
2023-08-24 07:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 07:54:17 | INFO | train_inner | epoch 019:     79 / 1474 loss=1.992, trans_loss=5.026, nll_loss=2.227, w2v_ctc_loss=0.655, task_loss=3.292, contrastive_loss=0, total=4101.48, n_correct=2644.58, ppl=4.68, accuracy=64.479, wps=7521.1, ups=0.92, wpb=8203, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=20351
2023-08-24 07:55:17 | INFO | train_inner | epoch 019:    179 / 1474 loss=1.988, trans_loss=5.02, nll_loss=2.219, w2v_ctc_loss=0.663, task_loss=3.062, contrastive_loss=0, total=4227.39, n_correct=2734.29, ppl=4.65, accuracy=64.68, wps=13910.6, ups=1.65, wpb=8454.8, bsz=324.7, num_updates=26700, lr=8.65485e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=20412
2023-08-24 07:56:17 | INFO | train_inner | epoch 019:    279 / 1474 loss=1.989, trans_loss=5.022, nll_loss=2.221, w2v_ctc_loss=0.659, task_loss=3.242, contrastive_loss=0, total=4186.65, n_correct=2710.41, ppl=4.66, accuracy=64.739, wps=13981.5, ups=1.67, wpb=8373.3, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=59, gb_free=13.6, wall=20472
2023-08-24 07:57:18 | INFO | train_inner | epoch 019:    379 / 1474 loss=1.991, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.652, task_loss=3.261, contrastive_loss=0, total=4165.84, n_correct=2686.01, ppl=4.7, accuracy=64.477, wps=13772.6, ups=1.65, wpb=8331.7, bsz=310, num_updates=26900, lr=8.62261e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=20532
2023-08-24 07:58:18 | INFO | train_inner | epoch 019:    479 / 1474 loss=1.993, trans_loss=5.033, nll_loss=2.237, w2v_ctc_loss=0.656, task_loss=3.356, contrastive_loss=0, total=4122.98, n_correct=2658.48, ppl=4.71, accuracy=64.48, wps=13722.1, ups=1.66, wpb=8246, bsz=302.7, num_updates=27000, lr=8.60663e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=59, gb_free=17.1, wall=20592
2023-08-24 07:59:18 | INFO | train_inner | epoch 019:    579 / 1474 loss=1.993, trans_loss=5.035, nll_loss=2.239, w2v_ctc_loss=0.653, task_loss=3.24, contrastive_loss=0, total=4121.66, n_correct=2655.32, ppl=4.72, accuracy=64.424, wps=13744.6, ups=1.67, wpb=8243.3, bsz=304.4, num_updates=27100, lr=8.59074e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=20652
2023-08-24 08:00:18 | INFO | train_inner | epoch 019:    679 / 1474 loss=1.984, trans_loss=5.034, nll_loss=2.239, w2v_ctc_loss=0.642, task_loss=2.973, contrastive_loss=0, total=4205.65, n_correct=2716.02, ppl=4.72, accuracy=64.58, wps=14060.7, ups=1.67, wpb=8411.3, bsz=322.9, num_updates=27200, lr=8.57493e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=20712
2023-08-24 08:01:19 | INFO | train_inner | epoch 019:    779 / 1474 loss=2, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.669, task_loss=3.387, contrastive_loss=0, total=4120.36, n_correct=2648.09, ppl=4.73, accuracy=64.268, wps=13552.8, ups=1.64, wpb=8240.7, bsz=298.5, num_updates=27300, lr=8.55921e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=13.7, wall=20773
2023-08-24 08:02:19 | INFO | train_inner | epoch 019:    879 / 1474 loss=1.999, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.661, task_loss=3.275, contrastive_loss=0, total=4176.52, n_correct=2684.4, ppl=4.76, accuracy=64.274, wps=13861.1, ups=1.66, wpb=8353, bsz=309.8, num_updates=27400, lr=8.54358e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=20833
2023-08-24 08:03:20 | INFO | train_inner | epoch 019:    979 / 1474 loss=2.006, trans_loss=5.058, nll_loss=2.27, w2v_ctc_loss=0.663, task_loss=3.358, contrastive_loss=0, total=4079.93, n_correct=2604.5, ppl=4.82, accuracy=63.837, wps=13400.2, ups=1.64, wpb=8159.9, bsz=305, num_updates=27500, lr=8.52803e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=20894
2023-08-24 08:04:20 | INFO | train_inner | epoch 019:   1079 / 1474 loss=2.004, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.66, task_loss=3.49, contrastive_loss=0, total=4041.08, n_correct=2584.57, ppl=4.82, accuracy=63.957, wps=13448.2, ups=1.66, wpb=8082.2, bsz=292.3, num_updates=27600, lr=8.51257e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=20954
2023-08-24 08:05:20 | INFO | train_inner | epoch 019:   1179 / 1474 loss=2.004, trans_loss=5.055, nll_loss=2.266, w2v_ctc_loss=0.662, task_loss=3.305, contrastive_loss=0, total=4146.59, n_correct=2651.89, ppl=4.81, accuracy=63.954, wps=13767.5, ups=1.66, wpb=8293.2, bsz=310.1, num_updates=27700, lr=8.49719e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=60, gb_free=12, wall=21014
2023-08-24 08:06:20 | INFO | train_inner | epoch 019:   1279 / 1474 loss=2.004, trans_loss=5.058, nll_loss=2.27, w2v_ctc_loss=0.658, task_loss=3.329, contrastive_loss=0, total=4142.96, n_correct=2651.53, ppl=4.82, accuracy=64.001, wps=13781.1, ups=1.66, wpb=8285.9, bsz=300.3, num_updates=27800, lr=8.48189e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=21075
2023-08-24 08:07:21 | INFO | train_inner | epoch 019:   1379 / 1474 loss=2.003, trans_loss=5.051, nll_loss=2.26, w2v_ctc_loss=0.665, task_loss=3.381, contrastive_loss=0, total=4129.64, n_correct=2650.84, ppl=4.79, accuracy=64.191, wps=13698.2, ups=1.66, wpb=8259.3, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=21135
2023-08-24 08:08:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:08:52 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.162 | trans_loss 5.557 | nll_loss 2.831 | w2v_ctc_loss 1.352 | task_loss 11.546 | contrastive_loss 0 | total 4003.4 | n_correct 2483.8 | ppl 7.12 | accuracy 62.042 | uer 17.323 | wer 19.142 | raw_wer 19.142 | bleu 20.09 | wps 1528.2 | wpb 4003.4 | bsz 141.8 | num_updates 27995 | best_bleu 20.12
2023-08-24 08:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27995 updates
2023-08-24 08:08:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0909.pt
2023-08-24 08:08:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0909.pt
2023-08-24 08:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.0909.pt (epoch 19 @ 27995 updates, score 20.09) (writing took 6.725264327018522 seconds)
2023-08-24 08:08:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-24 08:08:59 | INFO | train | epoch 019 | loss 1.996 | trans_loss 5.04 | nll_loss 2.246 | w2v_ctc_loss 0.658 | task_loss 3.286 | contrastive_loss 0 | total 4138.65 | n_correct 2661.93 | ppl 4.74 | accuracy 64.319 | wps 13014.3 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 27995 | lr 8.4523e-05 | gnorm 0.516 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 17.3 | wall 21234
2023-08-24 08:08:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 08:08:59 | INFO | fairseq.trainer | begin training epoch 20
2023-08-24 08:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 08:09:10 | INFO | train_inner | epoch 020:      5 / 1474 loss=1.995, trans_loss=5.042, nll_loss=2.25, w2v_ctc_loss=0.654, task_loss=3.335, contrastive_loss=0, total=4115.52, n_correct=2645.19, ppl=4.76, accuracy=64.274, wps=7516.3, ups=0.91, wpb=8231, bsz=302.4, num_updates=28000, lr=8.45154e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=21244
2023-08-24 08:09:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:09:43 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.165 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.362 | task_loss 11.546 | contrastive_loss 0 | total 4003.4 | n_correct 2492 | ppl 7.1 | accuracy 62.247 | uer 17.24 | wer 19.119 | raw_wer 19.119 | bleu 20.47 | wps 1610.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.47
2023-08-24 08:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-24 08:09:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_20_28000.pt
2023-08-24 08:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_20_28000.pt
2023-08-24 08:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.47) (writing took 12.039701065048575 seconds)
2023-08-24 08:10:56 | INFO | train_inner | epoch 020:    105 / 1474 loss=1.976, trans_loss=5.006, nll_loss=2.201, w2v_ctc_loss=0.643, task_loss=3.173, contrastive_loss=0, total=4189.63, n_correct=2723.58, ppl=4.6, accuracy=65.008, wps=7881.9, ups=0.94, wpb=8379.3, bsz=312, num_updates=28100, lr=8.43649e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=21351
2023-08-24 08:11:57 | INFO | train_inner | epoch 020:    205 / 1474 loss=1.985, trans_loss=5.017, nll_loss=2.216, w2v_ctc_loss=0.649, task_loss=3.357, contrastive_loss=0, total=4166.91, n_correct=2698.01, ppl=4.64, accuracy=64.748, wps=13690.3, ups=1.64, wpb=8333.8, bsz=305, num_updates=28200, lr=8.42152e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=14.5, wall=21412
2023-08-24 08:12:57 | INFO | train_inner | epoch 020:    305 / 1474 loss=1.974, trans_loss=5.008, nll_loss=2.205, w2v_ctc_loss=0.643, task_loss=2.982, contrastive_loss=0, total=4184.03, n_correct=2722.21, ppl=4.61, accuracy=65.062, wps=14005.8, ups=1.67, wpb=8368.1, bsz=324.8, num_updates=28300, lr=8.40663e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=59, gb_free=14.7, wall=21471
2023-08-24 08:13:57 | INFO | train_inner | epoch 020:    405 / 1474 loss=1.984, trans_loss=5.018, nll_loss=2.217, w2v_ctc_loss=0.645, task_loss=3.306, contrastive_loss=0, total=4121.39, n_correct=2669.57, ppl=4.65, accuracy=64.774, wps=13643.3, ups=1.66, wpb=8242.8, bsz=298.9, num_updates=28400, lr=8.39181e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=21532
2023-08-24 08:14:58 | INFO | train_inner | epoch 020:    505 / 1474 loss=1.99, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.647, task_loss=3.415, contrastive_loss=0, total=4097.17, n_correct=2644.53, ppl=4.71, accuracy=64.545, wps=13571.6, ups=1.66, wpb=8194.3, bsz=297.3, num_updates=28500, lr=8.37708e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=21592
2023-08-24 08:15:58 | INFO | train_inner | epoch 020:    605 / 1474 loss=1.992, trans_loss=5.029, nll_loss=2.231, w2v_ctc_loss=0.653, task_loss=3.377, contrastive_loss=0, total=4109.2, n_correct=2646.71, ppl=4.7, accuracy=64.409, wps=13747.9, ups=1.67, wpb=8218.4, bsz=300.3, num_updates=28600, lr=8.36242e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=59, gb_free=13.9, wall=21652
2023-08-24 08:16:57 | INFO | train_inner | epoch 020:    705 / 1474 loss=1.998, trans_loss=5.037, nll_loss=2.242, w2v_ctc_loss=0.662, task_loss=3.399, contrastive_loss=0, total=4115.08, n_correct=2648.12, ppl=4.73, accuracy=64.352, wps=13746.7, ups=1.67, wpb=8230.2, bsz=293.8, num_updates=28700, lr=8.34784e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=59, gb_free=15.3, wall=21712
2023-08-24 08:17:58 | INFO | train_inner | epoch 020:    805 / 1474 loss=1.986, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.651, task_loss=3.196, contrastive_loss=0, total=4160.72, n_correct=2691.36, ppl=4.69, accuracy=64.685, wps=13833.4, ups=1.66, wpb=8321.4, bsz=310.1, num_updates=28800, lr=8.33333e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=21772
2023-08-24 08:18:58 | INFO | train_inner | epoch 020:    905 / 1474 loss=1.993, trans_loss=5.04, nll_loss=2.247, w2v_ctc_loss=0.651, task_loss=3.161, contrastive_loss=0, total=4144.96, n_correct=2664.11, ppl=4.75, accuracy=64.273, wps=13633.5, ups=1.64, wpb=8289.9, bsz=320.4, num_updates=28900, lr=8.3189e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=60, gb_free=14.2, wall=21833
2023-08-24 08:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 08:20:00 | INFO | train_inner | epoch 020:   1006 / 1474 loss=1.987, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.645, task_loss=3.28, contrastive_loss=0, total=4166.11, n_correct=2693.68, ppl=4.71, accuracy=64.657, wps=13576.9, ups=1.63, wpb=8332.2, bsz=306, num_updates=29000, lr=8.30455e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=21894
2023-08-24 08:21:01 | INFO | train_inner | epoch 020:   1106 / 1474 loss=1.995, trans_loss=5.042, nll_loss=2.25, w2v_ctc_loss=0.658, task_loss=3.103, contrastive_loss=0, total=4181.53, n_correct=2691.86, ppl=4.76, accuracy=64.375, wps=13753.7, ups=1.64, wpb=8363.1, bsz=320.2, num_updates=29100, lr=8.29027e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=21955
2023-08-24 08:22:01 | INFO | train_inner | epoch 020:   1206 / 1474 loss=1.999, trans_loss=5.034, nll_loss=2.238, w2v_ctc_loss=0.665, task_loss=3.644, contrastive_loss=0, total=4029.26, n_correct=2593.81, ppl=4.72, accuracy=64.374, wps=13454.6, ups=1.67, wpb=8058.5, bsz=282.4, num_updates=29200, lr=8.27606e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=22015
2023-08-24 08:23:02 | INFO | train_inner | epoch 020:   1306 / 1474 loss=1.994, trans_loss=5.042, nll_loss=2.25, w2v_ctc_loss=0.653, task_loss=3.434, contrastive_loss=0, total=4127.21, n_correct=2656.82, ppl=4.76, accuracy=64.373, wps=13514.3, ups=1.64, wpb=8254.4, bsz=299.9, num_updates=29300, lr=8.26192e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=14.6, wall=22076
2023-08-24 08:24:02 | INFO | train_inner | epoch 020:   1406 / 1474 loss=1.999, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.659, task_loss=3.524, contrastive_loss=0, total=4110.89, n_correct=2641.27, ppl=4.76, accuracy=64.251, wps=13692.7, ups=1.67, wpb=8221.8, bsz=291.6, num_updates=29400, lr=8.24786e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=59, gb_free=13.1, wall=22136
2023-08-24 08:24:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:25:16 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.135 | trans_loss 5.549 | nll_loss 2.822 | w2v_ctc_loss 1.277 | task_loss 11.539 | contrastive_loss 0 | total 4003.4 | n_correct 2491.7 | ppl 7.07 | accuracy 62.24 | uer 16.938 | wer 18.597 | raw_wer 18.597 | bleu 20.27 | wps 1576.3 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 20.47
2023-08-24 08:25:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-08-24 08:25:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.2704.pt
2023-08-24 08:25:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.2704.pt
2023-08-24 08:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.2704.pt (epoch 20 @ 29468 updates, score 20.27) (writing took 6.81596180901397 seconds)
2023-08-24 08:25:23 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-24 08:25:23 | INFO | train | epoch 020 | loss 1.989 | trans_loss 5.03 | nll_loss 2.233 | w2v_ctc_loss 0.651 | task_loss 3.286 | contrastive_loss 0 | total 4138.84 | n_correct 2672.06 | ppl 4.7 | accuracy 64.561 | wps 12394.9 | ups 1.5 | wpb 8277.7 | bsz 305.7 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.517 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 16.2 | wall 22217
2023-08-24 08:25:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 08:25:23 | INFO | fairseq.trainer | begin training epoch 21
2023-08-24 08:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 08:25:50 | INFO | train_inner | epoch 021:     32 / 1474 loss=1.984, trans_loss=5.031, nll_loss=2.236, w2v_ctc_loss=0.642, task_loss=3.092, contrastive_loss=0, total=4166.35, n_correct=2688.83, ppl=4.71, accuracy=64.537, wps=7696.2, ups=0.92, wpb=8332.7, bsz=319.4, num_updates=29500, lr=8.23387e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=59, gb_free=11, wall=22244
2023-08-24 08:26:50 | INFO | train_inner | epoch 021:    132 / 1474 loss=1.97, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.637, task_loss=3.092, contrastive_loss=0, total=4181.45, n_correct=2721.81, ppl=4.57, accuracy=65.092, wps=13916.7, ups=1.66, wpb=8362.9, bsz=317.6, num_updates=29600, lr=8.21995e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=59, gb_free=15, wall=22304
2023-08-24 08:27:50 | INFO | train_inner | epoch 021:    232 / 1474 loss=1.969, trans_loss=5.004, nll_loss=2.199, w2v_ctc_loss=0.633, task_loss=3.11, contrastive_loss=0, total=4167.12, n_correct=2715.23, ppl=4.59, accuracy=65.158, wps=13976.9, ups=1.68, wpb=8334.2, bsz=315.1, num_updates=29700, lr=8.2061e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=59, gb_free=11.6, wall=22364
2023-08-24 08:28:50 | INFO | train_inner | epoch 021:    332 / 1474 loss=1.98, trans_loss=5.01, nll_loss=2.206, w2v_ctc_loss=0.646, task_loss=3.364, contrastive_loss=0, total=4130.24, n_correct=2683.73, ppl=4.61, accuracy=64.978, wps=13598.4, ups=1.65, wpb=8260.5, bsz=303.6, num_updates=29800, lr=8.19232e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=22425
2023-08-24 08:29:50 | INFO | train_inner | epoch 021:    432 / 1474 loss=1.976, trans_loss=5.009, nll_loss=2.205, w2v_ctc_loss=0.641, task_loss=3.156, contrastive_loss=0, total=4186.28, n_correct=2725.76, ppl=4.61, accuracy=65.112, wps=14000.3, ups=1.67, wpb=8372.6, bsz=310.3, num_updates=29900, lr=8.17861e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=59, gb_free=17.1, wall=22485
2023-08-24 08:30:51 | INFO | train_inner | epoch 021:    532 / 1474 loss=1.978, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.645, task_loss=3.367, contrastive_loss=0, total=4096.33, n_correct=2664.25, ppl=4.6, accuracy=65.04, wps=13562, ups=1.66, wpb=8192.7, bsz=298, num_updates=30000, lr=8.16497e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=22545
2023-08-24 08:30:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:31:24 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.557 | nll_loss 2.828 | w2v_ctc_loss 1.375 | task_loss 11.633 | contrastive_loss 0 | total 4003.4 | n_correct 2488.3 | ppl 7.1 | accuracy 62.155 | uer 17.267 | wer 19.201 | raw_wer 19.201 | bleu 19.85 | wps 1592.4 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.47
2023-08-24 08:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-24 08:31:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_30000.pt
2023-08-24 08:31:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_30000.pt
2023-08-24 08:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.85) (writing took 7.48778055596631 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 08:32:33 | INFO | train_inner | epoch 021:    632 / 1474 loss=1.981, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.64, task_loss=3.267, contrastive_loss=0, total=4215.02, n_correct=2729.1, ppl=4.65, accuracy=64.747, wps=8272.1, ups=0.98, wpb=8430, bsz=314.6, num_updates=30100, lr=8.15139e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=22647
2023-08-24 08:33:33 | INFO | train_inner | epoch 021:    732 / 1474 loss=1.98, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.64, task_loss=3.291, contrastive_loss=0, total=4147.25, n_correct=2685.38, ppl=4.67, accuracy=64.751, wps=13776.6, ups=1.66, wpb=8294.5, bsz=308.5, num_updates=30200, lr=8.13788e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=22707
2023-08-24 08:34:33 | INFO | train_inner | epoch 021:    832 / 1474 loss=1.987, trans_loss=5.029, nll_loss=2.232, w2v_ctc_loss=0.645, task_loss=3.492, contrastive_loss=0, total=4071.46, n_correct=2631.8, ppl=4.7, accuracy=64.64, wps=13543.3, ups=1.66, wpb=8142.9, bsz=294.2, num_updates=30300, lr=8.12444e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=22767
2023-08-24 08:35:33 | INFO | train_inner | epoch 021:    932 / 1474 loss=1.979, trans_loss=5.016, nll_loss=2.216, w2v_ctc_loss=0.64, task_loss=3.278, contrastive_loss=0, total=4098.4, n_correct=2657.9, ppl=4.65, accuracy=64.852, wps=13668.4, ups=1.67, wpb=8196.8, bsz=301.3, num_updates=30400, lr=8.11107e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=59, gb_free=15.7, wall=22827
2023-08-24 08:36:33 | INFO | train_inner | epoch 021:   1032 / 1474 loss=1.992, trans_loss=5.039, nll_loss=2.246, w2v_ctc_loss=0.651, task_loss=3.369, contrastive_loss=0, total=4099.06, n_correct=2642.34, ppl=4.74, accuracy=64.462, wps=13677.6, ups=1.67, wpb=8198.1, bsz=297.6, num_updates=30500, lr=8.09776e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=15.8, wall=22887
2023-08-24 08:37:33 | INFO | train_inner | epoch 021:   1132 / 1474 loss=1.987, trans_loss=5.024, nll_loss=2.225, w2v_ctc_loss=0.649, task_loss=3.512, contrastive_loss=0, total=4127.16, n_correct=2674.34, ppl=4.68, accuracy=64.799, wps=13691, ups=1.66, wpb=8254.3, bsz=295.6, num_updates=30600, lr=8.08452e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=15.4, wall=22947
2023-08-24 08:38:33 | INFO | train_inner | epoch 021:   1232 / 1474 loss=1.981, trans_loss=5.025, nll_loss=2.229, w2v_ctc_loss=0.643, task_loss=3.101, contrastive_loss=0, total=4159.29, n_correct=2692.3, ppl=4.69, accuracy=64.73, wps=13864.4, ups=1.67, wpb=8318.6, bsz=312.4, num_updates=30700, lr=8.07134e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=59, gb_free=17.7, wall=23007
2023-08-24 08:39:33 | INFO | train_inner | epoch 021:   1332 / 1474 loss=1.983, trans_loss=5.024, nll_loss=2.228, w2v_ctc_loss=0.648, task_loss=3.187, contrastive_loss=0, total=4139.42, n_correct=2682.73, ppl=4.68, accuracy=64.809, wps=13713.1, ups=1.66, wpb=8278.8, bsz=311.8, num_updates=30800, lr=8.05823e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=60, gb_free=14.3, wall=23068
2023-08-24 08:40:34 | INFO | train_inner | epoch 021:   1432 / 1474 loss=1.999, trans_loss=5.039, nll_loss=2.246, w2v_ctc_loss=0.665, task_loss=3.487, contrastive_loss=0, total=4123.35, n_correct=2649.17, ppl=4.74, accuracy=64.248, wps=13565.1, ups=1.64, wpb=8246.7, bsz=301.4, num_updates=30900, lr=8.04518e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=23129
2023-08-24 08:41:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
2023-08-24 08:41:32 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.562 | nll_loss 2.836 | w2v_ctc_loss 1.323 | task_loss 11.604 | contrastive_loss 0 | total 4003.4 | n_correct 2486.1 | ppl 7.14 | accuracy 62.1 | uer 17.201 | wer 19.209 | raw_wer 19.209 | bleu 19.76 | wps 1642.9 | wpb 4003.4 | bsz 141.8 | num_updates 30942 | best_bleu 20.47
2023-08-24 08:41:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30942 updates
2023-08-24 08:41:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 08:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 08:41:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 21 @ 30942 updates, score 19.76) (writing took 5.707468491978943 seconds)
2023-08-24 08:41:38 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-24 08:41:38 | INFO | train | epoch 021 | loss 1.981 | trans_loss 5.019 | nll_loss 2.219 | w2v_ctc_loss 0.644 | task_loss 3.29 | contrastive_loss 0 | total 4138.65 | n_correct 2682.39 | ppl 4.66 | accuracy 64.813 | wps 12511.1 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 30942 | lr 8.03972e-05 | gnorm 0.515 | clip 0 | loss_scale 32 | train_wall 878 | gb_free 15.4 | wall 23192
2023-08-24 08:41:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 08:41:38 | INFO | fairseq.trainer | begin training epoch 22
2023-08-24 08:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 08:42:21 | INFO | train_inner | epoch 022:     58 / 1474 loss=1.978, trans_loss=5.007, nll_loss=2.204, w2v_ctc_loss=0.646, task_loss=3.315, contrastive_loss=0, total=4141.35, n_correct=2695.79, ppl=4.61, accuracy=65.094, wps=7770.8, ups=0.94, wpb=8282.7, bsz=300, num_updates=31000, lr=8.03219e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=23235
2023-08-24 08:43:21 | INFO | train_inner | epoch 022:    158 / 1474 loss=1.971, trans_loss=4.997, nll_loss=2.19, w2v_ctc_loss=0.641, task_loss=3.315, contrastive_loss=0, total=4119.8, n_correct=2685.9, ppl=4.56, accuracy=65.195, wps=13633.4, ups=1.65, wpb=8239.6, bsz=309.8, num_updates=31100, lr=8.01927e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=23296
2023-08-24 08:44:21 | INFO | train_inner | epoch 022:    258 / 1474 loss=1.964, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.629, task_loss=2.968, contrastive_loss=0, total=4246.49, n_correct=2773.99, ppl=4.55, accuracy=65.324, wps=14186.7, ups=1.67, wpb=8493, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=23355
2023-08-24 08:44:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 08:45:23 | INFO | train_inner | epoch 022:    359 / 1474 loss=1.975, trans_loss=5.003, nll_loss=2.198, w2v_ctc_loss=0.64, task_loss=3.311, contrastive_loss=0, total=4192.82, n_correct=2729.2, ppl=4.59, accuracy=65.092, wps=13636, ups=1.63, wpb=8385.6, bsz=311, num_updates=31300, lr=7.99361e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=23417
2023-08-24 08:46:23 | INFO | train_inner | epoch 022:    459 / 1474 loss=1.981, trans_loss=5.012, nll_loss=2.208, w2v_ctc_loss=0.646, task_loss=3.444, contrastive_loss=0, total=4131.12, n_correct=2682.64, ppl=4.62, accuracy=64.937, wps=13712.5, ups=1.66, wpb=8262.2, bsz=297.3, num_updates=31400, lr=7.98087e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=23477
2023-08-24 08:47:24 | INFO | train_inner | epoch 022:    559 / 1474 loss=1.975, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.642, task_loss=3.311, contrastive_loss=0, total=4153.54, n_correct=2705.13, ppl=4.6, accuracy=65.128, wps=13711.5, ups=1.65, wpb=8307.1, bsz=307.1, num_updates=31500, lr=7.96819e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=23538
2023-08-24 08:48:23 | INFO | train_inner | epoch 022:    659 / 1474 loss=1.964, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.624, task_loss=3.103, contrastive_loss=0, total=4143.91, n_correct=2705.43, ppl=4.57, accuracy=65.287, wps=13907.1, ups=1.68, wpb=8287.8, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=59, gb_free=15.7, wall=23597
2023-08-24 08:49:24 | INFO | train_inner | epoch 022:    759 / 1474 loss=1.976, trans_loss=5.007, nll_loss=2.204, w2v_ctc_loss=0.641, task_loss=3.38, contrastive_loss=0, total=4168.91, n_correct=2709, ppl=4.61, accuracy=64.981, wps=13778.8, ups=1.65, wpb=8337.8, bsz=303.5, num_updates=31700, lr=7.94301e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=23658
2023-08-24 08:50:24 | INFO | train_inner | epoch 022:    859 / 1474 loss=1.982, trans_loss=5.018, nll_loss=2.219, w2v_ctc_loss=0.642, task_loss=3.572, contrastive_loss=0, total=4079.59, n_correct=2643.41, ppl=4.65, accuracy=64.796, wps=13429.5, ups=1.65, wpb=8159.2, bsz=288.7, num_updates=31800, lr=7.93052e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=23719
2023-08-24 08:51:25 | INFO | train_inner | epoch 022:    959 / 1474 loss=1.969, trans_loss=5.009, nll_loss=2.207, w2v_ctc_loss=0.625, task_loss=3.293, contrastive_loss=0, total=4129.75, n_correct=2687.9, ppl=4.62, accuracy=65.086, wps=13694.8, ups=1.66, wpb=8259.5, bsz=303.9, num_updates=31900, lr=7.91808e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=23779
2023-08-24 08:52:25 | INFO | train_inner | epoch 022:   1059 / 1474 loss=1.969, trans_loss=5.007, nll_loss=2.205, w2v_ctc_loss=0.628, task_loss=3.129, contrastive_loss=0, total=4155.56, n_correct=2708.24, ppl=4.61, accuracy=65.171, wps=13885.2, ups=1.67, wpb=8311.1, bsz=315.3, num_updates=32000, lr=7.90569e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=23839
2023-08-24 08:52:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:52:57 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.161 | trans_loss 5.559 | nll_loss 2.834 | w2v_ctc_loss 1.34 | task_loss 11.539 | contrastive_loss 0 | total 4003.4 | n_correct 2488.2 | ppl 7.13 | accuracy 62.152 | uer 17.145 | wer 19.145 | raw_wer 19.145 | bleu 19.63 | wps 1649.1 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.47
2023-08-24 08:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-24 08:52:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_22_32000.pt
2023-08-24 08:52:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_22_32000.pt
2023-08-24 08:53:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.63) (writing took 6.319800617988221 seconds)
2023-08-24 08:54:04 | INFO | train_inner | epoch 022:   1159 / 1474 loss=1.99, trans_loss=5.031, nll_loss=2.236, w2v_ctc_loss=0.652, task_loss=3.451, contrastive_loss=0, total=4089.92, n_correct=2642.85, ppl=4.71, accuracy=64.619, wps=8216.4, ups=1, wpb=8179.8, bsz=292.2, num_updates=32100, lr=7.89337e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=23938
2023-08-24 08:55:05 | INFO | train_inner | epoch 022:   1259 / 1474 loss=1.974, trans_loss=5.019, nll_loss=2.221, w2v_ctc_loss=0.636, task_loss=3.067, contrastive_loss=0, total=4179.82, n_correct=2715.25, ppl=4.66, accuracy=64.961, wps=13794.6, ups=1.65, wpb=8359.6, bsz=322.5, num_updates=32200, lr=7.8811e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=23999
2023-08-24 08:56:05 | INFO | train_inner | epoch 022:   1359 / 1474 loss=1.971, trans_loss=5.012, nll_loss=2.212, w2v_ctc_loss=0.627, task_loss=3.241, contrastive_loss=0, total=4076.98, n_correct=2655.22, ppl=4.63, accuracy=65.127, wps=13613.2, ups=1.67, wpb=8154, bsz=303.1, num_updates=32300, lr=7.86889e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=59, gb_free=10.3, wall=24059
2023-08-24 08:57:05 | INFO | train_inner | epoch 022:   1459 / 1474 loss=1.989, trans_loss=5.029, nll_loss=2.232, w2v_ctc_loss=0.653, task_loss=3.541, contrastive_loss=0, total=4070.93, n_correct=2630.9, ppl=4.7, accuracy=64.627, wps=13521.2, ups=1.66, wpb=8141.9, bsz=286.5, num_updates=32400, lr=7.85674e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=24119
2023-08-24 08:57:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 08:57:47 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.155 | trans_loss 5.547 | nll_loss 2.818 | w2v_ctc_loss 1.348 | task_loss 11.56 | contrastive_loss 0 | total 4003.4 | n_correct 2499.5 | ppl 7.05 | accuracy 62.434 | uer 17.055 | wer 18.817 | raw_wer 18.817 | bleu 20.57 | wps 1646.4 | wpb 4003.4 | bsz 141.8 | num_updates 32415 | best_bleu 20.57
2023-08-24 08:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32415 updates
2023-08-24 08:57:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 08:57:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-24 08:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 22 @ 32415 updates, score 20.57) (writing took 11.40854751993902 seconds)
2023-08-24 08:57:58 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-24 08:57:58 | INFO | train | epoch 022 | loss 1.975 | trans_loss 5.009 | nll_loss 2.207 | w2v_ctc_loss 0.638 | task_loss 3.292 | contrastive_loss 0 | total 4137.49 | n_correct 2690.9 | ppl 4.62 | accuracy 65.037 | wps 12433.7 | ups 1.5 | wpb 8275 | bsz 305.2 | num_updates 32415 | lr 7.85492e-05 | gnorm 0.518 | clip 0 | loss_scale 32 | train_wall 879 | gb_free 11.6 | wall 24173
2023-08-24 08:57:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 08:57:59 | INFO | fairseq.trainer | begin training epoch 23
2023-08-24 08:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 08:58:57 | INFO | train_inner | epoch 023:     85 / 1474 loss=1.969, trans_loss=4.99, nll_loss=2.182, w2v_ctc_loss=0.641, task_loss=3.373, contrastive_loss=0, total=4094.01, n_correct=2676.55, ppl=4.54, accuracy=65.377, wps=7274.8, ups=0.89, wpb=8188, bsz=301, num_updates=32500, lr=7.84465e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=24232
2023-08-24 08:59:58 | INFO | train_inner | epoch 023:    185 / 1474 loss=1.964, trans_loss=4.985, nll_loss=2.175, w2v_ctc_loss=0.629, task_loss=3.441, contrastive_loss=0, total=4118.15, n_correct=2700.95, ppl=4.51, accuracy=65.586, wps=13623.3, ups=1.65, wpb=8236.3, bsz=296.2, num_updates=32600, lr=7.8326e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=24292
2023-08-24 09:00:58 | INFO | train_inner | epoch 023:    285 / 1474 loss=1.963, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.621, task_loss=3.313, contrastive_loss=0, total=4156.76, n_correct=2714.74, ppl=4.55, accuracy=65.309, wps=13727.7, ups=1.65, wpb=8313.5, bsz=305.6, num_updates=32700, lr=7.82062e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=24353
2023-08-24 09:01:59 | INFO | train_inner | epoch 023:    385 / 1474 loss=1.963, trans_loss=4.989, nll_loss=2.18, w2v_ctc_loss=0.624, task_loss=3.387, contrastive_loss=0, total=4114.42, n_correct=2696.45, ppl=4.53, accuracy=65.537, wps=13660, ups=1.66, wpb=8228.8, bsz=295.1, num_updates=32800, lr=7.80869e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=60, gb_free=13, wall=24413
2023-08-24 09:02:59 | INFO | train_inner | epoch 023:    485 / 1474 loss=1.965, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.63, task_loss=3.191, contrastive_loss=0, total=4156.07, n_correct=2712.43, ppl=4.56, accuracy=65.264, wps=13802.9, ups=1.66, wpb=8312.1, bsz=312.6, num_updates=32900, lr=7.79681e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=24473
2023-08-24 09:03:59 | INFO | train_inner | epoch 023:    585 / 1474 loss=1.957, trans_loss=4.985, nll_loss=2.175, w2v_ctc_loss=0.623, task_loss=3.122, contrastive_loss=0, total=4169.74, n_correct=2735.58, ppl=4.52, accuracy=65.606, wps=13910, ups=1.67, wpb=8339.5, bsz=314.9, num_updates=33000, lr=7.78499e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=24533
2023-08-24 09:04:59 | INFO | train_inner | epoch 023:    685 / 1474 loss=1.968, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.633, task_loss=3.313, contrastive_loss=0, total=4139.41, n_correct=2703.17, ppl=4.56, accuracy=65.303, wps=13679.4, ups=1.65, wpb=8278.8, bsz=301.3, num_updates=33100, lr=7.77322e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=24594
2023-08-24 09:05:59 | INFO | train_inner | epoch 023:    785 / 1474 loss=1.972, trans_loss=5.003, nll_loss=2.199, w2v_ctc_loss=0.638, task_loss=3.304, contrastive_loss=0, total=4149.58, n_correct=2706.46, ppl=4.59, accuracy=65.223, wps=13888.8, ups=1.67, wpb=8299.2, bsz=306.1, num_updates=33200, lr=7.76151e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=12.2, wall=24653
2023-08-24 09:07:00 | INFO | train_inner | epoch 023:    885 / 1474 loss=1.963, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.631, task_loss=2.967, contrastive_loss=0, total=4192.08, n_correct=2740.33, ppl=4.57, accuracy=65.369, wps=13876.7, ups=1.66, wpb=8384.2, bsz=327.6, num_updates=33300, lr=7.74984e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=24714
2023-08-24 09:08:00 | INFO | train_inner | epoch 023:    985 / 1474 loss=1.97, trans_loss=5.005, nll_loss=2.203, w2v_ctc_loss=0.629, task_loss=3.28, contrastive_loss=0, total=4165.47, n_correct=2708.95, ppl=4.6, accuracy=65.033, wps=13773.8, ups=1.65, wpb=8330.9, bsz=310, num_updates=33400, lr=7.73823e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=14.6, wall=24774
2023-08-24 09:09:00 | INFO | train_inner | epoch 023:   1085 / 1474 loss=1.985, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.654, task_loss=3.518, contrastive_loss=0, total=4083.13, n_correct=2649.86, ppl=4.64, accuracy=64.898, wps=13516.8, ups=1.66, wpb=8166.3, bsz=289.5, num_updates=33500, lr=7.72667e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=24835
2023-08-24 09:10:01 | INFO | train_inner | epoch 023:   1185 / 1474 loss=1.969, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.632, task_loss=3.294, contrastive_loss=0, total=4165.04, n_correct=2713.74, ppl=4.62, accuracy=65.155, wps=13698.7, ups=1.64, wpb=8330.1, bsz=308.3, num_updates=33600, lr=7.71517e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=11.7, wall=24896
2023-08-24 09:11:01 | INFO | train_inner | epoch 023:   1285 / 1474 loss=1.968, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.628, task_loss=3.188, contrastive_loss=0, total=4131.11, n_correct=2695.09, ppl=4.62, accuracy=65.239, wps=13786.8, ups=1.67, wpb=8262.2, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=24956
2023-08-24 09:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 09:12:03 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.98, trans_loss=5.027, nll_loss=2.231, w2v_ctc_loss=0.637, task_loss=3.32, contrastive_loss=0, total=4137.22, n_correct=2681.05, ppl=4.69, accuracy=64.803, wps=13481.4, ups=1.63, wpb=8274.4, bsz=304.3, num_updates=33800, lr=7.69231e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=25017
2023-08-24 09:12:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 09:13:29 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.165 | trans_loss 5.551 | nll_loss 2.819 | w2v_ctc_loss 1.374 | task_loss 11.59 | contrastive_loss 0 | total 4003.4 | n_correct 2498.9 | ppl 7.06 | accuracy 62.419 | uer 16.879 | wer 18.784 | raw_wer 18.784 | bleu 20.12 | wps 1649.3 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.57
2023-08-24 09:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-08-24 09:13:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1202.pt
2023-08-24 09:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1202.pt
2023-08-24 09:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1202.pt (epoch 23 @ 33888 updates, score 20.12) (writing took 9.246639157063328 seconds)
2023-08-24 09:13:38 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-24 09:13:38 | INFO | train | epoch 023 | loss 1.969 | trans_loss 5.001 | nll_loss 2.197 | w2v_ctc_loss 0.632 | task_loss 3.284 | contrastive_loss 0 | total 4138.41 | n_correct 2699.83 | ppl 4.58 | accuracy 65.238 | wps 12977 | ups 1.57 | wpb 8276.8 | bsz 305.6 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.518 | clip 0 | loss_scale 32 | train_wall 881 | gb_free 13.6 | wall 25112
2023-08-24 09:13:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 09:13:38 | INFO | fairseq.trainer | begin training epoch 24
2023-08-24 09:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 09:13:53 | INFO | train_inner | epoch 024:     12 / 1474 loss=1.974, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.628, task_loss=3.27, contrastive_loss=0, total=4095.53, n_correct=2657.24, ppl=4.66, accuracy=64.881, wps=7436.8, ups=0.91, wpb=8191.1, bsz=306.3, num_updates=33900, lr=7.68095e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=25127
2023-08-24 09:14:53 | INFO | train_inner | epoch 024:    112 / 1474 loss=1.952, trans_loss=4.973, nll_loss=2.16, w2v_ctc_loss=0.622, task_loss=3.06, contrastive_loss=0, total=4167.42, n_correct=2741.64, ppl=4.47, accuracy=65.787, wps=13881.3, ups=1.67, wpb=8334.8, bsz=323, num_updates=34000, lr=7.66965e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=25187
2023-08-24 09:14:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 09:15:26 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.556 | nll_loss 2.824 | w2v_ctc_loss 1.337 | task_loss 11.539 | contrastive_loss 0 | total 4003.4 | n_correct 2491.6 | ppl 7.08 | accuracy 62.237 | uer 16.903 | wer 18.761 | raw_wer 18.761 | bleu 20.27 | wps 1584.8 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.57
2023-08-24 09:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-24 09:15:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_34000.pt
2023-08-24 09:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_34000.pt
2023-08-24 09:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.27) (writing took 7.5733500310452655 seconds)
2023-08-24 09:16:35 | INFO | train_inner | epoch 024:    212 / 1474 loss=1.948, trans_loss=4.977, nll_loss=2.166, w2v_ctc_loss=0.61, task_loss=2.88, contrastive_loss=0, total=4247.08, n_correct=2792.77, ppl=4.49, accuracy=65.757, wps=8325.9, ups=0.98, wpb=8494.2, bsz=339.5, num_updates=34100, lr=7.6584e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=25289
2023-08-24 09:17:35 | INFO | train_inner | epoch 024:    312 / 1474 loss=1.953, trans_loss=4.978, nll_loss=2.166, w2v_ctc_loss=0.617, task_loss=3.168, contrastive_loss=0, total=4139.31, n_correct=2721.77, ppl=4.49, accuracy=65.754, wps=13798.6, ups=1.67, wpb=8278.6, bsz=308.4, num_updates=34200, lr=7.64719e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=25349
2023-08-24 09:18:35 | INFO | train_inner | epoch 024:    412 / 1474 loss=1.965, trans_loss=4.985, nll_loss=2.175, w2v_ctc_loss=0.628, task_loss=3.437, contrastive_loss=0, total=4157.07, n_correct=2722.16, ppl=4.52, accuracy=65.483, wps=13777.4, ups=1.66, wpb=8314.1, bsz=299.9, num_updates=34300, lr=7.63604e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=25409
2023-08-24 09:19:36 | INFO | train_inner | epoch 024:    512 / 1474 loss=1.964, trans_loss=4.988, nll_loss=2.179, w2v_ctc_loss=0.631, task_loss=3.361, contrastive_loss=0, total=4138.82, n_correct=2712.21, ppl=4.53, accuracy=65.531, wps=13658.9, ups=1.65, wpb=8277.6, bsz=301.6, num_updates=34400, lr=7.62493e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=25470
2023-08-24 09:20:36 | INFO | train_inner | epoch 024:    612 / 1474 loss=1.958, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.622, task_loss=3.26, contrastive_loss=0, total=4164.75, n_correct=2730.36, ppl=4.52, accuracy=65.559, wps=13811, ups=1.66, wpb=8329.5, bsz=309.1, num_updates=34500, lr=7.61387e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=25530
2023-08-24 09:21:37 | INFO | train_inner | epoch 024:    712 / 1474 loss=1.968, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.629, task_loss=3.409, contrastive_loss=0, total=4103.92, n_correct=2683.1, ppl=4.57, accuracy=65.379, wps=13536.5, ups=1.65, wpb=8207.8, bsz=294, num_updates=34600, lr=7.60286e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=11.9, wall=25591
2023-08-24 09:22:37 | INFO | train_inner | epoch 024:    812 / 1474 loss=1.962, trans_loss=4.997, nll_loss=2.192, w2v_ctc_loss=0.624, task_loss=3.31, contrastive_loss=0, total=4109.8, n_correct=2690.32, ppl=4.57, accuracy=65.461, wps=13631.2, ups=1.66, wpb=8219.6, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=25651
2023-08-24 09:23:37 | INFO | train_inner | epoch 024:    912 / 1474 loss=1.974, trans_loss=5.004, nll_loss=2.2, w2v_ctc_loss=0.634, task_loss=3.646, contrastive_loss=0, total=4042.08, n_correct=2633.57, ppl=4.59, accuracy=65.154, wps=13456.1, ups=1.66, wpb=8084.2, bsz=280.6, num_updates=34800, lr=7.58098e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=25711
2023-08-24 09:24:38 | INFO | train_inner | epoch 024:   1012 / 1474 loss=1.968, trans_loss=5.003, nll_loss=2.2, w2v_ctc_loss=0.627, task_loss=3.401, contrastive_loss=0, total=4140.44, n_correct=2699.76, ppl=4.59, accuracy=65.205, wps=13681.8, ups=1.65, wpb=8280.9, bsz=298.7, num_updates=34900, lr=7.57011e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=11.6, wall=25772
2023-08-24 09:25:38 | INFO | train_inner | epoch 024:   1112 / 1474 loss=1.959, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.626, task_loss=3.161, contrastive_loss=0, total=4134.93, n_correct=2711.22, ppl=4.53, accuracy=65.569, wps=13783.5, ups=1.67, wpb=8269.9, bsz=309.4, num_updates=35000, lr=7.55929e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=59, gb_free=16.2, wall=25832
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 09:26:38 | INFO | train_inner | epoch 024:   1212 / 1474 loss=1.964, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.626, task_loss=3.276, contrastive_loss=0, total=4144.49, n_correct=2706.61, ppl=4.58, accuracy=65.306, wps=13705.2, ups=1.65, wpb=8289, bsz=309.8, num_updates=35100, lr=7.54851e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=25892
2023-08-24 09:27:39 | INFO | train_inner | epoch 024:   1312 / 1474 loss=1.972, trans_loss=5.004, nll_loss=2.2, w2v_ctc_loss=0.638, task_loss=3.519, contrastive_loss=0, total=4110.93, n_correct=2685.58, ppl=4.6, accuracy=65.328, wps=13494.9, ups=1.64, wpb=8221.9, bsz=293, num_updates=35200, lr=7.53778e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=13.4, wall=25953
2023-08-24 09:28:39 | INFO | train_inner | epoch 024:   1412 / 1474 loss=1.972, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.637, task_loss=3.424, contrastive_loss=0, total=4088.73, n_correct=2667.83, ppl=4.61, accuracy=65.248, wps=13635.7, ups=1.67, wpb=8177.5, bsz=294.1, num_updates=35300, lr=7.5271e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=26013
2023-08-24 09:29:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
2023-08-24 09:29:49 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.156 | trans_loss 5.547 | nll_loss 2.816 | w2v_ctc_loss 1.352 | task_loss 11.608 | contrastive_loss 0 | total 4003.4 | n_correct 2491.5 | ppl 7.04 | accuracy 62.235 | uer 17.044 | wer 18.832 | raw_wer 18.832 | bleu 20.1 | wps 1652.4 | wpb 4003.4 | bsz 141.8 | num_updates 35362 | best_bleu 20.57
2023-08-24 09:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35362 updates
2023-08-24 09:29:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1003.pt
2023-08-24 09:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1003.pt
2023-08-24 09:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.1003.pt (epoch 24 @ 35362 updates, score 20.1) (writing took 6.865008431021124 seconds)
2023-08-24 09:29:56 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-24 09:29:56 | INFO | train | epoch 024 | loss 1.962 | trans_loss 4.992 | nll_loss 2.185 | w2v_ctc_loss 0.626 | task_loss 3.284 | contrastive_loss 0 | total 4138.65 | n_correct 2709.56 | ppl 4.55 | accuracy 65.47 | wps 12472.9 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 35362 | lr 7.5205e-05 | gnorm 0.519 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 16.1 | wall 26090
2023-08-24 09:29:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 09:29:56 | INFO | fairseq.trainer | begin training epoch 25
2023-08-24 09:29:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 09:30:26 | INFO | train_inner | epoch 025:     38 / 1474 loss=1.955, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.62, task_loss=3.13, contrastive_loss=0, total=4170.36, n_correct=2741.2, ppl=4.52, accuracy=65.731, wps=7766, ups=0.93, wpb=8340.7, bsz=313, num_updates=35400, lr=7.51646e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=16.2, wall=26121
2023-08-24 09:31:26 | INFO | train_inner | epoch 025:    138 / 1474 loss=1.944, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.61, task_loss=3.238, contrastive_loss=0, total=4133.56, n_correct=2733.55, ppl=4.42, accuracy=66.131, wps=13814.8, ups=1.67, wpb=8267.1, bsz=306.4, num_updates=35500, lr=7.50587e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=26181
2023-08-24 09:32:27 | INFO | train_inner | epoch 025:    238 / 1474 loss=1.95, trans_loss=4.968, nll_loss=2.153, w2v_ctc_loss=0.621, task_loss=3.367, contrastive_loss=0, total=4112.46, n_correct=2712.46, ppl=4.45, accuracy=65.957, wps=13538.2, ups=1.65, wpb=8224.9, bsz=303.4, num_updates=35600, lr=7.49532e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=26241
2023-08-24 09:33:28 | INFO | train_inner | epoch 025:    338 / 1474 loss=1.955, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.617, task_loss=3.54, contrastive_loss=0, total=4139.11, n_correct=2723.62, ppl=4.47, accuracy=65.802, wps=13627.1, ups=1.65, wpb=8278.2, bsz=291.7, num_updates=35700, lr=7.48481e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=26302
2023-08-24 09:34:29 | INFO | train_inner | epoch 025:    438 / 1474 loss=1.96, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.631, task_loss=3.347, contrastive_loss=0, total=4181.96, n_correct=2753.17, ppl=4.48, accuracy=65.834, wps=13699.2, ups=1.64, wpb=8363.9, bsz=303, num_updates=35800, lr=7.47435e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=26363
2023-08-24 09:35:29 | INFO | train_inner | epoch 025:    538 / 1474 loss=1.958, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.624, task_loss=3.214, contrastive_loss=0, total=4162.59, n_correct=2730.2, ppl=4.52, accuracy=65.589, wps=13823.8, ups=1.66, wpb=8325.2, bsz=312.9, num_updates=35900, lr=7.46393e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=60, gb_free=11.7, wall=26423
2023-08-24 09:36:29 | INFO | train_inner | epoch 025:    638 / 1474 loss=1.952, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.616, task_loss=3.285, contrastive_loss=0, total=4142.58, n_correct=2724.73, ppl=4.48, accuracy=65.774, wps=13755.7, ups=1.66, wpb=8285.2, bsz=308.3, num_updates=36000, lr=7.45356e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=59, gb_free=14.6, wall=26484
2023-08-24 09:36:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 09:37:03 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 1.384 | task_loss 11.551 | contrastive_loss 0 | total 4003.4 | n_correct 2487.3 | ppl 7.11 | accuracy 62.13 | uer 17.23 | wer 19.086 | raw_wer 19.086 | bleu 20.29 | wps 1599.3 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.57
2023-08-24 09:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-24 09:37:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_25_36000.pt
2023-08-24 09:37:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_25_36000.pt
2023-08-24 09:37:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.29) (writing took 6.97473589098081 seconds)
2023-08-24 09:38:11 | INFO | train_inner | epoch 025:    738 / 1474 loss=1.958, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.623, task_loss=3.33, contrastive_loss=0, total=4126.89, n_correct=2713, ppl=4.51, accuracy=65.74, wps=8136.2, ups=0.99, wpb=8253.8, bsz=300.9, num_updates=36100, lr=7.44323e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=26585
2023-08-24 09:39:11 | INFO | train_inner | epoch 025:    838 / 1474 loss=1.954, trans_loss=4.985, nll_loss=2.178, w2v_ctc_loss=0.621, task_loss=3.003, contrastive_loss=0, total=4199.63, n_correct=2759.32, ppl=4.52, accuracy=65.704, wps=13939.7, ups=1.66, wpb=8399.3, bsz=329, num_updates=36200, lr=7.43294e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=26645
2023-08-24 09:40:12 | INFO | train_inner | epoch 025:    938 / 1474 loss=1.958, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.626, task_loss=3.164, contrastive_loss=0, total=4134.29, n_correct=2713.78, ppl=4.54, accuracy=65.641, wps=13668.9, ups=1.65, wpb=8268.6, bsz=312.8, num_updates=36300, lr=7.4227e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=26706
2023-08-24 09:41:12 | INFO | train_inner | epoch 025:   1038 / 1474 loss=1.963, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.62, task_loss=3.25, contrastive_loss=0, total=4184.54, n_correct=2734.8, ppl=4.58, accuracy=65.355, wps=13907.9, ups=1.66, wpb=8369.1, bsz=311.2, num_updates=36400, lr=7.41249e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=26766
2023-08-24 09:42:12 | INFO | train_inner | epoch 025:   1138 / 1474 loss=1.963, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.622, task_loss=3.556, contrastive_loss=0, total=4042.38, n_correct=2644.72, ppl=4.55, accuracy=65.425, wps=13330.7, ups=1.65, wpb=8084.8, bsz=286.2, num_updates=36500, lr=7.40233e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=26827
2023-08-24 09:43:12 | INFO | train_inner | epoch 025:   1238 / 1474 loss=1.961, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.618, task_loss=3.381, contrastive_loss=0, total=4077.76, n_correct=2666.81, ppl=4.56, accuracy=65.399, wps=13708.7, ups=1.68, wpb=8155.5, bsz=291.8, num_updates=36600, lr=7.39221e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=59, gb_free=15.4, wall=26886
2023-08-24 09:43:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 09:44:13 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.959, trans_loss=4.991, nll_loss=2.185, w2v_ctc_loss=0.623, task_loss=3.139, contrastive_loss=0, total=4181.81, n_correct=2739.22, ppl=4.55, accuracy=65.503, wps=13780.9, ups=1.65, wpb=8363.6, bsz=314.3, num_updates=36700, lr=7.38213e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=26947
2023-08-24 09:45:13 | INFO | train_inner | epoch 025:   1439 / 1474 loss=1.969, trans_loss=5.007, nll_loss=2.205, w2v_ctc_loss=0.628, task_loss=3.406, contrastive_loss=0, total=4102.27, n_correct=2676.07, ppl=4.61, accuracy=65.234, wps=13478, ups=1.64, wpb=8204.5, bsz=299.9, num_updates=36800, lr=7.3721e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=27008
2023-08-24 09:45:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 09:46:08 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.153 | trans_loss 5.543 | nll_loss 2.812 | w2v_ctc_loss 1.351 | task_loss 11.555 | contrastive_loss 0 | total 4003.4 | n_correct 2497.6 | ppl 7.02 | accuracy 62.387 | uer 16.887 | wer 18.78 | raw_wer 18.78 | bleu 19.87 | wps 1640.6 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.57
2023-08-24 09:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-08-24 09:46:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 09:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 09:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 25 @ 36835 updates, score 19.87) (writing took 5.840797645039856 seconds)
2023-08-24 09:46:14 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-24 09:46:14 | INFO | train | epoch 025 | loss 1.957 | trans_loss 4.984 | nll_loss 2.175 | w2v_ctc_loss 0.621 | task_loss 3.285 | contrastive_loss 0 | total 4139.06 | n_correct 2717.59 | ppl 4.52 | accuracy 65.657 | wps 12474.9 | ups 1.51 | wpb 8278.1 | bsz 305.7 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 14.2 | wall 27068
2023-08-24 09:46:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 09:46:14 | INFO | fairseq.trainer | begin training epoch 26
2023-08-24 09:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 09:47:00 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.944, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.61, task_loss=3.098, contrastive_loss=0, total=4178.19, n_correct=2759.69, ppl=4.44, accuracy=66.05, wps=7849.1, ups=0.94, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=14.2, wall=27114
2023-08-24 09:48:01 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.937, trans_loss=4.96, nll_loss=2.145, w2v_ctc_loss=0.603, task_loss=2.864, contrastive_loss=0, total=4269.55, n_correct=2824.53, ppl=4.42, accuracy=66.155, wps=14029.5, ups=1.64, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=27175
2023-08-24 09:49:01 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.948, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.618, task_loss=3.25, contrastive_loss=0, total=4128.39, n_correct=2724.32, ppl=4.43, accuracy=65.99, wps=13741.6, ups=1.66, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=59, gb_free=9.7, wall=27235
2023-08-24 09:50:01 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.946, trans_loss=4.965, nll_loss=2.151, w2v_ctc_loss=0.616, task_loss=3.143, contrastive_loss=0, total=4166.22, n_correct=2749.06, ppl=4.44, accuracy=65.985, wps=13811, ups=1.66, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=27296
2023-08-24 09:51:01 | INFO | train_inner | epoch 026:    465 / 1474 loss=1.944, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.612, task_loss=3.125, contrastive_loss=0, total=4171.18, n_correct=2759.81, ppl=4.42, accuracy=66.164, wps=13867.1, ups=1.66, wpb=8342.4, bsz=315.5, num_updates=37300, lr=7.32252e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=27356
2023-08-24 09:52:02 | INFO | train_inner | epoch 026:    565 / 1474 loss=1.959, trans_loss=4.979, nll_loss=2.168, w2v_ctc_loss=0.63, task_loss=3.355, contrastive_loss=0, total=4139.82, n_correct=2722.72, ppl=4.49, accuracy=65.769, wps=13678.8, ups=1.65, wpb=8279.6, bsz=300, num_updates=37400, lr=7.31272e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=27416
2023-08-24 09:53:02 | INFO | train_inner | epoch 026:    665 / 1474 loss=1.948, trans_loss=4.972, nll_loss=2.159, w2v_ctc_loss=0.611, task_loss=3.311, contrastive_loss=0, total=4146.72, n_correct=2735.49, ppl=4.47, accuracy=65.968, wps=13796.8, ups=1.66, wpb=8293.4, bsz=302.7, num_updates=37500, lr=7.30297e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=27476
2023-08-24 09:54:02 | INFO | train_inner | epoch 026:    765 / 1474 loss=1.953, trans_loss=4.979, nll_loss=2.168, w2v_ctc_loss=0.612, task_loss=3.353, contrastive_loss=0, total=4084.89, n_correct=2684.09, ppl=4.49, accuracy=65.708, wps=13615.1, ups=1.67, wpb=8169.8, bsz=297.2, num_updates=37600, lr=7.29325e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=59, gb_free=17.2, wall=27536
2023-08-24 09:55:02 | INFO | train_inner | epoch 026:    865 / 1474 loss=1.954, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.622, task_loss=3.241, contrastive_loss=0, total=4180.78, n_correct=2749.91, ppl=4.48, accuracy=65.775, wps=13873.6, ups=1.66, wpb=8361.6, bsz=309.6, num_updates=37700, lr=7.28357e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=27597
2023-08-24 09:56:03 | INFO | train_inner | epoch 026:    965 / 1474 loss=1.954, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.608, task_loss=3.408, contrastive_loss=0, total=4147.79, n_correct=2723.97, ppl=4.53, accuracy=65.673, wps=13663.2, ups=1.65, wpb=8295.6, bsz=299.5, num_updates=37800, lr=7.27393e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=60, gb_free=12.2, wall=27657
2023-08-24 09:57:03 | INFO | train_inner | epoch 026:   1065 / 1474 loss=1.957, trans_loss=4.984, nll_loss=2.175, w2v_ctc_loss=0.619, task_loss=3.465, contrastive_loss=0, total=4118.07, n_correct=2706.48, ppl=4.52, accuracy=65.722, wps=13666.2, ups=1.66, wpb=8236.1, bsz=293.6, num_updates=37900, lr=7.26433e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=27718
2023-08-24 09:58:04 | INFO | train_inner | epoch 026:   1165 / 1474 loss=1.959, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.617, task_loss=3.435, contrastive_loss=0, total=4108.48, n_correct=2689.02, ppl=4.55, accuracy=65.45, wps=13567.1, ups=1.65, wpb=8217, bsz=297.9, num_updates=38000, lr=7.25476e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=27778
2023-08-24 09:58:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 09:58:37 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.175 | trans_loss 5.56 | nll_loss 2.832 | w2v_ctc_loss 1.389 | task_loss 11.606 | contrastive_loss 0 | total 4003.4 | n_correct 2487.2 | ppl 7.12 | accuracy 62.127 | uer 17.214 | wer 19.086 | raw_wer 19.086 | bleu 20.02 | wps 1646.9 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.57
2023-08-24 09:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-24 09:58:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_38000.pt
2023-08-24 09:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_38000.pt
2023-08-24 09:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.02) (writing took 8.140278398990631 seconds)
2023-08-24 09:59:45 | INFO | train_inner | epoch 026:   1265 / 1474 loss=1.971, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.635, task_loss=3.665, contrastive_loss=0, total=4005.94, n_correct=2614.45, ppl=4.59, accuracy=65.264, wps=7900.6, ups=0.99, wpb=8011.9, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=27880
2023-08-24 10:00:46 | INFO | train_inner | epoch 026:   1365 / 1474 loss=1.953, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.61, task_loss=3.318, contrastive_loss=0, total=4146.34, n_correct=2723.54, ppl=4.54, accuracy=65.685, wps=13568.7, ups=1.64, wpb=8292.7, bsz=307.7, num_updates=38200, lr=7.23575e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=27941
2023-08-24 10:01:47 | INFO | train_inner | epoch 026:   1465 / 1474 loss=1.949, trans_loss=4.987, nll_loss=2.181, w2v_ctc_loss=0.608, task_loss=3.081, contrastive_loss=0, total=4172.4, n_correct=2743.82, ppl=4.53, accuracy=65.761, wps=13839.4, ups=1.66, wpb=8344.8, bsz=320, num_updates=38300, lr=7.22629e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=28001
2023-08-24 10:01:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 10:02:25 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.148 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 1.316 | task_loss 11.539 | contrastive_loss 0 | total 4003.4 | n_correct 2498.1 | ppl 7.07 | accuracy 62.399 | uer 16.911 | wer 18.855 | raw_wer 18.855 | bleu 19.89 | wps 1657.5 | wpb 4003.4 | bsz 141.8 | num_updates 38309 | best_bleu 20.57
2023-08-24 10:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38309 updates
2023-08-24 10:02:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 10:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 10:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 26 @ 38309 updates, score 19.89) (writing took 5.879226673976518 seconds)
2023-08-24 10:02:31 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-24 10:02:31 | INFO | train | epoch 026 | loss 1.952 | trans_loss 4.977 | nll_loss 2.166 | w2v_ctc_loss 0.616 | task_loss 3.284 | contrastive_loss 0 | total 4138.65 | n_correct 2723.98 | ppl 4.49 | accuracy 65.818 | wps 12488.3 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 38309 | lr 7.22544e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 879 | gb_free 15.9 | wall 28045
2023-08-24 10:02:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 10:02:31 | INFO | fairseq.trainer | begin training epoch 27
2023-08-24 10:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 10:03:32 | INFO | train_inner | epoch 027:     91 / 1474 loss=1.937, trans_loss=4.944, nll_loss=2.121, w2v_ctc_loss=0.601, task_loss=3.55, contrastive_loss=0, total=4051.87, n_correct=2695.02, ppl=4.35, accuracy=66.513, wps=7691.6, ups=0.95, wpb=8103.7, bsz=281.2, num_updates=38400, lr=7.21688e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=28106
2023-08-24 10:04:32 | INFO | train_inner | epoch 027:    191 / 1474 loss=1.934, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.611, task_loss=3.104, contrastive_loss=0, total=4197.99, n_correct=2792.82, ppl=4.36, accuracy=66.528, wps=13912, ups=1.66, wpb=8396, bsz=324.3, num_updates=38500, lr=7.2075e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=28167
2023-08-24 10:05:33 | INFO | train_inner | epoch 027:    291 / 1474 loss=1.94, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.605, task_loss=3.297, contrastive_loss=0, total=4161.57, n_correct=2758.61, ppl=4.4, accuracy=66.288, wps=13787, ups=1.66, wpb=8323.1, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=28227
2023-08-24 10:06:33 | INFO | train_inner | epoch 027:    391 / 1474 loss=1.946, trans_loss=4.965, nll_loss=2.15, w2v_ctc_loss=0.607, task_loss=3.414, contrastive_loss=0, total=4085.81, n_correct=2699.34, ppl=4.44, accuracy=66.066, wps=13475.1, ups=1.65, wpb=8171.6, bsz=298.1, num_updates=38700, lr=7.18885e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=28288
2023-08-24 10:07:34 | INFO | train_inner | epoch 027:    491 / 1474 loss=1.94, trans_loss=4.966, nll_loss=2.153, w2v_ctc_loss=0.606, task_loss=3.015, contrastive_loss=0, total=4241.27, n_correct=2800.18, ppl=4.45, accuracy=66.022, wps=13922.8, ups=1.64, wpb=8482.5, bsz=330.9, num_updates=38800, lr=7.17958e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=28349
2023-08-24 10:08:34 | INFO | train_inner | epoch 027:    591 / 1474 loss=1.945, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.613, task_loss=3.199, contrastive_loss=0, total=4133.35, n_correct=2729.89, ppl=4.45, accuracy=66.045, wps=13810.1, ups=1.67, wpb=8266.7, bsz=312.8, num_updates=38900, lr=7.17035e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=59, gb_free=12.6, wall=28409
2023-08-24 10:09:35 | INFO | train_inner | epoch 027:    691 / 1474 loss=1.952, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.618, task_loss=3.322, contrastive_loss=0, total=4151.08, n_correct=2737.59, ppl=4.48, accuracy=65.949, wps=13700.8, ups=1.65, wpb=8302.2, bsz=302.6, num_updates=39000, lr=7.16115e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=28469
2023-08-24 10:10:35 | INFO | train_inner | epoch 027:    791 / 1474 loss=1.953, trans_loss=4.972, nll_loss=2.159, w2v_ctc_loss=0.62, task_loss=3.454, contrastive_loss=0, total=4106.27, n_correct=2709.06, ppl=4.47, accuracy=65.974, wps=13677.1, ups=1.67, wpb=8212.5, bsz=293, num_updates=39100, lr=7.15199e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=28529
2023-08-24 10:11:35 | INFO | train_inner | epoch 027:    891 / 1474 loss=1.946, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.601, task_loss=3.392, contrastive_loss=0, total=4112.64, n_correct=2714.7, ppl=4.48, accuracy=66.009, wps=13694.4, ups=1.66, wpb=8225.3, bsz=294.8, num_updates=39200, lr=7.14286e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=28589
2023-08-24 10:12:36 | INFO | train_inner | epoch 027:    991 / 1474 loss=1.947, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.609, task_loss=3.177, contrastive_loss=0, total=4195.59, n_correct=2763.08, ppl=4.48, accuracy=65.857, wps=13752.3, ups=1.64, wpb=8391.2, bsz=316.2, num_updates=39300, lr=7.13376e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=28650
2023-08-24 10:13:36 | INFO | train_inner | epoch 027:   1091 / 1474 loss=1.946, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.608, task_loss=3.3, contrastive_loss=0, total=4151.68, n_correct=2737.89, ppl=4.47, accuracy=65.947, wps=13755.5, ups=1.66, wpb=8303.4, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=28711
2023-08-24 10:13:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 10:14:38 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.953, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.619, task_loss=3.424, contrastive_loss=0, total=4105.52, n_correct=2702.71, ppl=4.49, accuracy=65.831, wps=13426.1, ups=1.64, wpb=8211, bsz=298.3, num_updates=39500, lr=7.11568e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=28772
2023-08-24 10:15:38 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.959, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.618, task_loss=3.512, contrastive_loss=0, total=4065.94, n_correct=2665.56, ppl=4.53, accuracy=65.558, wps=13559.9, ups=1.67, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=59, gb_free=15.9, wall=28832
2023-08-24 10:16:37 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.947, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.609, task_loss=3.091, contrastive_loss=0, total=4149.21, n_correct=2732.3, ppl=4.5, accuracy=65.851, wps=13893.8, ups=1.67, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=28892
2023-08-24 10:17:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 10:17:59 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.146 | trans_loss 5.55 | nll_loss 2.817 | w2v_ctc_loss 1.311 | task_loss 11.523 | contrastive_loss 0 | total 4003.4 | n_correct 2497.3 | ppl 7.05 | accuracy 62.379 | uer 16.731 | wer 18.534 | raw_wer 18.534 | bleu 20.34 | wps 1649.5 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.57
2023-08-24 10:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-24 10:17:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3401.pt
2023-08-24 10:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3401.pt
2023-08-24 10:18:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3401.pt (epoch 27 @ 39782 updates, score 20.34) (writing took 7.515019209007733 seconds)
2023-08-24 10:18:07 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-24 10:18:07 | INFO | train | epoch 027 | loss 1.946 | trans_loss 4.968 | nll_loss 2.155 | w2v_ctc_loss 0.61 | task_loss 3.282 | contrastive_loss 0 | total 4138.61 | n_correct 2732.9 | ppl 4.45 | accuracy 66.034 | wps 13017 | ups 1.57 | wpb 8277.2 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 878 | gb_free 17.8 | wall 28982
2023-08-24 10:18:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 10:18:07 | INFO | fairseq.trainer | begin training epoch 28
2023-08-24 10:18:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 10:18:26 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.939, trans_loss=4.967, nll_loss=2.154, w2v_ctc_loss=0.6, task_loss=3.173, contrastive_loss=0, total=4106.72, n_correct=2715.52, ppl=4.45, accuracy=66.124, wps=7543.5, ups=0.92, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=29000
2023-08-24 10:19:26 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.937, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.608, task_loss=3.445, contrastive_loss=0, total=4103.42, n_correct=2734.87, ppl=4.35, accuracy=66.649, wps=13719.5, ups=1.67, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=59, gb_free=16, wall=29060
2023-08-24 10:20:26 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.929, trans_loss=4.946, nll_loss=2.125, w2v_ctc_loss=0.597, task_loss=3.073, contrastive_loss=0, total=4200.12, n_correct=2797.07, ppl=4.36, accuracy=66.595, wps=13976.2, ups=1.66, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=59, gb_free=10.8, wall=29120
2023-08-24 10:20:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 10:20:59 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.168 | trans_loss 5.548 | nll_loss 2.817 | w2v_ctc_loss 1.39 | task_loss 11.608 | contrastive_loss 0 | total 4003.4 | n_correct 2493.4 | ppl 7.05 | accuracy 62.282 | uer 16.925 | wer 18.664 | raw_wer 18.664 | bleu 20.38 | wps 1624.2 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.57
2023-08-24 10:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-24 10:20:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_40000.pt
2023-08-24 10:21:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_40000.pt
2023-08-24 10:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.38) (writing took 7.702009677886963 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 10:22:08 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.941, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.603, task_loss=3.278, contrastive_loss=0, total=4147.36, n_correct=2738.45, ppl=4.42, accuracy=66.029, wps=8144.5, ups=0.98, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=29222
2023-08-24 10:23:08 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.941, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.608, task_loss=3.401, contrastive_loss=0, total=4087.34, n_correct=2710.35, ppl=4.4, accuracy=66.311, wps=13626.9, ups=1.67, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=29282
2023-08-24 10:24:09 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.939, trans_loss=4.957, nll_loss=2.14, w2v_ctc_loss=0.601, task_loss=3.408, contrastive_loss=0, total=4099.71, n_correct=2719.59, ppl=4.41, accuracy=66.336, wps=13498.2, ups=1.65, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=29343
2023-08-24 10:25:09 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.943, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.604, task_loss=3.332, contrastive_loss=0, total=4177.06, n_correct=2761.57, ppl=4.44, accuracy=66.113, wps=13898.6, ups=1.66, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=17.2, wall=29403
2023-08-24 10:26:09 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.939, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.606, task_loss=2.954, contrastive_loss=0, total=4190.74, n_correct=2772.36, ppl=4.45, accuracy=66.154, wps=13876.5, ups=1.66, wpb=8381.5, bsz=328.5, num_updates=40500, lr=7.02728e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=29464
2023-08-24 10:27:09 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.937, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.602, task_loss=3.247, contrastive_loss=0, total=4091.75, n_correct=2713.79, ppl=4.43, accuracy=66.323, wps=13619.1, ups=1.66, wpb=8183.5, bsz=306, num_updates=40600, lr=7.01862e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=29524
2023-08-24 10:28:10 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.945, trans_loss=4.969, nll_loss=2.156, w2v_ctc_loss=0.606, task_loss=3.376, contrastive_loss=0, total=4123.89, n_correct=2724.45, ppl=4.46, accuracy=66.065, wps=13596.3, ups=1.65, wpb=8247.8, bsz=301, num_updates=40700, lr=7.01e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=29584
2023-08-24 10:29:10 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.947, trans_loss=4.97, nll_loss=2.158, w2v_ctc_loss=0.613, task_loss=3.191, contrastive_loss=0, total=4176.06, n_correct=2756.41, ppl=4.46, accuracy=66.005, wps=13800.9, ups=1.65, wpb=8352.1, bsz=311.4, num_updates=40800, lr=7.0014e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=29645
2023-08-24 10:30:11 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.937, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.602, task_loss=3.188, contrastive_loss=0, total=4206.08, n_correct=2788.24, ppl=4.43, accuracy=66.291, wps=13915.1, ups=1.65, wpb=8412.2, bsz=317.3, num_updates=40900, lr=6.99284e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=29705
2023-08-24 10:31:11 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.938, trans_loss=4.966, nll_loss=2.153, w2v_ctc_loss=0.597, task_loss=3.226, contrastive_loss=0, total=4109.72, n_correct=2715.87, ppl=4.45, accuracy=66.084, wps=13696.8, ups=1.67, wpb=8219.4, bsz=306.9, num_updates=41000, lr=6.9843e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=29765
2023-08-24 10:32:11 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.954, trans_loss=4.976, nll_loss=2.164, w2v_ctc_loss=0.616, task_loss=3.573, contrastive_loss=0, total=4085.44, n_correct=2692.46, ppl=4.48, accuracy=65.904, wps=13495.1, ups=1.65, wpb=8170.9, bsz=285.6, num_updates=41100, lr=6.9758e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=29826
2023-08-24 10:33:12 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.953, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.613, task_loss=3.486, contrastive_loss=0, total=4137.47, n_correct=2720.22, ppl=4.49, accuracy=65.746, wps=13673.6, ups=1.65, wpb=8274.9, bsz=294.8, num_updates=41200, lr=6.96733e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=29886
2023-08-24 10:33:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
2023-08-24 10:34:19 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.551 | nll_loss 2.818 | w2v_ctc_loss 1.346 | task_loss 11.525 | contrastive_loss 0 | total 4003.4 | n_correct 2496.9 | ppl 7.05 | accuracy 62.369 | uer 16.848 | wer 18.683 | raw_wer 18.683 | bleu 20.06 | wps 1580.2 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 20.57
2023-08-24 10:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-08-24 10:34:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 10:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 10:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 28 @ 41256 updates, score 20.06) (writing took 5.955770082073286 seconds)
2023-08-24 10:34:25 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-24 10:34:25 | INFO | train | epoch 028 | loss 1.941 | trans_loss 4.962 | nll_loss 2.147 | w2v_ctc_loss 0.605 | task_loss 3.281 | contrastive_loss 0 | total 4138.65 | n_correct 2739.93 | ppl 4.43 | accuracy 66.204 | wps 12478 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 879 | gb_free 16.4 | wall 29959
2023-08-24 10:34:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 10:34:25 | INFO | fairseq.trainer | begin training epoch 29
2023-08-24 10:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 10:34:59 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.933, trans_loss=4.946, nll_loss=2.127, w2v_ctc_loss=0.606, task_loss=3.153, contrastive_loss=0, total=4168.25, n_correct=2777.41, ppl=4.37, accuracy=66.633, wps=7777.7, ups=0.93, wpb=8336.5, bsz=315.7, num_updates=41300, lr=6.95889e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=29994
2023-08-24 10:35:59 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.934, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.604, task_loss=3.226, contrastive_loss=0, total=4117.66, n_correct=2738.12, ppl=4.36, accuracy=66.497, wps=13720.6, ups=1.67, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=59, gb_free=17.2, wall=30054
2023-08-24 10:37:00 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.918, trans_loss=4.934, nll_loss=2.112, w2v_ctc_loss=0.583, task_loss=2.991, contrastive_loss=0, total=4198.99, n_correct=2806.17, ppl=4.32, accuracy=66.83, wps=13851.9, ups=1.65, wpb=8398, bsz=330.7, num_updates=41500, lr=6.9421e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=60, gb_free=15.2, wall=30114
2023-08-24 10:38:00 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.941, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.612, task_loss=3.538, contrastive_loss=0, total=4091.28, n_correct=2716.65, ppl=4.39, accuracy=66.401, wps=13608.2, ups=1.66, wpb=8182.6, bsz=290.4, num_updates=41600, lr=6.93375e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=30174
2023-08-24 10:39:00 | INFO | train_inner | epoch 029:    444 / 1474 loss=1.923, trans_loss=4.93, nll_loss=2.105, w2v_ctc_loss=0.592, task_loss=3.177, contrastive_loss=0, total=4158.09, n_correct=2784.18, ppl=4.3, accuracy=66.958, wps=13804.9, ups=1.66, wpb=8316.2, bsz=307.2, num_updates=41700, lr=6.92543e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=30235
2023-08-24 10:40:01 | INFO | train_inner | epoch 029:    544 / 1474 loss=1.942, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.601, task_loss=3.491, contrastive_loss=0, total=4156.12, n_correct=2750.46, ppl=4.42, accuracy=66.179, wps=13616, ups=1.64, wpb=8312.2, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=60, gb_free=12.1, wall=30296
2023-08-24 10:41:01 | INFO | train_inner | epoch 029:    644 / 1474 loss=1.93, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.596, task_loss=3.09, contrastive_loss=0, total=4153.45, n_correct=2758.54, ppl=4.38, accuracy=66.416, wps=13808.5, ups=1.66, wpb=8306.9, bsz=320.5, num_updates=41900, lr=6.90889e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=30356
2023-08-24 10:42:02 | INFO | train_inner | epoch 029:    744 / 1474 loss=1.929, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.595, task_loss=3.035, contrastive_loss=0, total=4232.02, n_correct=2816.16, ppl=4.37, accuracy=66.544, wps=14028.7, ups=1.66, wpb=8464, bsz=328, num_updates=42000, lr=6.90066e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=60, gb_free=11.3, wall=30416
2023-08-24 10:42:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 10:42:35 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.551 | nll_loss 2.818 | w2v_ctc_loss 1.386 | task_loss 11.544 | contrastive_loss 0 | total 4003.4 | n_correct 2493.4 | ppl 7.05 | accuracy 62.282 | uer 17.126 | wer 18.892 | raw_wer 18.892 | bleu 19.83 | wps 1580.8 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.57
2023-08-24 10:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-24 10:42:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_42000.pt
2023-08-24 10:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_42000.pt
2023-08-24 10:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.83) (writing took 6.567436129087582 seconds)
2023-08-24 10:43:42 | INFO | train_inner | epoch 029:    844 / 1474 loss=1.942, trans_loss=4.966, nll_loss=2.151, w2v_ctc_loss=0.598, task_loss=3.644, contrastive_loss=0, total=4033.38, n_correct=2669.15, ppl=4.44, accuracy=66.177, wps=8034.5, ups=1, wpb=8066.8, bsz=280.8, num_updates=42100, lr=6.89246e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=30517
2023-08-24 10:44:42 | INFO | train_inner | epoch 029:    944 / 1474 loss=1.94, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.601, task_loss=3.347, contrastive_loss=0, total=4082.33, n_correct=2706.15, ppl=4.45, accuracy=66.289, wps=13647.8, ups=1.67, wpb=8164.7, bsz=297.1, num_updates=42200, lr=6.88428e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=30576
2023-08-24 10:45:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 10:45:43 | INFO | train_inner | epoch 029:   1045 / 1474 loss=1.936, trans_loss=4.954, nll_loss=2.138, w2v_ctc_loss=0.598, task_loss=3.294, contrastive_loss=0, total=4139.19, n_correct=2743.36, ppl=4.4, accuracy=66.278, wps=13579.7, ups=1.64, wpb=8278.4, bsz=306.4, num_updates=42300, lr=6.87614e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=30637
2023-08-24 10:46:43 | INFO | train_inner | epoch 029:   1145 / 1474 loss=1.947, trans_loss=4.969, nll_loss=2.156, w2v_ctc_loss=0.612, task_loss=3.576, contrastive_loss=0, total=4068.4, n_correct=2690.27, ppl=4.46, accuracy=66.126, wps=13613.3, ups=1.67, wpb=8136.8, bsz=284.2, num_updates=42400, lr=6.86803e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=59, gb_free=17.4, wall=30697
2023-08-24 10:47:43 | INFO | train_inner | epoch 029:   1245 / 1474 loss=1.945, trans_loss=4.97, nll_loss=2.158, w2v_ctc_loss=0.606, task_loss=3.364, contrastive_loss=0, total=4154.79, n_correct=2746.17, ppl=4.46, accuracy=66.096, wps=13813.8, ups=1.66, wpb=8309.6, bsz=299.6, num_updates=42500, lr=6.85994e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=30757
2023-08-24 10:48:43 | INFO | train_inner | epoch 029:   1345 / 1474 loss=1.937, trans_loss=4.959, nll_loss=2.144, w2v_ctc_loss=0.602, task_loss=3.225, contrastive_loss=0, total=4166.4, n_correct=2763.73, ppl=4.42, accuracy=66.334, wps=13800.7, ups=1.66, wpb=8332.8, bsz=311.5, num_updates=42600, lr=6.85189e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=30818
2023-08-24 10:49:43 | INFO | train_inner | epoch 029:   1445 / 1474 loss=1.939, trans_loss=4.962, nll_loss=2.15, w2v_ctc_loss=0.603, task_loss=3.225, contrastive_loss=0, total=4169.4, n_correct=2758.72, ppl=4.44, accuracy=66.166, wps=13964.3, ups=1.67, wpb=8338.8, bsz=312, num_updates=42700, lr=6.84386e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=59, gb_free=15.8, wall=30877
2023-08-24 10:50:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 10:50:34 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.159 | trans_loss 5.544 | nll_loss 2.811 | w2v_ctc_loss 1.371 | task_loss 11.592 | contrastive_loss 0 | total 4003.4 | n_correct 2498.1 | ppl 7.02 | accuracy 62.399 | uer 16.866 | wer 18.799 | raw_wer 18.799 | bleu 20.33 | wps 1574.5 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 20.57
2023-08-24 10:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-08-24 10:50:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3309.pt
2023-08-24 10:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3309.pt
2023-08-24 10:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.3309.pt (epoch 29 @ 42729 updates, score 20.33) (writing took 8.407114548957907 seconds)
2023-08-24 10:50:43 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-24 10:50:43 | INFO | train | epoch 029 | loss 1.935 | trans_loss 4.954 | nll_loss 2.137 | w2v_ctc_loss 0.6 | task_loss 3.286 | contrastive_loss 0 | total 4138.31 | n_correct 2747.54 | ppl 4.4 | accuracy 66.393 | wps 12467.8 | ups 1.51 | wpb 8276.6 | bsz 305.6 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 877 | gb_free 16 | wall 30937
2023-08-24 10:50:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 10:50:43 | INFO | fairseq.trainer | begin training epoch 30
2023-08-24 10:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 10:51:33 | INFO | train_inner | epoch 030:     71 / 1474 loss=1.924, trans_loss=4.938, nll_loss=2.116, w2v_ctc_loss=0.587, task_loss=3.113, contrastive_loss=0, total=4176.73, n_correct=2784.95, ppl=4.34, accuracy=66.678, wps=7568.7, ups=0.91, wpb=8353.5, bsz=319, num_updates=42800, lr=6.83586e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=30988
2023-08-24 10:52:33 | INFO | train_inner | epoch 030:    171 / 1474 loss=1.922, trans_loss=4.924, nll_loss=2.098, w2v_ctc_loss=0.596, task_loss=3.061, contrastive_loss=0, total=4202.84, n_correct=2814.41, ppl=4.28, accuracy=66.964, wps=14002.5, ups=1.67, wpb=8405.7, bsz=318.6, num_updates=42900, lr=6.82789e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=59, gb_free=12.5, wall=31048
2023-08-24 10:53:34 | INFO | train_inner | epoch 030:    271 / 1474 loss=1.932, trans_loss=4.939, nll_loss=2.116, w2v_ctc_loss=0.602, task_loss=3.387, contrastive_loss=0, total=4120.08, n_correct=2744.41, ppl=4.33, accuracy=66.611, wps=13712.5, ups=1.66, wpb=8240.2, bsz=296.4, num_updates=43000, lr=6.81994e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=31108
2023-08-24 10:54:34 | INFO | train_inner | epoch 030:    371 / 1474 loss=1.927, trans_loss=4.935, nll_loss=2.112, w2v_ctc_loss=0.596, task_loss=3.289, contrastive_loss=0, total=4175.82, n_correct=2788.19, ppl=4.32, accuracy=66.77, wps=13803.7, ups=1.65, wpb=8351.6, bsz=306.1, num_updates=43100, lr=6.81203e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=31168
2023-08-24 10:55:34 | INFO | train_inner | epoch 030:    471 / 1474 loss=1.923, trans_loss=4.936, nll_loss=2.114, w2v_ctc_loss=0.589, task_loss=3.161, contrastive_loss=0, total=4128.9, n_correct=2758.95, ppl=4.33, accuracy=66.82, wps=13854.2, ups=1.68, wpb=8257.8, bsz=312.5, num_updates=43200, lr=6.80414e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=31228
2023-08-24 10:56:34 | INFO | train_inner | epoch 030:    571 / 1474 loss=1.928, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.592, task_loss=3.206, contrastive_loss=0, total=4162.83, n_correct=2774.92, ppl=4.37, accuracy=66.659, wps=13861.1, ups=1.66, wpb=8325.7, bsz=311.5, num_updates=43300, lr=6.79628e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=59, gb_free=15, wall=31288
2023-08-24 10:57:34 | INFO | train_inner | epoch 030:    671 / 1474 loss=1.929, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.598, task_loss=3.199, contrastive_loss=0, total=4197.56, n_correct=2798.48, ppl=4.36, accuracy=66.669, wps=13876.7, ups=1.65, wpb=8395.1, bsz=317.6, num_updates=43400, lr=6.78844e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=31349
2023-08-24 10:58:34 | INFO | train_inner | epoch 030:    771 / 1474 loss=1.943, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.61, task_loss=3.378, contrastive_loss=0, total=4097.27, n_correct=2712.15, ppl=4.43, accuracy=66.194, wps=13610.9, ups=1.66, wpb=8194.5, bsz=301.1, num_updates=43500, lr=6.78064e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=59, gb_free=14.8, wall=31409
2023-08-24 10:59:34 | INFO | train_inner | epoch 030:    871 / 1474 loss=1.937, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.599, task_loss=3.433, contrastive_loss=0, total=4097.18, n_correct=2721.96, ppl=4.4, accuracy=66.435, wps=13672.4, ups=1.67, wpb=8194.4, bsz=292.2, num_updates=43600, lr=6.77285e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=31469
2023-08-24 11:00:34 | INFO | train_inner | epoch 030:    971 / 1474 loss=1.935, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.6, task_loss=3.311, contrastive_loss=0, total=4140.12, n_correct=2751.51, ppl=4.4, accuracy=66.46, wps=13864.8, ups=1.67, wpb=8280.2, bsz=304.6, num_updates=43700, lr=6.7651e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=59, gb_free=15.2, wall=31528
2023-08-24 11:01:35 | INFO | train_inner | epoch 030:   1071 / 1474 loss=1.949, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.607, task_loss=3.701, contrastive_loss=0, total=4099.61, n_correct=2702.13, ppl=4.46, accuracy=65.912, wps=13362.2, ups=1.63, wpb=8199.2, bsz=281.4, num_updates=43800, lr=6.75737e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=31590
2023-08-24 11:02:36 | INFO | train_inner | epoch 030:   1171 / 1474 loss=1.931, trans_loss=4.955, nll_loss=2.14, w2v_ctc_loss=0.592, task_loss=3.142, contrastive_loss=0, total=4164.38, n_correct=2767.88, ppl=4.41, accuracy=66.466, wps=13688, ups=1.64, wpb=8328.8, bsz=314.8, num_updates=43900, lr=6.74967e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=31651
2023-08-24 11:03:37 | INFO | train_inner | epoch 030:   1271 / 1474 loss=1.947, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.612, task_loss=3.703, contrastive_loss=0, total=4030.53, n_correct=2666.25, ppl=4.44, accuracy=66.151, wps=13259.4, ups=1.64, wpb=8061.1, bsz=281.4, num_updates=44000, lr=6.742e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=31711
2023-08-24 11:03:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:04:11 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.152 | trans_loss 5.548 | nll_loss 2.816 | w2v_ctc_loss 1.337 | task_loss 11.622 | contrastive_loss 0 | total 4003.4 | n_correct 2497.2 | ppl 7.04 | accuracy 62.377 | uer 16.991 | wer 18.903 | raw_wer 18.903 | bleu 20.04 | wps 1570 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.57
2023-08-24 11:04:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-24 11:04:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_30_44000.pt
2023-08-24 11:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_30_44000.pt
2023-08-24 11:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.04) (writing took 7.55677565804217 seconds)
2023-08-24 11:05:18 | INFO | train_inner | epoch 030:   1371 / 1474 loss=1.927, trans_loss=4.952, nll_loss=2.137, w2v_ctc_loss=0.591, task_loss=3.1, contrastive_loss=0, total=4163.24, n_correct=2770.04, ppl=4.4, accuracy=66.536, wps=8220, ups=0.99, wpb=8326.5, bsz=320.7, num_updates=44100, lr=6.73435e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=17.2, wall=31813
2023-08-24 11:06:18 | INFO | train_inner | epoch 030:   1471 / 1474 loss=1.933, trans_loss=4.959, nll_loss=2.146, w2v_ctc_loss=0.591, task_loss=3.142, contrastive_loss=0, total=4130.55, n_correct=2737.99, ppl=4.43, accuracy=66.286, wps=13858.9, ups=1.68, wpb=8261.1, bsz=311.7, num_updates=44200, lr=6.72673e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=31872
2023-08-24 11:06:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:06:53 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.555 | nll_loss 2.824 | w2v_ctc_loss 1.377 | task_loss 11.626 | contrastive_loss 0 | total 4003.4 | n_correct 2492.7 | ppl 7.08 | accuracy 62.265 | uer 17.251 | wer 19.149 | raw_wer 19.149 | bleu 19.74 | wps 1573.4 | wpb 4003.4 | bsz 141.8 | num_updates 44203 | best_bleu 20.57
2023-08-24 11:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44203 updates
2023-08-24 11:06:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 11:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 11:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 30 @ 44203 updates, score 19.74) (writing took 7.866897565079853 seconds)
2023-08-24 11:07:01 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-24 11:07:01 | INFO | train | epoch 030 | loss 1.932 | trans_loss 4.949 | nll_loss 2.13 | w2v_ctc_loss 0.597 | task_loss 3.285 | contrastive_loss 0 | total 4138.65 | n_correct 2752.76 | ppl 4.38 | accuracy 66.513 | wps 12469.5 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 44203 | lr 6.7265e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 877 | gb_free 17.1 | wall 31916
2023-08-24 11:07:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 11:07:02 | INFO | fairseq.trainer | begin training epoch 31
2023-08-24 11:07:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 11:08:07 | INFO | train_inner | epoch 031:     97 / 1474 loss=1.925, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.594, task_loss=3.399, contrastive_loss=0, total=4081.82, n_correct=2734.7, ppl=4.3, accuracy=66.997, wps=7461.1, ups=0.91, wpb=8163.6, bsz=295.5, num_updates=44300, lr=6.71913e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=60, gb_free=13.4, wall=31982
2023-08-24 11:09:08 | INFO | train_inner | epoch 031:    197 / 1474 loss=1.924, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.593, task_loss=3.385, contrastive_loss=0, total=4143.18, n_correct=2772.83, ppl=4.3, accuracy=66.925, wps=13701.4, ups=1.65, wpb=8286.4, bsz=301.1, num_updates=44400, lr=6.71156e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=32042
2023-08-24 11:10:08 | INFO | train_inner | epoch 031:    297 / 1474 loss=1.928, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.598, task_loss=3.38, contrastive_loss=0, total=4154.03, n_correct=2778.6, ppl=4.32, accuracy=66.889, wps=13757.5, ups=1.66, wpb=8308.1, bsz=301.5, num_updates=44500, lr=6.70402e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=32103
2023-08-24 11:11:08 | INFO | train_inner | epoch 031:    397 / 1474 loss=1.933, trans_loss=4.944, nll_loss=2.123, w2v_ctc_loss=0.596, task_loss=3.597, contrastive_loss=0, total=4079.78, n_correct=2718.63, ppl=4.36, accuracy=66.637, wps=13590.8, ups=1.67, wpb=8159.6, bsz=284.9, num_updates=44600, lr=6.6965e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=59, gb_free=15.7, wall=32163
2023-08-24 11:12:09 | INFO | train_inner | epoch 031:    497 / 1474 loss=1.929, trans_loss=4.936, nll_loss=2.114, w2v_ctc_loss=0.6, task_loss=3.399, contrastive_loss=0, total=4122.36, n_correct=2750.93, ppl=4.33, accuracy=66.732, wps=13683.2, ups=1.66, wpb=8244.7, bsz=302, num_updates=44700, lr=6.689e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=32223
2023-08-24 11:13:09 | INFO | train_inner | epoch 031:    597 / 1474 loss=1.924, trans_loss=4.936, nll_loss=2.113, w2v_ctc_loss=0.588, task_loss=3.438, contrastive_loss=0, total=4082.24, n_correct=2727.29, ppl=4.33, accuracy=66.809, wps=13468.3, ups=1.65, wpb=8164.5, bsz=294.3, num_updates=44800, lr=6.68153e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=32284
2023-08-24 11:13:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 11:14:10 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.92, trans_loss=4.934, nll_loss=2.111, w2v_ctc_loss=0.587, task_loss=3.137, contrastive_loss=0, total=4209.87, n_correct=2816.95, ppl=4.32, accuracy=66.913, wps=13943.9, ups=1.66, wpb=8419.7, bsz=314.9, num_updates=44900, lr=6.67409e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=14.6, wall=32344
2023-08-24 11:15:10 | INFO | train_inner | epoch 031:    798 / 1474 loss=1.936, trans_loss=4.952, nll_loss=2.135, w2v_ctc_loss=0.599, task_loss=3.445, contrastive_loss=0, total=4098.1, n_correct=2718.54, ppl=4.39, accuracy=66.337, wps=13570.9, ups=1.66, wpb=8196.2, bsz=295.7, num_updates=45000, lr=6.66667e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=32404
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:0')
2023-08-24 11:16:10 | INFO | train_inner | epoch 031:    898 / 1474 loss=1.927, trans_loss=4.938, nll_loss=2.116, w2v_ctc_loss=0.591, task_loss=3.417, contrastive_loss=0, total=4101.05, n_correct=2733.95, ppl=4.34, accuracy=66.665, wps=13685, ups=1.67, wpb=8202.1, bsz=296.9, num_updates=45100, lr=6.65927e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=32464
2023-08-24 11:17:10 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.927, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.589, task_loss=3.108, contrastive_loss=0, total=4186.3, n_correct=2789.33, ppl=4.38, accuracy=66.63, wps=13958.3, ups=1.67, wpb=8372.6, bsz=318.6, num_updates=45200, lr=6.6519e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=32524
2023-08-24 11:18:10 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.928, trans_loss=4.946, nll_loss=2.129, w2v_ctc_loss=0.593, task_loss=3.23, contrastive_loss=0, total=4147.34, n_correct=2760.41, ppl=4.37, accuracy=66.559, wps=13716.5, ups=1.65, wpb=8294.7, bsz=314.6, num_updates=45300, lr=6.64455e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=32585
2023-08-24 11:19:10 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.923, trans_loss=4.946, nll_loss=2.129, w2v_ctc_loss=0.584, task_loss=3.069, contrastive_loss=0, total=4185.34, n_correct=2786.93, ppl=4.37, accuracy=66.588, wps=14005.2, ups=1.67, wpb=8370.7, bsz=321.6, num_updates=45400, lr=6.63723e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=32645
2023-08-24 11:20:10 | INFO | train_inner | epoch 031:   1298 / 1474 loss=1.927, trans_loss=4.95, nll_loss=2.134, w2v_ctc_loss=0.593, task_loss=2.97, contrastive_loss=0, total=4223.54, n_correct=2811.44, ppl=4.39, accuracy=66.566, wps=14117.7, ups=1.67, wpb=8447.1, bsz=325, num_updates=45500, lr=6.62994e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=59, gb_free=13.4, wall=32704
2023-08-24 11:21:10 | INFO | train_inner | epoch 031:   1398 / 1474 loss=1.925, trans_loss=4.947, nll_loss=2.13, w2v_ctc_loss=0.586, task_loss=2.987, contrastive_loss=0, total=4195.76, n_correct=2792.6, ppl=4.38, accuracy=66.558, wps=13956.7, ups=1.66, wpb=8391.5, bsz=328.2, num_updates=45600, lr=6.62266e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=32764
2023-08-24 11:21:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2453, device='cuda:7')
2023-08-24 11:22:30 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.142 | trans_loss 5.544 | nll_loss 2.811 | w2v_ctc_loss 1.311 | task_loss 11.599 | contrastive_loss 0 | total 4003.4 | n_correct 2499.9 | ppl 7.02 | accuracy 62.444 | uer 16.789 | wer 18.784 | raw_wer 18.784 | bleu 20.51 | wps 1558 | wpb 4003.4 | bsz 141.8 | num_updates 45676 | best_bleu 20.57
2023-08-24 11:22:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45676 updates
2023-08-24 11:22:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5107.pt
2023-08-24 11:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5107.pt
2023-08-24 11:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5107.pt (epoch 31 @ 45676 updates, score 20.51) (writing took 7.41752128303051 seconds)
2023-08-24 11:22:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-24 11:22:38 | INFO | train | epoch 031 | loss 1.927 | trans_loss 4.942 | nll_loss 2.121 | w2v_ctc_loss 0.593 | task_loss 3.288 | contrastive_loss 0 | total 4138.6 | n_correct 2760.03 | ppl 4.35 | accuracy 66.69 | wps 13018.5 | ups 1.57 | wpb 8277.2 | bsz 305.7 | num_updates 45676 | lr 6.61715e-05 | gnorm 0.533 | clip 0 | loss_scale 32 | train_wall 876 | gb_free 12 | wall 32852
2023-08-24 11:22:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 11:22:38 | INFO | fairseq.trainer | begin training epoch 32
2023-08-24 11:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 11:22:59 | INFO | train_inner | epoch 032:     24 / 1474 loss=1.93, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.595, task_loss=3.491, contrastive_loss=0, total=4039.04, n_correct=2696.1, ppl=4.36, accuracy=66.751, wps=7396.3, ups=0.92, wpb=8078.1, bsz=287.3, num_updates=45700, lr=6.61541e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=59, gb_free=17.7, wall=32874
2023-08-24 11:24:00 | INFO | train_inner | epoch 032:    124 / 1474 loss=1.906, trans_loss=4.909, nll_loss=2.079, w2v_ctc_loss=0.575, task_loss=3.039, contrastive_loss=0, total=4224.84, n_correct=2849.58, ppl=4.22, accuracy=67.448, wps=13936.4, ups=1.65, wpb=8449.7, bsz=322.5, num_updates=45800, lr=6.60819e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=32934
2023-08-24 11:25:01 | INFO | train_inner | epoch 032:    224 / 1474 loss=1.915, trans_loss=4.926, nll_loss=2.101, w2v_ctc_loss=0.585, task_loss=3.105, contrastive_loss=0, total=4163.01, n_correct=2790.73, ppl=4.29, accuracy=67.036, wps=13688.5, ups=1.64, wpb=8326, bsz=322.2, num_updates=45900, lr=6.60098e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=32995
2023-08-24 11:26:01 | INFO | train_inner | epoch 032:    324 / 1474 loss=1.909, trans_loss=4.914, nll_loss=2.085, w2v_ctc_loss=0.578, task_loss=3.095, contrastive_loss=0, total=4185.21, n_correct=2818.79, ppl=4.24, accuracy=67.351, wps=13972, ups=1.67, wpb=8370.4, bsz=315.1, num_updates=46000, lr=6.5938e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=33055
2023-08-24 11:26:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:26:34 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.159 | trans_loss 5.548 | nll_loss 2.816 | w2v_ctc_loss 1.361 | task_loss 11.539 | contrastive_loss 0 | total 4003.4 | n_correct 2507.9 | ppl 7.04 | accuracy 62.644 | uer 16.688 | wer 18.579 | raw_wer 18.579 | bleu 20.48 | wps 1645.7 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.57
2023-08-24 11:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-24 11:26:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_32_46000.pt
2023-08-24 11:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_32_46000.pt
2023-08-24 11:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.48) (writing took 9.57914245792199 seconds)
2023-08-24 11:27:44 | INFO | train_inner | epoch 032:    424 / 1474 loss=1.918, trans_loss=4.924, nll_loss=2.098, w2v_ctc_loss=0.585, task_loss=3.274, contrastive_loss=0, total=4156.71, n_correct=2789.29, ppl=4.28, accuracy=67.103, wps=8063, ups=0.97, wpb=8313.4, bsz=305.7, num_updates=46100, lr=6.58665e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=10.6, wall=33158
2023-08-24 11:28:45 | INFO | train_inner | epoch 032:    524 / 1474 loss=1.926, trans_loss=4.938, nll_loss=2.117, w2v_ctc_loss=0.596, task_loss=3.158, contrastive_loss=0, total=4195.32, n_correct=2800.34, ppl=4.34, accuracy=66.749, wps=13814, ups=1.65, wpb=8390.6, bsz=318.2, num_updates=46200, lr=6.57952e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=33219
2023-08-24 11:29:45 | INFO | train_inner | epoch 032:    624 / 1474 loss=1.923, trans_loss=4.937, nll_loss=2.114, w2v_ctc_loss=0.586, task_loss=3.401, contrastive_loss=0, total=4141.99, n_correct=2770.36, ppl=4.33, accuracy=66.885, wps=13689.6, ups=1.65, wpb=8284, bsz=300.9, num_updates=46300, lr=6.57241e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=33279
2023-08-24 11:30:46 | INFO | train_inner | epoch 032:    724 / 1474 loss=1.926, trans_loss=4.939, nll_loss=2.117, w2v_ctc_loss=0.594, task_loss=3.357, contrastive_loss=0, total=4153.97, n_correct=2776.07, ppl=4.34, accuracy=66.829, wps=13664.3, ups=1.64, wpb=8307.9, bsz=301.5, num_updates=46400, lr=6.56532e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=33340
2023-08-24 11:31:46 | INFO | train_inner | epoch 032:    824 / 1474 loss=1.918, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.578, task_loss=3.387, contrastive_loss=0, total=4119.08, n_correct=2758.97, ppl=4.32, accuracy=66.98, wps=13741.7, ups=1.67, wpb=8238.2, bsz=295.1, num_updates=46500, lr=6.55826e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=33400
2023-08-24 11:32:46 | INFO | train_inner | epoch 032:    924 / 1474 loss=1.923, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.585, task_loss=3.39, contrastive_loss=0, total=4142.37, n_correct=2768.28, ppl=4.32, accuracy=66.828, wps=13687.4, ups=1.65, wpb=8284.7, bsz=299.1, num_updates=46600, lr=6.55122e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=33461
2023-08-24 11:33:46 | INFO | train_inner | epoch 032:   1024 / 1474 loss=1.927, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.588, task_loss=3.289, contrastive_loss=0, total=4112.12, n_correct=2739.52, ppl=4.36, accuracy=66.621, wps=13694.8, ups=1.67, wpb=8224.2, bsz=302.5, num_updates=46700, lr=6.5442e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=33521
2023-08-24 11:34:47 | INFO | train_inner | epoch 032:   1124 / 1474 loss=1.937, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.599, task_loss=3.834, contrastive_loss=0, total=4022.64, n_correct=2675.07, ppl=4.38, accuracy=66.5, wps=13260.7, ups=1.65, wpb=8045.3, bsz=273.1, num_updates=46800, lr=6.5372e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=60, gb_free=11, wall=33581
2023-08-24 11:35:48 | INFO | train_inner | epoch 032:   1224 / 1474 loss=1.931, trans_loss=4.954, nll_loss=2.138, w2v_ctc_loss=0.59, task_loss=3.286, contrastive_loss=0, total=4145.44, n_correct=2751.99, ppl=4.4, accuracy=66.386, wps=13730.3, ups=1.66, wpb=8290.9, bsz=308.7, num_updates=46900, lr=6.53023e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=33642
2023-08-24 11:36:47 | INFO | train_inner | epoch 032:   1324 / 1474 loss=1.927, trans_loss=4.944, nll_loss=2.124, w2v_ctc_loss=0.589, task_loss=3.354, contrastive_loss=0, total=4083.72, n_correct=2721.06, ppl=4.36, accuracy=66.632, wps=13710.5, ups=1.68, wpb=8167.4, bsz=297.1, num_updates=47000, lr=6.52328e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=59, gb_free=15.6, wall=33701
2023-08-24 11:37:47 | INFO | train_inner | epoch 032:   1424 / 1474 loss=1.931, trans_loss=4.947, nll_loss=2.13, w2v_ctc_loss=0.594, task_loss=3.312, contrastive_loss=0, total=4105.33, n_correct=2734.34, ppl=4.38, accuracy=66.605, wps=13638.8, ups=1.66, wpb=8210.7, bsz=305.7, num_updates=47100, lr=6.51635e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=33762
2023-08-24 11:38:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:38:51 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.542 | nll_loss 2.81 | w2v_ctc_loss 1.368 | task_loss 11.583 | contrastive_loss 0 | total 4003.4 | n_correct 2507.1 | ppl 7.01 | accuracy 62.624 | uer 16.68 | wer 18.437 | raw_wer 18.437 | bleu 20.27 | wps 1549.7 | wpb 4003.4 | bsz 141.8 | num_updates 47150 | best_bleu 20.57
2023-08-24 11:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47150 updates
2023-08-24 11:38:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 11:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 11:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 32 @ 47150 updates, score 20.27) (writing took 6.144060628022999 seconds)
2023-08-24 11:38:57 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-24 11:38:57 | INFO | train | epoch 032 | loss 1.922 | trans_loss 4.935 | nll_loss 2.113 | w2v_ctc_loss 0.587 | task_loss 3.284 | contrastive_loss 0 | total 4138.65 | n_correct 2767.23 | ppl 4.32 | accuracy 66.863 | wps 12458.9 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 47150 | lr 6.5129e-05 | gnorm 0.533 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 16.3 | wall 33831
2023-08-24 11:38:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 11:38:57 | INFO | fairseq.trainer | begin training epoch 33
2023-08-24 11:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 11:39:35 | INFO | train_inner | epoch 033:     50 / 1474 loss=1.913, trans_loss=4.929, nll_loss=2.106, w2v_ctc_loss=0.577, task_loss=3.067, contrastive_loss=0, total=4161.67, n_correct=2790.06, ppl=4.3, accuracy=67.042, wps=7755.6, ups=0.93, wpb=8323.3, bsz=322.6, num_updates=47200, lr=6.50945e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=59, gb_free=17.8, wall=33869
2023-08-24 11:40:35 | INFO | train_inner | epoch 033:    150 / 1474 loss=1.907, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.565, task_loss=3.552, contrastive_loss=0, total=4067.33, n_correct=2742.79, ppl=4.22, accuracy=67.435, wps=13469.6, ups=1.66, wpb=8134.7, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=33929
2023-08-24 11:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 11:41:36 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.906, trans_loss=4.913, nll_loss=2.086, w2v_ctc_loss=0.574, task_loss=2.805, contrastive_loss=0, total=4277.21, n_correct=2876.7, ppl=4.24, accuracy=67.256, wps=14051.1, ups=1.64, wpb=8554.4, bsz=345.7, num_updates=47400, lr=6.4957e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=33990
2023-08-24 11:42:36 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.92, trans_loss=4.927, nll_loss=2.103, w2v_ctc_loss=0.585, task_loss=3.388, contrastive_loss=0, total=4111.69, n_correct=2756.09, ppl=4.29, accuracy=67.031, wps=13636.9, ups=1.66, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=34051
2023-08-24 11:43:36 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.905, trans_loss=4.912, nll_loss=2.082, w2v_ctc_loss=0.572, task_loss=3.09, contrastive_loss=0, total=4147.28, n_correct=2794.65, ppl=4.23, accuracy=67.385, wps=13960, ups=1.68, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=34110
2023-08-24 11:44:36 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.922, trans_loss=4.93, nll_loss=2.105, w2v_ctc_loss=0.585, task_loss=3.437, contrastive_loss=0, total=4127.68, n_correct=2765.92, ppl=4.3, accuracy=67.009, wps=13672.3, ups=1.66, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=34170
2023-08-24 11:45:37 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.924, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.585, task_loss=3.361, contrastive_loss=0, total=4164.1, n_correct=2778.67, ppl=4.35, accuracy=66.729, wps=13734.8, ups=1.65, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=34231
2023-08-24 11:46:37 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.934, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.604, task_loss=3.597, contrastive_loss=0, total=4064.29, n_correct=2710.96, ppl=4.34, accuracy=66.702, wps=13450.6, ups=1.65, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=34291
2023-08-24 11:47:37 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.908, trans_loss=4.924, nll_loss=2.1, w2v_ctc_loss=0.571, task_loss=3.098, contrastive_loss=0, total=4141.12, n_correct=2784.25, ppl=4.29, accuracy=67.234, wps=13795.6, ups=1.67, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=34351
2023-08-24 11:47:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:48:11 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.163 | trans_loss 5.549 | nll_loss 2.814 | w2v_ctc_loss 1.373 | task_loss 11.569 | contrastive_loss 0 | total 4003.4 | n_correct 2503 | ppl 7.03 | accuracy 62.522 | uer 16.587 | wer 18.362 | raw_wer 18.362 | bleu 20.33 | wps 1573.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.57
2023-08-24 11:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-24 11:48:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_48000.pt
2023-08-24 11:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_48000.pt
2023-08-24 11:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.33) (writing took 9.564339456963353 seconds)
2023-08-24 11:49:21 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.922, trans_loss=4.933, nll_loss=2.111, w2v_ctc_loss=0.592, task_loss=3.278, contrastive_loss=0, total=4147.76, n_correct=2776.81, ppl=4.32, accuracy=66.947, wps=8002.7, ups=0.96, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=34455
2023-08-24 11:50:21 | INFO | train_inner | epoch 033:   1051 / 1474 loss=1.921, trans_loss=4.934, nll_loss=2.112, w2v_ctc_loss=0.584, task_loss=3.288, contrastive_loss=0, total=4137.41, n_correct=2766.44, ppl=4.32, accuracy=66.864, wps=13657.3, ups=1.65, wpb=8274.8, bsz=307.9, num_updates=48200, lr=6.44157e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=34516
2023-08-24 11:51:22 | INFO | train_inner | epoch 033:   1151 / 1474 loss=1.924, trans_loss=4.942, nll_loss=2.123, w2v_ctc_loss=0.581, task_loss=3.31, contrastive_loss=0, total=4182.88, n_correct=2788.94, ppl=4.36, accuracy=66.675, wps=13774.1, ups=1.65, wpb=8365.8, bsz=308.6, num_updates=48300, lr=6.43489e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=34576
2023-08-24 11:52:23 | INFO | train_inner | epoch 033:   1251 / 1474 loss=1.927, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.593, task_loss=3.504, contrastive_loss=0, total=4102.27, n_correct=2742.2, ppl=4.33, accuracy=66.846, wps=13538.5, ups=1.65, wpb=8204.5, bsz=291.8, num_updates=48400, lr=6.42824e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=34637
2023-08-24 11:53:24 | INFO | train_inner | epoch 033:   1351 / 1474 loss=1.919, trans_loss=4.937, nll_loss=2.117, w2v_ctc_loss=0.585, task_loss=3.199, contrastive_loss=0, total=4131.08, n_correct=2765.6, ppl=4.34, accuracy=66.946, wps=13530.8, ups=1.64, wpb=8262.2, bsz=313.9, num_updates=48500, lr=6.42161e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=34698
2023-08-24 11:54:24 | INFO | train_inner | epoch 033:   1451 / 1474 loss=1.919, trans_loss=4.935, nll_loss=2.114, w2v_ctc_loss=0.578, task_loss=3.248, contrastive_loss=0, total=4135.49, n_correct=2764.15, ppl=4.33, accuracy=66.84, wps=13742.7, ups=1.66, wpb=8271, bsz=310.7, num_updates=48600, lr=6.415e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=34758
2023-08-24 11:54:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 11:55:11 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.151 | trans_loss 5.542 | nll_loss 2.808 | w2v_ctc_loss 1.348 | task_loss 11.592 | contrastive_loss 0 | total 4003.4 | n_correct 2504.3 | ppl 7 | accuracy 62.554 | uer 16.702 | wer 18.575 | raw_wer 18.575 | bleu 20.53 | wps 1625.9 | wpb 4003.4 | bsz 141.8 | num_updates 48623 | best_bleu 20.57
2023-08-24 11:55:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48623 updates
2023-08-24 11:55:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5303.pt
2023-08-24 11:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5303.pt
2023-08-24 11:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_20.5303.pt (epoch 33 @ 48623 updates, score 20.53) (writing took 7.140577147016302 seconds)
2023-08-24 11:55:18 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-24 11:55:18 | INFO | train | epoch 033 | loss 1.918 | trans_loss 4.929 | nll_loss 2.105 | w2v_ctc_loss 0.582 | task_loss 3.288 | contrastive_loss 0 | total 4138.2 | n_correct 2772.73 | ppl 4.3 | accuracy 67.003 | wps 12426.9 | ups 1.5 | wpb 8276.4 | bsz 305.6 | num_updates 48623 | lr 6.41349e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 878 | gb_free 17.8 | wall 34812
2023-08-24 11:55:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-24 11:55:18 | INFO | fairseq.trainer | begin training epoch 34
2023-08-24 11:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 11:56:12 | INFO | train_inner | epoch 034:     77 / 1474 loss=1.909, trans_loss=4.912, nll_loss=2.082, w2v_ctc_loss=0.576, task_loss=3.248, contrastive_loss=0, total=4122.67, n_correct=2778, ppl=4.23, accuracy=67.384, wps=7619.4, ups=0.92, wpb=8245.3, bsz=301.4, num_updates=48700, lr=6.40841e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=34867
2023-08-24 11:57:12 | INFO | train_inner | epoch 034:    177 / 1474 loss=1.908, trans_loss=4.904, nll_loss=2.072, w2v_ctc_loss=0.58, task_loss=3.435, contrastive_loss=0, total=4074.94, n_correct=2752.27, ppl=4.2, accuracy=67.541, wps=13557.8, ups=1.66, wpb=8149.9, bsz=295.4, num_updates=48800, lr=6.40184e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=34927
2023-08-24 11:58:13 | INFO | train_inner | epoch 034:    277 / 1474 loss=1.915, trans_loss=4.925, nll_loss=2.1, w2v_ctc_loss=0.58, task_loss=3.113, contrastive_loss=0, total=4228.22, n_correct=2832.81, ppl=4.29, accuracy=66.998, wps=14046.2, ups=1.66, wpb=8456.4, bsz=324.6, num_updates=48900, lr=6.39529e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=34987
2023-08-24 11:59:13 | INFO | train_inner | epoch 034:    377 / 1474 loss=1.902, trans_loss=4.908, nll_loss=2.077, w2v_ctc_loss=0.567, task_loss=3.085, contrastive_loss=0, total=4173.35, n_correct=2814.05, ppl=4.22, accuracy=67.429, wps=13728.6, ups=1.64, wpb=8346.7, bsz=320.5, num_updates=49000, lr=6.38877e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=35048
2023-08-24 12:00:13 | INFO | train_inner | epoch 034:    477 / 1474 loss=1.919, trans_loss=4.922, nll_loss=2.094, w2v_ctc_loss=0.587, task_loss=3.604, contrastive_loss=0, total=4066.67, n_correct=2733.22, ppl=4.27, accuracy=67.21, wps=13585.4, ups=1.67, wpb=8133.3, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=35108
2023-08-24 12:01:13 | INFO | train_inner | epoch 034:    577 / 1474 loss=1.91, trans_loss=4.913, nll_loss=2.083, w2v_ctc_loss=0.574, task_loss=3.326, contrastive_loss=0, total=4115.49, n_correct=2770.29, ppl=4.24, accuracy=67.314, wps=13804.5, ups=1.68, wpb=8231, bsz=299.4, num_updates=49200, lr=6.37577e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=59, gb_free=14.8, wall=35167
2023-08-24 12:02:13 | INFO | train_inner | epoch 034:    677 / 1474 loss=1.91, trans_loss=4.918, nll_loss=2.091, w2v_ctc_loss=0.575, task_loss=3.338, contrastive_loss=0, total=4124.78, n_correct=2779.33, ppl=4.26, accuracy=67.381, wps=13691.1, ups=1.66, wpb=8249.6, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=59, gb_free=11.5, wall=35227
2023-08-24 12:03:13 | INFO | train_inner | epoch 034:    777 / 1474 loss=1.92, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.574, task_loss=3.411, contrastive_loss=0, total=4082.25, n_correct=2729.52, ppl=4.34, accuracy=66.863, wps=13705.6, ups=1.68, wpb=8164.5, bsz=296, num_updates=49400, lr=6.36285e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=35287
2023-08-24 12:04:14 | INFO | train_inner | epoch 034:    877 / 1474 loss=1.919, trans_loss=4.93, nll_loss=2.106, w2v_ctc_loss=0.583, task_loss=3.486, contrastive_loss=0, total=4110.66, n_correct=2756.41, ppl=4.31, accuracy=67.055, wps=13497, ups=1.64, wpb=8221.3, bsz=296.1, num_updates=49500, lr=6.35642e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=35348
2023-08-24 12:05:14 | INFO | train_inner | epoch 034:    977 / 1474 loss=1.919, trans_loss=4.929, nll_loss=2.107, w2v_ctc_loss=0.587, task_loss=3.217, contrastive_loss=0, total=4162.47, n_correct=2789.27, ppl=4.31, accuracy=67.01, wps=13836.5, ups=1.66, wpb=8324.9, bsz=312.5, num_updates=49600, lr=6.35001e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=35408
2023-08-24 12:06:13 | INFO | train_inner | epoch 034:   1077 / 1474 loss=1.92, trans_loss=4.934, nll_loss=2.111, w2v_ctc_loss=0.588, task_loss=3.171, contrastive_loss=0, total=4151.58, n_correct=2776, ppl=4.32, accuracy=66.866, wps=13930.2, ups=1.68, wpb=8303.2, bsz=308, num_updates=49700, lr=6.34361e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=35468
2023-08-24 12:07:14 | INFO | train_inner | epoch 034:   1177 / 1474 loss=1.917, trans_loss=4.929, nll_loss=2.105, w2v_ctc_loss=0.581, task_loss=3.392, contrastive_loss=0, total=4091.98, n_correct=2742.53, ppl=4.3, accuracy=67.022, wps=13588.1, ups=1.66, wpb=8184, bsz=297.4, num_updates=49800, lr=6.33724e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35528
2023-08-24 12:08:14 | INFO | train_inner | epoch 034:   1277 / 1474 loss=1.916, trans_loss=4.928, nll_loss=2.104, w2v_ctc_loss=0.578, task_loss=3.311, contrastive_loss=0, total=4162.83, n_correct=2790.57, ppl=4.3, accuracy=67.035, wps=13895.6, ups=1.67, wpb=8325.7, bsz=301.1, num_updates=49900, lr=6.33089e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=35588
2023-08-24 12:09:14 | INFO | train_inner | epoch 034:   1377 / 1474 loss=1.921, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.589, task_loss=3.158, contrastive_loss=0, total=4187.24, n_correct=2798.31, ppl=4.33, accuracy=66.829, wps=13866.8, ups=1.66, wpb=8374.5, bsz=320.2, num_updates=50000, lr=6.32456e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35648
2023-08-24 12:09:14 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-24 12:09:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 12:09:47 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.161 | trans_loss 5.547 | nll_loss 2.815 | w2v_ctc_loss 1.371 | task_loss 11.589 | contrastive_loss 0 | total 4003.4 | n_correct 2498.8 | ppl 7.04 | accuracy 62.417 | uer 16.89 | wer 18.81 | raw_wer 18.81 | bleu 20.24 | wps 1578.7 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.57
2023-08-24 12:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-24 12:09:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_50000.pt
2023-08-24 12:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_50000.pt
2023-08-24 12:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_mustc_0824_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.24) (writing took 7.735354342032224 seconds)
2023-08-24 12:09:55 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-24 12:09:55 | INFO | train | epoch 034 | loss 1.915 | trans_loss 4.923 | nll_loss 2.097 | w2v_ctc_loss 0.58 | task_loss 3.305 | contrastive_loss 0 | total 4133.06 | n_correct 2774.96 | ppl 4.28 | accuracy 67.14 | wps 12974.1 | ups 1.57 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.536 | clip 0 | loss_scale 64 | train_wall 818 | gb_free 17.1 | wall 35690
2023-08-24 12:09:55 | INFO | fairseq_cli.train | done training in 35645.4 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
stage 1: ST Network Training
dev=0,1,2,3,4,5,6,7 data=data_all_enfr_lcrm model=./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py data_all_enfr_lcrm --config-yaml config_st.yaml --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml --task joint_triple_pretraining_merge --max-tokens 11000 --skip-invalid-size-inputs-valid-test --update-freq 1 --log-interval 100 --save-dir ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5 --tensorboard-logdir ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5 --distributed-world-size 8 --ddp-backend no_c10d --fp16 --eval-bleu --eval-tokenized-bleu --eval-bleu-remove-bpe sentencepiece --best-checkpoint-metric bleu --keep-best-checkpoints 10 --maximize-best-checkpoint-metric
[34mRun command: 
python3 -u /mnt/zhangyh/fairseq-AT/fairseq_cli/train.py
        data_all_enfr_lcrm
        --config-yaml config_st.yaml
        --train-config /mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml
        --task joint_triple_pretraining_merge
        --max-tokens 11000
        --skip-invalid-size-inputs-valid-test
        --update-freq 1
        --log-interval 100
        --save-dir ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5
        --tensorboard-logdir ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5
        
        --distributed-world-size 8
        --ddp-backend no_c10d
        --fp16
        --eval-bleu
        --eval-tokenized-bleu
        --eval-bleu-remove-bpe sentencepiece
        --best-checkpoint-metric bleu
        --keep-best-checkpoints 10
        --maximize-best-checkpoint-metric
        --no-epoch-checkpoints
        --validate-interval 1 
        --save-interval 1 
        --keep-last-epochs 2 
        --save-interval-updates 2000
        --keep-interval-updates 5
        --share-decoder-input-output-embed
        --use-w2v-ctc [0m
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13986
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-06 01:14:05 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 01:14:05 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-06 01:14:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13986', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-06 01:14:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-06 01:14:09 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 01:14:13 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-06 01:14:13 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-06 01:14:13 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-06 01:14:15 | INFO | root | load pretrained hubert
2023-09-06 01:14:23 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 01:14:27 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 01:14:33 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 01:14:33 | INFO | root | share the sematic adapter and textual encoder
2023-09-06 01:14:33 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-06 01:14:33 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-06 01:14:33 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-06 01:14:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-06 01:14:33 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-09-06 01:14:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-06 01:14:33 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 01:14:33 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:33 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:33 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:14:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-06 01:14:49 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-06 01:14:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-06 01:14:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 01:14:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 01:14:50 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-06 01:14:50 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-09-06 01:14:50 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 01:14:50 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 01:14:50 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-06 01:14:50 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 01:14:50 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:50 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 01:14:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:14:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 01:15:45 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-06 01:15:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:15:45 | INFO | fairseq.trainer | begin training epoch 1
2023-09-06 01:15:45 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 01:16:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 01:17:57 | INFO | train_inner | epoch 001:    101 / 1191 loss=17.16, trans_loss=6.401, nll_loss=5.175, w2v_ctc_loss=21.38, task_loss=3.03, task_loss_gen=3.551, contrastive_loss=0, total=6742.88, n_correct=205.42, ppl=36.13, accuracy=3.046, wps=17186.3, ups=0.88, wpb=19527.6, bsz=683.2, num_updates=100, lr=4.098e-06, gnorm=1.634, clip=0, loss_scale=64, train_wall=120, gb_free=17.7, wall=186
2023-09-06 01:18:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 01:19:59 | INFO | train_inner | epoch 001:    202 / 1191 loss=13.548, trans_loss=6.32, nll_loss=5.118, w2v_ctc_loss=15.898, task_loss=2.312, task_loss_gen=3.909, contrastive_loss=0, total=6677.34, n_correct=191.45, ppl=34.72, accuracy=2.867, wps=15869.1, ups=0.82, wpb=19352.7, bsz=677.6, num_updates=200, lr=8.096e-06, gnorm=6.139, clip=4, loss_scale=32, train_wall=121, gb_free=17.8, wall=308
2023-09-06 01:22:03 | INFO | train_inner | epoch 001:    302 / 1191 loss=8.437, trans_loss=6.223, nll_loss=5.054, w2v_ctc_loss=8.128, task_loss=1.177, task_loss_gen=4.482, contrastive_loss=0, total=6864.64, n_correct=200.05, ppl=33.21, accuracy=2.914, wps=15992.5, ups=0.8, wpb=19894.5, bsz=719.8, num_updates=300, lr=1.2094e-05, gnorm=1.619, clip=0, loss_scale=32, train_wall=124, gb_free=18.2, wall=433
2023-09-06 01:23:58 | INFO | train_inner | epoch 001:    402 / 1191 loss=7.904, trans_loss=6.136, nll_loss=4.986, w2v_ctc_loss=7.387, task_loss=0.573, task_loss_gen=7.44, contrastive_loss=0, total=6664.2, n_correct=185.4, ppl=31.69, accuracy=2.782, wps=16791.7, ups=0.87, wpb=19324, bsz=657.6, num_updates=400, lr=1.6092e-05, gnorm=0.833, clip=0, loss_scale=32, train_wall=106, gb_free=17.9, wall=548
2023-09-06 01:25:56 | INFO | train_inner | epoch 001:    502 / 1191 loss=7.647, trans_loss=6.107, nll_loss=4.961, w2v_ctc_loss=7.029, task_loss=0.17, task_loss_gen=9.748, contrastive_loss=0, total=6743.88, n_correct=179.93, ppl=31.15, accuracy=2.668, wps=16526.4, ups=0.85, wpb=19536.7, bsz=687.8, num_updates=500, lr=2.009e-05, gnorm=0.702, clip=0, loss_scale=32, train_wall=118, gb_free=17.7, wall=666
2023-09-06 01:27:52 | INFO | train_inner | epoch 001:    602 / 1191 loss=7.547, trans_loss=6.083, nll_loss=4.94, w2v_ctc_loss=6.898, task_loss=0.051, task_loss_gen=12.882, contrastive_loss=0, total=6761.26, n_correct=171.21, ppl=30.7, accuracy=2.532, wps=16854.2, ups=0.86, wpb=19590.9, bsz=685.7, num_updates=600, lr=2.4088e-05, gnorm=0.852, clip=0, loss_scale=32, train_wall=116, gb_free=18.9, wall=782
2023-09-06 01:29:44 | INFO | train_inner | epoch 001:    702 / 1191 loss=7.439, trans_loss=6.047, nll_loss=4.905, w2v_ctc_loss=6.768, task_loss=0.016, task_loss_gen=16.198, contrastive_loss=0, total=6642.51, n_correct=157.58, ppl=29.96, accuracy=2.372, wps=17275.5, ups=0.9, wpb=19237.1, bsz=677.7, num_updates=700, lr=2.8086e-05, gnorm=0.875, clip=0, loss_scale=32, train_wall=110, gb_free=17.6, wall=894
2023-09-06 01:31:25 | INFO | train_inner | epoch 001:    802 / 1191 loss=7.378, trans_loss=5.986, nll_loss=4.837, w2v_ctc_loss=6.738, task_loss=0.005, task_loss_gen=18.296, contrastive_loss=0, total=6747.81, n_correct=149.5, ppl=28.58, accuracy=2.216, wps=19386.2, ups=0.99, wpb=19542.8, bsz=688.1, num_updates=800, lr=3.2084e-05, gnorm=0.908, clip=0, loss_scale=32, train_wall=100, gb_free=17.7, wall=994
2023-09-06 01:32:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 01:32:53 | INFO | train_inner | epoch 001:    903 / 1191 loss=6.964, trans_loss=5.854, nll_loss=4.686, w2v_ctc_loss=6.237, task_loss=0.003, task_loss_gen=21.91, contrastive_loss=0, total=6690.14, n_correct=87.23, ppl=25.75, accuracy=1.304, wps=21835.9, ups=1.13, wpb=19388, bsz=669.3, num_updates=900, lr=3.6082e-05, gnorm=1.305, clip=0, loss_scale=16, train_wall=88, gb_free=17.6, wall=1083
2023-09-06 01:34:15 | INFO | train_inner | epoch 001:   1003 / 1191 loss=6.284, trans_loss=5.884, nll_loss=4.721, w2v_ctc_loss=5.158, task_loss=0, task_loss_gen=27.059, contrastive_loss=0, total=6668.9, n_correct=24.82, ppl=26.38, accuracy=0.372, wps=23850.3, ups=1.23, wpb=19321.9, bsz=662.2, num_updates=1000, lr=4.008e-05, gnorm=0.435, clip=0, loss_scale=16, train_wall=80, gb_free=18.5, wall=1164
2023-09-06 01:35:35 | INFO | train_inner | epoch 001:   1103 / 1191 loss=6.228, trans_loss=6.192, nll_loss=5.081, w2v_ctc_loss=4.742, task_loss=0.943, task_loss_gen=14.75, contrastive_loss=0, total=6578.13, n_correct=20.56, ppl=33.84, accuracy=0.313, wps=23821.3, ups=1.25, wpb=19050.5, bsz=647.4, num_updates=1100, lr=4.4078e-05, gnorm=0.504, clip=0, loss_scale=16, train_wall=79, gb_free=17.6, wall=1244
2023-09-06 01:36:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-06 01:37:35 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 11.667 | trans_loss 14.713 | nll_loss 14.863 | w2v_ctc_loss 5.648 | task_loss 10.08 | task_loss_gen 22.958 | contrastive_loss 0 | total 6138.43 | n_correct 0.428571 | ppl 29802.6 | accuracy 0.007 | uer 75.733 | wer 73.663 | raw_wer 73.663 | bleu 0 | wps 1203.2 | wpb 6138.4 | bsz 201.1 | num_updates 1188
2023-09-06 01:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1188 updates
2023-09-06 01:37:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:37:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 1 @ 1188 updates, score 0.0) (writing took 5.493970101000741 seconds)
2023-09-06 01:37:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-06 01:37:41 | INFO | train | epoch 001 | loss 8.576 | trans_loss 6.119 | nll_loss 4.966 | w2v_ctc_loss 8.445 | task_loss 0.876 | task_loss_gen 12.03 | contrastive_loss 0 | total 6702.44 | n_correct 134.058 | ppl 31.26 | accuracy 2 | wps 17779.6 | ups 0.92 | wpb 19419.2 | bsz 677.7 | num_updates 1188 | lr 4.75962e-05 | gnorm 1.37 | clip 0.3 | loss_scale 16 | train_wall 1226 | gb_free 18.5 | wall 1370
2023-09-06 01:37:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:37:41 | INFO | fairseq.trainer | begin training epoch 2
2023-09-06 01:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 01:37:56 | INFO | train_inner | epoch 002:     12 / 1191 loss=5.948, trans_loss=6.21, nll_loss=5.164, w2v_ctc_loss=4.295, task_loss=2.35, task_loss_gen=4.008, contrastive_loss=0, total=6631.26, n_correct=20.43, ppl=35.84, accuracy=0.308, wps=13550.5, ups=0.71, wpb=19218.6, bsz=679.5, num_updates=1200, lr=4.8076e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=71, gb_free=17.5, wall=1386
2023-09-06 01:39:01 | INFO | train_inner | epoch 002:    112 / 1191 loss=5.739, trans_loss=6.226, nll_loss=5.171, w2v_ctc_loss=3.956, task_loss=2.052, task_loss_gen=4.16, contrastive_loss=0, total=6617.43, n_correct=18.82, ppl=36.02, accuracy=0.284, wps=29573, ups=1.54, wpb=19164.1, bsz=662.2, num_updates=1300, lr=5.2074e-05, gnorm=0.641, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=1451
2023-09-06 01:40:07 | INFO | train_inner | epoch 002:    212 / 1191 loss=5.709, trans_loss=6.426, nll_loss=5.426, w2v_ctc_loss=3.698, task_loss=1.778, task_loss_gen=4.266, contrastive_loss=0, total=6716.9, n_correct=14.63, ppl=42.99, accuracy=0.218, wps=29643.3, ups=1.52, wpb=19456.2, bsz=672.8, num_updates=1400, lr=5.6072e-05, gnorm=0.689, clip=0, loss_scale=16, train_wall=65, gb_free=17.5, wall=1517
2023-09-06 01:41:12 | INFO | train_inner | epoch 002:    312 / 1191 loss=5.55, trans_loss=6.385, nll_loss=5.365, w2v_ctc_loss=3.498, task_loss=1.64, task_loss_gen=4.107, contrastive_loss=0, total=6776.25, n_correct=14.19, ppl=41.2, accuracy=0.209, wps=29990.2, ups=1.53, wpb=19634.6, bsz=690.8, num_updates=1500, lr=6.007e-05, gnorm=0.731, clip=0, loss_scale=16, train_wall=65, gb_free=18, wall=1582
2023-09-06 01:42:17 | INFO | train_inner | epoch 002:    412 / 1191 loss=5.37, trans_loss=6.272, nll_loss=5.226, w2v_ctc_loss=3.341, task_loss=1.231, task_loss_gen=4.668, contrastive_loss=0, total=6718.15, n_correct=8.83, ppl=37.43, accuracy=0.131, wps=29973.5, ups=1.54, wpb=19472.2, bsz=690.8, num_updates=1600, lr=6.4068e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=1647
2023-09-06 01:43:22 | INFO | train_inner | epoch 002:    512 / 1191 loss=5.156, trans_loss=6.071, nll_loss=4.979, w2v_ctc_loss=3.218, task_loss=1.035, task_loss_gen=5.221, contrastive_loss=0, total=6696.54, n_correct=19.66, ppl=31.55, accuracy=0.294, wps=29819.3, ups=1.54, wpb=19408.7, bsz=678.7, num_updates=1700, lr=6.8066e-05, gnorm=0.752, clip=0, loss_scale=16, train_wall=65, gb_free=18.1, wall=1712
2023-09-06 01:44:27 | INFO | train_inner | epoch 002:    612 / 1191 loss=5.126, trans_loss=6.153, nll_loss=5.069, w2v_ctc_loss=3.086, task_loss=1.028, task_loss_gen=5.422, contrastive_loss=0, total=6640.77, n_correct=13.21, ppl=33.58, accuracy=0.199, wps=29517, ups=1.54, wpb=19228.2, bsz=659.1, num_updates=1800, lr=7.2064e-05, gnorm=0.768, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=1777
2023-09-06 01:45:32 | INFO | train_inner | epoch 002:    712 / 1191 loss=5.042, trans_loss=6.13, nll_loss=5.038, w2v_ctc_loss=2.985, task_loss=0.65, task_loss_gen=5.788, contrastive_loss=0, total=6799.78, n_correct=13.39, ppl=32.85, accuracy=0.197, wps=30520.5, ups=1.55, wpb=19685.9, bsz=701.6, num_updates=1900, lr=7.6062e-05, gnorm=0.765, clip=0, loss_scale=16, train_wall=64, gb_free=17.9, wall=1842
2023-09-06 01:46:37 | INFO | train_inner | epoch 002:    812 / 1191 loss=5.001, trans_loss=6.14, nll_loss=5.03, w2v_ctc_loss=2.906, task_loss=0.475, task_loss_gen=6.615, contrastive_loss=0, total=6729.15, n_correct=10.27, ppl=32.67, accuracy=0.153, wps=29842.1, ups=1.53, wpb=19495.9, bsz=677.7, num_updates=2000, lr=8.006e-05, gnorm=0.75, clip=0, loss_scale=16, train_wall=65, gb_free=17.7, wall=1907
2023-09-06 01:46:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 01:47:21 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.846 | trans_loss 12.902 | nll_loss 12.568 | w2v_ctc_loss 3.672 | task_loss 7.175 | task_loss_gen 24.859 | contrastive_loss 0 | total 6138.43 | n_correct 32 | ppl 6070.99 | accuracy 0.521 | uer 55.069 | wer 53.589 | raw_wer 53.589 | bleu 0 | wps 1217.4 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-09-06 01:47:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-06 01:47:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 01:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 01:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 19.330662569962442 seconds)
2023-09-06 01:48:46 | INFO | train_inner | epoch 002:    912 / 1191 loss=4.945, trans_loss=6.136, nll_loss=5.065, w2v_ctc_loss=2.829, task_loss=0.279, task_loss_gen=7.663, contrastive_loss=0, total=6738.95, n_correct=14.6, ppl=33.48, accuracy=0.217, wps=15218.2, ups=0.78, wpb=19533.2, bsz=703.8, num_updates=2100, lr=8.4058e-05, gnorm=0.834, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=2036
2023-09-06 01:49:51 | INFO | train_inner | epoch 002:   1012 / 1191 loss=5.063, trans_loss=6.351, nll_loss=5.318, w2v_ctc_loss=2.779, task_loss=0.151, task_loss_gen=9.471, contrastive_loss=0, total=6774.79, n_correct=12.94, ppl=39.89, accuracy=0.191, wps=30232.3, ups=1.54, wpb=19640.8, bsz=687.3, num_updates=2200, lr=8.8056e-05, gnorm=0.689, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=2100
2023-09-06 01:50:55 | INFO | train_inner | epoch 002:   1112 / 1191 loss=4.888, trans_loss=6.15, nll_loss=5.066, w2v_ctc_loss=2.722, task_loss=0.081, task_loss_gen=11.642, contrastive_loss=0, total=6659.17, n_correct=33.27, ppl=33.49, accuracy=0.5, wps=29905.7, ups=1.55, wpb=19287, bsz=656.7, num_updates=2300, lr=9.2054e-05, gnorm=0.656, clip=0, loss_scale=16, train_wall=64, gb_free=18.4, wall=2165
2023-09-06 01:51:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 01:52:30 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.953 | trans_loss 14.672 | nll_loss 14.75 | w2v_ctc_loss 3.361 | task_loss 0.58 | task_loss_gen 55.969 | contrastive_loss 0 | total 6138.43 | n_correct 0.285714 | ppl 27553.3 | accuracy 0.005 | uer 50.836 | wer 50.643 | raw_wer 50.643 | bleu 0 | wps 1214.3 | wpb 6138.4 | bsz 201.1 | num_updates 2379 | best_bleu 0
2023-09-06 01:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2379 updates
2023-09-06 01:52:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 01:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 2 @ 2379 updates, score 0.0) (writing took 11.415338346036151 seconds)
2023-09-06 01:52:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-06 01:52:42 | INFO | train | epoch 002 | loss 5.227 | trans_loss 6.232 | nll_loss 5.172 | w2v_ctc_loss 3.16 | task_loss 0.899 | task_loss_gen 6.664 | contrastive_loss 0 | total 6703.69 | n_correct 16.2939 | ppl 36.05 | accuracy 0.243 | wps 25670.1 | ups 1.32 | wpb 19422.7 | bsz 678.2 | num_updates 2379 | lr 9.52124e-05 | gnorm 0.749 | clip 0 | loss_scale 16 | train_wall 767 | gb_free 17.7 | wall 2272
2023-09-06 01:52:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 01:52:42 | INFO | fairseq.trainer | begin training epoch 3
2023-09-06 01:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 01:53:03 | INFO | train_inner | epoch 003:     21 / 1191 loss=4.991, trans_loss=6.331, nll_loss=5.296, w2v_ctc_loss=2.688, task_loss=0.054, task_loss_gen=12.943, contrastive_loss=0, total=6599.17, n_correct=20.1, ppl=39.28, accuracy=0.305, wps=14979.5, ups=0.78, wpb=19129.9, bsz=657.1, num_updates=2400, lr=9.6052e-05, gnorm=0.791, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=2293
2023-09-06 01:54:07 | INFO | train_inner | epoch 003:    121 / 1191 loss=4.836, trans_loss=6.161, nll_loss=5.078, w2v_ctc_loss=2.625, task_loss=0.03, task_loss_gen=13.406, contrastive_loss=0, total=6686.57, n_correct=11.27, ppl=33.78, accuracy=0.169, wps=30079.7, ups=1.55, wpb=19387.8, bsz=684.3, num_updates=2500, lr=0.00010005, gnorm=0.694, clip=0, loss_scale=16, train_wall=64, gb_free=18.6, wall=2357
2023-09-06 01:55:13 | INFO | train_inner | epoch 003:    221 / 1191 loss=4.855, trans_loss=6.262, nll_loss=5.224, w2v_ctc_loss=2.554, task_loss=0.017, task_loss_gen=14.494, contrastive_loss=0, total=6719.64, n_correct=13.44, ppl=37.37, accuracy=0.2, wps=29567.4, ups=1.52, wpb=19473.2, bsz=686.5, num_updates=2600, lr=0.000104048, gnorm=0.652, clip=0, loss_scale=16, train_wall=65, gb_free=18.8, wall=2423
2023-09-06 01:56:18 | INFO | train_inner | epoch 003:    321 / 1191 loss=4.811, trans_loss=6.195, nll_loss=5.123, w2v_ctc_loss=2.549, task_loss=0.014, task_loss_gen=17.989, contrastive_loss=0, total=6583.91, n_correct=13.83, ppl=34.84, accuracy=0.21, wps=29251.8, ups=1.53, wpb=19066, bsz=626, num_updates=2700, lr=0.000108046, gnorm=0.685, clip=0, loss_scale=16, train_wall=65, gb_free=17.6, wall=2488
2023-09-06 01:57:23 | INFO | train_inner | epoch 003:    421 / 1191 loss=4.76, trans_loss=6.189, nll_loss=5.115, w2v_ctc_loss=2.481, task_loss=0.006, task_loss_gen=17.316, contrastive_loss=0, total=6692.35, n_correct=25.62, ppl=34.65, accuracy=0.383, wps=30126.9, ups=1.55, wpb=19390.6, bsz=688.7, num_updates=2800, lr=0.000112044, gnorm=0.559, clip=0, loss_scale=16, train_wall=64, gb_free=17.4, wall=2553
2023-09-06 01:58:28 | INFO | train_inner | epoch 003:    521 / 1191 loss=4.763, trans_loss=6.207, nll_loss=5.149, w2v_ctc_loss=2.471, task_loss=0.003, task_loss_gen=19.283, contrastive_loss=0, total=6739.55, n_correct=23.85, ppl=35.49, accuracy=0.354, wps=29987.3, ups=1.54, wpb=19529.7, bsz=674.5, num_updates=2900, lr=0.000116042, gnorm=0.597, clip=0, loss_scale=32, train_wall=65, gb_free=17.9, wall=2618
2023-09-06 01:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 01:59:34 | INFO | train_inner | epoch 003:    622 / 1191 loss=4.843, trans_loss=6.347, nll_loss=5.316, w2v_ctc_loss=2.437, task_loss=0.002, task_loss_gen=21.491, contrastive_loss=0, total=6744.3, n_correct=14.57, ppl=39.83, accuracy=0.216, wps=29731.3, ups=1.52, wpb=19545.7, bsz=659.7, num_updates=3000, lr=0.00012004, gnorm=0.584, clip=0, loss_scale=16, train_wall=65, gb_free=18.6, wall=2683
2023-09-06 01:59:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 01:59:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-06 01:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-06 02:01:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-06 02:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 02:01:22 | INFO | train_inner | epoch 003:    727 / 1191 loss=3.762, trans_loss=5.132, nll_loss=3.773, w2v_ctc_loss=2.091, task_loss=1.885, task_loss_gen=8.311, contrastive_loss=0, total=6728.46, n_correct=686.39, ppl=13.67, accuracy=10.201, wps=17945.6, ups=0.92, wpb=19499, bsz=693.3, num_updates=3100, lr=0.000124038, gnorm=2.158, clip=0, loss_scale=0.5, train_wall=108, gb_free=14.7, wall=2792
2023-09-06 02:03:05 | INFO | train_inner | epoch 003:    827 / 1191 loss=3.096, trans_loss=4.408, nll_loss=2.8, w2v_ctc_loss=1.9, task_loss=1.32, task_loss_gen=4.586, contrastive_loss=0, total=6787.8, n_correct=1900.47, ppl=6.96, accuracy=27.998, wps=19101.2, ups=0.97, wpb=19674.9, bsz=712, num_updates=3200, lr=0.000128036, gnorm=4.569, clip=3, loss_scale=0.5, train_wall=102, gb_free=12.9, wall=2895
2023-09-06 02:04:47 | INFO | train_inner | epoch 003:    927 / 1191 loss=2.921, trans_loss=4.259, nll_loss=2.606, w2v_ctc_loss=1.815, task_loss=1.249, task_loss_gen=4.273, contrastive_loss=0, total=6806.95, n_correct=2294.87, ppl=6.09, accuracy=33.714, wps=19458.5, ups=0.99, wpb=19716, bsz=716.9, num_updates=3300, lr=0.000132034, gnorm=3.962, clip=3, loss_scale=0.5, train_wall=101, gb_free=13.9, wall=2996
2023-09-06 02:06:30 | INFO | train_inner | epoch 003:   1027 / 1191 loss=2.893, trans_loss=4.294, nll_loss=2.652, w2v_ctc_loss=1.794, task_loss=1.377, task_loss_gen=5.329, contrastive_loss=0, total=6529.36, n_correct=2246.6, ppl=6.28, accuracy=34.408, wps=18267.6, ups=0.97, wpb=18923.2, bsz=611.4, num_updates=3400, lr=0.000136032, gnorm=3.663, clip=0, loss_scale=0.5, train_wall=103, gb_free=6.7, wall=3100
2023-09-06 02:08:14 | INFO | train_inner | epoch 003:   1127 / 1191 loss=2.818, trans_loss=4.339, nll_loss=2.705, w2v_ctc_loss=1.712, task_loss=1.309, task_loss_gen=3.991, contrastive_loss=0, total=6784.07, n_correct=2393.91, ppl=6.52, accuracy=35.287, wps=18932.7, ups=0.96, wpb=19637.9, bsz=711.9, num_updates=3500, lr=0.00014003, gnorm=3.994, clip=0, loss_scale=0.5, train_wall=103, gb_free=12.6, wall=3204
2023-09-06 02:09:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:09:55 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.396 | trans_loss 7.066 | nll_loss 4.915 | w2v_ctc_loss 2.021 | task_loss 25.672 | task_loss_gen 16.199 | contrastive_loss 0 | total 6138.43 | n_correct 2269.29 | ppl 30.17 | accuracy 36.969 | uer 33.073 | wer 33.005 | raw_wer 33.005 | bleu 0.09 | wps 1554.7 | wpb 6138.4 | bsz 201.1 | num_updates 3564 | best_bleu 0.09
2023-09-06 02:09:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3564 updates
2023-09-06 02:09:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 3 @ 3564 updates, score 0.09) (writing took 12.184983404004015 seconds)
2023-09-06 02:10:08 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-06 02:10:08 | INFO | train | epoch 003 | loss 3.98 | trans_loss 5.387 | nll_loss 4.076 | w2v_ctc_loss 2.199 | task_loss 0.696 | task_loss_gen 11.36 | contrastive_loss 0 | total 6703.78 | n_correct 937.923 | ppl 16.87 | accuracy 13.991 | wps 22004.4 | ups 1.13 | wpb 19422.8 | bsz 677.7 | num_updates 3564 | lr 0.000142589 | gnorm 2.127 | clip 0.8 | loss_scale 0.5 | train_wall 982 | gb_free 15.1 | wall 3318
2023-09-06 02:10:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:10:08 | INFO | fairseq.trainer | begin training epoch 4
2023-09-06 02:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:10:53 | INFO | train_inner | epoch 004:     36 / 1191 loss=2.794, trans_loss=4.259, nll_loss=2.605, w2v_ctc_loss=1.675, task_loss=1.587, task_loss_gen=4.082, contrastive_loss=0, total=6564.97, n_correct=2314.96, ppl=6.08, accuracy=35.262, wps=11926, ups=0.63, wpb=19003.4, bsz=642.3, num_updates=3600, lr=0.000144028, gnorm=4.645, clip=4, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=3363
2023-09-06 02:12:37 | INFO | train_inner | epoch 004:    136 / 1191 loss=2.751, trans_loss=4.211, nll_loss=2.547, w2v_ctc_loss=1.622, task_loss=1.416, task_loss_gen=3.955, contrastive_loss=0, total=6717.55, n_correct=2402.64, ppl=5.85, accuracy=35.767, wps=18746.7, ups=0.96, wpb=19456.2, bsz=654.6, num_updates=3700, lr=0.000148026, gnorm=3.954, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.6, wall=3467
2023-09-06 02:14:20 | INFO | train_inner | epoch 004:    236 / 1191 loss=2.728, trans_loss=4.242, nll_loss=2.588, w2v_ctc_loss=1.6, task_loss=1.725, task_loss_gen=4.09, contrastive_loss=0, total=6754.2, n_correct=2441.85, ppl=6.01, accuracy=36.153, wps=19099.9, ups=0.98, wpb=19575.6, bsz=702.5, num_updates=3800, lr=0.000152024, gnorm=5.421, clip=11, loss_scale=0.5, train_wall=102, gb_free=11.9, wall=3569
2023-09-06 02:16:01 | INFO | train_inner | epoch 004:    336 / 1191 loss=2.711, trans_loss=4.227, nll_loss=2.569, w2v_ctc_loss=1.577, task_loss=1.679, task_loss_gen=4.028, contrastive_loss=0, total=6663.4, n_correct=2413.26, ppl=5.94, accuracy=36.217, wps=19064.8, ups=0.99, wpb=19310.2, bsz=662.9, num_updates=3900, lr=0.000156022, gnorm=4.812, clip=6, loss_scale=0.5, train_wall=101, gb_free=10.4, wall=3671
2023-09-06 02:17:43 | INFO | train_inner | epoch 004:    436 / 1191 loss=2.693, trans_loss=4.197, nll_loss=2.532, w2v_ctc_loss=1.554, task_loss=1.704, task_loss_gen=3.665, contrastive_loss=0, total=6723.42, n_correct=2444.34, ppl=5.78, accuracy=36.356, wps=19006.7, ups=0.98, wpb=19479.8, bsz=685.4, num_updates=4000, lr=0.00016002, gnorm=4.812, clip=3, loss_scale=0.5, train_wall=102, gb_free=14, wall=3773
2023-09-06 02:17:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:18:15 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.28 | trans_loss 6.982 | nll_loss 4.809 | w2v_ctc_loss 1.824 | task_loss 9.196 | task_loss_gen 14.374 | contrastive_loss 0 | total 6138.43 | n_correct 2320 | ppl 28.03 | accuracy 37.795 | uer 29.65 | wer 30.231 | raw_wer 30.231 | bleu 0.09 | wps 1857.5 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 0.09
2023-09-06 02:18:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-09-06 02:18:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 02:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 02:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 0.09) (writing took 19.101495963986963 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.5288,  0.2123, -0.6753,  0.0806,  0.0916], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.5342,  0.2090, -0.9287,  ..., -0.6470, -0.1570, -0.3625],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0408,  0.2778,  0.5347,  ..., -0.0736, -0.0948,  0.1440]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5288,  0.2123, -0.6753,  0.0806,  0.0916], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-06 02:20:17 | INFO | train_inner | epoch 004:    536 / 1191 loss=2.68, trans_loss=4.181, nll_loss=2.511, w2v_ctc_loss=1.537, task_loss=1.627, task_loss_gen=4.133, contrastive_loss=0, total=6675.14, n_correct=2432.58, ppl=5.7, accuracy=36.442, wps=12611.4, ups=0.65, wpb=19342.3, bsz=669.8, num_updates=4100, lr=0.000164018, gnorm=4.485, clip=3, loss_scale=0.5, train_wall=102, gb_free=13.9, wall=3927
2023-09-06 02:22:01 | INFO | train_inner | epoch 004:    636 / 1191 loss=2.651, trans_loss=4.186, nll_loss=2.517, w2v_ctc_loss=1.508, task_loss=1.373, task_loss_gen=3.646, contrastive_loss=0, total=6814.85, n_correct=2502, ppl=5.72, accuracy=36.714, wps=19003.6, ups=0.96, wpb=19752.2, bsz=705.4, num_updates=4200, lr=0.000168016, gnorm=4.003, clip=2, loss_scale=0.5, train_wall=103, gb_free=5, wall=4030
2023-09-06 02:23:42 | INFO | train_inner | epoch 004:    736 / 1191 loss=2.632, trans_loss=4.209, nll_loss=2.544, w2v_ctc_loss=1.473, task_loss=1.45, task_loss_gen=3.751, contrastive_loss=0, total=6699.76, n_correct=2462.44, ppl=5.83, accuracy=36.754, wps=19186.9, ups=0.99, wpb=19404.7, bsz=685.5, num_updates=4300, lr=0.000172014, gnorm=4.739, clip=4, loss_scale=0.5, train_wall=101, gb_free=4.7, wall=4132
2023-09-06 02:25:25 | INFO | train_inner | epoch 004:    836 / 1191 loss=2.621, trans_loss=4.205, nll_loss=2.541, w2v_ctc_loss=1.466, task_loss=1.623, task_loss_gen=3.612, contrastive_loss=0, total=6858.76, n_correct=2534.14, ppl=5.82, accuracy=36.947, wps=19220.8, ups=0.97, wpb=19866.4, bsz=725.5, num_updates=4400, lr=0.000176012, gnorm=5.22, clip=7, loss_scale=0.5, train_wall=103, gb_free=14, wall=4235
2023-09-06 02:27:08 | INFO | train_inner | epoch 004:    936 / 1191 loss=2.611, trans_loss=4.163, nll_loss=2.487, w2v_ctc_loss=1.451, task_loss=1.629, task_loss_gen=3.541, contrastive_loss=0, total=6732.9, n_correct=2490.1, ppl=5.61, accuracy=36.984, wps=19036.6, ups=0.98, wpb=19494.6, bsz=702.9, num_updates=4500, lr=0.00018001, gnorm=5.554, clip=5, loss_scale=0.5, train_wall=102, gb_free=10.6, wall=4337
2023-09-06 02:28:51 | INFO | train_inner | epoch 004:   1036 / 1191 loss=2.638, trans_loss=4.163, nll_loss=2.488, w2v_ctc_loss=1.484, task_loss=2.044, task_loss_gen=3.947, contrastive_loss=0, total=6643.82, n_correct=2441.78, ppl=5.61, accuracy=36.753, wps=18616.2, ups=0.97, wpb=19242.6, bsz=660.8, num_updates=4600, lr=0.000184008, gnorm=6.451, clip=16, loss_scale=0.5, train_wall=103, gb_free=13.6, wall=4441
2023-09-06 02:30:33 | INFO | train_inner | epoch 004:   1136 / 1191 loss=2.609, trans_loss=4.14, nll_loss=2.462, w2v_ctc_loss=1.443, task_loss=2.481, task_loss_gen=4.263, contrastive_loss=0, total=6570.21, n_correct=2413.91, ppl=5.51, accuracy=36.74, wps=18619.3, ups=0.98, wpb=19047.6, bsz=630.5, num_updates=4700, lr=0.000188006, gnorm=6.473, clip=16, loss_scale=0.5, train_wall=102, gb_free=7.3, wall=4543
2023-09-06 02:31:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-2.3906,  0.6953, -2.7422,  0.2268,  0.4775], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.7168, -0.6748, -0.1230,  ..., -0.8296, -0.1957, -0.3242],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-3.0762,  1.9209,  1.0703,  ..., -0.2284, -0.1178,  0.2257]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.3906,  0.6953, -2.7422,  0.2268,  0.4775], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.4854,  0.2076, -0.7617,  0.0833,  0.1941], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8911,  0.0201, -0.7734,  ..., -0.7007, -0.0948, -0.3074],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0340,  0.0861,  0.3057,  ..., -0.0524, -0.1356,  0.1263]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.4854,  0.2076, -0.7617,  0.0833,  0.1941], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.4421,  0.1212, -0.5474,  0.0598,  0.1006], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6543, -0.1981, -0.8301,  ..., -0.5317, -0.2339, -0.3145],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2258,  0.2162,  0.7090,  ..., -0.0029, -0.1130,  0.1217]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.4421,  0.1212, -0.5474,  0.0598,  0.1006], device='cuda:2',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.5864,  0.0569, -0.4683,  0.0504,  0.0476], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.2100, -0.1753, -1.0479,  ..., -0.5049, -0.2585, -0.2400],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6597,  0.1205,  0.1935,  ..., -0.0883, -0.1137,  0.1422]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5864,  0.0569, -0.4683,  0.0504,  0.0476], device='cuda:3',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.7363,  0.7329, -2.7266,  0.2321,  0.5508], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-2.0215, -0.4119, -0.0682,  ..., -0.8091, -0.4429, -0.4141],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2449,  0.0909,  0.5928,  ..., -0.1858, -0.0492,  0.1995]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.7363,  0.7329, -2.7266,  0.2321,  0.5508], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-0.7578,  0.1697, -0.4973,  0.0600, -0.0742], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8774,  0.0917, -0.1871,  ..., -0.5190, -0.3176, -0.3264],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0555,  0.2472,  1.0244,  ..., -0.1166, -0.0806,  0.1254]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.7578,  0.1697, -0.4973,  0.0600, -0.0742], device='cuda:5',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([-1.9355,  0.4683, -2.4688,  0.1725,  0.4819], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.8047,  0.3477,  0.6772,  ..., -0.8960, -0.2167, -0.3987],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.9175,  0.5156,  0.3853,  ..., -0.0902, -0.0969,  0.1753]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-1.9355,  0.4683, -2.4688,  0.1725,  0.4819], device='cuda:4',
       dtype=torch.float16)
--------------------
2023-09-06 02:32:11 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.236 | trans_loss 6.997 | nll_loss 4.833 | w2v_ctc_loss 1.647 | task_loss 13.01 | task_loss_gen 12.634 | contrastive_loss 0 | total 6138.43 | n_correct 2324 | ppl 28.5 | accuracy 37.86 | uer 27.026 | wer 27.94 | raw_wer 27.94 | bleu 0.08 | wps 1281.5 | wpb 6138.4 | bsz 201.1 | num_updates 4755 | best_bleu 0.09
2023-09-06 02:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4755 updates
2023-09-06 02:32:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt
2023-09-06 02:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt
2023-09-06 02:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.0805.pt (epoch 4 @ 4755 updates, score 0.08) (writing took 8.001362738898024 seconds)
2023-09-06 02:32:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-06 02:32:19 | INFO | train | epoch 004 | loss 2.667 | trans_loss 4.191 | nll_loss 2.523 | w2v_ctc_loss 1.521 | task_loss 1.706 | task_loss_gen 3.86 | contrastive_loss 0 | total 6703.69 | n_correct 2449.01 | ppl 5.75 | accuracy 36.532 | wps 17369.9 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 4755 | lr 0.000190205 | gnorm 5.061 | clip 6.4 | loss_scale 0.5 | train_wall 1216 | gb_free 13.2 | wall 4649
2023-09-06 02:32:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:32:20 | INFO | fairseq.trainer | begin training epoch 5
2023-09-06 02:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:33:14 | INFO | train_inner | epoch 005:     45 / 1191 loss=2.584, trans_loss=4.12, nll_loss=2.437, w2v_ctc_loss=1.428, task_loss=1.747, task_loss_gen=3.205, contrastive_loss=0, total=6770.61, n_correct=2541.14, ppl=5.41, accuracy=37.532, wps=12237.9, ups=0.62, wpb=19623.2, bsz=716.6, num_updates=4800, lr=0.000192004, gnorm=5.242, clip=5, loss_scale=0.5, train_wall=102, gb_free=12.3, wall=4703
2023-09-06 02:34:56 | INFO | train_inner | epoch 005:    145 / 1191 loss=2.581, trans_loss=4.133, nll_loss=2.452, w2v_ctc_loss=1.412, task_loss=1.741, task_loss_gen=3.553, contrastive_loss=0, total=6699.77, n_correct=2494.77, ppl=5.47, accuracy=37.237, wps=18906.1, ups=0.97, wpb=19409.6, bsz=671.7, num_updates=4900, lr=0.000196002, gnorm=5.576, clip=8, loss_scale=0.5, train_wall=102, gb_free=5.9, wall=4806
2023-09-06 02:36:38 | INFO | train_inner | epoch 005:    245 / 1191 loss=2.557, trans_loss=4.114, nll_loss=2.429, w2v_ctc_loss=1.39, task_loss=1.734, task_loss_gen=3.263, contrastive_loss=0, total=6859.5, n_correct=2582.27, ppl=5.38, accuracy=37.645, wps=19473.5, ups=0.98, wpb=19870.2, bsz=728.4, num_updates=5000, lr=0.0002, gnorm=4.648, clip=1, loss_scale=0.5, train_wall=101, gb_free=12.6, wall=4908
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:0')
2023-09-06 02:38:20 | INFO | train_inner | epoch 005:    345 / 1191 loss=2.558, trans_loss=4.105, nll_loss=2.418, w2v_ctc_loss=1.389, task_loss=3.392, task_loss_gen=4.312, contrastive_loss=0, total=6631.13, n_correct=2494.96, ppl=5.35, accuracy=37.625, wps=18863.4, ups=0.98, wpb=19212.5, bsz=667.2, num_updates=5100, lr=0.00019803, gnorm=8.971, clip=31, loss_scale=0.5, train_wall=101, gb_free=13.8, wall=5010
2023-09-06 02:40:03 | INFO | train_inner | epoch 005:    445 / 1191 loss=2.563, trans_loss=4.081, nll_loss=2.39, w2v_ctc_loss=1.401, task_loss=3.23, task_loss_gen=3.89, contrastive_loss=0, total=6691.68, n_correct=2520.19, ppl=5.24, accuracy=37.662, wps=18867.5, ups=0.97, wpb=19399.7, bsz=680, num_updates=5200, lr=0.000196116, gnorm=5.936, clip=16, loss_scale=1, train_wall=102, gb_free=14, wall=5113
2023-09-06 02:41:47 | INFO | train_inner | epoch 005:    545 / 1191 loss=2.534, trans_loss=4.065, nll_loss=2.369, w2v_ctc_loss=1.359, task_loss=2.9, task_loss_gen=3.805, contrastive_loss=0, total=6658.28, n_correct=2516.89, ppl=5.17, accuracy=37.801, wps=18592.4, ups=0.96, wpb=19286.8, bsz=671.1, num_updates=5300, lr=0.000194257, gnorm=4.207, clip=1, loss_scale=1, train_wall=103, gb_free=13.1, wall=5217
2023-09-06 02:43:28 | INFO | train_inner | epoch 005:    645 / 1191 loss=2.544, trans_loss=4.063, nll_loss=2.365, w2v_ctc_loss=1.368, task_loss=2.813, task_loss_gen=3.865, contrastive_loss=0, total=6704.06, n_correct=2536.14, ppl=5.15, accuracy=37.83, wps=19132, ups=0.99, wpb=19409.9, bsz=666.1, num_updates=5400, lr=0.00019245, gnorm=3.572, clip=1, loss_scale=1, train_wall=101, gb_free=12.6, wall=5318
2023-09-06 02:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 02:45:13 | INFO | train_inner | epoch 005:    746 / 1191 loss=2.521, trans_loss=4.06, nll_loss=2.364, w2v_ctc_loss=1.344, task_loss=2.325, task_loss_gen=3.653, contrastive_loss=0, total=6728.31, n_correct=2553.76, ppl=5.15, accuracy=37.955, wps=18666.2, ups=0.96, wpb=19503.3, bsz=690.7, num_updates=5500, lr=0.000190693, gnorm=5.595, clip=7, loss_scale=0.5, train_wall=104, gb_free=14.4, wall=5422
2023-09-06 02:46:55 | INFO | train_inner | epoch 005:    846 / 1191 loss=2.529, trans_loss=4.069, nll_loss=2.372, w2v_ctc_loss=1.353, task_loss=2.1, task_loss_gen=3.197, contrastive_loss=0, total=6763.5, n_correct=2553.31, ppl=5.18, accuracy=37.751, wps=19145.1, ups=0.98, wpb=19589.8, bsz=684.5, num_updates=5600, lr=0.000188982, gnorm=5.862, clip=7, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=5525
2023-09-06 02:48:38 | INFO | train_inner | epoch 005:    946 / 1191 loss=2.517, trans_loss=4.078, nll_loss=2.386, w2v_ctc_loss=1.334, task_loss=2.579, task_loss_gen=3.578, contrastive_loss=0, total=6600.15, n_correct=2495.63, ppl=5.23, accuracy=37.812, wps=18643.5, ups=0.97, wpb=19125.2, bsz=657.6, num_updates=5700, lr=0.000187317, gnorm=6.761, clip=14, loss_scale=0.5, train_wall=102, gb_free=13.9, wall=5627
2023-09-06 02:50:20 | INFO | train_inner | epoch 005:   1046 / 1191 loss=2.546, trans_loss=4.064, nll_loss=2.368, w2v_ctc_loss=1.373, task_loss=2.834, task_loss_gen=3.698, contrastive_loss=0, total=6646.83, n_correct=2506.98, ppl=5.16, accuracy=37.717, wps=18733.2, ups=0.97, wpb=19258.1, bsz=646.9, num_updates=5800, lr=0.000185695, gnorm=6.221, clip=10, loss_scale=0.5, train_wall=102, gb_free=13.1, wall=5730
2023-09-06 02:52:03 | INFO | train_inner | epoch 005:   1146 / 1191 loss=2.522, trans_loss=4.053, nll_loss=2.354, w2v_ctc_loss=1.346, task_loss=2.389, task_loss_gen=3.367, contrastive_loss=0, total=6691.45, n_correct=2540.57, ppl=5.11, accuracy=37.967, wps=18960.9, ups=0.98, wpb=19389, bsz=668.7, num_updates=5900, lr=0.000184115, gnorm=5.5, clip=2, loss_scale=0.5, train_wall=102, gb_free=13, wall=5832
2023-09-06 02:52:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.3993, device='cuda:2')
2023-09-06 02:53:24 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.135 | trans_loss 6.883 | nll_loss 4.686 | w2v_ctc_loss 1.568 | task_loss 24.442 | task_loss_gen 15.327 | contrastive_loss 0 | total 6138.43 | n_correct 2396.14 | ppl 25.74 | accuracy 39.035 | uer 25.994 | wer 27.084 | raw_wer 27.084 | bleu 0.15 | wps 1616.7 | wpb 6138.4 | bsz 201.1 | num_updates 5945 | best_bleu 0.15
2023-09-06 02:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5945 updates
2023-09-06 02:53:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 02:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 5 @ 5945 updates, score 0.15) (writing took 11.962950768065639 seconds)
2023-09-06 02:53:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-06 02:53:36 | INFO | train | epoch 005 | loss 2.542 | trans_loss 4.081 | nll_loss 2.388 | w2v_ctc_loss 1.369 | task_loss 2.507 | task_loss_gen 3.616 | contrastive_loss 0 | total 6703.59 | n_correct 2529.56 | ppl 5.24 | accuracy 37.734 | wps 18111 | ups 0.93 | wpb 19422.5 | bsz 678.2 | num_updates 5945 | lr 0.000183417 | gnorm 5.736 | clip 8.7 | loss_scale 0.5 | train_wall 1214 | gb_free 11.1 | wall 5925
2023-09-06 02:53:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 02:53:36 | INFO | fairseq.trainer | begin training epoch 6
2023-09-06 02:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 02:54:39 | INFO | train_inner | epoch 006:     55 / 1191 loss=2.5, trans_loss=4.042, nll_loss=2.339, w2v_ctc_loss=1.317, task_loss=2.395, task_loss_gen=3.322, contrastive_loss=0, total=6655.75, n_correct=2542.7, ppl=5.06, accuracy=38.203, wps=12334.1, ups=0.64, wpb=19286.4, bsz=662.9, num_updates=6000, lr=0.000182574, gnorm=5.35, clip=2, loss_scale=0.5, train_wall=101, gb_free=11.4, wall=5989
2023-09-06 02:54:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 02:55:13 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.139 | trans_loss 6.89 | nll_loss 4.694 | w2v_ctc_loss 1.563 | task_loss 19.681 | task_loss_gen 13.484 | contrastive_loss 0 | total 6138.43 | n_correct 2397.43 | ppl 25.89 | accuracy 39.056 | uer 25.991 | wer 27.125 | raw_wer 27.125 | bleu 0.2 | wps 1618 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 0.2
2023-09-06 02:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-09-06 02:55:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 02:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 02:55:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 0.2) (writing took 12.977749353041872 seconds)
2023-09-06 02:57:09 | INFO | train_inner | epoch 006:    155 / 1191 loss=2.481, trans_loss=4.041, nll_loss=2.336, w2v_ctc_loss=1.288, task_loss=2.382, task_loss_gen=3.293, contrastive_loss=0, total=6716.94, n_correct=2567.44, ppl=5.05, accuracy=38.223, wps=12925, ups=0.66, wpb=19447.8, bsz=676.1, num_updates=6100, lr=0.000181071, gnorm=5.318, clip=3, loss_scale=0.5, train_wall=102, gb_free=14.6, wall=6139
2023-09-06 02:58:52 | INFO | train_inner | epoch 006:    255 / 1191 loss=2.473, trans_loss=4.026, nll_loss=2.32, w2v_ctc_loss=1.286, task_loss=2.135, task_loss_gen=3.003, contrastive_loss=0, total=6862.39, n_correct=2636.6, ppl=4.99, accuracy=38.421, wps=19429.8, ups=0.98, wpb=19881.1, bsz=725.7, num_updates=6200, lr=0.000179605, gnorm=4.648, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.7, wall=6242
2023-09-06 03:00:36 | INFO | train_inner | epoch 006:    355 / 1191 loss=2.491, trans_loss=4.028, nll_loss=2.322, w2v_ctc_loss=1.305, task_loss=2.162, task_loss_gen=3.161, contrastive_loss=0, total=6708.81, n_correct=2572.84, ppl=5, accuracy=38.35, wps=18675.5, ups=0.96, wpb=19428.8, bsz=668.5, num_updates=6300, lr=0.000178174, gnorm=3.546, clip=0, loss_scale=0.5, train_wall=103, gb_free=11.2, wall=6346
2023-09-06 03:02:18 | INFO | train_inner | epoch 006:    455 / 1191 loss=2.485, trans_loss=4.039, nll_loss=2.336, w2v_ctc_loss=1.296, task_loss=2.117, task_loss_gen=3.288, contrastive_loss=0, total=6579.59, n_correct=2512.38, ppl=5.05, accuracy=38.184, wps=18621.8, ups=0.98, wpb=19065.8, bsz=655.4, num_updates=6400, lr=0.000176777, gnorm=4.221, clip=0, loss_scale=0.5, train_wall=102, gb_free=13.1, wall=6448
2023-09-06 03:04:01 | INFO | train_inner | epoch 006:    555 / 1191 loss=2.478, trans_loss=4.03, nll_loss=2.326, w2v_ctc_loss=1.294, task_loss=2.75, task_loss_gen=3.444, contrastive_loss=0, total=6695.79, n_correct=2564.62, ppl=5.02, accuracy=38.302, wps=18827.5, ups=0.97, wpb=19413.8, bsz=661.9, num_updates=6500, lr=0.000175412, gnorm=5.214, clip=6, loss_scale=0.5, train_wall=102, gb_free=13.8, wall=6551
2023-09-06 03:05:44 | INFO | train_inner | epoch 006:    655 / 1191 loss=2.483, trans_loss=4.021, nll_loss=2.313, w2v_ctc_loss=1.295, task_loss=2.554, task_loss_gen=3.216, contrastive_loss=0, total=6691.12, n_correct=2567.64, ppl=4.97, accuracy=38.374, wps=18846.2, ups=0.97, wpb=19377.3, bsz=661.5, num_updates=6600, lr=0.000174078, gnorm=4.547, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=6654
2023-09-06 03:07:27 | INFO | train_inner | epoch 006:    755 / 1191 loss=2.491, trans_loss=4.009, nll_loss=2.298, w2v_ctc_loss=1.319, task_loss=2.144, task_loss_gen=2.935, contrastive_loss=0, total=6834.57, n_correct=2637.79, ppl=4.92, accuracy=38.595, wps=19318.3, ups=0.98, wpb=19800.8, bsz=719.4, num_updates=6700, lr=0.000172774, gnorm=4.074, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.8, wall=6756
2023-09-06 03:09:10 | INFO | train_inner | epoch 006:    855 / 1191 loss=2.492, trans_loss=4.006, nll_loss=2.298, w2v_ctc_loss=1.318, task_loss=2.113, task_loss_gen=3.084, contrastive_loss=0, total=6618.09, n_correct=2542.74, ppl=4.92, accuracy=38.421, wps=18618.3, ups=0.97, wpb=19191.3, bsz=678.6, num_updates=6800, lr=0.000171499, gnorm=3.648, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.3, wall=6860
2023-09-06 03:10:54 | INFO | train_inner | epoch 006:    955 / 1191 loss=2.51, trans_loss=4.016, nll_loss=2.307, w2v_ctc_loss=1.336, task_loss=2.485, task_loss_gen=3.356, contrastive_loss=0, total=6622.17, n_correct=2542.14, ppl=4.95, accuracy=38.388, wps=18467.5, ups=0.96, wpb=19185.1, bsz=637.5, num_updates=6900, lr=0.000170251, gnorm=3.863, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.8, wall=6963
2023-09-06 03:12:36 | INFO | train_inner | epoch 006:   1055 / 1191 loss=2.466, trans_loss=4.005, nll_loss=2.295, w2v_ctc_loss=1.278, task_loss=2.14, task_loss_gen=3.135, contrastive_loss=0, total=6674.98, n_correct=2577.24, ppl=4.91, accuracy=38.61, wps=18917.8, ups=0.98, wpb=19341.4, bsz=667.2, num_updates=7000, lr=0.000169031, gnorm=3.333, clip=0, loss_scale=0.5, train_wall=102, gb_free=13.5, wall=7066
2023-09-06 03:14:17 | INFO | train_inner | epoch 006:   1155 / 1191 loss=2.485, trans_loss=4.004, nll_loss=2.295, w2v_ctc_loss=1.308, task_loss=2.015, task_loss_gen=2.807, contrastive_loss=0, total=6754.15, n_correct=2600.71, ppl=4.91, accuracy=38.505, wps=19422.6, ups=0.99, wpb=19579.8, bsz=709.1, num_updates=7100, lr=0.000167836, gnorm=3.622, clip=3, loss_scale=0.5, train_wall=100, gb_free=13.3, wall=7167
2023-09-06 03:14:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:15:26 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.075 | trans_loss 6.854 | nll_loss 4.65 | w2v_ctc_loss 1.433 | task_loss 25.526 | task_loss_gen 15.184 | contrastive_loss 0 | total 6138.43 | n_correct 2415.86 | ppl 25.11 | accuracy 39.356 | uer 24.267 | wer 25.575 | raw_wer 25.575 | bleu 0.13 | wps 1738.5 | wpb 6138.4 | bsz 201.1 | num_updates 7136 | best_bleu 0.2
2023-09-06 03:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7136 updates
2023-09-06 03:15:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 03:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 03:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt (epoch 6 @ 7136 updates, score 0.13) (writing took 7.225076515926048 seconds)
2023-09-06 03:15:34 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-06 03:15:34 | INFO | train | epoch 006 | loss 2.485 | trans_loss 4.021 | nll_loss 2.313 | w2v_ctc_loss 1.302 | task_loss 2.26 | task_loss_gen 3.142 | contrastive_loss 0 | total 6703.69 | n_correct 2574.4 | ppl 4.97 | accuracy 38.403 | wps 17548.4 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 7136 | lr 0.000167412 | gnorm 4.163 | clip 1.3 | loss_scale 0.5 | train_wall 1215 | gb_free 13.5 | wall 7244
2023-09-06 03:15:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:15:34 | INFO | fairseq.trainer | begin training epoch 7
2023-09-06 03:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 03:16:48 | INFO | train_inner | epoch 007:     64 / 1191 loss=2.456, trans_loss=3.999, nll_loss=2.284, w2v_ctc_loss=1.265, task_loss=1.95, task_loss_gen=2.942, contrastive_loss=0, total=6722.13, n_correct=2602.2, ppl=4.87, accuracy=38.711, wps=12859.7, ups=0.66, wpb=19459.1, bsz=690, num_updates=7200, lr=0.000166667, gnorm=2.716, clip=0, loss_scale=0.5, train_wall=101, gb_free=14.4, wall=7318
2023-09-06 03:18:31 | INFO | train_inner | epoch 007:    164 / 1191 loss=2.446, trans_loss=3.99, nll_loss=2.278, w2v_ctc_loss=1.257, task_loss=2.206, task_loss_gen=3.099, contrastive_loss=0, total=6674.7, n_correct=2582.54, ppl=4.85, accuracy=38.691, wps=18782, ups=0.97, wpb=19358.1, bsz=674.9, num_updates=7300, lr=0.000165521, gnorm=3.186, clip=0, loss_scale=0.5, train_wall=103, gb_free=13.3, wall=7421
2023-09-06 03:20:14 | INFO | train_inner | epoch 007:    264 / 1191 loss=2.45, trans_loss=3.989, nll_loss=2.275, w2v_ctc_loss=1.257, task_loss=1.971, task_loss_gen=3.077, contrastive_loss=0, total=6691.93, n_correct=2593.05, ppl=4.84, accuracy=38.749, wps=18813, ups=0.97, wpb=19392.2, bsz=675.1, num_updates=7400, lr=0.000164399, gnorm=2.815, clip=0, loss_scale=0.5, train_wall=103, gb_free=13.7, wall=7524
2023-09-06 03:21:55 | INFO | train_inner | epoch 007:    364 / 1191 loss=2.44, trans_loss=3.982, nll_loss=2.266, w2v_ctc_loss=1.25, task_loss=2.043, task_loss_gen=2.868, contrastive_loss=0, total=6730.79, n_correct=2624.67, ppl=4.81, accuracy=38.995, wps=19334.7, ups=0.99, wpb=19508.1, bsz=689.9, num_updates=7500, lr=0.000163299, gnorm=2.952, clip=1, loss_scale=1, train_wall=100, gb_free=12.4, wall=7625
2023-09-06 03:23:36 | INFO | train_inner | epoch 007:    464 / 1191 loss=2.41, trans_loss=3.982, nll_loss=2.266, w2v_ctc_loss=1.207, task_loss=2.032, task_loss_gen=2.795, contrastive_loss=0, total=6783.66, n_correct=2639.59, ppl=4.81, accuracy=38.911, wps=19381.1, ups=0.99, wpb=19655.7, bsz=707.6, num_updates=7600, lr=0.000162221, gnorm=1.508, clip=0, loss_scale=1, train_wall=101, gb_free=14.4, wall=7726
2023-09-06 03:25:19 | INFO | train_inner | epoch 007:    564 / 1191 loss=2.426, trans_loss=3.981, nll_loss=2.264, w2v_ctc_loss=1.223, task_loss=2.106, task_loss_gen=3.036, contrastive_loss=0, total=6712.4, n_correct=2608.58, ppl=4.8, accuracy=38.862, wps=18885.4, ups=0.97, wpb=19445.4, bsz=675.5, num_updates=7700, lr=0.000161165, gnorm=1.422, clip=0, loss_scale=1, train_wall=102, gb_free=14.3, wall=7829
2023-09-06 03:27:03 | INFO | train_inner | epoch 007:    664 / 1191 loss=2.415, trans_loss=3.98, nll_loss=2.263, w2v_ctc_loss=1.211, task_loss=2.058, task_loss_gen=2.93, contrastive_loss=0, total=6762.84, n_correct=2634.68, ppl=4.8, accuracy=38.958, wps=18952.9, ups=0.97, wpb=19590.9, bsz=694.5, num_updates=7800, lr=0.000160128, gnorm=1.572, clip=0, loss_scale=1, train_wall=103, gb_free=11.1, wall=7933
2023-09-06 03:28:45 | INFO | train_inner | epoch 007:    764 / 1191 loss=2.415, trans_loss=3.979, nll_loss=2.26, w2v_ctc_loss=1.207, task_loss=2.118, task_loss_gen=3.03, contrastive_loss=0, total=6663.7, n_correct=2592.36, ppl=4.79, accuracy=38.903, wps=18876.5, ups=0.98, wpb=19298.6, bsz=664.1, num_updates=7900, lr=0.000159111, gnorm=1.256, clip=0, loss_scale=1, train_wall=102, gb_free=13.7, wall=8035
2023-09-06 03:29:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 03:30:30 | INFO | train_inner | epoch 007:    865 / 1191 loss=2.447, trans_loss=3.981, nll_loss=2.265, w2v_ctc_loss=1.254, task_loss=2.144, task_loss_gen=3.166, contrastive_loss=0, total=6642.22, n_correct=2573.79, ppl=4.81, accuracy=38.749, wps=18343, ups=0.95, wpb=19242.7, bsz=654.8, num_updates=8000, lr=0.000158114, gnorm=2.499, clip=1, loss_scale=0.5, train_wall=104, gb_free=12.3, wall=8140
2023-09-06 03:30:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:31:03 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.069 | trans_loss 6.836 | nll_loss 4.63 | w2v_ctc_loss 1.453 | task_loss 13.897 | task_loss_gen 12.034 | contrastive_loss 0 | total 6138.43 | n_correct 2435.57 | ppl 24.75 | accuracy 39.677 | uer 23.86 | wer 25.073 | raw_wer 25.073 | bleu 0.19 | wps 1704.5 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 0.2
2023-09-06 03:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-09-06 03:31:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 03:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 03:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 0.19) (writing took 9.393209382891655 seconds)
2023-09-06 03:32:55 | INFO | train_inner | epoch 007:    965 / 1191 loss=2.439, trans_loss=3.976, nll_loss=2.258, w2v_ctc_loss=1.243, task_loss=2.097, task_loss_gen=3.048, contrastive_loss=0, total=6662.44, n_correct=2586.42, ppl=4.78, accuracy=38.821, wps=13267.5, ups=0.69, wpb=19297.8, bsz=651.1, num_updates=8100, lr=0.000157135, gnorm=2.211, clip=0, loss_scale=0.5, train_wall=102, gb_free=14.5, wall=8285
2023-09-06 03:34:38 | INFO | train_inner | epoch 007:   1065 / 1191 loss=2.44, trans_loss=3.973, nll_loss=2.253, w2v_ctc_loss=1.255, task_loss=2.182, task_loss_gen=3.01, contrastive_loss=0, total=6680.36, n_correct=2613.71, ppl=4.77, accuracy=39.125, wps=18890.6, ups=0.98, wpb=19342.7, bsz=695.6, num_updates=8200, lr=0.000156174, gnorm=2.73, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.9, wall=8388
2023-09-06 03:36:20 | INFO | train_inner | epoch 007:   1165 / 1191 loss=2.431, trans_loss=3.974, nll_loss=2.257, w2v_ctc_loss=1.238, task_loss=2.263, task_loss_gen=3.033, contrastive_loss=0, total=6716.49, n_correct=2615.02, ppl=4.78, accuracy=38.934, wps=18977.5, ups=0.97, wpb=19469.2, bsz=674, num_updates=8300, lr=0.00015523, gnorm=2.856, clip=1, loss_scale=0.5, train_wall=102, gb_free=13.2, wall=8490
2023-09-06 03:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:37:20 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.05 | trans_loss 6.831 | nll_loss 4.621 | w2v_ctc_loss 1.4 | task_loss 22.049 | task_loss_gen 13.945 | contrastive_loss 0 | total 6138.43 | n_correct 2431.71 | ppl 24.61 | accuracy 39.615 | uer 23.606 | wer 25.084 | raw_wer 25.084 | bleu 0.11 | wps 1724.5 | wpb 6138.4 | bsz 201.1 | num_updates 8326 | best_bleu 0.2
2023-09-06 03:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8326 updates
2023-09-06 03:37:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt
2023-09-06 03:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt
2023-09-06 03:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1106.pt (epoch 7 @ 8326 updates, score 0.11) (writing took 10.33597502799239 seconds)
2023-09-06 03:37:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-06 03:37:30 | INFO | train | epoch 007 | loss 2.433 | trans_loss 3.981 | nll_loss 2.265 | w2v_ctc_loss 1.236 | task_loss 2.101 | task_loss_gen 3.006 | contrastive_loss 0 | total 6704.01 | n_correct 2606.23 | ppl 4.81 | accuracy 38.876 | wps 17558.5 | ups 0.9 | wpb 19423.6 | bsz 678.4 | num_updates 8326 | lr 0.000154988 | gnorm 2.307 | clip 0.3 | loss_scale 0.5 | train_wall 1215 | gb_free 12.7 | wall 8560
2023-09-06 03:37:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:37:30 | INFO | fairseq.trainer | begin training epoch 8
2023-09-06 03:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 03:38:53 | INFO | train_inner | epoch 008:     74 / 1191 loss=2.386, trans_loss=3.968, nll_loss=2.246, w2v_ctc_loss=1.166, task_loss=2.284, task_loss_gen=2.929, contrastive_loss=0, total=6735.91, n_correct=2633.21, ppl=4.74, accuracy=39.092, wps=12745.4, ups=0.65, wpb=19506.1, bsz=674.3, num_updates=8400, lr=0.000154303, gnorm=2.513, clip=0, loss_scale=0.5, train_wall=101, gb_free=12.7, wall=8643
2023-09-06 03:40:36 | INFO | train_inner | epoch 008:    174 / 1191 loss=2.371, trans_loss=3.948, nll_loss=2.225, w2v_ctc_loss=1.161, task_loss=2.26, task_loss_gen=2.833, contrastive_loss=0, total=6733.69, n_correct=2654.55, ppl=4.68, accuracy=39.422, wps=19005.2, ups=0.97, wpb=19530.2, bsz=709.9, num_updates=8500, lr=0.000153393, gnorm=2.238, clip=0, loss_scale=0.5, train_wall=102, gb_free=10.2, wall=8746
2023-09-06 03:42:20 | INFO | train_inner | epoch 008:    274 / 1191 loss=2.388, trans_loss=3.959, nll_loss=2.236, w2v_ctc_loss=1.178, task_loss=2.184, task_loss_gen=2.9, contrastive_loss=0, total=6723.6, n_correct=2638.84, ppl=4.71, accuracy=39.247, wps=18814.5, ups=0.97, wpb=19475.4, bsz=686.2, num_updates=8600, lr=0.000152499, gnorm=2.328, clip=0, loss_scale=0.5, train_wall=103, gb_free=12.7, wall=8850
2023-09-06 03:42:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 03:44:05 | INFO | train_inner | epoch 008:    375 / 1191 loss=2.448, trans_loss=3.963, nll_loss=2.243, w2v_ctc_loss=1.265, task_loss=2.39, task_loss_gen=3.075, contrastive_loss=0, total=6673.62, n_correct=2597.77, ppl=4.74, accuracy=38.926, wps=18395.7, ups=0.95, wpb=19350.5, bsz=653.2, num_updates=8700, lr=0.00015162, gnorm=3.385, clip=2, loss_scale=0.25, train_wall=105, gb_free=14, wall=8955
2023-09-06 03:45:48 | INFO | train_inner | epoch 008:    475 / 1191 loss=2.424, trans_loss=3.959, nll_loss=2.238, w2v_ctc_loss=1.228, task_loss=2.547, task_loss_gen=3.174, contrastive_loss=0, total=6653.57, n_correct=2598.79, ppl=4.72, accuracy=39.059, wps=18781.4, ups=0.97, wpb=19281.2, bsz=656.8, num_updates=8800, lr=0.000150756, gnorm=4.211, clip=4, loss_scale=0.25, train_wall=102, gb_free=10.1, wall=9057
2023-09-06 03:47:30 | INFO | train_inner | epoch 008:    575 / 1191 loss=2.447, trans_loss=3.963, nll_loss=2.242, w2v_ctc_loss=1.267, task_loss=2.267, task_loss_gen=2.98, contrastive_loss=0, total=6681.08, n_correct=2611.53, ppl=4.73, accuracy=39.088, wps=18978.9, ups=0.98, wpb=19359.5, bsz=671, num_updates=8900, lr=0.000149906, gnorm=4.51, clip=4, loss_scale=0.25, train_wall=101, gb_free=13.3, wall=9159
2023-09-06 03:49:11 | INFO | train_inner | epoch 008:    675 / 1191 loss=2.505, trans_loss=3.968, nll_loss=2.247, w2v_ctc_loss=1.351, task_loss=2.07, task_loss_gen=2.888, contrastive_loss=0, total=6718.74, n_correct=2620.39, ppl=4.75, accuracy=39.001, wps=19201.1, ups=0.99, wpb=19462.4, bsz=676, num_updates=9000, lr=0.000149071, gnorm=4.027, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.3, wall=9261
2023-09-06 03:50:54 | INFO | train_inner | epoch 008:    775 / 1191 loss=2.547, trans_loss=3.961, nll_loss=2.24, w2v_ctc_loss=1.421, task_loss=2.078, task_loss_gen=2.902, contrastive_loss=0, total=6698, n_correct=2614.38, ppl=4.72, accuracy=39.032, wps=18872.5, ups=0.97, wpb=19410.7, bsz=673.3, num_updates=9100, lr=0.00014825, gnorm=4.061, clip=3, loss_scale=0.25, train_wall=102, gb_free=10.5, wall=9364
2023-09-06 03:52:36 | INFO | train_inner | epoch 008:    875 / 1191 loss=2.525, trans_loss=3.958, nll_loss=2.236, w2v_ctc_loss=1.39, task_loss=1.94, task_loss_gen=2.654, contrastive_loss=0, total=6791.96, n_correct=2657.72, ppl=4.71, accuracy=39.13, wps=19321.3, ups=0.98, wpb=19682.7, bsz=706.1, num_updates=9200, lr=0.000147442, gnorm=4.034, clip=5, loss_scale=0.25, train_wall=101, gb_free=14.5, wall=9466
2023-09-06 03:54:18 | INFO | train_inner | epoch 008:    975 / 1191 loss=2.612, trans_loss=3.966, nll_loss=2.244, w2v_ctc_loss=1.516, task_loss=2.179, task_loss_gen=3.022, contrastive_loss=0, total=6642.41, n_correct=2590.86, ppl=4.74, accuracy=39.005, wps=18790.7, ups=0.98, wpb=19234, bsz=659.5, num_updates=9300, lr=0.000146647, gnorm=5.401, clip=8, loss_scale=0.25, train_wall=102, gb_free=14.5, wall=9568
2023-09-06 03:56:00 | INFO | train_inner | epoch 008:   1075 / 1191 loss=2.56, trans_loss=3.963, nll_loss=2.238, w2v_ctc_loss=1.436, task_loss=2.187, task_loss_gen=2.9, contrastive_loss=0, total=6715.11, n_correct=2631.24, ppl=4.72, accuracy=39.184, wps=19062.3, ups=0.98, wpb=19429.4, bsz=669.3, num_updates=9400, lr=0.000145865, gnorm=3.914, clip=4, loss_scale=0.25, train_wall=101, gb_free=12.1, wall=9670
2023-09-06 03:57:41 | INFO | train_inner | epoch 008:   1175 / 1191 loss=2.595, trans_loss=3.951, nll_loss=2.227, w2v_ctc_loss=1.504, task_loss=1.855, task_loss_gen=2.736, contrastive_loss=0, total=6699.8, n_correct=2635.56, ppl=4.68, accuracy=39.338, wps=19165, ups=0.99, wpb=19416.9, bsz=710.5, num_updates=9500, lr=0.000145095, gnorm=3.964, clip=5, loss_scale=0.25, train_wall=101, gb_free=12.5, wall=9771
2023-09-06 03:57:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 03:58:34 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 5.097 | trans_loss 6.825 | nll_loss 4.614 | w2v_ctc_loss 1.57 | task_loss 10.224 | task_loss_gen 11.759 | contrastive_loss 0 | total 6138.43 | n_correct 2439.29 | ppl 24.49 | accuracy 39.738 | uer 26.406 | wer 27.772 | raw_wer 27.772 | bleu 0.25 | wps 1488.2 | wpb 6138.4 | bsz 201.1 | num_updates 9516 | best_bleu 0.25
2023-09-06 03:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9516 updates
2023-09-06 03:58:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 03:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 03:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 8 @ 9516 updates, score 0.25) (writing took 14.169435539050028 seconds)
2023-09-06 03:58:48 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-06 03:58:48 | INFO | train | epoch 008 | loss 2.486 | trans_loss 3.96 | nll_loss 2.238 | w2v_ctc_loss 1.328 | task_loss 2.183 | task_loss_gen 2.913 | contrastive_loss 0 | total 6703.53 | n_correct 2623.17 | ppl 4.72 | accuracy 39.131 | wps 18086.5 | ups 0.93 | wpb 19422.3 | bsz 678.3 | num_updates 9516 | lr 0.000144973 | gnorm 3.735 | clip 3.2 | loss_scale 0.25 | train_wall 1212 | gb_free 14 | wall 9838
2023-09-06 03:58:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 03:58:48 | INFO | fairseq.trainer | begin training epoch 9
2023-09-06 03:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:00:21 | INFO | train_inner | epoch 009:     84 / 1191 loss=2.557, trans_loss=3.948, nll_loss=2.222, w2v_ctc_loss=1.442, task_loss=2.072, task_loss_gen=2.803, contrastive_loss=0, total=6707.41, n_correct=2639.53, ppl=4.67, accuracy=39.352, wps=12182.5, ups=0.63, wpb=19430.9, bsz=685.6, num_updates=9600, lr=0.000144338, gnorm=3.571, clip=2, loss_scale=0.25, train_wall=101, gb_free=12.7, wall=9931
2023-09-06 04:02:03 | INFO | train_inner | epoch 009:    184 / 1191 loss=2.529, trans_loss=3.943, nll_loss=2.218, w2v_ctc_loss=1.402, task_loss=2.472, task_loss_gen=3.2, contrastive_loss=0, total=6743.4, n_correct=2654.12, ppl=4.65, accuracy=39.359, wps=19087.1, ups=0.98, wpb=19547.1, bsz=682.2, num_updates=9700, lr=0.000143592, gnorm=7.979, clip=33, loss_scale=0.25, train_wall=102, gb_free=12.3, wall=10033
2023-09-06 04:03:45 | INFO | train_inner | epoch 009:    284 / 1191 loss=2.489, trans_loss=3.954, nll_loss=2.227, w2v_ctc_loss=1.341, task_loss=2.251, task_loss_gen=2.92, contrastive_loss=0, total=6831.36, n_correct=2689.6, ppl=4.68, accuracy=39.371, wps=19462.7, ups=0.98, wpb=19775.9, bsz=716.2, num_updates=9800, lr=0.000142857, gnorm=7.074, clip=14, loss_scale=0.25, train_wall=101, gb_free=12.8, wall=10135
2023-09-06 04:05:28 | INFO | train_inner | epoch 009:    384 / 1191 loss=2.467, trans_loss=3.951, nll_loss=2.227, w2v_ctc_loss=1.307, task_loss=2.374, task_loss_gen=2.958, contrastive_loss=0, total=6733.92, n_correct=2643.82, ppl=4.68, accuracy=39.261, wps=18829.6, ups=0.96, wpb=19513.2, bsz=681.5, num_updates=9900, lr=0.000142134, gnorm=5.122, clip=12, loss_scale=0.25, train_wall=103, gb_free=10.2, wall=10238
2023-09-06 04:07:12 | INFO | train_inner | epoch 009:    484 / 1191 loss=2.459, trans_loss=3.946, nll_loss=2.221, w2v_ctc_loss=1.292, task_loss=2.271, task_loss_gen=2.762, contrastive_loss=0, total=6750.99, n_correct=2666.34, ppl=4.66, accuracy=39.496, wps=18850.8, ups=0.96, wpb=19565.9, bsz=700, num_updates=10000, lr=0.000141421, gnorm=3.055, clip=0, loss_scale=0.25, train_wall=103, gb_free=13, wall=10342
2023-09-06 04:07:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:07:46 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.083 | trans_loss 6.814 | nll_loss 4.601 | w2v_ctc_loss 1.548 | task_loss 17.255 | task_loss_gen 12.749 | contrastive_loss 0 | total 6138.43 | n_correct 2446.43 | ppl 24.27 | accuracy 39.854 | uer 24.51 | wer 25.872 | raw_wer 25.872 | bleu 0.15 | wps 1690.6 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 0.25
2023-09-06 04:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-09-06 04:07:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 04:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 04:07:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 0.15) (writing took 10.600317260017619 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 04:09:38 | INFO | train_inner | epoch 009:    584 / 1191 loss=2.481, trans_loss=3.944, nll_loss=2.217, w2v_ctc_loss=1.327, task_loss=2.4, task_loss_gen=2.924, contrastive_loss=0, total=6599.16, n_correct=2601.45, ppl=4.65, accuracy=39.421, wps=13110, ups=0.69, wpb=19115.2, bsz=657.7, num_updates=10100, lr=0.00014072, gnorm=3.015, clip=1, loss_scale=0.25, train_wall=101, gb_free=13.6, wall=10488
2023-09-06 04:11:20 | INFO | train_inner | epoch 009:    684 / 1191 loss=2.459, trans_loss=3.95, nll_loss=2.225, w2v_ctc_loss=1.287, task_loss=2.537, task_loss_gen=3.132, contrastive_loss=0, total=6559.67, n_correct=2583.05, ppl=4.67, accuracy=39.378, wps=18585.3, ups=0.98, wpb=18998.9, bsz=622.4, num_updates=10200, lr=0.000140028, gnorm=2.884, clip=0, loss_scale=0.25, train_wall=102, gb_free=11.9, wall=10590
2023-09-06 04:13:02 | INFO | train_inner | epoch 009:    784 / 1191 loss=2.453, trans_loss=3.942, nll_loss=2.216, w2v_ctc_loss=1.287, task_loss=2.112, task_loss_gen=2.743, contrastive_loss=0, total=6703.36, n_correct=2648.96, ppl=4.65, accuracy=39.517, wps=19003.7, ups=0.98, wpb=19428.1, bsz=686.7, num_updates=10300, lr=0.000139347, gnorm=2.483, clip=0, loss_scale=0.25, train_wall=102, gb_free=9.1, wall=10692
2023-09-06 04:14:45 | INFO | train_inner | epoch 009:    884 / 1191 loss=2.553, trans_loss=3.947, nll_loss=2.222, w2v_ctc_loss=1.438, task_loss=2.187, task_loss_gen=2.919, contrastive_loss=0, total=6733.77, n_correct=2648.89, ppl=4.67, accuracy=39.337, wps=19051.6, ups=0.98, wpb=19512.4, bsz=674, num_updates=10400, lr=0.000138675, gnorm=4.506, clip=6, loss_scale=0.25, train_wall=102, gb_free=14, wall=10795
2023-09-06 04:16:27 | INFO | train_inner | epoch 009:    984 / 1191 loss=2.543, trans_loss=3.945, nll_loss=2.219, w2v_ctc_loss=1.423, task_loss=2.098, task_loss_gen=2.943, contrastive_loss=0, total=6699.46, n_correct=2635.49, ppl=4.66, accuracy=39.339, wps=18933.1, ups=0.98, wpb=19407.9, bsz=675.5, num_updates=10500, lr=0.000138013, gnorm=5.319, clip=4, loss_scale=0.25, train_wall=102, gb_free=11.6, wall=10897
2023-09-06 04:18:09 | INFO | train_inner | epoch 009:   1084 / 1191 loss=2.567, trans_loss=3.944, nll_loss=2.219, w2v_ctc_loss=1.46, task_loss=2.191, task_loss_gen=2.777, contrastive_loss=0, total=6665.1, n_correct=2627.32, ppl=4.65, accuracy=39.419, wps=18935.3, ups=0.98, wpb=19316.1, bsz=678.5, num_updates=10600, lr=0.000137361, gnorm=3.475, clip=4, loss_scale=0.25, train_wall=101, gb_free=13, wall=10999
2023-09-06 04:19:52 | INFO | train_inner | epoch 009:   1184 / 1191 loss=2.592, trans_loss=3.944, nll_loss=2.219, w2v_ctc_loss=1.495, task_loss=2.177, task_loss_gen=2.953, contrastive_loss=0, total=6683.3, n_correct=2629.83, ppl=4.65, accuracy=39.349, wps=18879.5, ups=0.97, wpb=19368.4, bsz=658.4, num_updates=10700, lr=0.000136717, gnorm=3.305, clip=6, loss_scale=0.5, train_wall=102, gb_free=12.9, wall=11102
2023-09-06 04:19:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
2023-09-06 04:20:32 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.114 | trans_loss 6.818 | nll_loss 4.603 | w2v_ctc_loss 1.641 | task_loss 11.013 | task_loss_gen 11.923 | contrastive_loss 0 | total 6138.43 | n_correct 2445.71 | ppl 24.29 | accuracy 39.843 | uer 27.259 | wer 28.773 | raw_wer 28.773 | bleu 0.16 | wps 1728 | wpb 6138.4 | bsz 201.1 | num_updates 10707 | best_bleu 0.25
2023-09-06 04:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10707 updates
2023-09-06 04:20:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt
2023-09-06 04:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt
2023-09-06 04:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1606.pt (epoch 9 @ 10707 updates, score 0.16) (writing took 7.803101063007489 seconds)
2023-09-06 04:20:41 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-06 04:20:41 | INFO | train | epoch 009 | loss 2.512 | trans_loss 3.946 | nll_loss 2.22 | w2v_ctc_loss 1.375 | task_loss 2.254 | task_loss_gen 2.91 | contrastive_loss 0 | total 6703.69 | n_correct 2640.89 | ppl 4.66 | accuracy 39.395 | wps 17624.7 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 10707 | lr 0.000136672 | gnorm 4.357 | clip 7.1 | loss_scale 0.5 | train_wall 1212 | gb_free 14.3 | wall 11150
2023-09-06 04:20:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 04:20:41 | INFO | fairseq.trainer | begin training epoch 10
2023-09-06 04:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:22:23 | INFO | train_inner | epoch 010:     93 / 1191 loss=2.563, trans_loss=3.928, nll_loss=2.198, w2v_ctc_loss=1.461, task_loss=2.073, task_loss_gen=2.877, contrastive_loss=0, total=6658.21, n_correct=2644.49, ppl=4.59, accuracy=39.718, wps=12765.7, ups=0.66, wpb=19289, bsz=675.2, num_updates=10800, lr=0.000136083, gnorm=2.321, clip=2, loss_scale=0.5, train_wall=101, gb_free=13.6, wall=11253
2023-09-06 04:24:04 | INFO | train_inner | epoch 010:    193 / 1191 loss=2.518, trans_loss=3.933, nll_loss=2.204, w2v_ctc_loss=1.395, task_loss=2.202, task_loss_gen=2.957, contrastive_loss=0, total=6661.46, n_correct=2645.38, ppl=4.61, accuracy=39.712, wps=19048.7, ups=0.99, wpb=19303.2, bsz=679.5, num_updates=10900, lr=0.000135457, gnorm=2.452, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.9, wall=11354
2023-09-06 04:25:47 | INFO | train_inner | epoch 010:    293 / 1191 loss=2.523, trans_loss=3.931, nll_loss=2.2, w2v_ctc_loss=1.402, task_loss=2.09, task_loss_gen=2.871, contrastive_loss=0, total=6782.88, n_correct=2692.29, ppl=4.59, accuracy=39.692, wps=19171.3, ups=0.98, wpb=19645.1, bsz=690.7, num_updates=11000, lr=0.00013484, gnorm=4.021, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.9, wall=11457
2023-09-06 04:27:30 | INFO | train_inner | epoch 010:    393 / 1191 loss=2.514, trans_loss=3.93, nll_loss=2.201, w2v_ctc_loss=1.391, task_loss=2.023, task_loss_gen=2.695, contrastive_loss=0, total=6818.2, n_correct=2709.6, ppl=4.6, accuracy=39.741, wps=19078.8, ups=0.97, wpb=19754, bsz=723.2, num_updates=11100, lr=0.000134231, gnorm=2.611, clip=1, loss_scale=0.5, train_wall=103, gb_free=11.9, wall=11560
2023-09-06 04:29:13 | INFO | train_inner | epoch 010:    493 / 1191 loss=2.554, trans_loss=3.93, nll_loss=2.198, w2v_ctc_loss=1.445, task_loss=2.413, task_loss_gen=2.864, contrastive_loss=0, total=6725.27, n_correct=2663.43, ppl=4.59, accuracy=39.603, wps=19043.8, ups=0.98, wpb=19473.5, bsz=669.6, num_updates=11200, lr=0.000133631, gnorm=2.046, clip=1, loss_scale=0.5, train_wall=102, gb_free=14.2, wall=11663
2023-09-06 04:30:54 | INFO | train_inner | epoch 010:    593 / 1191 loss=2.552, trans_loss=3.931, nll_loss=2.201, w2v_ctc_loss=1.446, task_loss=2.297, task_loss_gen=2.788, contrastive_loss=0, total=6731.17, n_correct=2669.98, ppl=4.6, accuracy=39.666, wps=19234.7, ups=0.99, wpb=19501.1, bsz=680.7, num_updates=11300, lr=0.000133038, gnorm=2.044, clip=1, loss_scale=0.5, train_wall=101, gb_free=12, wall=11764
2023-09-06 04:32:36 | INFO | train_inner | epoch 010:    693 / 1191 loss=2.526, trans_loss=3.928, nll_loss=2.198, w2v_ctc_loss=1.405, task_loss=2.248, task_loss_gen=2.777, contrastive_loss=0, total=6746.82, n_correct=2682, ppl=4.59, accuracy=39.752, wps=19112.3, ups=0.98, wpb=19545.4, bsz=690.7, num_updates=11400, lr=0.000132453, gnorm=2.634, clip=2, loss_scale=0.5, train_wall=102, gb_free=12.7, wall=11866
2023-09-06 04:34:18 | INFO | train_inner | epoch 010:    793 / 1191 loss=2.572, trans_loss=3.932, nll_loss=2.204, w2v_ctc_loss=1.471, task_loss=2.287, task_loss_gen=3.006, contrastive_loss=0, total=6630.78, n_correct=2615.68, ppl=4.61, accuracy=39.448, wps=18863, ups=0.98, wpb=19219.8, bsz=651.1, num_updates=11500, lr=0.000131876, gnorm=2.389, clip=3, loss_scale=0.5, train_wall=101, gb_free=14, wall=11968
2023-09-06 04:35:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 04:36:03 | INFO | train_inner | epoch 010:    894 / 1191 loss=2.601, trans_loss=3.928, nll_loss=2.199, w2v_ctc_loss=1.519, task_loss=2.227, task_loss_gen=3.109, contrastive_loss=0, total=6558.58, n_correct=2601.32, ppl=4.59, accuracy=39.663, wps=18099.4, ups=0.95, wpb=19006.2, bsz=639.1, num_updates=11600, lr=0.000131306, gnorm=3.7, clip=4, loss_scale=0.25, train_wall=104, gb_free=14.1, wall=12073
2023-09-06 04:37:45 | INFO | train_inner | epoch 010:    994 / 1191 loss=2.61, trans_loss=3.927, nll_loss=2.197, w2v_ctc_loss=1.534, task_loss=2.094, task_loss_gen=2.717, contrastive_loss=0, total=6753.84, n_correct=2681.4, ppl=4.58, accuracy=39.702, wps=19221.8, ups=0.98, wpb=19567.9, bsz=689.1, num_updates=11700, lr=0.000130744, gnorm=4.43, clip=2, loss_scale=0.25, train_wall=101, gb_free=13.5, wall=12175
2023-09-06 04:39:28 | INFO | train_inner | epoch 010:   1094 / 1191 loss=2.569, trans_loss=3.926, nll_loss=2.197, w2v_ctc_loss=1.472, task_loss=2.296, task_loss_gen=2.818, contrastive_loss=0, total=6689.47, n_correct=2651.39, ppl=4.59, accuracy=39.635, wps=18890.1, ups=0.97, wpb=19393.8, bsz=676.6, num_updates=11800, lr=0.000130189, gnorm=3.436, clip=1, loss_scale=0.25, train_wall=102, gb_free=7.3, wall=12278
2023-09-06 04:41:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:41:40 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 5.098 | trans_loss 6.809 | nll_loss 4.591 | w2v_ctc_loss 1.611 | task_loss 12.894 | task_loss_gen 11.775 | contrastive_loss 0 | total 6138.43 | n_correct 2446.43 | ppl 24.1 | accuracy 39.854 | uer 26.689 | wer 28.412 | raw_wer 28.412 | bleu 0.13 | wps 1696.9 | wpb 6138.4 | bsz 201.1 | num_updates 11897 | best_bleu 0.25
2023-09-06 04:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11897 updates
2023-09-06 04:41:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 04:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt
2023-09-06 04:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.1304.pt (epoch 10 @ 11897 updates, score 0.13) (writing took 10.143143795896322 seconds)
2023-09-06 04:41:50 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-06 04:41:50 | INFO | train | epoch 010 | loss 2.554 | trans_loss 3.929 | nll_loss 2.199 | w2v_ctc_loss 1.449 | task_loss 2.203 | task_loss_gen 2.856 | contrastive_loss 0 | total 6704.88 | n_correct 2660.3 | ppl 4.59 | accuracy 39.677 | wps 18208.9 | ups 0.94 | wpb 19426.2 | bsz 678.5 | num_updates 11897 | lr 0.000129657 | gnorm 2.889 | clip 1.6 | loss_scale 0.25 | train_wall 1211 | gb_free 12.1 | wall 12420
2023-09-06 04:41:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 04:41:50 | INFO | fairseq.trainer | begin training epoch 11
2023-09-06 04:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 04:42:01 | INFO | train_inner | epoch 011:      3 / 1191 loss=2.556, trans_loss=3.926, nll_loss=2.194, w2v_ctc_loss=1.456, task_loss=2.177, task_loss_gen=2.795, contrastive_loss=0, total=6703.53, n_correct=2669.13, ppl=4.58, accuracy=39.817, wps=12715.4, ups=0.65, wpb=19417.9, bsz=681.5, num_updates=11900, lr=0.000129641, gnorm=3.052, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.2, wall=12430
2023-09-06 04:43:43 | INFO | train_inner | epoch 011:    103 / 1191 loss=2.594, trans_loss=3.917, nll_loss=2.185, w2v_ctc_loss=1.513, task_loss=2.365, task_loss_gen=2.969, contrastive_loss=0, total=6658.67, n_correct=2648.24, ppl=4.55, accuracy=39.771, wps=18782.3, ups=0.97, wpb=19302.4, bsz=654.5, num_updates=12000, lr=0.000129099, gnorm=3.022, clip=2, loss_scale=0.25, train_wall=102, gb_free=12.7, wall=12533
2023-09-06 04:43:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 04:44:16 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.085 | trans_loss 6.803 | nll_loss 4.584 | w2v_ctc_loss 1.58 | task_loss 11.122 | task_loss_gen 11.92 | contrastive_loss 0 | total 6138.43 | n_correct 2457.14 | ppl 23.98 | accuracy 40.029 | uer 26.542 | wer 28.1 | raw_wer 28.1 | bleu 0.14 | wps 1740.2 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 0.25
2023-09-06 04:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-09-06 04:44:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 04:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 04:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 0.14) (writing took 8.448308683000505 seconds)
2023-09-06 04:46:06 | INFO | train_inner | epoch 011:    203 / 1191 loss=2.562, trans_loss=3.917, nll_loss=2.182, w2v_ctc_loss=1.47, task_loss=2.181, task_loss_gen=2.745, contrastive_loss=0, total=6711.38, n_correct=2691.45, ppl=4.54, accuracy=40.103, wps=13577.7, ups=0.7, wpb=19433.4, bsz=694.6, num_updates=12100, lr=0.000128565, gnorm=3.129, clip=3, loss_scale=0.25, train_wall=101, gb_free=13.7, wall=12676
2023-09-06 04:47:49 | INFO | train_inner | epoch 011:    303 / 1191 loss=2.596, trans_loss=3.916, nll_loss=2.182, w2v_ctc_loss=1.521, task_loss=2.266, task_loss_gen=2.939, contrastive_loss=0, total=6592.11, n_correct=2628.72, ppl=4.54, accuracy=39.877, wps=18655, ups=0.98, wpb=19100.7, bsz=661.6, num_updates=12200, lr=0.000128037, gnorm=4.463, clip=6, loss_scale=0.25, train_wall=102, gb_free=12.3, wall=12779
2023-09-06 04:49:31 | INFO | train_inner | epoch 011:    403 / 1191 loss=2.588, trans_loss=3.915, nll_loss=2.182, w2v_ctc_loss=1.505, task_loss=2.535, task_loss_gen=3.048, contrastive_loss=0, total=6592.18, n_correct=2631.34, ppl=4.54, accuracy=39.916, wps=18738.5, ups=0.98, wpb=19108.3, bsz=655.9, num_updates=12300, lr=0.000127515, gnorm=8.811, clip=38, loss_scale=0.25, train_wall=101, gb_free=11.3, wall=12881
2023-09-06 04:51:13 | INFO | train_inner | epoch 011:    503 / 1191 loss=2.653, trans_loss=3.932, nll_loss=2.203, w2v_ctc_loss=1.594, task_loss=2.253, task_loss_gen=3.054, contrastive_loss=0, total=6673.62, n_correct=2631.86, ppl=4.6, accuracy=39.437, wps=18834.9, ups=0.97, wpb=19341.4, bsz=656.4, num_updates=12400, lr=0.000127, gnorm=8.659, clip=32, loss_scale=0.25, train_wall=102, gb_free=13.9, wall=12983
2023-09-06 04:52:54 | INFO | train_inner | epoch 011:    603 / 1191 loss=2.703, trans_loss=3.922, nll_loss=2.192, w2v_ctc_loss=1.68, task_loss=2.29, task_loss_gen=2.879, contrastive_loss=0, total=6642.09, n_correct=2632.97, ppl=4.57, accuracy=39.641, wps=19095.9, ups=0.99, wpb=19264.4, bsz=664.6, num_updates=12500, lr=0.000126491, gnorm=5.732, clip=10, loss_scale=0.25, train_wall=100, gb_free=14.1, wall=13084
2023-09-06 04:54:37 | INFO | train_inner | epoch 011:    703 / 1191 loss=2.674, trans_loss=3.914, nll_loss=2.182, w2v_ctc_loss=1.642, task_loss=2.361, task_loss_gen=2.896, contrastive_loss=0, total=6685.05, n_correct=2662.87, ppl=4.54, accuracy=39.833, wps=18917.5, ups=0.98, wpb=19384.9, bsz=669.6, num_updates=12600, lr=0.000125988, gnorm=4.247, clip=6, loss_scale=0.25, train_wall=102, gb_free=13.3, wall=13187
2023-09-06 04:56:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-06 04:56:20 | INFO | train_inner | epoch 011:    804 / 1191 loss=2.703, trans_loss=3.921, nll_loss=2.189, w2v_ctc_loss=1.684, task_loss=2.158, task_loss_gen=2.781, contrastive_loss=0, total=6797.73, n_correct=2706.61, ppl=4.56, accuracy=39.816, wps=19007.4, ups=0.97, wpb=19694.7, bsz=701.1, num_updates=12700, lr=0.000125491, gnorm=4.551, clip=5, loss_scale=0.125, train_wall=103, gb_free=13.2, wall=13290
2023-09-06 04:58:03 | INFO | train_inner | epoch 011:    904 / 1191 loss=2.682, trans_loss=3.927, nll_loss=2.194, w2v_ctc_loss=1.645, task_loss=2.262, task_loss_gen=2.821, contrastive_loss=0, total=6775.73, n_correct=2696.8, ppl=4.57, accuracy=39.801, wps=19105.2, ups=0.97, wpb=19615.9, bsz=682.4, num_updates=12800, lr=0.000125, gnorm=6.703, clip=17, loss_scale=0.125, train_wall=102, gb_free=12.2, wall=13393
2023-09-06 04:59:46 | INFO | train_inner | epoch 011:   1004 / 1191 loss=2.63, trans_loss=3.92, nll_loss=2.186, w2v_ctc_loss=1.572, task_loss=2.09, task_loss_gen=2.634, contrastive_loss=0, total=6815.44, n_correct=2723.41, ppl=4.55, accuracy=39.959, wps=19143.3, ups=0.97, wpb=19730.4, bsz=713, num_updates=12900, lr=0.000124515, gnorm=4.218, clip=4, loss_scale=0.125, train_wall=102, gb_free=14.1, wall=13496
2023-09-06 05:01:28 | INFO | train_inner | epoch 011:   1104 / 1191 loss=2.641, trans_loss=3.918, nll_loss=2.185, w2v_ctc_loss=1.589, task_loss=2.159, task_loss_gen=2.827, contrastive_loss=0, total=6719.62, n_correct=2676.19, ppl=4.55, accuracy=39.827, wps=19208.6, ups=0.99, wpb=19466, bsz=691.7, num_updates=13000, lr=0.000124035, gnorm=12.859, clip=34, loss_scale=0.125, train_wall=101, gb_free=15, wall=13597
2023-09-06 05:02:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:03:30 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 5.162 | trans_loss 6.8 | nll_loss 4.578 | w2v_ctc_loss 1.845 | task_loss 12.561 | task_loss_gen 11.481 | contrastive_loss 0 | total 6138.43 | n_correct 2465.57 | ppl 23.88 | accuracy 40.166 | uer 29.717 | wer 31.231 | raw_wer 31.231 | bleu 0.2 | wps 1695.3 | wpb 6138.4 | bsz 201.1 | num_updates 13087 | best_bleu 0.25
2023-09-06 05:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13087 updates
2023-09-06 05:03:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt
2023-09-06 05:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt
2023-09-06 05:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2006.pt (epoch 11 @ 13087 updates, score 0.2) (writing took 8.01055621006526 seconds)
2023-09-06 05:03:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-06 05:03:39 | INFO | train | epoch 011 | loss 2.645 | trans_loss 3.921 | nll_loss 2.188 | w2v_ctc_loss 1.593 | task_loss 2.25 | task_loss_gen 2.857 | contrastive_loss 0 | total 6703.49 | n_correct 2668.72 | ppl 4.56 | accuracy 39.811 | wps 17664.2 | ups 0.91 | wpb 19422.2 | bsz 678.2 | num_updates 13087 | lr 0.000123622 | gnorm 6.205 | clip 14.9 | loss_scale 0.125 | train_wall 1210 | gb_free 13.2 | wall 13728
2023-09-06 05:03:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:03:39 | INFO | fairseq.trainer | begin training epoch 12
2023-09-06 05:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:04:00 | INFO | train_inner | epoch 012:     13 / 1191 loss=2.712, trans_loss=3.923, nll_loss=2.19, w2v_ctc_loss=1.699, task_loss=2.029, task_loss_gen=2.592, contrastive_loss=0, total=6840.98, n_correct=2730.87, ppl=4.56, accuracy=39.919, wps=13010.6, ups=0.66, wpb=19805.8, bsz=723.2, num_updates=13100, lr=0.00012356, gnorm=7.903, clip=20, loss_scale=0.125, train_wall=102, gb_free=10.5, wall=13750
2023-09-06 05:05:42 | INFO | train_inner | epoch 012:    113 / 1191 loss=2.714, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.702, task_loss=2.407, task_loss_gen=2.859, contrastive_loss=0, total=6706.17, n_correct=2670.63, ppl=4.53, accuracy=39.823, wps=18944.2, ups=0.98, wpb=19429.8, bsz=660.9, num_updates=13200, lr=0.000123091, gnorm=10.326, clip=18, loss_scale=0.125, train_wall=102, gb_free=12.6, wall=13852
2023-09-06 05:07:24 | INFO | train_inner | epoch 012:    213 / 1191 loss=2.8, trans_loss=3.916, nll_loss=2.183, w2v_ctc_loss=1.835, task_loss=2.191, task_loss_gen=2.772, contrastive_loss=0, total=6758.31, n_correct=2691.92, ppl=4.54, accuracy=39.831, wps=19178, ups=0.98, wpb=19580.8, bsz=678.4, num_updates=13300, lr=0.000122628, gnorm=12.77, clip=26, loss_scale=0.125, train_wall=101, gb_free=13.6, wall=13954
2023-09-06 05:09:07 | INFO | train_inner | epoch 012:    313 / 1191 loss=2.724, trans_loss=3.913, nll_loss=2.179, w2v_ctc_loss=1.721, task_loss=2.133, task_loss_gen=2.699, contrastive_loss=0, total=6707.15, n_correct=2680.79, ppl=4.53, accuracy=39.969, wps=18913.5, ups=0.97, wpb=19435.8, bsz=693.4, num_updates=13400, lr=0.000122169, gnorm=5.835, clip=10, loss_scale=0.125, train_wall=102, gb_free=11.2, wall=14057
2023-09-06 05:10:49 | INFO | train_inner | epoch 012:    413 / 1191 loss=2.65, trans_loss=3.914, nll_loss=2.18, w2v_ctc_loss=1.608, task_loss=2.114, task_loss_gen=2.611, contrastive_loss=0, total=6766.6, n_correct=2703.07, ppl=4.53, accuracy=39.947, wps=19269.4, ups=0.98, wpb=19605.1, bsz=706.7, num_updates=13500, lr=0.000121716, gnorm=5.894, clip=13, loss_scale=0.125, train_wall=101, gb_free=14.3, wall=14159
2023-09-06 05:12:30 | INFO | train_inner | epoch 012:    513 / 1191 loss=2.659, trans_loss=3.917, nll_loss=2.183, w2v_ctc_loss=1.615, task_loss=2.182, task_loss_gen=2.692, contrastive_loss=0, total=6741.73, n_correct=2692.34, ppl=4.54, accuracy=39.935, wps=19259.5, ups=0.99, wpb=19531.2, bsz=688.4, num_updates=13600, lr=0.000121268, gnorm=5.647, clip=3, loss_scale=0.125, train_wall=101, gb_free=13, wall=14260
2023-09-06 05:14:13 | INFO | train_inner | epoch 012:    613 / 1191 loss=2.63, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.574, task_loss=2.253, task_loss_gen=2.912, contrastive_loss=0, total=6697.76, n_correct=2677.67, ppl=4.53, accuracy=39.979, wps=18955.3, ups=0.98, wpb=19401.1, bsz=671, num_updates=13700, lr=0.000120824, gnorm=5.355, clip=3, loss_scale=0.125, train_wall=102, gb_free=13.3, wall=14363
2023-09-06 05:15:55 | INFO | train_inner | epoch 012:    713 / 1191 loss=2.619, trans_loss=3.906, nll_loss=2.172, w2v_ctc_loss=1.566, task_loss=2.375, task_loss_gen=2.71, contrastive_loss=0, total=6731.9, n_correct=2697.06, ppl=4.51, accuracy=40.064, wps=19001.9, ups=0.97, wpb=19527.6, bsz=685.1, num_updates=13800, lr=0.000120386, gnorm=5.772, clip=7, loss_scale=0.125, train_wall=102, gb_free=13.4, wall=14465
2023-09-06 05:17:38 | INFO | train_inner | epoch 012:    813 / 1191 loss=2.641, trans_loss=3.92, nll_loss=2.186, w2v_ctc_loss=1.586, task_loss=2.341, task_loss_gen=2.922, contrastive_loss=0, total=6659.05, n_correct=2659.29, ppl=4.55, accuracy=39.935, wps=18760.6, ups=0.97, wpb=19282.5, bsz=661.1, num_updates=13900, lr=0.000119952, gnorm=7.557, clip=22, loss_scale=0.125, train_wall=102, gb_free=11.8, wall=14568
2023-09-06 05:19:22 | INFO | train_inner | epoch 012:    913 / 1191 loss=2.626, trans_loss=3.918, nll_loss=2.184, w2v_ctc_loss=1.567, task_loss=2.317, task_loss_gen=2.887, contrastive_loss=0, total=6701.85, n_correct=2677.69, ppl=4.54, accuracy=39.954, wps=18776.8, ups=0.97, wpb=19408.4, bsz=671.8, num_updates=14000, lr=0.000119523, gnorm=5.265, clip=7, loss_scale=0.125, train_wall=103, gb_free=13.6, wall=14671
2023-09-06 05:19:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:19:55 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 5.144 | trans_loss 6.799 | nll_loss 4.577 | w2v_ctc_loss 1.784 | task_loss 13.356 | task_loss_gen 11.845 | contrastive_loss 0 | total 6138.43 | n_correct 2468.29 | ppl 23.87 | accuracy 40.21 | uer 28.572 | wer 30.253 | raw_wer 30.253 | bleu 0.16 | wps 1717.3 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 0.25
2023-09-06 05:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-09-06 05:19:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 05:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 05:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 0.16) (writing took 9.49134656705428 seconds)
2023-09-06 05:21:46 | INFO | train_inner | epoch 012:   1013 / 1191 loss=2.622, trans_loss=3.915, nll_loss=2.185, w2v_ctc_loss=1.56, task_loss=2.465, task_loss_gen=2.882, contrastive_loss=0, total=6584.36, n_correct=2621.24, ppl=4.55, accuracy=39.81, wps=13200.7, ups=0.69, wpb=19095.9, bsz=659, num_updates=14100, lr=0.000119098, gnorm=4.715, clip=2, loss_scale=0.125, train_wall=101, gb_free=14.1, wall=14816
2023-09-06 05:23:29 | INFO | train_inner | epoch 012:   1113 / 1191 loss=2.61, trans_loss=3.916, nll_loss=2.18, w2v_ctc_loss=1.542, task_loss=2.358, task_loss_gen=2.913, contrastive_loss=0, total=6644.98, n_correct=2653.7, ppl=4.53, accuracy=39.935, wps=18801.3, ups=0.98, wpb=19243.3, bsz=668.4, num_updates=14200, lr=0.000118678, gnorm=5.534, clip=11, loss_scale=0.125, train_wall=102, gb_free=13.2, wall=14919
2023-09-06 05:24:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:25:24 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 5.133 | trans_loss 6.8 | nll_loss 4.583 | w2v_ctc_loss 1.748 | task_loss 13.526 | task_loss_gen 11.777 | contrastive_loss 0 | total 6138.43 | n_correct 2454.86 | ppl 23.97 | accuracy 39.992 | uer 28.267 | wer 29.877 | raw_wer 29.877 | bleu 0.31 | wps 1578 | wpb 6138.4 | bsz 201.1 | num_updates 14278 | best_bleu 0.31
2023-09-06 05:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14278 updates
2023-09-06 05:25:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 05:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 05:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 12 @ 14278 updates, score 0.31) (writing took 12.971250363974832 seconds)
2023-09-06 05:25:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-06 05:25:37 | INFO | train | epoch 012 | loss 2.66 | trans_loss 3.915 | nll_loss 2.181 | w2v_ctc_loss 1.621 | task_loss 2.278 | task_loss_gen 2.794 | contrastive_loss 0 | total 6703.69 | n_correct 2677.29 | ppl 4.53 | accuracy 39.937 | wps 17546.4 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 14278 | lr 0.000118354 | gnorm 6.712 | clip 10.7 | loss_scale 0.125 | train_wall 1210 | gb_free 13.9 | wall 15047
2023-09-06 05:25:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:25:37 | INFO | fairseq.trainer | begin training epoch 13
2023-09-06 05:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:26:08 | INFO | train_inner | epoch 013:     22 / 1191 loss=2.613, trans_loss=3.913, nll_loss=2.178, w2v_ctc_loss=1.549, task_loss=2.33, task_loss_gen=2.814, contrastive_loss=0, total=6692.41, n_correct=2676.93, ppl=4.53, accuracy=39.999, wps=12196, ups=0.63, wpb=19386.7, bsz=670.5, num_updates=14300, lr=0.000118262, gnorm=5.787, clip=6, loss_scale=0.125, train_wall=102, gb_free=12.6, wall=15077
2023-09-06 05:27:50 | INFO | train_inner | epoch 013:    122 / 1191 loss=2.596, trans_loss=3.902, nll_loss=2.164, w2v_ctc_loss=1.527, task_loss=2.401, task_loss_gen=2.89, contrastive_loss=0, total=6709.06, n_correct=2694.26, ppl=4.48, accuracy=40.159, wps=18979, ups=0.98, wpb=19438.9, bsz=666.1, num_updates=14400, lr=0.000117851, gnorm=5.154, clip=3, loss_scale=0.125, train_wall=102, gb_free=14.6, wall=15180
2023-09-06 05:29:33 | INFO | train_inner | epoch 013:    222 / 1191 loss=2.614, trans_loss=3.907, nll_loss=2.171, w2v_ctc_loss=1.557, task_loss=2.218, task_loss_gen=2.737, contrastive_loss=0, total=6683.81, n_correct=2683.82, ppl=4.5, accuracy=40.154, wps=18896.2, ups=0.98, wpb=19361.8, bsz=702.7, num_updates=14500, lr=0.000117444, gnorm=4.483, clip=3, loss_scale=0.125, train_wall=102, gb_free=14.3, wall=15282
2023-09-06 05:31:14 | INFO | train_inner | epoch 013:    322 / 1191 loss=2.627, trans_loss=3.902, nll_loss=2.165, w2v_ctc_loss=1.581, task_loss=1.971, task_loss_gen=2.593, contrastive_loss=0, total=6740.39, n_correct=2713.61, ppl=4.48, accuracy=40.259, wps=19250.6, ups=0.99, wpb=19531.1, bsz=716.4, num_updates=14600, lr=0.000117041, gnorm=5.729, clip=10, loss_scale=0.125, train_wall=101, gb_free=13.4, wall=15384
2023-09-06 05:32:56 | INFO | train_inner | epoch 013:    422 / 1191 loss=2.664, trans_loss=3.914, nll_loss=2.18, w2v_ctc_loss=1.625, task_loss=2.255, task_loss_gen=2.843, contrastive_loss=0, total=6715.72, n_correct=2677.64, ppl=4.53, accuracy=39.871, wps=19052.6, ups=0.98, wpb=19459.4, bsz=670.8, num_updates=14700, lr=0.000116642, gnorm=7.227, clip=13, loss_scale=0.125, train_wall=102, gb_free=14.1, wall=15486
2023-09-06 05:34:39 | INFO | train_inner | epoch 013:    522 / 1191 loss=2.69, trans_loss=3.909, nll_loss=2.173, w2v_ctc_loss=1.669, task_loss=2.335, task_loss_gen=3.016, contrastive_loss=0, total=6635.66, n_correct=2654.24, ppl=4.51, accuracy=40, wps=18675.6, ups=0.97, wpb=19230.2, bsz=649.9, num_updates=14800, lr=0.000116248, gnorm=4.158, clip=8, loss_scale=0.25, train_wall=102, gb_free=13.5, wall=15589
2023-09-06 05:36:21 | INFO | train_inner | epoch 013:    622 / 1191 loss=2.628, trans_loss=3.91, nll_loss=2.175, w2v_ctc_loss=1.574, task_loss=2.283, task_loss_gen=2.904, contrastive_loss=0, total=6711.43, n_correct=2687.97, ppl=4.51, accuracy=40.051, wps=18983.9, ups=0.98, wpb=19440.8, bsz=654.6, num_updates=14900, lr=0.000115857, gnorm=3.228, clip=2, loss_scale=0.25, train_wall=102, gb_free=11.9, wall=15691
2023-09-06 05:38:05 | INFO | train_inner | epoch 013:    722 / 1191 loss=2.563, trans_loss=3.909, nll_loss=2.173, w2v_ctc_loss=1.473, task_loss=2.334, task_loss_gen=2.89, contrastive_loss=0, total=6634.93, n_correct=2659.43, ppl=4.51, accuracy=40.082, wps=18588.2, ups=0.97, wpb=19220.1, bsz=660.1, num_updates=15000, lr=0.00011547, gnorm=2.479, clip=0, loss_scale=0.25, train_wall=103, gb_free=12.1, wall=15795
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 05:39:18 | INFO | train_inner | epoch 013:    822 / 1191 loss=2.612, trans_loss=5.635, nll_loss=3.129, w2v_ctc_loss=1.055, task_loss=3.175, task_loss_gen=3.996, contrastive_loss=0, total=6781.8, n_correct=2727.41, ppl=8.75, accuracy=40.217, wps=18641, ups=1.37, wpb=13616.6, bsz=465.9, num_updates=15100, lr=0.000115087, gnorm=2.416, clip=0, loss_scale=0.25, train_wall=72, gb_free=9.8, wall=15868
2023-09-06 05:40:30 | INFO | train_inner | epoch 013:    922 / 1191 loss=2.619, trans_loss=5.657, nll_loss=3.141, w2v_ctc_loss=1.05, task_loss=3.815, task_loss_gen=4.662, contrastive_loss=0, total=6544.72, n_correct=2622.05, ppl=8.82, accuracy=40.064, wps=18144.2, ups=1.39, wpb=13089.4, bsz=417.1, num_updates=15200, lr=0.000114708, gnorm=3.548, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.1, wall=15940
2023-09-06 05:41:43 | INFO | train_inner | epoch 013:   1022 / 1191 loss=2.61, trans_loss=5.655, nll_loss=3.139, w2v_ctc_loss=1.046, task_loss=3.169, task_loss_gen=4.046, contrastive_loss=0, total=6788.78, n_correct=2728.77, ppl=8.81, accuracy=40.195, wps=18644.9, ups=1.37, wpb=13577.6, bsz=466.8, num_updates=15300, lr=0.000114332, gnorm=2.921, clip=1, loss_scale=0.25, train_wall=72, gb_free=14.9, wall=16013
2023-09-06 05:42:56 | INFO | train_inner | epoch 013:   1122 / 1191 loss=2.607, trans_loss=5.655, nll_loss=3.139, w2v_ctc_loss=1.036, task_loss=3.236, task_loss_gen=4.137, contrastive_loss=0, total=6754.7, n_correct=2716.39, ppl=8.81, accuracy=40.215, wps=18537.6, ups=1.37, wpb=13509.4, bsz=465.2, num_updates=15400, lr=0.000113961, gnorm=3.342, clip=0, loss_scale=0.25, train_wall=72, gb_free=12.3, wall=16086
2023-09-06 05:43:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
2023-09-06 05:44:19 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 5.086 | trans_loss 6.786 | nll_loss 4.56 | w2v_ctc_loss 1.624 | task_loss 10.079 | task_loss_gen 11.638 | contrastive_loss 0 | total 6138.43 | n_correct 2477.71 | ppl 23.58 | accuracy 40.364 | uer 26.197 | wer 27.865 | raw_wer 27.865 | bleu 0.11 | wps 1697.4 | wpb 6138.4 | bsz 201.1 | num_updates 15469 | best_bleu 0.31
2023-09-06 05:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15469 updates
2023-09-06 05:44:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 05:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 05:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt (epoch 13 @ 15469 updates, score 0.11) (writing took 7.641052469029091 seconds)
2023-09-06 05:44:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-06 05:44:27 | INFO | train | epoch 013 | loss 2.621 | trans_loss 4.449 | nll_loss 2.471 | w2v_ctc_loss 1.406 | task_loss 2.569 | task_loss_gen 3.233 | contrastive_loss 0 | total 6703.69 | n_correct 2689.69 | ppl 5.55 | accuracy 40.123 | wps 17972.4 | ups 1.05 | wpb 17052.6 | bsz 588.7 | num_updates 15469 | lr 0.000113706 | gnorm 3.971 | clip 3.4 | loss_scale 0.25 | train_wall 1073 | gb_free 9.7 | wall 16177
2023-09-06 05:44:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 05:44:27 | INFO | fairseq.trainer | begin training epoch 14
2023-09-06 05:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 05:44:57 | INFO | train_inner | epoch 014:     31 / 1191 loss=2.603, trans_loss=5.656, nll_loss=3.141, w2v_ctc_loss=1.015, task_loss=3.155, task_loss_gen=4.009, contrastive_loss=0, total=6718.48, n_correct=2697.7, ppl=8.82, accuracy=40.153, wps=11091.7, ups=0.83, wpb=13437, bsz=458.1, num_updates=15500, lr=0.000113592, gnorm=2.512, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.5, wall=16207
2023-09-06 05:46:09 | INFO | train_inner | epoch 014:    131 / 1191 loss=2.618, trans_loss=5.653, nll_loss=3.135, w2v_ctc_loss=1.075, task_loss=2.93, task_loss_gen=4.048, contrastive_loss=0, total=6692.6, n_correct=2689.91, ppl=8.78, accuracy=40.192, wps=18535.6, ups=1.38, wpb=13385.2, bsz=463.1, num_updates=15600, lr=0.000113228, gnorm=5.458, clip=5, loss_scale=0.25, train_wall=72, gb_free=11.8, wall=16279
2023-09-06 05:47:22 | INFO | train_inner | epoch 014:    231 / 1191 loss=2.666, trans_loss=5.655, nll_loss=3.138, w2v_ctc_loss=1.214, task_loss=3.222, task_loss_gen=4.428, contrastive_loss=0, total=6609.27, n_correct=2647.6, ppl=8.8, accuracy=40.059, wps=18259.8, ups=1.38, wpb=13218.5, bsz=433.9, num_updates=15700, lr=0.000112867, gnorm=5.472, clip=10, loss_scale=0.25, train_wall=72, gb_free=12.5, wall=16351
2023-09-06 05:48:35 | INFO | train_inner | epoch 014:    331 / 1191 loss=2.64, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.136, task_loss=3.248, task_loss_gen=4.287, contrastive_loss=0, total=6742.67, n_correct=2707.11, ppl=8.78, accuracy=40.149, wps=18470.8, ups=1.37, wpb=13485.3, bsz=449.8, num_updates=15800, lr=0.000112509, gnorm=4.091, clip=2, loss_scale=0.25, train_wall=72, gb_free=14, wall=16424
2023-09-06 05:49:48 | INFO | train_inner | epoch 014:    431 / 1191 loss=2.639, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.142, task_loss=2.92, task_loss_gen=4.086, contrastive_loss=0, total=6792.33, n_correct=2731.74, ppl=8.78, accuracy=40.218, wps=18593.1, ups=1.37, wpb=13584.7, bsz=465.6, num_updates=15900, lr=0.000112154, gnorm=3.772, clip=4, loss_scale=0.25, train_wall=72, gb_free=6.9, wall=16497
2023-09-06 05:51:01 | INFO | train_inner | epoch 014:    531 / 1191 loss=2.624, trans_loss=5.645, nll_loss=3.126, w2v_ctc_loss=1.102, task_loss=3.227, task_loss_gen=3.983, contrastive_loss=0, total=6768.61, n_correct=2723.96, ppl=8.73, accuracy=40.244, wps=18559.1, ups=1.37, wpb=13537.2, bsz=471.9, num_updates=16000, lr=0.000111803, gnorm=3.562, clip=2, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=16570
2023-09-06 05:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 05:51:35 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.094 | trans_loss 6.797 | nll_loss 4.571 | w2v_ctc_loss 1.624 | task_loss 11.17 | task_loss_gen 11.62 | contrastive_loss 0 | total 6138.43 | n_correct 2459.29 | ppl 23.76 | accuracy 40.064 | uer 27.171 | wer 28.728 | raw_wer 28.728 | bleu 0.17 | wps 1674.3 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 0.31
2023-09-06 05:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-09-06 05:51:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 05:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 05:51:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 0.17) (writing took 9.014827652019449 seconds)
2023-09-06 05:52:56 | INFO | train_inner | epoch 014:    631 / 1191 loss=2.622, trans_loss=5.652, nll_loss=3.134, w2v_ctc_loss=1.08, task_loss=3.155, task_loss_gen=4.195, contrastive_loss=0, total=6766.55, n_correct=2719.13, ppl=8.78, accuracy=40.185, wps=11690.1, ups=0.86, wpb=13533.1, bsz=452.5, num_updates=16100, lr=0.000111456, gnorm=3.275, clip=0, loss_scale=0.25, train_wall=71, gb_free=12.9, wall=16686
2023-09-06 05:54:09 | INFO | train_inner | epoch 014:    731 / 1191 loss=2.643, trans_loss=5.656, nll_loss=3.139, w2v_ctc_loss=1.145, task_loss=3.15, task_loss_gen=4.282, contrastive_loss=0, total=6693.79, n_correct=2681.62, ppl=8.81, accuracy=40.061, wps=18364.4, ups=1.37, wpb=13387.6, bsz=448.6, num_updates=16200, lr=0.000111111, gnorm=4.923, clip=5, loss_scale=0.25, train_wall=72, gb_free=13.4, wall=16759
2023-09-06 05:55:22 | INFO | train_inner | epoch 014:    831 / 1191 loss=2.628, trans_loss=5.651, nll_loss=3.133, w2v_ctc_loss=1.112, task_loss=3.358, task_loss_gen=4.275, contrastive_loss=0, total=6689.02, n_correct=2690.7, ppl=8.77, accuracy=40.226, wps=18434.4, ups=1.38, wpb=13378, bsz=458.4, num_updates=16300, lr=0.00011077, gnorm=3.163, clip=0, loss_scale=0.25, train_wall=72, gb_free=14, wall=16832
2023-09-06 05:56:35 | INFO | train_inner | epoch 014:    931 / 1191 loss=2.624, trans_loss=5.653, nll_loss=3.135, w2v_ctc_loss=1.087, task_loss=3.283, task_loss_gen=4.285, contrastive_loss=0, total=6649.73, n_correct=2668.63, ppl=8.79, accuracy=40.131, wps=18216.7, ups=1.37, wpb=13299.5, bsz=446.5, num_updates=16400, lr=0.000110432, gnorm=3.158, clip=3, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=16905
2023-09-06 05:57:47 | INFO | train_inner | epoch 014:   1031 / 1191 loss=2.616, trans_loss=5.656, nll_loss=3.14, w2v_ctc_loss=1.048, task_loss=3.596, task_loss_gen=4.623, contrastive_loss=0, total=6592.87, n_correct=2644.76, ppl=8.81, accuracy=40.115, wps=18175.8, ups=1.38, wpb=13185.7, bsz=426.6, num_updates=16500, lr=0.000110096, gnorm=2.769, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.5, wall=16977
2023-09-06 05:59:00 | INFO | train_inner | epoch 014:   1131 / 1191 loss=2.595, trans_loss=5.651, nll_loss=3.133, w2v_ctc_loss=1.001, task_loss=3.046, task_loss_gen=3.943, contrastive_loss=0, total=6802.52, n_correct=2739.83, ppl=8.77, accuracy=40.277, wps=18702.6, ups=1.37, wpb=13605, bsz=472.8, num_updates=16600, lr=0.000109764, gnorm=2.639, clip=1, loss_scale=0.25, train_wall=72, gb_free=12.6, wall=17050
2023-09-06 05:59:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:00:17 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 5.081 | trans_loss 6.788 | nll_loss 4.561 | w2v_ctc_loss 1.6 | task_loss 11.016 | task_loss_gen 11.608 | contrastive_loss 0 | total 6138.43 | n_correct 2471.43 | ppl 23.61 | accuracy 40.262 | uer 26.299 | wer 27.891 | raw_wer 27.891 | bleu 0.31 | wps 1696.1 | wpb 6138.4 | bsz 201.1 | num_updates 16660 | best_bleu 0.31
2023-09-06 06:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16660 updates
2023-09-06 06:00:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 14 @ 16660 updates, score 0.31) (writing took 18.231535727973096 seconds)
2023-09-06 06:00:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-06 06:00:35 | INFO | train | epoch 014 | loss 2.627 | trans_loss 5.652 | nll_loss 3.135 | w2v_ctc_loss 1.097 | task_loss 3.218 | task_loss_gen 4.233 | contrastive_loss 0 | total 6703.69 | n_correct 2692.23 | ppl 8.78 | accuracy 40.16 | wps 16499.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 16660 | lr 0.000109566 | gnorm 3.789 | clip 2.9 | loss_scale 0.25 | train_wall 858 | gb_free 14.3 | wall 17145
2023-09-06 06:00:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:00:35 | INFO | fairseq.trainer | begin training epoch 15
2023-09-06 06:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:01:11 | INFO | train_inner | epoch 015:     40 / 1191 loss=2.598, trans_loss=5.646, nll_loss=3.127, w2v_ctc_loss=1.002, task_loss=3.383, task_loss_gen=4.261, contrastive_loss=0, total=6688.09, n_correct=2686.48, ppl=8.74, accuracy=40.168, wps=10199.1, ups=0.76, wpb=13376.2, bsz=448.7, num_updates=16700, lr=0.000109435, gnorm=2.884, clip=2, loss_scale=0.25, train_wall=71, gb_free=12.1, wall=17181
2023-09-06 06:02:24 | INFO | train_inner | epoch 015:    140 / 1191 loss=2.585, trans_loss=5.64, nll_loss=3.118, w2v_ctc_loss=0.981, task_loss=3.187, task_loss_gen=4.19, contrastive_loss=0, total=6699.56, n_correct=2706.71, ppl=8.68, accuracy=40.401, wps=18556.2, ups=1.38, wpb=13399.1, bsz=451.7, num_updates=16800, lr=0.000109109, gnorm=2.791, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.8, wall=17253
2023-09-06 06:03:36 | INFO | train_inner | epoch 015:    240 / 1191 loss=2.596, trans_loss=5.644, nll_loss=3.123, w2v_ctc_loss=1.003, task_loss=3.038, task_loss_gen=4.196, contrastive_loss=0, total=6739.41, n_correct=2713.16, ppl=8.71, accuracy=40.258, wps=18645.8, ups=1.38, wpb=13478.8, bsz=454.6, num_updates=16900, lr=0.000108786, gnorm=2.262, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.2, wall=17326
2023-09-06 06:04:48 | INFO | train_inner | epoch 015:    340 / 1191 loss=2.596, trans_loss=5.638, nll_loss=3.116, w2v_ctc_loss=1.007, task_loss=3.275, task_loss_gen=4.324, contrastive_loss=0, total=6625.74, n_correct=2671.62, ppl=8.67, accuracy=40.322, wps=18289.9, ups=1.38, wpb=13251.5, bsz=441.8, num_updates=17000, lr=0.000108465, gnorm=1.879, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.5, wall=17398
2023-09-06 06:06:01 | INFO | train_inner | epoch 015:    440 / 1191 loss=2.592, trans_loss=5.642, nll_loss=3.122, w2v_ctc_loss=0.996, task_loss=3.094, task_loss_gen=4.302, contrastive_loss=0, total=6716.18, n_correct=2706.88, ppl=8.7, accuracy=40.304, wps=18441.6, ups=1.37, wpb=13432.4, bsz=452, num_updates=17100, lr=0.000108148, gnorm=1.353, clip=0, loss_scale=0.5, train_wall=72, gb_free=5.8, wall=17471
2023-09-06 06:07:14 | INFO | train_inner | epoch 015:    540 / 1191 loss=2.581, trans_loss=5.635, nll_loss=3.112, w2v_ctc_loss=0.972, task_loss=2.958, task_loss_gen=4.2, contrastive_loss=0, total=6719.43, n_correct=2719.63, ppl=8.65, accuracy=40.474, wps=18409.1, ups=1.37, wpb=13438.9, bsz=464, num_updates=17200, lr=0.000107833, gnorm=1.474, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=17544
2023-09-06 06:08:26 | INFO | train_inner | epoch 015:    640 / 1191 loss=2.594, trans_loss=5.645, nll_loss=3.125, w2v_ctc_loss=0.977, task_loss=3.493, task_loss_gen=4.717, contrastive_loss=0, total=6626.73, n_correct=2664.14, ppl=8.72, accuracy=40.203, wps=18384.4, ups=1.39, wpb=13253.5, bsz=415.7, num_updates=17300, lr=0.000107521, gnorm=1.745, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.1, wall=17616
2023-09-06 06:09:38 | INFO | train_inner | epoch 015:    740 / 1191 loss=2.587, trans_loss=5.633, nll_loss=3.11, w2v_ctc_loss=0.996, task_loss=3.243, task_loss_gen=4.341, contrastive_loss=0, total=6627.23, n_correct=2681.73, ppl=8.64, accuracy=40.465, wps=18341.8, ups=1.38, wpb=13254.5, bsz=450.2, num_updates=17400, lr=0.000107211, gnorm=2.003, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.7, wall=17688
2023-09-06 06:10:52 | INFO | train_inner | epoch 015:    840 / 1191 loss=2.597, trans_loss=5.643, nll_loss=3.123, w2v_ctc_loss=1.003, task_loss=3.155, task_loss_gen=4.253, contrastive_loss=0, total=6711.36, n_correct=2701.81, ppl=8.71, accuracy=40.257, wps=18279.5, ups=1.36, wpb=13422.7, bsz=446.3, num_updates=17500, lr=0.000106904, gnorm=1.747, clip=0, loss_scale=0.5, train_wall=73, gb_free=10.2, wall=17762
2023-09-06 06:12:05 | INFO | train_inner | epoch 015:    940 / 1191 loss=2.572, trans_loss=5.631, nll_loss=3.107, w2v_ctc_loss=0.963, task_loss=2.917, task_loss_gen=3.986, contrastive_loss=0, total=6789.2, n_correct=2757.75, ppl=8.62, accuracy=40.62, wps=18537.5, ups=1.37, wpb=13578.4, bsz=480.3, num_updates=17600, lr=0.0001066, gnorm=1.61, clip=1, loss_scale=0.5, train_wall=73, gb_free=14, wall=17835
2023-09-06 06:13:18 | INFO | train_inner | epoch 015:   1040 / 1191 loss=2.584, trans_loss=5.639, nll_loss=3.117, w2v_ctc_loss=0.98, task_loss=3.015, task_loss_gen=4.269, contrastive_loss=0, total=6692.46, n_correct=2708.17, ppl=8.68, accuracy=40.466, wps=18418.8, ups=1.38, wpb=13384.9, bsz=452.7, num_updates=17700, lr=0.000106299, gnorm=1.642, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=17908
2023-09-06 06:14:31 | INFO | train_inner | epoch 015:   1140 / 1191 loss=2.584, trans_loss=5.642, nll_loss=3.122, w2v_ctc_loss=0.967, task_loss=3.122, task_loss_gen=4.347, contrastive_loss=0, total=6746.33, n_correct=2728.63, ppl=8.71, accuracy=40.446, wps=18392.8, ups=1.36, wpb=13492.7, bsz=445.5, num_updates=17800, lr=0.000106, gnorm=1.616, clip=0, loss_scale=0.5, train_wall=73, gb_free=14.3, wall=17981
2023-09-06 06:15:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:15:42 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 5.09 | trans_loss 6.768 | nll_loss 4.535 | w2v_ctc_loss 1.677 | task_loss 8.946 | task_loss_gen 11.98 | contrastive_loss 0 | total 6138.43 | n_correct 2483.57 | ppl 23.18 | accuracy 40.459 | uer 26.155 | wer 28.074 | raw_wer 28.074 | bleu 0.25 | wps 1649.5 | wpb 6138.4 | bsz 201.1 | num_updates 17851 | best_bleu 0.31
2023-09-06 06:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17851 updates
2023-09-06 06:15:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt
2023-09-06 06:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt
2023-09-06 06:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2502.pt (epoch 15 @ 17851 updates, score 0.25) (writing took 9.645971847930923 seconds)
2023-09-06 06:15:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-06 06:15:52 | INFO | train | epoch 015 | loss 2.587 | trans_loss 5.639 | nll_loss 3.118 | w2v_ctc_loss 0.985 | task_loss 3.118 | task_loss_gen 4.247 | contrastive_loss 0 | total 6703.69 | n_correct 2707.58 | ppl 8.68 | accuracy 40.389 | wps 17411 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 17851 | lr 0.000105848 | gnorm 1.831 | clip 0.4 | loss_scale 0.5 | train_wall 858 | gb_free 11.5 | wall 18062
2023-09-06 06:15:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:15:52 | INFO | fairseq.trainer | begin training epoch 16
2023-09-06 06:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:16:35 | INFO | train_inner | epoch 016:     49 / 1191 loss=2.58, trans_loss=5.634, nll_loss=3.111, w2v_ctc_loss=0.969, task_loss=3.046, task_loss_gen=4.157, contrastive_loss=0, total=6660.79, n_correct=2699.18, ppl=8.64, accuracy=40.523, wps=10777.7, ups=0.81, wpb=13321.6, bsz=451.5, num_updates=17900, lr=0.000105703, gnorm=1.477, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.4, wall=18105
2023-09-06 06:17:48 | INFO | train_inner | epoch 016:    149 / 1191 loss=2.575, trans_loss=5.627, nll_loss=3.102, w2v_ctc_loss=0.956, task_loss=3.16, task_loss_gen=4.329, contrastive_loss=0, total=6745.67, n_correct=2739.99, ppl=8.59, accuracy=40.619, wps=18517.7, ups=1.37, wpb=13491.3, bsz=447, num_updates=18000, lr=0.000105409, gnorm=2.092, clip=1, loss_scale=0.5, train_wall=72, gb_free=12.6, wall=18177
2023-09-06 06:17:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:18:24 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 5.076 | trans_loss 6.771 | nll_loss 4.537 | w2v_ctc_loss 1.623 | task_loss 12.674 | task_loss_gen 11.639 | contrastive_loss 0 | total 6138.43 | n_correct 2493.14 | ppl 23.22 | accuracy 40.615 | uer 25.719 | wer 27.367 | raw_wer 27.367 | bleu 0.26 | wps 1508.7 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 0.31
2023-09-06 06:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-09-06 06:18:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 06:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 06:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 0.26) (writing took 8.767071555019356 seconds)
2023-09-06 06:19:46 | INFO | train_inner | epoch 016:    249 / 1191 loss=2.576, trans_loss=5.629, nll_loss=3.104, w2v_ctc_loss=0.959, task_loss=3.24, task_loss_gen=4.303, contrastive_loss=0, total=6687.43, n_correct=2708.79, ppl=8.6, accuracy=40.506, wps=11334.6, ups=0.85, wpb=13374.9, bsz=441.7, num_updates=18100, lr=0.000105118, gnorm=1.605, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.9, wall=18296
2023-09-06 06:20:58 | INFO | train_inner | epoch 016:    349 / 1191 loss=2.57, trans_loss=5.628, nll_loss=3.104, w2v_ctc_loss=0.953, task_loss=3.05, task_loss_gen=4.037, contrastive_loss=0, total=6770.99, n_correct=2752.25, ppl=8.6, accuracy=40.648, wps=18839, ups=1.39, wpb=13542, bsz=463.4, num_updates=18200, lr=0.000104828, gnorm=1.396, clip=1, loss_scale=0.5, train_wall=71, gb_free=13.6, wall=18367
2023-09-06 06:22:10 | INFO | train_inner | epoch 016:    449 / 1191 loss=2.574, trans_loss=5.631, nll_loss=3.107, w2v_ctc_loss=0.951, task_loss=3.059, task_loss_gen=4.165, contrastive_loss=0, total=6692.76, n_correct=2711.26, ppl=8.61, accuracy=40.51, wps=18542.1, ups=1.39, wpb=13385.5, bsz=451.7, num_updates=18300, lr=0.000104542, gnorm=1.612, clip=1, loss_scale=0.5, train_wall=72, gb_free=12.3, wall=18440
2023-09-06 06:23:23 | INFO | train_inner | epoch 016:    549 / 1191 loss=2.57, trans_loss=5.625, nll_loss=3.099, w2v_ctc_loss=0.939, task_loss=3.209, task_loss_gen=4.394, contrastive_loss=0, total=6668.49, n_correct=2699.45, ppl=8.57, accuracy=40.481, wps=18290.7, ups=1.37, wpb=13337, bsz=440.7, num_updates=18400, lr=0.000104257, gnorm=1.896, clip=1, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=18513
2023-09-06 06:24:36 | INFO | train_inner | epoch 016:    649 / 1191 loss=2.57, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.956, task_loss=3.152, task_loss_gen=4.216, contrastive_loss=0, total=6705.69, n_correct=2731.1, ppl=8.56, accuracy=40.728, wps=18287.8, ups=1.36, wpb=13411.4, bsz=458.3, num_updates=18500, lr=0.000103975, gnorm=1.548, clip=0, loss_scale=0.5, train_wall=73, gb_free=10.5, wall=18586
2023-09-06 06:25:48 | INFO | train_inner | epoch 016:    749 / 1191 loss=2.576, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.963, task_loss=3.099, task_loss_gen=4.381, contrastive_loss=0, total=6640.16, n_correct=2696.17, ppl=8.56, accuracy=40.604, wps=18337.9, ups=1.38, wpb=13280.3, bsz=442.1, num_updates=18600, lr=0.000103695, gnorm=1.716, clip=0, loss_scale=0.5, train_wall=72, gb_free=12, wall=18658
2023-09-06 06:27:01 | INFO | train_inner | epoch 016:    849 / 1191 loss=2.585, trans_loss=5.629, nll_loss=3.104, w2v_ctc_loss=0.994, task_loss=3.048, task_loss_gen=4.393, contrastive_loss=0, total=6703.01, n_correct=2718.58, ppl=8.6, accuracy=40.558, wps=18363.4, ups=1.37, wpb=13406, bsz=444.4, num_updates=18700, lr=0.000103418, gnorm=2.045, clip=3, loss_scale=0.5, train_wall=72, gb_free=14.8, wall=18731
2023-09-06 06:28:14 | INFO | train_inner | epoch 016:    949 / 1191 loss=2.594, trans_loss=5.631, nll_loss=3.108, w2v_ctc_loss=1.027, task_loss=2.722, task_loss_gen=4.189, contrastive_loss=0, total=6726.21, n_correct=2727.7, ppl=8.62, accuracy=40.553, wps=18555.3, ups=1.38, wpb=13452.4, bsz=463.7, num_updates=18800, lr=0.000103142, gnorm=2.99, clip=6, loss_scale=0.5, train_wall=72, gb_free=12.7, wall=18804
2023-09-06 06:29:27 | INFO | train_inner | epoch 016:   1049 / 1191 loss=2.588, trans_loss=5.624, nll_loss=3.097, w2v_ctc_loss=1.02, task_loss=2.779, task_loss_gen=4.286, contrastive_loss=0, total=6699.97, n_correct=2724.97, ppl=8.56, accuracy=40.671, wps=18375.2, ups=1.37, wpb=13399.9, bsz=460.9, num_updates=18900, lr=0.000102869, gnorm=1.451, clip=1, loss_scale=1, train_wall=72, gb_free=14.2, wall=18877
2023-09-06 06:30:40 | INFO | train_inner | epoch 016:   1149 / 1191 loss=2.567, trans_loss=5.624, nll_loss=3.098, w2v_ctc_loss=0.96, task_loss=2.492, task_loss_gen=4.213, contrastive_loss=0, total=6782.02, n_correct=2764.31, ppl=8.56, accuracy=40.759, wps=18468.9, ups=1.36, wpb=13564, bsz=474.4, num_updates=19000, lr=0.000102598, gnorm=1.036, clip=0, loss_scale=1, train_wall=73, gb_free=12.8, wall=18950
2023-09-06 06:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:31:45 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 5.08 | trans_loss 6.767 | nll_loss 4.537 | w2v_ctc_loss 1.643 | task_loss 9.738 | task_loss_gen 12.02 | contrastive_loss 0 | total 6138.43 | n_correct 2490.14 | ppl 23.22 | accuracy 40.566 | uer 26.529 | wer 28.141 | raw_wer 28.141 | bleu 0.34 | wps 1624.7 | wpb 6138.4 | bsz 201.1 | num_updates 19042 | best_bleu 0.34
2023-09-06 06:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 19042 updates
2023-09-06 06:31:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 06:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 16 @ 19042 updates, score 0.34) (writing took 13.521773665910587 seconds)
2023-09-06 06:31:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-06 06:31:59 | INFO | train | epoch 016 | loss 2.577 | trans_loss 5.627 | nll_loss 3.102 | w2v_ctc_loss 0.971 | task_loss 3.004 | task_loss_gen 4.281 | contrastive_loss 0 | total 6703.69 | n_correct 2721.95 | ppl 8.58 | accuracy 40.604 | wps 16518.8 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 19042 | lr 0.000102485 | gnorm 1.785 | clip 1.3 | loss_scale 1 | train_wall 858 | gb_free 13.6 | wall 19029
2023-09-06 06:31:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:31:59 | INFO | fairseq.trainer | begin training epoch 17
2023-09-06 06:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:32:48 | INFO | train_inner | epoch 017:     58 / 1191 loss=2.584, trans_loss=5.62, nll_loss=3.092, w2v_ctc_loss=1.002, task_loss=2.827, task_loss_gen=4.52, contrastive_loss=0, total=6627.43, n_correct=2697.89, ppl=8.53, accuracy=40.708, wps=10357.6, ups=0.78, wpb=13254.9, bsz=443.1, num_updates=19100, lr=0.000102329, gnorm=2.198, clip=3, loss_scale=1, train_wall=72, gb_free=14.2, wall=19078
2023-09-06 06:34:01 | INFO | train_inner | epoch 017:    158 / 1191 loss=2.579, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=0.998, task_loss=2.763, task_loss_gen=4.394, contrastive_loss=0, total=6710.52, n_correct=2741.06, ppl=8.48, accuracy=40.847, wps=18521.7, ups=1.38, wpb=13421, bsz=454.4, num_updates=19200, lr=0.000102062, gnorm=1.306, clip=1, loss_scale=1, train_wall=72, gb_free=14, wall=19151
2023-09-06 06:35:13 | INFO | train_inner | epoch 017:    258 / 1191 loss=2.578, trans_loss=5.611, nll_loss=3.081, w2v_ctc_loss=0.999, task_loss=2.772, task_loss_gen=4.161, contrastive_loss=0, total=6792.28, n_correct=2775.57, ppl=8.46, accuracy=40.864, wps=18759.6, ups=1.38, wpb=13584.6, bsz=466.5, num_updates=19300, lr=0.000101797, gnorm=1.987, clip=2, loss_scale=1, train_wall=72, gb_free=13.6, wall=19223
2023-09-06 06:36:26 | INFO | train_inner | epoch 017:    358 / 1191 loss=2.577, trans_loss=5.619, nll_loss=3.092, w2v_ctc_loss=0.977, task_loss=3.175, task_loss_gen=4.369, contrastive_loss=0, total=6640.64, n_correct=2704.12, ppl=8.53, accuracy=40.721, wps=18286, ups=1.38, wpb=13281.3, bsz=444.5, num_updates=19400, lr=0.000101535, gnorm=1.159, clip=0, loss_scale=1, train_wall=72, gb_free=11.8, wall=19296
2023-09-06 06:37:38 | INFO | train_inner | epoch 017:    458 / 1191 loss=2.567, trans_loss=5.614, nll_loss=3.085, w2v_ctc_loss=0.95, task_loss=3.221, task_loss_gen=4.338, contrastive_loss=0, total=6716.56, n_correct=2739.63, ppl=8.49, accuracy=40.789, wps=18563.4, ups=1.38, wpb=13433.1, bsz=446.4, num_updates=19500, lr=0.000101274, gnorm=1.068, clip=0, loss_scale=1, train_wall=72, gb_free=14.5, wall=19368
2023-09-06 06:38:51 | INFO | train_inner | epoch 017:    558 / 1191 loss=2.575, trans_loss=5.621, nll_loss=3.094, w2v_ctc_loss=0.963, task_loss=3.092, task_loss_gen=4.431, contrastive_loss=0, total=6670.63, n_correct=2711.67, ppl=8.54, accuracy=40.651, wps=18336.9, ups=1.37, wpb=13341.3, bsz=439.3, num_updates=19600, lr=0.000101015, gnorm=1.255, clip=0, loss_scale=1, train_wall=72, gb_free=14.1, wall=19441
2023-09-06 06:40:03 | INFO | train_inner | epoch 017:    658 / 1191 loss=2.568, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=0.964, task_loss=2.799, task_loss_gen=4.229, contrastive_loss=0, total=6688.85, n_correct=2730.86, ppl=8.47, accuracy=40.827, wps=18581.8, ups=1.39, wpb=13377.7, bsz=461.1, num_updates=19700, lr=0.000100759, gnorm=1.168, clip=0, loss_scale=1, train_wall=71, gb_free=12.8, wall=19513
2023-09-06 06:41:15 | INFO | train_inner | epoch 017:    758 / 1191 loss=2.573, trans_loss=5.625, nll_loss=3.099, w2v_ctc_loss=0.942, task_loss=3.215, task_loss_gen=4.611, contrastive_loss=0, total=6639.61, n_correct=2688.8, ppl=8.57, accuracy=40.496, wps=18325, ups=1.38, wpb=13279.2, bsz=425.8, num_updates=19800, lr=0.000100504, gnorm=1.034, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=19585
2023-09-06 06:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 06:42:29 | INFO | train_inner | epoch 017:    859 / 1191 loss=2.573, trans_loss=5.615, nll_loss=3.087, w2v_ctc_loss=0.967, task_loss=3.031, task_loss_gen=4.594, contrastive_loss=0, total=6638.86, n_correct=2708.29, ppl=8.5, accuracy=40.795, wps=18071, ups=1.36, wpb=13277.7, bsz=442.3, num_updates=19900, lr=0.000100251, gnorm=2.172, clip=3, loss_scale=0.5, train_wall=73, gb_free=14.1, wall=19659
2023-09-06 06:43:41 | INFO | train_inner | epoch 017:    959 / 1191 loss=2.573, trans_loss=5.611, nll_loss=3.082, w2v_ctc_loss=1, task_loss=2.695, task_loss_gen=3.796, contrastive_loss=0, total=6802.45, n_correct=2784.65, ppl=8.47, accuracy=40.936, wps=18786.2, ups=1.38, wpb=13604.9, bsz=496.6, num_updates=20000, lr=0.0001, gnorm=3.958, clip=7, loss_scale=0.5, train_wall=72, gb_free=14.4, wall=19731
2023-09-06 06:43:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 06:44:15 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.071 | trans_loss 6.765 | nll_loss 4.531 | w2v_ctc_loss 1.62 | task_loss 9.847 | task_loss_gen 12.261 | contrastive_loss 0 | total 6138.43 | n_correct 2493.71 | ppl 23.12 | accuracy 40.625 | uer 27.059 | wer 28.698 | raw_wer 28.698 | bleu 0.23 | wps 1678.9 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 0.34
2023-09-06 06:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-09-06 06:44:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 06:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 06:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 0.23) (writing took 10.74252112605609 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 06:45:39 | INFO | train_inner | epoch 017:   1059 / 1191 loss=2.589, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=1.031, task_loss=3.007, task_loss_gen=4.337, contrastive_loss=0, total=6661.9, n_correct=2719.45, ppl=8.47, accuracy=40.821, wps=11364.2, ups=0.85, wpb=13323.8, bsz=443.5, num_updates=20100, lr=9.97509e-05, gnorm=3.101, clip=4, loss_scale=0.5, train_wall=72, gb_free=14.7, wall=19848
2023-09-06 06:46:51 | INFO | train_inner | epoch 017:   1159 / 1191 loss=2.589, trans_loss=5.615, nll_loss=3.087, w2v_ctc_loss=1.028, task_loss=3.075, task_loss_gen=4.285, contrastive_loss=0, total=6784.06, n_correct=2769.59, ppl=8.5, accuracy=40.825, wps=18647.2, ups=1.37, wpb=13568.1, bsz=456.6, num_updates=20200, lr=9.95037e-05, gnorm=2.605, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.5, wall=19921
2023-09-06 06:47:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
2023-09-06 06:47:50 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 5.075 | trans_loss 6.757 | nll_loss 4.523 | w2v_ctc_loss 1.65 | task_loss 23.174 | task_loss_gen 14.443 | contrastive_loss 0 | total 6138.43 | n_correct 2494.57 | ppl 22.99 | accuracy 40.639 | uer 26.101 | wer 27.672 | raw_wer 27.672 | bleu 0.24 | wps 1560.3 | wpb 6138.4 | bsz 201.1 | num_updates 20232 | best_bleu 0.34
2023-09-06 06:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20232 updates
2023-09-06 06:47:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt
2023-09-06 06:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt
2023-09-06 06:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2408.pt (epoch 17 @ 20232 updates, score 0.24) (writing took 7.84795209497679 seconds)
2023-09-06 06:47:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-06 06:47:58 | INFO | train | epoch 017 | loss 2.577 | trans_loss 5.616 | nll_loss 3.087 | w2v_ctc_loss 0.986 | task_loss 2.969 | task_loss_gen 4.318 | contrastive_loss 0 | total 6703.76 | n_correct 2733.59 | ppl 8.5 | accuracy 40.777 | wps 16625.3 | ups 1.24 | wpb 13407.5 | bsz 452.2 | num_updates 20232 | lr 9.9425e-05 | gnorm 1.923 | clip 1.8 | loss_scale 0.5 | train_wall 856 | gb_free 14.2 | wall 19988
2023-09-06 06:47:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 06:47:59 | INFO | fairseq.trainer | begin training epoch 18
2023-09-06 06:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 06:48:55 | INFO | train_inner | epoch 018:     68 / 1191 loss=2.573, trans_loss=5.607, nll_loss=3.077, w2v_ctc_loss=0.983, task_loss=3.06, task_loss_gen=4.135, contrastive_loss=0, total=6778.58, n_correct=2772.18, ppl=8.44, accuracy=40.896, wps=10946.6, ups=0.81, wpb=13557.2, bsz=458.2, num_updates=20300, lr=9.92583e-05, gnorm=2.468, clip=1, loss_scale=0.5, train_wall=71, gb_free=14.3, wall=20045
2023-09-06 06:50:08 | INFO | train_inner | epoch 018:    168 / 1191 loss=2.584, trans_loss=5.611, nll_loss=3.081, w2v_ctc_loss=1.002, task_loss=3.724, task_loss_gen=4.696, contrastive_loss=0, total=6623.23, n_correct=2697.51, ppl=8.46, accuracy=40.728, wps=18163.6, ups=1.37, wpb=13246.5, bsz=419.3, num_updates=20400, lr=9.90148e-05, gnorm=2.53, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=20118
2023-09-06 06:51:21 | INFO | train_inner | epoch 018:    268 / 1191 loss=2.581, trans_loss=5.612, nll_loss=3.083, w2v_ctc_loss=1.003, task_loss=3.006, task_loss_gen=4.554, contrastive_loss=0, total=6620.23, n_correct=2700.63, ppl=8.47, accuracy=40.794, wps=18074.4, ups=1.37, wpb=13240.5, bsz=447.8, num_updates=20500, lr=9.8773e-05, gnorm=2.609, clip=1, loss_scale=0.5, train_wall=73, gb_free=12.7, wall=20191
2023-09-06 06:52:34 | INFO | train_inner | epoch 018:    368 / 1191 loss=2.583, trans_loss=5.606, nll_loss=3.075, w2v_ctc_loss=1.028, task_loss=2.768, task_loss_gen=4.146, contrastive_loss=0, total=6770.44, n_correct=2774.31, ppl=8.43, accuracy=40.977, wps=18580.8, ups=1.37, wpb=13540.9, bsz=469, num_updates=20600, lr=9.85329e-05, gnorm=2.543, clip=3, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=20264
2023-09-06 06:53:46 | INFO | train_inner | epoch 018:    468 / 1191 loss=2.607, trans_loss=5.614, nll_loss=3.085, w2v_ctc_loss=1.091, task_loss=3.013, task_loss_gen=4.325, contrastive_loss=0, total=6684.28, n_correct=2723.96, ppl=8.49, accuracy=40.752, wps=18505.6, ups=1.38, wpb=13368.6, bsz=449.9, num_updates=20700, lr=9.82946e-05, gnorm=2.791, clip=3, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=20336
2023-09-06 06:54:59 | INFO | train_inner | epoch 018:    568 / 1191 loss=2.588, trans_loss=5.608, nll_loss=3.078, w2v_ctc_loss=1.043, task_loss=2.812, task_loss_gen=3.98, contrastive_loss=0, total=6821.08, n_correct=2790.59, ppl=8.44, accuracy=40.911, wps=18868, ups=1.38, wpb=13642.2, bsz=478.3, num_updates=20800, lr=9.80581e-05, gnorm=2.116, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.9, wall=20409
2023-09-06 06:56:11 | INFO | train_inner | epoch 018:    668 / 1191 loss=2.602, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=1.059, task_loss=3.086, task_loss_gen=4.674, contrastive_loss=0, total=6588.48, n_correct=2683.32, ppl=8.48, accuracy=40.727, wps=18338.3, ups=1.39, wpb=13177, bsz=429.5, num_updates=20900, lr=9.78232e-05, gnorm=2.81, clip=3, loss_scale=0.5, train_wall=71, gb_free=11, wall=20480
2023-09-06 06:57:24 | INFO | train_inner | epoch 018:    768 / 1191 loss=2.576, trans_loss=5.612, nll_loss=3.082, w2v_ctc_loss=1.001, task_loss=2.911, task_loss_gen=4.069, contrastive_loss=0, total=6821.72, n_correct=2788.83, ppl=8.47, accuracy=40.882, wps=18609.1, ups=1.36, wpb=13643.4, bsz=469.2, num_updates=21000, lr=9.759e-05, gnorm=1.742, clip=1, loss_scale=0.5, train_wall=73, gb_free=12.7, wall=20554
2023-09-06 06:58:37 | INFO | train_inner | epoch 018:    868 / 1191 loss=2.577, trans_loss=5.612, nll_loss=3.082, w2v_ctc_loss=0.993, task_loss=3.13, task_loss_gen=4.351, contrastive_loss=0, total=6705.27, n_correct=2739.14, ppl=8.47, accuracy=40.851, wps=18353.6, ups=1.37, wpb=13410.5, bsz=452.9, num_updates=21100, lr=9.73585e-05, gnorm=2.192, clip=2, loss_scale=0.5, train_wall=72, gb_free=13.1, wall=20627
2023-09-06 06:59:49 | INFO | train_inner | epoch 018:    968 / 1191 loss=2.562, trans_loss=5.608, nll_loss=3.077, w2v_ctc_loss=0.952, task_loss=2.889, task_loss_gen=4.117, contrastive_loss=0, total=6746.67, n_correct=2762.49, ppl=8.44, accuracy=40.946, wps=18656.2, ups=1.38, wpb=13493.3, bsz=463.4, num_updates=21200, lr=9.71286e-05, gnorm=1.225, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.4, wall=20699
2023-09-06 07:01:01 | INFO | train_inner | epoch 018:   1068 / 1191 loss=2.564, trans_loss=5.613, nll_loss=3.084, w2v_ctc_loss=0.942, task_loss=3.113, task_loss_gen=4.48, contrastive_loss=0, total=6593.82, n_correct=2695.05, ppl=8.48, accuracy=40.872, wps=18424.8, ups=1.4, wpb=13187.6, bsz=430.3, num_updates=21300, lr=9.69003e-05, gnorm=1.495, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.2, wall=20771
2023-09-06 07:02:14 | INFO | train_inner | epoch 018:   1168 / 1191 loss=2.548, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.914, task_loss=2.948, task_loss_gen=4.236, contrastive_loss=0, total=6737.04, n_correct=2765.41, ppl=8.42, accuracy=41.048, wps=18496.1, ups=1.37, wpb=13474.1, bsz=461.3, num_updates=21400, lr=9.66736e-05, gnorm=1.268, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.1, wall=20844
2023-09-06 07:02:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:03:05 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 5.014 | trans_loss 6.746 | nll_loss 4.505 | w2v_ctc_loss 1.472 | task_loss 10.43 | task_loss_gen 11.782 | contrastive_loss 0 | total 6138.43 | n_correct 2509.86 | ppl 22.7 | accuracy 40.888 | uer 24.194 | wer 25.675 | raw_wer 25.675 | bleu 0.26 | wps 1599.4 | wpb 6138.4 | bsz 201.1 | num_updates 21423 | best_bleu 0.34
2023-09-06 07:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21423 updates
2023-09-06 07:03:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt
2023-09-06 07:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt
2023-09-06 07:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2602.pt (epoch 18 @ 21423 updates, score 0.26) (writing took 8.109685115050524 seconds)
2023-09-06 07:03:14 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-06 07:03:14 | INFO | train | epoch 018 | loss 2.578 | trans_loss 5.61 | nll_loss 3.08 | w2v_ctc_loss 0.999 | task_loss 3.031 | task_loss_gen 4.304 | contrastive_loss 0 | total 6703.69 | n_correct 2739.91 | ppl 8.46 | accuracy 40.872 | wps 17441.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 21423 | lr 9.66217e-05 | gnorm 2.104 | clip 1.3 | loss_scale 0.5 | train_wall 857 | gb_free 13.8 | wall 20904
2023-09-06 07:03:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:03:14 | INFO | fairseq.trainer | begin training epoch 19
2023-09-06 07:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:04:18 | INFO | train_inner | epoch 019:     77 / 1191 loss=2.553, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.91, task_loss=3.224, task_loss_gen=4.514, contrastive_loss=0, total=6595.79, n_correct=2695.35, ppl=8.42, accuracy=40.865, wps=10583.1, ups=0.8, wpb=13191.6, bsz=428, num_updates=21500, lr=9.64486e-05, gnorm=1.255, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.4, wall=20968
2023-09-06 07:05:31 | INFO | train_inner | epoch 019:    177 / 1191 loss=2.551, trans_loss=5.602, nll_loss=3.069, w2v_ctc_loss=0.916, task_loss=3.053, task_loss_gen=4.345, contrastive_loss=0, total=6660.08, n_correct=2730.11, ppl=8.39, accuracy=40.992, wps=18416.2, ups=1.38, wpb=13320.2, bsz=442, num_updates=21600, lr=9.6225e-05, gnorm=1.438, clip=0, loss_scale=0.5, train_wall=72, gb_free=11, wall=21041
2023-09-06 07:06:44 | INFO | train_inner | epoch 019:    277 / 1191 loss=2.54, trans_loss=5.597, nll_loss=3.061, w2v_ctc_loss=0.897, task_loss=2.899, task_loss_gen=4.023, contrastive_loss=0, total=6784.94, n_correct=2790.84, ppl=8.35, accuracy=41.133, wps=18619.8, ups=1.37, wpb=13569.9, bsz=465.1, num_updates=21700, lr=9.60031e-05, gnorm=1.327, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.8, wall=21113
2023-09-06 07:07:56 | INFO | train_inner | epoch 019:    377 / 1191 loss=2.541, trans_loss=5.606, nll_loss=3.074, w2v_ctc_loss=0.886, task_loss=2.947, task_loss_gen=4.161, contrastive_loss=0, total=6697.58, n_correct=2743.48, ppl=8.42, accuracy=40.962, wps=18628, ups=1.39, wpb=13395.2, bsz=449.9, num_updates=21800, lr=9.57826e-05, gnorm=1.163, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.7, wall=21185
2023-09-06 07:09:08 | INFO | train_inner | epoch 019:    477 / 1191 loss=2.543, trans_loss=5.601, nll_loss=3.068, w2v_ctc_loss=0.907, task_loss=3.073, task_loss_gen=4.169, contrastive_loss=0, total=6742.97, n_correct=2774.05, ppl=8.38, accuracy=41.14, wps=18565.1, ups=1.38, wpb=13485.9, bsz=467, num_updates=21900, lr=9.55637e-05, gnorm=1.335, clip=0, loss_scale=1, train_wall=72, gb_free=8.9, wall=21258
2023-09-06 07:10:21 | INFO | train_inner | epoch 019:    577 / 1191 loss=2.534, trans_loss=5.601, nll_loss=3.069, w2v_ctc_loss=0.882, task_loss=3.09, task_loss_gen=4.159, contrastive_loss=0, total=6787.18, n_correct=2787.44, ppl=8.39, accuracy=41.069, wps=18616.9, ups=1.37, wpb=13574.4, bsz=467.7, num_updates=22000, lr=9.53463e-05, gnorm=1.291, clip=0, loss_scale=1, train_wall=72, gb_free=13, wall=21331
2023-09-06 07:10:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:10:56 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 5.013 | trans_loss 6.739 | nll_loss 4.499 | w2v_ctc_loss 1.482 | task_loss 11.987 | task_loss_gen 11.848 | contrastive_loss 0 | total 6138.43 | n_correct 2513.14 | ppl 22.61 | accuracy 40.941 | uer 23.825 | wer 25.218 | raw_wer 25.218 | bleu 0.36 | wps 1591.9 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 0.36
2023-09-06 07:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-09-06 07:10:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 07:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 07:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 0.36) (writing took 13.556856640032493 seconds)
2023-09-06 07:12:22 | INFO | train_inner | epoch 019:    677 / 1191 loss=2.539, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.895, task_loss=3.128, task_loss_gen=4.336, contrastive_loss=0, total=6625.21, n_correct=2726.18, ppl=8.32, accuracy=41.149, wps=10943, ups=0.83, wpb=13250.4, bsz=449.1, num_updates=22100, lr=9.51303e-05, gnorm=1.197, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=21452
2023-09-06 07:13:35 | INFO | train_inner | epoch 019:    777 / 1191 loss=2.545, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.918, task_loss=3.229, task_loss_gen=4.132, contrastive_loss=0, total=6792, n_correct=2792.91, ppl=8.32, accuracy=41.121, wps=18732.1, ups=1.38, wpb=13584, bsz=466.9, num_updates=22200, lr=9.49158e-05, gnorm=1.151, clip=0, loss_scale=1, train_wall=72, gb_free=9.9, wall=21525
2023-09-06 07:14:47 | INFO | train_inner | epoch 019:    877 / 1191 loss=2.558, trans_loss=5.597, nll_loss=3.064, w2v_ctc_loss=0.94, task_loss=3.143, task_loss_gen=4.507, contrastive_loss=0, total=6620.15, n_correct=2714.44, ppl=8.36, accuracy=41.003, wps=18232.6, ups=1.38, wpb=13240.3, bsz=439.6, num_updates=22300, lr=9.47027e-05, gnorm=1.166, clip=0, loss_scale=1, train_wall=72, gb_free=12.2, wall=21597
2023-09-06 07:16:00 | INFO | train_inner | epoch 019:    977 / 1191 loss=2.553, trans_loss=5.593, nll_loss=3.058, w2v_ctc_loss=0.932, task_loss=2.964, task_loss_gen=4.607, contrastive_loss=0, total=6616.49, n_correct=2718.25, ppl=8.33, accuracy=41.083, wps=18305.8, ups=1.38, wpb=13233, bsz=435.6, num_updates=22400, lr=9.44911e-05, gnorm=1.249, clip=0, loss_scale=1, train_wall=72, gb_free=14.2, wall=21669
2023-09-06 07:17:12 | INFO | train_inner | epoch 019:   1077 / 1191 loss=2.549, trans_loss=5.599, nll_loss=3.066, w2v_ctc_loss=0.915, task_loss=2.974, task_loss_gen=4.284, contrastive_loss=0, total=6732.97, n_correct=2764.36, ppl=8.37, accuracy=41.057, wps=18599.2, ups=1.38, wpb=13465.9, bsz=454.1, num_updates=22500, lr=9.42809e-05, gnorm=1.356, clip=0, loss_scale=1, train_wall=72, gb_free=12.9, wall=21742
2023-09-06 07:18:26 | INFO | train_inner | epoch 019:   1177 / 1191 loss=2.542, trans_loss=5.601, nll_loss=3.068, w2v_ctc_loss=0.903, task_loss=2.837, task_loss_gen=4.185, contrastive_loss=0, total=6792.13, n_correct=2793.12, ppl=8.39, accuracy=41.123, wps=18376.2, ups=1.35, wpb=13584.3, bsz=462.7, num_updates=22600, lr=9.40721e-05, gnorm=0.884, clip=0, loss_scale=1, train_wall=73, gb_free=13.8, wall=21816
2023-09-06 07:18:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:19:12 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 5.015 | trans_loss 6.736 | nll_loss 4.495 | w2v_ctc_loss 1.498 | task_loss 15.185 | task_loss_gen 12.217 | contrastive_loss 0 | total 6138.43 | n_correct 2513.29 | ppl 22.55 | accuracy 40.943 | uer 24.451 | wer 26.177 | raw_wer 26.177 | bleu 0.46 | wps 1516 | wpb 6138.4 | bsz 201.1 | num_updates 22614 | best_bleu 0.46
2023-09-06 07:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22614 updates
2023-09-06 07:19:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 07:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 07:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 19 @ 22614 updates, score 0.46) (writing took 12.896276931045577 seconds)
2023-09-06 07:19:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-06 07:19:25 | INFO | train | epoch 019 | loss 2.545 | trans_loss 5.599 | nll_loss 3.065 | w2v_ctc_loss 0.909 | task_loss 3.049 | task_loss_gen 4.289 | contrastive_loss 0 | total 6703.69 | n_correct 2752.68 | ppl 8.37 | accuracy 41.062 | wps 16439.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 22614 | lr 9.4043e-05 | gnorm 1.232 | clip 0 | loss_scale 1 | train_wall 858 | gb_free 14.3 | wall 21875
2023-09-06 07:19:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:19:25 | INFO | fairseq.trainer | begin training epoch 20
2023-09-06 07:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:20:35 | INFO | train_inner | epoch 020:     86 / 1191 loss=2.534, trans_loss=5.582, nll_loss=3.044, w2v_ctc_loss=0.887, task_loss=3.324, task_loss_gen=4.431, contrastive_loss=0, total=6677.37, n_correct=2759.26, ppl=8.25, accuracy=41.323, wps=10327, ups=0.77, wpb=13354.7, bsz=443.1, num_updates=22700, lr=9.38647e-05, gnorm=0.894, clip=0, loss_scale=1, train_wall=72, gb_free=13.7, wall=21945
2023-09-06 07:21:47 | INFO | train_inner | epoch 020:    186 / 1191 loss=2.535, trans_loss=5.583, nll_loss=3.046, w2v_ctc_loss=0.887, task_loss=3.129, task_loss_gen=4.453, contrastive_loss=0, total=6595.04, n_correct=2715.04, ppl=8.26, accuracy=41.168, wps=18383.4, ups=1.39, wpb=13190.1, bsz=437.3, num_updates=22800, lr=9.36586e-05, gnorm=1.086, clip=0, loss_scale=1, train_wall=71, gb_free=13.6, wall=22017
2023-09-06 07:22:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 07:23:01 | INFO | train_inner | epoch 020:    287 / 1191 loss=2.557, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.957, task_loss=2.988, task_loss_gen=4.247, contrastive_loss=0, total=6774.09, n_correct=2792.5, ppl=8.32, accuracy=41.223, wps=18436.8, ups=1.36, wpb=13548.2, bsz=460.8, num_updates=22900, lr=9.34539e-05, gnorm=2.336, clip=4, loss_scale=0.5, train_wall=73, gb_free=13.2, wall=22090
2023-09-06 07:24:12 | INFO | train_inner | epoch 020:    387 / 1191 loss=2.552, trans_loss=5.592, nll_loss=3.057, w2v_ctc_loss=0.948, task_loss=3.025, task_loss_gen=4.01, contrastive_loss=0, total=6796.65, n_correct=2804.85, ppl=8.32, accuracy=41.268, wps=18928.4, ups=1.39, wpb=13593.3, bsz=467.1, num_updates=23000, lr=9.32505e-05, gnorm=2.143, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.1, wall=22162
2023-09-06 07:25:25 | INFO | train_inner | epoch 020:    487 / 1191 loss=2.552, trans_loss=5.589, nll_loss=3.053, w2v_ctc_loss=0.938, task_loss=3.156, task_loss_gen=4.302, contrastive_loss=0, total=6661.06, n_correct=2737.71, ppl=8.3, accuracy=41.1, wps=18408.6, ups=1.38, wpb=13322.1, bsz=441.8, num_updates=23100, lr=9.30484e-05, gnorm=2.075, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.5, wall=22235
2023-09-06 07:26:37 | INFO | train_inner | epoch 020:    587 / 1191 loss=2.543, trans_loss=5.583, nll_loss=3.045, w2v_ctc_loss=0.926, task_loss=3.188, task_loss_gen=4.241, contrastive_loss=0, total=6667.89, n_correct=2757.84, ppl=8.25, accuracy=41.36, wps=18403, ups=1.38, wpb=13335.8, bsz=453.6, num_updates=23200, lr=9.28477e-05, gnorm=2.151, clip=1, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=22307
2023-09-06 07:27:49 | INFO | train_inner | epoch 020:    687 / 1191 loss=2.538, trans_loss=5.587, nll_loss=3.05, w2v_ctc_loss=0.913, task_loss=2.947, task_loss_gen=4.1, contrastive_loss=0, total=6676.16, n_correct=2756.01, ppl=8.28, accuracy=41.281, wps=18507.1, ups=1.39, wpb=13352.3, bsz=462.9, num_updates=23300, lr=9.26482e-05, gnorm=2.041, clip=2, loss_scale=0.5, train_wall=72, gb_free=12.8, wall=22379
2023-09-06 07:29:01 | INFO | train_inner | epoch 020:    787 / 1191 loss=2.544, trans_loss=5.591, nll_loss=3.056, w2v_ctc_loss=0.922, task_loss=2.862, task_loss_gen=4.027, contrastive_loss=0, total=6770.38, n_correct=2795.61, ppl=8.31, accuracy=41.292, wps=18824.4, ups=1.39, wpb=13540.8, bsz=460.7, num_updates=23400, lr=9.245e-05, gnorm=1.5, clip=0, loss_scale=0.5, train_wall=71, gb_free=13.1, wall=22451
2023-09-06 07:30:14 | INFO | train_inner | epoch 020:    887 / 1191 loss=2.552, trans_loss=5.597, nll_loss=3.062, w2v_ctc_loss=0.93, task_loss=3.125, task_loss_gen=4.344, contrastive_loss=0, total=6728.68, n_correct=2763.65, ppl=8.35, accuracy=41.073, wps=18593.3, ups=1.38, wpb=13457.4, bsz=446.4, num_updates=23500, lr=9.22531e-05, gnorm=1.989, clip=1, loss_scale=0.5, train_wall=72, gb_free=8.7, wall=22524
2023-09-06 07:31:27 | INFO | train_inner | epoch 020:    987 / 1191 loss=2.553, trans_loss=5.595, nll_loss=3.061, w2v_ctc_loss=0.928, task_loss=3.552, task_loss_gen=4.587, contrastive_loss=0, total=6655.57, n_correct=2732.94, ppl=8.35, accuracy=41.062, wps=18240.1, ups=1.37, wpb=13311.1, bsz=431.8, num_updates=23600, lr=9.20575e-05, gnorm=2.066, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.3, wall=22596
2023-09-06 07:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 07:32:40 | INFO | train_inner | epoch 020:   1088 / 1191 loss=2.559, trans_loss=5.601, nll_loss=3.067, w2v_ctc_loss=0.958, task_loss=2.882, task_loss_gen=4.193, contrastive_loss=0, total=6759.71, n_correct=2780.13, ppl=8.38, accuracy=41.128, wps=18472.2, ups=1.37, wpb=13519.4, bsz=458.8, num_updates=23700, lr=9.1863e-05, gnorm=4.253, clip=6, loss_scale=0.25, train_wall=72, gb_free=12.8, wall=22670
2023-09-06 07:33:53 | INFO | train_inner | epoch 020:   1188 / 1191 loss=2.554, trans_loss=5.605, nll_loss=3.072, w2v_ctc_loss=0.944, task_loss=3.502, task_loss_gen=4.189, contrastive_loss=0, total=6696.4, n_correct=2748.45, ppl=8.41, accuracy=41.044, wps=18305.2, ups=1.37, wpb=13392.8, bsz=460.1, num_updates=23800, lr=9.16698e-05, gnorm=3.711, clip=0, loss_scale=0.25, train_wall=73, gb_free=14.1, wall=22743
2023-09-06 07:33:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:34:29 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 5.011 | trans_loss 6.73 | nll_loss 4.481 | w2v_ctc_loss 1.5 | task_loss 21.165 | task_loss_gen 13.356 | contrastive_loss 0 | total 6138.43 | n_correct 2522.86 | ppl 22.34 | accuracy 41.099 | uer 24.248 | wer 25.958 | raw_wer 25.958 | bleu 0.25 | wps 1626.5 | wpb 6138.4 | bsz 201.1 | num_updates 23803 | best_bleu 0.46
2023-09-06 07:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23803 updates
2023-09-06 07:34:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt
2023-09-06 07:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt
2023-09-06 07:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.2506.pt (epoch 20 @ 23803 updates, score 0.25) (writing took 11.4122632490471 seconds)
2023-09-06 07:34:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-06 07:34:41 | INFO | train | epoch 020 | loss 2.548 | trans_loss 5.591 | nll_loss 3.056 | w2v_ctc_loss 0.929 | task_loss 3.14 | task_loss_gen 4.254 | contrastive_loss 0 | total 6703.9 | n_correct 2761.63 | ppl 8.31 | accuracy 41.194 | wps 17410.3 | ups 1.3 | wpb 13407.8 | bsz 452.3 | num_updates 23803 | lr 9.16641e-05 | gnorm 2.208 | clip 1.2 | loss_scale 0.25 | train_wall 855 | gb_free 15.1 | wall 22791
2023-09-06 07:34:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:34:41 | INFO | fairseq.trainer | begin training epoch 21
2023-09-06 07:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:35:58 | INFO | train_inner | epoch 021:     97 / 1191 loss=2.524, trans_loss=5.575, nll_loss=3.034, w2v_ctc_loss=0.879, task_loss=3.307, task_loss_gen=4.004, contrastive_loss=0, total=6731.66, n_correct=2798.12, ppl=8.19, accuracy=41.567, wps=10739, ups=0.8, wpb=13463.3, bsz=466.6, num_updates=23900, lr=9.14779e-05, gnorm=2.956, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.7, wall=22868
2023-09-06 07:37:10 | INFO | train_inner | epoch 021:    197 / 1191 loss=2.524, trans_loss=5.577, nll_loss=3.037, w2v_ctc_loss=0.88, task_loss=3.067, task_loss_gen=3.868, contrastive_loss=0, total=6811.2, n_correct=2826.45, ppl=8.21, accuracy=41.497, wps=18909.7, ups=1.39, wpb=13622.4, bsz=476.2, num_updates=24000, lr=9.12871e-05, gnorm=2.555, clip=0, loss_scale=0.25, train_wall=71, gb_free=14, wall=22940
2023-09-06 07:37:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:37:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 5.018 | trans_loss 6.744 | nll_loss 4.498 | w2v_ctc_loss 1.489 | task_loss 12.654 | task_loss_gen 11.615 | contrastive_loss 0 | total 6138.43 | n_correct 2515 | ppl 22.6 | accuracy 40.971 | uer 24.606 | wer 26.326 | raw_wer 26.326 | bleu 0.27 | wps 1687.1 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 0.46
2023-09-06 07:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-09-06 07:37:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 07:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 07:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 0.27) (writing took 10.762539027957246 seconds)
2023-09-06 07:39:07 | INFO | train_inner | epoch 021:    297 / 1191 loss=2.545, trans_loss=5.59, nll_loss=3.054, w2v_ctc_loss=0.908, task_loss=3.339, task_loss_gen=4.352, contrastive_loss=0, total=6641.5, n_correct=2730.15, ppl=8.3, accuracy=41.107, wps=11389.1, ups=0.86, wpb=13283, bsz=437.2, num_updates=24100, lr=9.10975e-05, gnorm=2.637, clip=0, loss_scale=0.25, train_wall=71, gb_free=10, wall=23057
2023-09-06 07:40:19 | INFO | train_inner | epoch 021:    397 / 1191 loss=2.548, trans_loss=5.591, nll_loss=3.055, w2v_ctc_loss=0.924, task_loss=3.342, task_loss_gen=4.309, contrastive_loss=0, total=6646.52, n_correct=2732.96, ppl=8.31, accuracy=41.119, wps=18365.9, ups=1.38, wpb=13293, bsz=443, num_updates=24200, lr=9.09091e-05, gnorm=2.918, clip=1, loss_scale=0.25, train_wall=72, gb_free=15, wall=23129
2023-09-06 07:41:32 | INFO | train_inner | epoch 021:    497 / 1191 loss=2.549, trans_loss=5.593, nll_loss=3.057, w2v_ctc_loss=0.911, task_loss=3.276, task_loss_gen=4.369, contrastive_loss=0, total=6696.95, n_correct=2749.14, ppl=8.32, accuracy=41.051, wps=18361, ups=1.37, wpb=13393.9, bsz=437.3, num_updates=24300, lr=9.07218e-05, gnorm=2.214, clip=0, loss_scale=0.25, train_wall=72, gb_free=10.5, wall=23202
2023-09-06 07:42:44 | INFO | train_inner | epoch 021:    597 / 1191 loss=2.557, trans_loss=5.607, nll_loss=3.074, w2v_ctc_loss=0.915, task_loss=3.519, task_loss_gen=4.547, contrastive_loss=0, total=6605.02, n_correct=2692.49, ppl=8.42, accuracy=40.764, wps=18361.4, ups=1.39, wpb=13210, bsz=423.9, num_updates=24400, lr=9.05357e-05, gnorm=2.859, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.7, wall=23274
2023-09-06 07:43:57 | INFO | train_inner | epoch 021:    697 / 1191 loss=2.529, trans_loss=5.589, nll_loss=3.052, w2v_ctc_loss=0.883, task_loss=3.026, task_loss_gen=4.056, contrastive_loss=0, total=6736.1, n_correct=2783.78, ppl=8.29, accuracy=41.326, wps=18481.5, ups=1.37, wpb=13472.2, bsz=472, num_updates=24500, lr=9.03508e-05, gnorm=2.276, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23347
2023-09-06 07:45:10 | INFO | train_inner | epoch 021:    797 / 1191 loss=2.538, trans_loss=5.598, nll_loss=3.062, w2v_ctc_loss=0.879, task_loss=3.286, task_loss_gen=4.388, contrastive_loss=0, total=6639.88, n_correct=2724.37, ppl=8.35, accuracy=41.03, wps=18292.1, ups=1.38, wpb=13279.8, bsz=443.4, num_updates=24600, lr=9.0167e-05, gnorm=2.651, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.3, wall=23420
2023-09-06 07:46:22 | INFO | train_inner | epoch 021:    897 / 1191 loss=2.532, trans_loss=5.592, nll_loss=3.056, w2v_ctc_loss=0.873, task_loss=3.137, task_loss_gen=4.127, contrastive_loss=0, total=6739.89, n_correct=2777.26, ppl=8.31, accuracy=41.206, wps=18556.8, ups=1.38, wpb=13479.8, bsz=453.1, num_updates=24700, lr=8.99843e-05, gnorm=2.247, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.7, wall=23492
2023-09-06 07:47:35 | INFO | train_inner | epoch 021:    997 / 1191 loss=2.53, trans_loss=5.594, nll_loss=3.058, w2v_ctc_loss=0.872, task_loss=3.19, task_loss_gen=4.004, contrastive_loss=0, total=6785.1, n_correct=2790.63, ppl=8.33, accuracy=41.129, wps=18652.2, ups=1.37, wpb=13570.2, bsz=461.6, num_updates=24800, lr=8.98027e-05, gnorm=3.332, clip=1, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23565
2023-09-06 07:48:48 | INFO | train_inner | epoch 021:   1097 / 1191 loss=2.531, trans_loss=5.593, nll_loss=3.057, w2v_ctc_loss=0.873, task_loss=3.042, task_loss_gen=4.018, contrastive_loss=0, total=6750.57, n_correct=2782.68, ppl=8.32, accuracy=41.221, wps=18520.8, ups=1.37, wpb=13501.1, bsz=462.1, num_updates=24900, lr=8.96221e-05, gnorm=2.441, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.2, wall=23638
2023-09-06 07:49:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 07:50:30 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.978 | trans_loss 6.723 | nll_loss 4.47 | w2v_ctc_loss 1.404 | task_loss 13.299 | task_loss_gen 11.722 | contrastive_loss 0 | total 6138.43 | n_correct 2528.71 | ppl 22.17 | accuracy 41.195 | uer 23.082 | wer 24.734 | raw_wer 24.734 | bleu 0.32 | wps 1649.4 | wpb 6138.4 | bsz 201.1 | num_updates 24994 | best_bleu 0.46
2023-09-06 07:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24994 updates
2023-09-06 07:50:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt
2023-09-06 07:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt
2023-09-06 07:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_0.3208.pt (epoch 21 @ 24994 updates, score 0.32) (writing took 7.580136829987168 seconds)
2023-09-06 07:50:38 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-06 07:50:38 | INFO | train | epoch 021 | loss 2.536 | trans_loss 5.591 | nll_loss 3.054 | w2v_ctc_loss 0.887 | task_loss 3.236 | task_loss_gen 4.187 | contrastive_loss 0 | total 6703.69 | n_correct 2760.63 | ppl 8.3 | accuracy 41.181 | wps 16678.4 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 24994 | lr 8.94535e-05 | gnorm 2.628 | clip 0.2 | loss_scale 0.25 | train_wall 856 | gb_free 13.4 | wall 23748
2023-09-06 07:50:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 07:50:38 | INFO | fairseq.trainer | begin training epoch 22
2023-09-06 07:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 07:50:50 | INFO | train_inner | epoch 022:      6 / 1191 loss=2.522, trans_loss=5.587, nll_loss=3.049, w2v_ctc_loss=0.846, task_loss=3.39, task_loss_gen=4.295, contrastive_loss=0, total=6645.47, n_correct=2736.29, ppl=8.28, accuracy=41.175, wps=10860.6, ups=0.82, wpb=13290.9, bsz=448.1, num_updates=25000, lr=8.94427e-05, gnorm=2.494, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.1, wall=23760
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 07:52:03 | INFO | train_inner | epoch 022:    106 / 1191 loss=2.514, trans_loss=5.573, nll_loss=3.031, w2v_ctc_loss=0.844, task_loss=3.264, task_loss_gen=4.048, contrastive_loss=0, total=6764.76, n_correct=2806.33, ppl=8.17, accuracy=41.485, wps=18741.3, ups=1.39, wpb=13529.5, bsz=459.7, num_updates=25100, lr=8.92644e-05, gnorm=2.724, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.3, wall=23833
2023-09-06 07:53:15 | INFO | train_inner | epoch 022:    206 / 1191 loss=2.521, trans_loss=5.581, nll_loss=3.041, w2v_ctc_loss=0.849, task_loss=3.246, task_loss_gen=4.269, contrastive_loss=0, total=6668.21, n_correct=2754.26, ppl=8.23, accuracy=41.304, wps=18375.6, ups=1.38, wpb=13336.4, bsz=445.8, num_updates=25200, lr=8.90871e-05, gnorm=2.274, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=23905
2023-09-06 07:54:28 | INFO | train_inner | epoch 022:    306 / 1191 loss=2.511, trans_loss=5.574, nll_loss=3.032, w2v_ctc_loss=0.835, task_loss=3.315, task_loss_gen=4.181, contrastive_loss=0, total=6707.19, n_correct=2782.94, ppl=8.18, accuracy=41.492, wps=18557.7, ups=1.38, wpb=13414.4, bsz=460.7, num_updates=25300, lr=8.89108e-05, gnorm=3.205, clip=1, loss_scale=0.25, train_wall=72, gb_free=12, wall=23977
2023-09-06 07:55:41 | INFO | train_inner | epoch 022:    406 / 1191 loss=2.509, trans_loss=5.572, nll_loss=3.03, w2v_ctc_loss=0.834, task_loss=3.372, task_loss_gen=4.161, contrastive_loss=0, total=6699.53, n_correct=2785.46, ppl=8.17, accuracy=41.577, wps=18344.5, ups=1.37, wpb=13399.1, bsz=461.5, num_updates=25400, lr=8.87357e-05, gnorm=3.321, clip=1, loss_scale=0.25, train_wall=72, gb_free=13.9, wall=24050
2023-09-06 07:56:53 | INFO | train_inner | epoch 022:    506 / 1191 loss=2.512, trans_loss=5.573, nll_loss=3.031, w2v_ctc_loss=0.846, task_loss=3.248, task_loss_gen=4.154, contrastive_loss=0, total=6724.31, n_correct=2799.31, ppl=8.17, accuracy=41.63, wps=18604, ups=1.38, wpb=13448.6, bsz=458.1, num_updates=25500, lr=8.85615e-05, gnorm=2.502, clip=0, loss_scale=0.25, train_wall=72, gb_free=14.1, wall=24123
2023-09-06 07:58:06 | INFO | train_inner | epoch 022:    606 / 1191 loss=2.512, trans_loss=5.577, nll_loss=3.036, w2v_ctc_loss=0.824, task_loss=3.344, task_loss_gen=4.335, contrastive_loss=0, total=6694.8, n_correct=2778.25, ppl=8.2, accuracy=41.499, wps=18330.3, ups=1.37, wpb=13389.6, bsz=444, num_updates=25600, lr=8.83883e-05, gnorm=2.513, clip=0, loss_scale=0.25, train_wall=72, gb_free=13.8, wall=24196
2023-09-06 07:59:18 | INFO | train_inner | epoch 022:    706 / 1191 loss=2.5, trans_loss=5.573, nll_loss=3.032, w2v_ctc_loss=0.806, task_loss=3.219, task_loss_gen=3.988, contrastive_loss=0, total=6721.65, n_correct=2800.33, ppl=8.18, accuracy=41.661, wps=18766, ups=1.4, wpb=13443.3, bsz=460.5, num_updates=25700, lr=8.82162e-05, gnorm=2.753, clip=0, loss_scale=0.25, train_wall=71, gb_free=13.6, wall=24267
2023-09-06 08:00:29 | INFO | train_inner | epoch 022:    806 / 1191 loss=2.501, trans_loss=5.567, nll_loss=3.024, w2v_ctc_loss=0.803, task_loss=3.442, task_loss_gen=4.385, contrastive_loss=0, total=6554.97, n_correct=2725.17, ppl=8.13, accuracy=41.574, wps=18261.8, ups=1.39, wpb=13109.9, bsz=429.5, num_updates=25800, lr=8.80451e-05, gnorm=1.61, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=24339
2023-09-06 08:01:43 | INFO | train_inner | epoch 022:    906 / 1191 loss=2.495, trans_loss=5.566, nll_loss=3.023, w2v_ctc_loss=0.8, task_loss=3.148, task_loss_gen=4.136, contrastive_loss=0, total=6727.29, n_correct=2807.05, ppl=8.13, accuracy=41.726, wps=18244.5, ups=1.36, wpb=13454.6, bsz=458.1, num_updates=25900, lr=8.7875e-05, gnorm=1.211, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.7, wall=24413
2023-09-06 08:02:56 | INFO | train_inner | epoch 022:   1006 / 1191 loss=2.49, trans_loss=5.559, nll_loss=3.014, w2v_ctc_loss=0.797, task_loss=3.032, task_loss_gen=4.046, contrastive_loss=0, total=6823.74, n_correct=2862.79, ppl=8.08, accuracy=41.953, wps=18826.1, ups=1.38, wpb=13647.5, bsz=465.7, num_updates=26000, lr=8.77058e-05, gnorm=1.067, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=24485
2023-09-06 08:02:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
2023-09-06 08:03:32 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.946 | trans_loss 6.694 | nll_loss 4.433 | w2v_ctc_loss 1.362 | task_loss 8.255 | task_loss_gen 12.386 | contrastive_loss 0 | total 6138.43 | n_correct 2571 | ppl 21.6 | accuracy 41.884 | uer 21.475 | wer 23.09 | raw_wer 23.09 | bleu 0.59 | wps 1461.1 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 0.59
2023-09-06 08:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26000 updates
2023-09-06 08:03:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 08:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 08:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_22_26000.pt (epoch 22 @ 26000 updates, score 0.59) (writing took 15.908736642915756 seconds)
2023-09-06 08:05:00 | INFO | train_inner | epoch 022:   1106 / 1191 loss=2.491, trans_loss=5.562, nll_loss=3.018, w2v_ctc_loss=0.787, task_loss=3.314, task_loss_gen=4.24, contrastive_loss=0, total=6691.44, n_correct=2800.37, ppl=8.1, accuracy=41.85, wps=10722.6, ups=0.8, wpb=13382.9, bsz=445.8, num_updates=26100, lr=8.75376e-05, gnorm=1.595, clip=0, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=24610
2023-09-06 08:06:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:06:36 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.93 | trans_loss 6.685 | nll_loss 4.425 | w2v_ctc_loss 1.329 | task_loss 10.24 | task_loss_gen 11.801 | contrastive_loss 0 | total 6138.43 | n_correct 2577.57 | ppl 21.47 | accuracy 41.991 | uer 21.574 | wer 23.083 | raw_wer 23.083 | bleu 0.65 | wps 1689.9 | wpb 6138.4 | bsz 201.1 | num_updates 26185 | best_bleu 0.65
2023-09-06 08:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26185 updates
2023-09-06 08:06:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:06:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 22 @ 26185 updates, score 0.65) (writing took 13.918930566986091 seconds)
2023-09-06 08:06:50 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-06 08:06:50 | INFO | train | epoch 022 | loss 2.504 | trans_loss 5.57 | nll_loss 3.027 | w2v_ctc_loss 0.818 | task_loss 3.27 | task_loss_gen 4.188 | contrastive_loss 0 | total 6703.69 | n_correct 2791.59 | ppl 8.15 | accuracy 41.643 | wps 16431.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 26185 | lr 8.73954e-05 | gnorm 2.184 | clip 0.2 | loss_scale 0.5 | train_wall 855 | gb_free 13.4 | wall 24720
2023-09-06 08:06:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:06:50 | INFO | fairseq.trainer | begin training epoch 23
2023-09-06 08:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:07:09 | INFO | train_inner | epoch 023:     15 / 1191 loss=2.488, trans_loss=5.557, nll_loss=3.011, w2v_ctc_loss=0.782, task_loss=3.304, task_loss_gen=4.363, contrastive_loss=0, total=6687.44, n_correct=2811.08, ppl=8.06, accuracy=42.035, wps=10399.6, ups=0.78, wpb=13374.9, bsz=437.8, num_updates=26200, lr=8.73704e-05, gnorm=1.242, clip=0, loss_scale=0.5, train_wall=72, gb_free=10.6, wall=24739
2023-09-06 08:08:22 | INFO | train_inner | epoch 023:    115 / 1191 loss=2.479, trans_loss=5.543, nll_loss=2.993, w2v_ctc_loss=0.77, task_loss=3.434, task_loss_gen=4.374, contrastive_loss=0, total=6659.81, n_correct=2805.46, ppl=7.96, accuracy=42.125, wps=18352, ups=1.38, wpb=13319.6, bsz=442.7, num_updates=26300, lr=8.72041e-05, gnorm=1.504, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.3, wall=24811
2023-09-06 08:09:35 | INFO | train_inner | epoch 023:    215 / 1191 loss=2.474, trans_loss=5.545, nll_loss=2.995, w2v_ctc_loss=0.773, task_loss=3.026, task_loss_gen=4.058, contrastive_loss=0, total=6794.98, n_correct=2876.57, ppl=7.97, accuracy=42.334, wps=18583.4, ups=1.37, wpb=13590, bsz=467.7, num_updates=26400, lr=8.70388e-05, gnorm=1.21, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.5, wall=24885
2023-09-06 08:10:47 | INFO | train_inner | epoch 023:    315 / 1191 loss=2.467, trans_loss=5.54, nll_loss=2.989, w2v_ctc_loss=0.75, task_loss=3.386, task_loss_gen=4.019, contrastive_loss=0, total=6832.59, n_correct=2894.52, ppl=7.94, accuracy=42.363, wps=18872.6, ups=1.38, wpb=13665.2, bsz=467.2, num_updates=26500, lr=8.68744e-05, gnorm=1.777, clip=0, loss_scale=0.5, train_wall=72, gb_free=15.2, wall=24957
2023-09-06 08:12:00 | INFO | train_inner | epoch 023:    415 / 1191 loss=2.481, trans_loss=5.553, nll_loss=3.005, w2v_ctc_loss=0.764, task_loss=3.481, task_loss_gen=4.452, contrastive_loss=0, total=6670.47, n_correct=2802.58, ppl=8.03, accuracy=42.015, wps=18369.2, ups=1.38, wpb=13340.9, bsz=432, num_updates=26600, lr=8.6711e-05, gnorm=1.659, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.5, wall=25030
2023-09-06 08:13:12 | INFO | train_inner | epoch 023:    515 / 1191 loss=2.464, trans_loss=5.535, nll_loss=2.982, w2v_ctc_loss=0.753, task_loss=3.116, task_loss_gen=4.035, contrastive_loss=0, total=6739.35, n_correct=2871.75, ppl=7.9, accuracy=42.612, wps=18614.6, ups=1.38, wpb=13478.7, bsz=459.7, num_updates=26700, lr=8.65485e-05, gnorm=1.293, clip=0, loss_scale=0.5, train_wall=72, gb_free=13.6, wall=25102
2023-09-06 08:14:24 | INFO | train_inner | epoch 023:    615 / 1191 loss=2.474, trans_loss=5.548, nll_loss=2.999, w2v_ctc_loss=0.765, task_loss=3.783, task_loss_gen=4.307, contrastive_loss=0, total=6671.11, n_correct=2822.61, ppl=7.99, accuracy=42.311, wps=18619.2, ups=1.4, wpb=13342.2, bsz=452.7, num_updates=26800, lr=8.63868e-05, gnorm=2.72, clip=1, loss_scale=0.5, train_wall=71, gb_free=14.1, wall=25174
2023-09-06 08:15:37 | INFO | train_inner | epoch 023:    715 / 1191 loss=2.47, trans_loss=5.541, nll_loss=2.989, w2v_ctc_loss=0.76, task_loss=3.341, task_loss_gen=4.305, contrastive_loss=0, total=6659.09, n_correct=2828, ppl=7.94, accuracy=42.468, wps=18231.1, ups=1.37, wpb=13318.2, bsz=442.8, num_updates=26900, lr=8.62261e-05, gnorm=1.315, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.9, wall=25247
2023-09-06 08:16:50 | INFO | train_inner | epoch 023:    815 / 1191 loss=2.468, trans_loss=5.539, nll_loss=2.987, w2v_ctc_loss=0.756, task_loss=3.375, task_loss_gen=4.384, contrastive_loss=0, total=6709.17, n_correct=2852.84, ppl=7.93, accuracy=42.522, wps=18335, ups=1.37, wpb=13418.3, bsz=442.6, num_updates=27000, lr=8.60663e-05, gnorm=1.884, clip=0, loss_scale=0.5, train_wall=73, gb_free=13.8, wall=25320
2023-09-06 08:18:02 | INFO | train_inner | epoch 023:    915 / 1191 loss=2.462, trans_loss=5.53, nll_loss=2.975, w2v_ctc_loss=0.758, task_loss=3.368, task_loss_gen=4.032, contrastive_loss=0, total=6731.52, n_correct=2871.55, ppl=7.86, accuracy=42.658, wps=18626.4, ups=1.38, wpb=13463, bsz=468.2, num_updates=27100, lr=8.59074e-05, gnorm=1.97, clip=0, loss_scale=0.5, train_wall=72, gb_free=4, wall=25392
2023-09-06 08:19:15 | INFO | train_inner | epoch 023:   1015 / 1191 loss=2.455, trans_loss=5.523, nll_loss=2.967, w2v_ctc_loss=0.755, task_loss=3.036, task_loss_gen=3.926, contrastive_loss=0, total=6696.93, n_correct=2874.58, ppl=7.82, accuracy=42.924, wps=18541.9, ups=1.38, wpb=13393.9, bsz=472.2, num_updates=27200, lr=8.57493e-05, gnorm=1.448, clip=0, loss_scale=0.5, train_wall=72, gb_free=10.4, wall=25464
2023-09-06 08:20:27 | INFO | train_inner | epoch 023:   1115 / 1191 loss=2.47, trans_loss=5.541, nll_loss=2.99, w2v_ctc_loss=0.758, task_loss=4.197, task_loss_gen=4.692, contrastive_loss=0, total=6610.02, n_correct=2811.06, ppl=7.94, accuracy=42.527, wps=18298.6, ups=1.38, wpb=13220, bsz=432.6, num_updates=27300, lr=8.55921e-05, gnorm=2.728, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.1, wall=25537
2023-09-06 08:21:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:21:57 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.885 | trans_loss 6.64 | nll_loss 4.357 | w2v_ctc_loss 1.28 | task_loss 12.179 | task_loss_gen 11.935 | contrastive_loss 0 | total 6138.43 | n_correct 2609.29 | ppl 20.49 | accuracy 42.507 | uer 20.635 | wer 22.25 | raw_wer 22.25 | bleu 0.8 | wps 1590.3 | wpb 6138.4 | bsz 201.1 | num_updates 27376 | best_bleu 0.8
2023-09-06 08:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27376 updates
2023-09-06 08:21:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 23 @ 27376 updates, score 0.8) (writing took 13.688264800934121 seconds)
2023-09-06 08:22:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-06 08:22:11 | INFO | train | epoch 023 | loss 2.469 | trans_loss 5.54 | nll_loss 2.988 | w2v_ctc_loss 0.76 | task_loss 3.409 | task_loss_gen 4.245 | contrastive_loss 0 | total 6703.69 | n_correct 2846.06 | ppl 7.93 | accuracy 42.455 | wps 17336.7 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 27376 | lr 8.54732e-05 | gnorm 1.775 | clip 0.1 | loss_scale 0.5 | train_wall 857 | gb_free 14.6 | wall 25641
2023-09-06 08:22:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:22:11 | INFO | fairseq.trainer | begin training epoch 24
2023-09-06 08:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:22:36 | INFO | train_inner | epoch 024:     24 / 1191 loss=2.462, trans_loss=5.533, nll_loss=2.978, w2v_ctc_loss=0.751, task_loss=3.421, task_loss_gen=4.407, contrastive_loss=0, total=6683.55, n_correct=2856.56, ppl=7.88, accuracy=42.74, wps=10337.4, ups=0.77, wpb=13367.1, bsz=445.9, num_updates=27400, lr=8.54358e-05, gnorm=1.771, clip=0, loss_scale=0.5, train_wall=72, gb_free=6.7, wall=25666
2023-09-06 08:23:49 | INFO | train_inner | epoch 024:    124 / 1191 loss=2.445, trans_loss=5.519, nll_loss=2.96, w2v_ctc_loss=0.734, task_loss=3.093, task_loss_gen=4.05, contrastive_loss=0, total=6726.65, n_correct=2898.75, ppl=7.78, accuracy=43.094, wps=18595, ups=1.38, wpb=13453.3, bsz=467.3, num_updates=27500, lr=8.52803e-05, gnorm=1.243, clip=0, loss_scale=0.5, train_wall=72, gb_free=14.3, wall=25738
2023-09-06 08:25:00 | INFO | train_inner | epoch 024:    224 / 1191 loss=2.434, trans_loss=5.508, nll_loss=2.947, w2v_ctc_loss=0.724, task_loss=3.034, task_loss_gen=3.84, contrastive_loss=0, total=6830.09, n_correct=2961.44, ppl=7.71, accuracy=43.359, wps=19064.4, ups=1.4, wpb=13660.2, bsz=485, num_updates=27600, lr=8.51257e-05, gnorm=1.932, clip=0, loss_scale=0.5, train_wall=71, gb_free=12.7, wall=25810
2023-09-06 08:26:13 | INFO | train_inner | epoch 024:    324 / 1191 loss=2.445, trans_loss=5.515, nll_loss=2.955, w2v_ctc_loss=0.731, task_loss=3.473, task_loss_gen=4.233, contrastive_loss=0, total=6738.1, n_correct=2900.1, ppl=7.76, accuracy=43.04, wps=18571.6, ups=1.38, wpb=13476.2, bsz=453.1, num_updates=27700, lr=8.49719e-05, gnorm=2.183, clip=0, loss_scale=0.5, train_wall=72, gb_free=12.2, wall=25883
2023-09-06 08:27:25 | INFO | train_inner | epoch 024:    424 / 1191 loss=2.451, trans_loss=5.517, nll_loss=2.958, w2v_ctc_loss=0.739, task_loss=3.477, task_loss_gen=4.414, contrastive_loss=0, total=6667.84, n_correct=2865.3, ppl=7.77, accuracy=42.972, wps=18564.1, ups=1.39, wpb=13335.7, bsz=436.6, num_updates=27800, lr=8.48189e-05, gnorm=1.212, clip=0, loss_scale=1, train_wall=71, gb_free=13.2, wall=25954
2023-09-06 08:28:38 | INFO | train_inner | epoch 024:    524 / 1191 loss=2.438, trans_loss=5.505, nll_loss=2.943, w2v_ctc_loss=0.729, task_loss=3.279, task_loss_gen=4.355, contrastive_loss=0, total=6644.61, n_correct=2879.43, ppl=7.69, accuracy=43.335, wps=18165.6, ups=1.37, wpb=13289.2, bsz=451.6, num_updates=27900, lr=8.46668e-05, gnorm=0.756, clip=0, loss_scale=1, train_wall=72, gb_free=11.9, wall=26028
2023-09-06 08:29:49 | INFO | train_inner | epoch 024:    624 / 1191 loss=2.453, trans_loss=5.518, nll_loss=2.958, w2v_ctc_loss=0.738, task_loss=3.444, task_loss_gen=4.53, contrastive_loss=0, total=6547.71, n_correct=2811.77, ppl=7.77, accuracy=42.943, wps=18349.7, ups=1.4, wpb=13095.4, bsz=418.8, num_updates=28000, lr=8.45154e-05, gnorm=0.874, clip=0, loss_scale=1, train_wall=71, gb_free=14.1, wall=26099
2023-09-06 08:29:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:30:25 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.858 | trans_loss 6.603 | nll_loss 4.308 | w2v_ctc_loss 1.276 | task_loss 12.452 | task_loss_gen 11.961 | contrastive_loss 0 | total 6138.43 | n_correct 2641.29 | ppl 19.8 | accuracy 43.029 | uer 20.576 | wer 22.228 | raw_wer 22.228 | bleu 1.02 | wps 1476.8 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 1.02
2023-09-06 08:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-09-06 08:30:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 08:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 08:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 1.02) (writing took 13.769007784081623 seconds)
2023-09-06 08:31:52 | INFO | train_inner | epoch 024:    724 / 1191 loss=2.434, trans_loss=5.5, nll_loss=2.937, w2v_ctc_loss=0.732, task_loss=3.304, task_loss_gen=4.07, contrastive_loss=0, total=6732.45, n_correct=2929.62, ppl=7.66, accuracy=43.515, wps=10989.4, ups=0.82, wpb=13464.9, bsz=470.3, num_updates=28100, lr=8.43649e-05, gnorm=1.272, clip=0, loss_scale=1, train_wall=71, gb_free=13.9, wall=26222
2023-09-06 08:33:04 | INFO | train_inner | epoch 024:    824 / 1191 loss=2.44, trans_loss=5.506, nll_loss=2.943, w2v_ctc_loss=0.73, task_loss=3.234, task_loss_gen=4.212, contrastive_loss=0, total=6751.06, n_correct=2923.11, ppl=7.69, accuracy=43.299, wps=18697.7, ups=1.38, wpb=13502.1, bsz=448.7, num_updates=28200, lr=8.42152e-05, gnorm=1.011, clip=0, loss_scale=1, train_wall=72, gb_free=14.1, wall=26294
2023-09-06 08:34:17 | INFO | train_inner | epoch 024:    924 / 1191 loss=2.433, trans_loss=5.504, nll_loss=2.94, w2v_ctc_loss=0.723, task_loss=3.07, task_loss_gen=4.152, contrastive_loss=0, total=6719.91, n_correct=2914.66, ppl=7.68, accuracy=43.373, wps=18393.9, ups=1.37, wpb=13439.8, bsz=459, num_updates=28300, lr=8.40663e-05, gnorm=0.815, clip=0, loss_scale=1, train_wall=72, gb_free=14, wall=26367
2023-09-06 08:35:30 | INFO | train_inner | epoch 024:   1024 / 1191 loss=2.438, trans_loss=5.508, nll_loss=2.946, w2v_ctc_loss=0.725, task_loss=3.715, task_loss_gen=4.67, contrastive_loss=0, total=6578.26, n_correct=2848.76, ppl=7.71, accuracy=43.306, wps=18118.5, ups=1.38, wpb=13156.5, bsz=436.9, num_updates=28400, lr=8.39181e-05, gnorm=1.415, clip=0, loss_scale=1, train_wall=72, gb_free=14.4, wall=26439
2023-09-06 08:36:44 | INFO | train_inner | epoch 024:   1124 / 1191 loss=2.437, trans_loss=5.502, nll_loss=2.938, w2v_ctc_loss=0.725, task_loss=3.367, task_loss_gen=4.389, contrastive_loss=0, total=6714.89, n_correct=2919.61, ppl=7.66, accuracy=43.48, wps=18154.9, ups=1.35, wpb=13429.8, bsz=435.1, num_updates=28500, lr=8.37708e-05, gnorm=0.875, clip=0, loss_scale=1, train_wall=73, gb_free=12.2, wall=26513
2023-09-06 08:37:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:38:08 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.84 | trans_loss 6.578 | nll_loss 4.281 | w2v_ctc_loss 1.27 | task_loss 12.09 | task_loss_gen 12.08 | contrastive_loss 0 | total 6138.43 | n_correct 2653.71 | ppl 19.44 | accuracy 43.231 | uer 19.857 | wer 21.458 | raw_wer 21.458 | bleu 1.17 | wps 1498.2 | wpb 6138.4 | bsz 201.1 | num_updates 28567 | best_bleu 1.17
2023-09-06 08:38:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28567 updates
2023-09-06 08:38:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:38:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 24 @ 28567 updates, score 1.17) (writing took 14.470593063975684 seconds)
2023-09-06 08:38:23 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-06 08:38:23 | INFO | train | epoch 024 | loss 2.44 | trans_loss 5.509 | nll_loss 2.947 | w2v_ctc_loss 0.73 | task_loss 3.304 | task_loss_gen 4.25 | contrastive_loss 0 | total 6703.69 | n_correct 2900.01 | ppl 7.71 | accuracy 43.26 | wps 16435 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 28567 | lr 8.36725e-05 | gnorm 1.214 | clip 0 | loss_scale 1 | train_wall 854 | gb_free 14.9 | wall 26613
2023-09-06 08:38:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:38:23 | INFO | fairseq.trainer | begin training epoch 25
2023-09-06 08:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:38:54 | INFO | train_inner | epoch 025:     33 / 1191 loss=2.433, trans_loss=5.499, nll_loss=2.934, w2v_ctc_loss=0.724, task_loss=3.421, task_loss_gen=4.429, contrastive_loss=0, total=6687.79, n_correct=2911.91, ppl=7.64, accuracy=43.541, wps=10232.4, ups=0.77, wpb=13375.6, bsz=446, num_updates=28600, lr=8.36242e-05, gnorm=0.917, clip=0, loss_scale=1, train_wall=71, gb_free=15.2, wall=26644
2023-09-06 08:40:07 | INFO | train_inner | epoch 025:    133 / 1191 loss=2.419, trans_loss=5.481, nll_loss=2.91, w2v_ctc_loss=0.704, task_loss=3.504, task_loss_gen=4.484, contrastive_loss=0, total=6603.88, n_correct=2897.46, ppl=7.52, accuracy=43.875, wps=18258.3, ups=1.38, wpb=13207.8, bsz=440.3, num_updates=28700, lr=8.34784e-05, gnorm=0.938, clip=0, loss_scale=1, train_wall=72, gb_free=14.3, wall=26716
2023-09-06 08:41:19 | INFO | train_inner | epoch 025:    233 / 1191 loss=2.408, trans_loss=5.48, nll_loss=2.91, w2v_ctc_loss=0.697, task_loss=3.021, task_loss_gen=4.047, contrastive_loss=0, total=6797.98, n_correct=2998.43, ppl=7.51, accuracy=44.108, wps=18778.3, ups=1.38, wpb=13596, bsz=475, num_updates=28800, lr=8.33333e-05, gnorm=0.848, clip=0, loss_scale=1, train_wall=72, gb_free=12.8, wall=26789
2023-09-06 08:42:32 | INFO | train_inner | epoch 025:    333 / 1191 loss=2.43, trans_loss=5.491, nll_loss=2.923, w2v_ctc_loss=0.722, task_loss=3.443, task_loss_gen=4.627, contrastive_loss=0, total=6570.06, n_correct=2871.84, ppl=7.58, accuracy=43.711, wps=17929.8, ups=1.36, wpb=13140.1, bsz=424.5, num_updates=28900, lr=8.3189e-05, gnorm=0.846, clip=0, loss_scale=1, train_wall=73, gb_free=6, wall=26862
2023-09-06 08:43:45 | INFO | train_inner | epoch 025:    433 / 1191 loss=2.422, trans_loss=5.484, nll_loss=2.914, w2v_ctc_loss=0.713, task_loss=3.425, task_loss_gen=4.575, contrastive_loss=0, total=6605.27, n_correct=2895.14, ppl=7.53, accuracy=43.831, wps=18247.4, ups=1.38, wpb=13210.5, bsz=423.9, num_updates=29000, lr=8.30455e-05, gnorm=0.762, clip=0, loss_scale=1, train_wall=72, gb_free=12.7, wall=26935
2023-09-06 08:44:58 | INFO | train_inner | epoch 025:    533 / 1191 loss=2.402, trans_loss=5.469, nll_loss=2.895, w2v_ctc_loss=0.702, task_loss=2.897, task_loss_gen=3.889, contrastive_loss=0, total=6839.61, n_correct=3043.28, ppl=7.44, accuracy=44.495, wps=18754.2, ups=1.37, wpb=13679.2, bsz=482.9, num_updates=29100, lr=8.29027e-05, gnorm=0.79, clip=0, loss_scale=1, train_wall=72, gb_free=12.5, wall=27008
2023-09-06 08:46:09 | INFO | train_inner | epoch 025:    633 / 1191 loss=2.405, trans_loss=5.465, nll_loss=2.89, w2v_ctc_loss=0.703, task_loss=3.082, task_loss_gen=4.086, contrastive_loss=0, total=6773.23, n_correct=3011.69, ppl=7.41, accuracy=44.465, wps=18909.2, ups=1.4, wpb=13546.5, bsz=454.7, num_updates=29200, lr=8.27606e-05, gnorm=0.77, clip=0, loss_scale=1, train_wall=71, gb_free=13.3, wall=27079
2023-09-06 08:47:22 | INFO | train_inner | epoch 025:    733 / 1191 loss=2.407, trans_loss=5.466, nll_loss=2.889, w2v_ctc_loss=0.713, task_loss=3.329, task_loss_gen=4.396, contrastive_loss=0, total=6672.24, n_correct=2962.8, ppl=7.41, accuracy=44.405, wps=18403.7, ups=1.38, wpb=13344.5, bsz=446.8, num_updates=29300, lr=8.26192e-05, gnorm=0.846, clip=0, loss_scale=1, train_wall=72, gb_free=12.3, wall=27152
2023-09-06 08:48:34 | INFO | train_inner | epoch 025:    833 / 1191 loss=2.394, trans_loss=5.454, nll_loss=2.875, w2v_ctc_loss=0.704, task_loss=3.037, task_loss_gen=4.093, contrastive_loss=0, total=6743.82, n_correct=3028.44, ppl=7.33, accuracy=44.907, wps=18716.1, ups=1.39, wpb=13487.6, bsz=462.6, num_updates=29400, lr=8.24786e-05, gnorm=0.739, clip=0, loss_scale=1, train_wall=71, gb_free=11.6, wall=27224
2023-09-06 08:49:46 | INFO | train_inner | epoch 025:    933 / 1191 loss=2.389, trans_loss=5.444, nll_loss=2.861, w2v_ctc_loss=0.709, task_loss=3.069, task_loss_gen=4.063, contrastive_loss=0, total=6769.34, n_correct=3059.37, ppl=7.27, accuracy=45.195, wps=18688, ups=1.38, wpb=13538.7, bsz=467.7, num_updates=29500, lr=8.23387e-05, gnorm=0.826, clip=0, loss_scale=1, train_wall=72, gb_free=13.4, wall=27296
2023-09-06 08:50:58 | INFO | train_inner | epoch 025:   1033 / 1191 loss=2.387, trans_loss=5.446, nll_loss=2.864, w2v_ctc_loss=0.707, task_loss=3.125, task_loss_gen=4.229, contrastive_loss=0, total=6674.8, n_correct=3020.29, ppl=7.28, accuracy=45.249, wps=18583.2, ups=1.39, wpb=13349.6, bsz=454.6, num_updates=29600, lr=8.21995e-05, gnorm=0.806, clip=0, loss_scale=1, train_wall=71, gb_free=13.3, wall=27368
2023-09-06 08:52:11 | INFO | train_inner | epoch 025:   1133 / 1191 loss=2.385, trans_loss=5.431, nll_loss=2.844, w2v_ctc_loss=0.718, task_loss=3.371, task_loss_gen=4.558, contrastive_loss=0, total=6656.31, n_correct=3039.37, ppl=7.18, accuracy=45.661, wps=18311.6, ups=1.38, wpb=13312.6, bsz=439.7, num_updates=29700, lr=8.2061e-05, gnorm=0.874, clip=0, loss_scale=1, train_wall=72, gb_free=11.5, wall=27441
2023-09-06 08:52:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:53:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.657 | trans_loss 6.3 | nll_loss 3.915 | w2v_ctc_loss 1.287 | task_loss 9.618 | task_loss_gen 12.553 | contrastive_loss 0 | total 6138.43 | n_correct 2930.57 | ppl 15.09 | accuracy 47.741 | uer 19.672 | wer 21.041 | raw_wer 21.041 | bleu 3.84 | wps 1430.1 | wpb 6138.4 | bsz 201.1 | num_updates 29758 | best_bleu 3.84
2023-09-06 08:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29758 updates
2023-09-06 08:53:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 08:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 25 @ 29758 updates, score 3.84) (writing took 13.31537883693818 seconds)
2023-09-06 08:53:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-06 08:53:44 | INFO | train | epoch 025 | loss 2.403 | trans_loss 5.463 | nll_loss 2.886 | w2v_ctc_loss 0.709 | task_loss 3.193 | task_loss_gen 4.269 | contrastive_loss 0 | total 6703.69 | n_correct 2990.98 | ppl 7.39 | accuracy 44.617 | wps 17334.9 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 29758 | lr 8.1981e-05 | gnorm 0.819 | clip 0 | loss_scale 1 | train_wall 855 | gb_free 11.5 | wall 27534
2023-09-06 08:53:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 08:53:44 | INFO | fairseq.trainer | begin training epoch 26
2023-09-06 08:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 08:54:22 | INFO | train_inner | epoch 026:     42 / 1191 loss=2.353, trans_loss=5.395, nll_loss=2.797, w2v_ctc_loss=0.709, task_loss=2.896, task_loss_gen=4.097, contrastive_loss=0, total=6831.33, n_correct=3210.23, ppl=6.95, accuracy=46.993, wps=10427, ups=0.76, wpb=13662.7, bsz=467.1, num_updates=29800, lr=8.19232e-05, gnorm=0.71, clip=0, loss_scale=1, train_wall=72, gb_free=11.4, wall=27572
2023-09-06 08:55:35 | INFO | train_inner | epoch 026:    142 / 1191 loss=2.294, trans_loss=5.306, nll_loss=2.681, w2v_ctc_loss=0.714, task_loss=2.935, task_loss_gen=4.348, contrastive_loss=0, total=6721.54, n_correct=3347.4, ppl=6.41, accuracy=49.801, wps=18423.9, ups=1.37, wpb=13443.1, bsz=458.7, num_updates=29900, lr=8.17861e-05, gnorm=0.591, clip=0, loss_scale=2, train_wall=72, gb_free=12.2, wall=27645
2023-09-06 08:56:47 | INFO | train_inner | epoch 026:    242 / 1191 loss=2.222, trans_loss=5.188, nll_loss=2.529, w2v_ctc_loss=0.732, task_loss=2.736, task_loss_gen=4.34, contrastive_loss=0, total=6683.63, n_correct=3576.5, ppl=5.77, accuracy=53.511, wps=18500.9, ups=1.38, wpb=13367.3, bsz=449.8, num_updates=30000, lr=8.16497e-05, gnorm=0.558, clip=0, loss_scale=2, train_wall=72, gb_free=14, wall=27717
2023-09-06 08:56:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 08:57:24 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.259 | trans_loss 5.684 | nll_loss 3.126 | w2v_ctc_loss 1.356 | task_loss 8.483 | task_loss_gen 12.601 | contrastive_loss 0 | total 6138.43 | n_correct 3547.57 | ppl 8.73 | accuracy 57.793 | uer 20.969 | wer 22.689 | raw_wer 22.689 | bleu 12.07 | wps 1467.5 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 12.07
2023-09-06 08:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-09-06 08:57:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-06 08:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-06 08:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 12.07) (writing took 15.432711002067663 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 08:58:53 | INFO | train_inner | epoch 026:    342 / 1191 loss=2.167, trans_loss=5.113, nll_loss=2.434, w2v_ctc_loss=0.742, task_loss=2.512, task_loss_gen=3.884, contrastive_loss=0, total=6872.19, n_correct=3869.25, ppl=5.4, accuracy=56.303, wps=10958.6, ups=0.8, wpb=13744.4, bsz=495.7, num_updates=30100, lr=8.15139e-05, gnorm=0.519, clip=0, loss_scale=2, train_wall=72, gb_free=13.8, wall=27842
2023-09-06 09:00:05 | INFO | train_inner | epoch 026:    442 / 1191 loss=2.147, trans_loss=5.072, nll_loss=2.379, w2v_ctc_loss=0.746, task_loss=2.866, task_loss_gen=4.669, contrastive_loss=0, total=6595.24, n_correct=3799.21, ppl=5.2, accuracy=57.605, wps=18089.9, ups=1.37, wpb=13190.5, bsz=428.8, num_updates=30200, lr=8.13788e-05, gnorm=0.562, clip=0, loss_scale=2, train_wall=72, gb_free=14.1, wall=27915
2023-09-06 09:01:19 | INFO | train_inner | epoch 026:    542 / 1191 loss=2.118, trans_loss=5.033, nll_loss=2.331, w2v_ctc_loss=0.741, task_loss=2.842, task_loss_gen=4.549, contrastive_loss=0, total=6665.83, n_correct=3923.94, ppl=5.03, accuracy=58.866, wps=18165.2, ups=1.36, wpb=13331.7, bsz=447.8, num_updates=30300, lr=8.12444e-05, gnorm=0.529, clip=0, loss_scale=2, train_wall=73, gb_free=14.1, wall=27989
2023-09-06 09:02:31 | INFO | train_inner | epoch 026:    642 / 1191 loss=2.104, trans_loss=5.01, nll_loss=2.298, w2v_ctc_loss=0.745, task_loss=3.008, task_loss_gen=4.8, contrastive_loss=0, total=6614.16, n_correct=3950.8, ppl=4.92, accuracy=59.732, wps=18282.6, ups=1.38, wpb=13228.3, bsz=426.8, num_updates=30400, lr=8.11107e-05, gnorm=0.516, clip=0, loss_scale=2, train_wall=72, gb_free=14.3, wall=28061
2023-09-06 09:03:44 | INFO | train_inner | epoch 026:    742 / 1191 loss=2.08, trans_loss=4.981, nll_loss=2.263, w2v_ctc_loss=0.74, task_loss=2.851, task_loss_gen=4.419, contrastive_loss=0, total=6774.24, n_correct=4112.97, ppl=4.8, accuracy=60.715, wps=18564.1, ups=1.37, wpb=13548.5, bsz=446.6, num_updates=30500, lr=8.09776e-05, gnorm=0.506, clip=0, loss_scale=2, train_wall=72, gb_free=11.9, wall=28134
2023-09-06 09:04:57 | INFO | train_inner | epoch 026:    842 / 1191 loss=2.064, trans_loss=4.956, nll_loss=2.233, w2v_ctc_loss=0.736, task_loss=2.777, task_loss_gen=4.442, contrastive_loss=0, total=6656.57, n_correct=4086.44, ppl=4.7, accuracy=61.39, wps=18357.9, ups=1.38, wpb=13313.1, bsz=453.7, num_updates=30600, lr=8.08452e-05, gnorm=0.522, clip=0, loss_scale=2, train_wall=72, gb_free=13.1, wall=28207
2023-09-06 09:06:09 | INFO | train_inner | epoch 026:    942 / 1191 loss=2.06, trans_loss=4.949, nll_loss=2.222, w2v_ctc_loss=0.746, task_loss=2.851, task_loss_gen=4.403, contrastive_loss=0, total=6706.19, n_correct=4145.79, ppl=4.67, accuracy=61.82, wps=18531.9, ups=1.38, wpb=13412.4, bsz=451.6, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=2, train_wall=72, gb_free=12.1, wall=28279
2023-09-06 09:07:22 | INFO | train_inner | epoch 026:   1042 / 1191 loss=2.052, trans_loss=4.935, nll_loss=2.205, w2v_ctc_loss=0.745, task_loss=2.932, task_loss_gen=4.525, contrastive_loss=0, total=6685.17, n_correct=4156.33, ppl=4.61, accuracy=62.172, wps=18421.6, ups=1.38, wpb=13370.3, bsz=443.6, num_updates=30800, lr=8.05823e-05, gnorm=0.525, clip=0, loss_scale=2, train_wall=72, gb_free=13, wall=28352
2023-09-06 09:08:35 | INFO | train_inner | epoch 026:   1142 / 1191 loss=2.032, trans_loss=4.92, nll_loss=2.186, w2v_ctc_loss=0.729, task_loss=2.715, task_loss_gen=4.196, contrastive_loss=0, total=6806.87, n_correct=4274.48, ppl=4.55, accuracy=62.797, wps=18638.7, ups=1.37, wpb=13613.7, bsz=478.9, num_updates=30900, lr=8.04518e-05, gnorm=0.51, clip=0, loss_scale=2, train_wall=72, gb_free=10.1, wall=28425
2023-09-06 09:09:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
2023-09-06 09:09:47 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.197 | nll_loss 2.498 | w2v_ctc_loss 1.325 | task_loss 14.351 | task_loss_gen 12.32 | contrastive_loss 0 | total 6138.43 | n_correct 4033.43 | ppl 5.65 | accuracy 65.708 | uer 19.913 | wer 21.376 | raw_wer 21.376 | bleu 22.34 | wps 1454 | wpb 6138.4 | bsz 201.1 | num_updates 30949 | best_bleu 22.34
2023-09-06 09:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30949 updates
2023-09-06 09:09:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 26 @ 30949 updates, score 22.34) (writing took 13.240448824013583 seconds)
2023-09-06 09:10:01 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-06 09:10:01 | INFO | train | epoch 026 | loss 2.126 | trans_loss 5.049 | nll_loss 2.351 | w2v_ctc_loss 0.737 | task_loss 2.837 | task_loss_gen 4.413 | contrastive_loss 0 | total 6703.69 | n_correct 3913.7 | ppl 5.1 | accuracy 58.381 | wps 16348.2 | ups 1.22 | wpb 13407.4 | bsz 452.1 | num_updates 30949 | lr 8.03881e-05 | gnorm 0.542 | clip 0 | loss_scale 2 | train_wall 858 | gb_free 12.3 | wall 28511
2023-09-06 09:10:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:10:01 | INFO | fairseq.trainer | begin training epoch 27
2023-09-06 09:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:10:46 | INFO | train_inner | epoch 027:     51 / 1191 loss=2.03, trans_loss=4.907, nll_loss=2.169, w2v_ctc_loss=0.736, task_loss=2.931, task_loss_gen=4.517, contrastive_loss=0, total=6618.74, n_correct=4177.2, ppl=4.5, accuracy=63.112, wps=10123.4, ups=0.76, wpb=13237.5, bsz=439.8, num_updates=31000, lr=8.03219e-05, gnorm=0.534, clip=0, loss_scale=2, train_wall=72, gb_free=14.3, wall=28555
2023-09-06 09:11:58 | INFO | train_inner | epoch 027:    151 / 1191 loss=2.02, trans_loss=4.891, nll_loss=2.148, w2v_ctc_loss=0.73, task_loss=2.76, task_loss_gen=4.342, contrastive_loss=0, total=6722.07, n_correct=4267.92, ppl=4.43, accuracy=63.491, wps=18488.8, ups=1.38, wpb=13444.1, bsz=463.7, num_updates=31100, lr=8.01927e-05, gnorm=0.487, clip=0, loss_scale=2, train_wall=72, gb_free=13.2, wall=28628
2023-09-06 09:13:11 | INFO | train_inner | epoch 027:    251 / 1191 loss=2.003, trans_loss=4.878, nll_loss=2.133, w2v_ctc_loss=0.716, task_loss=2.614, task_loss_gen=4.046, contrastive_loss=0, total=6827.01, n_correct=4368.94, ppl=4.39, accuracy=63.995, wps=18842.5, ups=1.38, wpb=13654, bsz=484.7, num_updates=31200, lr=8.00641e-05, gnorm=0.504, clip=0, loss_scale=2, train_wall=72, gb_free=13.2, wall=28701
2023-09-06 09:14:24 | INFO | train_inner | epoch 027:    351 / 1191 loss=2.001, trans_loss=4.873, nll_loss=2.126, w2v_ctc_loss=0.715, task_loss=2.852, task_loss_gen=4.255, contrastive_loss=0, total=6733.4, n_correct=4318.58, ppl=4.37, accuracy=64.137, wps=18449.6, ups=1.37, wpb=13466.8, bsz=465.5, num_updates=31300, lr=7.99361e-05, gnorm=0.561, clip=0, loss_scale=2, train_wall=72, gb_free=10.7, wall=28774
2023-09-06 09:15:37 | INFO | train_inner | epoch 027:    451 / 1191 loss=2.014, trans_loss=4.884, nll_loss=2.14, w2v_ctc_loss=0.736, task_loss=3.189, task_loss_gen=4.656, contrastive_loss=0, total=6623.81, n_correct=4238.57, ppl=4.41, accuracy=63.99, wps=18176.3, ups=1.37, wpb=13247.6, bsz=439.7, num_updates=31400, lr=7.98087e-05, gnorm=0.531, clip=0, loss_scale=2, train_wall=72, gb_free=13.3, wall=28846
2023-09-06 09:16:49 | INFO | train_inner | epoch 027:    551 / 1191 loss=1.997, trans_loss=4.862, nll_loss=2.112, w2v_ctc_loss=0.723, task_loss=2.907, task_loss_gen=4.265, contrastive_loss=0, total=6739.24, n_correct=4348.17, ppl=4.32, accuracy=64.52, wps=18556.9, ups=1.38, wpb=13478.5, bsz=458.5, num_updates=31500, lr=7.96819e-05, gnorm=0.515, clip=0, loss_scale=2, train_wall=72, gb_free=12.2, wall=28919
2023-09-06 09:18:02 | INFO | train_inner | epoch 027:    651 / 1191 loss=1.993, trans_loss=4.859, nll_loss=2.108, w2v_ctc_loss=0.712, task_loss=3.004, task_loss_gen=4.414, contrastive_loss=0, total=6706.8, n_correct=4333.11, ppl=4.31, accuracy=64.608, wps=18536.7, ups=1.38, wpb=13413.6, bsz=447.4, num_updates=31600, lr=7.95557e-05, gnorm=0.521, clip=0, loss_scale=2, train_wall=72, gb_free=13.7, wall=28991
2023-09-06 09:19:14 | INFO | train_inner | epoch 027:    751 / 1191 loss=1.992, trans_loss=4.855, nll_loss=2.104, w2v_ctc_loss=0.721, task_loss=3.083, task_loss_gen=4.541, contrastive_loss=0, total=6683.25, n_correct=4327.73, ppl=4.3, accuracy=64.755, wps=18504.8, ups=1.38, wpb=13366.5, bsz=446.6, num_updates=31700, lr=7.94301e-05, gnorm=0.55, clip=0, loss_scale=2, train_wall=72, gb_free=11.1, wall=29064
2023-09-06 09:20:27 | INFO | train_inner | epoch 027:    851 / 1191 loss=1.996, trans_loss=4.856, nll_loss=2.104, w2v_ctc_loss=0.729, task_loss=3.255, task_loss_gen=4.684, contrastive_loss=0, total=6642.36, n_correct=4298.6, ppl=4.3, accuracy=64.715, wps=18244.1, ups=1.37, wpb=13284.7, bsz=437.2, num_updates=31800, lr=7.93052e-05, gnorm=0.553, clip=0, loss_scale=2, train_wall=72, gb_free=11.9, wall=29136
2023-09-06 09:21:39 | INFO | train_inner | epoch 027:    951 / 1191 loss=1.993, trans_loss=4.854, nll_loss=2.103, w2v_ctc_loss=0.723, task_loss=3.337, task_loss_gen=4.707, contrastive_loss=0, total=6647.74, n_correct=4312.7, ppl=4.29, accuracy=64.875, wps=18360.6, ups=1.38, wpb=13295.5, bsz=427.9, num_updates=31900, lr=7.91808e-05, gnorm=0.538, clip=0, loss_scale=4, train_wall=72, gb_free=13.6, wall=29209
2023-09-06 09:22:51 | INFO | train_inner | epoch 027:   1051 / 1191 loss=1.983, trans_loss=4.847, nll_loss=2.093, w2v_ctc_loss=0.718, task_loss=3.011, task_loss_gen=4.512, contrastive_loss=0, total=6641.77, n_correct=4319.98, ppl=4.27, accuracy=65.043, wps=18370.5, ups=1.38, wpb=13283.5, bsz=447.4, num_updates=32000, lr=7.90569e-05, gnorm=0.436, clip=0, loss_scale=4, train_wall=72, gb_free=14.3, wall=29281
2023-09-06 09:22:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:23:26 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.836 | trans_loss 5.087 | nll_loss 2.355 | w2v_ctc_loss 1.295 | task_loss 14.665 | task_loss_gen 12.608 | contrastive_loss 0 | total 6138.43 | n_correct 4147.14 | ppl 5.11 | accuracy 67.56 | uer 19.3 | wer 20.699 | raw_wer 20.699 | bleu 24.64 | wps 1599.9 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 24.64
2023-09-06 09:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32000 updates
2023-09-06 09:23:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-06 09:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-06 09:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_27_32000.pt (epoch 27 @ 32000 updates, score 24.64) (writing took 16.214326540008187 seconds)
2023-09-06 09:24:56 | INFO | train_inner | epoch 027:   1151 / 1191 loss=1.976, trans_loss=4.836, nll_loss=2.08, w2v_ctc_loss=0.71, task_loss=2.898, task_loss_gen=4.392, contrastive_loss=0, total=6761.49, n_correct=4420.06, ppl=4.23, accuracy=65.371, wps=10882.8, ups=0.8, wpb=13523, bsz=454.9, num_updates=32100, lr=7.89337e-05, gnorm=0.431, clip=0, loss_scale=4, train_wall=72, gb_free=13.9, wall=29405
2023-09-06 09:25:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:25:59 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.837 | trans_loss 5.08 | nll_loss 2.344 | w2v_ctc_loss 1.314 | task_loss 10.048 | task_loss_gen 12.584 | contrastive_loss 0 | total 6138.43 | n_correct 4148.57 | ppl 5.08 | accuracy 67.584 | uer 19.068 | wer 20.454 | raw_wer 20.454 | bleu 24.72 | wps 1629.1 | wpb 6138.4 | bsz 201.1 | num_updates 32140 | best_bleu 24.72
2023-09-06 09:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32140 updates
2023-09-06 09:25:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:26:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 27 @ 32140 updates, score 24.72) (writing took 13.905794541002251 seconds)
2023-09-06 09:26:13 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-06 09:26:13 | INFO | train | epoch 027 | loss 1.997 | trans_loss 4.863 | nll_loss 2.114 | w2v_ctc_loss 0.72 | task_loss 2.966 | task_loss_gen 4.425 | contrastive_loss 0 | total 6703.69 | n_correct 4323.29 | ppl 4.33 | accuracy 64.491 | wps 16426.9 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 32140 | lr 7.88846e-05 | gnorm 0.51 | clip 0 | loss_scale 4 | train_wall 857 | gb_free 13.1 | wall 29483
2023-09-06 09:26:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:26:13 | INFO | fairseq.trainer | begin training epoch 28
2023-09-06 09:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:27:04 | INFO | train_inner | epoch 028:     60 / 1191 loss=1.962, trans_loss=4.816, nll_loss=2.055, w2v_ctc_loss=0.699, task_loss=2.775, task_loss_gen=4.487, contrastive_loss=0, total=6694.65, n_correct=4404.54, ppl=4.15, accuracy=65.792, wps=10439.6, ups=0.78, wpb=13389.3, bsz=453.1, num_updates=32200, lr=7.8811e-05, gnorm=0.431, clip=0, loss_scale=4, train_wall=71, gb_free=12.5, wall=29534
2023-09-06 09:28:16 | INFO | train_inner | epoch 028:    160 / 1191 loss=1.97, trans_loss=4.818, nll_loss=2.056, w2v_ctc_loss=0.714, task_loss=2.971, task_loss_gen=4.706, contrastive_loss=0, total=6668.32, n_correct=4384.99, ppl=4.16, accuracy=65.759, wps=18487.7, ups=1.39, wpb=13336.6, bsz=433.5, num_updates=32300, lr=7.86889e-05, gnorm=0.432, clip=0, loss_scale=4, train_wall=72, gb_free=10.9, wall=29606
2023-09-06 09:29:28 | INFO | train_inner | epoch 028:    260 / 1191 loss=1.962, trans_loss=4.814, nll_loss=2.052, w2v_ctc_loss=0.703, task_loss=2.973, task_loss_gen=4.559, contrastive_loss=0, total=6679.49, n_correct=4404.84, ppl=4.15, accuracy=65.946, wps=18571.5, ups=1.39, wpb=13359, bsz=449.8, num_updates=32400, lr=7.85674e-05, gnorm=0.448, clip=0, loss_scale=4, train_wall=71, gb_free=14.6, wall=29678
2023-09-06 09:30:41 | INFO | train_inner | epoch 028:    360 / 1191 loss=1.958, trans_loss=4.807, nll_loss=2.042, w2v_ctc_loss=0.708, task_loss=2.936, task_loss_gen=4.426, contrastive_loss=0, total=6774.84, n_correct=4475.37, ppl=4.12, accuracy=66.059, wps=18576.6, ups=1.37, wpb=13549.7, bsz=468.5, num_updates=32500, lr=7.84465e-05, gnorm=0.462, clip=0, loss_scale=4, train_wall=72, gb_free=12.2, wall=29751
2023-09-06 09:31:55 | INFO | train_inner | epoch 028:    460 / 1191 loss=1.958, trans_loss=4.808, nll_loss=2.044, w2v_ctc_loss=0.704, task_loss=2.876, task_loss_gen=4.358, contrastive_loss=0, total=6746.47, n_correct=4459.03, ppl=4.13, accuracy=66.094, wps=18333.2, ups=1.36, wpb=13492.9, bsz=465.1, num_updates=32600, lr=7.8326e-05, gnorm=0.441, clip=0, loss_scale=4, train_wall=73, gb_free=14.5, wall=29824
2023-09-06 09:33:06 | INFO | train_inner | epoch 028:    560 / 1191 loss=1.954, trans_loss=4.805, nll_loss=2.04, w2v_ctc_loss=0.7, task_loss=2.876, task_loss_gen=4.413, contrastive_loss=0, total=6711.63, n_correct=4442.11, ppl=4.11, accuracy=66.185, wps=18833.7, ups=1.4, wpb=13423.3, bsz=454, num_updates=32700, lr=7.82062e-05, gnorm=0.444, clip=0, loss_scale=4, train_wall=71, gb_free=11.9, wall=29896
2023-09-06 09:34:18 | INFO | train_inner | epoch 028:    660 / 1191 loss=1.951, trans_loss=4.8, nll_loss=2.035, w2v_ctc_loss=0.697, task_loss=2.977, task_loss_gen=4.542, contrastive_loss=0, total=6742.02, n_correct=4473.32, ppl=4.1, accuracy=66.35, wps=18656.7, ups=1.38, wpb=13484, bsz=456, num_updates=32800, lr=7.80869e-05, gnorm=0.448, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=29968
2023-09-06 09:35:31 | INFO | train_inner | epoch 028:    760 / 1191 loss=1.954, trans_loss=4.801, nll_loss=2.036, w2v_ctc_loss=0.706, task_loss=2.929, task_loss_gen=4.528, contrastive_loss=0, total=6702.27, n_correct=4440.3, ppl=4.1, accuracy=66.251, wps=18359.4, ups=1.37, wpb=13404.5, bsz=455.2, num_updates=32900, lr=7.79681e-05, gnorm=0.446, clip=0, loss_scale=4, train_wall=72, gb_free=13.3, wall=30041
2023-09-06 09:36:43 | INFO | train_inner | epoch 028:    860 / 1191 loss=1.949, trans_loss=4.796, nll_loss=2.03, w2v_ctc_loss=0.699, task_loss=2.926, task_loss_gen=4.495, contrastive_loss=0, total=6652.38, n_correct=4418.8, ppl=4.08, accuracy=66.424, wps=18426.1, ups=1.38, wpb=13304.8, bsz=454.3, num_updates=33000, lr=7.78499e-05, gnorm=0.442, clip=0, loss_scale=4, train_wall=71, gb_free=13.4, wall=30113
2023-09-06 09:37:56 | INFO | train_inner | epoch 028:    960 / 1191 loss=1.958, trans_loss=4.803, nll_loss=2.038, w2v_ctc_loss=0.711, task_loss=2.961, task_loss_gen=4.832, contrastive_loss=0, total=6636.39, n_correct=4397.27, ppl=4.11, accuracy=66.26, wps=18270.2, ups=1.38, wpb=13272.8, bsz=433.5, num_updates=33100, lr=7.77322e-05, gnorm=0.423, clip=0, loss_scale=4, train_wall=72, gb_free=13.8, wall=30186
2023-09-06 09:39:09 | INFO | train_inner | epoch 028:   1060 / 1191 loss=1.948, trans_loss=4.798, nll_loss=2.033, w2v_ctc_loss=0.691, task_loss=2.828, task_loss_gen=4.752, contrastive_loss=0, total=6686.82, n_correct=4439.06, ppl=4.09, accuracy=66.385, wps=18354.4, ups=1.37, wpb=13373.6, bsz=442.3, num_updates=33200, lr=7.76151e-05, gnorm=0.429, clip=0, loss_scale=4, train_wall=72, gb_free=14.8, wall=30259
2023-09-06 09:40:22 | INFO | train_inner | epoch 028:   1160 / 1191 loss=1.947, trans_loss=4.795, nll_loss=2.028, w2v_ctc_loss=0.695, task_loss=3.037, task_loss_gen=4.693, contrastive_loss=0, total=6684.12, n_correct=4447.74, ppl=4.08, accuracy=66.542, wps=18305.5, ups=1.37, wpb=13368.2, bsz=446, num_updates=33300, lr=7.74984e-05, gnorm=0.453, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=30332
2023-09-06 09:40:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:41:18 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.789 | trans_loss 5.032 | nll_loss 2.287 | w2v_ctc_loss 1.263 | task_loss 13.391 | task_loss_gen 12.57 | contrastive_loss 0 | total 6138.43 | n_correct 4203.29 | ppl 4.88 | accuracy 68.475 | uer 19.228 | wer 20.439 | raw_wer 20.439 | bleu 25.9 | wps 1696.6 | wpb 6138.4 | bsz 201.1 | num_updates 33331 | best_bleu 25.9
2023-09-06 09:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33331 updates
2023-09-06 09:41:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:41:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 28 @ 33331 updates, score 25.9) (writing took 14.04042054596357 seconds)
2023-09-06 09:41:32 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-06 09:41:32 | INFO | train | epoch 028 | loss 1.955 | trans_loss 4.804 | nll_loss 2.039 | w2v_ctc_loss 0.702 | task_loss 2.911 | task_loss_gen 4.544 | contrastive_loss 0 | total 6703.69 | n_correct 4438.71 | ppl 4.11 | accuracy 66.213 | wps 17367.1 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 33331 | lr 7.74624e-05 | gnorm 0.442 | clip 0 | loss_scale 4 | train_wall 856 | gb_free 13.2 | wall 30402
2023-09-06 09:41:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:41:32 | INFO | fairseq.trainer | begin training epoch 29
2023-09-06 09:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:42:31 | INFO | train_inner | epoch 029:     69 / 1191 loss=1.93, trans_loss=4.772, nll_loss=1.998, w2v_ctc_loss=0.685, task_loss=2.667, task_loss_gen=4.192, contrastive_loss=0, total=6795.78, n_correct=4566.82, ppl=4, accuracy=67.201, wps=10541.9, ups=0.78, wpb=13591.6, bsz=473, num_updates=33400, lr=7.73823e-05, gnorm=0.422, clip=0, loss_scale=4, train_wall=72, gb_free=13.1, wall=30461
2023-09-06 09:43:43 | INFO | train_inner | epoch 029:    169 / 1191 loss=1.936, trans_loss=4.776, nll_loss=2.004, w2v_ctc_loss=0.688, task_loss=2.924, task_loss_gen=4.592, contrastive_loss=0, total=6680.96, n_correct=4474.77, ppl=4.01, accuracy=66.978, wps=18575.2, ups=1.39, wpb=13361.9, bsz=438.8, num_updates=33500, lr=7.72667e-05, gnorm=0.434, clip=0, loss_scale=4, train_wall=71, gb_free=11.7, wall=30533
2023-09-06 09:44:56 | INFO | train_inner | epoch 029:    269 / 1191 loss=1.933, trans_loss=4.778, nll_loss=2.007, w2v_ctc_loss=0.681, task_loss=2.928, task_loss_gen=4.557, contrastive_loss=0, total=6669.15, n_correct=4466.1, ppl=4.02, accuracy=66.967, wps=18113.1, ups=1.36, wpb=13338.3, bsz=454, num_updates=33600, lr=7.71517e-05, gnorm=0.45, clip=0, loss_scale=4, train_wall=73, gb_free=12, wall=30606
2023-09-06 09:46:09 | INFO | train_inner | epoch 029:    369 / 1191 loss=1.936, trans_loss=4.778, nll_loss=2.007, w2v_ctc_loss=0.691, task_loss=2.853, task_loss_gen=4.557, contrastive_loss=0, total=6753.05, n_correct=4521.23, ppl=4.02, accuracy=66.951, wps=18508.1, ups=1.37, wpb=13506.1, bsz=452.3, num_updates=33700, lr=7.70371e-05, gnorm=0.432, clip=0, loss_scale=4, train_wall=72, gb_free=14.1, wall=30679
2023-09-06 09:47:22 | INFO | train_inner | epoch 029:    469 / 1191 loss=1.929, trans_loss=4.773, nll_loss=2.001, w2v_ctc_loss=0.682, task_loss=2.8, task_loss_gen=4.417, contrastive_loss=0, total=6767.55, n_correct=4542.99, ppl=4, accuracy=67.129, wps=18607.6, ups=1.37, wpb=13535.1, bsz=469.6, num_updates=33800, lr=7.69231e-05, gnorm=0.452, clip=0, loss_scale=4, train_wall=72, gb_free=15.1, wall=30752
2023-09-06 09:48:35 | INFO | train_inner | epoch 029:    569 / 1191 loss=1.945, trans_loss=4.78, nll_loss=2.009, w2v_ctc_loss=0.708, task_loss=3.223, task_loss_gen=4.894, contrastive_loss=0, total=6601.9, n_correct=4412.15, ppl=4.03, accuracy=66.832, wps=18071.4, ups=1.37, wpb=13203.8, bsz=422.9, num_updates=33900, lr=7.68095e-05, gnorm=0.46, clip=0, loss_scale=4, train_wall=72, gb_free=13.9, wall=30825
2023-09-06 09:49:47 | INFO | train_inner | epoch 029:    669 / 1191 loss=1.925, trans_loss=4.761, nll_loss=1.985, w2v_ctc_loss=0.685, task_loss=2.713, task_loss_gen=4.431, contrastive_loss=0, total=6730.73, n_correct=4535.37, ppl=3.96, accuracy=67.383, wps=18696.4, ups=1.39, wpb=13461.5, bsz=461.6, num_updates=34000, lr=7.66965e-05, gnorm=0.397, clip=0, loss_scale=8, train_wall=71, gb_free=12.8, wall=30897
2023-09-06 09:49:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:50:21 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.768 | trans_loss 5.009 | nll_loss 2.26 | w2v_ctc_loss 1.243 | task_loss 11.092 | task_loss_gen 12.589 | contrastive_loss 0 | total 6138.43 | n_correct 4231 | ppl 4.79 | accuracy 68.926 | uer 18.798 | wer 20.212 | raw_wer 20.212 | bleu 26.35 | wps 1688.4 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 26.35
2023-09-06 09:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-09-06 09:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-06 09:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-06 09:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 26.35) (writing took 16.268881382071413 seconds)
2023-09-06 09:51:50 | INFO | train_inner | epoch 029:    769 / 1191 loss=1.924, trans_loss=4.762, nll_loss=1.987, w2v_ctc_loss=0.683, task_loss=2.658, task_loss_gen=4.56, contrastive_loss=0, total=6668.92, n_correct=4497.76, ppl=3.96, accuracy=67.444, wps=10885.2, ups=0.82, wpb=13337.8, bsz=453.3, num_updates=34100, lr=7.6584e-05, gnorm=0.393, clip=0, loss_scale=8, train_wall=71, gb_free=13.6, wall=31020
2023-09-06 09:53:03 | INFO | train_inner | epoch 029:    869 / 1191 loss=1.933, trans_loss=4.772, nll_loss=1.999, w2v_ctc_loss=0.692, task_loss=2.713, task_loss_gen=4.985, contrastive_loss=0, total=6644.69, n_correct=4457.26, ppl=4, accuracy=67.08, wps=18224.1, ups=1.37, wpb=13289.4, bsz=431.6, num_updates=34200, lr=7.64719e-05, gnorm=0.4, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=31092
2023-09-06 09:54:16 | INFO | train_inner | epoch 029:    969 / 1191 loss=1.929, trans_loss=4.766, nll_loss=1.993, w2v_ctc_loss=0.692, task_loss=2.469, task_loss_gen=4.771, contrastive_loss=0, total=6741.09, n_correct=4532.78, ppl=3.98, accuracy=67.241, wps=18480.7, ups=1.37, wpb=13482.2, bsz=463.9, num_updates=34300, lr=7.63604e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=31165
2023-09-06 09:55:28 | INFO | train_inner | epoch 029:   1069 / 1191 loss=1.925, trans_loss=4.762, nll_loss=1.988, w2v_ctc_loss=0.686, task_loss=2.739, task_loss_gen=4.675, contrastive_loss=0, total=6710.1, n_correct=4527.2, ppl=3.97, accuracy=67.468, wps=18520.8, ups=1.38, wpb=13420.2, bsz=455.2, num_updates=34400, lr=7.62493e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=13.4, wall=31238
2023-09-06 09:56:41 | INFO | train_inner | epoch 029:   1169 / 1191 loss=1.919, trans_loss=4.761, nll_loss=1.987, w2v_ctc_loss=0.677, task_loss=2.432, task_loss_gen=4.643, contrastive_loss=0, total=6757.48, n_correct=4566.6, ppl=3.96, accuracy=67.578, wps=18486.7, ups=1.37, wpb=13515, bsz=464.2, num_updates=34500, lr=7.61387e-05, gnorm=0.395, clip=0, loss_scale=8, train_wall=73, gb_free=11.9, wall=31311
2023-09-06 09:56:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 09:57:31 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.757 | trans_loss 4.991 | nll_loss 2.238 | w2v_ctc_loss 1.246 | task_loss 14.886 | task_loss_gen 12.959 | contrastive_loss 0 | total 6138.43 | n_correct 4247.14 | ppl 4.72 | accuracy 69.189 | uer 18.533 | wer 19.955 | raw_wer 19.955 | bleu 26.79 | wps 1686.6 | wpb 6138.4 | bsz 201.1 | num_updates 34522 | best_bleu 26.79
2023-09-06 09:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34522 updates
2023-09-06 09:57:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 09:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 29 @ 34522 updates, score 26.79) (writing took 12.81016522902064 seconds)
2023-09-06 09:57:44 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-06 09:57:44 | INFO | train | epoch 029 | loss 1.93 | trans_loss 4.77 | nll_loss 1.997 | w2v_ctc_loss 0.687 | task_loss 2.76 | task_loss_gen 4.629 | contrastive_loss 0 | total 6703.69 | n_correct 4504.72 | ppl 3.99 | accuracy 67.198 | wps 16430 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 34522 | lr 7.61144e-05 | gnorm 0.418 | clip 0 | loss_scale 8 | train_wall 858 | gb_free 13.3 | wall 31374
2023-09-06 09:57:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 09:57:44 | INFO | fairseq.trainer | begin training epoch 30
2023-09-06 09:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 09:58:48 | INFO | train_inner | epoch 030:     78 / 1191 loss=1.911, trans_loss=4.747, nll_loss=1.968, w2v_ctc_loss=0.673, task_loss=2.08, task_loss_gen=4.397, contrastive_loss=0, total=6833.03, n_correct=4633.34, ppl=3.91, accuracy=67.808, wps=10750.3, ups=0.79, wpb=13666.1, bsz=481.4, num_updates=34600, lr=7.60286e-05, gnorm=0.381, clip=0, loss_scale=8, train_wall=72, gb_free=11.9, wall=31438
2023-09-06 10:00:00 | INFO | train_inner | epoch 030:    178 / 1191 loss=1.91, trans_loss=4.744, nll_loss=1.965, w2v_ctc_loss=0.669, task_loss=2.394, task_loss_gen=4.81, contrastive_loss=0, total=6687.83, n_correct=4540.64, ppl=3.9, accuracy=67.894, wps=18628.9, ups=1.39, wpb=13375.7, bsz=449, num_updates=34700, lr=7.5919e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=71, gb_free=13.3, wall=31510
2023-09-06 10:01:13 | INFO | train_inner | epoch 030:    278 / 1191 loss=1.911, trans_loss=4.74, nll_loss=1.959, w2v_ctc_loss=0.676, task_loss=2.611, task_loss_gen=4.552, contrastive_loss=0, total=6754.94, n_correct=4588.02, ppl=3.89, accuracy=67.921, wps=18626.3, ups=1.38, wpb=13509.9, bsz=459.9, num_updates=34800, lr=7.58098e-05, gnorm=0.391, clip=0, loss_scale=8, train_wall=72, gb_free=11.4, wall=31582
2023-09-06 10:02:27 | INFO | train_inner | epoch 030:    378 / 1191 loss=1.905, trans_loss=4.742, nll_loss=1.962, w2v_ctc_loss=0.666, task_loss=2.324, task_loss_gen=4.259, contrastive_loss=0, total=6859.61, n_correct=4662, ppl=3.9, accuracy=67.963, wps=18520.3, ups=1.35, wpb=13719.2, bsz=488, num_updates=34900, lr=7.57011e-05, gnorm=0.376, clip=0, loss_scale=8, train_wall=73, gb_free=11.8, wall=31657
2023-09-06 10:03:39 | INFO | train_inner | epoch 030:    478 / 1191 loss=1.916, trans_loss=4.745, nll_loss=1.966, w2v_ctc_loss=0.681, task_loss=2.665, task_loss_gen=4.883, contrastive_loss=0, total=6645.7, n_correct=4503.59, ppl=3.91, accuracy=67.767, wps=18340, ups=1.38, wpb=13291.4, bsz=444.7, num_updates=35000, lr=7.55929e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=31729
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 10:04:52 | INFO | train_inner | epoch 030:    578 / 1191 loss=1.914, trans_loss=4.744, nll_loss=1.965, w2v_ctc_loss=0.678, task_loss=2.615, task_loss_gen=4.838, contrastive_loss=0, total=6672.87, n_correct=4531.08, ppl=3.9, accuracy=67.903, wps=18400.2, ups=1.38, wpb=13345.7, bsz=443.6, num_updates=35100, lr=7.54851e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=31802
2023-09-06 10:06:05 | INFO | train_inner | epoch 030:    678 / 1191 loss=1.917, trans_loss=4.743, nll_loss=1.963, w2v_ctc_loss=0.681, task_loss=2.689, task_loss_gen=5.237, contrastive_loss=0, total=6565.21, n_correct=4451.16, ppl=3.9, accuracy=67.799, wps=18020.9, ups=1.37, wpb=13130.4, bsz=421.9, num_updates=35200, lr=7.53778e-05, gnorm=0.396, clip=0, loss_scale=8, train_wall=72, gb_free=10.9, wall=31874
2023-09-06 10:07:18 | INFO | train_inner | epoch 030:    778 / 1191 loss=1.917, trans_loss=4.745, nll_loss=1.967, w2v_ctc_loss=0.681, task_loss=2.775, task_loss_gen=4.902, contrastive_loss=0, total=6657.47, n_correct=4513.42, ppl=3.91, accuracy=67.795, wps=18128.6, ups=1.36, wpb=13314.9, bsz=440.1, num_updates=35300, lr=7.5271e-05, gnorm=0.395, clip=0, loss_scale=8, train_wall=73, gb_free=13.9, wall=31948
2023-09-06 10:08:31 | INFO | train_inner | epoch 030:    878 / 1191 loss=1.913, trans_loss=4.745, nll_loss=1.967, w2v_ctc_loss=0.675, task_loss=2.611, task_loss_gen=5.005, contrastive_loss=0, total=6666.67, n_correct=4526.6, ppl=3.91, accuracy=67.899, wps=18317, ups=1.37, wpb=13333.3, bsz=443.1, num_updates=35400, lr=7.51646e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=32021
2023-09-06 10:09:44 | INFO | train_inner | epoch 030:    978 / 1191 loss=1.914, trans_loss=4.742, nll_loss=1.963, w2v_ctc_loss=0.682, task_loss=2.741, task_loss_gen=4.855, contrastive_loss=0, total=6645.69, n_correct=4512.27, ppl=3.9, accuracy=67.898, wps=18240.1, ups=1.37, wpb=13291.4, bsz=445.1, num_updates=35500, lr=7.50587e-05, gnorm=0.397, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=32094
2023-09-06 10:10:56 | INFO | train_inner | epoch 030:   1078 / 1191 loss=1.911, trans_loss=4.742, nll_loss=1.963, w2v_ctc_loss=0.679, task_loss=2.629, task_loss_gen=4.555, contrastive_loss=0, total=6766.02, n_correct=4598.83, ppl=3.9, accuracy=67.97, wps=18603.6, ups=1.37, wpb=13532, bsz=457.1, num_updates=35600, lr=7.49532e-05, gnorm=0.392, clip=0, loss_scale=8, train_wall=72, gb_free=15.1, wall=32166
2023-09-06 10:12:10 | INFO | train_inner | epoch 030:   1178 / 1191 loss=1.912, trans_loss=4.749, nll_loss=1.972, w2v_ctc_loss=0.674, task_loss=2.42, task_loss_gen=4.709, contrastive_loss=0, total=6709.38, n_correct=4548.32, ppl=3.92, accuracy=67.79, wps=18332, ups=1.37, wpb=13418.8, bsz=457, num_updates=35700, lr=7.48481e-05, gnorm=0.389, clip=0, loss_scale=8, train_wall=73, gb_free=10, wall=32239
2023-09-06 10:12:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
2023-09-06 10:12:52 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.751 | trans_loss 4.97 | nll_loss 2.211 | w2v_ctc_loss 1.275 | task_loss 9.238 | task_loss_gen 13.158 | contrastive_loss 0 | total 6138.43 | n_correct 4269.29 | ppl 4.63 | accuracy 69.55 | uer 18.437 | wer 19.706 | raw_wer 19.706 | bleu 27.04 | wps 1748.2 | wpb 6138.4 | bsz 201.1 | num_updates 35713 | best_bleu 27.04
2023-09-06 10:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35713 updates
2023-09-06 10:12:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 30 @ 35713 updates, score 27.04) (writing took 14.340260511031374 seconds)
2023-09-06 10:13:06 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-06 10:13:06 | INFO | train | epoch 030 | loss 1.912 | trans_loss 4.744 | nll_loss 1.965 | w2v_ctc_loss 0.676 | task_loss 2.542 | task_loss_gen 4.745 | contrastive_loss 0 | total 6703.69 | n_correct 4550.13 | ppl 3.9 | accuracy 67.875 | wps 17314 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 35713 | lr 7.48345e-05 | gnorm 0.391 | clip 0 | loss_scale 8 | train_wall 860 | gb_free 14.2 | wall 32296
2023-09-06 10:13:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:13:07 | INFO | fairseq.trainer | begin training epoch 31
2023-09-06 10:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:14:18 | INFO | train_inner | epoch 031:     87 / 1191 loss=1.907, trans_loss=4.729, nll_loss=1.945, w2v_ctc_loss=0.673, task_loss=2.705, task_loss_gen=5.236, contrastive_loss=0, total=6586.06, n_correct=4498.9, ppl=3.85, accuracy=68.309, wps=10267, ups=0.78, wpb=13172.1, bsz=416.6, num_updates=35800, lr=7.47435e-05, gnorm=0.394, clip=0, loss_scale=8, train_wall=72, gb_free=12.1, wall=32368
2023-09-06 10:15:31 | INFO | train_inner | epoch 031:    187 / 1191 loss=1.893, trans_loss=4.723, nll_loss=1.938, w2v_ctc_loss=0.656, task_loss=2.436, task_loss_gen=4.599, contrastive_loss=0, total=6738.97, n_correct=4611.03, ppl=3.83, accuracy=68.423, wps=18488.6, ups=1.37, wpb=13477.9, bsz=458.5, num_updates=35900, lr=7.46393e-05, gnorm=0.383, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=32441
2023-09-06 10:16:43 | INFO | train_inner | epoch 031:    287 / 1191 loss=1.903, trans_loss=4.724, nll_loss=1.94, w2v_ctc_loss=0.673, task_loss=2.716, task_loss_gen=5.069, contrastive_loss=0, total=6546.21, n_correct=4475.91, ppl=3.84, accuracy=68.374, wps=18048.2, ups=1.38, wpb=13092.4, bsz=430.8, num_updates=36000, lr=7.45356e-05, gnorm=0.392, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=32513
2023-09-06 10:16:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 10:17:17 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.734 | trans_loss 4.964 | nll_loss 2.201 | w2v_ctc_loss 1.231 | task_loss 8.747 | task_loss_gen 13.472 | contrastive_loss 0 | total 6138.43 | n_correct 4268.86 | ppl 4.6 | accuracy 69.543 | uer 18.306 | wer 19.68 | raw_wer 19.68 | bleu 26.92 | wps 1684.6 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 27.04
2023-09-06 10:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-09-06 10:17:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-06 10:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-06 10:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 26.92) (writing took 10.974562954041176 seconds)
--Backword ST Loss tensor(2049.0725, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1170.2964, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 10:18:41 | INFO | train_inner | epoch 031:    387 / 1191 loss=1.898, trans_loss=4.725, nll_loss=1.941, w2v_ctc_loss=0.665, task_loss=2.196, task_loss_gen=4.917, contrastive_loss=0, total=6748.95, n_correct=4614.5, ppl=3.84, accuracy=68.374, wps=11492.2, ups=0.85, wpb=13497.9, bsz=458.1, num_updates=36100, lr=7.44323e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=71, gb_free=14.5, wall=32631
2023-09-06 10:19:54 | INFO | train_inner | epoch 031:    487 / 1191 loss=1.907, trans_loss=4.734, nll_loss=1.952, w2v_ctc_loss=0.673, task_loss=2.416, task_loss_gen=5.391, contrastive_loss=0, total=6661.78, n_correct=4543.6, ppl=3.87, accuracy=68.204, wps=18289.8, ups=1.37, wpb=13323.6, bsz=426.6, num_updates=36200, lr=7.43294e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=32704
2023-09-06 10:21:06 | INFO | train_inner | epoch 031:    587 / 1191 loss=1.898, trans_loss=4.723, nll_loss=1.939, w2v_ctc_loss=0.666, task_loss=2.099, task_loss_gen=5.167, contrastive_loss=0, total=6681.68, n_correct=4566.23, ppl=3.84, accuracy=68.34, wps=18380, ups=1.38, wpb=13363.4, bsz=451.8, num_updates=36300, lr=7.4227e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=32776
2023-09-06 10:22:18 | INFO | train_inner | epoch 031:    687 / 1191 loss=1.89, trans_loss=4.716, nll_loss=1.93, w2v_ctc_loss=0.658, task_loss=2.014, task_loss_gen=4.605, contrastive_loss=0, total=6839.98, n_correct=4692.91, ppl=3.81, accuracy=68.61, wps=18984.9, ups=1.39, wpb=13680, bsz=478.1, num_updates=36400, lr=7.41249e-05, gnorm=0.37, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=32848
2023-09-06 10:23:32 | INFO | train_inner | epoch 031:    787 / 1191 loss=1.893, trans_loss=4.719, nll_loss=1.934, w2v_ctc_loss=0.664, task_loss=2.114, task_loss_gen=4.815, contrastive_loss=0, total=6796.23, n_correct=4659.66, ppl=3.82, accuracy=68.562, wps=18598.7, ups=1.37, wpb=13592.5, bsz=476.2, num_updates=36500, lr=7.40233e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=73, gb_free=12.5, wall=32921
2023-09-06 10:24:44 | INFO | train_inner | epoch 031:    887 / 1191 loss=1.894, trans_loss=4.722, nll_loss=1.938, w2v_ctc_loss=0.658, task_loss=2.275, task_loss_gen=5.181, contrastive_loss=0, total=6613.41, n_correct=4530.56, ppl=3.83, accuracy=68.506, wps=18184, ups=1.37, wpb=13226.8, bsz=445.6, num_updates=36600, lr=7.39221e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=32994
2023-09-06 10:25:56 | INFO | train_inner | epoch 031:    987 / 1191 loss=1.892, trans_loss=4.716, nll_loss=1.93, w2v_ctc_loss=0.66, task_loss=2.22, task_loss_gen=4.942, contrastive_loss=0, total=6712.51, n_correct=4608.77, ppl=3.81, accuracy=68.659, wps=18617.8, ups=1.39, wpb=13425, bsz=455.1, num_updates=36700, lr=7.38213e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=33066
2023-09-06 10:27:09 | INFO | train_inner | epoch 031:   1087 / 1191 loss=1.886, trans_loss=4.716, nll_loss=1.931, w2v_ctc_loss=0.654, task_loss=1.783, task_loss_gen=4.576, contrastive_loss=0, total=6884.21, n_correct=4730.86, ppl=3.81, accuracy=68.72, wps=19038.7, ups=1.38, wpb=13768.4, bsz=489.3, num_updates=36800, lr=7.3721e-05, gnorm=0.373, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=33139
2023-09-06 10:28:22 | INFO | train_inner | epoch 031:   1187 / 1191 loss=1.893, trans_loss=4.718, nll_loss=1.933, w2v_ctc_loss=0.66, task_loss=2.083, task_loss_gen=5.278, contrastive_loss=0, total=6656.88, n_correct=4566.64, ppl=3.82, accuracy=68.6, wps=18279.1, ups=1.37, wpb=13313.8, bsz=445.6, num_updates=36900, lr=7.3621e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=33211
2023-09-06 10:28:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2797.6106, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1707.4456, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1654.6521, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(929.7510, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3310.4385, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(2004.6670, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1780.8369, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1016.0110, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2112.1719, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1140.2004, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1131.2644, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(637.0609, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1175.3707, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(680.6300, device='cuda:2', grad_fn=<MulBackward0>)
2023-09-06 10:28:58 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.708 | trans_loss 4.957 | nll_loss 2.194 | w2v_ctc_loss 1.162 | task_loss 12.988 | task_loss_gen 12.719 | contrastive_loss 0 | total 6138.43 | n_correct 4285.43 | ppl 4.58 | accuracy 69.813 | uer 18.193 | wer 19.543 | raw_wer 19.543 | bleu 27.35 | wps 1737.4 | wpb 6138.4 | bsz 201.1 | num_updates 36904 | best_bleu 27.35
2023-09-06 10:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36904 updates
2023-09-06 10:28:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 31 @ 36904 updates, score 27.35) (writing took 12.602034433977678 seconds)
2023-09-06 10:29:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-06 10:29:11 | INFO | train | epoch 031 | loss 1.896 | trans_loss 4.722 | nll_loss 1.937 | w2v_ctc_loss 0.663 | task_loss 2.248 | task_loss_gen 4.983 | contrastive_loss 0 | total 6703.69 | n_correct 4590.41 | ppl 3.83 | accuracy 68.476 | wps 16555.6 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 36904 | lr 7.3617e-05 | gnorm 0.382 | clip 0 | loss_scale 16 | train_wall 858 | gb_free 10 | wall 33261
2023-09-06 10:29:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:29:11 | INFO | fairseq.trainer | begin training epoch 32
2023-09-06 10:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:30:28 | INFO | train_inner | epoch 032:     96 / 1191 loss=1.882, trans_loss=4.699, nll_loss=1.909, w2v_ctc_loss=0.651, task_loss=1.998, task_loss_gen=5.054, contrastive_loss=0, total=6689.32, n_correct=4614.09, ppl=3.75, accuracy=68.977, wps=10565.6, ups=0.79, wpb=13378.6, bsz=452.4, num_updates=37000, lr=7.35215e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=12.1, wall=33338
2023-09-06 10:31:41 | INFO | train_inner | epoch 032:    196 / 1191 loss=1.883, trans_loss=4.708, nll_loss=1.919, w2v_ctc_loss=0.648, task_loss=2.07, task_loss_gen=4.89, contrastive_loss=0, total=6806.67, n_correct=4683.37, ppl=3.78, accuracy=68.806, wps=18748.9, ups=1.38, wpb=13613.3, bsz=466.5, num_updates=37100, lr=7.34223e-05, gnorm=0.376, clip=0, loss_scale=16, train_wall=72, gb_free=10.5, wall=33411
2023-09-06 10:32:54 | INFO | train_inner | epoch 032:    296 / 1191 loss=1.887, trans_loss=4.708, nll_loss=1.92, w2v_ctc_loss=0.656, task_loss=2.264, task_loss_gen=5.149, contrastive_loss=0, total=6678.58, n_correct=4593.79, ppl=3.78, accuracy=68.784, wps=18346.3, ups=1.37, wpb=13357.2, bsz=446.2, num_updates=37200, lr=7.33236e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=33483
2023-09-06 10:34:06 | INFO | train_inner | epoch 032:    396 / 1191 loss=1.882, trans_loss=4.699, nll_loss=1.909, w2v_ctc_loss=0.655, task_loss=1.966, task_loss_gen=5.017, contrastive_loss=0, total=6758.65, n_correct=4661.15, ppl=3.75, accuracy=68.966, wps=18595.9, ups=1.38, wpb=13517.3, bsz=458.9, num_updates=37300, lr=7.32252e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=72, gb_free=7.7, wall=33556
2023-09-06 10:35:19 | INFO | train_inner | epoch 032:    496 / 1191 loss=1.886, trans_loss=4.708, nll_loss=1.92, w2v_ctc_loss=0.657, task_loss=2.077, task_loss_gen=5.089, contrastive_loss=0, total=6744.1, n_correct=4643.61, ppl=3.78, accuracy=68.854, wps=18455.8, ups=1.37, wpb=13488.2, bsz=454.9, num_updates=37400, lr=7.31272e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=73, gb_free=14, wall=33629
2023-09-06 10:36:32 | INFO | train_inner | epoch 032:    596 / 1191 loss=1.887, trans_loss=4.708, nll_loss=1.921, w2v_ctc_loss=0.659, task_loss=2.202, task_loss_gen=5.224, contrastive_loss=0, total=6688.42, n_correct=4606.64, ppl=3.79, accuracy=68.875, wps=18331.7, ups=1.37, wpb=13376.8, bsz=444.7, num_updates=37500, lr=7.30297e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=33702
2023-09-06 10:37:46 | INFO | train_inner | epoch 032:    696 / 1191 loss=1.886, trans_loss=4.702, nll_loss=1.912, w2v_ctc_loss=0.655, task_loss=2.258, task_loss_gen=5.465, contrastive_loss=0, total=6670, n_correct=4600.24, ppl=3.76, accuracy=68.969, wps=18081.3, ups=1.36, wpb=13340, bsz=436.6, num_updates=37600, lr=7.29325e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=33776
2023-09-06 10:38:59 | INFO | train_inner | epoch 032:    796 / 1191 loss=1.885, trans_loss=4.705, nll_loss=1.917, w2v_ctc_loss=0.657, task_loss=2.18, task_loss_gen=5.031, contrastive_loss=0, total=6761.99, n_correct=4657.65, ppl=3.78, accuracy=68.88, wps=18623.5, ups=1.38, wpb=13524, bsz=465.5, num_updates=37700, lr=7.28357e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=33849
2023-09-06 10:40:12 | INFO | train_inner | epoch 032:    896 / 1191 loss=1.886, trans_loss=4.706, nll_loss=1.918, w2v_ctc_loss=0.655, task_loss=2.169, task_loss_gen=5.36, contrastive_loss=0, total=6694.46, n_correct=4606.33, ppl=3.78, accuracy=68.808, wps=18314.7, ups=1.37, wpb=13388.9, bsz=444.9, num_updates=37800, lr=7.27393e-05, gnorm=0.38, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=33922
2023-09-06 10:41:24 | INFO | train_inner | epoch 032:    996 / 1191 loss=1.885, trans_loss=4.704, nll_loss=1.915, w2v_ctc_loss=0.66, task_loss=2.158, task_loss_gen=5.303, contrastive_loss=0, total=6610.12, n_correct=4557.45, ppl=3.77, accuracy=68.947, wps=18273, ups=1.38, wpb=13220.2, bsz=440.7, num_updates=37900, lr=7.26433e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=33994
2023-09-06 10:42:37 | INFO | train_inner | epoch 032:   1096 / 1191 loss=1.884, trans_loss=4.704, nll_loss=1.915, w2v_ctc_loss=0.654, task_loss=2.155, task_loss_gen=5.494, contrastive_loss=0, total=6609.06, n_correct=4555.36, ppl=3.77, accuracy=68.926, wps=18114.4, ups=1.37, wpb=13218.1, bsz=431, num_updates=38000, lr=7.25476e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=15, wall=34067
2023-09-06 10:42:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 10:43:10 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.719 | trans_loss 4.942 | nll_loss 2.175 | w2v_ctc_loss 1.233 | task_loss 8.453 | task_loss_gen 13.55 | contrastive_loss 0 | total 6138.43 | n_correct 4292.29 | ppl 4.52 | accuracy 69.925 | uer 18.263 | wer 19.509 | raw_wer 19.509 | bleu 27.62 | wps 1712.9 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 27.62
2023-09-06 10:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38000 updates
2023-09-06 10:43:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-06 10:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-06 10:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_32_38000.pt (epoch 32 @ 38000 updates, score 27.62) (writing took 13.705750732915476 seconds)
--Backword ST Loss tensor(2353.1250, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1357.4500, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 10:44:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2240.7683, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1264.2593, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2598.7163, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1521.3013, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1543.4166, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(865.6767, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2027.4688, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1133.1781, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2311.1260, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1364.1544, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1916.9280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1095.4872, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1585.4166, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(861.9168, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-06 10:45:07 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.725 | trans_loss 4.942 | nll_loss 2.178 | w2v_ctc_loss 1.252 | task_loss 6.287 | task_loss_gen 14.577 | contrastive_loss 0 | total 6138.43 | n_correct 4307.86 | ppl 4.52 | accuracy 70.179 | uer 18.172 | wer 19.487 | raw_wer 19.487 | bleu 27.89 | wps 1668.5 | wpb 6138.4 | bsz 201.1 | num_updates 38095 | best_bleu 27.89
2023-09-06 10:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38095 updates
2023-09-06 10:45:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 10:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 32 @ 38095 updates, score 27.89) (writing took 13.453006501076743 seconds)
2023-09-06 10:45:21 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-06 10:45:21 | INFO | train | epoch 032 | loss 1.884 | trans_loss 4.705 | nll_loss 1.916 | w2v_ctc_loss 0.655 | task_loss 2.099 | task_loss_gen 5.164 | contrastive_loss 0 | total 6703.69 | n_correct 4618.4 | ppl 3.77 | accuracy 68.893 | wps 16463.5 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 38095 | lr 7.24571e-05 | gnorm 0.38 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 11.4 | wall 34231
2023-09-06 10:45:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 10:45:21 | INFO | fairseq.trainer | begin training epoch 33
2023-09-06 10:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 10:45:32 | INFO | train_inner | epoch 033:      5 / 1191 loss=1.88, trans_loss=4.709, nll_loss=1.922, w2v_ctc_loss=0.649, task_loss=1.723, task_loss_gen=5.005, contrastive_loss=0, total=6703.57, n_correct=4618.54, ppl=3.79, accuracy=68.897, wps=7685.9, ups=0.57, wpb=13407.1, bsz=482.5, num_updates=38100, lr=7.24524e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=34241
2023-09-06 10:46:45 | INFO | train_inner | epoch 033:    105 / 1191 loss=1.868, trans_loss=4.688, nll_loss=1.895, w2v_ctc_loss=0.637, task_loss=1.755, task_loss_gen=5.341, contrastive_loss=0, total=6806.82, n_correct=4720.04, ppl=3.72, accuracy=69.343, wps=18538.1, ups=1.36, wpb=13613.6, bsz=467.7, num_updates=38200, lr=7.23575e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=13.9, wall=34315
2023-09-06 10:47:57 | INFO | train_inner | epoch 033:    205 / 1191 loss=1.871, trans_loss=4.686, nll_loss=1.893, w2v_ctc_loss=0.643, task_loss=1.66, task_loss_gen=5.572, contrastive_loss=0, total=6763.38, n_correct=4687.66, ppl=3.71, accuracy=69.309, wps=18738.1, ups=1.39, wpb=13526.8, bsz=455.5, num_updates=38300, lr=7.22629e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=34387
2023-09-06 10:49:11 | INFO | train_inner | epoch 033:    305 / 1191 loss=1.877, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.647, task_loss=1.824, task_loss_gen=6.163, contrastive_loss=0, total=6595.67, n_correct=4567.07, ppl=3.73, accuracy=69.243, wps=17991.7, ups=1.36, wpb=13191.3, bsz=434, num_updates=38400, lr=7.21688e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=12.1, wall=34460
2023-09-06 10:50:23 | INFO | train_inner | epoch 033:    405 / 1191 loss=1.876, trans_loss=4.692, nll_loss=1.899, w2v_ctc_loss=0.645, task_loss=1.879, task_loss_gen=6.094, contrastive_loss=0, total=6592.1, n_correct=4563.24, ppl=3.73, accuracy=69.223, wps=18325.7, ups=1.39, wpb=13184.2, bsz=432.6, num_updates=38500, lr=7.2075e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=71, gb_free=4, wall=34532
2023-09-06 10:51:34 | INFO | train_inner | epoch 033:    505 / 1191 loss=1.87, trans_loss=4.686, nll_loss=1.893, w2v_ctc_loss=0.64, task_loss=1.81, task_loss_gen=5.523, contrastive_loss=0, total=6691.29, n_correct=4640.73, ppl=3.71, accuracy=69.355, wps=18735.2, ups=1.4, wpb=13382.6, bsz=456.4, num_updates=38600, lr=7.19816e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=71, gb_free=14.8, wall=34604
2023-09-06 10:52:47 | INFO | train_inner | epoch 033:    605 / 1191 loss=1.876, trans_loss=4.686, nll_loss=1.892, w2v_ctc_loss=0.654, task_loss=1.843, task_loss_gen=5.966, contrastive_loss=0, total=6673.5, n_correct=4619.75, ppl=3.71, accuracy=69.225, wps=18211.1, ups=1.36, wpb=13347, bsz=446.7, num_updates=38700, lr=7.18885e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=11.3, wall=34677
2023-09-06 10:54:01 | INFO | train_inner | epoch 033:    705 / 1191 loss=1.872, trans_loss=4.688, nll_loss=1.895, w2v_ctc_loss=0.645, task_loss=1.74, task_loss_gen=6.039, contrastive_loss=0, total=6684.47, n_correct=4632.55, ppl=3.72, accuracy=69.303, wps=18241.4, ups=1.36, wpb=13368.9, bsz=443.1, num_updates=38800, lr=7.17958e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=4.2, wall=34750
2023-09-06 10:55:13 | INFO | train_inner | epoch 033:    805 / 1191 loss=1.865, trans_loss=4.684, nll_loss=1.89, w2v_ctc_loss=0.634, task_loss=1.711, task_loss_gen=5.502, contrastive_loss=0, total=6794.84, n_correct=4723.9, ppl=3.71, accuracy=69.522, wps=18771, ups=1.38, wpb=13589.7, bsz=467.9, num_updates=38900, lr=7.17035e-05, gnorm=0.374, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=34823
2023-09-06 10:56:26 | INFO | train_inner | epoch 033:    905 / 1191 loss=1.875, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.651, task_loss=1.686, task_loss_gen=5.705, contrastive_loss=0, total=6754.04, n_correct=4679.74, ppl=3.73, accuracy=69.288, wps=18482.6, ups=1.37, wpb=13508.1, bsz=463.2, num_updates=39000, lr=7.16115e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=34896
2023-09-06 10:57:39 | INFO | train_inner | epoch 033:   1005 / 1191 loss=1.877, trans_loss=4.697, nll_loss=1.907, w2v_ctc_loss=0.646, task_loss=1.827, task_loss_gen=6.163, contrastive_loss=0, total=6679.84, n_correct=4621.41, ppl=3.75, accuracy=69.184, wps=18201.2, ups=1.36, wpb=13359.7, bsz=440.5, num_updates=39100, lr=7.15199e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=73, gb_free=4.3, wall=34969
2023-09-06 10:58:53 | INFO | train_inner | epoch 033:   1105 / 1191 loss=1.875, trans_loss=4.691, nll_loss=1.898, w2v_ctc_loss=0.652, task_loss=1.638, task_loss_gen=5.862, contrastive_loss=0, total=6749.49, n_correct=4674.89, ppl=3.73, accuracy=69.263, wps=18429.4, ups=1.37, wpb=13499, bsz=463.2, num_updates=39200, lr=7.14286e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=12.6, wall=35043
2023-09-06 10:59:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:00:29 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.694 | trans_loss 4.926 | nll_loss 2.158 | w2v_ctc_loss 1.183 | task_loss 7.069 | task_loss_gen 14.452 | contrastive_loss 0 | total 6138.43 | n_correct 4309 | ppl 4.46 | accuracy 70.197 | uer 17.993 | wer 19.483 | raw_wer 19.483 | bleu 27.63 | wps 1646.3 | wpb 6138.4 | bsz 201.1 | num_updates 39286 | best_bleu 27.89
2023-09-06 11:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39286 updates
2023-09-06 11:00:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt
2023-09-06 11:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt
2023-09-06 11:00:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.6302.pt (epoch 33 @ 39286 updates, score 27.63) (writing took 8.112319394014776 seconds)
2023-09-06 11:00:38 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-06 11:00:38 | INFO | train | epoch 033 | loss 1.873 | trans_loss 4.689 | nll_loss 1.896 | w2v_ctc_loss 0.645 | task_loss 1.757 | task_loss_gen 5.804 | contrastive_loss 0 | total 6703.69 | n_correct 4645.9 | ppl 3.72 | accuracy 69.304 | wps 17413.3 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 39286 | lr 7.13503e-05 | gnorm 0.377 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 10.4 | wall 35148
2023-09-06 11:00:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:00:38 | INFO | fairseq.trainer | begin training epoch 34
2023-09-06 11:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:00:56 | INFO | train_inner | epoch 034:     14 / 1191 loss=1.866, trans_loss=4.682, nll_loss=1.888, w2v_ctc_loss=0.642, task_loss=1.676, task_loss_gen=5.599, contrastive_loss=0, total=6714.43, n_correct=4664.77, ppl=3.7, accuracy=69.474, wps=10876.8, ups=0.81, wpb=13428.9, bsz=468.7, num_updates=39300, lr=7.13376e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=35166
2023-09-06 11:02:09 | INFO | train_inner | epoch 034:    114 / 1191 loss=1.856, trans_loss=4.673, nll_loss=1.876, w2v_ctc_loss=0.624, task_loss=1.549, task_loss_gen=5.536, contrastive_loss=0, total=6812.86, n_correct=4750.72, ppl=3.67, accuracy=69.732, wps=18811.8, ups=1.38, wpb=13625.7, bsz=478.9, num_updates=39400, lr=7.1247e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=35238
2023-09-06 11:03:22 | INFO | train_inner | epoch 034:    214 / 1191 loss=1.865, trans_loss=4.677, nll_loss=1.88, w2v_ctc_loss=0.638, task_loss=1.91, task_loss_gen=5.935, contrastive_loss=0, total=6669.32, n_correct=4642.87, ppl=3.68, accuracy=69.615, wps=18262.6, ups=1.37, wpb=13338.6, bsz=448.9, num_updates=39500, lr=7.11568e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=35311
2023-09-06 11:04:34 | INFO | train_inner | epoch 034:    314 / 1191 loss=1.865, trans_loss=4.675, nll_loss=1.878, w2v_ctc_loss=0.637, task_loss=1.757, task_loss_gen=6.57, contrastive_loss=0, total=6597.66, n_correct=4593.44, ppl=3.68, accuracy=69.622, wps=18191.5, ups=1.38, wpb=13195.3, bsz=431.8, num_updates=39600, lr=7.10669e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=35384
2023-09-06 11:05:48 | INFO | train_inner | epoch 034:    414 / 1191 loss=1.866, trans_loss=4.679, nll_loss=1.883, w2v_ctc_loss=0.635, task_loss=1.781, task_loss_gen=6.231, contrastive_loss=0, total=6670.6, n_correct=4639.24, ppl=3.69, accuracy=69.548, wps=18118.8, ups=1.36, wpb=13341.2, bsz=433.1, num_updates=39700, lr=7.09773e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=35458
2023-09-06 11:07:01 | INFO | train_inner | epoch 034:    514 / 1191 loss=1.86, trans_loss=4.673, nll_loss=1.875, w2v_ctc_loss=0.629, task_loss=1.905, task_loss_gen=6.126, contrastive_loss=0, total=6672.9, n_correct=4654.34, ppl=3.67, accuracy=69.75, wps=18275.9, ups=1.37, wpb=13345.8, bsz=440, num_updates=39800, lr=7.08881e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=5.1, wall=35531
2023-09-06 11:08:14 | INFO | train_inner | epoch 034:    614 / 1191 loss=1.863, trans_loss=4.677, nll_loss=1.882, w2v_ctc_loss=0.637, task_loss=1.847, task_loss_gen=5.607, contrastive_loss=0, total=6739.24, n_correct=4689.31, ppl=3.68, accuracy=69.582, wps=18441.3, ups=1.37, wpb=13478.5, bsz=463.2, num_updates=39900, lr=7.07992e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=35604
2023-09-06 11:09:26 | INFO | train_inner | epoch 034:    714 / 1191 loss=1.866, trans_loss=4.678, nll_loss=1.883, w2v_ctc_loss=0.639, task_loss=1.51, task_loss_gen=6.337, contrastive_loss=0, total=6627.68, n_correct=4610.39, ppl=3.69, accuracy=69.563, wps=18403.6, ups=1.39, wpb=13255.4, bsz=441.5, num_updates=40000, lr=7.07107e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=35676
2023-09-06 11:09:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:10:01 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.703 | trans_loss 4.926 | nll_loss 2.159 | w2v_ctc_loss 1.213 | task_loss 6.628 | task_loss_gen 14.668 | contrastive_loss 0 | total 6138.43 | n_correct 4316.14 | ppl 4.47 | accuracy 70.313 | uer 17.979 | wer 19.36 | raw_wer 19.36 | bleu 28.05 | wps 1616.7 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 28.05
2023-09-06 11:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-09-06 11:10:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-06 11:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-06 11:10:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 28.05) (writing took 14.717169138020836 seconds)
--Backword ST Loss tensor(1834.7694, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1111.5298, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 11:11:29 | INFO | train_inner | epoch 034:    814 / 1191 loss=1.864, trans_loss=4.674, nll_loss=1.878, w2v_ctc_loss=0.643, task_loss=1.6, task_loss_gen=6.236, contrastive_loss=0, total=6664.33, n_correct=4642.12, ppl=3.67, accuracy=69.656, wps=10875, ups=0.82, wpb=13328.7, bsz=454.5, num_updates=40100, lr=7.06225e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=35798
2023-09-06 11:12:41 | INFO | train_inner | epoch 034:    914 / 1191 loss=1.867, trans_loss=4.673, nll_loss=1.876, w2v_ctc_loss=0.642, task_loss=1.574, task_loss_gen=7.003, contrastive_loss=0, total=6654.7, n_correct=4635.51, ppl=3.67, accuracy=69.658, wps=18315.6, ups=1.38, wpb=13309.4, bsz=428.5, num_updates=40200, lr=7.05346e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=35871
2023-09-06 11:13:54 | INFO | train_inner | epoch 034:   1014 / 1191 loss=1.866, trans_loss=4.678, nll_loss=1.883, w2v_ctc_loss=0.639, task_loss=1.33, task_loss_gen=7.162, contrastive_loss=0, total=6667.27, n_correct=4643.61, ppl=3.69, accuracy=69.648, wps=18357.5, ups=1.38, wpb=13334.5, bsz=439.7, num_updates=40300, lr=7.0447e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=12.1, wall=35944
2023-09-06 11:15:07 | INFO | train_inner | epoch 034:   1114 / 1191 loss=1.853, trans_loss=4.67, nll_loss=1.873, w2v_ctc_loss=0.624, task_loss=1.091, task_loss_gen=6.653, contrastive_loss=0, total=6861.81, n_correct=4790.88, ppl=3.66, accuracy=69.819, wps=18819.2, ups=1.37, wpb=13723.6, bsz=480.5, num_updates=40400, lr=7.03598e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=72, gb_free=13.3, wall=36017
2023-09-06 11:16:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2803.7712, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1537.4453, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
--Backword ST Loss tensor(2393.0061, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1172.1565, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
--Backword ST Loss tensor(1798.3802, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1000.9257, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
--Backword ST Loss tensor(2507.8379, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1453.2545, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
--Backword ST Loss tensor(1838.6941, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1009.7489, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
--Backword ST Loss tensor(1971.9866, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1184.1243, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
--Backword ST Loss tensor(2231.4927, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1287.1949, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
2023-09-06 11:16:38 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.702 | trans_loss 4.92 | nll_loss 2.151 | w2v_ctc_loss 1.225 | task_loss 5.99 | task_loss_gen 15.859 | contrastive_loss 0 | total 6138.43 | n_correct 4322.43 | ppl 4.44 | accuracy 70.416 | uer 17.666 | wer 18.977 | raw_wer 18.977 | bleu 27.9 | wps 1540.2 | wpb 6138.4 | bsz 201.1 | num_updates 40477 | best_bleu 28.05
2023-09-06 11:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40477 updates
2023-09-06 11:16:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt
2023-09-06 11:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt
2023-09-06 11:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_27.9009.pt (epoch 34 @ 40477 updates, score 27.9) (writing took 7.471538525889628 seconds)
2023-09-06 11:16:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-06 11:16:46 | INFO | train | epoch 034 | loss 1.862 | trans_loss 4.675 | nll_loss 1.878 | w2v_ctc_loss 0.635 | task_loss 1.593 | task_loss_gen 6.288 | contrastive_loss 0 | total 6703.69 | n_correct 4670.32 | ppl 3.68 | accuracy 69.668 | wps 16494.9 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 40477 | lr 7.02928e-05 | gnorm 0.378 | clip 0 | loss_scale 64 | train_wall 859 | gb_free 13.8 | wall 36116
2023-09-06 11:16:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:16:46 | INFO | fairseq.trainer | begin training epoch 35
2023-09-06 11:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:17:11 | INFO | train_inner | epoch 035:     23 / 1191 loss=1.855, trans_loss=4.67, nll_loss=1.873, w2v_ctc_loss=0.626, task_loss=1.312, task_loss_gen=6.645, contrastive_loss=0, total=6766.65, n_correct=4725.24, ppl=3.66, accuracy=69.831, wps=10876.7, ups=0.8, wpb=13533.3, bsz=471.5, num_updates=40500, lr=7.02728e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=72, gb_free=10.7, wall=36141
2023-09-06 11:18:24 | INFO | train_inner | epoch 035:    123 / 1191 loss=1.854, trans_loss=4.662, nll_loss=1.861, w2v_ctc_loss=0.631, task_loss=1.211, task_loss_gen=7.343, contrastive_loss=0, total=6708.25, n_correct=4695.48, ppl=3.63, accuracy=69.996, wps=18520.5, ups=1.38, wpb=13416.5, bsz=451.4, num_updates=40600, lr=7.01862e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=36213
2023-09-06 11:19:36 | INFO | train_inner | epoch 035:    223 / 1191 loss=1.851, trans_loss=4.66, nll_loss=1.859, w2v_ctc_loss=0.62, task_loss=1.256, task_loss_gen=7.663, contrastive_loss=0, total=6627.47, n_correct=4643.87, ppl=3.63, accuracy=70.07, wps=18403.4, ups=1.39, wpb=13254.9, bsz=444.5, num_updates=40700, lr=7.01e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=36285
2023-09-06 11:20:48 | INFO | train_inner | epoch 035:    323 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.856, w2v_ctc_loss=0.625, task_loss=1.136, task_loss_gen=7.257, contrastive_loss=0, total=6767.84, n_correct=4747.8, ppl=3.62, accuracy=70.152, wps=18631.6, ups=1.38, wpb=13535.7, bsz=463.2, num_updates=40800, lr=7.0014e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=36358
2023-09-06 11:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 11:22:02 | INFO | train_inner | epoch 035:    424 / 1191 loss=1.86, trans_loss=4.666, nll_loss=1.866, w2v_ctc_loss=0.633, task_loss=1.375, task_loss_gen=8.437, contrastive_loss=0, total=6572.39, n_correct=4598.2, ppl=3.65, accuracy=69.962, wps=17850.2, ups=1.36, wpb=13144.8, bsz=421.2, num_updates=40900, lr=6.99284e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=36432
2023-09-06 11:23:15 | INFO | train_inner | epoch 035:    524 / 1191 loss=1.854, trans_loss=4.661, nll_loss=1.86, w2v_ctc_loss=0.631, task_loss=1.455, task_loss_gen=6.919, contrastive_loss=0, total=6718.03, n_correct=4699.41, ppl=3.63, accuracy=69.952, wps=18469.3, ups=1.37, wpb=13436.1, bsz=456.1, num_updates=41000, lr=6.9843e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=36505
2023-09-06 11:24:28 | INFO | train_inner | epoch 035:    624 / 1191 loss=1.853, trans_loss=4.661, nll_loss=1.861, w2v_ctc_loss=0.626, task_loss=1.601, task_loss_gen=6.653, contrastive_loss=0, total=6702.8, n_correct=4685.06, ppl=3.63, accuracy=69.897, wps=18212.5, ups=1.36, wpb=13405.6, bsz=446.4, num_updates=41100, lr=6.9758e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=73, gb_free=9.3, wall=36578
2023-09-06 11:25:41 | INFO | train_inner | epoch 035:    724 / 1191 loss=1.857, trans_loss=4.669, nll_loss=1.871, w2v_ctc_loss=0.631, task_loss=1.653, task_loss_gen=6.453, contrastive_loss=0, total=6709.59, n_correct=4687.11, ppl=3.66, accuracy=69.857, wps=18453.4, ups=1.38, wpb=13419.2, bsz=453.6, num_updates=41200, lr=6.96733e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=36651
2023-09-06 11:26:54 | INFO | train_inner | epoch 035:    824 / 1191 loss=1.856, trans_loss=4.671, nll_loss=1.874, w2v_ctc_loss=0.625, task_loss=1.588, task_loss_gen=5.959, contrastive_loss=0, total=6756.65, n_correct=4718.22, ppl=3.66, accuracy=69.831, wps=18442.5, ups=1.36, wpb=13513.3, bsz=459.7, num_updates=41300, lr=6.95889e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=36724
2023-09-06 11:28:07 | INFO | train_inner | epoch 035:    924 / 1191 loss=1.849, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.621, task_loss=1.398, task_loss_gen=5.758, contrastive_loss=0, total=6770.43, n_correct=4739.35, ppl=3.64, accuracy=70.001, wps=18679.4, ups=1.38, wpb=13540.9, bsz=473.1, num_updates=41400, lr=6.95048e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=36797
2023-09-06 11:29:19 | INFO | train_inner | epoch 035:   1024 / 1191 loss=1.854, trans_loss=4.659, nll_loss=1.857, w2v_ctc_loss=0.629, task_loss=1.579, task_loss_gen=6.423, contrastive_loss=0, total=6727.5, n_correct=4708.17, ppl=3.62, accuracy=69.984, wps=18658.2, ups=1.39, wpb=13455, bsz=442.9, num_updates=41500, lr=6.9421e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=36869
2023-09-06 11:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 11:30:33 | INFO | train_inner | epoch 035:   1125 / 1191 loss=1.859, trans_loss=4.67, nll_loss=1.872, w2v_ctc_loss=0.635, task_loss=1.422, task_loss_gen=6.64, contrastive_loss=0, total=6635.8, n_correct=4636.34, ppl=3.66, accuracy=69.869, wps=17977.2, ups=1.35, wpb=13271.6, bsz=444.4, num_updates=41600, lr=6.93375e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=73, gb_free=11.4, wall=36943
2023-09-06 11:31:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:31:54 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.697 | trans_loss 4.917 | nll_loss 2.149 | w2v_ctc_loss 1.214 | task_loss 15.598 | task_loss_gen 13.25 | contrastive_loss 0 | total 6138.43 | n_correct 4325.43 | ppl 4.43 | accuracy 70.465 | uer 18.019 | wer 19.275 | raw_wer 19.275 | bleu 28.15 | wps 1724 | wpb 6138.4 | bsz 201.1 | num_updates 41666 | best_bleu 28.15
2023-09-06 11:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41666 updates
2023-09-06 11:31:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 11:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 11:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 35 @ 41666 updates, score 28.15) (writing took 13.84492250403855 seconds)
2023-09-06 11:32:08 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-09-06 11:32:08 | INFO | train | epoch 035 | loss 1.854 | trans_loss 4.664 | nll_loss 1.864 | w2v_ctc_loss 0.628 | task_loss 1.438 | task_loss_gen 6.774 | contrastive_loss 0 | total 6703.22 | n_correct 4689.35 | ppl 3.64 | accuracy 69.957 | wps 17279.9 | ups 1.29 | wpb 13406.4 | bsz 452.2 | num_updates 41666 | lr 6.92826e-05 | gnorm 0.379 | clip 0 | loss_scale 16 | train_wall 860 | gb_free 14.1 | wall 37038
2023-09-06 11:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:32:09 | INFO | fairseq.trainer | begin training epoch 36
2023-09-06 11:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:32:41 | INFO | train_inner | epoch 036:     34 / 1191 loss=1.852, trans_loss=4.663, nll_loss=1.864, w2v_ctc_loss=0.625, task_loss=1.814, task_loss_gen=5.616, contrastive_loss=0, total=6723.46, n_correct=4706.32, ppl=3.64, accuracy=69.998, wps=10498.2, ups=0.78, wpb=13446.9, bsz=466.6, num_updates=41700, lr=6.92543e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=73, gb_free=12.4, wall=37071
2023-09-06 11:33:53 | INFO | train_inner | epoch 036:    134 / 1191 loss=1.847, trans_loss=4.65, nll_loss=1.846, w2v_ctc_loss=0.621, task_loss=2.067, task_loss_gen=5.714, contrastive_loss=0, total=6615.18, n_correct=4644.24, ppl=3.6, accuracy=70.206, wps=18384.5, ups=1.39, wpb=13230.4, bsz=439.7, num_updates=41800, lr=6.91714e-05, gnorm=0.387, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=37143
2023-09-06 11:35:05 | INFO | train_inner | epoch 036:    234 / 1191 loss=1.837, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.61, task_loss=1.773, task_loss_gen=5.255, contrastive_loss=0, total=6741.47, n_correct=4751.61, ppl=3.57, accuracy=70.483, wps=18649.7, ups=1.38, wpb=13482.9, bsz=470.3, num_updates=41900, lr=6.90889e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=8.4, wall=37215
2023-09-06 11:36:17 | INFO | train_inner | epoch 036:    334 / 1191 loss=1.845, trans_loss=4.655, nll_loss=1.853, w2v_ctc_loss=0.619, task_loss=1.892, task_loss_gen=5.153, contrastive_loss=0, total=6788.68, n_correct=4765.72, ppl=3.61, accuracy=70.201, wps=18825.7, ups=1.39, wpb=13577.4, bsz=468.7, num_updates=42000, lr=6.90066e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=71, gb_free=13.9, wall=37287
2023-09-06 11:36:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 11:36:51 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.699 | trans_loss 4.916 | nll_loss 2.147 | w2v_ctc_loss 1.224 | task_loss 5.77 | task_loss_gen 15.282 | contrastive_loss 0 | total 6138.43 | n_correct 4330.29 | ppl 4.43 | accuracy 70.544 | uer 17.915 | wer 19.16 | raw_wer 19.16 | bleu 28.37 | wps 1703.9 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 28.37
2023-09-06 11:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-09-06 11:36:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-06 11:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-06 11:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 28.37) (writing took 13.892014258075505 seconds)
--Backword ST Loss tensor(2075.8174, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1128.3402, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 11:38:19 | INFO | train_inner | epoch 036:    434 / 1191 loss=1.847, trans_loss=4.655, nll_loss=1.854, w2v_ctc_loss=0.624, task_loss=1.981, task_loss_gen=5.037, contrastive_loss=0, total=6801.05, n_correct=4775.82, ppl=3.61, accuracy=70.222, wps=11212.8, ups=0.82, wpb=13602.1, bsz=473.4, num_updates=42100, lr=6.89246e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=73, gb_free=13.3, wall=37408
2023-09-06 11:39:31 | INFO | train_inner | epoch 036:    534 / 1191 loss=1.848, trans_loss=4.66, nll_loss=1.861, w2v_ctc_loss=0.617, task_loss=1.908, task_loss_gen=5.118, contrastive_loss=0, total=6792.76, n_correct=4758.11, ppl=3.63, accuracy=70.047, wps=18730.8, ups=1.38, wpb=13585.5, bsz=472.4, num_updates=42200, lr=6.88428e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=12.6, wall=37481
2023-09-06 11:40:44 | INFO | train_inner | epoch 036:    634 / 1191 loss=1.85, trans_loss=4.653, nll_loss=1.851, w2v_ctc_loss=0.627, task_loss=2.247, task_loss_gen=5.446, contrastive_loss=0, total=6667.35, n_correct=4681.02, ppl=3.61, accuracy=70.208, wps=18307.9, ups=1.37, wpb=13334.7, bsz=440.8, num_updates=42300, lr=6.87614e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.5, wall=37554
2023-09-06 11:41:57 | INFO | train_inner | epoch 036:    734 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.857, w2v_ctc_loss=0.621, task_loss=2.228, task_loss_gen=5.353, contrastive_loss=0, total=6721.83, n_correct=4711.16, ppl=3.62, accuracy=70.087, wps=18342.8, ups=1.36, wpb=13443.7, bsz=450.1, num_updates=42400, lr=6.86803e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=73, gb_free=13.9, wall=37627
2023-09-06 11:43:10 | INFO | train_inner | epoch 036:    834 / 1191 loss=1.849, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.621, task_loss=2.142, task_loss_gen=5.565, contrastive_loss=0, total=6678.35, n_correct=4679.49, ppl=3.64, accuracy=70.07, wps=18275.8, ups=1.37, wpb=13356.7, bsz=447.4, num_updates=42500, lr=6.85994e-05, gnorm=0.39, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=37700
2023-09-06 11:44:24 | INFO | train_inner | epoch 036:    934 / 1191 loss=1.855, trans_loss=4.66, nll_loss=1.86, w2v_ctc_loss=0.626, task_loss=2.412, task_loss_gen=5.975, contrastive_loss=0, total=6679.59, n_correct=4673.79, ppl=3.63, accuracy=69.971, wps=18204.3, ups=1.36, wpb=13359.2, bsz=429.9, num_updates=42600, lr=6.85189e-05, gnorm=0.392, clip=0, loss_scale=16, train_wall=73, gb_free=13.2, wall=37774
2023-09-06 11:45:36 | INFO | train_inner | epoch 036:   1034 / 1191 loss=1.848, trans_loss=4.66, nll_loss=1.861, w2v_ctc_loss=0.62, task_loss=2.027, task_loss_gen=5.33, contrastive_loss=0, total=6715.41, n_correct=4707.46, ppl=3.63, accuracy=70.099, wps=18579.9, ups=1.38, wpb=13430.8, bsz=465.8, num_updates=42700, lr=6.84386e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.8, wall=37846
2023-09-06 11:46:48 | INFO | train_inner | epoch 036:   1134 / 1191 loss=1.853, trans_loss=4.655, nll_loss=1.853, w2v_ctc_loss=0.631, task_loss=2.308, task_loss_gen=5.672, contrastive_loss=0, total=6605.28, n_correct=4631.84, ppl=3.61, accuracy=70.123, wps=18219, ups=1.38, wpb=13210.6, bsz=432.4, num_updates=42800, lr=6.83586e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=37918
2023-09-06 11:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2577.2063, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1551.1210, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2032.7184, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1166.4968, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2406.9739, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1356.9275, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2207.5479, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1273.7585, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1554.6871, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(850.8668, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1985.6858, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1166.7562, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2246.6257, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1182.2650, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 11:48:03 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.696 | trans_loss 4.907 | nll_loss 2.136 | w2v_ctc_loss 1.231 | task_loss 8.22 | task_loss_gen 14.287 | contrastive_loss 0 | total 6138.43 | n_correct 4327.29 | ppl 4.4 | accuracy 70.495 | uer 17.648 | wer 19.115 | raw_wer 19.115 | bleu 28.12 | wps 1718.5 | wpb 6138.4 | bsz 201.1 | num_updates 42857 | best_bleu 28.37
2023-09-06 11:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42857 updates
2023-09-06 11:48:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt
2023-09-06 11:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt
2023-09-06 11:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.1206.pt (epoch 36 @ 42857 updates, score 28.12) (writing took 7.892403287929483 seconds)
2023-09-06 11:48:11 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-09-06 11:48:11 | INFO | train | epoch 036 | loss 1.848 | trans_loss 4.656 | nll_loss 1.855 | w2v_ctc_loss 0.622 | task_loss 2.1 | task_loss_gen 5.438 | contrastive_loss 0 | total 6703.69 | n_correct 4701.92 | ppl 3.62 | accuracy 70.139 | wps 16587.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 42857 | lr 6.83131e-05 | gnorm 0.385 | clip 0 | loss_scale 16 | train_wall 858 | gb_free 12.7 | wall 38001
2023-09-06 11:48:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 11:48:11 | INFO | fairseq.trainer | begin training epoch 37
2023-09-06 11:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 11:48:50 | INFO | train_inner | epoch 037:     43 / 1191 loss=1.85, trans_loss=4.657, nll_loss=1.855, w2v_ctc_loss=0.623, task_loss=2.287, task_loss_gen=5.569, contrastive_loss=0, total=6672.81, n_correct=4678.39, ppl=3.62, accuracy=70.111, wps=10946.1, ups=0.82, wpb=13345.6, bsz=440.3, num_updates=42900, lr=6.82789e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=15.1, wall=38040
2023-09-06 11:50:03 | INFO | train_inner | epoch 037:    143 / 1191 loss=1.841, trans_loss=4.647, nll_loss=1.843, w2v_ctc_loss=0.611, task_loss=2.026, task_loss_gen=5.128, contrastive_loss=0, total=6762.6, n_correct=4757.04, ppl=3.59, accuracy=70.343, wps=18607.3, ups=1.38, wpb=13525.2, bsz=464, num_updates=43000, lr=6.81994e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=12.7, wall=38113
2023-09-06 11:51:16 | INFO | train_inner | epoch 037:    243 / 1191 loss=1.842, trans_loss=4.643, nll_loss=1.838, w2v_ctc_loss=0.617, task_loss=2.244, task_loss_gen=5.399, contrastive_loss=0, total=6696.92, n_correct=4715.29, ppl=3.58, accuracy=70.41, wps=18477.3, ups=1.38, wpb=13393.8, bsz=449.2, num_updates=43100, lr=6.81203e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=11.6, wall=38185
2023-09-06 11:52:28 | INFO | train_inner | epoch 037:    343 / 1191 loss=1.844, trans_loss=4.648, nll_loss=1.844, w2v_ctc_loss=0.617, task_loss=2.277, task_loss_gen=5.534, contrastive_loss=0, total=6637.72, n_correct=4666.73, ppl=3.59, accuracy=70.306, wps=18395, ups=1.39, wpb=13275.4, bsz=440.5, num_updates=43200, lr=6.80414e-05, gnorm=0.391, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=38258
2023-09-06 11:53:40 | INFO | train_inner | epoch 037:    443 / 1191 loss=1.839, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.612, task_loss=2.307, task_loss_gen=5.449, contrastive_loss=0, total=6703.75, n_correct=4721.84, ppl=3.57, accuracy=70.436, wps=18466.5, ups=1.38, wpb=13407.5, bsz=446.8, num_updates=43300, lr=6.79628e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=38330
2023-09-06 11:54:54 | INFO | train_inner | epoch 037:    543 / 1191 loss=1.839, trans_loss=4.642, nll_loss=1.837, w2v_ctc_loss=0.615, task_loss=2.3, task_loss_gen=5.43, contrastive_loss=0, total=6639.95, n_correct=4681.1, ppl=3.57, accuracy=70.499, wps=18050.8, ups=1.36, wpb=13279.9, bsz=449.3, num_updates=43400, lr=6.78844e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=73, gb_free=13.4, wall=38404
2023-09-06 11:56:07 | INFO | train_inner | epoch 037:    643 / 1191 loss=1.842, trans_loss=4.648, nll_loss=1.845, w2v_ctc_loss=0.608, task_loss=2.282, task_loss_gen=5.794, contrastive_loss=0, total=6631.82, n_correct=4664.94, ppl=3.59, accuracy=70.342, wps=18248.8, ups=1.38, wpb=13263.6, bsz=428.1, num_updates=43500, lr=6.78064e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=72, gb_free=12.2, wall=38476
2023-09-06 11:57:19 | INFO | train_inner | epoch 037:    743 / 1191 loss=1.844, trans_loss=4.646, nll_loss=1.842, w2v_ctc_loss=0.62, task_loss=2.322, task_loss_gen=5.367, contrastive_loss=0, total=6719.07, n_correct=4726.43, ppl=3.58, accuracy=70.344, wps=18523.3, ups=1.38, wpb=13438.1, bsz=451.8, num_updates=43600, lr=6.77285e-05, gnorm=0.389, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=38549
2023-09-06 11:58:32 | INFO | train_inner | epoch 037:    843 / 1191 loss=1.839, trans_loss=4.651, nll_loss=1.849, w2v_ctc_loss=0.61, task_loss=2.232, task_loss_gen=5.192, contrastive_loss=0, total=6808.88, n_correct=4787.97, ppl=3.6, accuracy=70.319, wps=18604.1, ups=1.37, wpb=13617.8, bsz=466.8, num_updates=43700, lr=6.7651e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=38622
2023-09-06 11:59:46 | INFO | train_inner | epoch 037:    943 / 1191 loss=1.831, trans_loss=4.642, nll_loss=1.838, w2v_ctc_loss=0.604, task_loss=1.85, task_loss_gen=5.033, contrastive_loss=0, total=6855.49, n_correct=4838.14, ppl=3.57, accuracy=70.573, wps=18739.3, ups=1.37, wpb=13711, bsz=499.9, num_updates=43800, lr=6.75737e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=38695
2023-09-06 12:00:59 | INFO | train_inner | epoch 037:   1043 / 1191 loss=1.841, trans_loss=4.643, nll_loss=1.839, w2v_ctc_loss=0.616, task_loss=2.101, task_loss_gen=6.079, contrastive_loss=0, total=6689.96, n_correct=4713.04, ppl=3.58, accuracy=70.449, wps=18241.7, ups=1.36, wpb=13379.9, bsz=441.4, num_updates=43900, lr=6.74967e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=38769
2023-09-06 12:02:12 | INFO | train_inner | epoch 037:   1143 / 1191 loss=1.845, trans_loss=4.652, nll_loss=1.85, w2v_ctc_loss=0.618, task_loss=1.774, task_loss_gen=6.389, contrastive_loss=0, total=6631.9, n_correct=4663.73, ppl=3.6, accuracy=70.323, wps=18270.3, ups=1.38, wpb=13263.8, bsz=443.6, num_updates=44000, lr=6.742e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=38841
2023-09-06 12:02:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:02:45 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.9 | nll_loss 2.126 | w2v_ctc_loss 1.182 | task_loss 10.978 | task_loss_gen 14.144 | contrastive_loss 0 | total 6138.43 | n_correct 4332.57 | ppl 4.37 | accuracy 70.581 | uer 17.578 | wer 19.011 | raw_wer 19.011 | bleu 28.19 | wps 1642.1 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 28.37
2023-09-06 12:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44000 updates
2023-09-06 12:02:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-06 12:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-06 12:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_37_44000.pt (epoch 37 @ 44000 updates, score 28.19) (writing took 8.800060661975294 seconds)
--Backword ST Loss tensor(2808.5962, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1697.1611, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:03:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2411.4268, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1402.1918, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1608.7341, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(919.2394, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2234.9009, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1283.4520, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1411.5433, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(826.7528, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2498.3572, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1368.0658, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1891.8773, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1088.8613, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1239.6111, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(652.8146, device='cuda:3', grad_fn=<MulBackward0>)
2023-09-06 12:04:02 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.69 | trans_loss 4.905 | nll_loss 2.131 | w2v_ctc_loss 1.218 | task_loss 7.318 | task_loss_gen 15.168 | contrastive_loss 0 | total 6138.43 | n_correct 4332 | ppl 4.38 | accuracy 70.572 | uer 17.592 | wer 18.929 | raw_wer 18.929 | bleu 28.48 | wps 1723.9 | wpb 6138.4 | bsz 201.1 | num_updates 44048 | best_bleu 28.48
2023-09-06 12:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44048 updates
2023-09-06 12:04:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 12:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 12:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 37 @ 44048 updates, score 28.48) (writing took 14.73071038397029 seconds)
2023-09-06 12:04:17 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-09-06 12:04:17 | INFO | train | epoch 037 | loss 1.841 | trans_loss 4.646 | nll_loss 1.842 | w2v_ctc_loss 0.614 | task_loss 2.143 | task_loss_gen 5.549 | contrastive_loss 0 | total 6703.69 | n_correct 4719.02 | ppl 3.59 | accuracy 70.394 | wps 16528.1 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 44048 | lr 6.73832e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 13.5 | wall 38967
2023-09-06 12:04:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:04:17 | INFO | fairseq.trainer | begin training epoch 38
2023-09-06 12:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:05:03 | INFO | train_inner | epoch 038:     52 / 1191 loss=1.842, trans_loss=4.648, nll_loss=1.844, w2v_ctc_loss=0.615, task_loss=1.91, task_loss_gen=6.55, contrastive_loss=0, total=6590.11, n_correct=4639.72, ppl=3.59, accuracy=70.404, wps=7681.7, ups=0.58, wpb=13180.2, bsz=432.1, num_updates=44100, lr=6.73435e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=39013
2023-09-06 12:06:16 | INFO | train_inner | epoch 038:    152 / 1191 loss=1.831, trans_loss=4.63, nll_loss=1.823, w2v_ctc_loss=0.605, task_loss=2.064, task_loss_gen=5.924, contrastive_loss=0, total=6707.39, n_correct=4748.29, ppl=3.54, accuracy=70.792, wps=18399.6, ups=1.37, wpb=13414.8, bsz=449.4, num_updates=44200, lr=6.72673e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=8, wall=39086
2023-09-06 12:07:29 | INFO | train_inner | epoch 038:    252 / 1191 loss=1.837, trans_loss=4.638, nll_loss=1.832, w2v_ctc_loss=0.611, task_loss=1.824, task_loss_gen=6.069, contrastive_loss=0, total=6683.44, n_correct=4714.2, ppl=3.56, accuracy=70.536, wps=18406.8, ups=1.38, wpb=13366.9, bsz=456.5, num_updates=44300, lr=6.71913e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=39158
2023-09-06 12:08:42 | INFO | train_inner | epoch 038:    352 / 1191 loss=1.834, trans_loss=4.63, nll_loss=1.822, w2v_ctc_loss=0.61, task_loss=1.786, task_loss_gen=6.468, contrastive_loss=0, total=6695.6, n_correct=4736.58, ppl=3.54, accuracy=70.742, wps=18131.6, ups=1.35, wpb=13391.2, bsz=443, num_updates=44400, lr=6.71156e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=39232
2023-09-06 12:09:55 | INFO | train_inner | epoch 038:    452 / 1191 loss=1.831, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.604, task_loss=1.715, task_loss_gen=6.031, contrastive_loss=0, total=6755.69, n_correct=4774.44, ppl=3.56, accuracy=70.673, wps=18506.6, ups=1.37, wpb=13511.4, bsz=476.3, num_updates=44500, lr=6.70402e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=39305
2023-09-06 12:11:08 | INFO | train_inner | epoch 038:    552 / 1191 loss=1.83, trans_loss=4.633, nll_loss=1.825, w2v_ctc_loss=0.603, task_loss=1.792, task_loss_gen=6.158, contrastive_loss=0, total=6799.96, n_correct=4815.04, ppl=3.54, accuracy=70.81, wps=18705.4, ups=1.38, wpb=13599.9, bsz=463.7, num_updates=44600, lr=6.6965e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=72, gb_free=11.7, wall=39378
2023-09-06 12:12:21 | INFO | train_inner | epoch 038:    652 / 1191 loss=1.835, trans_loss=4.643, nll_loss=1.839, w2v_ctc_loss=0.608, task_loss=1.85, task_loss_gen=5.674, contrastive_loss=0, total=6826.7, n_correct=4815.87, ppl=3.58, accuracy=70.545, wps=18702.9, ups=1.37, wpb=13653.4, bsz=474.6, num_updates=44700, lr=6.689e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=39451
2023-09-06 12:13:34 | INFO | train_inner | epoch 038:    752 / 1191 loss=1.832, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.606, task_loss=1.943, task_loss_gen=5.958, contrastive_loss=0, total=6730.12, n_correct=4754.98, ppl=3.56, accuracy=70.652, wps=18453.1, ups=1.37, wpb=13460.2, bsz=464.2, num_updates=44800, lr=6.68153e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=39524
2023-09-06 12:14:47 | INFO | train_inner | epoch 038:    852 / 1191 loss=1.835, trans_loss=4.636, nll_loss=1.829, w2v_ctc_loss=0.607, task_loss=2.106, task_loss_gen=6.514, contrastive_loss=0, total=6687.39, n_correct=4721.33, ppl=3.55, accuracy=70.6, wps=18343.8, ups=1.37, wpb=13374.8, bsz=435.4, num_updates=44900, lr=6.67409e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=11.5, wall=39597
2023-09-06 12:16:00 | INFO | train_inner | epoch 038:    952 / 1191 loss=1.837, trans_loss=4.64, nll_loss=1.834, w2v_ctc_loss=0.61, task_loss=2.16, task_loss_gen=6.137, contrastive_loss=0, total=6685.88, n_correct=4719.35, ppl=3.57, accuracy=70.587, wps=18310, ups=1.37, wpb=13371.8, bsz=446, num_updates=45000, lr=6.66667e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=10.6, wall=39670
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:0')
2023-09-06 12:17:12 | INFO | train_inner | epoch 038:   1052 / 1191 loss=1.837, trans_loss=4.636, nll_loss=1.83, w2v_ctc_loss=0.613, task_loss=2.19, task_loss_gen=6.311, contrastive_loss=0, total=6622.97, n_correct=4672.42, ppl=3.56, accuracy=70.549, wps=18313, ups=1.38, wpb=13245.9, bsz=440.1, num_updates=45100, lr=6.65927e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=39742
2023-09-06 12:18:25 | INFO | train_inner | epoch 038:   1152 / 1191 loss=1.833, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.605, task_loss=2.004, task_loss_gen=6.225, contrastive_loss=0, total=6688.64, n_correct=4724.66, ppl=3.56, accuracy=70.637, wps=18531.6, ups=1.39, wpb=13377.3, bsz=448.4, num_updates=45200, lr=6.6519e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=39814
2023-09-06 12:18:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1786, device='cuda:5')
2023-09-06 12:19:26 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.687 | trans_loss 4.899 | nll_loss 2.123 | w2v_ctc_loss 1.222 | task_loss 11.828 | task_loss_gen 14.459 | contrastive_loss 0 | total 6138.43 | n_correct 4343.29 | ppl 4.36 | accuracy 70.756 | uer 17.348 | wer 18.84 | raw_wer 18.84 | bleu 28.42 | wps 1780 | wpb 6138.4 | bsz 201.1 | num_updates 45239 | best_bleu 28.48
2023-09-06 12:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45239 updates
2023-09-06 12:19:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt
2023-09-06 12:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt
2023-09-06 12:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.4203.pt (epoch 38 @ 45239 updates, score 28.42) (writing took 8.190815735957585 seconds)
2023-09-06 12:19:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-09-06 12:19:35 | INFO | train | epoch 038 | loss 1.834 | trans_loss 4.636 | nll_loss 1.83 | w2v_ctc_loss 0.607 | task_loss 1.956 | task_loss_gen 6.172 | contrastive_loss 0 | total 6703.69 | n_correct 4735.87 | ppl 3.56 | accuracy 70.646 | wps 17400.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 45239 | lr 6.64903e-05 | gnorm 0.383 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 13.8 | wall 39885
2023-09-06 12:19:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:19:35 | INFO | fairseq.trainer | begin training epoch 39
2023-09-06 12:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:20:28 | INFO | train_inner | epoch 039:     61 / 1191 loss=1.833, trans_loss=4.633, nll_loss=1.826, w2v_ctc_loss=0.605, task_loss=2.293, task_loss_gen=6.889, contrastive_loss=0, total=6527.07, n_correct=4618.88, ppl=3.54, accuracy=70.765, wps=10601, ups=0.81, wpb=13054.1, bsz=420.4, num_updates=45300, lr=6.64455e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=10.1, wall=39938
2023-09-06 12:21:40 | INFO | train_inner | epoch 039:    161 / 1191 loss=1.825, trans_loss=4.621, nll_loss=1.81, w2v_ctc_loss=0.598, task_loss=2.072, task_loss_gen=6.39, contrastive_loss=0, total=6683.06, n_correct=4746.07, ppl=3.51, accuracy=71.016, wps=18419.1, ups=1.38, wpb=13366.1, bsz=440.5, num_updates=45400, lr=6.63723e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=40010
2023-09-06 12:22:53 | INFO | train_inner | epoch 039:    261 / 1191 loss=1.832, trans_loss=4.634, nll_loss=1.827, w2v_ctc_loss=0.604, task_loss=2.601, task_loss_gen=6.339, contrastive_loss=0, total=6673.47, n_correct=4717.58, ppl=3.55, accuracy=70.692, wps=18335.4, ups=1.37, wpb=13346.9, bsz=445, num_updates=45500, lr=6.62994e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=40083
2023-09-06 12:24:07 | INFO | train_inner | epoch 039:    361 / 1191 loss=1.833, trans_loss=4.629, nll_loss=1.821, w2v_ctc_loss=0.609, task_loss=2.581, task_loss_gen=6.325, contrastive_loss=0, total=6602.39, n_correct=4677.77, ppl=3.53, accuracy=70.85, wps=17968.3, ups=1.36, wpb=13204.8, bsz=427.5, num_updates=45600, lr=6.62266e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=40156
2023-09-06 12:25:19 | INFO | train_inner | epoch 039:    461 / 1191 loss=1.824, trans_loss=4.625, nll_loss=1.816, w2v_ctc_loss=0.594, task_loss=2.124, task_loss_gen=6.163, contrastive_loss=0, total=6752.25, n_correct=4789.08, ppl=3.52, accuracy=70.926, wps=18584.5, ups=1.38, wpb=13504.5, bsz=462.8, num_updates=45700, lr=6.61541e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=40229
2023-09-06 12:26:32 | INFO | train_inner | epoch 039:    561 / 1191 loss=1.826, trans_loss=4.623, nll_loss=1.814, w2v_ctc_loss=0.598, task_loss=2.067, task_loss_gen=6.386, contrastive_loss=0, total=6699.88, n_correct=4752.56, ppl=3.52, accuracy=70.935, wps=18401.2, ups=1.37, wpb=13399.8, bsz=450.3, num_updates=45800, lr=6.60819e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=40302
2023-09-06 12:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 12:27:46 | INFO | train_inner | epoch 039:    662 / 1191 loss=1.829, trans_loss=4.632, nll_loss=1.824, w2v_ctc_loss=0.603, task_loss=1.98, task_loss_gen=6.393, contrastive_loss=0, total=6707.94, n_correct=4744.18, ppl=3.54, accuracy=70.725, wps=18186.4, ups=1.36, wpb=13415.9, bsz=462.7, num_updates=45900, lr=6.60098e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=73, gb_free=6.1, wall=40376
2023-09-06 12:28:59 | INFO | train_inner | epoch 039:    762 / 1191 loss=1.83, trans_loss=4.632, nll_loss=1.824, w2v_ctc_loss=0.605, task_loss=2.059, task_loss_gen=6.301, contrastive_loss=0, total=6736.15, n_correct=4766.53, ppl=3.54, accuracy=70.76, wps=18384, ups=1.36, wpb=13472.3, bsz=455.3, num_updates=46000, lr=6.5938e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=12.7, wall=40449
2023-09-06 12:28:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:29:32 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.892 | nll_loss 2.114 | w2v_ctc_loss 1.189 | task_loss 11.979 | task_loss_gen 14.682 | contrastive_loss 0 | total 6138.43 | n_correct 4347 | ppl 4.33 | accuracy 70.816 | uer 17.26 | wer 18.661 | raw_wer 18.661 | bleu 28.72 | wps 1739.8 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 28.72
2023-09-06 12:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-09-06 12:29:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-06 12:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-06 12:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 28.72) (writing took 14.484925823984668 seconds)
--Backword ST Loss tensor(2797.3718, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1596.1881, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:30:59 | INFO | train_inner | epoch 039:    862 / 1191 loss=1.827, trans_loss=4.631, nll_loss=1.824, w2v_ctc_loss=0.599, task_loss=1.763, task_loss_gen=6.143, contrastive_loss=0, total=6798.2, n_correct=4814.61, ppl=3.54, accuracy=70.822, wps=11299.8, ups=0.83, wpb=13596.4, bsz=472.1, num_updates=46100, lr=6.58665e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=40569
2023-09-06 12:32:12 | INFO | train_inner | epoch 039:    962 / 1191 loss=1.821, trans_loss=4.622, nll_loss=1.812, w2v_ctc_loss=0.595, task_loss=1.862, task_loss_gen=5.887, contrastive_loss=0, total=6835.31, n_correct=4850.18, ppl=3.51, accuracy=70.958, wps=18729.2, ups=1.37, wpb=13670.6, bsz=480.9, num_updates=46200, lr=6.57952e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=40642
2023-09-06 12:33:25 | INFO | train_inner | epoch 039:   1062 / 1191 loss=1.822, trans_loss=4.624, nll_loss=1.815, w2v_ctc_loss=0.592, task_loss=2.006, task_loss_gen=6.05, contrastive_loss=0, total=6757.98, n_correct=4794.51, ppl=3.52, accuracy=70.946, wps=18672.8, ups=1.38, wpb=13516, bsz=459.7, num_updates=46300, lr=6.57241e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=40715
2023-09-06 12:34:37 | INFO | train_inner | epoch 039:   1162 / 1191 loss=1.837, trans_loss=4.633, nll_loss=1.825, w2v_ctc_loss=0.615, task_loss=2.267, task_loss_gen=6.709, contrastive_loss=0, total=6582.59, n_correct=4653.19, ppl=3.54, accuracy=70.689, wps=18160.7, ups=1.38, wpb=13165.2, bsz=428.8, num_updates=46400, lr=6.56532e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=40787
2023-09-06 12:34:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2541.7473, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1418.5901, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2095.0024, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1310.1160, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2316.9895, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1461.6812, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2651.2571, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1556.9844, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2435.6958, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1438.0281, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2181.4453, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1172.4755, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1851.2646, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1067.9636, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 12:35:31 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.895 | nll_loss 2.118 | w2v_ctc_loss 1.192 | task_loss 32.414 | task_loss_gen 19.448 | contrastive_loss 0 | total 6138.43 | n_correct 4345.57 | ppl 4.34 | accuracy 70.793 | uer 17.18 | wer 18.672 | raw_wer 18.672 | bleu 28.31 | wps 1726.4 | wpb 6138.4 | bsz 201.1 | num_updates 46429 | best_bleu 28.72
2023-09-06 12:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46429 updates
2023-09-06 12:35:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt
2023-09-06 12:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt
2023-09-06 12:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3101.pt (epoch 39 @ 46429 updates, score 28.31) (writing took 8.6472507850267 seconds)
2023-09-06 12:35:40 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-09-06 12:35:40 | INFO | train | epoch 039 | loss 1.828 | trans_loss 4.628 | nll_loss 1.819 | w2v_ctc_loss 0.601 | task_loss 2.128 | task_loss_gen 6.284 | contrastive_loss 0 | total 6703.27 | n_correct 4749.3 | ppl 3.53 | accuracy 70.851 | wps 16522.4 | ups 1.23 | wpb 13406.5 | bsz 452.1 | num_updates 46429 | lr 6.56327e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 13.1 | wall 40850
2023-09-06 12:35:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:35:41 | INFO | fairseq.trainer | begin training epoch 40
2023-09-06 12:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:36:40 | INFO | train_inner | epoch 040:     71 / 1191 loss=1.817, trans_loss=4.614, nll_loss=1.802, w2v_ctc_loss=0.591, task_loss=2.072, task_loss_gen=5.935, contrastive_loss=0, total=6767.38, n_correct=4812.29, ppl=3.49, accuracy=71.11, wps=11057.1, ups=0.82, wpb=13534.8, bsz=468.9, num_updates=46500, lr=6.55826e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=40910
2023-09-06 12:37:52 | INFO | train_inner | epoch 040:    171 / 1191 loss=1.822, trans_loss=4.617, nll_loss=1.805, w2v_ctc_loss=0.599, task_loss=2.388, task_loss_gen=6.035, contrastive_loss=0, total=6723.92, n_correct=4786.7, ppl=3.49, accuracy=71.189, wps=18725.2, ups=1.39, wpb=13447.8, bsz=450.2, num_updates=46600, lr=6.55122e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=40981
2023-09-06 12:39:04 | INFO | train_inner | epoch 040:    271 / 1191 loss=1.816, trans_loss=4.615, nll_loss=1.803, w2v_ctc_loss=0.589, task_loss=2.065, task_loss_gen=5.806, contrastive_loss=0, total=6753.31, n_correct=4802.28, ppl=3.49, accuracy=71.11, wps=18652.6, ups=1.38, wpb=13506.6, bsz=465.8, num_updates=46700, lr=6.5442e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=41054
2023-09-06 12:40:17 | INFO | train_inner | epoch 040:    371 / 1191 loss=1.826, trans_loss=4.62, nll_loss=1.81, w2v_ctc_loss=0.6, task_loss=2.259, task_loss_gen=6.625, contrastive_loss=0, total=6618.47, n_correct=4698.37, ppl=3.51, accuracy=70.989, wps=18062.8, ups=1.36, wpb=13236.9, bsz=438.2, num_updates=46800, lr=6.5372e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=41127
2023-09-06 12:41:30 | INFO | train_inner | epoch 040:    471 / 1191 loss=1.818, trans_loss=4.617, nll_loss=1.805, w2v_ctc_loss=0.591, task_loss=2.268, task_loss_gen=6.182, contrastive_loss=0, total=6719.05, n_correct=4781.41, ppl=3.5, accuracy=71.162, wps=18471, ups=1.37, wpb=13438.1, bsz=454.8, num_updates=46900, lr=6.53023e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=41200
2023-09-06 12:42:42 | INFO | train_inner | epoch 040:    571 / 1191 loss=1.818, trans_loss=4.618, nll_loss=1.807, w2v_ctc_loss=0.587, task_loss=2.249, task_loss_gen=5.869, contrastive_loss=0, total=6684.61, n_correct=4750.58, ppl=3.5, accuracy=71.067, wps=18462.9, ups=1.38, wpb=13369.2, bsz=455.8, num_updates=47000, lr=6.52328e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=41272
2023-09-06 12:43:56 | INFO | train_inner | epoch 040:    671 / 1191 loss=1.823, trans_loss=4.621, nll_loss=1.81, w2v_ctc_loss=0.595, task_loss=2.256, task_loss_gen=6.344, contrastive_loss=0, total=6699.46, n_correct=4755.32, ppl=3.51, accuracy=70.981, wps=18220.4, ups=1.36, wpb=13398.9, bsz=447.6, num_updates=47100, lr=6.51635e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=7.6, wall=41346
2023-09-06 12:45:09 | INFO | train_inner | epoch 040:    771 / 1191 loss=1.826, trans_loss=4.621, nll_loss=1.811, w2v_ctc_loss=0.602, task_loss=2.491, task_loss_gen=6.285, contrastive_loss=0, total=6659.73, n_correct=4729.33, ppl=3.51, accuracy=71.014, wps=18275.2, ups=1.37, wpb=13319.5, bsz=443.6, num_updates=47200, lr=6.50945e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=41419
2023-09-06 12:46:22 | INFO | train_inner | epoch 040:    871 / 1191 loss=1.827, trans_loss=4.624, nll_loss=1.815, w2v_ctc_loss=0.6, task_loss=2.559, task_loss_gen=6.113, contrastive_loss=0, total=6696.57, n_correct=4749.88, ppl=3.52, accuracy=70.93, wps=18223, ups=1.36, wpb=13393.1, bsz=441.7, num_updates=47300, lr=6.50256e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=41492
2023-09-06 12:47:35 | INFO | train_inner | epoch 040:    971 / 1191 loss=1.825, trans_loss=4.628, nll_loss=1.82, w2v_ctc_loss=0.594, task_loss=2.207, task_loss_gen=5.948, contrastive_loss=0, total=6694.1, n_correct=4747.47, ppl=3.53, accuracy=70.92, wps=18528.2, ups=1.38, wpb=13388.2, bsz=455.1, num_updates=47400, lr=6.4957e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=41565
2023-09-06 12:48:48 | INFO | train_inner | epoch 040:   1071 / 1191 loss=1.823, trans_loss=4.619, nll_loss=1.809, w2v_ctc_loss=0.601, task_loss=2.404, task_loss_gen=5.983, contrastive_loss=0, total=6744.49, n_correct=4790.34, ppl=3.5, accuracy=71.026, wps=18434.2, ups=1.37, wpb=13489, bsz=455.8, num_updates=47500, lr=6.48886e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=41638
2023-09-06 12:50:01 | INFO | train_inner | epoch 040:   1171 / 1191 loss=1.817, trans_loss=4.619, nll_loss=1.809, w2v_ctc_loss=0.586, task_loss=2.131, task_loss_gen=6.017, contrastive_loss=0, total=6706.26, n_correct=4768.15, ppl=3.5, accuracy=71.1, wps=18444.4, ups=1.38, wpb=13412.5, bsz=463.1, num_updates=47600, lr=6.48204e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=41710
2023-09-06 12:50:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:50:48 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.888 | nll_loss 2.11 | w2v_ctc_loss 1.157 | task_loss 15.74 | task_loss_gen 15.158 | contrastive_loss 0 | total 6138.43 | n_correct 4347.14 | ppl 4.32 | accuracy 70.818 | uer 17.132 | wer 18.657 | raw_wer 18.657 | bleu 28.38 | wps 1745.9 | wpb 6138.4 | bsz 201.1 | num_updates 47620 | best_bleu 28.72
2023-09-06 12:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47620 updates
2023-09-06 12:50:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt
2023-09-06 12:50:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt
2023-09-06 12:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.3807.pt (epoch 40 @ 47620 updates, score 28.38) (writing took 7.713489155983552 seconds)
2023-09-06 12:50:56 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-09-06 12:50:56 | INFO | train | epoch 040 | loss 1.822 | trans_loss 4.62 | nll_loss 1.809 | w2v_ctc_loss 0.594 | task_loss 2.281 | task_loss_gen 6.118 | contrastive_loss 0 | total 6703.69 | n_correct 4762.69 | ppl 3.5 | accuracy 71.046 | wps 17436.5 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 47620 | lr 6.48068e-05 | gnorm 0.386 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 11.9 | wall 41766
2023-09-06 12:50:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 12:50:56 | INFO | fairseq.trainer | begin training epoch 41
2023-09-06 12:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 12:52:02 | INFO | train_inner | epoch 041:     80 / 1191 loss=1.816, trans_loss=4.615, nll_loss=1.803, w2v_ctc_loss=0.588, task_loss=2.405, task_loss_gen=5.995, contrastive_loss=0, total=6708.43, n_correct=4776.38, ppl=3.49, accuracy=71.2, wps=11014.6, ups=0.82, wpb=13416.9, bsz=461.1, num_updates=47700, lr=6.47524e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=41832
2023-09-06 12:53:15 | INFO | train_inner | epoch 041:    180 / 1191 loss=1.821, trans_loss=4.614, nll_loss=1.801, w2v_ctc_loss=0.594, task_loss=2.172, task_loss_gen=6.323, contrastive_loss=0, total=6679.28, n_correct=4747.32, ppl=3.49, accuracy=71.075, wps=18511.1, ups=1.39, wpb=13358.6, bsz=446.1, num_updates=47800, lr=6.46846e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=41904
2023-09-06 12:54:28 | INFO | train_inner | epoch 041:    280 / 1191 loss=1.81, trans_loss=4.609, nll_loss=1.796, w2v_ctc_loss=0.582, task_loss=1.956, task_loss_gen=5.848, contrastive_loss=0, total=6799.31, n_correct=4851.95, ppl=3.47, accuracy=71.359, wps=18512.7, ups=1.36, wpb=13598.6, bsz=478, num_updates=47900, lr=6.46171e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=73, gb_free=13.6, wall=41978
2023-09-06 12:55:41 | INFO | train_inner | epoch 041:    380 / 1191 loss=1.813, trans_loss=4.61, nll_loss=1.797, w2v_ctc_loss=0.587, task_loss=1.611, task_loss_gen=6.663, contrastive_loss=0, total=6787.95, n_correct=4843.29, ppl=3.48, accuracy=71.351, wps=18575.7, ups=1.37, wpb=13575.9, bsz=460.8, num_updates=48000, lr=6.45497e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=42051
2023-09-06 12:55:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 12:56:14 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.668 | trans_loss 4.893 | nll_loss 2.116 | w2v_ctc_loss 1.174 | task_loss 22.324 | task_loss_gen 15.948 | contrastive_loss 0 | total 6138.43 | n_correct 4352.71 | ppl 4.34 | accuracy 70.909 | uer 17.279 | wer 18.736 | raw_wer 18.736 | bleu 28.64 | wps 1747.9 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 28.72
2023-09-06 12:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-09-06 12:56:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-06 12:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-06 12:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 28.64) (writing took 9.281694228993729 seconds)
--Backword ST Loss tensor(1687.9701, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(985.9595, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 12:57:36 | INFO | train_inner | epoch 041:    480 / 1191 loss=1.816, trans_loss=4.611, nll_loss=1.798, w2v_ctc_loss=0.593, task_loss=1.67, task_loss_gen=6.795, contrastive_loss=0, total=6778.68, n_correct=4837.4, ppl=3.48, accuracy=71.362, wps=11756.1, ups=0.87, wpb=13557.4, bsz=458.9, num_updates=48100, lr=6.44826e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=42166
2023-09-06 12:58:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 12:58:50 | INFO | train_inner | epoch 041:    581 / 1191 loss=1.809, trans_loss=4.605, nll_loss=1.79, w2v_ctc_loss=0.579, task_loss=1.533, task_loss_gen=7.01, contrastive_loss=0, total=6791.35, n_correct=4850.65, ppl=3.46, accuracy=71.424, wps=18568.6, ups=1.37, wpb=13582.7, bsz=462.3, num_updates=48200, lr=6.44157e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=72, gb_free=10.9, wall=42239
2023-09-06 13:00:02 | INFO | train_inner | epoch 041:    681 / 1191 loss=1.817, trans_loss=4.612, nll_loss=1.799, w2v_ctc_loss=0.593, task_loss=2.048, task_loss_gen=6.568, contrastive_loss=0, total=6677.75, n_correct=4756.62, ppl=3.48, accuracy=71.231, wps=18447.9, ups=1.38, wpb=13355.5, bsz=448.7, num_updates=48300, lr=6.43489e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=10.3, wall=42312
2023-09-06 13:01:15 | INFO | train_inner | epoch 041:    781 / 1191 loss=1.821, trans_loss=4.612, nll_loss=1.799, w2v_ctc_loss=0.597, task_loss=2.349, task_loss_gen=6.69, contrastive_loss=0, total=6547.43, n_correct=4660.12, ppl=3.48, accuracy=71.175, wps=18003.4, ups=1.37, wpb=13094.9, bsz=422.4, num_updates=48400, lr=6.42824e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=42385
2023-09-06 13:02:28 | INFO | train_inner | epoch 041:    881 / 1191 loss=1.818, trans_loss=4.61, nll_loss=1.796, w2v_ctc_loss=0.591, task_loss=2.441, task_loss_gen=6.465, contrastive_loss=0, total=6581.95, n_correct=4688.7, ppl=3.47, accuracy=71.236, wps=17973.4, ups=1.37, wpb=13163.9, bsz=427.6, num_updates=48500, lr=6.42161e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=10.4, wall=42458
2023-09-06 13:03:41 | INFO | train_inner | epoch 041:    981 / 1191 loss=1.823, trans_loss=4.62, nll_loss=1.811, w2v_ctc_loss=0.596, task_loss=2.514, task_loss_gen=6.483, contrastive_loss=0, total=6677.96, n_correct=4740.62, ppl=3.51, accuracy=70.989, wps=18236.7, ups=1.37, wpb=13355.9, bsz=444.6, num_updates=48600, lr=6.415e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=73, gb_free=13.8, wall=42531
2023-09-06 13:04:55 | INFO | train_inner | epoch 041:   1081 / 1191 loss=1.815, trans_loss=4.616, nll_loss=1.805, w2v_ctc_loss=0.588, task_loss=2.438, task_loss_gen=5.829, contrastive_loss=0, total=6841.34, n_correct=4874.27, ppl=3.49, accuracy=71.247, wps=18657.7, ups=1.36, wpb=13682.7, bsz=478.7, num_updates=48700, lr=6.40841e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=42604
2023-09-06 13:06:07 | INFO | train_inner | epoch 041:   1181 / 1191 loss=1.819, trans_loss=4.615, nll_loss=1.804, w2v_ctc_loss=0.589, task_loss=2.443, task_loss_gen=6.651, contrastive_loss=0, total=6589.42, n_correct=4689.07, ppl=3.49, accuracy=71.161, wps=18243.6, ups=1.38, wpb=13178.8, bsz=431.4, num_updates=48800, lr=6.40184e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=42677
2023-09-06 13:06:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1781.7280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1082.5361, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1912.5507, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1139.8356, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3617.3083, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(2218.8662, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1320.2130, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(737.5485, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2227.6731, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1271.6799, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2076.0674, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1156.4071, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2408.7302, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1482.7592, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 13:06:47 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.674 | trans_loss 4.893 | nll_loss 2.116 | w2v_ctc_loss 1.194 | task_loss 30.392 | task_loss_gen 18.337 | contrastive_loss 0 | total 6138.43 | n_correct 4347 | ppl 4.34 | accuracy 70.816 | uer 17.239 | wer 18.873 | raw_wer 18.873 | bleu 28.66 | wps 1750.1 | wpb 6138.4 | bsz 201.1 | num_updates 48810 | best_bleu 28.72
2023-09-06 13:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48810 updates
2023-09-06 13:06:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt
2023-09-06 13:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt
2023-09-06 13:06:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6600.pt (epoch 41 @ 48810 updates, score 28.66) (writing took 8.731995202950202 seconds)
2023-09-06 13:06:56 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-09-06 13:06:56 | INFO | train | epoch 041 | loss 1.816 | trans_loss 4.612 | nll_loss 1.8 | w2v_ctc_loss 0.589 | task_loss 2.123 | task_loss_gen 6.434 | contrastive_loss 0 | total 6704.36 | n_correct 4776.42 | ppl 3.48 | accuracy 71.244 | wps 16625.1 | ups 1.24 | wpb 13408.7 | bsz 452.2 | num_updates 48810 | lr 6.40119e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 11.3 | wall 42726
2023-09-06 13:06:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:06:56 | INFO | fairseq.trainer | begin training epoch 42
2023-09-06 13:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:08:09 | INFO | train_inner | epoch 042:     90 / 1191 loss=1.803, trans_loss=4.6, nll_loss=1.784, w2v_ctc_loss=0.574, task_loss=2.218, task_loss_gen=5.522, contrastive_loss=0, total=6824.86, n_correct=4884.58, ppl=3.44, accuracy=71.57, wps=11208.1, ups=0.82, wpb=13649.7, bsz=483.3, num_updates=48900, lr=6.39529e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=42798
2023-09-06 13:09:22 | INFO | train_inner | epoch 042:    190 / 1191 loss=1.814, trans_loss=4.607, nll_loss=1.793, w2v_ctc_loss=0.583, task_loss=2.361, task_loss_gen=6.215, contrastive_loss=0, total=6671.53, n_correct=4756.64, ppl=3.46, accuracy=71.298, wps=18181.7, ups=1.36, wpb=13343.1, bsz=441.1, num_updates=49000, lr=6.38877e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=42872
2023-09-06 13:10:35 | INFO | train_inner | epoch 042:    290 / 1191 loss=1.812, trans_loss=4.6, nll_loss=1.784, w2v_ctc_loss=0.589, task_loss=2.639, task_loss_gen=6.328, contrastive_loss=0, total=6650.86, n_correct=4753.68, ppl=3.44, accuracy=71.475, wps=18173.8, ups=1.37, wpb=13301.7, bsz=445.5, num_updates=49100, lr=6.38226e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=42945
2023-09-06 13:11:48 | INFO | train_inner | epoch 042:    390 / 1191 loss=1.809, trans_loss=4.601, nll_loss=1.786, w2v_ctc_loss=0.583, task_loss=2.782, task_loss_gen=6.291, contrastive_loss=0, total=6626.36, n_correct=4735.76, ppl=3.45, accuracy=71.468, wps=18173.5, ups=1.37, wpb=13252.7, bsz=447.3, num_updates=49200, lr=6.37577e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=43018
2023-09-06 13:13:01 | INFO | train_inner | epoch 042:    490 / 1191 loss=1.816, trans_loss=4.608, nll_loss=1.794, w2v_ctc_loss=0.587, task_loss=3.033, task_loss_gen=6.483, contrastive_loss=0, total=6622.87, n_correct=4724.41, ppl=3.47, accuracy=71.335, wps=18110.6, ups=1.37, wpb=13245.7, bsz=418.4, num_updates=49300, lr=6.3693e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=43091
2023-09-06 13:14:14 | INFO | train_inner | epoch 042:    590 / 1191 loss=1.821, trans_loss=4.611, nll_loss=1.799, w2v_ctc_loss=0.598, task_loss=2.747, task_loss_gen=6.362, contrastive_loss=0, total=6598.24, n_correct=4697.99, ppl=3.48, accuracy=71.201, wps=18233.3, ups=1.38, wpb=13196.5, bsz=431.9, num_updates=49400, lr=6.36285e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=12, wall=43163
2023-09-06 13:15:26 | INFO | train_inner | epoch 042:    690 / 1191 loss=1.808, trans_loss=4.606, nll_loss=1.792, w2v_ctc_loss=0.58, task_loss=2.248, task_loss_gen=5.606, contrastive_loss=0, total=6827.49, n_correct=4881.49, ppl=3.46, accuracy=71.498, wps=18787.4, ups=1.38, wpb=13655, bsz=480.8, num_updates=49500, lr=6.35642e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=72, gb_free=8.4, wall=43236
2023-09-06 13:16:39 | INFO | train_inner | epoch 042:    790 / 1191 loss=1.814, trans_loss=4.611, nll_loss=1.798, w2v_ctc_loss=0.59, task_loss=2.301, task_loss_gen=5.936, contrastive_loss=0, total=6715.54, n_correct=4789.81, ppl=3.48, accuracy=71.324, wps=18503.2, ups=1.38, wpb=13431.1, bsz=463.9, num_updates=49600, lr=6.35001e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=43309
2023-09-06 13:17:51 | INFO | train_inner | epoch 042:    890 / 1191 loss=1.81, trans_loss=4.601, nll_loss=1.785, w2v_ctc_loss=0.583, task_loss=2.313, task_loss_gen=6.419, contrastive_loss=0, total=6567.62, n_correct=4694.3, ppl=3.45, accuracy=71.476, wps=18244.8, ups=1.39, wpb=13135.2, bsz=440.7, num_updates=49700, lr=6.34361e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=43381
2023-09-06 13:19:04 | INFO | train_inner | epoch 042:    990 / 1191 loss=1.805, trans_loss=4.603, nll_loss=1.79, w2v_ctc_loss=0.576, task_loss=2.036, task_loss_gen=5.685, contrastive_loss=0, total=6827.16, n_correct=4876.74, ppl=3.46, accuracy=71.431, wps=18678.1, ups=1.37, wpb=13654.3, bsz=484, num_updates=49800, lr=6.33724e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=43454
2023-09-06 13:20:16 | INFO | train_inner | epoch 042:   1090 / 1191 loss=1.815, trans_loss=4.608, nll_loss=1.794, w2v_ctc_loss=0.586, task_loss=2.398, task_loss_gen=6.87, contrastive_loss=0, total=6664.62, n_correct=4753.72, ppl=3.47, accuracy=71.328, wps=18430.5, ups=1.38, wpb=13329.2, bsz=421.6, num_updates=49900, lr=6.33089e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=43526
2023-09-06 13:21:29 | INFO | train_inner | epoch 042:   1190 / 1191 loss=1.81, trans_loss=4.604, nll_loss=1.79, w2v_ctc_loss=0.585, task_loss=1.884, task_loss_gen=6.429, contrastive_loss=0, total=6824.38, n_correct=4878.68, ppl=3.46, accuracy=71.489, wps=18686.8, ups=1.37, wpb=13648.8, bsz=463.9, num_updates=50000, lr=6.32456e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=43599
2023-09-06 13:21:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-06 13:21:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 13:22:02 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.666 | trans_loss 4.883 | nll_loss 2.105 | w2v_ctc_loss 1.188 | task_loss 17.003 | task_loss_gen 15.493 | contrastive_loss 0 | total 6138.43 | n_correct 4353 | ppl 4.3 | accuracy 70.914 | uer 17.158 | wer 18.643 | raw_wer 18.643 | bleu 28.65 | wps 1728.4 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 28.72
2023-09-06 13:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50000 updates
2023-09-06 13:22:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt
2023-09-06 13:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt
2023-09-06 13:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_42_50000.pt (epoch 42 @ 50000 updates, score 28.65) (writing took 9.404174275929108 seconds)
2023-09-06 13:22:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-09-06 13:22:13 | INFO | train | epoch 042 | loss 1.811 | trans_loss 4.605 | nll_loss 1.791 | w2v_ctc_loss 0.584 | task_loss 2.4 | task_loss_gen 6.153 | contrastive_loss 0 | total 6705.54 | n_correct 4788.29 | ppl 3.46 | accuracy 71.408 | wps 17412.5 | ups 1.3 | wpb 13411.1 | bsz 452.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 14.2 | wall 43642
2023-09-06 13:22:13 | INFO | fairseq_cli.train | done training in 43587.3 seconds
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1728 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16744
2023-09-06 13:36:19 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16744
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-06 13:36:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-06 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-06 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-06 13:36:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16744', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-06 13:36:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-06 13:36:24 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 13:36:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-06 13:36:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-06 13:36:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-06 13:36:30 | INFO | root | load pretrained hubert
2023-09-06 13:36:38 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 13:36:41 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 13:36:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 13:36:48 | INFO | root | share the sematic adapter and textual encoder
2023-09-06 13:36:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-06 13:36:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-06 13:36:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-06 13:36:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-06 13:36:48 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-09-06 13:36:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-06 13:36:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 13:36:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:36:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:36:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 13:37:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-06 13:37:04 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-06 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-06 13:37:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 13:37:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 13:37:04 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-06 13:37:04 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-09-06 13:37:04 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 13:37:07 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
2023-09-06 13:37:23 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-06 13:37:24 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_last.pt (epoch 42 @ 50000 updates)
2023-09-06 13:37:24 | INFO | fairseq.trainer | loading train data for epoch 42
2023-09-06 13:37:24 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 13:37:24 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:37:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 13:37:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 13:37:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
2023-09-06 13:38:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:38:24 | INFO | fairseq.trainer | begin training epoch 42
2023-09-06 13:38:24 | INFO | fairseq_cli.train | Start iterating over samples
--Backword ST Loss tensor(1718.1373, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1021.0747, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 13:38:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1544.7151, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(901.5706, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(0., device='cuda:7', grad_fn=<MulBackward0>) 	MT Loss tensor(1474.5765, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(1379.3282, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(788.9484, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(2725.9148, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1605.6843, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(0., device='cuda:6', grad_fn=<MulBackward0>) 	MT Loss tensor(1474.5765, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(2211.3982, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1313.1876, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
--Backword ST Loss tensor(1982.1458, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1240.6178, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-06 13:39:07 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.666 | trans_loss 4.884 | nll_loss 2.106 | w2v_ctc_loss 1.186 | task_loss 16.727 | task_loss_gen 15.505 | contrastive_loss 0 | total 6138.43 | n_correct 4351.29 | ppl 4.31 | accuracy 70.886 | uer 17.164 | wer 18.646 | raw_wer 18.646 | bleu 28.61 | wps 1720.4 | wpb 6138.4 | bsz 201.1 | num_updates 50001 | best_bleu 28.72
2023-09-06 13:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50001 updates
2023-09-06 13:39:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt
2023-09-06 13:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt
2023-09-06 13:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6103.pt (epoch 42 @ 50001 updates, score 28.61) (writing took 8.464933410985395 seconds)
2023-09-06 13:39:16 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-09-06 13:39:16 | INFO | train | epoch 042 | loss 1.811 | trans_loss 4.605 | nll_loss 1.791 | w2v_ctc_loss 0.584 | task_loss 2.4 | task_loss_gen 6.156 | contrastive_loss 0 | total 6703.69 | n_correct 4787 | ppl 3.46 | accuracy 71.408 | wps 15682.3 | ups 1.17 | wpb 13407.4 | bsz 452.1 | num_updates 50001 | lr 6.32449e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 11.1 | wall 0
2023-09-06 13:39:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:39:16 | INFO | fairseq.trainer | begin training epoch 43
2023-09-06 13:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:40:38 | INFO | train_inner | epoch 043:     99 / 1191 loss=1.804, trans_loss=4.594, nll_loss=1.777, w2v_ctc_loss=0.576, task_loss=2.523, task_loss_gen=6.5, contrastive_loss=0, total=6732.96, n_correct=4827.73, ppl=3.43, accuracy=71.703, wps=5933, ups=0.44, wpb=13465.9, bsz=453.1, num_updates=50100, lr=6.31824e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=77, gb_free=11.3, wall=0
2023-09-06 13:41:53 | INFO | train_inner | epoch 043:    199 / 1191 loss=1.81, trans_loss=4.599, nll_loss=1.783, w2v_ctc_loss=0.583, task_loss=2.802, task_loss_gen=6.737, contrastive_loss=0, total=6600.22, n_correct=4721.61, ppl=3.44, accuracy=71.537, wps=17703.5, ups=1.34, wpb=13200.4, bsz=424.1, num_updates=50200, lr=6.31194e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=74, gb_free=13.9, wall=0
2023-09-06 13:43:08 | INFO | train_inner | epoch 043:    299 / 1191 loss=1.804, trans_loss=4.601, nll_loss=1.786, w2v_ctc_loss=0.575, task_loss=2.458, task_loss_gen=5.85, contrastive_loss=0, total=6773.88, n_correct=4845.19, ppl=3.45, accuracy=71.528, wps=18003.5, ups=1.33, wpb=13547.8, bsz=472.8, num_updates=50300, lr=6.30567e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=75, gb_free=13.7, wall=0
2023-09-06 13:44:23 | INFO | train_inner | epoch 043:    399 / 1191 loss=1.812, trans_loss=4.605, nll_loss=1.79, w2v_ctc_loss=0.587, task_loss=2.895, task_loss_gen=5.889, contrastive_loss=0, total=6701.97, n_correct=4789.29, ppl=3.46, accuracy=71.461, wps=17895.7, ups=1.34, wpb=13403.9, bsz=453.3, num_updates=50400, lr=6.29941e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=74, gb_free=12.6, wall=0
2023-09-06 13:45:37 | INFO | train_inner | epoch 043:    499 / 1191 loss=1.806, trans_loss=4.597, nll_loss=1.78, w2v_ctc_loss=0.578, task_loss=2.665, task_loss_gen=6.032, contrastive_loss=0, total=6702.87, n_correct=4802.7, ppl=3.43, accuracy=71.651, wps=18078.4, ups=1.35, wpb=13405.7, bsz=449.6, num_updates=50500, lr=6.29317e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=74, gb_free=14.1, wall=0
2023-09-06 13:46:52 | INFO | train_inner | epoch 043:    599 / 1191 loss=1.815, trans_loss=4.603, nll_loss=1.788, w2v_ctc_loss=0.591, task_loss=2.962, task_loss_gen=6.562, contrastive_loss=0, total=6674.04, n_correct=4764.55, ppl=3.45, accuracy=71.389, wps=17784.8, ups=1.33, wpb=13348.1, bsz=434.8, num_updates=50600, lr=6.28695e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=74, gb_free=14.2, wall=0
2023-09-06 13:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 13:48:06 | INFO | train_inner | epoch 043:    700 / 1191 loss=1.806, trans_loss=4.592, nll_loss=1.774, w2v_ctc_loss=0.581, task_loss=3.168, task_loss_gen=6.116, contrastive_loss=0, total=6623.68, n_correct=4742.6, ppl=3.42, accuracy=71.601, wps=17804.9, ups=1.34, wpb=13247.4, bsz=436.9, num_updates=50700, lr=6.28074e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=74, gb_free=13.7, wall=0
2023-09-06 13:49:22 | INFO | train_inner | epoch 043:    800 / 1191 loss=1.802, trans_loss=4.596, nll_loss=1.78, w2v_ctc_loss=0.571, task_loss=3.592, task_loss_gen=5.721, contrastive_loss=0, total=6741.48, n_correct=4827.03, ppl=3.43, accuracy=71.602, wps=17775.9, ups=1.32, wpb=13483, bsz=460.1, num_updates=50800, lr=6.27456e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=75, gb_free=9, wall=0
2023-09-06 13:50:36 | INFO | train_inner | epoch 043:    900 / 1191 loss=1.812, trans_loss=4.6, nll_loss=1.785, w2v_ctc_loss=0.588, task_loss=3.86, task_loss_gen=6.023, contrastive_loss=0, total=6579.57, n_correct=4701.36, ppl=3.45, accuracy=71.454, wps=17887.5, ups=1.36, wpb=13159.1, bsz=431.2, num_updates=50900, lr=6.26839e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=73, gb_free=11.6, wall=0
2023-09-06 13:51:49 | INFO | train_inner | epoch 043:   1000 / 1191 loss=1.806, trans_loss=4.602, nll_loss=1.788, w2v_ctc_loss=0.576, task_loss=3.458, task_loss_gen=5.569, contrastive_loss=0, total=6711.09, n_correct=4801.86, ppl=3.45, accuracy=71.551, wps=18259.4, ups=1.36, wpb=13422.2, bsz=452.8, num_updates=51000, lr=6.26224e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=73, gb_free=14.4, wall=0
2023-09-06 13:53:02 | INFO | train_inner | epoch 043:   1100 / 1191 loss=1.806, trans_loss=4.603, nll_loss=1.789, w2v_ctc_loss=0.573, task_loss=3.328, task_loss_gen=5.399, contrastive_loss=0, total=6760.41, n_correct=4829.72, ppl=3.46, accuracy=71.441, wps=18526.6, ups=1.37, wpb=13520.8, bsz=471.8, num_updates=51100, lr=6.25611e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=0
2023-09-06 13:54:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 13:54:41 | INFO | dev_st | epoch 043 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.885 | nll_loss 2.103 | w2v_ctc_loss 1.203 | task_loss 25.667 | task_loss_gen 16.834 | contrastive_loss 0 | total 6138.43 | n_correct 4356.86 | ppl 4.3 | accuracy 70.977 | uer 16.982 | wer 18.397 | raw_wer 18.397 | bleu 28.64 | wps 1740.2 | wpb 6138.4 | bsz 201.1 | num_updates 51191 | best_bleu 28.72
2023-09-06 13:54:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 51191 updates
2023-09-06 13:54:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt
2023-09-06 13:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt
2023-09-06 13:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6400.pt (epoch 43 @ 51191 updates, score 28.64) (writing took 7.690105653018691 seconds)
2023-09-06 13:54:49 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-09-06 13:54:49 | INFO | train | epoch 043 | loss 1.807 | trans_loss 4.599 | nll_loss 1.784 | w2v_ctc_loss 0.58 | task_loss 3.076 | task_loss_gen 5.952 | contrastive_loss 0 | total 6703.66 | n_correct 4795.71 | ppl 3.44 | accuracy 71.539 | wps 17092.8 | ups 1.27 | wpb 13407.3 | bsz 452.2 | num_updates 51191 | lr 6.25055e-05 | gnorm 0.41 | clip 0 | loss_scale 16 | train_wall 876 | gb_free 12.4 | wall 0
2023-09-06 13:54:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 13:54:50 | INFO | fairseq.trainer | begin training epoch 44
2023-09-06 13:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 13:55:04 | INFO | train_inner | epoch 044:      9 / 1191 loss=1.806, trans_loss=4.602, nll_loss=1.787, w2v_ctc_loss=0.58, task_loss=3.282, task_loss_gen=5.271, contrastive_loss=0, total=6797.32, n_correct=4862.85, ppl=3.45, accuracy=71.541, wps=11174.8, ups=0.82, wpb=13594.6, bsz=477.7, num_updates=51200, lr=6.25e-05, gnorm=0.431, clip=0, loss_scale=16, train_wall=71, gb_free=13.2, wall=0
2023-09-06 13:56:17 | INFO | train_inner | epoch 044:    109 / 1191 loss=1.8, trans_loss=4.587, nll_loss=1.768, w2v_ctc_loss=0.569, task_loss=3.516, task_loss_gen=5.722, contrastive_loss=0, total=6679.82, n_correct=4795.68, ppl=3.41, accuracy=71.794, wps=18187.6, ups=1.36, wpb=13359.6, bsz=441.2, num_updates=51300, lr=6.24391e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=14.3, wall=0
2023-09-06 13:57:32 | INFO | train_inner | epoch 044:    209 / 1191 loss=1.802, trans_loss=4.599, nll_loss=1.784, w2v_ctc_loss=0.568, task_loss=3.503, task_loss_gen=5.629, contrastive_loss=0, total=6695.29, n_correct=4794.74, ppl=3.44, accuracy=71.614, wps=18089.3, ups=1.35, wpb=13390.6, bsz=456.1, num_updates=51400, lr=6.23783e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=13, wall=0
2023-09-06 13:58:44 | INFO | train_inner | epoch 044:    309 / 1191 loss=1.804, trans_loss=4.597, nll_loss=1.78, w2v_ctc_loss=0.573, task_loss=3.537, task_loss_gen=5.456, contrastive_loss=0, total=6700.97, n_correct=4797.14, ppl=3.43, accuracy=71.589, wps=18464.3, ups=1.38, wpb=13401.9, bsz=452.6, num_updates=51500, lr=6.23177e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=0
2023-09-06 13:59:57 | INFO | train_inner | epoch 044:    409 / 1191 loss=1.796, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.568, task_loss=3.457, task_loss_gen=5.368, contrastive_loss=0, total=6804.45, n_correct=4885.83, ppl=3.41, accuracy=71.803, wps=18713.9, ups=1.38, wpb=13608.9, bsz=473.3, num_updates=51600, lr=6.22573e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=11.2, wall=0
2023-09-06 14:01:10 | INFO | train_inner | epoch 044:    509 / 1191 loss=1.807, trans_loss=4.601, nll_loss=1.785, w2v_ctc_loss=0.577, task_loss=3.477, task_loss_gen=5.648, contrastive_loss=0, total=6655.25, n_correct=4759.73, ppl=3.45, accuracy=71.518, wps=18159.2, ups=1.36, wpb=13310.5, bsz=441.2, num_updates=51700, lr=6.2197e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=0
2023-09-06 14:02:24 | INFO | train_inner | epoch 044:    609 / 1191 loss=1.802, trans_loss=4.598, nll_loss=1.781, w2v_ctc_loss=0.57, task_loss=3.406, task_loss_gen=5.154, contrastive_loss=0, total=6833.75, n_correct=4894.87, ppl=3.44, accuracy=71.628, wps=18427.3, ups=1.35, wpb=13667.5, bsz=466, num_updates=51800, lr=6.2137e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=0
2023-09-06 14:03:38 | INFO | train_inner | epoch 044:    709 / 1191 loss=1.807, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.582, task_loss=3.642, task_loss_gen=5.391, contrastive_loss=0, total=6684.9, n_correct=4788.82, ppl=3.44, accuracy=71.636, wps=18195, ups=1.36, wpb=13369.8, bsz=447.5, num_updates=51900, lr=6.20771e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=0
2023-09-06 14:04:52 | INFO | train_inner | epoch 044:    809 / 1191 loss=1.804, trans_loss=4.593, nll_loss=1.776, w2v_ctc_loss=0.576, task_loss=3.552, task_loss_gen=5.445, contrastive_loss=0, total=6656.84, n_correct=4773.51, ppl=3.42, accuracy=71.708, wps=18011, ups=1.35, wpb=13313.7, bsz=442.1, num_updates=52000, lr=6.20174e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=73, gb_free=15.2, wall=0
2023-09-06 14:04:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:05:24 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 3.665 | trans_loss 4.883 | nll_loss 2.1 | w2v_ctc_loss 1.187 | task_loss 35.107 | task_loss_gen 19.791 | contrastive_loss 0 | total 6138.43 | n_correct 4360.71 | ppl 4.29 | accuracy 71.04 | uer 17.038 | wer 18.49 | raw_wer 18.49 | bleu 28.65 | wps 1738.4 | wpb 6138.4 | bsz 201.1 | num_updates 52000 | best_bleu 28.72
2023-09-06 14:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 52000 updates
2023-09-06 14:05:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt
2023-09-06 14:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt
2023-09-06 14:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_44_52000.pt (epoch 44 @ 52000 updates, score 28.65) (writing took 8.818902858998626 seconds)
--Backword ST Loss tensor(1682.9839, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1005.3674, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 14:06:47 | INFO | train_inner | epoch 044:    909 / 1191 loss=1.805, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.577, task_loss=3.165, task_loss_gen=5.069, contrastive_loss=0, total=6781.41, n_correct=4860.43, ppl=3.44, accuracy=71.673, wps=11722.3, ups=0.86, wpb=13562.8, bsz=468.3, num_updates=52100, lr=6.19578e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=6.2, wall=0
2023-09-06 14:08:00 | INFO | train_inner | epoch 044:   1009 / 1191 loss=1.808, trans_loss=4.595, nll_loss=1.778, w2v_ctc_loss=0.583, task_loss=3.361, task_loss_gen=5.517, contrastive_loss=0, total=6659.98, n_correct=4764.49, ppl=3.43, accuracy=71.539, wps=18373.7, ups=1.38, wpb=13320, bsz=448.8, num_updates=52200, lr=6.18984e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=71, gb_free=12.5, wall=0
2023-09-06 14:09:12 | INFO | train_inner | epoch 044:   1109 / 1191 loss=1.802, trans_loss=4.591, nll_loss=1.773, w2v_ctc_loss=0.573, task_loss=3.433, task_loss_gen=5.618, contrastive_loss=0, total=6660.47, n_correct=4776.52, ppl=3.42, accuracy=71.714, wps=18453.1, ups=1.39, wpb=13320.9, bsz=444.5, num_updates=52300, lr=6.18392e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=71, gb_free=13.4, wall=0
2023-09-06 14:10:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2158.2170, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1306.8412, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1995.7280, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1179.7162, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2415.6912, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1534.7655, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1881.2483, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1080.7881, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2609.7634, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1619.9615, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2306.8945, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1374.9971, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2928.0994, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1799.6743, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-06 14:10:46 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 3.676 | trans_loss 4.885 | nll_loss 2.104 | w2v_ctc_loss 1.218 | task_loss 28.066 | task_loss_gen 18.005 | contrastive_loss 0 | total 6138.43 | n_correct 4355.57 | ppl 4.3 | accuracy 70.956 | uer 16.998 | wer 18.449 | raw_wer 18.449 | bleu 28.89 | wps 1625.1 | wpb 6138.4 | bsz 201.1 | num_updates 52382 | best_bleu 28.89
2023-09-06 14:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 52382 updates
2023-09-06 14:10:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 44 @ 52382 updates, score 28.89) (writing took 13.500149061903358 seconds)
2023-09-06 14:11:00 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-09-06 14:11:00 | INFO | train | epoch 044 | loss 1.804 | trans_loss 4.595 | nll_loss 1.779 | w2v_ctc_loss 0.575 | task_loss 3.448 | task_loss_gen 5.461 | contrastive_loss 0 | total 6703.69 | n_correct 4803.42 | ppl 3.43 | accuracy 71.653 | wps 16449.3 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 52382 | lr 6.17908e-05 | gnorm 0.43 | clip 0 | loss_scale 16 | train_wall 862 | gb_free 13.3 | wall 0
2023-09-06 14:11:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:11:00 | INFO | fairseq.trainer | begin training epoch 45
2023-09-06 14:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:11:22 | INFO | train_inner | epoch 045:     18 / 1191 loss=1.806, trans_loss=4.599, nll_loss=1.783, w2v_ctc_loss=0.583, task_loss=3.288, task_loss_gen=5.555, contrastive_loss=0, total=6632.04, n_correct=4749.21, ppl=3.44, accuracy=71.61, wps=10239.4, ups=0.77, wpb=13264.1, bsz=448.2, num_updates=52400, lr=6.17802e-05, gnorm=0.437, clip=0, loss_scale=16, train_wall=73, gb_free=9, wall=0
2023-09-06 14:12:35 | INFO | train_inner | epoch 045:    118 / 1191 loss=1.802, trans_loss=4.592, nll_loss=1.774, w2v_ctc_loss=0.568, task_loss=3.466, task_loss_gen=5.838, contrastive_loss=0, total=6670.4, n_correct=4785.24, ppl=3.42, accuracy=71.738, wps=18258.4, ups=1.37, wpb=13340.8, bsz=433.5, num_updates=52500, lr=6.17213e-05, gnorm=0.436, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:13:47 | INFO | train_inner | epoch 045:    218 / 1191 loss=1.798, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.569, task_loss=3.163, task_loss_gen=5.312, contrastive_loss=0, total=6727.47, n_correct=4835.67, ppl=3.4, accuracy=71.879, wps=18526.8, ups=1.38, wpb=13454.9, bsz=448.7, num_updates=52600, lr=6.16626e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=0
2023-09-06 14:15:00 | INFO | train_inner | epoch 045:    318 / 1191 loss=1.793, trans_loss=4.582, nll_loss=1.761, w2v_ctc_loss=0.562, task_loss=2.914, task_loss_gen=5.104, contrastive_loss=0, total=6780.65, n_correct=4875.75, ppl=3.39, accuracy=71.907, wps=18578.6, ups=1.37, wpb=13561.3, bsz=469, num_updates=52700, lr=6.16041e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=0
2023-09-06 14:16:13 | INFO | train_inner | epoch 045:    418 / 1191 loss=1.801, trans_loss=4.586, nll_loss=1.767, w2v_ctc_loss=0.573, task_loss=2.92, task_loss_gen=5.884, contrastive_loss=0, total=6562.23, n_correct=4714.52, ppl=3.4, accuracy=71.843, wps=18114.5, ups=1.38, wpb=13124.5, bsz=429.5, num_updates=52800, lr=6.15457e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=0
2023-09-06 14:17:26 | INFO | train_inner | epoch 045:    518 / 1191 loss=1.8, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.574, task_loss=2.73, task_loss_gen=5.492, contrastive_loss=0, total=6731.19, n_correct=4839.78, ppl=3.41, accuracy=71.901, wps=18375.2, ups=1.36, wpb=13462.4, bsz=449.9, num_updates=52900, lr=6.14875e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=14.4, wall=0
2023-09-06 14:18:40 | INFO | train_inner | epoch 045:    618 / 1191 loss=1.798, trans_loss=4.591, nll_loss=1.773, w2v_ctc_loss=0.571, task_loss=2.396, task_loss_gen=5.243, contrastive_loss=0, total=6800.14, n_correct=4881.13, ppl=3.42, accuracy=71.78, wps=18469.5, ups=1.36, wpb=13600.3, bsz=479.9, num_updates=53000, lr=6.14295e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=73, gb_free=14, wall=0
2023-09-06 14:19:52 | INFO | train_inner | epoch 045:    718 / 1191 loss=1.8, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.574, task_loss=2.392, task_loss_gen=6.045, contrastive_loss=0, total=6648.02, n_correct=4774.7, ppl=3.4, accuracy=71.821, wps=18345.9, ups=1.38, wpb=13296, bsz=435, num_updates=53100, lr=6.13716e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=0
2023-09-06 14:21:05 | INFO | train_inner | epoch 045:    818 / 1191 loss=1.796, trans_loss=4.584, nll_loss=1.764, w2v_ctc_loss=0.57, task_loss=2.451, task_loss_gen=5.681, contrastive_loss=0, total=6743.87, n_correct=4849.57, ppl=3.4, accuracy=71.911, wps=18487.7, ups=1.37, wpb=13487.7, bsz=463.9, num_updates=53200, lr=6.13139e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=0
2023-09-06 14:22:17 | INFO | train_inner | epoch 045:    918 / 1191 loss=1.798, trans_loss=4.587, nll_loss=1.768, w2v_ctc_loss=0.568, task_loss=2.691, task_loss_gen=6.064, contrastive_loss=0, total=6624.82, n_correct=4760.69, ppl=3.41, accuracy=71.861, wps=18335.5, ups=1.38, wpb=13249.6, bsz=437.6, num_updates=53300, lr=6.12564e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:23:31 | INFO | train_inner | epoch 045:   1018 / 1191 loss=1.798, trans_loss=4.589, nll_loss=1.77, w2v_ctc_loss=0.569, task_loss=2.591, task_loss_gen=5.557, contrastive_loss=0, total=6761.87, n_correct=4850.04, ppl=3.41, accuracy=71.726, wps=18474.6, ups=1.37, wpb=13523.7, bsz=475.5, num_updates=53400, lr=6.1199e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=73, gb_free=13.3, wall=0
2023-09-06 14:24:45 | INFO | train_inner | epoch 045:   1118 / 1191 loss=1.801, trans_loss=4.598, nll_loss=1.782, w2v_ctc_loss=0.568, task_loss=2.687, task_loss_gen=5.62, contrastive_loss=0, total=6739.03, n_correct=4826.14, ppl=3.44, accuracy=71.615, wps=18224.2, ups=1.35, wpb=13478.1, bsz=456.6, num_updates=53500, lr=6.11418e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=0
2023-09-06 14:25:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:26:11 | INFO | dev_st | epoch 045 | valid on 'dev_st' subset | loss 3.657 | trans_loss 4.874 | nll_loss 2.09 | w2v_ctc_loss 1.177 | task_loss 21.59 | task_loss_gen 15.798 | contrastive_loss 0 | total 6138.43 | n_correct 4365.43 | ppl 4.26 | accuracy 71.116 | uer 16.704 | wer 18.274 | raw_wer 18.274 | bleu 29.25 | wps 1770.2 | wpb 6138.4 | bsz 201.1 | num_updates 53573 | best_bleu 29.25
2023-09-06 14:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 53573 updates
2023-09-06 14:26:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 14:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_best.pt (epoch 45 @ 53573 updates, score 29.25) (writing took 13.300631770980544 seconds)
2023-09-06 14:26:24 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-09-06 14:26:24 | INFO | train | epoch 045 | loss 1.799 | trans_loss 4.589 | nll_loss 1.77 | w2v_ctc_loss 0.57 | task_loss 2.77 | task_loss_gen 5.637 | contrastive_loss 0 | total 6703.69 | n_correct 4813.43 | ppl 3.41 | accuracy 71.803 | wps 17276.1 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 53573 | lr 6.11001e-05 | gnorm 0.403 | clip 0 | loss_scale 32 | train_wall 862 | gb_free 13.2 | wall 0
2023-09-06 14:26:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:26:25 | INFO | fairseq.trainer | begin training epoch 46
2023-09-06 14:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:26:52 | INFO | train_inner | epoch 046:     27 / 1191 loss=1.795, trans_loss=4.585, nll_loss=1.765, w2v_ctc_loss=0.566, task_loss=2.723, task_loss_gen=5.702, contrastive_loss=0, total=6718.04, n_correct=4830.12, ppl=3.4, accuracy=71.898, wps=10581.2, ups=0.79, wpb=13436.1, bsz=454.9, num_updates=53600, lr=6.10847e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:28:04 | INFO | train_inner | epoch 046:    127 / 1191 loss=1.792, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.563, task_loss=2.786, task_loss_gen=6.082, contrastive_loss=0, total=6663.69, n_correct=4803.02, ppl=3.37, accuracy=72.077, wps=18420.7, ups=1.38, wpb=13327.4, bsz=437.6, num_updates=53700, lr=6.10278e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=0
2023-09-06 14:29:17 | INFO | train_inner | epoch 046:    227 / 1191 loss=1.792, trans_loss=4.58, nll_loss=1.759, w2v_ctc_loss=0.559, task_loss=2.464, task_loss_gen=5.674, contrastive_loss=0, total=6762.2, n_correct=4864.82, ppl=3.38, accuracy=71.941, wps=18609.1, ups=1.38, wpb=13524.4, bsz=463.9, num_updates=53800, lr=6.09711e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=0
2023-09-06 14:30:29 | INFO | train_inner | epoch 046:    327 / 1191 loss=1.791, trans_loss=4.579, nll_loss=1.758, w2v_ctc_loss=0.562, task_loss=2.411, task_loss_gen=5.562, contrastive_loss=0, total=6829.04, n_correct=4918.52, ppl=3.38, accuracy=72.024, wps=18769.7, ups=1.37, wpb=13658.1, bsz=469.8, num_updates=53900, lr=6.09145e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=0
2023-09-06 14:31:44 | INFO | train_inner | epoch 046:    427 / 1191 loss=1.792, trans_loss=4.582, nll_loss=1.762, w2v_ctc_loss=0.564, task_loss=2.642, task_loss_gen=5.877, contrastive_loss=0, total=6722.66, n_correct=4842.51, ppl=3.39, accuracy=72.033, wps=18139.4, ups=1.35, wpb=13445.3, bsz=461.7, num_updates=54000, lr=6.08581e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=0
2023-09-06 14:31:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:32:17 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 3.677 | trans_loss 4.88 | nll_loss 2.097 | w2v_ctc_loss 1.231 | task_loss 38.247 | task_loss_gen 21.142 | contrastive_loss 0 | total 6138.43 | n_correct 4367.29 | ppl 4.28 | accuracy 71.147 | uer 17.15 | wer 18.643 | raw_wer 18.643 | bleu 28.62 | wps 1691.4 | wpb 6138.4 | bsz 201.1 | num_updates 54000 | best_bleu 29.25
2023-09-06 14:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 54000 updates
2023-09-06 14:32:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt
2023-09-06 14:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt
2023-09-06 14:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_46_54000.pt (epoch 46 @ 54000 updates, score 28.62) (writing took 9.978976218029857 seconds)
--Backword ST Loss tensor(3481.8765, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(2023.9858, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 14:33:40 | INFO | train_inner | epoch 046:    527 / 1191 loss=1.792, trans_loss=4.582, nll_loss=1.761, w2v_ctc_loss=0.561, task_loss=2.953, task_loss_gen=6.052, contrastive_loss=0, total=6766.53, n_correct=4871.62, ppl=3.39, accuracy=71.996, wps=11662.4, ups=0.86, wpb=13533.1, bsz=463.2, num_updates=54100, lr=6.08018e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=0
2023-09-06 14:34:53 | INFO | train_inner | epoch 046:    627 / 1191 loss=1.793, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.563, task_loss=3.091, task_loss_gen=5.983, contrastive_loss=0, total=6658.17, n_correct=4793.99, ppl=3.38, accuracy=72.002, wps=18265, ups=1.37, wpb=13316.3, bsz=452.1, num_updates=54200, lr=6.07457e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=0
2023-09-06 14:36:05 | INFO | train_inner | epoch 046:    727 / 1191 loss=1.79, trans_loss=4.578, nll_loss=1.757, w2v_ctc_loss=0.559, task_loss=2.736, task_loss_gen=5.683, contrastive_loss=0, total=6763.57, n_correct=4875.39, ppl=3.38, accuracy=72.083, wps=18692, ups=1.38, wpb=13527.1, bsz=458.9, num_updates=54300, lr=6.06897e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=11.7, wall=0
2023-09-06 14:37:18 | INFO | train_inner | epoch 046:    827 / 1191 loss=1.797, trans_loss=4.589, nll_loss=1.771, w2v_ctc_loss=0.567, task_loss=2.836, task_loss_gen=5.761, contrastive_loss=0, total=6721.64, n_correct=4829.34, ppl=3.41, accuracy=71.848, wps=18320.6, ups=1.36, wpb=13443.3, bsz=455.9, num_updates=54400, lr=6.06339e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=0
2023-09-06 14:38:31 | INFO | train_inner | epoch 046:    927 / 1191 loss=1.796, trans_loss=4.586, nll_loss=1.766, w2v_ctc_loss=0.57, task_loss=2.646, task_loss_gen=5.542, contrastive_loss=0, total=6811.3, n_correct=4897.54, ppl=3.4, accuracy=71.903, wps=18669.5, ups=1.37, wpb=13622.6, bsz=468.4, num_updates=54500, lr=6.05783e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=0
2023-09-06 14:39:45 | INFO | train_inner | epoch 046:   1027 / 1191 loss=1.802, trans_loss=4.588, nll_loss=1.769, w2v_ctc_loss=0.577, task_loss=2.799, task_loss_gen=6.396, contrastive_loss=0, total=6588.76, n_correct=4737.95, ppl=3.41, accuracy=71.91, wps=17895.4, ups=1.36, wpb=13177.5, bsz=423.3, num_updates=54600, lr=6.05228e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=0
2023-09-06 14:40:57 | INFO | train_inner | epoch 046:   1127 / 1191 loss=1.798, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.573, task_loss=2.831, task_loss_gen=6.546, contrastive_loss=0, total=6492.04, n_correct=4670.87, ppl=3.38, accuracy=71.948, wps=18014.4, ups=1.39, wpb=12984.1, bsz=419.7, num_updates=54700, lr=6.04674e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=0
2023-09-06 14:41:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(1707.3628, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1057.1147, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1481.7738, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(868.3412, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1138.5153, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(718.0974, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2201.6121, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1289.4028, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2248.2708, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1311.4828, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2465.6396, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1487.9614, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1773.3262, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1023.3325, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-06 14:42:17 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 3.65 | trans_loss 4.878 | nll_loss 2.095 | w2v_ctc_loss 1.146 | task_loss 34.169 | task_loss_gen 19.438 | contrastive_loss 0 | total 6138.43 | n_correct 4365.43 | ppl 4.27 | accuracy 71.116 | uer 16.875 | wer 18.453 | raw_wer 18.453 | bleu 29.05 | wps 1704.7 | wpb 6138.4 | bsz 201.1 | num_updates 54764 | best_bleu 29.25
2023-09-06 14:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 54764 updates
2023-09-06 14:42:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt
2023-09-06 14:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt
2023-09-06 14:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_29.0504.pt (epoch 46 @ 54764 updates, score 29.05) (writing took 9.657549981959164 seconds)
2023-09-06 14:42:27 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-09-06 14:42:27 | INFO | train | epoch 046 | loss 1.794 | trans_loss 4.581 | nll_loss 1.761 | w2v_ctc_loss 0.565 | task_loss 2.732 | task_loss_gen 5.918 | contrastive_loss 0 | total 6703.69 | n_correct 4825.94 | ppl 3.39 | accuracy 71.989 | wps 16587 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 54764 | lr 6.04321e-05 | gnorm 0.4 | clip 0 | loss_scale 64 | train_wall 858 | gb_free 14.3 | wall 0
2023-09-06 14:42:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:42:27 | INFO | fairseq.trainer | begin training epoch 47
2023-09-06 14:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:43:01 | INFO | train_inner | epoch 047:     36 / 1191 loss=1.795, trans_loss=4.581, nll_loss=1.76, w2v_ctc_loss=0.568, task_loss=2.598, task_loss_gen=6.203, contrastive_loss=0, total=6621.19, n_correct=4766.48, ppl=3.39, accuracy=71.988, wps=10659, ups=0.8, wpb=13242.4, bsz=446.8, num_updates=54800, lr=6.04122e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:44:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 14:44:15 | INFO | train_inner | epoch 047:    137 / 1191 loss=1.784, trans_loss=4.568, nll_loss=1.743, w2v_ctc_loss=0.555, task_loss=2.174, task_loss_gen=6.138, contrastive_loss=0, total=6721.79, n_correct=4860.32, ppl=3.35, accuracy=72.307, wps=18151, ups=1.35, wpb=13443.6, bsz=459.4, num_updates=54900, lr=6.03572e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=0
2023-09-06 14:45:28 | INFO | train_inner | epoch 047:    237 / 1191 loss=1.786, trans_loss=4.57, nll_loss=1.746, w2v_ctc_loss=0.556, task_loss=2.462, task_loss_gen=6.155, contrastive_loss=0, total=6718.37, n_correct=4853.18, ppl=3.35, accuracy=72.237, wps=18427, ups=1.37, wpb=13436.7, bsz=453.6, num_updates=55000, lr=6.03023e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=0
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 14:46:42 | INFO | train_inner | epoch 047:    337 / 1191 loss=1.795, trans_loss=4.578, nll_loss=1.756, w2v_ctc_loss=0.568, task_loss=2.896, task_loss_gen=6.253, contrastive_loss=0, total=6617.22, n_correct=4766.15, ppl=3.38, accuracy=72.026, wps=17919.5, ups=1.35, wpb=13234.4, bsz=438.4, num_updates=55100, lr=6.02475e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=73, gb_free=10.8, wall=0
2023-09-06 14:47:55 | INFO | train_inner | epoch 047:    437 / 1191 loss=1.789, trans_loss=4.568, nll_loss=1.744, w2v_ctc_loss=0.558, task_loss=2.913, task_loss_gen=6.245, contrastive_loss=0, total=6600.85, n_correct=4765.64, ppl=3.35, accuracy=72.197, wps=18007.5, ups=1.36, wpb=13201.7, bsz=436.7, num_updates=55200, lr=6.01929e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=73, gb_free=10.7, wall=0
2023-09-06 14:49:08 | INFO | train_inner | epoch 047:    537 / 1191 loss=1.789, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.564, task_loss=2.624, task_loss_gen=5.665, contrastive_loss=0, total=6749.44, n_correct=4867.62, ppl=3.37, accuracy=72.119, wps=18641.2, ups=1.38, wpb=13498.9, bsz=466, num_updates=55300, lr=6.01385e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=0
2023-09-06 14:50:21 | INFO | train_inner | epoch 047:    637 / 1191 loss=1.792, trans_loss=4.576, nll_loss=1.754, w2v_ctc_loss=0.568, task_loss=2.76, task_loss_gen=5.746, contrastive_loss=0, total=6757.57, n_correct=4875.85, ppl=3.37, accuracy=72.154, wps=18540, ups=1.37, wpb=13515.1, bsz=464.1, num_updates=55400, lr=6.00842e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=0
2023-09-06 14:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 14:51:34 | INFO | train_inner | epoch 047:    738 / 1191 loss=1.796, trans_loss=4.583, nll_loss=1.763, w2v_ctc_loss=0.568, task_loss=2.983, task_loss_gen=6.015, contrastive_loss=0, total=6661.83, n_correct=4794.69, ppl=3.39, accuracy=71.973, wps=18234.9, ups=1.37, wpb=13323.7, bsz=440.3, num_updates=55500, lr=6.003e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=0
2023-09-06 14:52:47 | INFO | train_inner | epoch 047:    838 / 1191 loss=1.783, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.552, task_loss=3.196, task_loss_gen=5.254, contrastive_loss=0, total=6828.86, n_correct=4933.26, ppl=3.36, accuracy=72.241, wps=18630.4, ups=1.36, wpb=13657.7, bsz=468.6, num_updates=55600, lr=5.9976e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=0
2023-09-06 14:54:00 | INFO | train_inner | epoch 047:    938 / 1191 loss=1.789, trans_loss=4.578, nll_loss=1.756, w2v_ctc_loss=0.556, task_loss=3.179, task_loss_gen=5.454, contrastive_loss=0, total=6700.11, n_correct=4826.43, ppl=3.38, accuracy=72.035, wps=18417.4, ups=1.37, wpb=13400.2, bsz=450.2, num_updates=55700, lr=5.99222e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=0
2023-09-06 14:55:13 | INFO | train_inner | epoch 047:   1038 / 1191 loss=1.794, trans_loss=4.581, nll_loss=1.76, w2v_ctc_loss=0.565, task_loss=3.273, task_loss_gen=5.429, contrastive_loss=0, total=6711.84, n_correct=4834.47, ppl=3.39, accuracy=72.029, wps=18281.4, ups=1.36, wpb=13423.7, bsz=450.4, num_updates=55800, lr=5.98684e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=73, gb_free=11.7, wall=0
2023-09-06 14:55:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 14:56:26 | INFO | train_inner | epoch 047:   1139 / 1191 loss=1.796, trans_loss=4.584, nll_loss=1.764, w2v_ctc_loss=0.565, task_loss=3.582, task_loss_gen=5.573, contrastive_loss=0, total=6626.4, n_correct=4766.25, ppl=3.4, accuracy=71.928, wps=18253.6, ups=1.38, wpb=13252.8, bsz=433.7, num_updates=55900, lr=5.98149e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=0
2023-09-06 14:57:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
mt_weight tensor(0.5000)
asr_weight tensor(0.1786)
2023-09-06 14:57:37 | INFO | dev_st | epoch 047 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.872 | nll_loss 2.088 | w2v_ctc_loss 1.195 | task_loss 50.577 | task_loss_gen 26.338 | contrastive_loss 0 | total 6138.43 | n_correct 4370.71 | ppl 4.25 | accuracy 71.202 | uer 16.621 | wer 18.219 | raw_wer 18.219 | bleu 28.67 | wps 1688.6 | wpb 6138.4 | bsz 201.1 | num_updates 55952 | best_bleu 29.25
2023-09-06 14:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 55952 updates
2023-09-06 14:57:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt
2023-09-06 14:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt
2023-09-06 14:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.6702.pt (epoch 47 @ 55952 updates, score 28.67) (writing took 7.97138655197341 seconds)
2023-09-06 14:57:46 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-09-06 14:57:46 | INFO | train | epoch 047 | loss 1.79 | trans_loss 4.576 | nll_loss 1.754 | w2v_ctc_loss 0.562 | task_loss 2.92 | task_loss_gen 5.776 | contrastive_loss 0 | total 6703.56 | n_correct 4834.4 | ppl 3.37 | accuracy 72.117 | wps 17343.1 | ups 1.29 | wpb 13407.1 | bsz 452.1 | num_updates 55952 | lr 5.97871e-05 | gnorm 0.429 | clip 0 | loss_scale 8 | train_wall 860 | gb_free 13.7 | wall 0
2023-09-06 14:57:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 14:57:46 | INFO | fairseq.trainer | begin training epoch 48
2023-09-06 14:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 14:58:29 | INFO | train_inner | epoch 048:     48 / 1191 loss=1.789, trans_loss=4.577, nll_loss=1.755, w2v_ctc_loss=0.56, task_loss=3.564, task_loss_gen=5.008, contrastive_loss=0, total=6755.92, n_correct=4875.99, ppl=3.38, accuracy=72.174, wps=11004.7, ups=0.81, wpb=13511.8, bsz=465.5, num_updates=56000, lr=5.97614e-05, gnorm=0.576, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=0
2023-09-06 14:58:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 14:59:02 | INFO | dev_st | epoch 048 | valid on 'dev_st' subset | loss 3.67 | trans_loss 4.876 | nll_loss 2.091 | w2v_ctc_loss 1.218 | task_loss 34.95 | task_loss_gen 20.11 | contrastive_loss 0 | total 6138.43 | n_correct 4367.57 | ppl 4.26 | accuracy 71.151 | uer 16.757 | wer 18.219 | raw_wer 18.219 | bleu 28.84 | wps 1678.6 | wpb 6138.4 | bsz 201.1 | num_updates 56000 | best_bleu 29.25
2023-09-06 14:59:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 56000 updates
2023-09-06 14:59:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt
2023-09-06 14:59:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt
2023-09-06 14:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_48_56000.pt (epoch 48 @ 56000 updates, score 28.84) (writing took 10.312104300945066 seconds)
--Backword ST Loss tensor(2573.0110, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1487.2593, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 15:00:26 | INFO | train_inner | epoch 048:    148 / 1191 loss=1.788, trans_loss=4.576, nll_loss=1.753, w2v_ctc_loss=0.557, task_loss=3.658, task_loss_gen=5.146, contrastive_loss=0, total=6761.65, n_correct=4876.25, ppl=3.37, accuracy=72.116, wps=11504.9, ups=0.85, wpb=13523.3, bsz=465.9, num_updates=56100, lr=5.97081e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=0
2023-09-06 15:01:39 | INFO | train_inner | epoch 048:    248 / 1191 loss=1.786, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.55, task_loss=3.842, task_loss_gen=5.215, contrastive_loss=0, total=6673.84, n_correct=4811.49, ppl=3.37, accuracy=72.095, wps=18362.9, ups=1.38, wpb=13347.7, bsz=451.5, num_updates=56200, lr=5.9655e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=0
2023-09-06 15:02:51 | INFO | train_inner | epoch 048:    348 / 1191 loss=1.784, trans_loss=4.571, nll_loss=1.748, w2v_ctc_loss=0.556, task_loss=3.395, task_loss_gen=4.87, contrastive_loss=0, total=6764.05, n_correct=4888.96, ppl=3.36, accuracy=72.279, wps=18668.5, ups=1.38, wpb=13528.1, bsz=468.9, num_updates=56300, lr=5.9602e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=0
2023-09-06 15:04:04 | INFO | train_inner | epoch 048:    448 / 1191 loss=1.788, trans_loss=4.572, nll_loss=1.748, w2v_ctc_loss=0.556, task_loss=3.696, task_loss_gen=5.188, contrastive_loss=0, total=6606.75, n_correct=4768.83, ppl=3.36, accuracy=72.181, wps=18241.5, ups=1.38, wpb=13213.5, bsz=444, num_updates=56400, lr=5.95491e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=72, gb_free=11.2, wall=0
2023-09-06 15:05:16 | INFO | train_inner | epoch 048:    548 / 1191 loss=1.784, trans_loss=4.57, nll_loss=1.746, w2v_ctc_loss=0.555, task_loss=3.513, task_loss_gen=4.954, contrastive_loss=0, total=6781.21, n_correct=4899.74, ppl=3.35, accuracy=72.255, wps=18752.6, ups=1.38, wpb=13562.4, bsz=471.7, num_updates=56500, lr=5.94964e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:06:28 | INFO | train_inner | epoch 048:    648 / 1191 loss=1.788, trans_loss=4.568, nll_loss=1.743, w2v_ctc_loss=0.557, task_loss=4.071, task_loss_gen=5.516, contrastive_loss=0, total=6643.62, n_correct=4800.77, ppl=3.35, accuracy=72.261, wps=18383.6, ups=1.38, wpb=13287.2, bsz=428.9, num_updates=56600, lr=5.94438e-05, gnorm=0.624, clip=0, loss_scale=8, train_wall=71, gb_free=13.1, wall=0
2023-09-06 15:07:41 | INFO | train_inner | epoch 048:    748 / 1191 loss=1.795, trans_loss=4.58, nll_loss=1.758, w2v_ctc_loss=0.565, task_loss=3.869, task_loss_gen=5.547, contrastive_loss=0, total=6579.2, n_correct=4739.13, ppl=3.38, accuracy=72.032, wps=18044.7, ups=1.37, wpb=13158.4, bsz=423, num_updates=56700, lr=5.93914e-05, gnorm=0.589, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=0
2023-09-06 15:08:54 | INFO | train_inner | epoch 048:    848 / 1191 loss=1.784, trans_loss=4.572, nll_loss=1.75, w2v_ctc_loss=0.554, task_loss=3.401, task_loss_gen=4.831, contrastive_loss=0, total=6756.73, n_correct=4881.84, ppl=3.36, accuracy=72.252, wps=18601.4, ups=1.38, wpb=13513.5, bsz=466.3, num_updates=56800, lr=5.93391e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=72, gb_free=12.4, wall=0
2023-09-06 15:10:06 | INFO | train_inner | epoch 048:    948 / 1191 loss=1.789, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.558, task_loss=3.978, task_loss_gen=5.483, contrastive_loss=0, total=6678.5, n_correct=4817.58, ppl=3.37, accuracy=72.136, wps=18476.1, ups=1.38, wpb=13357, bsz=438.4, num_updates=56900, lr=5.92869e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=0
2023-09-06 15:11:19 | INFO | train_inner | epoch 048:   1048 / 1191 loss=1.787, trans_loss=4.579, nll_loss=1.757, w2v_ctc_loss=0.554, task_loss=3.92, task_loss_gen=5.128, contrastive_loss=0, total=6849.67, n_correct=4939.53, ppl=3.38, accuracy=72.113, wps=18778.1, ups=1.37, wpb=13699.3, bsz=473.3, num_updates=57000, lr=5.92349e-05, gnorm=0.622, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=0
2023-09-06 15:12:33 | INFO | train_inner | epoch 048:   1148 / 1191 loss=1.792, trans_loss=4.581, nll_loss=1.759, w2v_ctc_loss=0.56, task_loss=3.728, task_loss_gen=5.18, contrastive_loss=0, total=6719.48, n_correct=4837.73, ppl=3.38, accuracy=71.996, wps=18267.1, ups=1.36, wpb=13439, bsz=447.9, num_updates=57100, lr=5.9183e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=73, gb_free=14.9, wall=0
2023-09-06 15:13:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(3237.3193, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1964.2389, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1470.1304, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(897.3575, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1136.5033, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(671.9695, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1734.4319, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(989.7063, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1933.6711, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1144.8184, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2047.3541, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1203.7058, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1514.3202, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(849.9476, device='cuda:5', grad_fn=<MulBackward0>)
2023-09-06 15:13:36 | INFO | dev_st | epoch 048 | valid on 'dev_st' subset | loss 3.671 | trans_loss 4.878 | nll_loss 2.095 | w2v_ctc_loss 1.215 | task_loss 20.257 | task_loss_gen 15.241 | contrastive_loss 0 | total 6138.43 | n_correct 4366.86 | ppl 4.27 | accuracy 71.14 | uer 17.027 | wer 18.579 | raw_wer 18.579 | bleu 28.75 | wps 1755 | wpb 6138.4 | bsz 201.1 | num_updates 57143 | best_bleu 29.25
2023-09-06 15:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 57143 updates
2023-09-06 15:13:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt
2023-09-06 15:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt
2023-09-06 15:13:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7504.pt (epoch 48 @ 57143 updates, score 28.75) (writing took 7.5665960350306705 seconds)
2023-09-06 15:13:44 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-09-06 15:13:44 | INFO | train | epoch 048 | loss 1.788 | trans_loss 4.574 | nll_loss 1.752 | w2v_ctc_loss 0.557 | task_loss 3.73 | task_loss_gen 5.173 | contrastive_loss 0 | total 6703.69 | n_correct 4837.24 | ppl 3.37 | accuracy 72.158 | wps 16656.7 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 57143 | lr 5.91607e-05 | gnorm 0.58 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 13.2 | wall 0
2023-09-06 15:13:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:13:44 | INFO | fairseq.trainer | begin training epoch 49
2023-09-06 15:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:14:33 | INFO | train_inner | epoch 049:     57 / 1191 loss=1.781, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.549, task_loss=3.647, task_loss_gen=4.953, contrastive_loss=0, total=6679.78, n_correct=4834.63, ppl=3.34, accuracy=72.377, wps=11077, ups=0.83, wpb=13359.6, bsz=456.1, num_updates=57200, lr=5.91312e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=71, gb_free=13.5, wall=0
2023-09-06 15:15:46 | INFO | train_inner | epoch 049:    157 / 1191 loss=1.787, trans_loss=4.567, nll_loss=1.741, w2v_ctc_loss=0.554, task_loss=3.838, task_loss_gen=5.418, contrastive_loss=0, total=6612.2, n_correct=4781.45, ppl=3.34, accuracy=72.313, wps=18220.3, ups=1.38, wpb=13224.4, bsz=422.4, num_updates=57300, lr=5.90796e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=0
2023-09-06 15:16:58 | INFO | train_inner | epoch 049:    257 / 1191 loss=1.782, trans_loss=4.564, nll_loss=1.738, w2v_ctc_loss=0.553, task_loss=3.672, task_loss_gen=4.959, contrastive_loss=0, total=6685.78, n_correct=4839.98, ppl=3.34, accuracy=72.392, wps=18445, ups=1.38, wpb=13371.6, bsz=456.3, num_updates=57400, lr=5.90281e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=72, gb_free=12.9, wall=0
2023-09-06 15:18:11 | INFO | train_inner | epoch 049:    357 / 1191 loss=1.784, trans_loss=4.568, nll_loss=1.744, w2v_ctc_loss=0.555, task_loss=3.615, task_loss_gen=4.949, contrastive_loss=0, total=6723.83, n_correct=4863.11, ppl=3.35, accuracy=72.326, wps=18609.8, ups=1.38, wpb=13447.7, bsz=459.3, num_updates=57500, lr=5.89768e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=72, gb_free=15.3, wall=0
2023-09-06 15:19:23 | INFO | train_inner | epoch 049:    457 / 1191 loss=1.789, trans_loss=4.576, nll_loss=1.753, w2v_ctc_loss=0.557, task_loss=3.736, task_loss_gen=5.209, contrastive_loss=0, total=6648.78, n_correct=4791.83, ppl=3.37, accuracy=72.071, wps=18352.9, ups=1.38, wpb=13297.6, bsz=452.1, num_updates=57600, lr=5.89256e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=72, gb_free=9.9, wall=0
2023-09-06 15:20:36 | INFO | train_inner | epoch 049:    557 / 1191 loss=1.791, trans_loss=4.575, nll_loss=1.751, w2v_ctc_loss=0.559, task_loss=3.747, task_loss_gen=5.176, contrastive_loss=0, total=6687.89, n_correct=4819.23, ppl=3.37, accuracy=72.059, wps=18478.6, ups=1.38, wpb=13375.8, bsz=438.2, num_updates=57700, lr=5.88745e-05, gnorm=0.556, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=0
2023-09-06 15:21:49 | INFO | train_inner | epoch 049:    657 / 1191 loss=1.787, trans_loss=4.574, nll_loss=1.75, w2v_ctc_loss=0.556, task_loss=3.83, task_loss_gen=5.245, contrastive_loss=0, total=6670.64, n_correct=4817.54, ppl=3.36, accuracy=72.22, wps=18076.5, ups=1.35, wpb=13341.3, bsz=443.9, num_updates=57800, lr=5.88235e-05, gnorm=0.571, clip=0, loss_scale=8, train_wall=73, gb_free=14.2, wall=0
2023-09-06 15:23:01 | INFO | train_inner | epoch 049:    757 / 1191 loss=1.785, trans_loss=4.575, nll_loss=1.752, w2v_ctc_loss=0.551, task_loss=3.711, task_loss_gen=5.026, contrastive_loss=0, total=6753.54, n_correct=4878.54, ppl=3.37, accuracy=72.237, wps=18772.8, ups=1.39, wpb=13507.1, bsz=465, num_updates=57900, lr=5.87727e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=71, gb_free=13.6, wall=0
2023-09-06 15:24:14 | INFO | train_inner | epoch 049:    857 / 1191 loss=1.787, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.557, task_loss=3.076, task_loss_gen=4.962, contrastive_loss=0, total=6770.54, n_correct=4887.61, ppl=3.36, accuracy=72.189, wps=18655.6, ups=1.38, wpb=13541.1, bsz=466.9, num_updates=58000, lr=5.8722e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=0
2023-09-06 15:24:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:24:47 | INFO | dev_st | epoch 049 | valid on 'dev_st' subset | loss 3.661 | trans_loss 4.874 | nll_loss 2.089 | w2v_ctc_loss 1.192 | task_loss 28.37 | task_loss_gen 17.202 | contrastive_loss 0 | total 6138.43 | n_correct 4377.14 | ppl 4.25 | accuracy 71.307 | uer 16.589 | wer 18.133 | raw_wer 18.133 | bleu 28.59 | wps 1734.8 | wpb 6138.4 | bsz 201.1 | num_updates 58000 | best_bleu 29.25
2023-09-06 15:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 58000 updates
2023-09-06 15:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt
2023-09-06 15:24:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt
2023-09-06 15:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_49_58000.pt (epoch 49 @ 58000 updates, score 28.59) (writing took 6.9795685049612075 seconds)
--Backword ST Loss tensor(2259.4529, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1271.5597, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-06 15:26:06 | INFO | train_inner | epoch 049:    957 / 1191 loss=1.784, trans_loss=4.573, nll_loss=1.749, w2v_ctc_loss=0.553, task_loss=3.144, task_loss_gen=4.817, contrastive_loss=0, total=6761.92, n_correct=4883.79, ppl=3.36, accuracy=72.225, wps=12042.5, ups=0.89, wpb=13523.8, bsz=467.2, num_updates=58100, lr=5.86715e-05, gnorm=0.437, clip=0, loss_scale=16, train_wall=71, gb_free=11.9, wall=0
2023-09-06 15:27:20 | INFO | train_inner | epoch 049:   1057 / 1191 loss=1.784, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.551, task_loss=3.153, task_loss_gen=5.301, contrastive_loss=0, total=6705.5, n_correct=4850.33, ppl=3.36, accuracy=72.334, wps=18278.2, ups=1.36, wpb=13411, bsz=447.5, num_updates=58200, lr=5.8621e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=11.1, wall=0
2023-09-06 15:28:33 | INFO | train_inner | epoch 049:   1157 / 1191 loss=1.787, trans_loss=4.572, nll_loss=1.749, w2v_ctc_loss=0.553, task_loss=3.384, task_loss_gen=5.385, contrastive_loss=0, total=6652.04, n_correct=4803.87, ppl=3.36, accuracy=72.216, wps=18207.7, ups=1.37, wpb=13304.1, bsz=436.4, num_updates=58300, lr=5.85707e-05, gnorm=0.453, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=0
2023-09-06 15:28:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2049.5686, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1088.6987, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3155.9907, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1955.5491, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2143.3647, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1082.7660, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3638.3079, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(2152.2073, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1152.7844, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(690.7031, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1469.7068, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(865.5139, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2844.4546, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1675.8196, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-06 15:29:30 | INFO | dev_st | epoch 049 | valid on 'dev_st' subset | loss 3.649 | trans_loss 4.873 | nll_loss 2.089 | w2v_ctc_loss 1.153 | task_loss 30.537 | task_loss_gen 17.778 | contrastive_loss 0 | total 6138.43 | n_correct 4373.14 | ppl 4.25 | accuracy 71.242 | uer 16.431 | wer 18.062 | raw_wer 18.062 | bleu 28.71 | wps 1756.7 | wpb 6138.4 | bsz 201.1 | num_updates 58334 | best_bleu 29.25
2023-09-06 15:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 58334 updates
2023-09-06 15:29:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt
2023-09-06 15:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt
2023-09-06 15:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.7102.pt (epoch 49 @ 58334 updates, score 28.71) (writing took 7.675531419925392 seconds)
2023-09-06 15:29:38 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-09-06 15:29:38 | INFO | train | epoch 049 | loss 1.785 | trans_loss 4.571 | nll_loss 1.747 | w2v_ctc_loss 0.554 | task_loss 3.515 | task_loss_gen 5.103 | contrastive_loss 0 | total 6703.69 | n_correct 4843.69 | ppl 3.36 | accuracy 72.254 | wps 16743 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 58334 | lr 5.85537e-05 | gnorm 0.516 | clip 0 | loss_scale 16 | train_wall 856 | gb_free 13.7 | wall 0
2023-09-06 15:29:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:29:38 | INFO | fairseq.trainer | begin training epoch 50
2023-09-06 15:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:30:34 | INFO | train_inner | epoch 050:     66 / 1191 loss=1.779, trans_loss=4.564, nll_loss=1.739, w2v_ctc_loss=0.548, task_loss=3.176, task_loss_gen=5.089, contrastive_loss=0, total=6708.17, n_correct=4862.95, ppl=3.34, accuracy=72.493, wps=11065.7, ups=0.82, wpb=13416.3, bsz=455.7, num_updates=58400, lr=5.85206e-05, gnorm=0.435, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=0
2023-09-06 15:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 15:31:48 | INFO | train_inner | epoch 050:    167 / 1191 loss=1.775, trans_loss=4.558, nll_loss=1.731, w2v_ctc_loss=0.539, task_loss=3.048, task_loss_gen=5, contrastive_loss=0, total=6753.39, n_correct=4897.72, ppl=3.32, accuracy=72.522, wps=18355.4, ups=1.36, wpb=13506.8, bsz=460.9, num_updates=58500, lr=5.84705e-05, gnorm=0.459, clip=0, loss_scale=8, train_wall=73, gb_free=14.9, wall=0
2023-09-06 15:33:00 | INFO | train_inner | epoch 050:    267 / 1191 loss=1.785, trans_loss=4.565, nll_loss=1.738, w2v_ctc_loss=0.555, task_loss=3.712, task_loss_gen=5.359, contrastive_loss=0, total=6571.43, n_correct=4754.96, ppl=3.34, accuracy=72.358, wps=18190.8, ups=1.38, wpb=13142.9, bsz=420.8, num_updates=58600, lr=5.84206e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=0
2023-09-06 15:34:12 | INFO | train_inner | epoch 050:    367 / 1191 loss=1.783, trans_loss=4.565, nll_loss=1.739, w2v_ctc_loss=0.554, task_loss=3.755, task_loss_gen=5.018, contrastive_loss=0, total=6736.79, n_correct=4876.72, ppl=3.34, accuracy=72.389, wps=18560, ups=1.38, wpb=13473.6, bsz=451.1, num_updates=58700, lr=5.83708e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:35:25 | INFO | train_inner | epoch 050:    467 / 1191 loss=1.778, trans_loss=4.565, nll_loss=1.739, w2v_ctc_loss=0.544, task_loss=3.564, task_loss_gen=4.845, contrastive_loss=0, total=6713.38, n_correct=4857.57, ppl=3.34, accuracy=72.357, wps=18454.4, ups=1.37, wpb=13426.8, bsz=467.5, num_updates=58800, lr=5.83212e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=72, gb_free=9.2, wall=0
2023-09-06 15:36:38 | INFO | train_inner | epoch 050:    567 / 1191 loss=1.778, trans_loss=4.564, nll_loss=1.739, w2v_ctc_loss=0.548, task_loss=3.483, task_loss_gen=4.797, contrastive_loss=0, total=6785.13, n_correct=4918.2, ppl=3.34, accuracy=72.485, wps=18637.9, ups=1.37, wpb=13570.3, bsz=469, num_updates=58900, lr=5.82717e-05, gnorm=0.571, clip=0, loss_scale=8, train_wall=72, gb_free=13.4, wall=0
2023-09-06 15:37:50 | INFO | train_inner | epoch 050:    667 / 1191 loss=1.784, trans_loss=4.561, nll_loss=1.735, w2v_ctc_loss=0.557, task_loss=3.933, task_loss_gen=5.341, contrastive_loss=0, total=6658.77, n_correct=4823.48, ppl=3.33, accuracy=72.438, wps=18385.4, ups=1.38, wpb=13317.5, bsz=435.7, num_updates=59000, lr=5.82223e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=0
2023-09-06 15:39:03 | INFO | train_inner | epoch 050:    767 / 1191 loss=1.776, trans_loss=4.562, nll_loss=1.735, w2v_ctc_loss=0.541, task_loss=3.659, task_loss_gen=5.023, contrastive_loss=0, total=6708.2, n_correct=4861.72, ppl=3.33, accuracy=72.474, wps=18539, ups=1.38, wpb=13416.4, bsz=447.6, num_updates=59100, lr=5.8173e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=72, gb_free=10.2, wall=0
2023-09-06 15:40:15 | INFO | train_inner | epoch 050:    867 / 1191 loss=1.788, trans_loss=4.573, nll_loss=1.75, w2v_ctc_loss=0.557, task_loss=3.688, task_loss_gen=5.081, contrastive_loss=0, total=6627.13, n_correct=4784.82, ppl=3.36, accuracy=72.2, wps=18360.4, ups=1.39, wpb=13254.3, bsz=441.5, num_updates=59200, lr=5.81238e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=71, gb_free=11.4, wall=0
2023-09-06 15:41:28 | INFO | train_inner | epoch 050:    967 / 1191 loss=1.783, trans_loss=4.569, nll_loss=1.745, w2v_ctc_loss=0.552, task_loss=3.808, task_loss_gen=5.227, contrastive_loss=0, total=6653.63, n_correct=4811.72, ppl=3.35, accuracy=72.317, wps=18278.6, ups=1.37, wpb=13307.3, bsz=443.3, num_updates=59300, lr=5.80748e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=0
2023-09-06 15:42:40 | INFO | train_inner | epoch 050:   1067 / 1191 loss=1.775, trans_loss=4.561, nll_loss=1.735, w2v_ctc_loss=0.542, task_loss=3.566, task_loss_gen=4.718, contrastive_loss=0, total=6789.63, n_correct=4924.81, ppl=3.33, accuracy=72.534, wps=18774, ups=1.38, wpb=13579.3, bsz=466.6, num_updates=59400, lr=5.80259e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=72, gb_free=12.5, wall=0
2023-09-06 15:43:52 | INFO | train_inner | epoch 050:   1167 / 1191 loss=1.779, trans_loss=4.567, nll_loss=1.742, w2v_ctc_loss=0.543, task_loss=3.379, task_loss_gen=4.731, contrastive_loss=0, total=6761.3, n_correct=4892.46, ppl=3.35, accuracy=72.36, wps=18792.7, ups=1.39, wpb=13522.6, bsz=467.9, num_updates=59500, lr=5.79771e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=71, gb_free=14.3, wall=0
2023-09-06 15:44:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:44:43 | INFO | dev_st | epoch 050 | valid on 'dev_st' subset | loss 3.66 | trans_loss 4.873 | nll_loss 2.091 | w2v_ctc_loss 1.192 | task_loss 28.958 | task_loss_gen 17.21 | contrastive_loss 0 | total 6138.43 | n_correct 4369.71 | ppl 4.26 | accuracy 71.186 | uer 17.124 | wer 18.754 | raw_wer 18.754 | bleu 28.85 | wps 1750.3 | wpb 6138.4 | bsz 201.1 | num_updates 59524 | best_bleu 29.25
2023-09-06 15:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 59524 updates
2023-09-06 15:44:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt
2023-09-06 15:44:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt
2023-09-06 15:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint.best_bleu_28.8503.pt (epoch 50 @ 59524 updates, score 28.85) (writing took 8.160001026000828 seconds)
2023-09-06 15:44:51 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-09-06 15:44:51 | INFO | train | epoch 050 | loss 1.78 | trans_loss 4.565 | nll_loss 1.739 | w2v_ctc_loss 0.548 | task_loss 3.574 | task_loss_gen 5.013 | contrastive_loss 0 | total 6704.13 | n_correct 4854.39 | ppl 3.34 | accuracy 72.409 | wps 17467 | ups 1.3 | wpb 13408.3 | bsz 452.1 | num_updates 59524 | lr 5.79654e-05 | gnorm 0.54 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 13.8 | wall 0
2023-09-06 15:44:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 15:44:52 | INFO | fairseq.trainer | begin training epoch 51
2023-09-06 15:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 15:45:54 | INFO | train_inner | epoch 051:     76 / 1191 loss=1.772, trans_loss=4.551, nll_loss=1.722, w2v_ctc_loss=0.541, task_loss=3.41, task_loss_gen=4.944, contrastive_loss=0, total=6696.16, n_correct=4871.23, ppl=3.3, accuracy=72.747, wps=11025.9, ups=0.82, wpb=13392.3, bsz=452.5, num_updates=59600, lr=5.79284e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=72, gb_free=13.1, wall=0
2023-09-06 15:47:05 | INFO | train_inner | epoch 051:    176 / 1191 loss=1.784, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.551, task_loss=3.878, task_loss_gen=5.324, contrastive_loss=0, total=6626.19, n_correct=4792.29, ppl=3.34, accuracy=72.323, wps=18419.1, ups=1.39, wpb=13252.4, bsz=435.1, num_updates=59700, lr=5.78799e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=71, gb_free=13.5, wall=0
2023-09-06 15:48:19 | INFO | train_inner | epoch 051:    276 / 1191 loss=1.782, trans_loss=4.559, nll_loss=1.732, w2v_ctc_loss=0.553, task_loss=4.049, task_loss_gen=5.536, contrastive_loss=0, total=6666.05, n_correct=4833.29, ppl=3.32, accuracy=72.506, wps=18235.1, ups=1.37, wpb=13332.1, bsz=432.4, num_updates=59800, lr=5.78315e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=72, gb_free=9.8, wall=0
2023-09-06 15:49:32 | INFO | train_inner | epoch 051:    376 / 1191 loss=1.777, trans_loss=4.56, nll_loss=1.733, w2v_ctc_loss=0.546, task_loss=3.723, task_loss_gen=5.123, contrastive_loss=0, total=6770.7, n_correct=4912.89, ppl=3.32, accuracy=72.561, wps=18446.6, ups=1.36, wpb=13541.4, bsz=469.4, num_updates=59900, lr=5.77832e-05, gnorm=0.583, clip=0, loss_scale=8, train_wall=73, gb_free=10.4, wall=0
2023-09-06 15:50:44 | INFO | train_inner | epoch 051:    476 / 1191 loss=1.779, trans_loss=4.566, nll_loss=1.741, w2v_ctc_loss=0.545, task_loss=3.541, task_loss_gen=4.985, contrastive_loss=0, total=6767.23, n_correct=4897.87, ppl=3.34, accuracy=72.376, wps=18699.5, ups=1.38, wpb=13534.5, bsz=463.7, num_updates=60000, lr=5.7735e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=72, gb_free=14.9, wall=0
2023-09-06 15:50:44 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-09-06 15:50:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 15:51:17 | INFO | dev_st | epoch 051 | valid on 'dev_st' subset | loss 3.672 | trans_loss 4.873 | nll_loss 2.09 | w2v_ctc_loss 1.231 | task_loss 44.877 | task_loss_gen 23.786 | contrastive_loss 0 | total 6138.43 | n_correct 4372.86 | ppl 4.26 | accuracy 71.237 | uer 16.915 | wer 18.382 | raw_wer 18.382 | bleu 29.04 | wps 1761.3 | wpb 6138.4 | bsz 201.1 | num_updates 60000 | best_bleu 29.25
2023-09-06 15:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 60000 updates
2023-09-06 15:51:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt
2023-09-06 15:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt
2023-09-06 15:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale3.5_alpha0_mt0.5/checkpoint_51_60000.pt (epoch 51 @ 60000 updates, score 29.04) (writing took 9.170054742018692 seconds)
2023-09-06 15:51:27 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-09-06 15:51:27 | INFO | train | epoch 051 | loss 1.778 | trans_loss 4.56 | nll_loss 1.733 | w2v_ctc_loss 0.547 | task_loss 3.739 | task_loss_gen 5.196 | contrastive_loss 0 | total 6706.48 | n_correct 4862.68 | ppl 3.32 | accuracy 72.507 | wps 16141.8 | ups 1.2 | wpb 13413 | bsz 449.9 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.563 | clip 0 | loss_scale 8 | train_wall 342 | gb_free 14.9 | wall 0
2023-09-06 15:51:27 | INFO | fairseq_cli.train | done training in 7983.4 seconds
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 384 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
